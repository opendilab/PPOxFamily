[2023-06-10 05:30:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 51
envstep_count: 1108
train_sample_count: 1108
avg_envstep_per_episode: 21.725490196078432
avg_sample_per_episode: 21.725490196078432
avg_envstep_per_sec: 856.6283801187
avg_train_sample_per_sec: 856.6283801187
avg_episode_per_sec: 39.42964565528312
collect_time: 1.2934430211691894
reward_mean: 1.6666666666666667
reward_std: 2.3982564472816716
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 1198
total_train_sample_count: 1173
total_episode_count: 51
total_duration: 1.2934430211691894
[2023-06-10 05:30:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 22.391304347826086
avg_sample_per_episode: 22.391304347826086
avg_envstep_per_sec: 919.2711252990808
avg_train_sample_per_sec: 919.2711252990808
avg_episode_per_sec: 41.05482695510458
collect_time: 1.1204529019280292
reward_mean: 1.7826086956521738
reward_std: 2.636805078270662
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 2267
total_train_sample_count: 2242
total_episode_count: 97
total_duration: 2.4138959230972183
[2023-06-10 05:30:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 24.617021276595743
avg_sample_per_episode: 24.617021276595743
avg_envstep_per_sec: 896.0031688662073
avg_train_sample_per_sec: 896.0031688662073
avg_episode_per_sec: 36.39770867477247
collect_time: 1.2912900759760206
reward_mean: 2.382978723404255
reward_std: 2.8175226139994636
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 3317
total_train_sample_count: 3308
total_episode_count: 144
total_duration: 3.705185999073239
[2023-06-10 05:30:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1001
train_sample_count: 1001
avg_envstep_per_episode: 21.29787234042553
avg_sample_per_episode: 21.29787234042553
avg_envstep_per_sec: 803.7639588094877
avg_train_sample_per_sec: 803.7639588094877
avg_episode_per_sec: 37.73916689714878
collect_time: 1.2453905018118163
reward_mean: 1.446808510638298
reward_std: 1.9549012124825809
reward_max: 7.0
reward_min: 0.0
total_envstep_count: 4359
total_train_sample_count: 4348
total_episode_count: 191
total_duration: 4.950576500885055
[2023-06-10 05:30:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1058
train_sample_count: 1058
avg_envstep_per_episode: 24.045454545454547
avg_sample_per_episode: 24.045454545454547
avg_envstep_per_sec: 828.7941557307839
avg_train_sample_per_sec: 828.7941557307839
avg_episode_per_sec: 34.467809879163035
collect_time: 1.2765534031391852
reward_mean: 2.2045454545454546
reward_std: 2.966322681020034
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 5427
total_train_sample_count: 5419
total_episode_count: 235
total_duration: 6.22712990402424
[2023-06-10 05:30:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 21.9375
avg_sample_per_episode: 21.9375
avg_envstep_per_sec: 807.1030147195497
avg_train_sample_per_sec: 807.1030147195497
avg_episode_per_sec: 36.79102061399657
collect_time: 1.3046661712270942
reward_mean: 1.7916666666666667
reward_std: 2.6532867458221614
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 6471
total_train_sample_count: 6459
total_episode_count: 283
total_duration: 7.531796075251334
[2023-06-10 05:30:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 24.244444444444444
avg_sample_per_episode: 24.244444444444444
avg_envstep_per_sec: 849.8645113163511
avg_train_sample_per_sec: 849.8645113163511
avg_episode_per_sec: 35.05398992597232
collect_time: 1.2837340369821482
reward_mean: 2.422222222222222
reward_std: 2.7446018848227953
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 7552
total_train_sample_count: 7550
total_episode_count: 328
total_duration: 8.815530112233482
[2023-06-10 05:30:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1066
train_sample_count: 1066
avg_envstep_per_episode: 23.17391304347826
avg_sample_per_episode: 23.17391304347826
avg_envstep_per_sec: 750.0278867750177
avg_train_sample_per_sec: 750.0278867750177
avg_episode_per_sec: 32.36518085520714
collect_time: 1.4212804867611049
reward_mean: 1.9782608695652173
reward_std: 2.6661251025377366
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 8646
total_train_sample_count: 8629
total_episode_count: 374
total_duration: 10.236810598994587
[2023-06-10 05:30:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 50
envstep_count: 1149
train_sample_count: 1149
avg_envstep_per_episode: 22.98
avg_sample_per_episode: 22.98
avg_envstep_per_sec: 808.0117733833572
avg_train_sample_per_sec: 808.0117733833572
avg_episode_per_sec: 35.16152190528099
collect_time: 1.4220089828503806
reward_mean: 1.72
reward_std: 2.6611275805567836
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 9755
total_train_sample_count: 9726
total_episode_count: 424
total_duration: 11.658819581844968
[2023-06-10 05:30:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 51
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 20.980392156862745
avg_sample_per_episode: 20.980392156862745
avg_envstep_per_sec: 814.2800876211453
avg_train_sample_per_sec: 814.2800876211453
avg_episode_per_sec: 38.81148081184898
collect_time: 1.3140441676842671
reward_mean: 1.5098039215686274
reward_std: 2.622471136831449
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 10850
total_train_sample_count: 10835
total_episode_count: 475
total_duration: 12.972863749529235
[2023-06-10 05:31:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1112
train_sample_count: 1112
avg_envstep_per_episode: 24.17391304347826
avg_sample_per_episode: 24.17391304347826
avg_envstep_per_sec: 799.8655530911634
avg_train_sample_per_sec: 799.8655530911634
avg_episode_per_sec: 33.08796352715244
collect_time: 1.3902336407694527
reward_mean: 2.347826086956522
reward_std: 2.7443015370538264
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 11919
total_train_sample_count: 11908
total_episode_count: 521
total_duration: 14.363097390298687
[2023-06-10 05:31:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 23.571428571428573
avg_sample_per_episode: 23.571428571428573
avg_envstep_per_sec: 811.4949561562745
avg_train_sample_per_sec: 811.4949561562745
avg_episode_per_sec: 34.42705874602377
collect_time: 1.2199706140987396
reward_mean: 1.7857142857142858
reward_std: 2.3556994137391882
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 12993
total_train_sample_count: 12963
total_episode_count: 563
total_duration: 15.583068004397427
[2023-06-10 05:31:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1079
train_sample_count: 1079
avg_envstep_per_episode: 25.093023255813954
avg_sample_per_episode: 25.093023255813954
avg_envstep_per_sec: 815.3137964021945
avg_train_sample_per_sec: 815.3137964021945
avg_episode_per_sec: 32.491652683312665
collect_time: 1.323416830135092
reward_mean: 2.511627906976744
reward_std: 3.2662623046751973
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 14051
total_train_sample_count: 14042
total_episode_count: 606
total_duration: 16.90648483453252
[2023-06-10 05:31:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 24.727272727272727
avg_sample_per_episode: 24.727272727272727
avg_envstep_per_sec: 857.763726431068
avg_train_sample_per_sec: 857.763726431068
avg_episode_per_sec: 34.688974230668194
collect_time: 1.2684145604138395
reward_mean: 2.522727272727273
reward_std: 3.467305977816445
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 15130
total_train_sample_count: 15130
total_episode_count: 650
total_duration: 18.174899394946358
[2023-06-10 05:31:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 21.617021276595743
avg_sample_per_episode: 21.617021276595743
avg_envstep_per_sec: 749.8591209058128
avg_train_sample_per_sec: 749.8591209058128
avg_episode_per_sec: 34.68836484505237
collect_time: 1.3549211734234758
reward_mean: 1.7234042553191489
reward_std: 2.718746016163964
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 16176
total_train_sample_count: 16172
total_episode_count: 697
total_duration: 19.529820568369836
[2023-06-10 05:31:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 50
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 21.06
avg_sample_per_episode: 21.06
avg_envstep_per_sec: 789.3475396823638
avg_train_sample_per_sec: 789.3475396823638
avg_episode_per_sec: 37.48088982347407
collect_time: 1.334013152715635
reward_mean: 1.38
reward_std: 2.3228430855311775
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 17245
total_train_sample_count: 17225
total_episode_count: 747
total_duration: 20.86383372108547
[2023-06-10 05:31:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 49
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 23.612244897959183
avg_sample_per_episode: 23.612244897959183
avg_envstep_per_sec: 820.1909644574099
avg_train_sample_per_sec: 820.1909644574099
avg_episode_per_sec: 34.73583168402168
collect_time: 1.4106470933453932
reward_mean: 2.163265306122449
reward_std: 2.8381291536640765
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 18311
total_train_sample_count: 18291
total_episode_count: 796
total_duration: 22.274480814430863
[2023-06-10 05:31:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 50
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 20.72
avg_sample_per_episode: 20.72
avg_envstep_per_sec: 751.1472036511724
avg_train_sample_per_sec: 751.1472036511724
avg_episode_per_sec: 36.25227816849288
collect_time: 1.37922366609929
reward_mean: 1.38
reward_std: 2.087007426915391
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 19369
total_train_sample_count: 19366
total_episode_count: 846
total_duration: 23.653704480530152
[2023-06-10 05:31:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1029
train_sample_count: 1029
avg_envstep_per_episode: 23.386363636363637
avg_sample_per_episode: 23.386363636363637
avg_envstep_per_sec: 827.097385396977
avg_train_sample_per_sec: 827.097385396977
avg_episode_per_sec: 35.36665204807287
collect_time: 1.2441098450651213
reward_mean: 1.9772727272727273
reward_std: 2.8879737813878212
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 20421
total_train_sample_count: 20421
total_episode_count: 890
total_duration: 24.897814325595274
[2023-06-10 05:31:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 56
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 19.875
avg_sample_per_episode: 19.875
avg_envstep_per_sec: 781.5255399099674
avg_train_sample_per_sec: 781.5255399099674
avg_episode_per_sec: 39.32203974389773
collect_time: 1.4241377193229268
reward_mean: 1.125
reward_std: 2.0620941159067265
reward_max: 7.0
reward_min: 0.0
total_envstep_count: 21518
total_train_sample_count: 21495
total_episode_count: 946
total_duration: 26.321952044918202
[2023-06-10 05:31:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1035
train_sample_count: 1035
avg_envstep_per_episode: 23.0
avg_sample_per_episode: 23.0
avg_envstep_per_sec: 811.755364758953
avg_train_sample_per_sec: 811.755364758953
avg_episode_per_sec: 35.29371151125883
collect_time: 1.2750146718246063
reward_mean: 1.8888888888888888
reward_std: 2.7505330572028095
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 22563
total_train_sample_count: 22556
total_episode_count: 991
total_duration: 27.59696671674281
[2023-06-10 05:31:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 51
envstep_count: 1042
train_sample_count: 1042
avg_envstep_per_episode: 20.431372549019606
avg_sample_per_episode: 20.431372549019606
avg_envstep_per_sec: 826.3071853065925
avg_train_sample_per_sec: 826.3071853065925
avg_episode_per_sec: 40.44305801404627
collect_time: 1.2610322390133604
reward_mean: 1.411764705882353
reward_std: 2.1978284343846357
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 23637
total_train_sample_count: 23637
total_episode_count: 1042
total_duration: 28.85799895575617
[2023-06-10 05:31:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 49
envstep_count: 1103
train_sample_count: 1103
avg_envstep_per_episode: 22.510204081632654
avg_sample_per_episode: 22.510204081632654
avg_envstep_per_sec: 919.9782111435703
avg_train_sample_per_sec: 919.9782111435703
avg_episode_per_sec: 40.869385626504936
collect_time: 1.1989414386552983
reward_mean: 1.7551020408163265
reward_std: 2.4372166480614053
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 24715
total_train_sample_count: 24701
total_episode_count: 1091
total_duration: 30.05694039441147
[2023-06-10 05:31:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 26.736842105263158
avg_sample_per_episode: 26.736842105263158
avg_envstep_per_sec: 832.5000387197341
avg_train_sample_per_sec: 832.5000387197341
avg_episode_per_sec: 31.13681247180108
collect_time: 1.220420363658436
reward_mean: 2.5
reward_std: 2.826100158391977
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 25743
total_train_sample_count: 25743
total_episode_count: 1129
total_duration: 31.277360758069907
[2023-06-10 05:31:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 25.225
avg_sample_per_episode: 25.225
avg_envstep_per_sec: 927.8381796596883
avg_train_sample_per_sec: 927.8381796596883
avg_episode_per_sec: 36.782484822980706
collect_time: 1.087474111455599
reward_mean: 2.225
reward_std: 2.9537053001272824
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 26804
total_train_sample_count: 26804
total_episode_count: 1169
total_duration: 32.36483486952551
[2023-06-10 05:31:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 50
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 22.7
avg_sample_per_episode: 22.7
avg_envstep_per_sec: 759.7950716597829
avg_train_sample_per_sec: 759.7950716597829
avg_episode_per_sec: 33.47114853126797
collect_time: 1.4938238511084003
reward_mean: 1.6
reward_std: 3.0000000000000004
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 27869
total_train_sample_count: 27861
total_episode_count: 1219
total_duration: 33.85865872063391
[2023-06-10 05:31:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1058
train_sample_count: 1058
avg_envstep_per_episode: 22.041666666666668
avg_sample_per_episode: 22.041666666666668
avg_envstep_per_sec: 765.2505149316073
avg_train_sample_per_sec: 765.2505149316073
avg_episode_per_sec: 34.71835984566838
collect_time: 1.382553790368317
reward_mean: 1.7291666666666667
reward_std: 2.6119882539722283
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 28937
total_train_sample_count: 28932
total_episode_count: 1267
total_duration: 35.24121251100223
[2023-06-10 05:31:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 52
envstep_count: 1143
train_sample_count: 1143
avg_envstep_per_episode: 21.98076923076923
avg_sample_per_episode: 21.98076923076923
avg_envstep_per_sec: 925.2706846356775
avg_train_sample_per_sec: 925.2706846356775
avg_episode_per_sec: 42.094554331631876
collect_time: 1.2353141831679804
reward_mean: 1.6153846153846154
reward_std: 2.427041932966693
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 30038
total_train_sample_count: 30010
total_episode_count: 1319
total_duration: 36.47652669417021
[2023-06-10 05:31:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 21.06382978723404
avg_sample_per_episode: 21.06382978723404
avg_envstep_per_sec: 735.5660509039445
avg_train_sample_per_sec: 735.5660509039445
avg_episode_per_sec: 34.920812517662014
collect_time: 1.3459022460095582
reward_mean: 1.553191489361702
reward_std: 2.28602144996822
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 31078
total_train_sample_count: 31078
total_episode_count: 1366
total_duration: 37.82242894017977
[2023-06-10 05:31:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1100
train_sample_count: 1100
avg_envstep_per_episode: 22.916666666666668
avg_sample_per_episode: 22.916666666666668
avg_envstep_per_sec: 761.2755677761376
avg_train_sample_per_sec: 761.2755677761376
avg_episode_per_sec: 33.21929750295873
collect_time: 1.444943259131979
reward_mean: 2.0208333333333335
reward_std: 2.824665048972867
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 32167
total_train_sample_count: 32152
total_episode_count: 1414
total_duration: 39.26737219931175
[2023-06-10 05:31:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 25.9
avg_sample_per_episode: 25.9
avg_envstep_per_sec: 814.13206644587
avg_train_sample_per_sec: 814.13206644587
avg_episode_per_sec: 31.43367051914556
collect_time: 1.2725208141262687
reward_mean: 2.575
reward_std: 2.9823438768860977
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 33228
total_train_sample_count: 33227
total_episode_count: 1454
total_duration: 40.53989301343802
[2023-06-10 05:31:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 25.863636363636363
avg_sample_per_episode: 25.863636363636363
avg_envstep_per_sec: 740.572899414161
avg_train_sample_per_sec: 740.572899414161
avg_episode_per_sec: 28.633750065222397
collect_time: 1.5366481826437726
reward_mean: 2.25
reward_std: 3.241246954210959
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 34284
total_train_sample_count: 34274
total_episode_count: 1498
total_duration: 42.07654119608179
[2023-06-10 05:32:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 845
train_sample_count: 845
avg_envstep_per_episode: 22.83783783783784
avg_sample_per_episode: 22.83783783783784
avg_envstep_per_sec: 806.9076569312621
avg_train_sample_per_sec: 806.9076569312621
avg_episode_per_sec: 35.33205125024461
collect_time: 1.0472078096440507
reward_mean: 2.027027027027027
reward_std: 2.5307459266420813
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 35327
total_train_sample_count: 35314
total_episode_count: 1535
total_duration: 43.12374900572584
[2023-06-10 05:32:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 49
envstep_count: 1224
train_sample_count: 1224
avg_envstep_per_episode: 24.979591836734695
avg_sample_per_episode: 24.979591836734695
avg_envstep_per_sec: 800.3628010727526
avg_train_sample_per_sec: 800.3628010727526
avg_episode_per_sec: 32.040667690003986
collect_time: 1.5293064574708275
reward_mean: 2.306122448979592
reward_std: 3.2020661801001147
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 36406
total_train_sample_count: 36395
total_episode_count: 1584
total_duration: 44.653055463196665
[2023-06-10 05:32:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 27.974358974358974
avg_sample_per_episode: 27.974358974358974
avg_envstep_per_sec: 877.1141827661314
avg_train_sample_per_sec: 877.1141827661314
avg_episode_per_sec: 31.354219182290677
collect_time: 1.243851737249696
reward_mean: 2.8205128205128207
reward_std: 3.7952182794006957
reward_max: 17.0
reward_min: 0.0
total_envstep_count: 37475
total_train_sample_count: 37447
total_episode_count: 1623
total_duration: 45.896907200446364
[2023-06-10 05:32:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 24.897435897435898
avg_sample_per_episode: 24.897435897435898
avg_envstep_per_sec: 807.5048934281571
avg_train_sample_per_sec: 807.5048934281571
avg_episode_per_sec: 32.43325524582711
collect_time: 1.2024694932531563
reward_mean: 2.1538461538461537
reward_std: 2.4341424177037574
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 38483
total_train_sample_count: 38483
total_episode_count: 1662
total_duration: 47.09937669369952
[2023-06-10 05:32:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1037
train_sample_count: 1037
avg_envstep_per_episode: 24.11627906976744
avg_sample_per_episode: 24.11627906976744
avg_envstep_per_sec: 816.2269084037853
avg_train_sample_per_sec: 816.2269084037853
avg_episode_per_sec: 33.845474504689264
collect_time: 1.270480045834263
reward_mean: 2.3255813953488373
reward_std: 3.055463503319747
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 39548
total_train_sample_count: 39520
total_episode_count: 1705
total_duration: 48.36985673953378
[2023-06-10 05:32:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1060
train_sample_count: 1060
avg_envstep_per_episode: 23.043478260869566
avg_sample_per_episode: 23.043478260869566
avg_envstep_per_sec: 747.4075045962749
avg_train_sample_per_sec: 747.4075045962749
avg_episode_per_sec: 32.434665293800606
collect_time: 1.4182356926862507
reward_mean: 1.934782608695652
reward_std: 2.7694150529217745
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 40598
total_train_sample_count: 40593
total_episode_count: 1751
total_duration: 49.78809243222003
[2023-06-10 05:32:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 50
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 22.38
avg_sample_per_episode: 22.38
avg_envstep_per_sec: 733.4341798013004
avg_train_sample_per_sec: 733.4341798013004
avg_episode_per_sec: 32.771857899968744
collect_time: 1.5256992799315077
reward_mean: 1.82
reward_std: 2.40574312843246
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 41689
total_train_sample_count: 41660
total_episode_count: 1801
total_duration: 51.31379171215154
[2023-06-10 05:32:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 25.926829268292682
avg_sample_per_episode: 25.926829268292682
avg_envstep_per_sec: 827.4789690866231
avg_train_sample_per_sec: 827.4789690866231
avg_episode_per_sec: 31.915933897038144
collect_time: 1.2846247937556003
reward_mean: 2.6341463414634148
reward_std: 3.3983934336394435
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 42758
total_train_sample_count: 42749
total_episode_count: 1842
total_duration: 52.59841650590714
[2023-06-10 05:32:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1068
train_sample_count: 1068
avg_envstep_per_episode: 25.428571428571427
avg_sample_per_episode: 25.428571428571427
avg_envstep_per_sec: 810.2090404980735
avg_train_sample_per_sec: 810.2090404980735
avg_episode_per_sec: 31.862153278014123
collect_time: 1.3181783300559697
reward_mean: 2.357142857142857
reward_std: 3.5511328076667414
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 43831
total_train_sample_count: 43830
total_episode_count: 1884
total_duration: 53.91659483596311
[2023-06-10 05:32:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 51
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 22.274509803921568
avg_sample_per_episode: 22.274509803921568
avg_envstep_per_sec: 746.6771419539671
avg_train_sample_per_sec: 746.6771419539671
avg_episode_per_sec: 33.521597041947466
collect_time: 1.5214072269940129
reward_mean: 1.7254901960784315
reward_std: 2.232368226113852
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 44941
total_train_sample_count: 44940
total_episode_count: 1935
total_duration: 55.438002062957125
[2023-06-10 05:32:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 23.857142857142858
avg_sample_per_episode: 23.857142857142858
avg_envstep_per_sec: 805.4283491823072
avg_train_sample_per_sec: 805.4283491823072
avg_episode_per_sec: 33.76046972620449
collect_time: 1.244058519938189
reward_mean: 2.1904761904761907
reward_std: 2.9779994502389657
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 45998
total_train_sample_count: 45994
total_episode_count: 1977
total_duration: 56.68206058289531
[2023-06-10 05:32:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 52
envstep_count: 1141
train_sample_count: 1141
avg_envstep_per_episode: 21.942307692307693
avg_sample_per_episode: 21.942307692307693
avg_envstep_per_sec: 741.5707428014956
avg_train_sample_per_sec: 741.5707428014956
avg_episode_per_sec: 33.79638792785081
collect_time: 1.5386259653253662
reward_mean: 1.4038461538461537
reward_std: 2.6330708555178526
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 47070
total_train_sample_count: 47070
total_episode_count: 2029
total_duration: 58.22068654822068
[2023-06-10 05:32:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1077
train_sample_count: 1077
avg_envstep_per_episode: 24.477272727272727
avg_sample_per_episode: 24.477272727272727
avg_envstep_per_sec: 800.2995258047919
avg_train_sample_per_sec: 800.2995258047919
avg_episode_per_sec: 32.69561665312056
collect_time: 1.3457461428793855
reward_mean: 2.409090909090909
reward_std: 3.0099696602078736
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 48123
total_train_sample_count: 48108
total_episode_count: 2073
total_duration: 59.56643269110006
[2023-06-10 05:32:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 23.627906976744185
avg_sample_per_episode: 23.627906976744185
avg_envstep_per_sec: 832.3473636976296
avg_train_sample_per_sec: 832.3473636976296
avg_episode_per_sec: 35.22729984153354
collect_time: 1.2206442217663906
reward_mean: 2.2325581395348837
reward_std: 2.7180465737092057
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 49177
total_train_sample_count: 49176
total_episode_count: 2116
total_duration: 60.78707691286645
[2023-06-10 05:32:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1058
train_sample_count: 1058
avg_envstep_per_episode: 26.45
avg_sample_per_episode: 26.45
avg_envstep_per_sec: 858.9870869909805
avg_train_sample_per_sec: 858.9870869909805
avg_episode_per_sec: 32.47588230589719
collect_time: 1.2316832418356356
reward_mean: 2.875
reward_std: 3.5297839877250277
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 50299
total_train_sample_count: 50247
total_episode_count: 2156
total_duration: 62.018760154702086
[2023-06-10 05:32:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1084
train_sample_count: 1084
avg_envstep_per_episode: 28.526315789473685
avg_sample_per_episode: 28.526315789473685
avg_envstep_per_sec: 903.7165450973567
avg_train_sample_per_sec: 903.7165450973567
avg_episode_per_sec: 31.680100289390733
collect_time: 1.199491152265251
reward_mean: 2.9210526315789473
reward_std: 3.7231959880794583
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 51304
total_train_sample_count: 51292
total_episode_count: 2194
total_duration: 63.21825130696734
[2023-06-10 05:32:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 24.357142857142858
avg_sample_per_episode: 24.357142857142858
avg_envstep_per_sec: 863.1559131006134
avg_train_sample_per_sec: 863.1559131006134
avg_episode_per_sec: 35.43748616835363
collect_time: 1.1851856477761908
reward_mean: 2.238095238095238
reward_std: 2.625964891230902
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 52385
total_train_sample_count: 52354
total_episode_count: 2236
total_duration: 64.40343695474353
[2023-06-10 05:32:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 22.854166666666668
avg_sample_per_episode: 22.854166666666668
avg_envstep_per_sec: 868.853418091982
avg_train_sample_per_sec: 868.853418091982
avg_episode_per_sec: 38.01728720912957
collect_time: 1.262583511968028
reward_mean: 1.9375
reward_std: 2.366486935663636
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 53442
total_train_sample_count: 53438
total_episode_count: 2284
total_duration: 65.66602046671156
[2023-06-10 05:32:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1052
train_sample_count: 1052
avg_envstep_per_episode: 22.869565217391305
avg_sample_per_episode: 22.869565217391305
avg_envstep_per_sec: 764.1615080656485
avg_train_sample_per_sec: 764.1615080656485
avg_episode_per_sec: 33.41390624621657
collect_time: 1.3766723250206205
reward_mean: 1.6956521739130435
reward_std: 2.7730815163655604
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 54484
total_train_sample_count: 54477
total_episode_count: 2330
total_duration: 67.04269279173218
[2023-06-10 05:32:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 24.27906976744186
avg_sample_per_episode: 24.27906976744186
avg_envstep_per_sec: 867.6261507634559
avg_train_sample_per_sec: 867.6261507634559
avg_episode_per_sec: 35.735559849452684
collect_time: 1.203283233315808
reward_mean: 2.4651162790697674
reward_std: 2.8230680754406547
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 55554
total_train_sample_count: 55534
total_episode_count: 2373
total_duration: 68.24597602504798
[2023-06-10 05:32:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1126
train_sample_count: 1126
avg_envstep_per_episode: 23.458333333333332
avg_sample_per_episode: 23.458333333333332
avg_envstep_per_sec: 729.2505166378511
avg_train_sample_per_sec: 729.2505166378511
avg_episode_per_sec: 31.087055771418164
collect_time: 1.5440510144460773
reward_mean: 2.0
reward_std: 2.972092416687835
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 56597
total_train_sample_count: 56595
total_episode_count: 2421
total_duration: 69.79002703949406
[2023-06-10 05:33:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 22.304347826086957
avg_sample_per_episode: 22.304347826086957
avg_envstep_per_sec: 760.1536668519639
avg_train_sample_per_sec: 760.1536668519639
avg_episode_per_sec: 34.08096362104321
collect_time: 1.349727094324217
reward_mean: 1.7608695652173914
reward_std: 2.415392511163924
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 57686
total_train_sample_count: 57647
total_episode_count: 2467
total_duration: 71.13975413381829
[2023-06-10 05:33:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1039
train_sample_count: 1039
avg_envstep_per_episode: 22.106382978723403
avg_sample_per_episode: 22.106382978723403
avg_envstep_per_sec: 785.8305070325397
avg_train_sample_per_sec: 785.8305070325397
avg_episode_per_sec: 35.54767452408986
collect_time: 1.322168063853211
reward_mean: 1.6808510638297873
reward_std: 2.5524821709734162
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 58724
total_train_sample_count: 58712
total_episode_count: 2514
total_duration: 72.4619221976715
[2023-06-10 05:33:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 25.675
avg_sample_per_episode: 25.675
avg_envstep_per_sec: 881.6980987037925
avg_train_sample_per_sec: 881.6980987037925
avg_episode_per_sec: 34.340724389631646
collect_time: 1.164797793609649
reward_mean: 2.65
reward_std: 3.453621287865825
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 59824
total_train_sample_count: 59817
total_episode_count: 2554
total_duration: 73.62671999128115
[2023-06-10 05:33:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1116
train_sample_count: 1116
avg_envstep_per_episode: 26.571428571428573
avg_sample_per_episode: 26.571428571428573
avg_envstep_per_sec: 773.1047489929649
avg_train_sample_per_sec: 773.1047489929649
avg_episode_per_sec: 29.09534001586427
collect_time: 1.443530131529635
reward_mean: 2.6904761904761907
reward_std: 3.254945652666732
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 60900
total_train_sample_count: 60894
total_episode_count: 2596
total_duration: 75.07025012281079
[2023-06-10 05:33:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1112
train_sample_count: 1112
avg_envstep_per_episode: 25.86046511627907
avg_sample_per_episode: 25.86046511627907
avg_envstep_per_sec: 826.7663657121203
avg_train_sample_per_sec: 826.7663657121203
avg_episode_per_sec: 31.97028212735717
collect_time: 1.3449990784787174
reward_mean: 2.6511627906976742
reward_std: 3.25564783629377
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 61957
total_train_sample_count: 61954
total_episode_count: 2639
total_duration: 76.41524920128951
[2023-06-10 05:33:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 946
train_sample_count: 946
avg_envstep_per_episode: 24.894736842105264
avg_sample_per_episode: 24.894736842105264
avg_envstep_per_sec: 824.6202413315981
avg_train_sample_per_sec: 824.6202413315981
avg_episode_per_sec: 33.124280307188926
collect_time: 1.1471947359337162
reward_mean: 2.236842105263158
reward_std: 3.149220542880545
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 62991
total_train_sample_count: 62991
total_episode_count: 2677
total_duration: 77.56244393722322
[2023-06-10 05:33:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1131
train_sample_count: 1131
avg_envstep_per_episode: 23.5625
avg_sample_per_episode: 23.5625
avg_envstep_per_sec: 813.9113890778741
avg_train_sample_per_sec: 813.9113890778741
avg_episode_per_sec: 34.54265842240314
collect_time: 1.3895861578757036
reward_mean: 2.1458333333333335
reward_std: 2.7079326626700957
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 64076
total_train_sample_count: 64057
total_episode_count: 2725
total_duration: 78.95203009509892
[2023-06-10 05:33:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1093
train_sample_count: 1093
avg_envstep_per_episode: 24.84090909090909
avg_sample_per_episode: 24.84090909090909
avg_envstep_per_sec: 817.51147640382
avg_train_sample_per_sec: 817.51147640382
avg_episode_per_sec: 32.90988560088571
collect_time: 1.3369842889644024
reward_mean: 2.4545454545454546
reward_std: 2.8320771806264022
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 65144
total_train_sample_count: 65111
total_episode_count: 2769
total_duration: 80.28901438406332
[2023-06-10 05:33:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 27.0
avg_sample_per_episode: 27.0
avg_envstep_per_sec: 828.3727252895386
avg_train_sample_per_sec: 828.3727252895386
avg_episode_per_sec: 30.68047130701995
collect_time: 1.238572889566572
reward_mean: 2.4473684210526314
reward_std: 3.3771474136820876
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 66176
total_train_sample_count: 66176
total_episode_count: 2807
total_duration: 81.52758727362989
[2023-06-10 05:33:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1105
train_sample_count: 1105
avg_envstep_per_episode: 24.02173913043478
avg_sample_per_episode: 24.02173913043478
avg_envstep_per_sec: 727.2402548511625
avg_train_sample_per_sec: 727.2402548511625
avg_episode_per_sec: 30.274254953080067
collect_time: 1.5194428424842215
reward_mean: 2.1739130434782608
reward_std: 3.143691736091342
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 67235
total_train_sample_count: 67229
total_episode_count: 2853
total_duration: 83.04703011611412
[2023-06-10 05:33:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 19.958333333333332
avg_sample_per_episode: 19.958333333333332
avg_envstep_per_sec: 737.2756242086915
avg_train_sample_per_sec: 737.2756242086915
avg_episode_per_sec: 36.940741087700616
collect_time: 1.2993783715936753
reward_mean: 1.125
reward_std: 1.943203969393503
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 68263
total_train_sample_count: 68252
total_episode_count: 2901
total_duration: 84.34640848770779
[2023-06-10 05:33:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 49
envstep_count: 1045
train_sample_count: 1045
avg_envstep_per_episode: 21.3265306122449
avg_sample_per_episode: 21.3265306122449
avg_envstep_per_sec: 739.3711036454292
avg_train_sample_per_sec: 739.3711036454292
avg_episode_per_sec: 34.66907567332635
collect_time: 1.413363323029104
reward_mean: 1.6326530612244898
reward_std: 2.496478152387433
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 69349
total_train_sample_count: 69336
total_episode_count: 2950
total_duration: 85.7597718107369
[2023-06-10 05:33:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1095
train_sample_count: 1095
avg_envstep_per_episode: 23.804347826086957
avg_sample_per_episode: 23.804347826086957
avg_envstep_per_sec: 837.0140046983961
avg_train_sample_per_sec: 837.0140046983961
avg_episode_per_sec: 35.16223216084586
collect_time: 1.3082218384082651
reward_mean: 2.239130434782609
reward_std: 2.5553420821682193
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 70407
total_train_sample_count: 70405
total_episode_count: 2996
total_duration: 87.06799364914517
[2023-06-10 05:33:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 24.363636363636363
avg_sample_per_episode: 24.363636363636363
avg_envstep_per_sec: 834.667758375402
avg_train_sample_per_sec: 834.667758375402
avg_episode_per_sec: 34.25875127660232
collect_time: 1.2843433680564609
reward_mean: 2.1363636363636362
reward_std: 2.792774028964661
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 71477
total_train_sample_count: 71464
total_episode_count: 3040
total_duration: 88.35233701720162
[2023-06-10 05:33:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1080
train_sample_count: 1080
avg_envstep_per_episode: 26.341463414634145
avg_sample_per_episode: 26.341463414634145
avg_envstep_per_sec: 846.3899774761039
avg_train_sample_per_sec: 846.3899774761039
avg_episode_per_sec: 32.13147136714839
collect_time: 1.276007548223232
reward_mean: 2.7804878048780486
reward_std: 3.502697184588535
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 72562
total_train_sample_count: 72544
total_episode_count: 3081
total_duration: 89.62834456542485
[2023-06-10 05:33:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 28.609756097560975
avg_sample_per_episode: 28.609756097560975
avg_envstep_per_sec: 776.3365176598492
avg_train_sample_per_sec: 776.3365176598492
avg_episode_per_sec: 27.135377002603423
collect_time: 1.5109427075977746
reward_mean: 3.1707317073170733
reward_std: 3.5054135069700845
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 73705
total_train_sample_count: 73665
total_episode_count: 3122
total_duration: 91.13928727302263
[2023-06-10 05:33:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 23.82051282051282
avg_sample_per_episode: 23.82051282051282
avg_envstep_per_sec: 799.6220280646542
avg_train_sample_per_sec: 799.6220280646542
avg_episode_per_sec: 33.56863196396288
collect_time: 1.1617989092277543
reward_mean: 1.9230769230769231
reward_std: 2.683134555955942
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 74719
total_train_sample_count: 74698
total_episode_count: 3161
total_duration: 92.30108618225039
[2023-06-10 05:33:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 24.395833333333332
avg_sample_per_episode: 24.395833333333332
avg_envstep_per_sec: 757.6085033830942
avg_train_sample_per_sec: 757.6085033830942
avg_episode_per_sec: 31.05483190639498
collect_time: 1.5456531899667303
reward_mean: 2.3125
reward_std: 2.8878787630369804
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 75747
total_train_sample_count: 75739
total_episode_count: 3209
total_duration: 93.84673937221712
[2023-06-10 05:33:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1131
train_sample_count: 1131
avg_envstep_per_episode: 24.06382978723404
avg_sample_per_episode: 24.06382978723404
avg_envstep_per_sec: 819.1761076013274
avg_train_sample_per_sec: 819.1761076013274
avg_episode_per_sec: 34.04180111163783
collect_time: 1.3806555019185562
reward_mean: 2.25531914893617
reward_std: 2.8543962741065436
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 76893
total_train_sample_count: 76883
total_episode_count: 3256
total_duration: 95.22739487413567
[2023-06-10 05:33:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 22.068181818181817
avg_sample_per_episode: 22.068181818181817
avg_envstep_per_sec: 871.6876759969126
avg_train_sample_per_sec: 871.6876759969126
avg_episode_per_sec: 39.49975050861396
collect_time: 1.1139310864863474
reward_mean: 1.5227272727272727
reward_std: 2.0055449991963914
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 77958
total_train_sample_count: 77958
total_episode_count: 3300
total_duration: 96.34132596062202
[2023-06-10 05:33:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1057
train_sample_count: 1057
avg_envstep_per_episode: 26.425
avg_sample_per_episode: 26.425
avg_envstep_per_sec: 833.4829037246278
avg_train_sample_per_sec: 833.4829037246278
avg_episode_per_sec: 31.541453310298117
collect_time: 1.2681723827525795
reward_mean: 2.25
reward_std: 2.7363296585024255
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 78989
total_train_sample_count: 78989
total_episode_count: 3340
total_duration: 97.6094983433746
[2023-06-10 05:33:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 49
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 23.877551020408163
avg_sample_per_episode: 23.877551020408163
avg_envstep_per_sec: 814.3126850979229
avg_train_sample_per_sec: 814.3126850979229
avg_episode_per_sec: 34.103693649400185
collect_time: 1.4367945156832538
reward_mean: 2.2448979591836733
reward_std: 2.931396631995996
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 80095
total_train_sample_count: 80081
total_episode_count: 3389
total_duration: 99.04629285905786
[2023-06-10 05:34:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 27.470588235294116
avg_sample_per_episode: 27.470588235294116
avg_envstep_per_sec: 928.0186463953662
avg_train_sample_per_sec: 928.0186463953662
avg_episode_per_sec: 33.78226335914609
collect_time: 1.0064452946369846
reward_mean: 3.176470588235294
reward_std: 3.7453546775839075
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 81127
total_train_sample_count: 81119
total_episode_count: 3423
total_duration: 100.05273815369485
[2023-06-10 05:34:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 24.88888888888889
avg_sample_per_episode: 24.88888888888889
avg_envstep_per_sec: 780.1079685240148
avg_train_sample_per_sec: 780.1079685240148
avg_episode_per_sec: 31.343623735339882
collect_time: 1.4356987047819418
reward_mean: 1.9777777777777779
reward_std: 2.840100850235106
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 82206
total_train_sample_count: 82200
total_episode_count: 3468
total_duration: 101.48843685847679
[2023-06-10 05:34:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 26.24390243902439
avg_sample_per_episode: 26.24390243902439
avg_envstep_per_sec: 800.5397475394791
avg_train_sample_per_sec: 800.5397475394791
avg_episode_per_sec: 30.50383796386491
collect_time: 1.344093161279211
reward_mean: 2.731707317073171
reward_std: 3.131464165015421
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 83275
total_train_sample_count: 83263
total_episode_count: 3509
total_duration: 102.83253001975599
[2023-06-10 05:34:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 51
envstep_count: 1096
train_sample_count: 1096
avg_envstep_per_episode: 21.49019607843137
avg_sample_per_episode: 21.49019607843137
avg_envstep_per_sec: 862.2858064131453
avg_train_sample_per_sec: 862.2858064131453
avg_episode_per_sec: 40.12461325462629
collect_time: 1.271040288322774
reward_mean: 1.411764705882353
reward_std: 2.410568809192628
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 84343
total_train_sample_count: 84333
total_episode_count: 3560
total_duration: 104.10357030807877
[2023-06-10 05:34:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 24.682926829268293
avg_sample_per_episode: 24.682926829268293
avg_envstep_per_sec: 794.15205253639
avg_train_sample_per_sec: 794.15205253639
avg_episode_per_sec: 32.1741444209407
collect_time: 1.2743151601356941
reward_mean: 2.2439024390243905
reward_std: 3.1836509782728175
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 85380
total_train_sample_count: 85371
total_episode_count: 3601
total_duration: 105.37788546821447
[2023-06-10 05:34:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1095
train_sample_count: 1095
avg_envstep_per_episode: 23.29787234042553
avg_sample_per_episode: 23.29787234042553
avg_envstep_per_sec: 696.408413390764
avg_train_sample_per_sec: 696.408413390764
avg_episode_per_sec: 29.891502675220007
collect_time: 1.5723532038743204
reward_mean: 2.3191489361702127
reward_std: 2.8961190684550737
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 86465
total_train_sample_count: 86453
total_episode_count: 3648
total_duration: 106.95023867208879
[2023-06-10 05:34:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 25.375
avg_sample_per_episode: 25.375
avg_envstep_per_sec: 766.5711514141826
avg_train_sample_per_sec: 766.5711514141826
avg_episode_per_sec: 30.20970054834217
collect_time: 1.3240780038845865
reward_mean: 2.7
reward_std: 3.1717503054307414
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 87549
total_train_sample_count: 87507
total_episode_count: 3688
total_duration: 108.27431667597337
[2023-06-10 05:34:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 24.113636363636363
avg_sample_per_episode: 24.113636363636363
avg_envstep_per_sec: 835.189369834493
avg_train_sample_per_sec: 835.189369834493
avg_episode_per_sec: 34.63556293375843
collect_time: 1.2703705750113357
reward_mean: 2.159090909090909
reward_std: 2.819922482962494
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 88612
total_train_sample_count: 88581
total_episode_count: 3732
total_duration: 109.54468725098471
[2023-06-10 05:34:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1098
train_sample_count: 1098
avg_envstep_per_episode: 26.142857142857142
avg_sample_per_episode: 26.142857142857142
avg_envstep_per_sec: 805.9748565356597
avg_train_sample_per_sec: 805.9748565356597
avg_episode_per_sec: 30.829639321036165
collect_time: 1.362325376649538
reward_mean: 2.9047619047619047
reward_std: 3.4282407247916793
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 89679
total_train_sample_count: 89679
total_episode_count: 3774
total_duration: 110.90701262763424
[2023-06-10 05:34:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 25.88372093023256
avg_sample_per_episode: 25.88372093023256
avg_envstep_per_sec: 827.6646620524285
avg_train_sample_per_sec: 827.6646620524285
avg_episode_per_sec: 31.976262774711973
collect_time: 1.3447475179621682
reward_mean: 2.558139534883721
reward_std: 2.6962706853053517
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 90788
total_train_sample_count: 90779
total_episode_count: 3817
total_duration: 112.2517601455964
[2023-06-10 05:34:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 26.897435897435898
avg_sample_per_episode: 26.897435897435898
avg_envstep_per_sec: 798.8404068409529
avg_train_sample_per_sec: 798.8404068409529
avg_episode_per_sec: 29.699500349663648
collect_time: 1.3131534046309867
reward_mean: 3.051282051282051
reward_std: 3.2181274850743034
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 91859
total_train_sample_count: 91854
total_episode_count: 3856
total_duration: 113.56491355022739
[2023-06-10 05:34:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1183
train_sample_count: 1183
avg_envstep_per_episode: 26.288888888888888
avg_sample_per_episode: 26.288888888888888
avg_envstep_per_sec: 792.1344977752073
avg_train_sample_per_sec: 792.1344977752073
avg_episode_per_sec: 30.13191242593772
collect_time: 1.493433253219724
reward_mean: 2.8222222222222224
reward_std: 3.6349469743275264
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 92970
total_train_sample_count: 92959
total_episode_count: 3901
total_duration: 115.05834680344711
[2023-06-10 05:34:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1095
train_sample_count: 1095
avg_envstep_per_episode: 24.333333333333332
avg_sample_per_episode: 24.333333333333332
avg_envstep_per_sec: 812.2427110107452
avg_train_sample_per_sec: 812.2427110107452
avg_episode_per_sec: 33.37983743879775
collect_time: 1.3481192076656434
reward_mean: 2.111111111111111
reward_std: 2.643417167415627
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 94077
total_train_sample_count: 94054
total_episode_count: 3946
total_duration: 116.40646601111276
[2023-06-10 05:34:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 50
envstep_count: 1020
train_sample_count: 1020
avg_envstep_per_episode: 20.4
avg_sample_per_episode: 20.4
avg_envstep_per_sec: 761.2211269399164
avg_train_sample_per_sec: 761.2211269399164
avg_episode_per_sec: 37.31476112450571
collect_time: 1.3399523001947753
reward_mean: 1.04
reward_std: 2.0972362766269326
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 95113
total_train_sample_count: 95100
total_episode_count: 3996
total_duration: 117.74641831130754
[2023-06-10 05:34:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 25.302325581395348
avg_sample_per_episode: 25.302325581395348
avg_envstep_per_sec: 849.3614422108705
avg_train_sample_per_sec: 849.3614422108705
avg_episode_per_sec: 33.5685128814958
collect_time: 1.280962315840425
reward_mean: 2.813953488372093
reward_std: 3.127193659478604
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 96163
total_train_sample_count: 96149
total_episode_count: 4039
total_duration: 119.02738062714796
[2023-06-10 05:34:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1018
train_sample_count: 1018
avg_envstep_per_episode: 24.829268292682926
avg_sample_per_episode: 24.829268292682926
avg_envstep_per_sec: 907.765640125653
avg_train_sample_per_sec: 907.765640125653
avg_episode_per_sec: 36.56030574179938
collect_time: 1.1214348230442919
reward_mean: 2.4878048780487805
reward_std: 2.8637511748047726
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 97238
total_train_sample_count: 97219
total_episode_count: 4080
total_duration: 120.14881545019226
[2023-06-10 05:34:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 29.333333333333332
avg_sample_per_episode: 29.333333333333332
avg_envstep_per_sec: 903.353739449855
avg_train_sample_per_sec: 903.353739449855
avg_episode_per_sec: 30.796150208517783
collect_time: 1.1689772830775096
reward_mean: 3.7222222222222223
reward_std: 3.5324771848843404
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 98341
total_train_sample_count: 98327
total_episode_count: 4116
total_duration: 121.31779273326977
[2023-06-10 05:34:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1163
train_sample_count: 1163
avg_envstep_per_episode: 28.365853658536587
avg_sample_per_episode: 28.365853658536587
avg_envstep_per_sec: 840.6195209347691
avg_train_sample_per_sec: 840.6195209347691
avg_episode_per_sec: 29.634910024355573
collect_time: 1.3835034412557345
reward_mean: 3.2439024390243905
reward_std: 3.8873182668203317
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 99434
total_train_sample_count: 99412
total_episode_count: 4157
total_duration: 122.70129617452551
[2023-06-10 05:34:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 26.923076923076923
avg_sample_per_episode: 26.923076923076923
avg_envstep_per_sec: 858.7505973343807
avg_train_sample_per_sec: 858.7505973343807
avg_episode_per_sec: 31.89645075813414
collect_time: 1.2227065730833495
reward_mean: 2.871794871794872
reward_std: 3.5603189656840577
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 100490
total_train_sample_count: 100475
total_episode_count: 4196
total_duration: 123.92400274760885
[2023-06-10 05:34:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1129
train_sample_count: 1129
avg_envstep_per_episode: 28.94871794871795
avg_sample_per_episode: 28.94871794871795
avg_envstep_per_sec: 809.7067305648601
avg_train_sample_per_sec: 809.7067305648601
avg_episode_per_sec: 27.970383075314032
collect_time: 1.3943319937731005
reward_mean: 3.6153846153846154
reward_std: 3.7045736431756944
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 101539
total_train_sample_count: 101539
total_episode_count: 4235
total_duration: 125.31833474138196
[2023-06-10 05:34:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1055
train_sample_count: 1055
avg_envstep_per_episode: 21.979166666666668
avg_sample_per_episode: 21.979166666666668
avg_envstep_per_sec: 750.1028515245196
avg_train_sample_per_sec: 750.1028515245196
avg_episode_per_sec: 34.12790224945681
collect_time: 1.4064737893687556
reward_mean: 1.5625
reward_std: 2.5569044598237665
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 102624
total_train_sample_count: 102607
total_episode_count: 4283
total_duration: 126.72480853075072
[2023-06-10 05:34:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 26.13157894736842
avg_sample_per_episode: 26.13157894736842
avg_envstep_per_sec: 790.0243228439323
avg_train_sample_per_sec: 790.0243228439323
avg_episode_per_sec: 30.232552133000432
collect_time: 1.256923326645685
reward_mean: 2.5526315789473686
reward_std: 2.834908041032025
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 103720
total_train_sample_count: 103717
total_episode_count: 4321
total_duration: 127.98173185739641
[2023-06-10 05:35:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 23.652173913043477
avg_sample_per_episode: 23.652173913043477
avg_envstep_per_sec: 777.9594846154384
avg_train_sample_per_sec: 777.9594846154384
avg_episode_per_sec: 32.89166938631449
collect_time: 1.3985304138785852
reward_mean: 1.9130434782608696
reward_std: 2.725292859863447
reward_max: 8.0
reward_min: 0.0
total_envstep_count: 104790
total_train_sample_count: 104779
total_episode_count: 4367
total_duration: 129.380262271275
[2023-06-10 05:35:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1074
train_sample_count: 1074
avg_envstep_per_episode: 28.263157894736842
avg_sample_per_episode: 28.263157894736842
avg_envstep_per_sec: 834.6016642989025
avg_train_sample_per_sec: 834.6016642989025
avg_episode_per_sec: 29.529667824355954
collect_time: 1.286841430998345
reward_mean: 3.3157894736842106
reward_std: 3.1631535160666777
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 105853
total_train_sample_count: 105840
total_episode_count: 4405
total_duration: 130.66710370227335
[2023-06-10 05:35:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1084
train_sample_count: 1084
avg_envstep_per_episode: 22.583333333333332
avg_sample_per_episode: 22.583333333333332
avg_envstep_per_sec: 817.9165719995947
avg_train_sample_per_sec: 817.9165719995947
avg_episode_per_sec: 36.21770798522191
collect_time: 1.3253185436136843
reward_mean: 1.9375
reward_std: 2.9608997084219744
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 106891
total_train_sample_count: 106885
total_episode_count: 4453
total_duration: 131.99242224588704
[2023-06-10 05:35:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 26.41025641025641
avg_sample_per_episode: 26.41025641025641
avg_envstep_per_sec: 806.2217703543704
avg_train_sample_per_sec: 806.2217703543704
avg_episode_per_sec: 30.52684373186451
collect_time: 1.2775641118538255
reward_mean: 2.5128205128205128
reward_std: 3.5868119897529667
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 107974
total_train_sample_count: 107954
total_episode_count: 4492
total_duration: 133.26998635774086
[2023-06-10 05:35:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 924
train_sample_count: 924
avg_envstep_per_episode: 27.176470588235293
avg_sample_per_episode: 27.176470588235293
avg_envstep_per_sec: 819.9531917146106
avg_train_sample_per_sec: 819.9531917146106
avg_episode_per_sec: 30.171437790364457
collect_time: 1.126893595069514
reward_mean: 3.088235294117647
reward_std: 4.039275175651776
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 109033
total_train_sample_count: 109008
total_episode_count: 4526
total_duration: 134.39687995281037
[2023-06-10 05:35:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 48
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 26.541666666666668
avg_sample_per_episode: 26.541666666666668
avg_envstep_per_sec: 746.5880890213289
avg_train_sample_per_sec: 746.5880890213289
avg_episode_per_sec: 28.128907592640335
collect_time: 1.7064295810960945
reward_mean: 2.75
reward_std: 3.79418414594407
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 110096
total_train_sample_count: 110061
total_episode_count: 4574
total_duration: 136.10330953390647
[2023-06-10 05:35:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 898
train_sample_count: 898
avg_envstep_per_episode: 24.27027027027027
avg_sample_per_episode: 24.27027027027027
avg_envstep_per_sec: 856.9528554959961
avg_train_sample_per_sec: 856.9528554959961
avg_episode_per_sec: 35.308747943598945
collect_time: 1.0478989529479381
reward_mean: 2.27027027027027
reward_std: 2.9559710404229005
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 111151
total_train_sample_count: 111128
total_episode_count: 4611
total_duration: 137.15120848685442
[2023-06-10 05:35:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1162
train_sample_count: 1162
avg_envstep_per_episode: 28.341463414634145
avg_sample_per_episode: 28.341463414634145
avg_envstep_per_sec: 798.1187355258566
avg_train_sample_per_sec: 798.1187355258566
avg_episode_per_sec: 28.160815969500963
collect_time: 1.4559237219690038
reward_mean: 2.707317073170732
reward_std: 3.2702942542255586
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 112204
total_train_sample_count: 112186
total_episode_count: 4652
total_duration: 138.60713220882343
[2023-06-10 05:35:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1021
train_sample_count: 1021
avg_envstep_per_episode: 24.30952380952381
avg_sample_per_episode: 24.30952380952381
avg_envstep_per_sec: 836.6151889176675
avg_train_sample_per_sec: 836.6151889176675
avg_episode_per_sec: 34.4151204060157
collect_time: 1.2203938125016256
reward_mean: 2.357142857142857
reward_std: 2.99063163077976
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 113245
total_train_sample_count: 113233
total_episode_count: 4694
total_duration: 139.82752602132504
[2023-06-10 05:35:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1021
train_sample_count: 1021
avg_envstep_per_episode: 24.30952380952381
avg_sample_per_episode: 24.30952380952381
avg_envstep_per_sec: 846.0628391109185
avg_train_sample_per_sec: 846.0628391109185
avg_episode_per_sec: 34.803760276844834
collect_time: 1.2067661558955993
reward_mean: 2.142857142857143
reward_std: 2.9404520916691297
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 114305
total_train_sample_count: 114293
total_episode_count: 4736
total_duration: 141.03429217722064
[2023-06-10 05:35:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1149
train_sample_count: 1149
avg_envstep_per_episode: 28.725
avg_sample_per_episode: 28.725
avg_envstep_per_sec: 879.6245467546818
avg_train_sample_per_sec: 879.6245467546818
avg_episode_per_sec: 30.622264464914945
collect_time: 1.306239126953837
reward_mean: 3.25
reward_std: 3.498213829942361
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 115367
total_train_sample_count: 115351
total_episode_count: 4776
total_duration: 142.34053130417448
[2023-06-10 05:35:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 29.942857142857143
avg_sample_per_episode: 29.942857142857143
avg_envstep_per_sec: 855.464090665967
avg_train_sample_per_sec: 855.464090665967
avg_episode_per_sec: 28.56988852414966
collect_time: 1.2250660330863758
reward_mean: 3.4285714285714284
reward_std: 3.915432574428777
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 116435
total_train_sample_count: 116425
total_episode_count: 4811
total_duration: 143.56559733726084
[2023-06-10 05:35:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 51
envstep_count: 1087
train_sample_count: 1087
avg_envstep_per_episode: 21.313725490196077
avg_sample_per_episode: 21.313725490196077
avg_envstep_per_sec: 837.8026859548845
avg_train_sample_per_sec: 837.8026859548845
avg_episode_per_sec: 39.30812969981519
collect_time: 1.297441531547602
reward_mean: 1.4313725490196079
reward_std: 2.5990564046477638
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 117510
total_train_sample_count: 117486
total_episode_count: 4862
total_duration: 144.86303886880845
[2023-06-10 05:35:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1022
train_sample_count: 1022
avg_envstep_per_episode: 25.55
avg_sample_per_episode: 25.55
avg_envstep_per_sec: 814.6988329155836
avg_train_sample_per_sec: 814.6988329155836
avg_episode_per_sec: 31.886451386128517
collect_time: 1.2544512876525702
reward_mean: 2.625
reward_std: 3.143942588534339
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 118569
total_train_sample_count: 118547
total_episode_count: 4902
total_duration: 146.117490156461
[2023-06-10 05:35:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 29.6
avg_sample_per_episode: 29.6
avg_envstep_per_sec: 874.1132358729483
avg_train_sample_per_sec: 874.1132358729483
avg_episode_per_sec: 29.53085256327528
collect_time: 1.1852011358292507
reward_mean: 3.3142857142857145
reward_std: 3.7930118343488206
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 119635
total_train_sample_count: 119635
total_episode_count: 4937
total_duration: 147.30269129229026
[2023-06-10 05:35:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 28.88888888888889
avg_sample_per_episode: 28.88888888888889
avg_envstep_per_sec: 826.8013193198
avg_train_sample_per_sec: 826.8013193198
avg_episode_per_sec: 28.62004566876231
collect_time: 1.2578596280610632
reward_mean: 3.2777777777777777
reward_std: 3.8701931556097295
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 120727
total_train_sample_count: 120714
total_episode_count: 4973
total_duration: 148.56055092035132
[2023-06-10 05:35:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 28.84090909090909
avg_sample_per_episode: 28.84090909090909
avg_envstep_per_sec: 745.9032145390895
avg_train_sample_per_sec: 745.9032145390895
avg_episode_per_sec: 25.862680409550777
collect_time: 1.7012931105064937
reward_mean: 3.090909090909091
reward_std: 3.7587363798960043
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 121879
total_train_sample_count: 121840
total_episode_count: 5017
total_duration: 150.26184403085782
[2023-06-10 05:35:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1058
train_sample_count: 1058
avg_envstep_per_episode: 24.6046511627907
avg_sample_per_episode: 24.6046511627907
avg_envstep_per_sec: 810.6157988456343
avg_train_sample_per_sec: 810.6157988456343
avg_episode_per_sec: 32.94563265629705
collect_time: 1.3051805818572197
reward_mean: 2.302325581395349
reward_std: 3.136691218620905
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 122896
total_train_sample_count: 122885
total_episode_count: 5060
total_duration: 151.56702461271504
[2023-06-10 05:35:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 992
train_sample_count: 992
avg_envstep_per_episode: 24.8
avg_sample_per_episode: 24.8
avg_envstep_per_sec: 764.0458814037522
avg_train_sample_per_sec: 764.0458814037522
avg_episode_per_sec: 30.80830166950614
collect_time: 1.2983513479287871
reward_mean: 2.275
reward_std: 3.316530566721796
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 123956
total_train_sample_count: 123942
total_episode_count: 5100
total_duration: 152.86537596064383
[2023-06-10 05:35:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 24.714285714285715
avg_sample_per_episode: 24.714285714285715
avg_envstep_per_sec: 779.3820024493939
avg_train_sample_per_sec: 779.3820024493939
avg_episode_per_sec: 31.535687960380102
collect_time: 1.3318244413366453
reward_mean: 2.3333333333333335
reward_std: 2.615582122830373
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 125006
total_train_sample_count: 125006
total_episode_count: 5142
total_duration: 154.19720040198047
[2023-06-10 05:35:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1071
train_sample_count: 1071
avg_envstep_per_episode: 24.34090909090909
avg_sample_per_episode: 24.34090909090909
avg_envstep_per_sec: 827.5577647541716
avg_train_sample_per_sec: 827.5577647541716
avg_episode_per_sec: 33.99863832790247
collect_time: 1.2941694774843224
reward_mean: 2.3636363636363638
reward_std: 2.908380595099344
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 126107
total_train_sample_count: 126090
total_episode_count: 5186
total_duration: 155.4913698794648
[2023-06-10 05:36:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 1111
train_sample_count: 1111
avg_envstep_per_episode: 32.6764705882353
avg_sample_per_episode: 32.6764705882353
avg_envstep_per_sec: 609.9111420395454
avg_train_sample_per_sec: 609.9111420395454
avg_episode_per_sec: 18.665147461156206
collect_time: 1.8215768222971158
reward_mean: 4.205882352941177
reward_std: 4.5230092258083445
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 127189
total_train_sample_count: 127188
total_episode_count: 5220
total_duration: 157.31294670176192
[2023-06-10 05:36:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 30.243243243243242
avg_sample_per_episode: 30.243243243243242
avg_envstep_per_sec: 793.4215926285289
avg_train_sample_per_sec: 793.4215926285289
avg_episode_per_sec: 26.23467285724358
collect_time: 1.4103472988337278
reward_mean: 3.5675675675675675
reward_std: 3.643138983190187
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 128273
total_train_sample_count: 128268
total_episode_count: 5257
total_duration: 158.72329400059564
[2023-06-10 05:36:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 27.82051282051282
avg_sample_per_episode: 27.82051282051282
avg_envstep_per_sec: 817.7050166213905
avg_train_sample_per_sec: 817.7050166213905
avg_episode_per_sec: 29.392161887773483
collect_time: 1.3268843628757765
reward_mean: 3.1025641025641026
reward_std: 3.499412930946486
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 129342
total_train_sample_count: 129327
total_episode_count: 5296
total_duration: 160.05017836347142
[2023-06-10 05:36:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1067
train_sample_count: 1067
avg_envstep_per_episode: 24.813953488372093
avg_sample_per_episode: 24.813953488372093
avg_envstep_per_sec: 790.1050851548846
avg_train_sample_per_sec: 790.1050851548846
avg_episode_per_sec: 31.84116088253049
collect_time: 1.3504532752005205
reward_mean: 2.3255813953488373
reward_std: 3.387534812196018
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 130430
total_train_sample_count: 130407
total_episode_count: 5339
total_duration: 161.40063163867194
[2023-06-10 05:36:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 959
train_sample_count: 959
avg_envstep_per_episode: 25.91891891891892
avg_sample_per_episode: 25.91891891891892
avg_envstep_per_sec: 785.8581758471815
avg_train_sample_per_sec: 785.8581758471815
avg_episode_per_sec: 30.3198670556264
collect_time: 1.2203219734479007
reward_mean: 2.6486486486486487
reward_std: 3.206549178370571
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 131521
total_train_sample_count: 131483
total_episode_count: 5376
total_duration: 162.62095361211985
[2023-06-10 05:36:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 27.5
avg_sample_per_episode: 27.5
avg_envstep_per_sec: 849.2762705200764
avg_train_sample_per_sec: 849.2762705200764
avg_episode_per_sec: 30.882773473457327
collect_time: 1.3599814808115451
reward_mean: 3.0714285714285716
reward_std: 4.020144851351795
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 132553
total_train_sample_count: 132534
total_episode_count: 5418
total_duration: 163.9809350929314
[2023-06-10 05:36:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1059
train_sample_count: 1059
avg_envstep_per_episode: 25.829268292682926
avg_sample_per_episode: 25.829268292682926
avg_envstep_per_sec: 856.2837209166502
avg_train_sample_per_sec: 856.2837209166502
avg_episode_per_sec: 33.15168324606483
collect_time: 1.236739615774013
reward_mean: 2.8048780487804876
reward_std: 3.7169323320095105
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 133597
total_train_sample_count: 133593
total_episode_count: 5459
total_duration: 165.2176747087054
[2023-06-10 05:36:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1071
train_sample_count: 1071
avg_envstep_per_episode: 23.8
avg_sample_per_episode: 23.8
avg_envstep_per_sec: 765.9183808296693
avg_train_sample_per_sec: 765.9183808296693
avg_episode_per_sec: 32.18144457267518
collect_time: 1.3983213183105172
reward_mean: 2.3555555555555556
reward_std: 3.019606711371205
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 134680
total_train_sample_count: 134664
total_episode_count: 5504
total_duration: 166.6159960270159
[2023-06-10 05:36:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 27.263157894736842
avg_sample_per_episode: 27.263157894736842
avg_envstep_per_sec: 900.4022645269913
avg_train_sample_per_sec: 900.4022645269913
avg_episode_per_sec: 33.026337888055664
collect_time: 1.1505968396739232
reward_mean: 2.6578947368421053
reward_std: 3.5782700597493498
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 135740
total_train_sample_count: 135713
total_episode_count: 5542
total_duration: 167.76659286668982
[2023-06-10 05:36:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1115
train_sample_count: 1115
avg_envstep_per_episode: 27.195121951219512
avg_sample_per_episode: 27.195121951219512
avg_envstep_per_sec: 788.3565836189233
avg_train_sample_per_sec: 788.3565836189233
avg_episode_per_sec: 28.98889679674965
collect_time: 1.4143346084352229
reward_mean: 3.024390243902439
reward_std: 3.4534380527664115
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 136807
total_train_sample_count: 136802
total_episode_count: 5583
total_duration: 169.18092747512503
[2023-06-10 05:36:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 26.536585365853657
avg_sample_per_episode: 26.536585365853657
avg_envstep_per_sec: 870.977940966721
avg_train_sample_per_sec: 870.977940966721
avg_episode_per_sec: 32.82177902540033
collect_time: 1.2491705573994223
reward_mean: 3.048780487804878
reward_std: 3.2531502144333966
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 137890
total_train_sample_count: 137890
total_episode_count: 5624
total_duration: 170.43009803252446
[2023-06-10 05:36:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1007
train_sample_count: 1007
avg_envstep_per_episode: 23.976190476190474
avg_sample_per_episode: 23.976190476190474
avg_envstep_per_sec: 755.2443792357417
avg_train_sample_per_sec: 755.2443792357417
avg_episode_per_sec: 31.49976556891872
collect_time: 1.333343256415915
reward_mean: 2.0952380952380953
reward_std: 2.9098316414194647
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 138958
total_train_sample_count: 138936
total_episode_count: 5666
total_duration: 171.76344128894036
[2023-06-10 05:36:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 31.205882352941178
avg_sample_per_episode: 31.205882352941178
avg_envstep_per_sec: 926.7263081422269
avg_train_sample_per_sec: 926.7263081422269
avg_episode_per_sec: 29.697167273172212
collect_time: 1.1448903421409784
reward_mean: 3.8823529411764706
reward_std: 3.636131637770727
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 139995
total_train_sample_count: 139984
total_episode_count: 5700
total_duration: 172.90833163108132
[2023-06-10 05:36:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1103
train_sample_count: 1103
avg_envstep_per_episode: 29.81081081081081
avg_sample_per_episode: 29.81081081081081
avg_envstep_per_sec: 789.1103914905964
avg_train_sample_per_sec: 789.1103914905964
avg_episode_per_sec: 26.470611500591176
collect_time: 1.3977765492562826
reward_mean: 3.7837837837837838
reward_std: 3.7857137934904057
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 141076
total_train_sample_count: 141061
total_episode_count: 5737
total_duration: 174.30610818033762
[2023-06-10 05:36:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 24.94736842105263
avg_sample_per_episode: 24.94736842105263
avg_envstep_per_sec: 870.4490986217952
avg_train_sample_per_sec: 870.4490986217952
avg_episode_per_sec: 34.89141956500867
collect_time: 1.0890929768334452
reward_mean: 2.1842105263157894
reward_std: 2.9096505773021035
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 142141
total_train_sample_count: 142139
total_episode_count: 5775
total_duration: 175.39520115717107
[2023-06-10 05:36:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1177
train_sample_count: 1177
avg_envstep_per_episode: 25.04255319148936
avg_sample_per_episode: 25.04255319148936
avg_envstep_per_sec: 807.6431893358462
avg_train_sample_per_sec: 807.6431893358462
avg_episode_per_sec: 32.25083253932436
collect_time: 1.4573267199440996
reward_mean: 2.3617021276595747
reward_std: 3.09718837434304
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 143209
total_train_sample_count: 143199
total_episode_count: 5822
total_duration: 176.85252787711516
[2023-06-10 05:36:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 24.925
avg_sample_per_episode: 24.925
avg_envstep_per_sec: 848.3054527107255
avg_train_sample_per_sec: 848.3054527107255
avg_episode_per_sec: 34.03432107164395
collect_time: 1.1752842054876897
reward_mean: 2.325
reward_std: 2.8756520999592423
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 144274
total_train_sample_count: 144274
total_episode_count: 5862
total_duration: 178.02781208260285
[2023-06-10 05:36:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 27.5609756097561
avg_sample_per_episode: 27.5609756097561
avg_envstep_per_sec: 783.8613186440093
avg_train_sample_per_sec: 783.8613186440093
avg_episode_per_sec: 28.440985897702994
collect_time: 1.4415815312264306
reward_mean: 2.7804878048780486
reward_std: 3.453610306952755
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 145370
total_train_sample_count: 145352
total_episode_count: 5903
total_duration: 179.46939361382928
[2023-06-10 05:36:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1118
train_sample_count: 1118
avg_envstep_per_episode: 27.26829268292683
avg_sample_per_episode: 27.26829268292683
avg_envstep_per_sec: 794.9023131209732
avg_train_sample_per_sec: 794.9023131209732
avg_episode_per_sec: 29.15115817348828
collect_time: 1.4064621294287967
reward_mean: 3.0
reward_std: 2.979605473965942
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 146439
total_train_sample_count: 146418
total_episode_count: 5944
total_duration: 180.8758557432581
[2023-06-10 05:36:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 25.205128205128204
avg_sample_per_episode: 25.205128205128204
avg_envstep_per_sec: 798.6391447996659
avg_train_sample_per_sec: 798.6391447996659
avg_episode_per_sec: 31.685581533252257
collect_time: 1.230843750147734
reward_mean: 2.641025641025641
reward_std: 3.576900101019858
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 147564
total_train_sample_count: 147557
total_episode_count: 5983
total_duration: 182.1066994934058
[2023-06-10 05:36:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 29.17948717948718
avg_sample_per_episode: 29.17948717948718
avg_envstep_per_sec: 895.1101137804923
avg_train_sample_per_sec: 895.1101137804923
avg_episode_per_sec: 30.676005656800704
collect_time: 1.2713519627140215
reward_mean: 3.5384615384615383
reward_std: 3.4997886664853315
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 148614
total_train_sample_count: 148604
total_episode_count: 6022
total_duration: 183.37805145611983
[2023-06-10 05:37:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 24.930232558139537
avg_sample_per_episode: 24.930232558139537
avg_envstep_per_sec: 754.4749408950411
avg_train_sample_per_sec: 754.4749408950411
avg_episode_per_sec: 30.263453785901834
collect_time: 1.4208556731231865
reward_mean: 2.558139534883721
reward_std: 3.3501289498361126
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 149675
total_train_sample_count: 149663
total_episode_count: 6065
total_duration: 184.79890712924302
[2023-06-10 05:37:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 30.08108108108108
avg_sample_per_episode: 30.08108108108108
avg_envstep_per_sec: 782.3428256292311
avg_train_sample_per_sec: 782.3428256292311
avg_episode_per_sec: 26.0078028286447
collect_time: 1.422649973309111
reward_mean: 3.918918918918919
reward_std: 4.225907088798284
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 150769
total_train_sample_count: 150737
total_episode_count: 6102
total_duration: 186.22155710255214
[2023-06-10 05:37:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 25.833333333333332
avg_sample_per_episode: 25.833333333333332
avg_envstep_per_sec: 849.231140798052
avg_train_sample_per_sec: 849.231140798052
avg_episode_per_sec: 32.87346351476331
collect_time: 1.2776262525893571
reward_mean: 2.738095238095238
reward_std: 3.2371322097360586
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 151844
total_train_sample_count: 151835
total_episode_count: 6144
total_duration: 187.4991833551415
[2023-06-10 05:37:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 27.047619047619047
avg_sample_per_episode: 27.047619047619047
avg_envstep_per_sec: 827.125473541266
avg_train_sample_per_sec: 827.125473541266
avg_episode_per_sec: 30.580343211913004
collect_time: 1.3734312826037318
reward_mean: 2.8333333333333335
reward_std: 3.728376811803449
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 152932
total_train_sample_count: 152932
total_episode_count: 6186
total_duration: 188.87261463774522
[2023-06-10 05:37:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 28.666666666666668
avg_sample_per_episode: 28.666666666666668
avg_envstep_per_sec: 783.3898984755057
avg_train_sample_per_sec: 783.3898984755057
avg_episode_per_sec: 27.327554597982758
collect_time: 1.317351681465762
reward_mean: 3.1944444444444446
reward_std: 3.4304149768767402
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 153997
total_train_sample_count: 153990
total_episode_count: 6222
total_duration: 190.18996631921098
[2023-06-10 05:37:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 23.891304347826086
avg_sample_per_episode: 23.891304347826086
avg_envstep_per_sec: 796.0313853855364
avg_train_sample_per_sec: 796.0313853855364
avg_episode_per_sec: 33.31887509348014
collect_time: 1.3805988308711332
reward_mean: 2.369565217391304
reward_std: 2.995349262150982
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 155088
total_train_sample_count: 155063
total_episode_count: 6268
total_duration: 191.5705651500821
[2023-06-10 05:37:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 24.975609756097562
avg_sample_per_episode: 24.975609756097562
avg_envstep_per_sec: 831.9919227856674
avg_train_sample_per_sec: 831.9919227856674
avg_episode_per_sec: 33.31217659591051
collect_time: 1.2307811794271428
reward_mean: 2.3902439024390243
reward_std: 3.1147019493355264
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 156156
total_train_sample_count: 156126
total_episode_count: 6309
total_duration: 192.80134632950924
[2023-06-10 05:37:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 952
train_sample_count: 952
avg_envstep_per_episode: 25.72972972972973
avg_sample_per_episode: 25.72972972972973
avg_envstep_per_sec: 828.3986523181538
avg_train_sample_per_sec: 828.3986523181538
avg_episode_per_sec: 32.196166109003876
collect_time: 1.1492051530213934
reward_mean: 2.5405405405405403
reward_std: 3.4374298585047884
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 157220
total_train_sample_count: 157208
total_episode_count: 6346
total_duration: 193.95055148253064
[2023-06-10 05:37:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1271
train_sample_count: 1271
avg_envstep_per_episode: 31.0
avg_sample_per_episode: 31.0
avg_envstep_per_sec: 783.6294516552018
avg_train_sample_per_sec: 783.6294516552018
avg_episode_per_sec: 25.278369408232315
collect_time: 1.6219400602100418
reward_mean: 3.3658536585365852
reward_std: 3.9184124308939428
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 158321
total_train_sample_count: 158310
total_episode_count: 6387
total_duration: 195.5724915427407
[2023-06-10 05:37:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 27.25
avg_sample_per_episode: 27.25
avg_envstep_per_sec: 877.7323407837357
avg_train_sample_per_sec: 877.7323407837357
avg_episode_per_sec: 32.210361129678375
collect_time: 1.241836433902764
reward_mean: 3.225
reward_std: 3.372591733370643
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 159398
total_train_sample_count: 159387
total_episode_count: 6427
total_duration: 196.81432797664345
[2023-06-10 05:37:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 33
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 29.09090909090909
avg_sample_per_episode: 29.09090909090909
avg_envstep_per_sec: 790.285830113415
avg_train_sample_per_sec: 790.285830113415
avg_episode_per_sec: 27.16607541014864
collect_time: 1.214750364260269
reward_mean: 3.757575757575758
reward_std: 3.86930659382118
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 160485
total_train_sample_count: 160451
total_episode_count: 6460
total_duration: 198.02907834090374
[2023-06-10 05:37:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 30.17142857142857
avg_sample_per_episode: 30.17142857142857
avg_envstep_per_sec: 803.9751623969679
avg_train_sample_per_sec: 803.9751623969679
avg_episode_per_sec: 26.646904056717688
collect_time: 1.3134734123522502
reward_mean: 3.657142857142857
reward_std: 3.9852790340943307
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 161546
total_train_sample_count: 161533
total_episode_count: 6495
total_duration: 199.34255175325598
[2023-06-10 05:37:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 29.487179487179485
avg_sample_per_episode: 29.487179487179485
avg_envstep_per_sec: 804.8221004486918
avg_train_sample_per_sec: 804.8221004486918
avg_episode_per_sec: 27.293966884781725
collect_time: 1.4288872029717747
reward_mean: 3.6153846153846154
reward_std: 3.9001340188372393
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 162619
total_train_sample_count: 162618
total_episode_count: 6534
total_duration: 200.77143895622774
[2023-06-10 05:37:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1059
train_sample_count: 1059
avg_envstep_per_episode: 26.475
avg_sample_per_episode: 26.475
avg_envstep_per_sec: 801.7651368465685
avg_train_sample_per_sec: 801.7651368465685
avg_episode_per_sec: 30.2838578601159
collect_time: 1.3208356803404608
reward_mean: 2.875
reward_std: 3.52269428137044
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 163703
total_train_sample_count: 163690
total_episode_count: 6574
total_duration: 202.0922746365682
[2023-06-10 05:37:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 23.302325581395348
avg_sample_per_episode: 23.302325581395348
avg_envstep_per_sec: 818.6820532381164
avg_train_sample_per_sec: 818.6820532381164
avg_episode_per_sec: 35.133062164909184
collect_time: 1.2239183649339935
reward_mean: 2.2325581395348837
reward_std: 3.1830744922737795
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 164749
total_train_sample_count: 164744
total_episode_count: 6617
total_duration: 203.3161930015022
[2023-06-10 05:37:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 29.57894736842105
avg_sample_per_episode: 29.57894736842105
avg_envstep_per_sec: 843.0996441589526
avg_train_sample_per_sec: 843.0996441589526
avg_episode_per_sec: 28.503368752704805
collect_time: 1.3331757494943126
reward_mean: 3.0789473684210527
reward_std: 3.556917492698066
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 165807
total_train_sample_count: 165790
total_episode_count: 6655
total_duration: 204.6493687509965
[2023-06-10 05:37:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 26.083333333333332
avg_sample_per_episode: 26.083333333333332
avg_envstep_per_sec: 783.3002965304361
avg_train_sample_per_sec: 783.3002965304361
avg_episode_per_sec: 30.03068229509659
collect_time: 1.1987739621180062
reward_mean: 2.8333333333333335
reward_std: 3.5862391318916687
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 166873
total_train_sample_count: 166846
total_episode_count: 6691
total_duration: 205.8481427131145
[2023-06-10 05:37:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 30.4
avg_sample_per_episode: 30.4
avg_envstep_per_sec: 808.1225179531305
avg_train_sample_per_sec: 808.1225179531305
avg_episode_per_sec: 26.582977564247713
collect_time: 1.5047223323017533
reward_mean: 3.95
reward_std: 4.012168989461935
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 167971
total_train_sample_count: 167971
total_episode_count: 6731
total_duration: 207.35286504541625
[2023-06-10 05:37:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1126
train_sample_count: 1126
avg_envstep_per_episode: 26.80952380952381
avg_sample_per_episode: 26.80952380952381
avg_envstep_per_sec: 739.6206786175863
avg_train_sample_per_sec: 739.6206786175863
avg_episode_per_sec: 27.587982683782087
collect_time: 1.5224019995014055
reward_mean: 2.9285714285714284
reward_std: 3.6278870745725174
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 169049
total_train_sample_count: 169019
total_episode_count: 6773
total_duration: 208.87526704491765
[2023-06-10 05:37:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 23.7
avg_sample_per_episode: 23.7
avg_envstep_per_sec: 776.7245899552055
avg_train_sample_per_sec: 776.7245899552055
avg_episode_per_sec: 32.77318944958673
collect_time: 1.2205098335494595
reward_mean: 1.95
reward_std: 3.1460292433478747
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 170112
total_train_sample_count: 170097
total_episode_count: 6813
total_duration: 210.09577687846712
[2023-06-10 05:37:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 27.953488372093023
avg_sample_per_episode: 27.953488372093023
avg_envstep_per_sec: 823.6957877857582
avg_train_sample_per_sec: 823.6957877857582
avg_episode_per_sec: 29.466654637926457
collect_time: 1.459276613798392
reward_mean: 3.186046511627907
reward_std: 3.2867302897920703
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 171182
total_train_sample_count: 171182
total_episode_count: 6856
total_duration: 211.5550534922655
[2023-06-10 05:38:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 26.973684210526315
avg_sample_per_episode: 26.973684210526315
avg_envstep_per_sec: 773.0013819794281
avg_train_sample_per_sec: 773.0013819794281
avg_episode_per_sec: 28.657612209969038
collect_time: 1.3260002166817322
reward_mean: 2.5526315789473686
reward_std: 3.3615266614805948
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 172258
total_train_sample_count: 172246
total_episode_count: 6894
total_duration: 212.88105370894723
[2023-06-10 05:38:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 986
train_sample_count: 986
avg_envstep_per_episode: 28.17142857142857
avg_sample_per_episode: 28.17142857142857
avg_envstep_per_sec: 827.6981481838386
avg_train_sample_per_sec: 827.6981481838386
avg_episode_per_sec: 29.380765909162626
collect_time: 1.1912555345973799
reward_mean: 3.0285714285714285
reward_std: 3.668286593303779
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 173306
total_train_sample_count: 173284
total_episode_count: 6929
total_duration: 214.07230924354462
[2023-06-10 05:38:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 31.62857142857143
avg_sample_per_episode: 31.62857142857143
avg_envstep_per_sec: 781.969122352006
avg_train_sample_per_sec: 781.969122352006
avg_episode_per_sec: 24.723504320072458
collect_time: 1.4156569209157088
reward_mean: 4.228571428571429
reward_std: 4.050296033524424
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 174378
total_train_sample_count: 174378
total_episode_count: 6964
total_duration: 215.48796616446035
[2023-06-10 05:38:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 25.609756097560975
avg_sample_per_episode: 25.609756097560975
avg_envstep_per_sec: 766.6558846575676
avg_train_sample_per_sec: 766.6558846575676
avg_episode_per_sec: 29.93608692472407
collect_time: 1.3695844785290991
reward_mean: 2.5365853658536586
reward_std: 3.3720339159797232
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 175428
total_train_sample_count: 175428
total_episode_count: 7005
total_duration: 216.85755064298945
[2023-06-10 05:38:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1094
train_sample_count: 1094
avg_envstep_per_episode: 28.05128205128205
avg_sample_per_episode: 28.05128205128205
avg_envstep_per_sec: 811.4393049556301
avg_train_sample_per_sec: 811.4393049556301
avg_episode_per_sec: 28.926995332056283
collect_time: 1.3482216024275784
reward_mean: 3.4615384615384617
reward_std: 3.842049091680074
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 176503
total_train_sample_count: 176496
total_episode_count: 7044
total_duration: 218.20577224541702
[2023-06-10 05:38:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 31
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 35.70967741935484
avg_sample_per_episode: 35.70967741935484
avg_envstep_per_sec: 884.3282744175584
avg_train_sample_per_sec: 884.3282744175584
avg_episode_per_sec: 24.764387088477246
collect_time: 1.2517975869640705
reward_mean: 4.935483870967742
reward_std: 4.039606207819766
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 177590
total_train_sample_count: 177590
total_episode_count: 7075
total_duration: 219.4575698323811
[2023-06-10 05:38:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 27.5609756097561
avg_sample_per_episode: 27.5609756097561
avg_envstep_per_sec: 852.8186598244523
avg_train_sample_per_sec: 852.8186598244523
avg_episode_per_sec: 30.94297792283411
collect_time: 1.3250179120524916
reward_mean: 3.073170731707317
reward_std: 3.770166871524836
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 178722
total_train_sample_count: 178707
total_episode_count: 7116
total_duration: 220.78258774443358
[2023-06-10 05:38:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 26.333333333333332
avg_sample_per_episode: 26.333333333333332
avg_envstep_per_sec: 860.696048794863
avg_train_sample_per_sec: 860.696048794863
avg_episode_per_sec: 32.684660080817586
collect_time: 1.2850064799862957
reward_mean: 3.0238095238095237
reward_std: 3.4260076393188617
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 179825
total_train_sample_count: 179800
total_episode_count: 7158
total_duration: 222.06759422441988
[2023-06-10 05:38:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1074
train_sample_count: 1074
avg_envstep_per_episode: 24.40909090909091
avg_sample_per_episode: 24.40909090909091
avg_envstep_per_sec: 844.0589878353994
avg_train_sample_per_sec: 844.0589878353994
avg_episode_per_sec: 34.579697825658826
collect_time: 1.2724229176852762
reward_mean: 2.5454545454545454
reward_std: 3.4208886767685054
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 180886
total_train_sample_count: 180874
total_episode_count: 7202
total_duration: 223.34001714210515
[2023-06-10 05:38:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 45
envstep_count: 1067
train_sample_count: 1067
avg_envstep_per_episode: 23.711111111111112
avg_sample_per_episode: 23.711111111111112
avg_envstep_per_sec: 747.7560079067201
avg_train_sample_per_sec: 747.7560079067201
avg_episode_per_sec: 31.53610155182981
collect_time: 1.4269360442679377
reward_mean: 2.1333333333333333
reward_std: 3.3105890714493698
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 181961
total_train_sample_count: 181941
total_episode_count: 7247
total_duration: 224.7669531863731
[2023-06-10 05:38:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 897
train_sample_count: 897
avg_envstep_per_episode: 26.38235294117647
avg_sample_per_episode: 26.38235294117647
avg_envstep_per_sec: 864.9414051313088
avg_train_sample_per_sec: 864.9414051313088
avg_episode_per_sec: 32.784847017240246
collect_time: 1.037064470123065
reward_mean: 2.735294117647059
reward_std: 3.012804278305705
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 183026
total_train_sample_count: 183020
total_episode_count: 7281
total_duration: 225.80401765649614
[2023-06-10 05:38:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1241
train_sample_count: 1241
avg_envstep_per_episode: 33.54054054054054
avg_sample_per_episode: 33.54054054054054
avg_envstep_per_sec: 854.9075288703453
avg_train_sample_per_sec: 854.9075288703453
avg_episode_per_sec: 25.488782085578386
collect_time: 1.451618985786484
reward_mean: 4.1891891891891895
reward_std: 4.769485426592445
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 184123
total_train_sample_count: 184118
total_episode_count: 7318
total_duration: 227.25563664228264
[2023-06-10 05:38:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 24.761904761904763
avg_sample_per_episode: 24.761904761904763
avg_envstep_per_sec: 839.3322241519365
avg_train_sample_per_sec: 839.3322241519365
avg_episode_per_sec: 33.896109052289745
collect_time: 1.2390802712844948
reward_mean: 2.5714285714285716
reward_std: 2.6916348116309674
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 185166
total_train_sample_count: 185158
total_episode_count: 7360
total_duration: 228.49471691356715
[2023-06-10 05:38:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 29.27777777777778
avg_sample_per_episode: 29.27777777777778
avg_envstep_per_sec: 846.5937969653118
avg_train_sample_per_sec: 846.5937969653118
avg_episode_per_sec: 28.91591716390059
collect_time: 1.2449890417082592
reward_mean: 3.75
reward_std: 4.335736513109522
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 186283
total_train_sample_count: 186277
total_episode_count: 7396
total_duration: 229.7397059552754
[2023-06-10 05:38:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1034
train_sample_count: 1034
avg_envstep_per_episode: 27.945945945945947
avg_sample_per_episode: 27.945945945945947
avg_envstep_per_sec: 819.060078267165
avg_train_sample_per_sec: 819.060078267165
avg_episode_per_sec: 29.308726204917896
collect_time: 1.2624226566964052
reward_mean: 3.27027027027027
reward_std: 3.5841139630216774
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 187350
total_train_sample_count: 187350
total_episode_count: 7433
total_duration: 231.0021286119718
[2023-06-10 05:38:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 26.613636363636363
avg_sample_per_episode: 26.613636363636363
avg_envstep_per_sec: 780.4232599369325
avg_train_sample_per_sec: 780.4232599369325
avg_episode_per_sec: 29.32418739301881
collect_time: 1.5004678359979056
reward_mean: 2.590909090909091
reward_std: 3.7131105669835134
reward_max: 17.0
reward_min: 0.0
total_envstep_count: 188443
total_train_sample_count: 188430
total_episode_count: 7477
total_duration: 232.50259644796972
[2023-06-10 05:38:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 32.628571428571426
avg_sample_per_episode: 32.628571428571426
avg_envstep_per_sec: 872.2588803886862
avg_train_sample_per_sec: 872.2588803886862
avg_episode_per_sec: 26.73297794536254
collect_time: 1.3092443375195157
reward_mean: 4.2
reward_std: 3.54400902933387
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 189573
total_train_sample_count: 189559
total_episode_count: 7512
total_duration: 233.81184078548924
[2023-06-10 05:38:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 29.705882352941178
avg_sample_per_episode: 29.705882352941178
avg_envstep_per_sec: 856.598257850999
avg_train_sample_per_sec: 856.598257850999
avg_episode_per_sec: 28.83598095736036
collect_time: 1.1790824820655712
reward_mean: 3.588235294117647
reward_std: 3.4566019275891677
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 190621
total_train_sample_count: 190621
total_episode_count: 7546
total_duration: 234.99092326755482
[2023-06-10 05:38:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1166
train_sample_count: 1166
avg_envstep_per_episode: 24.80851063829787
avg_sample_per_episode: 24.80851063829787
avg_envstep_per_sec: 810.6365927829405
avg_train_sample_per_sec: 810.6365927829405
avg_episode_per_sec: 32.675746021267756
collect_time: 1.4383757288788135
reward_mean: 2.3191489361702127
reward_std: 3.7365724593235794
reward_max: 16.0
reward_min: 0.0
total_envstep_count: 191715
total_train_sample_count: 191696
total_episode_count: 7593
total_duration: 236.42929899643363
[2023-06-10 05:38:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1031
train_sample_count: 1031
avg_envstep_per_episode: 27.864864864864863
avg_sample_per_episode: 27.864864864864863
avg_envstep_per_sec: 892.8348104952097
avg_train_sample_per_sec: 892.8348104952097
avg_episode_per_sec: 32.0415984367825
collect_time: 1.1547488828623933
reward_mean: 3.2972972972972974
reward_std: 3.2204151559199907
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 192778
total_train_sample_count: 192766
total_episode_count: 7630
total_duration: 237.58404787929604
[2023-06-10 05:38:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 24.347826086956523
avg_sample_per_episode: 24.347826086956523
avg_envstep_per_sec: 862.5832943043986
avg_train_sample_per_sec: 862.5832943043986
avg_episode_per_sec: 35.427528158930656
collect_time: 1.2984253316697798
reward_mean: 2.391304347826087
reward_std: 3.3328291994324872
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 193851
total_train_sample_count: 193847
total_episode_count: 7676
total_duration: 238.88247321096583
[2023-06-10 05:38:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 34
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 30.823529411764707
avg_sample_per_episode: 30.823529411764707
avg_envstep_per_sec: 895.023977844517
avg_train_sample_per_sec: 895.023977844517
avg_episode_per_sec: 29.03703744915418
collect_time: 1.1709183507283174
reward_mean: 3.588235294117647
reward_std: 3.971350689321941
reward_max: 16.0
reward_min: 0.0
total_envstep_count: 194999
total_train_sample_count: 194973
total_episode_count: 7710
total_duration: 240.05339156169416
[2023-06-10 05:39:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1039
train_sample_count: 1039
avg_envstep_per_episode: 28.08108108108108
avg_sample_per_episode: 28.08108108108108
avg_envstep_per_sec: 834.6912462996594
avg_train_sample_per_sec: 834.6912462996594
avg_episode_per_sec: 29.724327346571126
collect_time: 1.2447716501234187
reward_mean: 3.2432432432432434
reward_std: 3.4122625085592713
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 196051
total_train_sample_count: 196038
total_episode_count: 7747
total_duration: 241.29816321181758
[2023-06-10 05:39:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 32
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 33.5
avg_sample_per_episode: 33.5
avg_envstep_per_sec: 886.6445339322884
avg_train_sample_per_sec: 886.6445339322884
avg_episode_per_sec: 26.46700101290413
collect_time: 1.209052736439547
reward_mean: 4.46875
reward_std: 4.2055348574824585
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 197123
total_train_sample_count: 197097
total_episode_count: 7779
total_duration: 242.50721594825714
[2023-06-10 05:39:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 28.625
avg_sample_per_episode: 28.625
avg_envstep_per_sec: 795.5920276602943
avg_train_sample_per_sec: 795.5920276602943
avg_episode_per_sec: 27.79360795319805
collect_time: 1.4391798311092399
reward_mean: 3.5
reward_std: 3.8013155617496426
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 198259
total_train_sample_count: 198216
total_episode_count: 7819
total_duration: 243.94639577936638
[2023-06-10 05:39:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 46
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 25.02173913043478
avg_sample_per_episode: 25.02173913043478
avg_envstep_per_sec: 872.0703140775415
avg_train_sample_per_sec: 872.0703140775415
avg_episode_per_sec: 34.85250603611374
collect_time: 1.3198477019797477
reward_mean: 2.4347826086956523
reward_std: 3.7801091191579403
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 199315
total_train_sample_count: 199302
total_episode_count: 7865
total_duration: 245.26624348134612
[2023-06-10 05:39:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 47
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 24.404255319148938
avg_sample_per_episode: 24.404255319148938
avg_envstep_per_sec: 783.3884223140082
avg_train_sample_per_sec: 783.3884223140082
avg_episode_per_sec: 32.1004846109489
collect_time: 1.4641523506461067
reward_mean: 2.5531914893617023
reward_std: 3.240754513133578
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 200432
total_train_sample_count: 200423
total_episode_count: 7912
total_duration: 246.73039583199224
[2023-06-10 05:39:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 31
envstep_count: 957
train_sample_count: 957
avg_envstep_per_episode: 30.870967741935484
avg_sample_per_episode: 30.870967741935484
avg_envstep_per_sec: 834.8252414679548
avg_train_sample_per_sec: 834.8252414679548
avg_episode_per_sec: 27.042405940968234
collect_time: 1.1463477054397797
reward_mean: 4.096774193548387
reward_std: 3.5227815138286305
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 201534
total_train_sample_count: 201497
total_episode_count: 7943
total_duration: 247.87674353743202
[2023-06-10 05:39:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1105
train_sample_count: 1105
avg_envstep_per_episode: 29.07894736842105
avg_sample_per_episode: 29.07894736842105
avg_envstep_per_sec: 871.8950555836786
avg_train_sample_per_sec: 871.8950555836786
avg_episode_per_sec: 29.9837213684885
collect_time: 1.2673543598206005
reward_mean: 3.736842105263158
reward_std: 3.74646647927516
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 202610
total_train_sample_count: 202602
total_episode_count: 7981
total_duration: 249.1440978972526
[2023-06-10 05:39:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1051
train_sample_count: 1051
avg_envstep_per_episode: 29.194444444444443
avg_sample_per_episode: 29.194444444444443
avg_envstep_per_sec: 795.8014786782078
avg_train_sample_per_sec: 795.8014786782078
avg_episode_per_sec: 27.25866149611368
collect_time: 1.3206811348801035
reward_mean: 3.4166666666666665
reward_std: 4.11214326382511
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 203661
total_train_sample_count: 203653
total_episode_count: 8017
total_duration: 250.4647790321327
[2023-06-10 05:39:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 44
envstep_count: 1252
train_sample_count: 1252
avg_envstep_per_episode: 28.454545454545453
avg_sample_per_episode: 28.454545454545453
avg_envstep_per_sec: 756.1220246294449
avg_train_sample_per_sec: 756.1220246294449
avg_episode_per_sec: 26.572978501354296
collect_time: 1.6558173935133969
reward_mean: 3.340909090909091
reward_std: 3.4505808589950204
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 204822
total_train_sample_count: 204775
total_episode_count: 8061
total_duration: 252.12059642564608
[2023-06-10 05:39:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 28.216216216216218
avg_sample_per_episode: 28.216216216216218
avg_envstep_per_sec: 814.8500968503236
avg_train_sample_per_sec: 814.8500968503236
avg_episode_per_sec: 28.878786957339052
collect_time: 1.2812172496946614
reward_mean: 3.3783783783783785
reward_std: 4.002373291553139
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 205890
total_train_sample_count: 205884
total_episode_count: 8098
total_duration: 253.40181367534075
[2023-06-10 05:39:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1074
train_sample_count: 1074
avg_envstep_per_episode: 26.195121951219512
avg_sample_per_episode: 26.195121951219512
avg_envstep_per_sec: 888.7364525304735
avg_train_sample_per_sec: 888.7364525304735
avg_episode_per_sec: 33.927555450418446
collect_time: 1.2084572394234883
reward_mean: 2.926829268292683
reward_std: 3.4738763328202595
reward_max: 15.0
reward_min: 0.0
total_envstep_count: 206948
total_train_sample_count: 206932
total_episode_count: 8139
total_duration: 254.61027091476424
[2023-06-10 05:39:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 26.83783783783784
avg_sample_per_episode: 26.83783783783784
avg_envstep_per_sec: 796.1821761486518
avg_train_sample_per_sec: 796.1821761486518
avg_episode_per_sec: 29.666405354985013
collect_time: 1.2472019969140846
reward_mean: 3.2972972972972974
reward_std: 4.348748592068725
reward_max: 17.0
reward_min: 0.0
total_envstep_count: 208012
total_train_sample_count: 208003
total_episode_count: 8176
total_duration: 255.85747291167831
[2023-06-10 05:39:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1121
train_sample_count: 1121
avg_envstep_per_episode: 28.743589743589745
avg_sample_per_episode: 28.743589743589745
avg_envstep_per_sec: 802.6436482187468
avg_train_sample_per_sec: 802.6436482187468
avg_episode_per_sec: 27.924266084327495
collect_time: 1.396634736333814
reward_mean: 3.4358974358974357
reward_std: 3.9600237748242004
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 209128
total_train_sample_count: 209111
total_episode_count: 8215
total_duration: 257.2541076480121
[2023-06-10 05:39:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 29.358974358974358
avg_sample_per_episode: 29.358974358974358
avg_envstep_per_sec: 860.5354397624764
avg_train_sample_per_sec: 860.5354397624764
avg_episode_per_sec: 29.31081410544679
collect_time: 1.330566932044125
reward_mean: 3.58974358974359
reward_std: 4.099518099996938
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 210152
total_train_sample_count: 210152
total_episode_count: 8254
total_duration: 258.58467458005623
[2023-06-10 05:39:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 39
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 25.692307692307693
avg_sample_per_episode: 25.692307692307693
avg_envstep_per_sec: 872.6384055650853
avg_train_sample_per_sec: 872.6384055650853
avg_episode_per_sec: 33.964967881275776
collect_time: 1.1482419219804396
reward_mean: 2.6923076923076925
reward_std: 2.9190255324631194
reward_max: 9.0
reward_min: 0.0
total_envstep_count: 211251
total_train_sample_count: 211219
total_episode_count: 8293
total_duration: 259.7329165020367
[2023-06-10 05:39:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1101
train_sample_count: 1101
avg_envstep_per_episode: 28.973684210526315
avg_sample_per_episode: 28.973684210526315
avg_envstep_per_sec: 916.1142021084778
avg_train_sample_per_sec: 916.1142021084778
avg_episode_per_sec: 31.618837129992873
collect_time: 1.201815229439735
reward_mean: 3.8684210526315788
reward_std: 3.894470118889758
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 212333
total_train_sample_count: 212333
total_episode_count: 8331
total_duration: 260.9347317314764
[2023-06-10 05:39:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1045
train_sample_count: 1045
avg_envstep_per_episode: 29.857142857142858
avg_sample_per_episode: 29.857142857142858
avg_envstep_per_sec: 885.6397422857094
avg_train_sample_per_sec: 885.6397422857094
avg_episode_per_sec: 29.662575100478303
collect_time: 1.1799380155445651
reward_mean: 3.6857142857142855
reward_std: 3.95525999558222
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 213434
total_train_sample_count: 213430
total_episode_count: 8366
total_duration: 262.11466974702097
[2023-06-10 05:39:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 29.72222222222222
avg_sample_per_episode: 29.72222222222222
avg_envstep_per_sec: 826.5826876723565
avg_train_sample_per_sec: 826.5826876723565
avg_episode_per_sec: 27.810258650658728
collect_time: 1.2944863423320692
reward_mean: 3.5
reward_std: 4.106228331584973
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 214535
total_train_sample_count: 214513
total_episode_count: 8402
total_duration: 263.409156089353
[2023-06-10 05:39:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 38
envstep_count: 1098
train_sample_count: 1098
avg_envstep_per_episode: 28.894736842105264
avg_sample_per_episode: 28.894736842105264
avg_envstep_per_sec: 802.9145371723106
avg_train_sample_per_sec: 802.9145371723106
avg_episode_per_sec: 27.787570503231148
collect_time: 1.367517897816268
reward_mean: 3.736842105263158
reward_std: 4.592237217226455
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 215568
total_train_sample_count: 215559
total_episode_count: 8440
total_duration: 264.77667398716926
[2023-06-10 05:39:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1021
train_sample_count: 1021
avg_envstep_per_episode: 25.525
avg_sample_per_episode: 25.525
avg_envstep_per_sec: 816.8243991285178
avg_train_sample_per_sec: 816.8243991285178
avg_episode_per_sec: 32.00095589142087
collect_time: 1.2499626616067299
reward_mean: 2.675
reward_std: 3.73086786150354
reward_max: 13.0
reward_min: 0.0
total_envstep_count: 216613
total_train_sample_count: 216606
total_episode_count: 8480
total_duration: 266.026636648776
[2023-06-10 05:39:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1094
train_sample_count: 1094
avg_envstep_per_episode: 29.56756756756757
avg_sample_per_episode: 29.56756756756757
avg_envstep_per_sec: 761.5771282838523
avg_train_sample_per_sec: 761.5771282838523
avg_episode_per_sec: 25.75717892733321
collect_time: 1.4364927193457526
reward_mean: 3.7567567567567566
reward_std: 4.193981565680179
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 217742
total_train_sample_count: 217726
total_episode_count: 8517
total_duration: 267.46312936812177
[2023-06-10 05:40:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 33
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 32.21212121212121
avg_sample_per_episode: 32.21212121212121
avg_envstep_per_sec: 790.0083002542636
avg_train_sample_per_sec: 790.0083002542636
avg_episode_per_sec: 24.525187119840734
collect_time: 1.3455554829713487
reward_mean: 3.9393939393939394
reward_std: 4.1116198528692705
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 218816
total_train_sample_count: 218802
total_episode_count: 8550
total_duration: 268.8086848510931
[2023-06-10 05:40:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1084
train_sample_count: 1084
avg_envstep_per_episode: 26.4390243902439
avg_sample_per_episode: 26.4390243902439
avg_envstep_per_sec: 775.3627735766029
avg_train_sample_per_sec: 775.3627735766029
avg_episode_per_sec: 29.32645176811874
collect_time: 1.3980552548321499
reward_mean: 2.5121951219512195
reward_std: 3.1554981147469134
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 219868
total_train_sample_count: 219847
total_episode_count: 8591
total_duration: 270.2067401059253
[2023-06-10 05:40:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 43
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 26.627906976744185
avg_sample_per_episode: 26.627906976744185
avg_envstep_per_sec: 755.5928525834623
avg_train_sample_per_sec: 755.5928525834623
avg_episode_per_sec: 28.375976123221726
collect_time: 1.515366372359278
reward_mean: 2.953488372093023
reward_std: 4.339936171281211
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 220928
total_train_sample_count: 220927
total_episode_count: 8634
total_duration: 271.72210647828456
[2023-06-10 05:40:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1108
train_sample_count: 1108
avg_envstep_per_episode: 27.024390243902438
avg_sample_per_episode: 27.024390243902438
avg_envstep_per_sec: 835.1903847327304
avg_train_sample_per_sec: 835.1903847327304
avg_episode_per_sec: 30.90505936285374
collect_time: 1.3266436255184757
reward_mean: 2.951219512195122
reward_std: 3.581464610559826
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 222080
total_train_sample_count: 222035
total_episode_count: 8675
total_duration: 273.04875010380306
[2023-06-10 05:40:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1096
train_sample_count: 1096
avg_envstep_per_episode: 27.4
avg_sample_per_episode: 27.4
avg_envstep_per_sec: 808.8570683076889
avg_train_sample_per_sec: 808.8570683076889
avg_episode_per_sec: 29.520330960134633
collect_time: 1.3549983587249583
reward_mean: 2.925
reward_std: 3.7174419968575165
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 223154
total_train_sample_count: 223131
total_episode_count: 8715
total_duration: 274.40374846252803
[2023-06-10 05:40:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1105
train_sample_count: 1105
avg_envstep_per_episode: 26.951219512195124
avg_sample_per_episode: 26.951219512195124
avg_envstep_per_sec: 741.0184262219675
avg_train_sample_per_sec: 741.0184262219675
avg_episode_per_sec: 27.49480133493273
collect_time: 1.4911909891819668
reward_mean: 2.8048780487804876
reward_std: 3.3145614593871584
reward_max: 10.0
reward_min: 0.0
total_envstep_count: 224242
total_train_sample_count: 224236
total_episode_count: 8756
total_duration: 275.89493945171
[2023-06-10 05:40:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 41
envstep_count: 1067
train_sample_count: 1067
avg_envstep_per_episode: 26.024390243902438
avg_sample_per_episode: 26.024390243902438
avg_envstep_per_sec: 817.054245135131
avg_train_sample_per_sec: 817.054245135131
avg_episode_per_sec: 31.395711387572984
collect_time: 1.3059108453974568
reward_mean: 2.7560975609756095
reward_std: 3.587107590877452
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 225362
total_train_sample_count: 225329
total_episode_count: 8797
total_duration: 277.2008502971075
[2023-06-10 05:40:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 36
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 30.22222222222222
avg_sample_per_episode: 30.22222222222222
avg_envstep_per_sec: 796.5247693197505
avg_train_sample_per_sec: 796.5247693197505
avg_episode_per_sec: 26.355598984844683
collect_time: 1.3659336682388117
reward_mean: 3.3055555555555554
reward_std: 4.12188902516825
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 226398
total_train_sample_count: 226391
total_episode_count: 8833
total_duration: 278.5667839653463
[2023-06-10 05:40:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 37
envstep_count: 1029
train_sample_count: 1029
avg_envstep_per_episode: 27.81081081081081
avg_sample_per_episode: 27.81081081081081
avg_envstep_per_sec: 781.7804471228641
avg_train_sample_per_sec: 781.7804471228641
avg_episode_per_sec: 28.11066719489404
collect_time: 1.3162263187663008
reward_mean: 3.135135135135135
reward_std: 3.814355261747335
reward_max: 14.0
reward_min: 0.0
total_envstep_count: 227498
total_train_sample_count: 227498
total_episode_count: 8870
total_duration: 279.88301028411263
[2023-06-10 05:40:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 40
envstep_count: 1117
train_sample_count: 1117
avg_envstep_per_episode: 27.925
avg_sample_per_episode: 27.925
avg_envstep_per_sec: 812.4626453602683
avg_train_sample_per_sec: 812.4626453602683
avg_episode_per_sec: 29.094454623465293
collect_time: 1.374832438609767
reward_mean: 3.175
reward_std: 3.33831918785487
reward_max: 12.0
reward_min: 0.0
total_envstep_count: 228566
total_train_sample_count: 228550
total_episode_count: 8910
total_duration: 281.2578427227224
[2023-06-10 05:40:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 35
envstep_count: 1007
train_sample_count: 1007
avg_envstep_per_episode: 28.771428571428572
avg_sample_per_episode: 28.771428571428572
avg_envstep_per_sec: 811.9131273217159
avg_train_sample_per_sec: 811.9131273217159
avg_episode_per_sec: 28.219423491817334
collect_time: 1.2402804759689297
reward_mean: 3.3714285714285714
reward_std: 3.431665270770482
reward_max: 11.0
reward_min: 0.0
total_envstep_count: 229637
total_train_sample_count: 229609
total_episode_count: 8945
total_duration: 282.4981231986913
