[2023-04-29 14:00:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2688
envstep_count: 67200
train_sample_count: 67200
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 296.14747770898214
avg_train_sample_per_sec: 296.14747770898214
avg_episode_per_sec: 11.845899108359285
collect_time: 226.91397043075958
reward_mean: -217.99486322996893
reward_std: 40.789886426358365
reward_max: -115.53577301212832
reward_min: -414.28030682599575
total_envstep_count: 67200
total_train_sample_count: 67200
total_episode_count: 2688
total_duration: 226.91397043075958
[2023-04-29 14:05:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 237.10342375645823
avg_train_sample_per_sec: 237.10342375645823
avg_episode_per_sec: 9.484136950258328
collect_time: 269.9244025499095
reward_mean: -204.11036846673005
reward_std: 34.915294736845155
reward_max: -113.68032928106577
reward_min: -328.84952915901005
total_envstep_count: 131200
total_train_sample_count: 131200
total_episode_count: 5248
total_duration: 496.8383729806691
[2023-04-29 14:10:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 246.95106290344873
avg_train_sample_per_sec: 246.95106290344873
avg_episode_per_sec: 9.878042516137949
collect_time: 259.16065817875136
reward_mean: -203.0305983161908
reward_std: 33.34253434715472
reward_max: -113.27561146019649
reward_min: -308.27528385666324
total_envstep_count: 195200
total_train_sample_count: 195200
total_episode_count: 7808
total_duration: 755.9990311594204
[2023-04-29 14:14:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 290.33792254959866
avg_train_sample_per_sec: 290.33792254959866
avg_episode_per_sec: 11.613516901983946
collect_time: 220.43279581938467
reward_mean: -199.42708762074133
reward_std: 32.26345074390525
reward_max: -111.79729853847049
reward_min: -302.1158277870628
total_envstep_count: 259200
total_train_sample_count: 259200
total_episode_count: 10368
total_duration: 976.431826978805
[2023-04-29 14:19:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 226.01024646662924
avg_train_sample_per_sec: 226.01024646662924
avg_episode_per_sec: 9.04040985866517
collect_time: 283.17300211187415
reward_mean: -198.5036286730239
reward_std: 32.89677999679214
reward_max: -110.08446163992775
reward_min: -298.65060460116956
total_envstep_count: 323200
total_train_sample_count: 323200
total_episode_count: 12928
total_duration: 1259.6048290906792
[2023-04-29 14:23:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 236.71547256731867
avg_train_sample_per_sec: 236.71547256731867
avg_episode_per_sec: 9.468618902692747
collect_time: 270.3667796020358
reward_mean: -194.7217888726822
reward_std: 32.57204887259738
reward_max: -112.65667395005265
reward_min: -297.05066550855605
total_envstep_count: 387200
total_train_sample_count: 387200
total_episode_count: 15488
total_duration: 1529.971608692715
[2023-04-29 14:27:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 303.09903084069515
avg_train_sample_per_sec: 303.09903084069515
avg_episode_per_sec: 12.123961233627806
collect_time: 211.15211032673196
reward_mean: -191.45372039848226
reward_std: 31.822333173425722
reward_max: -104.79884411776607
reward_min: -291.83384915496396
total_envstep_count: 451200
total_train_sample_count: 451200
total_episode_count: 18048
total_duration: 1741.123719019447
[2023-04-29 14:32:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 227.55734997427254
avg_train_sample_per_sec: 227.55734997427254
avg_episode_per_sec: 9.102293998970902
collect_time: 281.2477821842968
reward_mean: -187.6594948786638
reward_std: 31.067222150300406
reward_max: -105.86726943335208
reward_min: -288.57740855540555
total_envstep_count: 515200
total_train_sample_count: 515200
total_episode_count: 20608
total_duration: 2022.3715012037437
[2023-04-29 14:37:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 238.97107729311685
avg_train_sample_per_sec: 238.97107729311685
avg_episode_per_sec: 9.558843091724674
collect_time: 267.8148365272629
reward_mean: -185.0094225879725
reward_std: 30.74591188319982
reward_max: -106.9537674260614
reward_min: -288.1991909859423
total_envstep_count: 579200
total_train_sample_count: 579200
total_episode_count: 23168
total_duration: 2290.1863377310065
[2023-04-29 14:41:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 306.75093391652797
avg_train_sample_per_sec: 306.75093391652797
avg_episode_per_sec: 12.270037356661119
collect_time: 208.63832159485932
reward_mean: -181.7676889409079
reward_std: 29.868471246448248
reward_max: -103.96260654410423
reward_min: -272.1104092430865
total_envstep_count: 643200
total_train_sample_count: 643200
total_episode_count: 25728
total_duration: 2498.824659325866
[2023-04-29 14:46:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 227.5391924469946
avg_train_sample_per_sec: 227.5391924469946
avg_episode_per_sec: 9.101567697879783
collect_time: 281.2702256333657
reward_mean: -179.13182512314762
reward_std: 30.226717439210613
reward_max: -102.28849076491042
reward_min: -281.2275785876745
total_envstep_count: 707200
total_train_sample_count: 707200
total_episode_count: 28288
total_duration: 2780.0948849592314
[2023-04-29 14:51:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 235.06629064834866
avg_train_sample_per_sec: 235.06629064834866
avg_episode_per_sec: 9.402651625933945
collect_time: 272.26362326762484
reward_mean: -177.12983063968738
reward_std: 29.151326295813146
reward_max: -105.29684973095158
reward_min: -272.0329000952998
total_envstep_count: 771200
total_train_sample_count: 771200
total_episode_count: 30848
total_duration: 3052.3585082268564
[2023-04-29 14:54:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 309.03995825680533
avg_train_sample_per_sec: 309.03995825680533
avg_episode_per_sec: 12.361598330272212
collect_time: 207.0929609264878
reward_mean: -175.39500065516654
reward_std: 28.659428626551257
reward_max: -103.40343793654888
reward_min: -260.95956286062926
total_envstep_count: 835200
total_train_sample_count: 835200
total_episode_count: 33408
total_duration: 3259.451469153344
[2023-04-29 14:59:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2560
envstep_count: 64000
train_sample_count: 64000
avg_envstep_per_episode: 25.0
avg_sample_per_episode: 25.0
avg_envstep_per_sec: 231.60953850571443
avg_train_sample_per_sec: 231.60953850571443
avg_episode_per_sec: 9.264381540228577
collect_time: 276.32713407622003
reward_mean: -172.36962698622952
reward_std: 28.43641588623627
reward_max: -104.05006979728763
reward_min: -261.3536097951072
total_envstep_count: 899200
total_train_sample_count: 899200
total_episode_count: 35968
total_duration: 3535.778603229564
