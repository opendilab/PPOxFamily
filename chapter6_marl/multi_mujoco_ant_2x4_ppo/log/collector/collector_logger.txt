[2023-05-17 11:38:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 334
envstep_count: 18745
train_sample_count: 18745
avg_envstep_per_episode: 56.122754491017965
avg_sample_per_episode: 56.122754491017965
avg_envstep_per_sec: 1719.3124135717717
avg_train_sample_per_sec: 1719.3124135717717
avg_episode_per_sec: 30.634854421604256
collect_time: 10.90261423812927
reward_mean: -332.5918010883298
reward_std: 706.3277462920842
reward_max: -19.02318499253481
reward_min: -3033.820910832937
total_envstep_count: 40631
total_train_sample_count: 32745
total_episode_count: 334
total_duration: 10.90261423812927
[2023-05-17 11:38:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 353
envstep_count: 21311
train_sample_count: 21311
avg_envstep_per_episode: 60.37110481586402
avg_sample_per_episode: 60.37110481586402
avg_envstep_per_sec: 1660.058152137949
avg_train_sample_per_sec: 1660.058152137949
avg_episode_per_sec: 27.4975612455866
collect_time: 12.837502091450276
reward_mean: -269.9477801456694
reward_std: 559.2402583746746
reward_max: -10.305276309957566
reward_min: -2841.579963849948
total_envstep_count: 75375
total_train_sample_count: 62056
total_episode_count: 687
total_duration: 23.740116329579546
[2023-05-17 11:39:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 331
envstep_count: 20326
train_sample_count: 20326
avg_envstep_per_episode: 61.40785498489426
avg_sample_per_episode: 61.40785498489426
avg_envstep_per_sec: 1703.8833627681781
avg_train_sample_per_sec: 1703.8833627681781
avg_episode_per_sec: 27.74699365720097
collect_time: 11.929220300019711
reward_mean: -270.67128657795797
reward_std: 557.7866537325249
reward_max: -17.041082689038802
reward_min: -2684.381334128643
total_envstep_count: 110063
total_train_sample_count: 91982
total_episode_count: 1018
total_duration: 35.66933662959926
[2023-05-17 11:39:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 340
envstep_count: 19859
train_sample_count: 19859
avg_envstep_per_episode: 58.40882352941176
avg_sample_per_episode: 58.40882352941176
avg_envstep_per_sec: 1700.222161566053
avg_train_sample_per_sec: 1700.222161566053
avg_episode_per_sec: 29.108995162518656
collect_time: 11.680238294099242
reward_mean: -240.42843222968838
reward_std: 497.62392758544894
reward_max: -10.896697577627936
reward_min: -2478.6214193476167
total_envstep_count: 145598
total_train_sample_count: 121841
total_episode_count: 1358
total_duration: 47.3495749236985
[2023-05-17 11:40:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 372
envstep_count: 21936
train_sample_count: 21936
avg_envstep_per_episode: 58.96774193548387
avg_sample_per_episode: 58.96774193548387
avg_envstep_per_sec: 1684.7082427409307
avg_train_sample_per_sec: 1684.7082427409307
avg_episode_per_sec: 28.569997551952326
collect_time: 13.020652148238614
reward_mean: -226.21563777109353
reward_std: 466.95689024458227
reward_max: -10.57643416758858
reward_min: -2396.2755299675364
total_envstep_count: 179902
total_train_sample_count: 151377
total_episode_count: 1730
total_duration: 60.37022707193711
[2023-05-17 11:40:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 311
envstep_count: 18188
train_sample_count: 18188
avg_envstep_per_episode: 58.48231511254019
avg_sample_per_episode: 58.48231511254019
avg_envstep_per_sec: 1679.15855891832
avg_train_sample_per_sec: 1679.15855891832
avg_episode_per_sec: 28.712244987002283
collect_time: 10.831615575194007
reward_mean: -225.17843198851654
reward_std: 461.4785626067974
reward_max: -6.79894934095949
reward_min: -2261.245358610756
total_envstep_count: 214678
total_train_sample_count: 181565
total_episode_count: 2041
total_duration: 71.20184264713112
[2023-05-17 11:40:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 304
envstep_count: 20636
train_sample_count: 20636
avg_envstep_per_episode: 67.88157894736842
avg_sample_per_episode: 67.88157894736842
avg_envstep_per_sec: 1676.9876739510048
avg_train_sample_per_sec: 1676.9876739510048
avg_episode_per_sec: 24.704606167915557
collect_time: 12.305397541403101
reward_mean: -237.18335121942337
reward_std: 473.2095333812217
reward_max: -8.472458268277117
reward_min: -2076.784035413362
total_envstep_count: 250949
total_train_sample_count: 211401
total_episode_count: 2345
total_duration: 83.50724018853421
[2023-05-17 11:41:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 275
envstep_count: 19891
train_sample_count: 19891
avg_envstep_per_episode: 72.33090909090909
avg_sample_per_episode: 72.33090909090909
avg_envstep_per_sec: 1670.6813656704458
avg_train_sample_per_sec: 1670.6813656704458
avg_episode_per_sec: 23.097751523773194
collect_time: 11.9059207870064
reward_mean: -229.57145008209486
reward_std: 440.30485948294495
reward_max: -10.445359726870773
reward_min: -1913.6287314897013
total_envstep_count: 286364
total_train_sample_count: 241292
total_episode_count: 2620
total_duration: 95.4131609755406
[2023-05-17 11:41:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 318
envstep_count: 20110
train_sample_count: 20110
avg_envstep_per_episode: 63.23899371069182
avg_sample_per_episode: 63.23899371069182
avg_envstep_per_sec: 1654.5351943673304
avg_train_sample_per_sec: 1654.5351943673304
avg_episode_per_sec: 26.163211924853858
collect_time: 12.154470976780742
reward_mean: -180.1347432622593
reward_std: 356.09957644139087
reward_max: -9.828348564094238
reward_min: -1762.1433664362878
total_envstep_count: 323068
total_train_sample_count: 271402
total_episode_count: 2938
total_duration: 107.56763195232135
[2023-05-17 11:42:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 325
envstep_count: 18688
train_sample_count: 18688
avg_envstep_per_episode: 57.50153846153846
avg_sample_per_episode: 57.50153846153846
avg_envstep_per_sec: 1650.8471608023253
avg_train_sample_per_sec: 1650.8471608023253
avg_episode_per_sec: 28.709617254963383
collect_time: 11.32024844196811
reward_mean: -156.79956397568242
reward_std: 316.68210735410514
reward_max: -2.8542706626306735
reward_min: -1541.806900123843
total_envstep_count: 357756
total_train_sample_count: 300890
total_episode_count: 3263
total_duration: 118.88788039428945
[2023-05-17 11:42:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 307
envstep_count: 19593
train_sample_count: 19593
avg_envstep_per_episode: 63.82084690553746
avg_sample_per_episode: 63.82084690553746
avg_envstep_per_sec: 1699.1346237190469
avg_train_sample_per_sec: 1699.1346237190469
avg_episode_per_sec: 26.62350479670022
collect_time: 11.531163997538382
reward_mean: -164.8528820531483
reward_std: 339.4145358414132
reward_max: -1.9174030082435825
reward_min: -1533.228311030219
total_envstep_count: 393716
total_train_sample_count: 330083
total_episode_count: 3570
total_duration: 130.41904439182784
[2023-05-17 11:42:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 178
envstep_count: 14936
train_sample_count: 14936
avg_envstep_per_episode: 83.91011235955057
avg_sample_per_episode: 83.91011235955057
avg_envstep_per_sec: 1709.3727237628882
avg_train_sample_per_sec: 1709.3727237628882
avg_episode_per_sec: 20.37147461367127
collect_time: 8.737708161810948
reward_mean: -229.68633056959908
reward_std: 379.5010339516889
reward_max: 7.222809294277505
reward_min: -1293.751131652029
total_envstep_count: 428778
total_train_sample_count: 360219
total_episode_count: 3748
total_duration: 139.1567525536388
[2023-05-17 11:43:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 204
envstep_count: 17956
train_sample_count: 17956
avg_envstep_per_episode: 88.01960784313725
avg_sample_per_episode: 88.01960784313725
avg_envstep_per_sec: 1670.5850765871046
avg_train_sample_per_sec: 1670.5850765871046
avg_episode_per_sec: 18.979692338147103
collect_time: 10.748330181832419
reward_mean: -182.6345978356847
reward_std: 303.18021644996156
reward_max: 8.718357779812953
reward_min: -1163.4255237290752
total_envstep_count: 466554
total_train_sample_count: 390175
total_episode_count: 3952
total_duration: 149.9050827354712
[2023-05-17 11:43:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 207
envstep_count: 17473
train_sample_count: 17473
avg_envstep_per_episode: 84.41062801932367
avg_sample_per_episode: 84.41062801932367
avg_envstep_per_sec: 1667.9133170594434
avg_train_sample_per_sec: 1667.9133170594434
avg_episode_per_sec: 19.759517920866752
collect_time: 10.475964081158105
reward_mean: -148.68877161500657
reward_std: 255.79012684471476
reward_max: 12.18388834907282
reward_min: -1014.407049641872
total_envstep_count: 501936
total_train_sample_count: 419648
total_episode_count: 4159
total_duration: 160.38104681662932
[2023-05-17 11:44:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 211
envstep_count: 18466
train_sample_count: 18466
avg_envstep_per_episode: 87.51658767772511
avg_sample_per_episode: 87.51658767772511
avg_envstep_per_sec: 1680.394176945284
avg_train_sample_per_sec: 1680.394176945284
avg_episode_per_sec: 19.200864904985103
collect_time: 10.989088306392816
reward_mean: -130.13634162815666
reward_std: 212.37051031115627
reward_max: 19.102096294708545
reward_min: -813.0316353256284
total_envstep_count: 540732
total_train_sample_count: 450114
total_episode_count: 4370
total_duration: 171.37013512302212
[2023-05-17 11:44:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 193
envstep_count: 20240
train_sample_count: 20240
avg_envstep_per_episode: 104.87046632124353
avg_sample_per_episode: 104.87046632124353
avg_envstep_per_sec: 1670.0537175916443
avg_train_sample_per_sec: 1670.0537175916443
avg_episode_per_sec: 15.924919342647597
collect_time: 12.119370644668697
reward_mean: -125.56824135039129
reward_std: 197.8077911323491
reward_max: 16.285589511865815
reward_min: -751.4416250997436
total_envstep_count: 577148
total_train_sample_count: 479954
total_episode_count: 4563
total_duration: 183.48950576769082
[2023-05-17 11:44:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 178
envstep_count: 14761
train_sample_count: 14761
avg_envstep_per_episode: 82.92696629213484
avg_sample_per_episode: 82.92696629213484
avg_envstep_per_sec: 1664.549811016387
avg_train_sample_per_sec: 1664.549811016387
avg_episode_per_sec: 20.07247926027484
collect_time: 8.867863191782059
reward_mean: -89.74884085569236
reward_std: 144.82479997524902
reward_max: 14.643848809561144
reward_min: -585.8106239950577
total_envstep_count: 612354
total_train_sample_count: 509515
total_episode_count: 4741
total_duration: 192.35736895947286
[2023-05-17 11:45:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 196
envstep_count: 19859
train_sample_count: 19859
avg_envstep_per_episode: 101.32142857142857
avg_sample_per_episode: 101.32142857142857
avg_envstep_per_sec: 1710.5777633908501
avg_train_sample_per_sec: 1710.5777633908501
avg_episode_per_sec: 16.88268501055474
collect_time: 11.609527742622955
reward_mean: -66.20531494254094
reward_std: 114.27581904867439
reward_max: 44.4712743909127
reward_min: -439.0922984655495
total_envstep_count: 649009
total_train_sample_count: 539374
total_episode_count: 4937
total_duration: 203.96689670209582
[2023-05-17 11:45:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 193
envstep_count: 20400
train_sample_count: 20400
avg_envstep_per_episode: 105.69948186528498
avg_sample_per_episode: 105.69948186528498
avg_envstep_per_sec: 1642.848996396964
avg_train_sample_per_sec: 1642.848996396964
avg_episode_per_sec: 15.54264001493206
collect_time: 12.417452878956333
reward_mean: -49.72508928631275
reward_std: 82.41408799574123
reward_max: 38.74497338755207
reward_min: -376.61928920676047
total_envstep_count: 685705
total_train_sample_count: 568974
total_episode_count: 5130
total_duration: 216.38434958105216
[2023-05-17 11:46:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 185
envstep_count: 19089
train_sample_count: 19089
avg_envstep_per_episode: 103.18378378378378
avg_sample_per_episode: 103.18378378378378
avg_envstep_per_sec: 1630.0598582774971
avg_train_sample_per_sec: 1630.0598582774971
avg_episode_per_sec: 15.79763600929001
collect_time: 11.710612897474553
reward_mean: -35.05105348384833
reward_std: 59.39060831415345
reward_max: 78.48201468105117
reward_min: -257.385051905286
total_envstep_count: 722713
total_train_sample_count: 598863
total_episode_count: 5315
total_duration: 228.09496247852672
[2023-05-17 11:46:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 181
envstep_count: 20181
train_sample_count: 20181
avg_envstep_per_episode: 111.49723756906077
avg_sample_per_episode: 111.49723756906077
avg_envstep_per_sec: 1675.620977273464
avg_train_sample_per_sec: 1675.620977273464
avg_episode_per_sec: 15.028363157747236
collect_time: 12.043893143924533
reward_mean: -9.783867688378958
reward_std: 34.791532225360754
reward_max: 106.1352659107969
reward_min: -153.98461201718553
total_envstep_count: 761889
total_train_sample_count: 629444
total_episode_count: 5496
total_duration: 240.13885562245125
[2023-05-17 11:46:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 137
envstep_count: 17514
train_sample_count: 17514
avg_envstep_per_episode: 127.83941605839416
avg_sample_per_episode: 127.83941605839416
avg_envstep_per_sec: 1636.5686164985352
avg_train_sample_per_sec: 1636.5686164985352
avg_episode_per_sec: 12.801752909689352
collect_time: 10.70165944980143
reward_mean: 5.423231623292204
reward_std: 27.794665154116462
reward_max: 70.45470366564551
reward_min: -76.47704643397978
total_envstep_count: 799249
total_train_sample_count: 659358
total_episode_count: 5633
total_duration: 250.84051507225269
[2023-05-17 11:47:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 109
envstep_count: 17963
train_sample_count: 17963
avg_envstep_per_episode: 164.7981651376147
avg_sample_per_episode: 164.7981651376147
avg_envstep_per_sec: 1549.100456678843
avg_train_sample_per_sec: 1549.100456678843
avg_episode_per_sec: 9.399986070143846
collect_time: 11.595761864605826
reward_mean: 40.388759180378806
reward_std: 47.8792618519533
reward_max: 177.40547182820322
reward_min: -35.336086548032384
total_envstep_count: 838409
total_train_sample_count: 689321
total_episode_count: 5742
total_duration: 262.4362769368585
[2023-05-17 11:47:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 104
envstep_count: 18867
train_sample_count: 18867
avg_envstep_per_episode: 181.41346153846155
avg_sample_per_episode: 181.41346153846155
avg_envstep_per_sec: 1628.039980496866
avg_train_sample_per_sec: 1628.039980496866
avg_episode_per_sec: 8.974196108108023
collect_time: 11.588781741245647
reward_mean: 62.41111784247484
reward_std: 64.38378882373803
reward_max: 254.39734571759092
reward_min: -31.42316194783919
total_envstep_count: 877849
total_train_sample_count: 719388
total_episode_count: 5846
total_duration: 274.0250586781042
[2023-05-17 11:48:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 81
envstep_count: 14491
train_sample_count: 14491
avg_envstep_per_episode: 178.90123456790124
avg_sample_per_episode: 178.90123456790124
avg_envstep_per_sec: 1731.3747080463763
avg_train_sample_per_sec: 1731.3747080463763
avg_episode_per_sec: 9.677824260006659
collect_time: 8.36964981217217
reward_mean: 106.36564724081663
reward_std: 89.05872063932351
reward_max: 303.13519050382484
reward_min: -15.989322343412768
total_envstep_count: 917529
total_train_sample_count: 749479
total_episode_count: 5927
total_duration: 282.39470849027634
[2023-05-17 11:48:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 93
envstep_count: 17397
train_sample_count: 17397
avg_envstep_per_episode: 187.06451612903226
avg_sample_per_episode: 187.06451612903226
avg_envstep_per_sec: 1705.3584777055803
avg_train_sample_per_sec: 1705.3584777055803
avg_episode_per_sec: 9.116418832362992
collect_time: 10.201374213946051
reward_mean: 116.388610132305
reward_std: 98.63530920837376
reward_max: 334.1548837239063
reward_min: -17.277883062202704
total_envstep_count: 956193
total_train_sample_count: 779676
total_episode_count: 6020
total_duration: 292.5960827042224
[2023-05-17 11:48:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 79
envstep_count: 14362
train_sample_count: 14362
avg_envstep_per_episode: 181.79746835443038
avg_sample_per_episode: 181.79746835443038
avg_envstep_per_sec: 1653.9724447247686
avg_train_sample_per_sec: 1653.9724447247686
avg_episode_per_sec: 9.097884913887809
collect_time: 8.683336923663155
reward_mean: 148.30706882051382
reward_std: 114.45886638387987
reward_max: 344.50954658589086
reward_min: 0.009792117697599467
total_envstep_count: 995457
total_train_sample_count: 809638
total_episode_count: 6099
total_duration: 301.27941962788555
[2023-05-17 11:49:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 79
envstep_count: 15941
train_sample_count: 15941
avg_envstep_per_episode: 201.78481012658227
avg_sample_per_episode: 201.78481012658227
avg_envstep_per_sec: 1699.1171551033865
avg_train_sample_per_sec: 1699.1171551033865
avg_episode_per_sec: 8.42044133073004
collect_time: 9.381931052912025
reward_mean: 186.2465657474251
reward_std: 130.67537187395078
reward_max: 436.4195542005399
reward_min: -20.31440850920631
total_envstep_count: 1037033
total_train_sample_count: 839979
total_episode_count: 6178
total_duration: 310.66135068079757
[2023-05-17 11:49:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 69
envstep_count: 14949
train_sample_count: 14949
avg_envstep_per_episode: 216.65217391304347
avg_sample_per_episode: 216.65217391304347
avg_envstep_per_sec: 1716.228844312259
avg_train_sample_per_sec: 1716.228844312259
avg_episode_per_sec: 7.92158607649648
collect_time: 8.710376853030041
reward_mean: 222.31080867902958
reward_std: 157.43586144085307
reward_max: 510.1663878028397
reward_min: 6.729824098145777
total_envstep_count: 1076503
total_train_sample_count: 870528
total_episode_count: 6247
total_duration: 319.3717275338276
[2023-05-17 11:50:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 56
envstep_count: 13434
train_sample_count: 13434
avg_envstep_per_episode: 239.89285714285714
avg_sample_per_episode: 239.89285714285714
avg_envstep_per_sec: 1686.9697969677316
avg_train_sample_per_sec: 1686.9697969677316
avg_episode_per_sec: 7.032180186853727
collect_time: 7.9633909416440884
reward_mean: 264.8430065362317
reward_std: 158.98135208343922
reward_max: 476.7427199451827
reward_min: 4.488035460281773
total_envstep_count: 1114279
total_train_sample_count: 900362
total_episode_count: 6303
total_duration: 327.3351184754717
[2023-05-17 11:50:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 63
envstep_count: 14656
train_sample_count: 14656
avg_envstep_per_episode: 232.63492063492063
avg_sample_per_episode: 232.63492063492063
avg_envstep_per_sec: 1691.739355936625
avg_train_sample_per_sec: 1691.739355936625
avg_episode_per_sec: 7.272078290393517
collect_time: 8.663273067786356
reward_mean: 282.3327424380345
reward_std: 157.7147878308714
reward_max: 521.8845698475028
reward_min: 0.7025636016135368
total_envstep_count: 1155015
total_train_sample_count: 931018
total_episode_count: 6366
total_duration: 335.99839154325804
[2023-05-17 11:51:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 9177
train_sample_count: 9177
avg_envstep_per_episode: 208.5681818181818
avg_sample_per_episode: 208.5681818181818
avg_envstep_per_sec: 1650.7917643632193
avg_train_sample_per_sec: 1650.7917643632193
avg_episode_per_sec: 7.914878242560929
collect_time: 5.559150583441371
reward_mean: 392.98673435853453
reward_std: 137.04154892791513
reward_max: 537.8998659667494
reward_min: 21.309349023342122
total_envstep_count: 1190999
total_train_sample_count: 961395
total_episode_count: 6410
total_duration: 341.5575421266994
[2023-05-17 11:51:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 55
envstep_count: 14688
train_sample_count: 14688
avg_envstep_per_episode: 267.05454545454546
avg_sample_per_episode: 267.05454545454546
avg_envstep_per_sec: 1680.9452006562137
avg_train_sample_per_sec: 1680.9452006562137
avg_episode_per_sec: 6.294389027511693
collect_time: 8.73794100739634
reward_mean: 359.11958340674124
reward_std: 177.68742764652885
reward_max: 609.2949663625949
reward_min: 35.3437295741818
total_envstep_count: 1230174
total_train_sample_count: 991283
total_episode_count: 6465
total_duration: 350.2954831340957
[2023-05-17 11:51:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 57
envstep_count: 14021
train_sample_count: 14021
avg_envstep_per_episode: 245.98245614035088
avg_sample_per_episode: 245.98245614035088
avg_envstep_per_sec: 1623.330319946615
avg_train_sample_per_sec: 1623.330319946615
avg_episode_per_sec: 6.599374383921051
collect_time: 8.63718235759996
reward_mean: 389.1490441588502
reward_std: 190.27300532621945
reward_max: 581.5168173350885
reward_min: 13.161939555928392
total_envstep_count: 1271502
total_train_sample_count: 1021704
total_episode_count: 6522
total_duration: 358.9326654916957
[2023-05-17 11:52:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 50
envstep_count: 13027
train_sample_count: 13027
avg_envstep_per_episode: 260.54
avg_sample_per_episode: 260.54
avg_envstep_per_sec: 1653.1672563434831
avg_train_sample_per_sec: 1653.1672563434831
avg_episode_per_sec: 6.345157197910045
collect_time: 7.8800254178838784
reward_mean: 433.1548345710533
reward_std: 154.60348787520024
reward_max: 600.6903881588748
reward_min: 16.938428726301634
total_envstep_count: 1313398
total_train_sample_count: 1052331
total_episode_count: 6572
total_duration: 366.81269090957954
[2023-05-17 11:52:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 50
envstep_count: 10548
train_sample_count: 10548
avg_envstep_per_episode: 210.96
avg_sample_per_episode: 210.96
avg_envstep_per_sec: 1682.5986751390003
avg_train_sample_per_sec: 1682.5986751390003
avg_episode_per_sec: 7.975913325459804
collect_time: 6.268874542605131
reward_mean: 427.28683175546973
reward_std: 196.6229336991201
reward_max: 657.4359681215253
reward_min: -1.0250421439135975
total_envstep_count: 1351998
total_train_sample_count: 1082479
total_episode_count: 6622
total_duration: 373.0815654521847
[2023-05-17 11:53:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 8857
train_sample_count: 8857
avg_envstep_per_episode: 227.10256410256412
avg_sample_per_episode: 227.10256410256412
avg_envstep_per_sec: 1668.9814257268936
avg_train_sample_per_sec: 1668.9814257268936
avg_episode_per_sec: 7.349020616839658
collect_time: 5.3068295808879355
reward_mean: 496.2947434297757
reward_std: 151.1945459887379
reward_max: 642.0773446773244
reward_min: 33.13608561498828
total_envstep_count: 1387221
total_train_sample_count: 1111736
total_episode_count: 6661
total_duration: 378.38839503307264
[2023-05-17 11:53:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12271
train_sample_count: 12271
avg_envstep_per_episode: 299.2926829268293
avg_sample_per_episode: 299.2926829268293
avg_envstep_per_sec: 1691.38806759261
avg_train_sample_per_sec: 1691.38806759261
avg_episode_per_sec: 5.651284391760819
collect_time: 7.2549879209361965
reward_mean: 542.052789045258
reward_std: 123.45072195213794
reward_max: 693.7309011455519
reward_min: 111.81526289537281
total_envstep_count: 1424213
total_train_sample_count: 1141207
total_episode_count: 6702
total_duration: 385.6433829540088
[2023-05-17 11:54:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 12058
train_sample_count: 12058
avg_envstep_per_episode: 274.04545454545456
avg_sample_per_episode: 274.04545454545456
avg_envstep_per_sec: 1697.7182621640757
avg_train_sample_per_sec: 1697.7182621640757
avg_episode_per_sec: 6.195024343607508
collect_time: 7.102474108177236
reward_mean: 527.9347234117819
reward_std: 168.09668524227754
reward_max: 696.9044851424238
reward_min: 24.13886559395121
total_envstep_count: 1464549
total_train_sample_count: 1171265
total_episode_count: 6746
total_duration: 392.7458570621861
[2023-05-17 11:54:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 9584
train_sample_count: 9584
avg_envstep_per_episode: 252.21052631578948
avg_sample_per_episode: 252.21052631578948
avg_envstep_per_sec: 1679.671182896658
avg_train_sample_per_sec: 1679.671182896658
avg_episode_per_sec: 6.659798095792258
collect_time: 5.705878684822122
reward_mean: 568.0895549352813
reward_std: 119.93354596102441
reward_max: 704.748455302188
reward_min: 103.71520258096068
total_envstep_count: 1500677
total_train_sample_count: 1200849
total_episode_count: 6784
total_duration: 398.4517357470082
[2023-05-17 11:54:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 11194
train_sample_count: 11194
avg_envstep_per_episode: 254.4090909090909
avg_sample_per_episode: 254.4090909090909
avg_envstep_per_sec: 1700.1785700744902
avg_train_sample_per_sec: 1700.1785700744902
avg_episode_per_sec: 6.682853053714273
collect_time: 6.58401428945758
reward_mean: 574.2938404069431
reward_std: 176.04900639837868
reward_max: 775.609545541723
reward_min: 73.51622606024137
total_envstep_count: 1538509
total_train_sample_count: 1230843
total_episode_count: 6828
total_duration: 405.03575003646574
[2023-05-17 11:55:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 8987
train_sample_count: 8987
avg_envstep_per_episode: 224.675
avg_sample_per_episode: 224.675
avg_envstep_per_sec: 1675.6730338986508
avg_train_sample_per_sec: 1675.6730338986508
avg_episode_per_sec: 7.458208674301328
collect_time: 5.363218132770619
reward_mean: 603.6624542816672
reward_std: 130.19127568553643
reward_max: 794.8890240805025
reward_min: 135.96059904958463
total_envstep_count: 1575309
total_train_sample_count: 1260630
total_episode_count: 6868
total_duration: 410.39896816923635
[2023-05-17 11:55:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12572
train_sample_count: 12572
avg_envstep_per_episode: 292.3720930232558
avg_sample_per_episode: 292.3720930232558
avg_envstep_per_sec: 1672.3153273647101
avg_train_sample_per_sec: 1672.3153273647101
avg_episode_per_sec: 5.719818571164694
collect_time: 7.517720967020839
reward_mean: 663.0888385072636
reward_std: 95.12074930149592
reward_max: 790.0434477781182
reward_min: 265.4135216883238
total_envstep_count: 1615517
total_train_sample_count: 1290802
total_episode_count: 6911
total_duration: 417.9166891362572
[2023-05-17 11:56:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 7361
train_sample_count: 7361
avg_envstep_per_episode: 204.47222222222223
avg_sample_per_episode: 204.47222222222223
avg_envstep_per_sec: 1661.3198097856598
avg_train_sample_per_sec: 1661.3198097856598
avg_episode_per_sec: 8.124916879810318
collect_time: 4.4308145587872705
reward_mean: 648.6001382364676
reward_std: 138.22811977379652
reward_max: 782.8685114698108
reward_min: 155.67339252186463
total_envstep_count: 1651837
total_train_sample_count: 1320563
total_episode_count: 6947
total_duration: 422.3475036950445
[2023-05-17 11:56:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12245
train_sample_count: 12245
avg_envstep_per_episode: 284.7674418604651
avg_sample_per_episode: 284.7674418604651
avg_envstep_per_sec: 1709.745118344731
avg_train_sample_per_sec: 1709.745118344731
avg_episode_per_sec: 6.00400490721302
collect_time: 7.161886218370869
reward_mean: 649.8435555050183
reward_std: 158.80224711842857
reward_max: 802.9995524320926
reward_min: 54.93637368697701
total_envstep_count: 1690381
total_train_sample_count: 1350408
total_episode_count: 6990
total_duration: 429.50938991341536
[2023-05-17 11:56:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 13420
train_sample_count: 13420
avg_envstep_per_episode: 305.0
avg_sample_per_episode: 305.0
avg_envstep_per_sec: 1692.0544599318212
avg_train_sample_per_sec: 1692.0544599318212
avg_episode_per_sec: 5.5477195407600695
collect_time: 7.931186801481992
reward_mean: 666.3601341465233
reward_std: 121.9856323418819
reward_max: 819.4247835216976
reward_min: 238.98689378400346
total_envstep_count: 1732261
total_train_sample_count: 1381028
total_episode_count: 7034
total_duration: 437.44057671489736
[2023-05-17 11:57:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12838
train_sample_count: 12838
avg_envstep_per_episode: 298.5581395348837
avg_sample_per_episode: 298.5581395348837
avg_envstep_per_sec: 1667.331060468567
avg_train_sample_per_sec: 1667.331060468567
avg_episode_per_sec: 5.58461096745197
collect_time: 7.699730608024635
reward_mean: 658.404384778216
reward_std: 149.81524715702483
reward_max: 829.4623774495284
reward_min: 107.36129604563544
total_envstep_count: 1772260
total_train_sample_count: 1410666
total_episode_count: 7077
total_duration: 445.140307322922
[2023-05-17 11:57:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11584
train_sample_count: 11584
avg_envstep_per_episode: 282.5365853658537
avg_sample_per_episode: 282.5365853658537
avg_envstep_per_sec: 1689.4991798861292
avg_train_sample_per_sec: 1689.4991798861292
avg_episode_per_sec: 5.979753658091445
collect_time: 6.856469738435003
reward_mean: 698.0204866293071
reward_std: 87.15602779192729
reward_max: 838.8293299541541
reward_min: 272.76937065219386
total_envstep_count: 1812204
total_train_sample_count: 1441050
total_episode_count: 7118
total_duration: 451.996777061357
[2023-05-17 11:58:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 10655
train_sample_count: 10655
avg_envstep_per_episode: 259.8780487804878
avg_sample_per_episode: 259.8780487804878
avg_envstep_per_sec: 1673.8133521446957
avg_train_sample_per_sec: 1673.8133521446957
avg_episode_per_sec: 6.440764658651574
collect_time: 6.365703790298663
reward_mean: 702.0419345232577
reward_std: 119.97430341770313
reward_max: 835.8278906375949
reward_min: 188.3906443825079
total_envstep_count: 1851788
total_train_sample_count: 1471705
total_episode_count: 7159
total_duration: 458.3624808516557
[2023-05-17 11:58:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 45
envstep_count: 13084
train_sample_count: 13084
avg_envstep_per_episode: 290.75555555555553
avg_sample_per_episode: 290.75555555555553
avg_envstep_per_sec: 1699.8688246747927
avg_train_sample_per_sec: 1699.8688246747927
avg_episode_per_sec: 5.8463846767323195
collect_time: 7.697064508788284
reward_mean: 692.6486946507792
reward_std: 154.26280076827513
reward_max: 812.6790222296702
reward_min: 81.52835535008735
total_envstep_count: 1894028
total_train_sample_count: 1501989
total_episode_count: 7204
total_duration: 466.05954536044396
[2023-05-17 11:59:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12871
train_sample_count: 12871
avg_envstep_per_episode: 313.9268292682927
avg_sample_per_episode: 313.9268292682927
avg_envstep_per_sec: 1617.0960910345643
avg_train_sample_per_sec: 1617.0960910345643
avg_episode_per_sec: 5.151187921095263
collect_time: 7.959329115541651
reward_mean: 729.8620039803443
reward_std: 96.76577864342856
reward_max: 870.1298105186255
reward_min: 411.2755098731553
total_envstep_count: 1933532
total_train_sample_count: 1532060
total_episode_count: 7245
total_duration: 474.0188744759856
[2023-05-17 11:59:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12346
train_sample_count: 12346
avg_envstep_per_episode: 301.1219512195122
avg_sample_per_episode: 301.1219512195122
avg_envstep_per_sec: 1615.480676507922
avg_train_sample_per_sec: 1615.480676507922
avg_episode_per_sec: 5.364871840014969
collect_time: 7.642307444176636
reward_mean: 727.5453496283629
reward_std: 122.64205635475321
reward_max: 859.3406992076772
reward_min: 197.0085549913844
total_envstep_count: 1973532
total_train_sample_count: 1562006
total_episode_count: 7286
total_duration: 481.6611819201623
[2023-05-17 11:59:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12721
train_sample_count: 12721
avg_envstep_per_episode: 310.2682926829268
avg_sample_per_episode: 310.2682926829268
avg_envstep_per_sec: 1637.8122406905372
avg_train_sample_per_sec: 1637.8122406905372
avg_episode_per_sec: 5.278696790213979
collect_time: 7.767068583292887
reward_mean: 754.8139441060006
reward_std: 114.41295946259915
reward_max: 911.777528569885
reward_min: 316.8721566756392
total_envstep_count: 2013884
total_train_sample_count: 1591927
total_episode_count: 7327
total_duration: 489.42825050345516
[2023-05-17 12:00:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11735
train_sample_count: 11735
avg_envstep_per_episode: 286.219512195122
avg_sample_per_episode: 286.219512195122
avg_envstep_per_sec: 1681.2876334246077
avg_train_sample_per_sec: 1681.2876334246077
avg_episode_per_sec: 5.874119554359516
collect_time: 6.979769414051436
reward_mean: 754.4710056675934
reward_std: 101.34696949175915
reward_max: 879.0914976273291
reward_min: 193.0490768764175
total_envstep_count: 2053884
total_train_sample_count: 1622062
total_episode_count: 7368
total_duration: 496.4080199175066
[2023-05-17 12:00:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 11772
train_sample_count: 11772
avg_envstep_per_episode: 280.2857142857143
avg_sample_per_episode: 280.2857142857143
avg_envstep_per_sec: 1736.208508529485
avg_train_sample_per_sec: 1736.208508529485
avg_episode_per_sec: 6.194423832674004
collect_time: 6.780291619449855
reward_mean: 769.2903188752474
reward_std: 53.09775158004934
reward_max: 874.932447472255
reward_min: 652.1253865450378
total_envstep_count: 2095460
total_train_sample_count: 1651834
total_episode_count: 7410
total_duration: 503.18831153695646
[2023-05-17 12:01:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11981
train_sample_count: 11981
avg_envstep_per_episode: 292.219512195122
avg_sample_per_episode: 292.219512195122
avg_envstep_per_sec: 1718.7632430685849
avg_train_sample_per_sec: 1718.7632430685849
avg_episode_per_sec: 5.881753857425255
collect_time: 6.970709926638753
reward_mean: 787.2980859631002
reward_std: 53.83490319448359
reward_max: 908.4426806931943
reward_min: 649.6138966086551
total_envstep_count: 2136300
total_train_sample_count: 1681815
total_episode_count: 7451
total_duration: 510.1590214635952
[2023-05-17 12:01:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11937
train_sample_count: 11937
avg_envstep_per_episode: 291.1463414634146
avg_sample_per_episode: 291.1463414634146
avg_envstep_per_sec: 1674.368725235536
avg_train_sample_per_sec: 1674.368725235536
avg_episode_per_sec: 5.750952310853394
collect_time: 7.129254040695728
reward_mean: 794.1603461248417
reward_std: 69.5952767326802
reward_max: 918.8352698383043
reward_min: 605.0014936478603
total_envstep_count: 2177284
total_train_sample_count: 1711752
total_episode_count: 7492
total_duration: 517.2882755042909
[2023-05-17 12:02:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11901
train_sample_count: 11901
avg_envstep_per_episode: 290.2682926829268
avg_sample_per_episode: 290.2682926829268
avg_envstep_per_sec: 1685.1196125742356
avg_train_sample_per_sec: 1685.1196125742356
avg_episode_per_sec: 5.80538644782318
collect_time: 7.062406674989499
reward_mean: 793.8624163170714
reward_std: 104.38878614790649
reward_max: 962.7383395985828
reward_min: 385.27107306102545
total_envstep_count: 2218660
total_train_sample_count: 1741653
total_episode_count: 7533
total_duration: 524.3506821792804
[2023-05-17 12:02:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10400
train_sample_count: 10400
avg_envstep_per_episode: 273.6842105263158
avg_sample_per_episode: 273.6842105263158
avg_envstep_per_sec: 1706.0583386889814
avg_train_sample_per_sec: 1706.0583386889814
avg_episode_per_sec: 6.233674699055893
collect_time: 6.09592284399364
reward_mean: 803.8883034641461
reward_std: 64.08600976557473
reward_max: 931.2853560989748
reward_min: 664.8460049704664
total_envstep_count: 2256364
total_train_sample_count: 1771253
total_episode_count: 7571
total_duration: 530.4466050232741
[2023-05-17 12:02:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 11961
train_sample_count: 11961
avg_envstep_per_episode: 299.025
avg_sample_per_episode: 299.025
avg_envstep_per_sec: 1696.5884803835193
avg_train_sample_per_sec: 1696.5884803835193
avg_episode_per_sec: 5.673734571970636
collect_time: 7.050030186044984
reward_mean: 789.2147754864369
reward_std: 99.48988864188058
reward_max: 948.7364937575503
reward_min: 391.8889903727911
total_envstep_count: 2295996
total_train_sample_count: 1801214
total_episode_count: 7611
total_duration: 537.496635209319
[2023-05-17 12:03:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 13171
train_sample_count: 13171
avg_envstep_per_episode: 306.30232558139534
avg_sample_per_episode: 306.30232558139534
avg_envstep_per_sec: 1691.5426529499794
avg_train_sample_per_sec: 1691.5426529499794
avg_episode_per_sec: 5.5224610186659415
collect_time: 7.786383616771548
reward_mean: 802.0926867538561
reward_std: 61.65609138706316
reward_max: 916.3826400028255
reward_min: 689.6457960531873
total_envstep_count: 2337628
total_train_sample_count: 1831185
total_episode_count: 7654
total_duration: 545.2830188260906
[2023-05-17 12:03:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 12168
train_sample_count: 12168
avg_envstep_per_episode: 304.2
avg_sample_per_episode: 304.2
avg_envstep_per_sec: 1683.744247971898
avg_train_sample_per_sec: 1683.744247971898
avg_episode_per_sec: 5.534990953227804
collect_time: 7.22675074593816
reward_mean: 835.7171555727557
reward_std: 79.89612130543854
reward_max: 989.3282592864475
reward_min: 686.3723640135119
total_envstep_count: 2378660
total_train_sample_count: 1861353
total_episode_count: 7694
total_duration: 552.5097695720287
[2023-05-17 12:04:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 13009
train_sample_count: 13009
avg_envstep_per_episode: 309.73809523809524
avg_sample_per_episode: 309.73809523809524
avg_envstep_per_sec: 1663.361860398562
avg_train_sample_per_sec: 1663.361860398562
avg_episode_per_sec: 5.3702204732677075
collect_time: 7.820907951371979
reward_mean: 856.6497189746793
reward_std: 94.71442976182473
reward_max: 970.1513534272237
reward_min: 453.32435047114757
total_envstep_count: 2420660
total_train_sample_count: 1891562
total_episode_count: 7736
total_duration: 560.3306775234007
[2023-05-17 12:04:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12887
train_sample_count: 12887
avg_envstep_per_episode: 314.3170731707317
avg_sample_per_episode: 314.3170731707317
avg_envstep_per_sec: 1673.1769007513792
avg_train_sample_per_sec: 1673.1769007513792
avg_episode_per_sec: 5.323213543168041
collect_time: 7.702114459154195
reward_mean: 846.0803020079572
reward_std: 81.62485435736377
reward_max: 1003.5466854126926
reward_min: 667.7980946855802
total_envstep_count: 2460828
total_train_sample_count: 1922049
total_episode_count: 7777
total_duration: 568.032791982555
[2023-05-17 12:05:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 13196
train_sample_count: 13196
avg_envstep_per_episode: 321.8536585365854
avg_sample_per_episode: 321.8536585365854
avg_envstep_per_sec: 1682.2241716309163
avg_train_sample_per_sec: 1682.2241716309163
avg_episode_per_sec: 5.226674070693208
collect_time: 7.844376642862335
reward_mean: 864.1631276151728
reward_std: 79.95233334804115
reward_max: 999.6236421534226
reward_min: 681.2047861106996
total_envstep_count: 2501884
total_train_sample_count: 1952445
total_episode_count: 7818
total_duration: 575.8771686254173
[2023-05-17 12:05:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 13566
train_sample_count: 13566
avg_envstep_per_episode: 315.48837209302326
avg_sample_per_episode: 315.48837209302326
avg_envstep_per_sec: 1694.2827293397556
avg_train_sample_per_sec: 1694.2827293397556
avg_episode_per_sec: 5.370349208433547
collect_time: 8.006928103012966
reward_mean: 790.8615520889659
reward_std: 130.11854754363995
reward_max: 1024.8474413321594
reward_min: 87.36857097484571
total_envstep_count: 2543460
total_train_sample_count: 1982811
total_episode_count: 7861
total_duration: 583.8840967284302
[2023-05-17 12:05:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 12506
train_sample_count: 12506
avg_envstep_per_episode: 312.65
avg_sample_per_episode: 312.65
avg_envstep_per_sec: 1705.8094125712494
avg_train_sample_per_sec: 1705.8094125712494
avg_episode_per_sec: 5.455971254026066
collect_time: 7.331416926085018
reward_mean: 854.0041123379993
reward_std: 83.3114085825017
reward_max: 1031.8037946094544
reward_min: 584.9508213108713
total_envstep_count: 2583460
total_train_sample_count: 2012517
total_episode_count: 7901
total_duration: 591.2155136545152
[2023-05-17 12:06:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 12506
train_sample_count: 12506
avg_envstep_per_episode: 312.65
avg_sample_per_episode: 312.65
avg_envstep_per_sec: 1660.7811336504801
avg_train_sample_per_sec: 1660.7811336504801
avg_episode_per_sec: 5.311949891733504
collect_time: 7.530191514465958
reward_mean: 864.1876481588013
reward_std: 96.23702870495019
reward_max: 1012.8203280315275
reward_min: 588.5568257049106
total_envstep_count: 2623460
total_train_sample_count: 2042223
total_episode_count: 7941
total_duration: 598.7457051689812
[2023-05-17 12:06:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 12506
train_sample_count: 12506
avg_envstep_per_episode: 312.65
avg_sample_per_episode: 312.65
avg_envstep_per_sec: 1652.834019363517
avg_train_sample_per_sec: 1652.834019363517
avg_episode_per_sec: 5.28653132692633
collect_time: 7.566397988840939
reward_mean: 887.1070163290957
reward_std: 75.83471246657854
reward_max: 1025.537226307034
reward_min: 658.8972997727204
total_envstep_count: 2663460
total_train_sample_count: 2071929
total_episode_count: 7981
total_duration: 606.3121031578221
[2023-05-17 12:07:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 9297
train_sample_count: 9297
avg_envstep_per_episode: 238.3846153846154
avg_sample_per_episode: 238.3846153846154
avg_envstep_per_sec: 1668.5465301907989
avg_train_sample_per_sec: 1668.5465301907989
avg_episode_per_sec: 6.9993884777284245
collect_time: 5.57191533576045
reward_mean: 792.9883104383009
reward_std: 193.34071733269482
reward_max: 1160.512105890365
reward_min: 142.02872540145628
total_envstep_count: 2701884
total_train_sample_count: 2102026
total_episode_count: 8020
total_duration: 611.8840184935825
[2023-05-17 12:07:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 11291
train_sample_count: 11291
avg_envstep_per_episode: 268.8333333333333
avg_sample_per_episode: 268.8333333333333
avg_envstep_per_sec: 1618.2308805740033
avg_train_sample_per_sec: 1618.2308805740033
avg_episode_per_sec: 6.019457708272796
collect_time: 6.977372719518839
reward_mean: 845.227741304687
reward_std: 143.86727457147464
reward_max: 1029.252952440453
reward_min: 262.1161757223667
total_envstep_count: 2740660
total_train_sample_count: 2131717
total_episode_count: 8062
total_duration: 618.8613912131013
[2023-05-17 12:07:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 13873
train_sample_count: 13873
avg_envstep_per_episode: 315.29545454545456
avg_sample_per_episode: 315.29545454545456
avg_envstep_per_sec: 1715.1780029310173
avg_train_sample_per_sec: 1715.1780029310173
avg_episode_per_sec: 5.439907167084607
collect_time: 8.088373321190476
reward_mean: 776.9448690189544
reward_std: 201.4738952445643
reward_max: 1087.211661687949
reward_min: 100.61956286088119
total_envstep_count: 2781876
total_train_sample_count: 2162390
total_episode_count: 8106
total_duration: 626.9497645342918
[2023-05-17 12:08:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 13728
train_sample_count: 13728
avg_envstep_per_episode: 334.8292682926829
avg_sample_per_episode: 334.8292682926829
avg_envstep_per_sec: 1673.9552066133417
avg_train_sample_per_sec: 1673.9552066133417
avg_episode_per_sec: 4.999429157280522
collect_time: 8.20093628895469
reward_mean: 848.042455526965
reward_std: 124.580034925364
reward_max: 1068.9521025985277
reward_min: 576.3124584033397
total_envstep_count: 2824876
total_train_sample_count: 2192918
total_episode_count: 8147
total_duration: 635.1507008232466
[2023-05-17 12:08:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 12204
train_sample_count: 12204
avg_envstep_per_episode: 312.9230769230769
avg_sample_per_episode: 312.9230769230769
avg_envstep_per_sec: 1669.1854111179314
avg_train_sample_per_sec: 1669.1854111179314
avg_episode_per_sec: 5.334171667781
collect_time: 7.311350745527072
reward_mean: 813.0266288337386
reward_std: 107.67959007887879
reward_max: 1023.3641487576124
reward_min: 592.4415437307798
total_envstep_count: 2861676
total_train_sample_count: 2222722
total_episode_count: 8186
total_duration: 642.4620515687736
[2023-05-17 12:09:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 12561
train_sample_count: 12561
avg_envstep_per_episode: 322.0769230769231
avg_sample_per_episode: 322.0769230769231
avg_envstep_per_sec: 1664.537943487525
avg_train_sample_per_sec: 1664.537943487525
avg_episode_per_sec: 5.168137870871226
collect_time: 7.546238311445341
reward_mean: 828.4439307725869
reward_std: 146.74692940833555
reward_max: 1035.5548911702376
reward_min: 388.1513404630012
total_envstep_count: 2900244
total_train_sample_count: 2252883
total_episode_count: 8225
total_duration: 650.008289880219
[2023-05-17 12:09:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 13768
train_sample_count: 13768
avg_envstep_per_episode: 320.1860465116279
avg_sample_per_episode: 320.1860465116279
avg_envstep_per_sec: 1663.8352625821913
avg_train_sample_per_sec: 1663.8352625821913
avg_episode_per_sec: 5.196463995571921
collect_time: 8.274857679499313
reward_mean: 826.4283921028779
reward_std: 156.68154896236248
reward_max: 1063.7038762517834
reward_min: 255.4737079021518
total_envstep_count: 2941876
total_train_sample_count: 2282651
total_episode_count: 8268
total_duration: 658.2831475597183
[2023-05-17 12:10:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 14162
train_sample_count: 14162
avg_envstep_per_episode: 321.8636363636364
avg_sample_per_episode: 321.8636363636364
avg_envstep_per_sec: 1715.9159956482754
avg_train_sample_per_sec: 1715.9159956482754
avg_episode_per_sec: 5.331189366510671
collect_time: 8.253317782406695
reward_mean: 860.5384765359704
reward_std: 160.33714490785164
reward_max: 1087.6888767894252
reward_min: 324.4625218942939
total_envstep_count: 2985092
total_train_sample_count: 2312813
total_episode_count: 8312
total_duration: 666.536465342125
[2023-05-17 12:10:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 10603
train_sample_count: 10603
avg_envstep_per_episode: 271.87179487179486
avg_sample_per_episode: 271.87179487179486
avg_envstep_per_sec: 1687.2025889807799
avg_train_sample_per_sec: 1687.2025889807799
avg_episode_per_sec: 6.20587578706502
collect_time: 6.284366838486867
reward_mean: 851.4038137475343
reward_std: 111.83518870353221
reward_max: 1079.5871696333743
reward_min: 649.0676589243933
total_envstep_count: 3023228
total_train_sample_count: 2343016
total_episode_count: 8351
total_duration: 672.8208321806119
[2023-05-17 12:10:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10751
train_sample_count: 10751
avg_envstep_per_episode: 298.6388888888889
avg_sample_per_episode: 298.6388888888889
avg_envstep_per_sec: 1704.8599165756152
avg_train_sample_per_sec: 1704.8599165756152
avg_episode_per_sec: 5.708767277157673
collect_time: 6.306089958167636
reward_mean: 851.3112504668861
reward_std: 101.65440845799013
reward_max: 1036.7280380721002
reward_min: 586.6127767133758
total_envstep_count: 3059500
total_train_sample_count: 2372967
total_episode_count: 8387
total_duration: 679.1269221387795
[2023-05-17 12:11:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12131
train_sample_count: 12131
avg_envstep_per_episode: 282.1162790697674
avg_sample_per_episode: 282.1162790697674
avg_envstep_per_sec: 1679.3924121569896
avg_train_sample_per_sec: 1679.3924121569896
avg_episode_per_sec: 5.952837665711859
collect_time: 7.2234457606123765
reward_mean: 851.6866689885096
reward_std: 143.23942249295615
reward_max: 1089.5071479283215
reward_min: 427.1967788885382
total_envstep_count: 3102356
total_train_sample_count: 2403098
total_episode_count: 8430
total_duration: 686.3503678993918
[2023-05-17 12:11:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12304
train_sample_count: 12304
avg_envstep_per_episode: 286.13953488372096
avg_sample_per_episode: 286.13953488372096
avg_envstep_per_sec: 1688.8188466979036
avg_train_sample_per_sec: 1688.8188466979036
avg_episode_per_sec: 5.9020814700918285
collect_time: 7.285565307408571
reward_mean: 858.075403080055
reward_std: 128.34777518837825
reward_max: 1086.0953366894516
reward_min: 595.379924102687
total_envstep_count: 3145092
total_train_sample_count: 2433402
total_episode_count: 8473
total_duration: 693.6359332068004
[2023-05-17 12:12:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 12220
train_sample_count: 12220
avg_envstep_per_episode: 277.72727272727275
avg_sample_per_episode: 277.72727272727275
avg_envstep_per_sec: 1655.4018142705077
avg_train_sample_per_sec: 1655.4018142705077
avg_episode_per_sec: 5.960530264149127
collect_time: 7.381893564847297
reward_mean: 890.8477343805909
reward_std: 147.2232389919337
reward_max: 1126.5562980883828
reward_min: 575.6339916774193
total_envstep_count: 3187932
total_train_sample_count: 2463622
total_episode_count: 8517
total_duration: 701.0178267716476
[2023-05-17 12:12:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12357
train_sample_count: 12357
avg_envstep_per_episode: 287.3720930232558
avg_sample_per_episode: 287.3720930232558
avg_envstep_per_sec: 1689.2950724534555
avg_train_sample_per_sec: 1689.2950724534555
avg_episode_per_sec: 5.878424222343496
collect_time: 7.314885481820091
reward_mean: 902.0032298845101
reward_std: 129.17300972532757
reward_max: 1093.4729256366738
reward_min: 642.4691334558975
total_envstep_count: 3231180
total_train_sample_count: 2493979
total_episode_count: 8560
total_duration: 708.3327122534677
[2023-05-17 12:13:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 11402
train_sample_count: 11402
avg_envstep_per_episode: 300.05263157894734
avg_sample_per_episode: 300.05263157894734
avg_envstep_per_sec: 1717.1046105063556
avg_train_sample_per_sec: 1717.1046105063556
avg_episode_per_sec: 5.7226780564147965
collect_time: 6.640247734608129
reward_mean: 845.4175670222606
reward_std: 124.17491736013449
reward_max: 1050.1268618174006
reward_min: 612.769896414552
total_envstep_count: 3268412
total_train_sample_count: 2524181
total_episode_count: 8598
total_duration: 714.9729599880758
[2023-05-17 12:13:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 8734
train_sample_count: 8734
avg_envstep_per_episode: 256.88235294117646
avg_sample_per_episode: 256.88235294117646
avg_envstep_per_sec: 1657.6393059297347
avg_train_sample_per_sec: 1657.6393059297347
avg_episode_per_sec: 6.452912342753719
collect_time: 5.268938766567969
reward_mean: 863.5906565590001
reward_std: 162.09979273710027
reward_max: 1162.2184208076537
reward_min: 214.30218344849632
total_envstep_count: 3304340
total_train_sample_count: 2554515
total_episode_count: 8632
total_duration: 720.2418987546438
[2023-05-17 12:13:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 9929
train_sample_count: 9929
avg_envstep_per_episode: 254.5897435897436
avg_sample_per_episode: 254.5897435897436
avg_envstep_per_sec: 1678.589739741948
avg_train_sample_per_sec: 1678.589739741948
avg_episode_per_sec: 6.593312503770367
collect_time: 5.915084409801289
reward_mean: 913.844244674395
reward_std: 118.96274965540663
reward_max: 1112.7409304050384
reward_min: 699.4958321099771
total_envstep_count: 3340412
total_train_sample_count: 2585244
total_episode_count: 8671
total_duration: 726.156983164445
[2023-05-17 12:14:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 11927
train_sample_count: 11927
avg_envstep_per_episode: 361.42424242424244
avg_sample_per_episode: 361.42424242424244
avg_envstep_per_sec: 1665.3365174818798
avg_train_sample_per_sec: 1665.3365174818798
avg_episode_per_sec: 4.607705632338562
collect_time: 7.161915849917568
reward_mean: 940.4311339922485
reward_std: 129.91766054637247
reward_max: 1145.50268731005
reward_min: 719.5908295972954
total_envstep_count: 3375180
total_train_sample_count: 2614771
total_episode_count: 8704
total_duration: 733.3188990143626
[2023-05-17 12:14:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 16825
train_sample_count: 16825
avg_envstep_per_episode: 420.625
avg_sample_per_episode: 420.625
avg_envstep_per_sec: 1703.6049823084797
avg_train_sample_per_sec: 1703.6049823084797
avg_episode_per_sec: 4.0501752922638445
collect_time: 9.876115751435046
reward_mean: 961.2910980897043
reward_std: 119.84871327474197
reward_max: 1165.5544035504754
reward_min: 660.3284860762296
total_envstep_count: 3411980
total_train_sample_count: 2644396
total_episode_count: 8744
total_duration: 743.1950147657976
[2023-05-17 12:15:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 11768
train_sample_count: 11768
avg_envstep_per_episode: 356.6060606060606
avg_sample_per_episode: 356.6060606060606
avg_envstep_per_sec: 1642.0701991238054
avg_train_sample_per_sec: 1642.0701991238054
avg_episode_per_sec: 4.604717587617741
collect_time: 7.166563284736124
reward_mean: 936.5488985023763
reward_std: 210.04102209866323
reward_max: 1225.5784670813464
reward_min: 253.9967612136642
total_envstep_count: 3447180
total_train_sample_count: 2673764
total_episode_count: 8777
total_duration: 750.3615780505337
[2023-05-17 12:15:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 13961
train_sample_count: 13961
avg_envstep_per_episode: 357.97435897435895
avg_sample_per_episode: 357.97435897435895
avg_envstep_per_sec: 1659.5793340684445
avg_train_sample_per_sec: 1659.5793340684445
avg_episode_per_sec: 4.636028510040064
collect_time: 8.412372770257827
reward_mean: 904.3142339424967
reward_std: 164.84172216643552
reward_max: 1201.7862089734756
reward_min: 437.92851774477475
total_envstep_count: 3483915
total_train_sample_count: 2703325
total_episode_count: 8816
total_duration: 758.7739508207915
[2023-05-17 12:15:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 13350
train_sample_count: 13350
avg_envstep_per_episode: 392.6470588235294
avg_sample_per_episode: 392.6470588235294
avg_envstep_per_sec: 1696.65442540319
avg_train_sample_per_sec: 1696.65442540319
avg_episode_per_sec: 4.321067450465053
collect_time: 7.8684261214993905
reward_mean: 881.2207549596809
reward_std: 146.1628260211297
reward_max: 1170.5371690207571
reward_min: 584.6104519769295
total_envstep_count: 3519427
total_train_sample_count: 2734275
total_episode_count: 8850
total_duration: 766.6423769422909
[2023-05-17 12:16:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 16635
train_sample_count: 16635
avg_envstep_per_episode: 415.875
avg_sample_per_episode: 415.875
avg_envstep_per_sec: 1714.8322283323564
avg_train_sample_per_sec: 1714.8322283323564
avg_episode_per_sec: 4.123431868547897
collect_time: 9.700657431763595
reward_mean: 932.1868138994644
reward_std: 165.02616093003132
reward_max: 1201.1704628027728
reward_min: 651.2468536809598
total_envstep_count: 3556227
total_train_sample_count: 2765710
total_episode_count: 8890
total_duration: 776.3430343740545
[2023-05-17 12:16:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 12922
train_sample_count: 12922
avg_envstep_per_episode: 403.8125
avg_sample_per_episode: 403.8125
avg_envstep_per_sec: 1732.3325189531238
avg_train_sample_per_sec: 1732.3325189531238
avg_episode_per_sec: 4.289942780258471
collect_time: 7.459306950959375
reward_mean: 934.2464779282575
reward_std: 161.8724364031442
reward_max: 1250.2274578575607
reward_min: 641.6064432535264
total_envstep_count: 3591427
total_train_sample_count: 2796232
total_episode_count: 8922
total_duration: 783.8023413250138
[2023-05-17 12:17:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10922
train_sample_count: 10922
avg_envstep_per_episode: 287.42105263157896
avg_sample_per_episode: 287.42105263157896
avg_envstep_per_sec: 1713.102463207083
avg_train_sample_per_sec: 1713.102463207083
avg_episode_per_sec: 5.960253946334843
collect_time: 6.375567273164167
reward_mean: 896.3232595203102
reward_std: 249.85334813551475
reward_max: 1241.8651467661284
reward_min: 144.64911010384776
total_envstep_count: 3626731
total_train_sample_count: 2825954
total_episode_count: 8960
total_duration: 790.177908598178
[2023-05-17 12:17:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 7550
train_sample_count: 7550
avg_envstep_per_episode: 193.5897435897436
avg_sample_per_episode: 193.5897435897436
avg_envstep_per_sec: 1687.3185527842559
avg_train_sample_per_sec: 1687.3185527842559
avg_episode_per_sec: 8.715950140210063
collect_time: 4.474555197382079
reward_mean: 927.1859523257319
reward_std: 196.9270027110341
reward_max: 1272.4379386967646
reward_min: 576.7516701360266
total_envstep_count: 3663514
total_train_sample_count: 2855904
total_episode_count: 8999
total_duration: 794.65246379556
[2023-05-17 12:17:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 7566
train_sample_count: 7566
avg_envstep_per_episode: 184.53658536585365
avg_sample_per_episode: 184.53658536585365
avg_envstep_per_sec: 1664.0582367201098
avg_train_sample_per_sec: 1664.0582367201098
avg_episode_per_sec: 9.017497714185104
collect_time: 4.54671587390639
reward_mean: 841.3064439765672
reward_std: 254.3764936395819
reward_max: 1356.0499443516878
reward_min: 226.73843051597197
total_envstep_count: 3699842
total_train_sample_count: 2885870
total_episode_count: 9040
total_duration: 799.1991796694664
[2023-05-17 12:18:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 11008
train_sample_count: 11008
avg_envstep_per_episode: 282.2564102564103
avg_sample_per_episode: 282.2564102564103
avg_envstep_per_sec: 1668.112670980737
avg_train_sample_per_sec: 1668.112670980737
avg_episode_per_sec: 5.90991952836562
collect_time: 6.599074625773356
reward_mean: 825.052056982879
reward_std: 257.27624770924524
reward_max: 1316.5653450777993
reward_min: 176.063121115441
total_envstep_count: 3736538
total_train_sample_count: 2916478
total_episode_count: 9079
total_duration: 805.7982542952398
[2023-05-17 12:18:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 12198
train_sample_count: 12198
avg_envstep_per_episode: 312.7692307692308
avg_sample_per_episode: 312.7692307692308
avg_envstep_per_sec: 1684.1041733561067
avg_train_sample_per_sec: 1684.1041733561067
avg_episode_per_sec: 5.384494405713081
collect_time: 7.243019875481724
reward_mean: 902.4608777915535
reward_std: 194.63120156105575
reward_max: 1228.3570735259545
reward_min: 51.64327797893462
total_envstep_count: 3772650
total_train_sample_count: 2945876
total_episode_count: 9118
total_duration: 813.0412741707215
[2023-05-17 12:19:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10004
train_sample_count: 10004
avg_envstep_per_episode: 277.8888888888889
avg_sample_per_episode: 277.8888888888889
avg_envstep_per_sec: 1722.581260655739
avg_train_sample_per_sec: 1722.581260655739
avg_episode_per_sec: 6.198813013155399
collect_time: 5.8075634679734955
reward_mean: 882.4846372514284
reward_std: 233.84898821560878
reward_max: 1163.438067034231
reward_min: 126.57577204471873
total_envstep_count: 3809266
total_train_sample_count: 2975480
total_episode_count: 9154
total_duration: 818.848837638695
[2023-05-17 12:19:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 7246
train_sample_count: 7246
avg_envstep_per_episode: 176.73170731707316
avg_sample_per_episode: 176.73170731707316
avg_envstep_per_sec: 1655.7700076512772
avg_train_sample_per_sec: 1655.7700076512772
avg_episode_per_sec: 9.368833882652824
collect_time: 4.376211651688575
reward_mean: 875.0132974533218
reward_std: 230.7320711943574
reward_max: 1157.9320537886063
reward_min: 186.38950660045913
total_envstep_count: 3845352
total_train_sample_count: 3005126
total_episode_count: 9195
total_duration: 823.2250492903836
[2023-05-17 12:19:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 7936
train_sample_count: 7936
avg_envstep_per_episode: 226.74285714285713
avg_sample_per_episode: 226.74285714285713
avg_envstep_per_sec: 1666.5977792844913
avg_train_sample_per_sec: 1666.5977792844913
avg_episode_per_sec: 7.350166617308115
collect_time: 4.761796816630289
reward_mean: 884.9325290788238
reward_std: 141.2872738621323
reward_max: 1150.15664907629
reward_min: 476.46339088697937
total_envstep_count: 3881216
total_train_sample_count: 3034662
total_episode_count: 9230
total_duration: 827.9868461070139
[2023-05-17 12:20:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 8151
train_sample_count: 8151
avg_envstep_per_episode: 214.5
avg_sample_per_episode: 214.5
avg_envstep_per_sec: 1678.246361374067
avg_train_sample_per_sec: 1678.246361374067
avg_episode_per_sec: 7.823992360718261
collect_time: 4.856855457935482
reward_mean: 937.9780492513013
reward_std: 190.30195572512315
reward_max: 1196.2182890741467
reward_min: 87.62454256068612
total_envstep_count: 3917320
total_train_sample_count: 3064013
total_episode_count: 9268
total_duration: 832.8437015649494
[2023-05-17 12:20:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 7602
train_sample_count: 7602
avg_envstep_per_episode: 217.2
avg_sample_per_episode: 217.2
avg_envstep_per_sec: 1692.867425521691
avg_train_sample_per_sec: 1692.867425521691
avg_episode_per_sec: 7.794048920449774
collect_time: 4.4906056347899135
reward_mean: 964.6789740820243
reward_std: 128.02847473432806
reward_max: 1149.7731259929553
reward_min: 712.1491317447062
total_envstep_count: 3953216
total_train_sample_count: 3093615
total_episode_count: 9303
total_duration: 837.3343071997392
[2023-05-17 12:21:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 8393
train_sample_count: 8393
avg_envstep_per_episode: 226.83783783783784
avg_sample_per_episode: 226.83783783783784
avg_envstep_per_sec: 1697.6867985447475
avg_train_sample_per_sec: 1697.6867985447475
avg_episode_per_sec: 7.484142922215614
collect_time: 4.943785866270773
reward_mean: 944.3827900702041
reward_std: 115.34366352742826
reward_max: 1116.9687728784354
reward_min: 707.7653738378682
total_envstep_count: 3989319
total_train_sample_count: 3123208
total_episode_count: 9340
total_duration: 842.27809306601
[2023-05-17 12:21:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 8088
train_sample_count: 8088
avg_envstep_per_episode: 224.66666666666666
avg_sample_per_episode: 224.66666666666666
avg_envstep_per_sec: 1661.627659777531
avg_train_sample_per_sec: 1661.627659777531
avg_episode_per_sec: 7.395968812066162
collect_time: 4.867516469413413
reward_mean: 925.7157469335561
reward_std: 120.82698227574737
reward_max: 1151.2313679869505
reward_min: 715.2216182458635
total_envstep_count: 4025215
total_train_sample_count: 3152896
total_episode_count: 9376
total_duration: 847.1456095354234
[2023-05-17 12:21:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11510
train_sample_count: 11510
avg_envstep_per_episode: 311.0810810810811
avg_sample_per_episode: 311.0810810810811
avg_envstep_per_sec: 1667.3033561016373
avg_train_sample_per_sec: 1667.3033561016373
avg_episode_per_sec: 5.359706705105176
collect_time: 6.903362821095624
reward_mean: 939.7464537136194
reward_std: 150.2451238630997
reward_max: 1151.9226065310156
reward_min: 666.2701910129351
total_envstep_count: 4061247
total_train_sample_count: 3182806
total_episode_count: 9413
total_duration: 854.048972356519
[2023-05-17 12:22:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 9696
train_sample_count: 9696
avg_envstep_per_episode: 277.0285714285714
avg_sample_per_episode: 277.0285714285714
avg_envstep_per_sec: 1676.5868484791442
avg_train_sample_per_sec: 1676.5868484791442
avg_episode_per_sec: 6.052035859815392
collect_time: 5.783177894300781
reward_mean: 984.0027311603412
reward_std: 122.2067294698595
reward_max: 1181.9046808428402
reward_min: 720.979368902895
total_envstep_count: 4097215
total_train_sample_count: 3212902
total_episode_count: 9448
total_duration: 859.8321502508198
[2023-05-17 12:22:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 10770
train_sample_count: 10770
avg_envstep_per_episode: 291.0810810810811
avg_sample_per_episode: 291.0810810810811
avg_envstep_per_sec: 1650.409361834354
avg_train_sample_per_sec: 1650.409361834354
avg_episode_per_sec: 5.669930026728978
collect_time: 6.525653725103474
reward_mean: 973.0282752903793
reward_std: 148.7056521580815
reward_max: 1206.3381439552245
reward_min: 648.784346250771
total_envstep_count: 4133247
total_train_sample_count: 3242872
total_episode_count: 9485
total_duration: 866.3578039759233
[2023-05-17 12:23:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10848
train_sample_count: 10848
avg_envstep_per_episode: 301.3333333333333
avg_sample_per_episode: 301.3333333333333
avg_envstep_per_sec: 1648.4989878342587
avg_train_sample_per_sec: 1648.4989878342587
avg_episode_per_sec: 5.470682481750859
collect_time: 6.580531792895869
reward_mean: 962.4795880008019
reward_std: 190.33255801945518
reward_max: 1260.7253231414973
reward_min: 494.72161869931546
total_envstep_count: 4169863
total_train_sample_count: 3272920
total_episode_count: 9521
total_duration: 872.9383357688191
[2023-05-17 12:23:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12684
train_sample_count: 12684
avg_envstep_per_episode: 309.3658536585366
avg_sample_per_episode: 309.3658536585366
avg_envstep_per_sec: 1630.5835340175313
avg_train_sample_per_sec: 1630.5835340175313
avg_episode_per_sec: 5.27072886271829
collect_time: 7.778810306484812
reward_mean: 1019.8528599459692
reward_std: 172.6290676609788
reward_max: 1304.5277251604416
reward_min: 683.8228517794681
total_envstep_count: 4210079
total_train_sample_count: 3303604
total_episode_count: 9562
total_duration: 880.717146075304
[2023-05-17 12:23:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 9925
train_sample_count: 9925
avg_envstep_per_episode: 230.8139534883721
avg_sample_per_episode: 230.8139534883721
avg_envstep_per_sec: 1707.9970831235194
avg_train_sample_per_sec: 1707.9970831235194
avg_episode_per_sec: 7.39988660698351
collect_time: 5.810899853440933
reward_mean: 942.0254348606467
reward_std: 300.15426847877984
reward_max: 1333.1989457434704
reward_min: 261.12890476061915
total_envstep_count: 4249167
total_train_sample_count: 3333929
total_episode_count: 9605
total_duration: 886.5280459287449
[2023-05-17 12:24:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 46
envstep_count: 15086
train_sample_count: 15086
avg_envstep_per_episode: 327.95652173913044
avg_sample_per_episode: 327.95652173913044
avg_envstep_per_sec: 1651.4954423648287
avg_train_sample_per_sec: 1651.4954423648287
avg_episode_per_sec: 5.035714592919404
collect_time: 9.134751215781666
reward_mean: 990.8020209039438
reward_std: 286.36226738918083
reward_max: 1416.7218244265928
reward_min: 167.73711632175664
total_envstep_count: 4292335
total_train_sample_count: 3364615
total_episode_count: 9651
total_duration: 895.6627971445265
[2023-05-17 12:24:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 13515
train_sample_count: 13515
avg_envstep_per_episode: 329.6341463414634
avg_sample_per_episode: 329.6341463414634
avg_envstep_per_sec: 1658.02119796701
avg_train_sample_per_sec: 1658.02119796701
avg_episode_per_sec: 5.029883027498884
collect_time: 8.151282997208646
reward_mean: 1025.2313077274137
reward_std: 252.50518716529461
reward_max: 1399.4379268778916
reward_min: 431.0771554856043
total_envstep_count: 4332807
total_train_sample_count: 3394930
total_episode_count: 9692
total_duration: 903.8140801417352
[2023-05-17 12:25:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10999
train_sample_count: 10999
avg_envstep_per_episode: 305.52777777777777
avg_sample_per_episode: 305.52777777777777
avg_envstep_per_sec: 1693.5594461815722
avg_train_sample_per_sec: 1693.5594461815722
avg_episode_per_sec: 5.543062102239895
collect_time: 6.494605208455588
reward_mean: 969.0910944794068
reward_std: 207.33274253224195
reward_max: 1295.5726866565285
reward_min: 599.00143066905
total_envstep_count: 4368871
total_train_sample_count: 3424329
total_episode_count: 9728
total_duration: 910.3086853501908
[2023-05-17 12:25:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 11903
train_sample_count: 11903
avg_envstep_per_episode: 313.2368421052632
avg_sample_per_episode: 313.2368421052632
avg_envstep_per_sec: 1671.2776579373508
avg_train_sample_per_sec: 1671.2776579373508
avg_episode_per_sec: 5.335507939311042
collect_time: 7.122096046380698
reward_mean: 985.2367360034651
reward_std: 245.8915274407269
reward_max: 1334.5088701768898
reward_min: 100.69895548096969
total_envstep_count: 4405047
total_train_sample_count: 3453832
total_episode_count: 9766
total_duration: 917.4307813965714
[2023-05-17 12:25:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 11199
train_sample_count: 11199
avg_envstep_per_episode: 319.9714285714286
avg_sample_per_episode: 319.9714285714286
avg_envstep_per_sec: 1715.9097716617227
avg_train_sample_per_sec: 1715.9097716617227
avg_episode_per_sec: 5.362696848661514
collect_time: 6.526566947138867
reward_mean: 997.2612126315884
reward_std: 202.85846531018905
reward_max: 1332.9400016259065
reward_min: 626.653885135169
total_envstep_count: 4440871
total_train_sample_count: 3483431
total_episode_count: 9801
total_duration: 923.9573483437104
[2023-05-17 12:26:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11967
train_sample_count: 11967
avg_envstep_per_episode: 323.43243243243245
avg_sample_per_episode: 323.43243243243245
avg_envstep_per_sec: 1707.0867785542005
avg_train_sample_per_sec: 1707.0867785542005
avg_episode_per_sec: 5.278032155636786
collect_time: 7.010188439357094
reward_mean: 1026.3385593844778
reward_std: 168.28019952824104
reward_max: 1297.2440336776535
reward_min: 635.170939104882
total_envstep_count: 4477047
total_train_sample_count: 3512998
total_episode_count: 9838
total_duration: 930.9675367830674
[2023-05-17 12:26:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10815
train_sample_count: 10815
avg_envstep_per_episode: 300.4166666666667
avg_sample_per_episode: 300.4166666666667
avg_envstep_per_sec: 1659.1586565226617
avg_train_sample_per_sec: 1659.1586565226617
avg_episode_per_sec: 5.522858218660732
collect_time: 6.518363965665922
reward_mean: 1066.695623010011
reward_std: 177.5225422422869
reward_max: 1310.7745089569444
reward_min: 595.0835976168349
total_envstep_count: 4512871
total_train_sample_count: 3543413
total_episode_count: 9874
total_duration: 937.4859007487333
[2023-05-17 12:27:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10483
train_sample_count: 10483
avg_envstep_per_episode: 291.19444444444446
avg_sample_per_episode: 291.19444444444446
avg_envstep_per_sec: 1713.9723677133159
avg_train_sample_per_sec: 1713.9723677133159
avg_episode_per_sec: 5.88600641397304
collect_time: 6.1162012862470005
reward_mean: 991.8970778045319
reward_std: 280.8443526289421
reward_max: 1378.159229620785
reward_min: 18.57783687564499
total_envstep_count: 4548807
total_train_sample_count: 3573896
total_episode_count: 9910
total_duration: 943.6021020349804
[2023-05-17 12:27:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 12546
train_sample_count: 12546
avg_envstep_per_episode: 313.65
avg_sample_per_episode: 313.65
avg_envstep_per_sec: 1681.941002576825
avg_train_sample_per_sec: 1681.941002576825
avg_episode_per_sec: 5.362477291811972
collect_time: 7.459239046303554
reward_mean: 977.8269110723846
reward_std: 314.33700730079187
reward_max: 1513.383910052479
reward_min: 190.16691829137832
total_envstep_count: 4586743
total_train_sample_count: 3604442
total_episode_count: 9950
total_duration: 951.0613410812839
[2023-05-17 12:27:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 8286
train_sample_count: 8286
avg_envstep_per_episode: 212.46153846153845
avg_sample_per_episode: 212.46153846153845
avg_envstep_per_sec: 1641.68481826582
avg_train_sample_per_sec: 1641.68481826582
avg_episode_per_sec: 7.726974162728334
collect_time: 5.047253838134927
reward_mean: 940.6024712870828
reward_std: 261.949271082656
reward_max: 1299.158435537925
reward_min: 110.09878615002718
total_envstep_count: 4624151
total_train_sample_count: 3634328
total_episode_count: 9989
total_duration: 956.1085949194188
[2023-05-17 12:28:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 7058
train_sample_count: 7058
avg_envstep_per_episode: 207.58823529411765
avg_sample_per_episode: 207.58823529411765
avg_envstep_per_sec: 1681.0315333768947
avg_train_sample_per_sec: 1681.0315333768947
avg_episode_per_sec: 8.097913308984758
collect_time: 4.198612494687549
reward_mean: 1080.761363103878
reward_std: 215.26696621186923
reward_max: 1419.6632930791336
reward_min: 668.8758642698197
total_envstep_count: 4659863
total_train_sample_count: 3663786
total_episode_count: 10023
total_duration: 960.3072074141063
[2023-05-17 12:28:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 8566
train_sample_count: 8566
avg_envstep_per_episode: 225.42105263157896
avg_sample_per_episode: 225.42105263157896
avg_envstep_per_sec: 1685.4020604805505
avg_train_sample_per_sec: 1685.4020604805505
avg_episode_per_sec: 7.47668436823032
collect_time: 5.0824667898872855
reward_mean: 1059.3608524642132
reward_std: 282.5009815179483
reward_max: 1474.7902620381203
reward_min: 359.5870127142705
total_envstep_count: 4696151
total_train_sample_count: 3693152
total_episode_count: 10061
total_duration: 965.3896742039935
[2023-05-17 12:29:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 7295
train_sample_count: 7295
avg_envstep_per_episode: 197.16216216216216
avg_sample_per_episode: 197.16216216216216
avg_envstep_per_sec: 1644.4381041948432
avg_train_sample_per_sec: 1644.4381041948432
avg_episode_per_sec: 8.340535963702425
collect_time: 4.436165752539412
reward_mean: 1040.3318952009597
reward_std: 317.0936141204986
reward_max: 1493.1334744669878
reward_min: 275.5305125762846
total_envstep_count: 4732911
total_train_sample_count: 3723247
total_episode_count: 10098
total_duration: 969.825839956533
[2023-05-17 12:29:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 12622
train_sample_count: 12622
avg_envstep_per_episode: 315.55
avg_sample_per_episode: 315.55
avg_envstep_per_sec: 1688.5461621244892
avg_train_sample_per_sec: 1688.5461621244892
avg_episode_per_sec: 5.351120779985705
collect_time: 7.475069549842389
reward_mean: 915.6172169047506
reward_std: 313.62307876868323
reward_max: 1467.712058309595
reward_min: 159.96427917378614
total_envstep_count: 4769135
total_train_sample_count: 3753869
total_episode_count: 10138
total_duration: 977.3009095063753
[2023-05-17 12:29:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 11237
train_sample_count: 11237
avg_envstep_per_episode: 330.5
avg_sample_per_episode: 330.5
avg_envstep_per_sec: 1665.4699919827308
avg_train_sample_per_sec: 1665.4699919827308
avg_episode_per_sec: 5.039243546089957
collect_time: 6.747044410342348
reward_mean: 1200.1625669213481
reward_std: 237.92747475212735
reward_max: 1485.5188178661674
reward_min: 567.9445035854503
total_envstep_count: 4804911
total_train_sample_count: 3783906
total_episode_count: 10172
total_duration: 984.0479539167177
[2023-05-17 12:30:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 12215
train_sample_count: 12215
avg_envstep_per_episode: 277.6136363636364
avg_sample_per_episode: 277.6136363636364
avg_envstep_per_sec: 1662.2297770035832
avg_train_sample_per_sec: 1662.2297770035832
avg_episode_per_sec: 5.987565303983435
collect_time: 7.348562857548706
reward_mean: 1037.4892506583878
reward_std: 379.64184187758184
reward_max: 1679.5746571005748
reward_min: 5.281456527408022
total_envstep_count: 4845879
total_train_sample_count: 3814921
total_episode_count: 10216
total_duration: 991.3965167742664
[2023-05-17 12:30:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10509
train_sample_count: 10509
avg_envstep_per_episode: 276.55263157894734
avg_sample_per_episode: 276.55263157894734
avg_envstep_per_sec: 1590.2718835668188
avg_train_sample_per_sec: 1590.2718835668188
avg_episode_per_sec: 5.750340810309175
collect_time: 6.608303969022817
reward_mean: 1098.7815773219718
reward_std: 273.2241191027906
reward_max: 1551.4640026512036
reward_min: 491.79792423197347
total_envstep_count: 4882383
total_train_sample_count: 3844630
total_episode_count: 10254
total_duration: 998.0048207432892
[2023-05-17 12:31:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 7504
train_sample_count: 7504
avg_envstep_per_episode: 220.7058823529412
avg_sample_per_episode: 220.7058823529412
avg_envstep_per_sec: 1667.7295184254233
avg_train_sample_per_sec: 1667.7295184254233
avg_episode_per_sec: 7.5563437668529305
collect_time: 4.499530599593186
reward_mean: 968.5511156878665
reward_std: 328.9775376645345
reward_max: 1564.9125404738445
reward_min: 301.03910996304336
total_envstep_count: 4917879
total_train_sample_count: 3874134
total_episode_count: 10288
total_duration: 1002.5043513428824
[2023-05-17 12:31:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12706
train_sample_count: 12706
avg_envstep_per_episode: 295.48837209302326
avg_sample_per_episode: 295.48837209302326
avg_envstep_per_sec: 1693.3537360367927
avg_train_sample_per_sec: 1693.3537360367927
avg_episode_per_sec: 5.73069499839305
collect_time: 7.50345289917849
reward_mean: 980.5218665555544
reward_std: 359.088519492093
reward_max: 1630.5585459058764
reward_min: 120.1705471895801
total_envstep_count: 4956911
total_train_sample_count: 3904040
total_episode_count: 10331
total_duration: 1010.0078042420608
[2023-05-17 12:32:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 13371
train_sample_count: 13371
avg_envstep_per_episode: 318.35714285714283
avg_sample_per_episode: 318.35714285714283
avg_envstep_per_sec: 1654.5207640899532
avg_train_sample_per_sec: 1654.5207640899532
avg_episode_per_sec: 5.1970587160106225
collect_time: 8.081494224918076
reward_mean: 1009.8114243261314
reward_std: 302.3164102879083
reward_max: 1544.002630049218
reward_min: 526.5896286754543
total_envstep_count: 4998135
total_train_sample_count: 3934211
total_episode_count: 10373
total_duration: 1018.0892984669789
[2023-05-17 12:32:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 14003
train_sample_count: 14003
avg_envstep_per_episode: 318.25
avg_sample_per_episode: 318.25
avg_envstep_per_sec: 1685.929580395075
avg_train_sample_per_sec: 1685.929580395075
avg_episode_per_sec: 5.29750064538908
collect_time: 8.305803612935355
reward_mean: 1047.5923472817126
reward_std: 322.5079836874608
reward_max: 1607.6648018707608
reward_min: 434.73397248840433
total_envstep_count: 5041063
total_train_sample_count: 3965014
total_episode_count: 10417
total_duration: 1026.3951020799143
[2023-05-17 12:32:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12954
train_sample_count: 12954
avg_envstep_per_episode: 301.25581395348837
avg_sample_per_episode: 301.25581395348837
avg_envstep_per_sec: 1673.3910851977525
avg_train_sample_per_sec: 1673.3910851977525
avg_episode_per_sec: 5.554717976185222
collect_time: 7.741167091534472
reward_mean: 1097.0799382860068
reward_std: 374.10199367361366
reward_max: 1733.715629828908
reward_min: 170.39256158240565
total_envstep_count: 5084911
total_train_sample_count: 3995568
total_episode_count: 10460
total_duration: 1034.1362691714487
[2023-05-17 12:33:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 14144
train_sample_count: 14144
avg_envstep_per_episode: 336.76190476190476
avg_sample_per_episode: 336.76190476190476
avg_envstep_per_sec: 1707.8674796971256
avg_train_sample_per_sec: 1707.8674796971256
avg_episode_per_sec: 5.071439065842709
collect_time: 8.281673003404402
reward_mean: 1125.8292300573205
reward_std: 360.93763051895445
reward_max: 1660.4817202970312
reward_min: 355.65328718710293
total_envstep_count: 5128111
total_train_sample_count: 4026112
total_episode_count: 10502
total_duration: 1042.4179421748531
[2023-05-17 12:33:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 48
envstep_count: 14379
train_sample_count: 14379
avg_envstep_per_episode: 299.5625
avg_sample_per_episode: 299.5625
avg_envstep_per_sec: 1658.4546169056505
avg_train_sample_per_sec: 1658.4546169056505
avg_episode_per_sec: 5.536255762672733
collect_time: 8.670119672510774
reward_mean: 942.4828438330278
reward_std: 324.19186570633644
reward_max: 1644.1041279398685
reward_min: 59.93732394093593
total_envstep_count: 5170935
total_train_sample_count: 4056491
total_episode_count: 10550
total_duration: 1051.0880618473639
[2023-05-17 12:34:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12332
train_sample_count: 12332
avg_envstep_per_episode: 300.780487804878
avg_sample_per_episode: 300.780487804878
avg_envstep_per_sec: 1696.7877849385452
avg_train_sample_per_sec: 1696.7877849385452
avg_episode_per_sec: 5.641282775095714
collect_time: 7.267850528784096
reward_mean: 1083.5170922422355
reward_std: 311.598223661113
reward_max: 1607.4859366813923
reward_min: 272.2181046948185
total_envstep_count: 5213863
total_train_sample_count: 4086823
total_episode_count: 10591
total_duration: 1058.355912376148
[2023-05-17 12:34:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 10597
train_sample_count: 10597
avg_envstep_per_episode: 264.925
avg_sample_per_episode: 264.925
avg_envstep_per_sec: 1690.9722902440838
avg_train_sample_per_sec: 1690.9722902440838
avg_episode_per_sec: 6.382833972800165
collect_time: 6.266808782815935
reward_mean: 1026.4288152645217
reward_std: 319.4023690773076
reward_max: 1558.4331686107496
reward_min: 287.5373445558186
total_envstep_count: 5252983
total_train_sample_count: 4117020
total_episode_count: 10631
total_duration: 1064.622721158964
[2023-05-17 12:35:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 8725
train_sample_count: 8725
avg_envstep_per_episode: 242.36111111111111
avg_sample_per_episode: 242.36111111111111
avg_envstep_per_sec: 1646.8251946626672
avg_train_sample_per_sec: 1646.8251946626672
avg_episode_per_sec: 6.794923439295819
collect_time: 5.298072939543054
reward_mean: 1074.2995555878458
reward_std: 382.0272244192767
reward_max: 1603.4937739109562
reward_min: 335.46961181061437
total_envstep_count: 5289063
total_train_sample_count: 4146945
total_episode_count: 10667
total_duration: 1069.920794098507
[2023-05-17 12:35:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 8311
train_sample_count: 8311
avg_envstep_per_episode: 218.71052631578948
avg_sample_per_episode: 218.71052631578948
avg_envstep_per_sec: 1641.8892571588694
avg_train_sample_per_sec: 1641.8892571588694
avg_episode_per_sec: 7.507134132118523
collect_time: 5.061851744119077
reward_mean: 1126.4085444278624
reward_std: 340.3234231552798
reward_max: 1715.1770798110656
reward_min: 256.51146538927554
total_envstep_count: 5324983
total_train_sample_count: 4176856
total_episode_count: 10705
total_duration: 1074.9826458426262
[2023-05-17 12:35:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 9284
train_sample_count: 9284
avg_envstep_per_episode: 238.05128205128204
avg_sample_per_episode: 238.05128205128204
avg_envstep_per_sec: 1702.4668446653836
avg_train_sample_per_sec: 1702.4668446653836
avg_episode_per_sec: 7.15168105794377
collect_time: 5.45326332145091
reward_mean: 1221.6675193053602
reward_std: 324.53848429715123
reward_max: 1653.132912013146
reward_min: 297.77464402815264
total_envstep_count: 5361847
total_train_sample_count: 4206540
total_episode_count: 10744
total_duration: 1080.4359091640772
[2023-05-17 12:36:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 8908
train_sample_count: 8908
avg_envstep_per_episode: 254.5142857142857
avg_sample_per_episode: 254.5142857142857
avg_envstep_per_sec: 1723.0905245871281
avg_train_sample_per_sec: 1723.0905245871281
avg_episode_per_sec: 6.770113197187863
collect_time: 5.169780619700441
reward_mean: 903.5506185419315
reward_std: 297.9346632022847
reward_max: 1435.2578322254062
reward_min: 383.0431413305986
total_envstep_count: 5397279
total_train_sample_count: 4236248
total_episode_count: 10779
total_duration: 1085.6056897837777
[2023-05-17 12:36:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 6120
train_sample_count: 6120
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 1720.879234190616
avg_train_sample_per_sec: 1720.879234190616
avg_episode_per_sec: 10.122819024650683
collect_time: 3.556321604914031
reward_mean: 1054.1008409689764
reward_std: 297.84240585393013
reward_max: 1520.1562606746888
reward_min: 250.35675371172732
total_envstep_count: 5433583
total_train_sample_count: 4265968
total_episode_count: 10815
total_duration: 1089.1620113886918
[2023-05-17 12:37:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 3664
train_sample_count: 3664
avg_envstep_per_episode: 99.02702702702703
avg_sample_per_episode: 99.02702702702703
avg_envstep_per_sec: 1665.881638036297
avg_train_sample_per_sec: 1665.881638036297
avg_episode_per_sec: 16.822494707244267
collect_time: 2.19943597212527
reward_mean: 1059.264441717388
reward_std: 284.78704468299867
reward_max: 1580.9160468670957
reward_min: 415.75314206434405
total_envstep_count: 5469279
total_train_sample_count: 4296032
total_episode_count: 10852
total_duration: 1091.361447360817
[2023-05-17 12:37:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 3025
train_sample_count: 3025
avg_envstep_per_episode: 86.42857142857143
avg_sample_per_episode: 86.42857142857143
avg_envstep_per_sec: 1630.1544053712034
avg_train_sample_per_sec: 1630.1544053712034
avg_episode_per_sec: 18.861290640658552
collect_time: 1.8556524400589989
reward_mean: 1020.1856673722427
reward_std: 291.0162652432724
reward_max: 1470.361166616536
reward_min: 340.88985648679096
total_envstep_count: 5505511
total_train_sample_count: 4325857
total_episode_count: 10887
total_duration: 1093.217099800876
[2023-05-17 12:37:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 76.83783783783784
avg_sample_per_episode: 76.83783783783784
avg_envstep_per_sec: 1676.4467853034325
avg_train_sample_per_sec: 1676.4467853034325
avg_episode_per_sec: 21.817984894909255
collect_time: 1.6958486394695935
reward_mean: 1132.3768783018886
reward_std: 278.0298609009108
reward_max: 1509.9250179099743
reward_min: 481.61571050374164
total_envstep_count: 5541279
total_train_sample_count: 4355900
total_episode_count: 10924
total_duration: 1094.9129484403456
[2023-05-17 12:38:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 3025
train_sample_count: 3025
avg_envstep_per_episode: 86.42857142857143
avg_sample_per_episode: 86.42857142857143
avg_envstep_per_sec: 1720.7227066327534
avg_train_sample_per_sec: 1720.7227066327534
avg_episode_per_sec: 19.90918834120541
collect_time: 1.7579822642775254
reward_mean: 1107.186799945559
reward_std: 267.6139077488105
reward_max: 1551.830389561679
reward_min: 391.5771088148141
total_envstep_count: 5577511
total_train_sample_count: 4385725
total_episode_count: 10959
total_duration: 1096.670930704623
[2023-05-17 12:38:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 3719
train_sample_count: 3719
avg_envstep_per_episode: 97.86842105263158
avg_sample_per_episode: 97.86842105263158
avg_envstep_per_sec: 1597.4210689677047
avg_train_sample_per_sec: 1597.4210689677047
avg_episode_per_sec: 16.32212977165173
collect_time: 2.328127550241537
reward_mean: 1066.6952249571375
reward_std: 402.8186406372126
reward_max: 1615.0778336388835
reward_min: 207.94489094793235
total_envstep_count: 5613279
total_train_sample_count: 4415044
total_episode_count: 10997
total_duration: 1098.9990582548646
[2023-05-17 12:39:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 3901
train_sample_count: 3901
avg_envstep_per_episode: 111.45714285714286
avg_sample_per_episode: 111.45714285714286
avg_envstep_per_sec: 1623.810907411641
avg_train_sample_per_sec: 1623.810907411641
avg_episode_per_sec: 14.568926367446151
collect_time: 2.4023733195746324
reward_mean: 1270.7562880922617
reward_std: 340.9989914709891
reward_max: 1673.1682795566976
reward_min: 467.22390735266515
total_envstep_count: 5649511
total_train_sample_count: 4444145
total_episode_count: 11032
total_duration: 1101.4014315744394
[2023-05-17 12:39:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 3938
train_sample_count: 3938
avg_envstep_per_episode: 106.43243243243244
avg_sample_per_episode: 106.43243243243244
avg_envstep_per_sec: 1635.378452525881
avg_train_sample_per_sec: 1635.378452525881
avg_episode_per_sec: 15.365414612355915
collect_time: 2.4080053115030746
reward_mean: 1126.1923091774777
reward_std: 327.5153171267012
reward_max: 1716.4860244719935
reward_min: 484.8584943696192
total_envstep_count: 5685279
total_train_sample_count: 4473283
total_episode_count: 11069
total_duration: 1103.8094368859424
[2023-05-17 12:39:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 3901
train_sample_count: 3901
avg_envstep_per_episode: 111.45714285714286
avg_sample_per_episode: 111.45714285714286
avg_envstep_per_sec: 1572.3855504940582
avg_train_sample_per_sec: 1572.3855504940582
avg_episode_per_sec: 14.107535059546791
collect_time: 2.48094368380215
reward_mean: 1138.4462257200846
reward_std: 357.535777323955
reward_max: 1708.171953606123
reward_min: 311.7007813343533
total_envstep_count: 5721511
total_train_sample_count: 4502384
total_episode_count: 11104
total_duration: 1106.2903805697447
[2023-05-17 12:40:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11439
train_sample_count: 11439
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 1715.1110293686552
avg_train_sample_per_sec: 1715.1110293686552
avg_episode_per_sec: 6.147351359744284
collect_time: 6.669539058477619
reward_mean: 990.2661090531243
reward_std: 449.35849820412363
reward_max: 1701.9912664158232
reward_min: 273.12362799838166
total_envstep_count: 5760959
total_train_sample_count: 4532623
total_episode_count: 11145
total_duration: 1112.9599196282222
[2023-05-17 12:40:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 9233
train_sample_count: 9233
avg_envstep_per_episode: 236.74358974358975
avg_sample_per_episode: 236.74358974358975
avg_envstep_per_sec: 1668.698835902855
avg_train_sample_per_sec: 1668.698835902855
avg_episode_per_sec: 7.048549182303839
collect_time: 5.533053539289164
reward_mean: 1007.3289390702528
reward_std: 395.8672523444665
reward_max: 1691.8252752473804
reward_min: 17.385092283653776
total_envstep_count: 5797759
total_train_sample_count: 4562656
total_episode_count: 11184
total_duration: 1118.4929731675113
[2023-05-17 12:41:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9833
train_sample_count: 9833
avg_envstep_per_episode: 273.1388888888889
avg_sample_per_episode: 273.1388888888889
avg_envstep_per_sec: 1642.2694151023425
avg_train_sample_per_sec: 1642.2694151023425
avg_episode_per_sec: 6.012579980035017
collect_time: 5.987446340762079
reward_mean: 1001.3093963055749
reward_std: 363.1389385056107
reward_max: 1625.057703228488
reward_min: 314.4988511017545
total_envstep_count: 5833511
total_train_sample_count: 4592089
total_episode_count: 11220
total_duration: 1124.4804195082734
[2023-05-17 12:41:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9490
train_sample_count: 9490
avg_envstep_per_episode: 263.6111111111111
avg_sample_per_episode: 263.6111111111111
avg_envstep_per_sec: 1710.3572932684365
avg_train_sample_per_sec: 1710.3572932684365
avg_episode_per_sec: 6.488183620407135
collect_time: 5.548548269622029
reward_mean: 1174.3832790246738
reward_std: 374.85370020416275
reward_max: 1718.2729843823304
reward_min: 231.2577078111913
total_envstep_count: 5869759
total_train_sample_count: 4621579
total_episode_count: 11256
total_duration: 1130.0289677778953
[2023-05-17 12:41:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9833
train_sample_count: 9833
avg_envstep_per_episode: 273.1388888888889
avg_sample_per_episode: 273.1388888888889
avg_envstep_per_sec: 1675.4874185097171
avg_train_sample_per_sec: 1675.4874185097171
avg_episode_per_sec: 6.1341957760957815
collect_time: 5.868739980599844
reward_mean: 1115.1425519945262
reward_std: 297.57463875608113
reward_max: 1643.6686788105294
reward_min: 552.8950040285894
total_envstep_count: 5905511
total_train_sample_count: 4651012
total_episode_count: 11292
total_duration: 1135.8977077584952
[2023-05-17 12:42:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9490
train_sample_count: 9490
avg_envstep_per_episode: 263.6111111111111
avg_sample_per_episode: 263.6111111111111
avg_envstep_per_sec: 1689.1419644268344
avg_train_sample_per_sec: 1689.1419644268344
avg_episode_per_sec: 6.407703974643418
collect_time: 5.618237069386989
reward_mean: 1124.297308503169
reward_std: 340.27235797120125
reward_max: 1675.2834120580972
reward_min: 480.2294108988615
total_envstep_count: 5941759
total_train_sample_count: 4680502
total_episode_count: 11328
total_duration: 1141.5159448278823
[2023-05-17 12:42:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9833
train_sample_count: 9833
avg_envstep_per_episode: 273.1388888888889
avg_sample_per_episode: 273.1388888888889
avg_envstep_per_sec: 1636.6064856346918
avg_train_sample_per_sec: 1636.6064856346918
avg_episode_per_sec: 5.991847196465871
collect_time: 6.008163896641695
reward_mean: 1171.3046396964826
reward_std: 344.9887610261003
reward_max: 1711.5279197259522
reward_min: 237.58647624267758
total_envstep_count: 5977511
total_train_sample_count: 4709935
total_episode_count: 11364
total_duration: 1147.524108724524
[2023-05-17 12:43:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9490
train_sample_count: 9490
avg_envstep_per_episode: 263.6111111111111
avg_sample_per_episode: 263.6111111111111
avg_envstep_per_sec: 1637.5989387819673
avg_train_sample_per_sec: 1637.5989387819673
avg_episode_per_sec: 6.212177217718738
collect_time: 5.795069705564529
reward_mean: 1198.036144583284
reward_std: 377.6415829116487
reward_max: 1694.958701677986
reward_min: 288.1131429104631
total_envstep_count: 6013759
total_train_sample_count: 4739425
total_episode_count: 11400
total_duration: 1153.3191784300886
[2023-05-17 12:43:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9833
train_sample_count: 9833
avg_envstep_per_episode: 273.1388888888889
avg_sample_per_episode: 273.1388888888889
avg_envstep_per_sec: 1667.9226155328297
avg_train_sample_per_sec: 1667.9226155328297
avg_episode_per_sec: 6.106499965339354
collect_time: 5.895357439504937
reward_mean: 1138.9500006550334
reward_std: 389.7851271473432
reward_max: 1705.7327748345967
reward_min: 293.2006249309991
total_envstep_count: 6049511
total_train_sample_count: 4768858
total_episode_count: 11436
total_duration: 1159.2145358695936
[2023-05-17 12:43:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9490
train_sample_count: 9490
avg_envstep_per_episode: 263.6111111111111
avg_sample_per_episode: 263.6111111111111
avg_envstep_per_sec: 1736.533199908874
avg_train_sample_per_sec: 1736.533199908874
avg_episode_per_sec: 6.587481053395096
collect_time: 5.464911353550854
reward_mean: 1224.2233575155565
reward_std: 384.0519843198414
reward_max: 1722.4587306128522
reward_min: 308.57260591703704
total_envstep_count: 6085759
total_train_sample_count: 4798348
total_episode_count: 11472
total_duration: 1164.6794472231445
[2023-05-17 12:44:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9833
train_sample_count: 9833
avg_envstep_per_episode: 273.1388888888889
avg_sample_per_episode: 273.1388888888889
avg_envstep_per_sec: 1645.4735711131225
avg_train_sample_per_sec: 1645.4735711131225
avg_episode_per_sec: 6.024310847154725
collect_time: 5.9757872582227
reward_mean: 1221.234810385995
reward_std: 445.46772821081913
reward_max: 1803.79528006573
reward_min: 211.7796256609698
total_envstep_count: 6121511
total_train_sample_count: 4827781
total_episode_count: 11508
total_duration: 1170.6552344813672
[2023-05-17 12:44:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 9413
train_sample_count: 9413
avg_envstep_per_episode: 254.40540540540542
avg_sample_per_episode: 254.40540540540542
avg_envstep_per_sec: 1687.8030793255768
avg_train_sample_per_sec: 1687.8030793255768
avg_episode_per_sec: 6.634305103053898
collect_time: 5.577072417572142
reward_mean: 1320.3561880350865
reward_std: 391.76865500936
reward_max: 1861.7008816672103
reward_min: 6.391086298324714
total_envstep_count: 6157847
total_train_sample_count: 4857194
total_episode_count: 11545
total_duration: 1176.2323068989394
[2023-05-17 12:45:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10307
train_sample_count: 10307
avg_envstep_per_episode: 271.2368421052632
avg_sample_per_episode: 271.2368421052632
avg_envstep_per_sec: 1670.8699991276874
avg_train_sample_per_sec: 1670.8699991276874
avg_episode_per_sec: 6.1601882183809185
collect_time: 6.168642686373556
reward_mean: 1179.9199914264866
reward_std: 466.93826134058685
reward_max: 1835.3308994982326
reward_min: -23.0570167979324
total_envstep_count: 6194079
total_train_sample_count: 4886701
total_episode_count: 11583
total_duration: 1182.400949585313
[2023-05-17 12:45:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 13261
train_sample_count: 13261
avg_envstep_per_episode: 323.4390243902439
avg_sample_per_episode: 323.4390243902439
avg_envstep_per_sec: 1669.5947115978704
avg_train_sample_per_sec: 1669.5947115978704
avg_episode_per_sec: 5.162007629553781
collect_time: 7.942646145128647
reward_mean: 1201.0639801048192
reward_std: 405.4510558557622
reward_max: 1876.8012541872058
reward_min: 102.51387609960173
total_envstep_count: 6235823
total_train_sample_count: 4918362
total_episode_count: 11624
total_duration: 1190.3435957304416
[2023-05-17 12:45:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 13209
train_sample_count: 13209
avg_envstep_per_episode: 322.1707317073171
avg_sample_per_episode: 322.1707317073171
avg_envstep_per_sec: 1669.6385594329543
avg_train_sample_per_sec: 1669.6385594329543
avg_episode_per_sec: 5.182465056912039
collect_time: 7.9112930911742145
reward_mean: 1122.229466807819
reward_std: 509.02010630088733
reward_max: 1962.0039658507399
reward_min: 178.5135182445069
total_envstep_count: 6277215
total_train_sample_count: 4949571
total_episode_count: 11665
total_duration: 1198.2548888216159
[2023-05-17 12:46:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10804
train_sample_count: 10804
avg_envstep_per_episode: 284.3157894736842
avg_sample_per_episode: 284.3157894736842
avg_envstep_per_sec: 1671.1889731574684
avg_train_sample_per_sec: 1671.1889731574684
avg_episode_per_sec: 5.877932338021455
collect_time: 6.464858357452787
reward_mean: 1186.486296545235
reward_std: 559.115643974193
reward_max: 1965.5198528645212
reward_min: -99.30641881990027
total_envstep_count: 6313511
total_train_sample_count: 4979575
total_episode_count: 11703
total_duration: 1204.7197471790687
[2023-05-17 12:46:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12567
train_sample_count: 12567
avg_envstep_per_episode: 306.5121951219512
avg_sample_per_episode: 306.5121951219512
avg_envstep_per_sec: 1686.3561286723725
avg_train_sample_per_sec: 1686.3561286723725
avg_episode_per_sec: 5.501758675544464
collect_time: 7.45216255708318
reward_mean: 1066.8481370455374
reward_std: 508.9545278590306
reward_max: 1857.9299888922014
reward_min: 171.7598383064278
total_envstep_count: 6353439
total_train_sample_count: 5009342
total_episode_count: 11744
total_duration: 1212.171909736152
[2023-05-17 12:47:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 10701
train_sample_count: 10701
avg_envstep_per_episode: 289.2162162162162
avg_sample_per_episode: 289.2162162162162
avg_envstep_per_sec: 1621.521518896024
avg_train_sample_per_sec: 1621.521518896024
avg_episode_per_sec: 5.606606503985878
collect_time: 6.599357378424144
reward_mean: 1132.011800915319
reward_std: 478.9201073705254
reward_max: 1974.3347416189438
reward_min: -2.0268177598080754
total_envstep_count: 6390311
total_train_sample_count: 5038843
total_episode_count: 11781
total_duration: 1218.7712671145762
[2023-05-17 12:47:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11318
train_sample_count: 11318
avg_envstep_per_episode: 276.0487804878049
avg_sample_per_episode: 276.0487804878049
avg_envstep_per_sec: 1706.549054466861
avg_train_sample_per_sec: 1706.549054466861
avg_episode_per_sec: 6.1820561259181215
collect_time: 6.6320976653881365
reward_mean: 1071.1382202811214
reward_std: 534.9069670869836
reward_max: 1868.307360185544
reward_min: -42.49088067515724
total_envstep_count: 6431799
total_train_sample_count: 5068961
total_episode_count: 11822
total_duration: 1225.4033647799642
[2023-05-17 12:47:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 13166
train_sample_count: 13166
avg_envstep_per_episode: 306.1860465116279
avg_sample_per_episode: 306.1860465116279
avg_envstep_per_sec: 1654.0604076024433
avg_train_sample_per_sec: 1654.0604076024433
avg_episode_per_sec: 5.402141692762044
collect_time: 7.959806026119739
reward_mean: 1104.4693023073412
reward_std: 459.8613419674631
reward_max: 1809.9173159161733
reward_min: 6.873729787661347
total_envstep_count: 6472743
total_train_sample_count: 5098927
total_episode_count: 11865
total_duration: 1233.363170806084
[2023-05-17 12:48:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 13524
train_sample_count: 13524
avg_envstep_per_episode: 329.8536585365854
avg_sample_per_episode: 329.8536585365854
avg_envstep_per_sec: 1676.6378087737514
avg_train_sample_per_sec: 1676.6378087737514
avg_episode_per_sec: 5.082974723434177
collect_time: 8.066142806293445
reward_mean: 1147.2629684352135
reward_std: 488.38936328262633
reward_max: 1817.110328098631
reward_min: 108.00178768609844
total_envstep_count: 6514015
total_train_sample_count: 5129251
total_episode_count: 11906
total_duration: 1241.4293136123777
[2023-05-17 12:48:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 11478
train_sample_count: 11478
avg_envstep_per_episode: 294.3076923076923
avg_sample_per_episode: 294.3076923076923
avg_envstep_per_sec: 1651.3597922007937
avg_train_sample_per_sec: 1651.3597922007937
avg_episode_per_sec: 5.610997725721463
collect_time: 6.950635503062046
reward_mean: 1093.053396230745
reward_std: 411.0814007285848
reward_max: 1856.7642244858216
reward_min: 120.94526325434452
total_envstep_count: 6552383
total_train_sample_count: 5159129
total_episode_count: 11945
total_duration: 1248.3799491154398
[2023-05-17 12:49:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 9170
train_sample_count: 9170
avg_envstep_per_episode: 269.70588235294116
avg_sample_per_episode: 269.70588235294116
avg_envstep_per_sec: 1704.6009517820364
avg_train_sample_per_sec: 1704.6009517820364
avg_episode_per_sec: 6.320221631471019
collect_time: 5.379558183640242
reward_mean: 976.955261333806
reward_std: 532.7887224679583
reward_max: 1891.2105654657526
reward_min: 49.550121079081194
total_envstep_count: 6587935
total_train_sample_count: 5188699
total_episode_count: 11979
total_duration: 1253.75950729908
[2023-05-17 12:49:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10670
train_sample_count: 10670
avg_envstep_per_episode: 280.7894736842105
avg_sample_per_episode: 280.7894736842105
avg_envstep_per_sec: 1702.442965734785
avg_train_sample_per_sec: 1702.442965734785
avg_episode_per_sec: 6.063058359692768
collect_time: 6.267464000119828
reward_mean: 898.6574732680917
reward_std: 463.25044353884994
reward_max: 1901.830526157487
reward_min: 81.3503658572028
total_envstep_count: 6624383
total_train_sample_count: 5218169
total_episode_count: 12017
total_duration: 1260.0269712991999
[2023-05-17 12:50:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 9586
train_sample_count: 9586
avg_envstep_per_episode: 273.8857142857143
avg_sample_per_episode: 273.8857142857143
avg_envstep_per_sec: 1690.5679524532136
avg_train_sample_per_sec: 1690.5679524532136
avg_episode_per_sec: 6.172530600444657
collect_time: 5.670283756467513
reward_mean: 1038.1602424181342
reward_std: 527.5249225327121
reward_max: 1823.3294056729544
reward_min: -27.511217989486326
total_envstep_count: 6659935
total_train_sample_count: 5248155
total_episode_count: 12052
total_duration: 1265.6972550556675
[2023-05-17 12:50:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11421
train_sample_count: 11421
avg_envstep_per_episode: 308.6756756756757
avg_sample_per_episode: 308.6756756756757
avg_envstep_per_sec: 1706.2127708818177
avg_train_sample_per_sec: 1706.2127708818177
avg_episode_per_sec: 5.527525831593316
collect_time: 6.693772426810117
reward_mean: 1209.9364982857394
reward_std: 417.1310478330724
reward_max: 1848.5222750038572
reward_min: 127.14884405016691
total_envstep_count: 6696383
total_train_sample_count: 5278776
total_episode_count: 12089
total_duration: 1272.3910274824775
[2023-05-17 12:50:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 10062
train_sample_count: 10062
avg_envstep_per_episode: 287.48571428571427
avg_sample_per_episode: 287.48571428571427
avg_envstep_per_sec: 1681.272789224783
avg_train_sample_per_sec: 1681.272789224783
avg_episode_per_sec: 5.848195947412782
collect_time: 5.98475159087032
reward_mean: 1056.6847581498557
reward_std: 441.34954037042525
reward_max: 1726.0644963997972
reward_min: 74.05042225601571
total_envstep_count: 6731935
total_train_sample_count: 5309238
total_episode_count: 12124
total_duration: 1278.3757790733478
[2023-05-17 12:51:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11421
train_sample_count: 11421
avg_envstep_per_episode: 308.6756756756757
avg_sample_per_episode: 308.6756756756757
avg_envstep_per_sec: 1676.6669795397129
avg_train_sample_per_sec: 1676.6669795397129
avg_episode_per_sec: 5.431807919006162
collect_time: 6.811728351169265
reward_mean: 1108.9302183807865
reward_std: 401.2902159033004
reward_max: 1790.8089880879395
reward_min: 364.64113085290666
total_envstep_count: 6768383
total_train_sample_count: 5339859
total_episode_count: 12161
total_duration: 1285.187507424517
[2023-05-17 12:51:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 10062
train_sample_count: 10062
avg_envstep_per_episode: 287.48571428571427
avg_sample_per_episode: 287.48571428571427
avg_envstep_per_sec: 1667.4021929912137
avg_train_sample_per_sec: 1667.4021929912137
avg_episode_per_sec: 5.799947997882377
collect_time: 6.0345368635682375
reward_mean: 1099.1797362871396
reward_std: 396.22846458089845
reward_max: 1901.7199965904224
reward_min: 423.2032020168797
total_envstep_count: 6803935
total_train_sample_count: 5370321
total_episode_count: 12196
total_duration: 1291.2220442880853
[2023-05-17 12:52:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11421
train_sample_count: 11421
avg_envstep_per_episode: 308.6756756756757
avg_sample_per_episode: 308.6756756756757
avg_envstep_per_sec: 1672.3994541499062
avg_train_sample_per_sec: 1672.3994541499062
avg_episode_per_sec: 5.4179826463135035
collect_time: 6.829110097865575
reward_mean: 1027.7847817074592
reward_std: 520.3543926154749
reward_max: 1864.3797730597405
reward_min: -66.54842725508693
total_envstep_count: 6840383
total_train_sample_count: 5400942
total_episode_count: 12233
total_duration: 1298.051154385951
[2023-05-17 12:52:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 10062
train_sample_count: 10062
avg_envstep_per_episode: 287.48571428571427
avg_sample_per_episode: 287.48571428571427
avg_envstep_per_sec: 1697.9023447578845
avg_train_sample_per_sec: 1697.9023447578845
avg_episode_per_sec: 5.906040753977933
collect_time: 5.926135876462794
reward_mean: 1193.7711197982458
reward_std: 484.21406844222446
reward_max: 1796.0907973551393
reward_min: 12.331399837757758
total_envstep_count: 6875935
total_train_sample_count: 5431404
total_episode_count: 12268
total_duration: 1303.9772902624136
[2023-05-17 12:52:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 11649
train_sample_count: 11649
avg_envstep_per_episode: 306.55263157894734
avg_sample_per_episode: 306.55263157894734
avg_envstep_per_sec: 1730.6211473972025
avg_train_sample_per_sec: 1730.6211473972025
avg_episode_per_sec: 5.645429101304292
collect_time: 6.731109242204577
reward_mean: 1254.905362528496
reward_std: 443.58375395447933
reward_max: 1897.5735392648726
reward_min: 55.455790503832745
total_envstep_count: 6912383
total_train_sample_count: 5462253
total_episode_count: 12306
total_duration: 1310.7083995046182
[2023-05-17 12:53:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 10518
train_sample_count: 10518
avg_envstep_per_episode: 300.51428571428573
avg_sample_per_episode: 300.51428571428573
avg_envstep_per_sec: 1689.5909698133798
avg_train_sample_per_sec: 1689.5909698133798
avg_episode_per_sec: 5.6223316166066075
collect_time: 6.225175316344016
reward_mean: 1297.834008006785
reward_std: 443.6267778967801
reward_max: 1905.94972679511
reward_min: 182.86045071737274
total_envstep_count: 6947935
total_train_sample_count: 5493171
total_episode_count: 12341
total_duration: 1316.9335748209623
[2023-05-17 12:53:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11991
train_sample_count: 11991
avg_envstep_per_episode: 324.0810810810811
avg_sample_per_episode: 324.0810810810811
avg_envstep_per_sec: 1681.449962241403
avg_train_sample_per_sec: 1681.449962241403
avg_episode_per_sec: 5.188361988402295
collect_time: 7.131345130256378
reward_mean: 1304.1747719864475
reward_std: 449.02839176791855
reward_max: 1989.9630435264658
reward_min: 453.41938489403174
total_envstep_count: 6984383
total_train_sample_count: 5524362
total_episode_count: 12378
total_duration: 1324.0649199512188
[2023-05-17 12:54:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 10866
train_sample_count: 10866
avg_envstep_per_episode: 310.45714285714286
avg_sample_per_episode: 310.45714285714286
avg_envstep_per_sec: 1664.3853537153414
avg_train_sample_per_sec: 1664.3853537153414
avg_episode_per_sec: 5.361079272964932
collect_time: 6.528536180485042
reward_mean: 1300.2207503038298
reward_std: 408.45541620779346
reward_max: 1923.1851276777725
reward_min: 348.029886981953
total_envstep_count: 7019935
total_train_sample_count: 5554428
total_episode_count: 12413
total_duration: 1330.5934561317038
[2023-05-17 12:54:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 13552
train_sample_count: 13552
avg_envstep_per_episode: 338.8
avg_sample_per_episode: 338.8
avg_envstep_per_sec: 1696.8561003907448
avg_train_sample_per_sec: 1696.8561003907448
avg_episode_per_sec: 5.0084300483788216
collect_time: 7.98653462534584
reward_mean: 1306.8337467738288
reward_std: 611.8715296072603
reward_max: 2068.213021830333
reward_min: 163.76044457139224
total_envstep_count: 7056263
total_train_sample_count: 5584380
total_episode_count: 12453
total_duration: 1338.5799907570497
[2023-05-17 12:54:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 8495
train_sample_count: 8495
avg_envstep_per_episode: 257.42424242424244
avg_sample_per_episode: 257.42424242424244
avg_envstep_per_sec: 1702.0368382107047
avg_train_sample_per_sec: 1702.0368382107047
avg_episode_per_sec: 6.611797017181078
collect_time: 4.991078811743296
reward_mean: 1314.362940552386
reward_std: 518.610673123152
reward_max: 2032.4762527870691
reward_min: 158.981309711268
total_envstep_count: 7091935
total_train_sample_count: 5613675
total_episode_count: 12486
total_duration: 1343.571069568793
[2023-05-17 12:55:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 10449
train_sample_count: 10449
avg_envstep_per_episode: 282.4054054054054
avg_sample_per_episode: 282.4054054054054
avg_envstep_per_sec: 1733.517596741074
avg_train_sample_per_sec: 1733.517596741074
avg_episode_per_sec: 6.13840090720832
collect_time: 6.027628458830528
reward_mean: 1443.868970107796
reward_std: 498.58784417517757
reward_max: 2170.733729941375
reward_min: 111.33477394634528
total_envstep_count: 7128135
total_train_sample_count: 5642924
total_episode_count: 12523
total_duration: 1349.5986980276236
[2023-05-17 12:55:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 8532
train_sample_count: 8532
avg_envstep_per_episode: 243.77142857142857
avg_sample_per_episode: 243.77142857142857
avg_envstep_per_sec: 1722.0081640500173
avg_train_sample_per_sec: 1722.0081640500173
avg_episode_per_sec: 7.064027864715261
collect_time: 4.95468034247495
reward_mean: 1523.8865198503238
reward_std: 571.1086063456027
reward_max: 2291.7839049185764
reward_min: 450.4756375379968
total_envstep_count: 7163935
total_train_sample_count: 5672256
total_episode_count: 12558
total_duration: 1354.5533783700987
[2023-05-17 12:56:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 13677
train_sample_count: 13677
avg_envstep_per_episode: 341.925
avg_sample_per_episode: 341.925
avg_envstep_per_sec: 1695.9832721595672
avg_train_sample_per_sec: 1695.9832721595672
avg_episode_per_sec: 4.960103157591774
collect_time: 8.064348407507875
reward_mean: 1351.294686977999
reward_std: 611.002974193273
reward_max: 2164.367823985745
reward_min: -388.69409930618633
total_envstep_count: 7200807
total_train_sample_count: 5703133
total_episode_count: 12598
total_duration: 1362.6177267776065
[2023-05-17 12:56:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 12143
train_sample_count: 12143
avg_envstep_per_episode: 328.18918918918916
avg_sample_per_episode: 328.18918918918916
avg_envstep_per_sec: 1722.7102733847578
avg_train_sample_per_sec: 1722.7102733847578
avg_episode_per_sec: 5.249137784339623
collect_time: 7.048776679169387
reward_mean: 1399.6887192401844
reward_std: 543.3401725733157
reward_max: 2112.600686575817
reward_min: 401.636947480764
total_envstep_count: 7238879
total_train_sample_count: 5733676
total_episode_count: 12635
total_duration: 1369.666503456776
[2023-05-17 12:56:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 8998
train_sample_count: 8998
avg_envstep_per_episode: 230.71794871794873
avg_sample_per_episode: 230.71794871794873
avg_envstep_per_sec: 1704.9225197034002
avg_train_sample_per_sec: 1704.9225197034002
avg_episode_per_sec: 7.389639727543077
collect_time: 5.277659187448209
reward_mean: 1474.4765157766979
reward_std: 517.6583840676304
reward_max: 2135.7397848427763
reward_min: 64.19696210368369
total_envstep_count: 7276615
total_train_sample_count: 5763074
total_episode_count: 12674
total_duration: 1374.9441626442242
[2023-05-17 12:57:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 11406
train_sample_count: 11406
avg_envstep_per_episode: 285.15
avg_sample_per_episode: 285.15
avg_envstep_per_sec: 1701.9246703235378
avg_train_sample_per_sec: 1701.9246703235378
avg_episode_per_sec: 5.968524181390629
collect_time: 6.70182423399016
reward_mean: 1493.2128403100603
reward_std: 604.8195023571845
reward_max: 2244.3688675080352
reward_min: -23.1421920198769
total_envstep_count: 7317567
total_train_sample_count: 5793680
total_episode_count: 12714
total_duration: 1381.6459868782144
[2023-05-17 12:57:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 11710
train_sample_count: 11710
avg_envstep_per_episode: 285.609756097561
avg_sample_per_episode: 285.609756097561
avg_envstep_per_sec: 1695.1455714800995
avg_train_sample_per_sec: 1695.1455714800995
avg_episode_per_sec: 5.9351809078295545
collect_time: 6.907961296666415
reward_mean: 1483.6988421638562
reward_std: 522.0925910782195
reward_max: 2251.4620806599655
reward_min: 130.2460186361683
total_envstep_count: 7359535
total_train_sample_count: 5824190
total_episode_count: 12755
total_duration: 1388.5539481748808
[2023-05-17 12:58:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 12615
train_sample_count: 12615
avg_envstep_per_episode: 286.70454545454544
avg_sample_per_episode: 286.70454545454544
avg_envstep_per_sec: 1680.0182482646449
avg_train_sample_per_sec: 1680.0182482646449
avg_episode_per_sec: 5.859754492559998
collect_time: 7.508847009864635
reward_mean: 1613.5848881298768
reward_std: 691.705927607127
reward_max: 2582.7295740373947
reward_min: -438.7868916423067
total_envstep_count: 7400807
total_train_sample_count: 5854805
total_episode_count: 12799
total_duration: 1396.0627951847455
[2023-05-17 12:58:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 11585
train_sample_count: 11585
avg_envstep_per_episode: 331.0
avg_sample_per_episode: 331.0
avg_envstep_per_sec: 1692.750753630971
avg_train_sample_per_sec: 1692.750753630971
avg_episode_per_sec: 5.114050615199308
collect_time: 6.843890026425942
reward_mean: 1518.4546191437537
reward_std: 736.1001699452561
reward_max: 2387.278623258476
reward_min: -117.24347041203893
total_envstep_count: 7437567
total_train_sample_count: 5883990
total_episode_count: 12834
total_duration: 1402.9066852111714
[2023-05-17 12:58:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 14085
train_sample_count: 14085
avg_envstep_per_episode: 352.125
avg_sample_per_episode: 352.125
avg_envstep_per_sec: 1647.4218910663833
avg_train_sample_per_sec: 1647.4218910663833
avg_episode_per_sec: 4.678514422623737
collect_time: 8.549722494510934
reward_mean: 1553.7373755881586
reward_std: 700.1092470473931
reward_max: 2435.9595192137176
reward_min: -152.3339999806779
total_envstep_count: 7474367
total_train_sample_count: 5912875
total_episode_count: 12874
total_duration: 1411.4564077056823
[2023-05-17 12:59:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 11344
train_sample_count: 11344
avg_envstep_per_episode: 298.5263157894737
avg_sample_per_episode: 298.5263157894737
avg_envstep_per_sec: 1632.0869557539672
avg_train_sample_per_sec: 1632.0869557539672
avg_episode_per_sec: 5.4671460083436845
collect_time: 6.950610051753932
reward_mean: 1636.5587054154134
reward_std: 673.3865355811804
reward_max: 2383.0219408164053
reward_min: -8.900203301684499
total_envstep_count: 7512263
total_train_sample_count: 5942619
total_episode_count: 12912
total_duration: 1418.4070177574363
[2023-05-17 12:59:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 11699
train_sample_count: 11699
avg_envstep_per_episode: 292.475
avg_sample_per_episode: 292.475
avg_envstep_per_sec: 1627.6098910715912
avg_train_sample_per_sec: 1627.6098910715912
avg_episode_per_sec: 5.564953897159043
collect_time: 7.187840319830923
reward_mean: 1582.8236572225012
reward_std: 747.0395702763881
reward_max: 2501.984021544197
reward_min: -377.1695664359393
total_envstep_count: 7552807
total_train_sample_count: 5973118
total_episode_count: 12952
total_duration: 1425.5948580772672
[2023-05-17 13:00:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 11882
train_sample_count: 11882
avg_envstep_per_episode: 282.9047619047619
avg_sample_per_episode: 282.9047619047619
avg_envstep_per_sec: 1676.2044187021354
avg_train_sample_per_sec: 1676.2044187021354
avg_episode_per_sec: 5.924977746632695
collect_time: 7.088634218730963
reward_mean: 1668.6966311248952
reward_std: 628.6168954025806
reward_max: 2626.971626681566
reward_min: 218.47192086648988
total_envstep_count: 7594367
total_train_sample_count: 6003400
total_episode_count: 12994
total_duration: 1432.6834922959981
[2023-05-17 13:00:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 11284
train_sample_count: 11284
avg_envstep_per_episode: 289.3333333333333
avg_sample_per_episode: 289.3333333333333
avg_envstep_per_sec: 1682.0228063731458
avg_train_sample_per_sec: 1682.0228063731458
avg_episode_per_sec: 5.813442879169859
collect_time: 6.708589180387556
reward_mean: 1552.0680333289956
reward_std: 812.3961941084937
reward_max: 2694.437280152414
reward_min: -163.53873319017026
total_envstep_count: 7632167
total_train_sample_count: 6033884
total_episode_count: 13033
total_duration: 1439.3920814763858
[2023-05-17 13:01:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 11287
train_sample_count: 11287
avg_envstep_per_episode: 297.0263157894737
avg_sample_per_episode: 297.0263157894737
avg_envstep_per_sec: 1648.2074566794756
avg_train_sample_per_sec: 1648.2074566794756
avg_episode_per_sec: 5.549028382548071
collect_time: 6.84804570823815
reward_mean: 1591.8148552963003
reward_std: 783.5211780270745
reward_max: 2528.1749696255733
reward_min: -32.858704818655795
total_envstep_count: 7668375
total_train_sample_count: 6065171
total_episode_count: 13071
total_duration: 1446.240127184624
[2023-05-17 13:01:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 8915
train_sample_count: 8915
avg_envstep_per_episode: 254.71428571428572
avg_sample_per_episode: 254.71428571428572
avg_envstep_per_sec: 1640.3417395574145
avg_train_sample_per_sec: 1640.3417395574145
avg_episode_per_sec: 6.439928310096411
collect_time: 5.434843109220267
reward_mean: 1319.9866897841068
reward_std: 711.7654307168087
reward_max: 2590.8435670629688
reward_min: 152.14897543239832
total_envstep_count: 7704167
total_train_sample_count: 6096086
total_episode_count: 13106
total_duration: 1451.6749702938444
[2023-05-17 13:01:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10044
train_sample_count: 10044
avg_envstep_per_episode: 264.3157894736842
avg_sample_per_episode: 264.3157894736842
avg_envstep_per_sec: 1690.018246531802
avg_train_sample_per_sec: 1690.018246531802
avg_episode_per_sec: 6.393936018340152
collect_time: 5.943131099686027
reward_mean: 1501.6509024595655
reward_std: 689.0794829073103
reward_max: 2444.815814930645
reward_min: 212.73160095599928
total_envstep_count: 7740398
total_train_sample_count: 6126930
total_episode_count: 13144
total_duration: 1457.6181013935304
[2023-05-17 13:02:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 10400
train_sample_count: 10400
avg_envstep_per_episode: 288.8888888888889
avg_sample_per_episode: 288.8888888888889
avg_envstep_per_sec: 1758.261121195184
avg_train_sample_per_sec: 1758.261121195184
avg_episode_per_sec: 6.086288496444868
collect_time: 5.914934860716572
reward_mean: 1500.5437096302778
reward_std: 786.0900645225969
reward_max: 2528.342726503337
reward_min: -170.76088557374572
total_envstep_count: 7776734
total_train_sample_count: 6157330
total_episode_count: 13180
total_duration: 1463.533036254247
[2023-05-17 13:02:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 11790
train_sample_count: 11790
avg_envstep_per_episode: 280.7142857142857
avg_sample_per_episode: 280.7142857142857
avg_envstep_per_sec: 1682.6288034244797
avg_train_sample_per_sec: 1682.6288034244797
avg_episode_per_sec: 5.994097518560488
collect_time: 7.006893009322696
reward_mean: 1462.759589605091
reward_std: 776.2126608852989
reward_max: 2557.6981573825083
reward_min: -199.00903929969036
total_envstep_count: 7816734
total_train_sample_count: 6187920
total_episode_count: 13222
total_duration: 1470.5399292635698
[2023-05-17 13:03:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 8273
train_sample_count: 8273
avg_envstep_per_episode: 236.37142857142857
avg_sample_per_episode: 236.37142857142857
avg_envstep_per_sec: 1660.45122925904
avg_train_sample_per_sec: 1660.45122925904
avg_episode_per_sec: 7.0247543846327085
collect_time: 4.982380604874342
reward_mean: 1444.155840438041
reward_std: 779.9913634016843
reward_max: 2559.57384550956
reward_min: -270.04897602222127
total_envstep_count: 7852550
total_train_sample_count: 6217793
total_episode_count: 13257
total_duration: 1475.5223098684442
[2023-05-17 13:03:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 11634
train_sample_count: 11634
avg_envstep_per_episode: 306.1578947368421
avg_sample_per_episode: 306.1578947368421
avg_envstep_per_sec: 1681.58620917339
avg_train_sample_per_sec: 1681.58620917339
avg_episode_per_sec: 5.492545637664502
collect_time: 6.918467775564641
reward_mean: 1541.5755616689892
reward_std: 690.2794348129012
reward_max: 2574.609005210005
reward_min: 42.64488408591811
total_envstep_count: 7889830
total_train_sample_count: 6247427
total_episode_count: 13295
total_duration: 1482.440777644009
[2023-05-17 13:03:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 12664
train_sample_count: 12664
avg_envstep_per_episode: 333.2631578947368
avg_sample_per_episode: 333.2631578947368
avg_envstep_per_sec: 1702.618453350334
avg_train_sample_per_sec: 1702.618453350334
avg_episode_per_sec: 5.108930924456151
collect_time: 7.437955329968593
reward_mean: 1215.9482470241185
reward_std: 804.4548468145746
reward_max: 2656.5439934553747
reward_min: -541.8166580812162
total_envstep_count: 7925342
total_train_sample_count: 6277291
total_episode_count: 13333
total_duration: 1489.8787329739775
[2023-05-17 13:04:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 7995
train_sample_count: 7995
avg_envstep_per_episode: 222.08333333333334
avg_sample_per_episode: 222.08333333333334
avg_envstep_per_sec: 1706.6310832143897
avg_train_sample_per_sec: 1706.6310832143897
avg_episode_per_sec: 7.684642776199879
collect_time: 4.684667986324057
reward_mean: 1390.135256022125
reward_std: 739.8620617617618
reward_max: 2715.233032970772
reward_min: -375.1428917315943
total_envstep_count: 7960757
total_train_sample_count: 6308086
total_episode_count: 13369
total_duration: 1494.5634009603016
[2023-05-17 13:04:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 7582
train_sample_count: 7582
avg_envstep_per_episode: 199.52631578947367
avg_sample_per_episode: 199.52631578947367
avg_envstep_per_sec: 1696.651664545707
avg_train_sample_per_sec: 1696.651664545707
avg_episode_per_sec: 8.50339794945092
collect_time: 4.468801792635582
reward_mean: 1504.137452064695
reward_std: 866.5137692931416
reward_max: 2778.147492403843
reward_min: -287.5200539556003
total_envstep_count: 7996893
total_train_sample_count: 6338468
total_episode_count: 13407
total_duration: 1499.032202752937
[2023-05-17 13:05:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 7683
train_sample_count: 7683
avg_envstep_per_episode: 219.5142857142857
avg_sample_per_episode: 219.5142857142857
avg_envstep_per_sec: 1721.5920689898164
avg_train_sample_per_sec: 1721.5920689898164
avg_episode_per_sec: 7.842733621585783
collect_time: 4.462729666562751
reward_mean: 1438.4733132508663
reward_std: 795.752614899739
reward_max: 2658.133576422175
reward_min: -626.2905180931518
total_envstep_count: 8033356
total_train_sample_count: 6368151
total_episode_count: 13442
total_duration: 1503.4949324195
[2023-05-17 13:05:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 6900
train_sample_count: 6900
avg_envstep_per_episode: 181.57894736842104
avg_sample_per_episode: 181.57894736842104
avg_envstep_per_sec: 1701.1561839544177
avg_train_sample_per_sec: 1701.1561839544177
avg_episode_per_sec: 9.368686230473605
collect_time: 4.056064966334029
reward_mean: 1436.7983585669235
reward_std: 778.1222180348338
reward_max: 2785.2477508969214
reward_min: -399.00343133753313
total_envstep_count: 8069532
total_train_sample_count: 6397851
total_episode_count: 13480
total_duration: 1507.550997385834
[2023-05-17 13:05:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 5759
train_sample_count: 5759
avg_envstep_per_episode: 164.54285714285714
avg_sample_per_episode: 164.54285714285714
avg_envstep_per_sec: 1600.6461460923679
avg_train_sample_per_sec: 1600.6461460923679
avg_episode_per_sec: 9.727837317803939
collect_time: 3.5979220104701812
reward_mean: 1470.5930556709854
reward_std: 654.9511101927412
reward_max: 2611.865994962207
reward_min: -18.098263471112134
total_envstep_count: 8105356
total_train_sample_count: 6427610
total_episode_count: 13515
total_duration: 1511.1489193963043
[2023-05-17 13:06:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 7543
train_sample_count: 7543
avg_envstep_per_episode: 198.5
avg_sample_per_episode: 198.5
avg_envstep_per_sec: 1624.9679397106304
avg_train_sample_per_sec: 1624.9679397106304
avg_episode_per_sec: 8.186236472093855
collect_time: 4.641937736533581
reward_mean: 1606.5704318793858
reward_std: 763.2488527432748
reward_max: 2564.2463552907866
reward_min: -572.0480856915706
total_envstep_count: 8141732
total_train_sample_count: 6457153
total_episode_count: 13553
total_duration: 1515.790857132838
[2023-05-17 13:06:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 11082
train_sample_count: 11082
avg_envstep_per_episode: 299.5135135135135
avg_sample_per_episode: 299.5135135135135
avg_envstep_per_sec: 1697.5038355032073
avg_train_sample_per_sec: 1697.5038355032073
avg_episode_per_sec: 5.667536718427962
collect_time: 6.528409402217849
reward_mean: 1312.7483953830829
reward_std: 830.9052720567961
reward_max: 2568.878005835733
reward_min: -288.15211663246487
total_envstep_count: 8178314
total_train_sample_count: 6487835
total_episode_count: 13590
total_duration: 1522.319266535056
[2023-05-17 13:07:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 11545
train_sample_count: 11545
avg_envstep_per_episode: 288.625
avg_sample_per_episode: 288.625
avg_envstep_per_sec: 1668.613962225696
avg_train_sample_per_sec: 1668.613962225696
avg_episode_per_sec: 5.781252359378764
collect_time: 6.9189160952486555
reward_mean: 1340.1216206286194
reward_std: 831.4032804764087
reward_max: 2458.128929398182
reward_min: -99.93359150452898
total_envstep_count: 8214162
total_train_sample_count: 6517780
total_episode_count: 13630
total_duration: 1529.2381826303047
[2023-05-17 13:07:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 8640
train_sample_count: 8640
avg_envstep_per_episode: 254.11764705882354
avg_sample_per_episode: 254.11764705882354
avg_envstep_per_sec: 1714.4179294984892
avg_train_sample_per_sec: 1714.4179294984892
avg_episode_per_sec: 6.746552037378314
collect_time: 5.039611317251809
reward_mean: 1837.3327783989878
reward_std: 617.4933627602932
reward_max: 2706.2148611990715
reward_min: 640.7908273711926
total_envstep_count: 8249762
total_train_sample_count: 6547620
total_episode_count: 13664
total_duration: 1534.2777939475566
[2023-05-17 13:07:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10004
train_sample_count: 10004
avg_envstep_per_episode: 263.2631578947368
avg_sample_per_episode: 263.2631578947368
avg_envstep_per_sec: 1723.3008656431666
avg_train_sample_per_sec: 1723.3008656431666
avg_episode_per_sec: 6.545924919476242
collect_time: 5.8051383826505125
reward_mean: 1452.5080352933053
reward_std: 806.4014575462843
reward_max: 2707.2380260312602
reward_min: -203.69794662246102
total_envstep_count: 8286137
total_train_sample_count: 6578424
total_episode_count: 13702
total_duration: 1540.082932330207
[2023-05-17 13:08:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 7724
train_sample_count: 7724
avg_envstep_per_episode: 220.68571428571428
avg_sample_per_episode: 220.68571428571428
avg_envstep_per_sec: 1680.1586026079376
avg_train_sample_per_sec: 1680.1586026079376
avg_episode_per_sec: 7.613354620828304
collect_time: 4.597185044323094
reward_mean: 1197.7401081837631
reward_std: 722.0490512548994
reward_max: 2710.3601421855074
reward_min: 72.57130547496655
total_envstep_count: 8322873
total_train_sample_count: 6608548
total_episode_count: 13737
total_duration: 1544.6801173745303
[2023-05-17 13:08:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 8307
train_sample_count: 8307
avg_envstep_per_episode: 207.675
avg_sample_per_episode: 207.675
avg_envstep_per_sec: 1617.4403618580452
avg_train_sample_per_sec: 1617.4403618580452
avg_episode_per_sec: 7.788324843423836
collect_time: 5.135892609021627
reward_mean: 1072.2129468575472
reward_std: 798.743128175398
reward_max: 2646.022131887567
reward_min: -366.342393877768
total_envstep_count: 8359033
total_train_sample_count: 6638855
total_episode_count: 13777
total_duration: 1549.8160099835518
[2023-05-17 13:09:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 7812
train_sample_count: 7812
avg_envstep_per_episode: 244.125
avg_sample_per_episode: 244.125
avg_envstep_per_sec: 1655.5805622505031
avg_train_sample_per_sec: 1655.5805622505031
avg_episode_per_sec: 6.781692011266783
collect_time: 4.718586445217022
reward_mean: 935.1291834687668
reward_std: 580.7758627184178
reward_max: 2282.710804964753
reward_min: -339.44839892316963
total_envstep_count: 8394233
total_train_sample_count: 6669067
total_episode_count: 13809
total_duration: 1554.5345964287687
[2023-05-17 13:09:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 10555
train_sample_count: 10555
avg_envstep_per_episode: 263.875
avg_sample_per_episode: 263.875
avg_envstep_per_sec: 1717.7860103283351
avg_train_sample_per_sec: 1717.7860103283351
avg_episode_per_sec: 6.509847504797102
collect_time: 6.144537175490521
reward_mean: 1387.879905809144
reward_std: 637.8125553282908
reward_max: 2596.6318444451617
reward_min: 116.00433852069597
total_envstep_count: 8430689
total_train_sample_count: 6698422
total_episode_count: 13849
total_duration: 1560.6791336042593
[2023-05-17 13:09:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 12748
train_sample_count: 12748
avg_envstep_per_episode: 310.9268292682927
avg_sample_per_episode: 310.9268292682927
avg_envstep_per_sec: 1683.6711411953636
avg_train_sample_per_sec: 1683.6711411953636
avg_episode_per_sec: 5.415007592485873
collect_time: 7.571549863917751
reward_mean: 1459.357718062805
reward_std: 631.6537489549913
reward_max: 2762.2261051298465
reward_min: 231.57271975076236
total_envstep_count: 8471033
total_train_sample_count: 6728370
total_episode_count: 13890
total_duration: 1568.250683468177
[2023-05-17 13:10:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 9399
train_sample_count: 9399
avg_envstep_per_episode: 261.0833333333333
avg_sample_per_episode: 261.0833333333333
avg_envstep_per_sec: 1684.625970324857
avg_train_sample_per_sec: 1684.625970324857
avg_episode_per_sec: 6.452445465655373
collect_time: 5.579280009667388
reward_mean: 1427.4977750229693
reward_std: 820.998315553676
reward_max: 2575.675140914225
reward_min: -229.88692271647244
total_envstep_count: 8507489
total_train_sample_count: 6757769
total_episode_count: 13926
total_duration: 1573.8299634778443
[2023-05-17 13:10:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 8057
train_sample_count: 8057
avg_envstep_per_episode: 223.80555555555554
avg_sample_per_episode: 223.80555555555554
avg_envstep_per_sec: 1745.0675187113593
avg_train_sample_per_sec: 1745.0675187113593
avg_episode_per_sec: 7.797248439072724
collect_time: 4.617013332498258
reward_mean: 1200.2233332540216
reward_std: 852.2247426086864
reward_max: 2565.362517467012
reward_min: -246.79392150432145
total_envstep_count: 8543537
total_train_sample_count: 6787826
total_episode_count: 13962
total_duration: 1578.4469768103427
[2023-05-17 13:11:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 4914
train_sample_count: 4914
avg_envstep_per_episode: 140.4
avg_sample_per_episode: 140.4
avg_envstep_per_sec: 1672.3607686632215
avg_train_sample_per_sec: 1672.3607686632215
avg_episode_per_sec: 11.91140148620528
collect_time: 2.9383612029645603
reward_mean: 1454.9364369012715
reward_std: 954.7017035476673
reward_max: 2689.109898286664
reward_min: -595.7530269676122
total_envstep_count: 8579185
total_train_sample_count: 6818340
total_episode_count: 13997
total_duration: 1581.3853380133073
[2023-05-17 13:11:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 6153
train_sample_count: 6153
avg_envstep_per_episode: 166.2972972972973
avg_sample_per_episode: 166.2972972972973
avg_envstep_per_sec: 1695.3792865565747
avg_train_sample_per_sec: 1695.3792865565747
avg_episode_per_sec: 10.19486975501272
collect_time: 3.629276380093768
reward_mean: 1306.6690364815208
reward_std: 760.3932954014059
reward_max: 2782.9740094388853
reward_min: -261.7284581559204
total_envstep_count: 8615537
total_train_sample_count: 6848893
total_episode_count: 14034
total_duration: 1585.0146143934012
[2023-05-17 13:11:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 4760
train_sample_count: 4760
avg_envstep_per_episode: 132.22222222222223
avg_sample_per_episode: 132.22222222222223
avg_envstep_per_sec: 1623.4370715136756
avg_train_sample_per_sec: 1623.4370715136756
avg_episode_per_sec: 12.278095498842925
collect_time: 2.9320508220018815
reward_mean: 1497.6392472110508
reward_std: 629.687257477402
reward_max: 2686.957749470765
reward_min: 310.1516677021909
total_envstep_count: 8651265
total_train_sample_count: 6879253
total_episode_count: 14070
total_duration: 1587.946665215403
[2023-05-17 13:12:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 7731
train_sample_count: 7731
avg_envstep_per_episode: 198.23076923076923
avg_sample_per_episode: 198.23076923076923
avg_envstep_per_sec: 1668.333435295161
avg_train_sample_per_sec: 1668.333435295161
avg_episode_per_sec: 8.41611744619212
collect_time: 4.633965750756673
reward_mean: 1462.4200094763476
reward_std: 924.7018110756965
reward_max: 2861.431383244874
reward_min: -255.12361021843805
total_envstep_count: 8687857
total_train_sample_count: 6909384
total_episode_count: 14109
total_duration: 1592.5806309661598
[2023-05-17 13:12:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 8742
train_sample_count: 8742
avg_envstep_per_episode: 257.11764705882354
avg_sample_per_episode: 257.11764705882354
avg_envstep_per_sec: 1685.8501268182958
avg_train_sample_per_sec: 1685.8501268182958
avg_episode_per_sec: 6.55672664285313
collect_time: 5.185514335428365
reward_mean: 1591.4830939367337
reward_std: 852.7161396317933
reward_max: 2876.5429390301815
reward_min: -338.2967511991942
total_envstep_count: 8723265
total_train_sample_count: 6938926
total_episode_count: 14143
total_duration: 1597.766145301588
[2023-05-17 13:13:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10833
train_sample_count: 10833
avg_envstep_per_episode: 285.07894736842104
avg_sample_per_episode: 285.07894736842104
avg_envstep_per_sec: 1691.3308713972472
avg_train_sample_per_sec: 1691.3308713972472
avg_episode_per_sec: 5.932850836619163
collect_time: 6.40501523575373
reward_mean: 1430.064576315993
reward_std: 830.2002257231782
reward_max: 2703.8132719452187
reward_min: -89.39214781279749
total_envstep_count: 8759857
total_train_sample_count: 6968559
total_episode_count: 14181
total_duration: 1604.1711605373418
[2023-05-17 13:13:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 8742
train_sample_count: 8742
avg_envstep_per_episode: 257.11764705882354
avg_sample_per_episode: 257.11764705882354
avg_envstep_per_sec: 1641.4796041240825
avg_train_sample_per_sec: 1641.4796041240825
avg_episode_per_sec: 6.384157691628781
collect_time: 5.325682986274361
reward_mean: 1565.4996254321456
reward_std: 826.3667220060564
reward_max: 2882.0972487659874
reward_min: -87.81796671057688
total_envstep_count: 8795265
total_train_sample_count: 6998101
total_episode_count: 14215
total_duration: 1609.4968435236162
[2023-05-17 13:13:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 10833
train_sample_count: 10833
avg_envstep_per_episode: 285.07894736842104
avg_sample_per_episode: 285.07894736842104
avg_envstep_per_sec: 1691.9488267301879
avg_train_sample_per_sec: 1691.9488267301879
avg_episode_per_sec: 5.935018500484366
collect_time: 6.402675913630052
reward_mean: 1540.4765988993531
reward_std: 921.7240438015626
reward_max: 2878.463537420791
reward_min: -352.61711816340284
total_envstep_count: 8831857
total_train_sample_count: 7027734
total_episode_count: 14253
total_duration: 1615.8995194372462
[2023-05-17 13:14:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 7385
train_sample_count: 7385
avg_envstep_per_episode: 217.2058823529412
avg_sample_per_episode: 217.2058823529412
avg_envstep_per_sec: 1696.1407725914894
avg_train_sample_per_sec: 1696.1407725914894
avg_episode_per_sec: 7.808908093176796
collect_time: 4.354001813609286
reward_mean: 1487.600423629451
reward_std: 968.3240144347066
reward_max: 2790.612011361409
reward_min: -243.31820434796686
total_envstep_count: 8867184
total_train_sample_count: 7057119
total_episode_count: 14287
total_duration: 1620.2535212508556
[2023-05-17 13:14:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 7168
train_sample_count: 7168
avg_envstep_per_episode: 188.6315789473684
avg_sample_per_episode: 188.6315789473684
avg_envstep_per_sec: 1666.0251716751618
avg_train_sample_per_sec: 1666.0251716751618
avg_episode_per_sec: 8.832164693590423
collect_time: 4.3024560023860206
reward_mean: 1701.0524517256138
reward_std: 874.5114569169269
reward_max: 2924.9694986562004
reward_min: -540.7420143033083
total_envstep_count: 8903830
total_train_sample_count: 7086287
total_episode_count: 14325
total_duration: 1624.5559772532415
[2023-05-17 13:15:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 7329
train_sample_count: 7329
avg_envstep_per_episode: 209.4
avg_sample_per_episode: 209.4
avg_envstep_per_sec: 1745.9864113853703
avg_train_sample_per_sec: 1745.9864113853703
avg_episode_per_sec: 8.338043989423927
collect_time: 4.19762717064031
reward_mean: 1313.5531400925502
reward_std: 887.5698179766885
reward_max: 2690.3785222248507
reward_min: -413.6049709111437
total_envstep_count: 8939181
total_train_sample_count: 7115616
total_episode_count: 14360
total_duration: 1628.7536044238818
[2023-05-17 13:15:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 8264
train_sample_count: 8264
avg_envstep_per_episode: 223.35135135135135
avg_sample_per_episode: 223.35135135135135
avg_envstep_per_sec: 1684.0387607229522
avg_train_sample_per_sec: 1684.0387607229522
avg_episode_per_sec: 7.539863764127448
collect_time: 4.907250469966791
reward_mean: 1724.2834804888603
reward_std: 818.6424052131387
reward_max: 2845.0751158179482
reward_min: -85.51409411848665
total_envstep_count: 8975829
total_train_sample_count: 7145080
total_episode_count: 14397
total_duration: 1633.6608548938486
[2023-05-17 13:15:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 6756
train_sample_count: 6756
avg_envstep_per_episode: 187.66666666666666
avg_sample_per_episode: 187.66666666666666
avg_envstep_per_sec: 1754.5335992847818
avg_train_sample_per_sec: 1754.5335992847818
avg_episode_per_sec: 9.349202127627612
collect_time: 3.8505959662180405
reward_mean: 1291.1809934613157
reward_std: 908.3000366804652
reward_max: 2941.1306959134754
reward_min: -278.46789640055704
total_envstep_count: 9011181
total_train_sample_count: 7174636
total_episode_count: 14433
total_duration: 1637.5114508600666
[2023-05-17 13:16:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 6165
train_sample_count: 6165
avg_envstep_per_episode: 176.14285714285714
avg_sample_per_episode: 176.14285714285714
avg_envstep_per_sec: 1691.5526920789528
avg_train_sample_per_sec: 1691.5526920789528
avg_episode_per_sec: 9.60329995503055
collect_time: 3.6445805258499453
reward_mean: 1552.178259664511
reward_std: 905.7210847232055
reward_max: 2808.989600621107
reward_min: -295.8697775073429
total_envstep_count: 9047797
total_train_sample_count: 7204401
total_episode_count: 14468
total_duration: 1641.1560313859165
[2023-05-17 13:16:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 6444
train_sample_count: 6444
avg_envstep_per_episode: 174.16216216216216
avg_sample_per_episode: 174.16216216216216
avg_envstep_per_sec: 1664.3187407424168
avg_train_sample_per_sec: 1664.3187407424168
avg_episode_per_sec: 9.55614422834721
collect_time: 3.8718544965283934
reward_mean: 1408.6039901874692
reward_std: 954.3676243456699
reward_max: 2715.6945080288347
reward_min: -470.9626853481072
total_envstep_count: 9083181
total_train_sample_count: 7234045
total_episode_count: 14505
total_duration: 1645.027885882445
[2023-05-17 13:16:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 5928
train_sample_count: 5928
avg_envstep_per_episode: 164.66666666666666
avg_sample_per_episode: 164.66666666666666
avg_envstep_per_sec: 1689.8516682095553
avg_train_sample_per_sec: 1689.8516682095553
avg_episode_per_sec: 10.262257094390012
collect_time: 3.508000205888414
reward_mean: 1750.3942553980667
reward_std: 747.4351553287843
reward_max: 2957.6516235100835
reward_min: -56.5813069597766
total_envstep_count: 9119797
total_train_sample_count: 7263173
total_episode_count: 14541
total_duration: 1648.5358860883334
[2023-05-17 13:17:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 5493
train_sample_count: 5493
avg_envstep_per_episode: 152.58333333333334
avg_sample_per_episode: 152.58333333333334
avg_envstep_per_sec: 1660.0736283730375
avg_train_sample_per_sec: 1660.0736283730375
avg_episode_per_sec: 10.879783473771955
collect_time: 3.308889380637556
reward_mean: 1974.4508315698808
reward_std: 859.1882139259639
reward_max: 3029.9620807559154
reward_min: -445.2572472666045
total_envstep_count: 9155181
total_train_sample_count: 7292266
total_episode_count: 14577
total_duration: 1651.844775468971
[2023-05-17 13:17:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 12141
train_sample_count: 12141
avg_envstep_per_episode: 275.9318181818182
avg_sample_per_episode: 275.9318181818182
avg_envstep_per_sec: 1667.5664939802004
avg_train_sample_per_sec: 1667.5664939802004
avg_episode_per_sec: 6.043400521796295
collect_time: 7.280669192999601
reward_mean: 1509.3093269985648
reward_std: 904.4400690607329
reward_max: 3018.827822957156
reward_min: -138.33726347527596
total_envstep_count: 9197397
total_train_sample_count: 7322807
total_episode_count: 14621
total_duration: 1659.1254446619705
[2023-05-17 13:18:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 10165
train_sample_count: 10165
avg_envstep_per_episode: 242.02380952380952
avg_sample_per_episode: 242.02380952380952
avg_envstep_per_sec: 1716.9956876173192
avg_train_sample_per_sec: 1716.9956876173192
avg_episode_per_sec: 7.094325516962853
collect_time: 5.920224537142551
reward_mean: 1540.0690910351825
reward_std: 756.6877621363722
reward_max: 2636.304918515045
reward_min: -363.8324014401927
total_envstep_count: 9237597
total_train_sample_count: 7352972
total_episode_count: 14663
total_duration: 1665.045669199113
[2023-05-17 13:18:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 11245
train_sample_count: 11245
avg_envstep_per_episode: 281.125
avg_sample_per_episode: 281.125
avg_envstep_per_sec: 1650.2499296939693
avg_train_sample_per_sec: 1650.2499296939693
avg_episode_per_sec: 5.870164267475213
collect_time: 6.81411936317145
reward_mean: 1774.77773398997
reward_std: 687.2803940645964
reward_max: 2817.622976732147
reward_min: 359.7660233520397
total_envstep_count: 9275708
total_train_sample_count: 7382617
total_episode_count: 14703
total_duration: 1671.8597885622844
[2023-05-17 13:19:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 7909
train_sample_count: 7909
avg_envstep_per_episode: 225.97142857142856
avg_sample_per_episode: 225.97142857142856
avg_envstep_per_sec: 1613.3545955211798
avg_train_sample_per_sec: 1613.3545955211798
avg_episode_per_sec: 7.139639757648412
collect_time: 4.902208120865747
reward_mean: 1880.9572496042906
reward_std: 758.9967984552928
reward_max: 2789.5089669193685
reward_min: -114.02412861696008
total_envstep_count: 9313148
total_train_sample_count: 7412126
total_episode_count: 14738
total_duration: 1676.76199668315
[2023-05-17 13:19:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 11155
train_sample_count: 11155
avg_envstep_per_episode: 265.5952380952381
avg_sample_per_episode: 265.5952380952381
avg_envstep_per_sec: 1690.9532761341889
avg_train_sample_per_sec: 1690.9532761341889
avg_episode_per_sec: 6.3666550961574115
collect_time: 6.5968706276155995
reward_mean: 1905.0553931978498
reward_std: 864.8077283872129
reward_max: 2884.1265822646974
reward_min: -446.54607002334086
total_envstep_count: 9353148
total_train_sample_count: 7442081
total_episode_count: 14780
total_duration: 1683.3588673107656
[2023-05-17 13:19:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 12696
train_sample_count: 12696
avg_envstep_per_episode: 295.25581395348837
avg_sample_per_episode: 295.25581395348837
avg_envstep_per_sec: 1712.2949009001586
avg_train_sample_per_sec: 1712.2949009001586
avg_episode_per_sec: 5.799360486665629
collect_time: 7.41461064523738
reward_mean: 1594.9352404556864
reward_std: 842.5606466540386
reward_max: 2970.246312473019
reward_min: -369.6007701254148
total_envstep_count: 9394324
total_train_sample_count: 7472777
total_episode_count: 14823
total_duration: 1690.773477956003
[2023-05-17 13:20:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 12928
train_sample_count: 12928
avg_envstep_per_episode: 340.2105263157895
avg_sample_per_episode: 340.2105263157895
avg_envstep_per_sec: 1631.0344483212957
avg_train_sample_per_sec: 1631.0344483212957
avg_episode_per_sec: 4.794191602429551
collect_time: 7.926258095471769
reward_mean: 1929.942966075577
reward_std: 709.8564007919641
reward_max: 2801.0986298438193
reward_min: 89.0739704583039
total_envstep_count: 9431924
total_train_sample_count: 7502505
total_episode_count: 14861
total_duration: 1698.6997360514747
[2023-05-17 13:20:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 15645
train_sample_count: 15645
avg_envstep_per_episode: 411.7105263157895
avg_sample_per_episode: 411.7105263157895
avg_envstep_per_sec: 1653.1786491772239
avg_train_sample_per_sec: 1653.1786491772239
avg_episode_per_sec: 4.015390774607511
collect_time: 9.463587016313339
reward_mean: 1673.217220202033
reward_std: 756.7985526609015
reward_max: 2712.8193035704517
reward_min: -43.09210097481753
total_envstep_count: 9468596
total_train_sample_count: 7531750
total_episode_count: 14899
total_duration: 1708.163323067788
[2023-05-17 13:21:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 14185
train_sample_count: 14185
avg_envstep_per_episode: 405.2857142857143
avg_sample_per_episode: 405.2857142857143
avg_envstep_per_sec: 1652.3746000322053
avg_train_sample_per_sec: 1652.3746000322053
avg_episode_per_sec: 4.077061050484821
collect_time: 8.584615134923721
reward_mean: 1989.2611458563804
reward_std: 740.8728075361471
reward_max: 2857.8779458071413
reward_min: -35.04993317550233
total_envstep_count: 9505412
total_train_sample_count: 7561135
total_episode_count: 14934
total_duration: 1716.7479382027118
[2023-05-17 13:21:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 10607
train_sample_count: 10607
avg_envstep_per_episode: 258.7073170731707
avg_sample_per_episode: 258.7073170731707
avg_envstep_per_sec: 1702.1702010221243
avg_train_sample_per_sec: 1702.1702010221243
avg_episode_per_sec: 6.57952090524249
collect_time: 6.231456756575034
reward_mean: 1747.612897059088
reward_std: 939.0994568590702
reward_max: 2829.008788077317
reward_min: -244.99405886495015
total_envstep_count: 9545732
total_train_sample_count: 7591342
total_episode_count: 14975
total_duration: 1722.9793949592868
[2023-05-17 13:21:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 5964
train_sample_count: 5964
avg_envstep_per_episode: 161.1891891891892
avg_sample_per_episode: 161.1891891891892
avg_envstep_per_sec: 1680.7610939263957
avg_train_sample_per_sec: 1680.7610939263957
avg_episode_per_sec: 10.427256954271737
collect_time: 3.548392464313656
reward_mean: 1793.4389922682635
reward_std: 903.1818012041532
reward_max: 2847.181008543603
reward_min: -154.35184114820404
total_envstep_count: 9581780
total_train_sample_count: 7620506
total_episode_count: 15012
total_duration: 1726.5277874236003
[2023-05-17 13:22:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 5520
train_sample_count: 5520
avg_envstep_per_episode: 157.71428571428572
avg_sample_per_episode: 157.71428571428572
avg_envstep_per_sec: 1586.4136164223335
avg_train_sample_per_sec: 1586.4136164223335
avg_episode_per_sec: 10.058781988185086
collect_time: 3.4795465336767957
reward_mean: 1547.9500773192176
reward_std: 1091.9843003545566
reward_max: 2993.950200144222
reward_min: -505.4598005743909
total_envstep_count: 9617732
total_train_sample_count: 7649626
total_episode_count: 15047
total_duration: 1730.007333957277
[2023-05-17 13:22:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 5964
train_sample_count: 5964
avg_envstep_per_episode: 161.1891891891892
avg_sample_per_episode: 161.1891891891892
avg_envstep_per_sec: 1653.6292575530954
avg_train_sample_per_sec: 1653.6292575530954
avg_episode_per_sec: 10.258934025731813
collect_time: 3.606612529839389
reward_mean: 1766.6759755801331
reward_std: 955.6688431042128
reward_max: 2998.1906132571967
reward_min: -281.50099534556495
total_envstep_count: 9653780
total_train_sample_count: 7678790
total_episode_count: 15084
total_duration: 1733.6139464871164
[2023-05-17 13:23:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 5520
train_sample_count: 5520
avg_envstep_per_episode: 157.71428571428572
avg_sample_per_episode: 157.71428571428572
avg_envstep_per_sec: 1702.491886727649
avg_train_sample_per_sec: 1702.491886727649
avg_episode_per_sec: 10.794785513671687
collect_time: 3.242306200125255
reward_mean: 1734.0225857636187
reward_std: 1106.9841010121806
reward_max: 3030.298574389435
reward_min: -618.6109333075149
total_envstep_count: 9689732
total_train_sample_count: 7707910
total_episode_count: 15119
total_duration: 1736.8562526872417
[2023-05-17 13:23:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 5964
train_sample_count: 5964
avg_envstep_per_episode: 161.1891891891892
avg_sample_per_episode: 161.1891891891892
avg_envstep_per_sec: 1633.6385079731174
avg_train_sample_per_sec: 1633.6385079731174
avg_episode_per_sec: 10.134913614186006
collect_time: 3.650746460059658
reward_mean: 1804.954501976005
reward_std: 824.3466298261425
reward_max: 3035.422649336885
reward_min: 62.257960193595835
total_envstep_count: 9725780
total_train_sample_count: 7737074
total_episode_count: 15156
total_duration: 1740.5069991473015
[2023-05-17 13:23:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 5520
train_sample_count: 5520
avg_envstep_per_episode: 157.71428571428572
avg_sample_per_episode: 157.71428571428572
avg_envstep_per_sec: 1692.9441459901698
avg_train_sample_per_sec: 1692.9441459901698
avg_episode_per_sec: 10.734247302473902
collect_time: 3.260591917975806
reward_mean: 1890.719226687392
reward_std: 875.3860084845255
reward_max: 2994.6514946902316
reward_min: 158.52761311858512
total_envstep_count: 9761732
total_train_sample_count: 7766194
total_episode_count: 15191
total_duration: 1743.7675910652772
[2023-05-17 13:24:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 9069
train_sample_count: 9069
avg_envstep_per_episode: 232.53846153846155
avg_sample_per_episode: 232.53846153846155
avg_envstep_per_sec: 1616.9801137513307
avg_train_sample_per_sec: 1616.9801137513307
avg_episode_per_sec: 6.953602870912107
collect_time: 5.608603298750703
reward_mean: 1817.7718747313268
reward_std: 851.4294246650915
reward_max: 3054.721207648127
reward_min: 113.80139185595513
total_envstep_count: 9799260
total_train_sample_count: 7795663
total_episode_count: 15230
total_duration: 1749.376194364028
[2023-05-17 13:24:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 10762
train_sample_count: 10762
avg_envstep_per_episode: 275.94871794871796
avg_sample_per_episode: 275.94871794871796
avg_envstep_per_sec: 1716.7613390719712
avg_train_sample_per_sec: 1716.7613390719712
avg_episode_per_sec: 6.2213057260552755
collect_time: 6.268780496779831
reward_mean: 1637.0604782569405
reward_std: 756.0941406896019
reward_max: 2817.980124815855
reward_min: -198.6879177727723
total_envstep_count: 9836596
total_train_sample_count: 7825225
total_episode_count: 15269
total_duration: 1755.6449748608077
[2023-05-17 13:25:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 6150
train_sample_count: 6150
avg_envstep_per_episode: 175.71428571428572
avg_sample_per_episode: 175.71428571428572
avg_envstep_per_sec: 1716.6947736487575
avg_train_sample_per_sec: 1716.6947736487575
avg_episode_per_sec: 9.769807654911629
collect_time: 3.58246561613772
reward_mean: 1847.341233743757
reward_std: 823.4071632901293
reward_max: 2872.918176325009
reward_min: -97.84560780856222
total_envstep_count: 9873884
total_train_sample_count: 7854575
total_episode_count: 15304
total_duration: 1759.2274404769455
[2023-05-17 13:25:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 6834
train_sample_count: 6834
avg_envstep_per_episode: 175.23076923076923
avg_sample_per_episode: 175.23076923076923
avg_envstep_per_sec: 1716.8094045354478
avg_train_sample_per_sec: 1716.8094045354478
avg_episode_per_sec: 9.797419780053039
collect_time: 3.9806398904537774
reward_mean: 1682.4798966689868
reward_std: 1035.104345600198
reward_max: 2887.948371328385
reward_min: -489.3928103704479
total_envstep_count: 9910532
total_train_sample_count: 7883809
total_episode_count: 15343
total_duration: 1763.2080803673994
[2023-05-17 13:25:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 11250
train_sample_count: 11250
avg_envstep_per_episode: 281.25
avg_sample_per_episode: 281.25
avg_envstep_per_sec: 1641.5121232524602
avg_train_sample_per_sec: 1641.5121232524602
avg_episode_per_sec: 5.836487549342081
collect_time: 6.853437047854065
reward_mean: 1696.6403298094579
reward_std: 861.7230971911746
reward_max: 2824.9894362233285
reward_min: -441.7254113696099
total_envstep_count: 9951260
total_train_sample_count: 7913859
total_episode_count: 15383
total_duration: 1770.0615174152533
[2023-05-17 13:26:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 10614
train_sample_count: 10614
avg_envstep_per_episode: 265.35
avg_sample_per_episode: 265.35
avg_envstep_per_sec: 1735.7368402120164
avg_train_sample_per_sec: 1735.7368402120164
avg_episode_per_sec: 6.541310873231644
collect_time: 6.114982268108985
reward_mean: 1943.984078345431
reward_std: 805.9203181576703
reward_max: 2901.567411943823
reward_min: -831.9251859209432
total_envstep_count: 9991260
total_train_sample_count: 7943673
total_episode_count: 15423
total_duration: 1776.1764996833624
