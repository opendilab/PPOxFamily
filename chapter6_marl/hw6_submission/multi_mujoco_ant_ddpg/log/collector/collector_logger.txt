[2023-05-17 13:59:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 8000
train_sample_count: 8000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2578.1712369568872
avg_train_sample_per_sec: 2578.1712369568872
avg_episode_per_sec: 2.578171236956887
collect_time: 3.1029746532440186
reward_mean: -1891.003901326415
reward_std: 7.830546694928026
reward_max: -1881.0404304651647
reward_min: -1903.8991198060355
total_envstep_count: 8000
total_train_sample_count: 8000
total_episode_count: 8
total_duration: 3.1029746532440186
[2023-05-17 13:59:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 8000
train_sample_count: 8000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2463.9622078855614
avg_train_sample_per_sec: 2463.9622078855614
avg_episode_per_sec: 2.4639622078855616
collect_time: 3.246803045272827
reward_mean: -648.0293576357826
reward_std: 16.48727553762496
reward_max: -629.7000369952532
reward_min: -681.0581233220015
total_envstep_count: 16000
total_train_sample_count: 16000
total_episode_count: 16
total_duration: 6.349777698516846
[2023-05-17 13:59:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 727
train_sample_count: 727
avg_envstep_per_episode: 727.0
avg_sample_per_episode: 727.0
avg_envstep_per_sec: 2478.83455733515
avg_train_sample_per_sec: 2478.83455733515
avg_episode_per_sec: 3.409676144890165
collect_time: 0.29328298568725586
reward_mean: 427.4368819646697
reward_std: 0.0
reward_max: 427.4368819646697
reward_min: 427.4368819646697
total_envstep_count: 22223
total_train_sample_count: 22027
total_episode_count: 17
total_duration: 6.643060684204102
[2023-05-17 13:59:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2399.0470774881373
avg_train_sample_per_sec: 2399.0470774881373
avg_episode_per_sec: 2.3990470774881376
collect_time: 2.917825192213058
reward_mean: 515.7698526530379
reward_std: 69.07426388407292
reward_max: 645.5273401853193
reward_min: 418.52237281573605
total_envstep_count: 26223
total_train_sample_count: 26027
total_episode_count: 24
total_duration: 9.56088587641716
[2023-05-17 13:59:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 929.0
avg_sample_per_episode: 929.0
avg_envstep_per_sec: 2506.318432488223
avg_train_sample_per_sec: 2506.318432488223
avg_episode_per_sec: 2.697866988684847
collect_time: 0.37066319584846497
reward_mean: 732.8831725220593
reward_std: 0.0
reward_max: 732.8831725220593
reward_min: 732.8831725220593
total_envstep_count: 30398
total_train_sample_count: 30356
total_episode_count: 25
total_duration: 9.931549072265625
[2023-05-17 13:59:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2545.419925971388
avg_train_sample_per_sec: 2545.419925971388
avg_episode_per_sec: 2.545419925971388
collect_time: 2.7500374019145966
reward_mean: 887.3006582642234
reward_std: 37.053787838202986
reward_max: 946.7590459250399
reward_min: 837.0466982193992
total_envstep_count: 34398
total_train_sample_count: 34356
total_episode_count: 32
total_duration: 12.681586474180222
[2023-05-17 13:59:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1868.592742910031
avg_train_sample_per_sec: 1868.592742910031
avg_episode_per_sec: 1.8685927429100309
collect_time: 0.535162091255188
reward_mean: 868.6387944347662
reward_std: 0.0
reward_max: 868.6387944347662
reward_min: 868.6387944347662
total_envstep_count: 38397
total_train_sample_count: 38356
total_episode_count: 33
total_duration: 13.21674856543541
[2023-05-17 13:59:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2490.7107117866226
avg_train_sample_per_sec: 2490.7107117866226
avg_episode_per_sec: 2.4907107117866225
collect_time: 2.8104428052902217
reward_mean: 868.4510223605037
reward_std: 25.238787336896372
reward_max: 888.4859468422617
reward_min: 813.1625232524394
total_envstep_count: 42397
total_train_sample_count: 42356
total_episode_count: 40
total_duration: 16.02719137072563
[2023-05-17 13:59:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2418.633429878482
avg_train_sample_per_sec: 2418.633429878482
avg_episode_per_sec: 2.4186334298784815
collect_time: 0.41345661878585815
reward_mean: 873.8995344031903
reward_std: 0.0
reward_max: 873.8995344031903
reward_min: 873.8995344031903
total_envstep_count: 46396
total_train_sample_count: 46356
total_episode_count: 41
total_duration: 16.44064798951149
[2023-05-17 13:59:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2441.762015526037
avg_train_sample_per_sec: 2441.762015526037
avg_episode_per_sec: 2.441762015526037
collect_time: 2.8667822480201726
reward_mean: 854.8003643178541
reward_std: 4.432486735175595
reward_max: 863.7271569062742
reward_min: 849.9080662663113
total_envstep_count: 50396
total_train_sample_count: 50356
total_episode_count: 48
total_duration: 19.307430237531662
[2023-05-17 14:00:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2470.6223997464763
avg_train_sample_per_sec: 2470.6223997464763
avg_episode_per_sec: 2.470622399746476
collect_time: 0.4047563076019287
reward_mean: 866.5318386771753
reward_std: 0.0
reward_max: 866.5318386771753
reward_min: 866.5318386771753
total_envstep_count: 54395
total_train_sample_count: 54356
total_episode_count: 49
total_duration: 19.71218654513359
[2023-05-17 14:00:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2480.232266487884
avg_train_sample_per_sec: 2480.232266487884
avg_episode_per_sec: 2.4802322664878838
collect_time: 2.822316318750382
reward_mean: 869.9494166169635
reward_std: 7.506543352902594
reward_max: 879.2289063530143
reward_min: 858.8259594458501
total_envstep_count: 58395
total_train_sample_count: 58356
total_episode_count: 56
total_duration: 22.534502863883972
[2023-05-17 14:00:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2462.972177669071
avg_train_sample_per_sec: 2462.972177669071
avg_episode_per_sec: 2.4629721776690707
collect_time: 0.40601351857185364
reward_mean: 883.671979063495
reward_std: 0.0
reward_max: 883.671979063495
reward_min: 883.671979063495
total_envstep_count: 62394
total_train_sample_count: 62356
total_episode_count: 57
total_duration: 22.940516382455826
[2023-05-17 14:00:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2318.010601338949
avg_train_sample_per_sec: 2318.010601338949
avg_episode_per_sec: 2.318010601338949
collect_time: 3.0198308825492863
reward_mean: 870.4912429555425
reward_std: 9.237231984816248
reward_max: 877.3208718220623
reward_min: 849.1934076879866
total_envstep_count: 66394
total_train_sample_count: 66356
total_episode_count: 64
total_duration: 25.96034726500511
[2023-05-17 14:00:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2466.4017907460625
avg_train_sample_per_sec: 2466.4017907460625
avg_episode_per_sec: 2.4664017907460627
collect_time: 0.40544894337654114
reward_mean: 879.4943978676729
reward_std: 0.0
reward_max: 879.4943978676729
reward_min: 879.4943978676729
total_envstep_count: 70393
total_train_sample_count: 70356
total_episode_count: 65
total_duration: 26.365796208381653
[2023-05-17 14:00:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2443.2727599960685
avg_train_sample_per_sec: 2443.2727599960685
avg_episode_per_sec: 2.443272759996068
collect_time: 2.8650096356868744
reward_mean: 892.0865784516465
reward_std: 11.651049517751396
reward_max: 918.8058075301265
reward_min: 883.0366582917552
total_envstep_count: 74393
total_train_sample_count: 74356
total_episode_count: 72
total_duration: 29.230805844068527
[2023-05-17 14:00:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2472.4548904740313
avg_train_sample_per_sec: 2472.4548904740313
avg_episode_per_sec: 2.4724548904740313
collect_time: 0.40445631742477417
reward_mean: 898.1083601688389
reward_std: 0.0
reward_max: 898.1083601688389
reward_min: 898.1083601688389
total_envstep_count: 78392
total_train_sample_count: 78356
total_episode_count: 73
total_duration: 29.6352621614933
[2023-05-17 14:00:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2496.2759706077113
avg_train_sample_per_sec: 2496.2759706077113
avg_episode_per_sec: 2.4962759706077113
collect_time: 2.8041771352291107
reward_mean: 902.3270487857861
reward_std: 10.85736387071804
reward_max: 917.9578536065121
reward_min: 886.9678735678096
total_envstep_count: 82392
total_train_sample_count: 82356
total_episode_count: 80
total_duration: 32.43943929672241
[2023-05-17 14:00:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1575.3048117350952
avg_train_sample_per_sec: 1575.3048117350952
avg_episode_per_sec: 1.5753048117350952
collect_time: 0.6347977817058563
reward_mean: 884.8852717503544
reward_std: 0.0
reward_max: 884.8852717503544
reward_min: 884.8852717503544
total_envstep_count: 86391
total_train_sample_count: 86356
total_episode_count: 81
total_duration: 33.07423707842827
[2023-05-17 14:00:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2394.202499802353
avg_train_sample_per_sec: 2394.202499802353
avg_episode_per_sec: 2.3942024998023532
collect_time: 2.923729300498962
reward_mean: 914.7784012525308
reward_std: 13.597783565737112
reward_max: 938.8912705770064
reward_min: 893.3552769919875
total_envstep_count: 90391
total_train_sample_count: 90356
total_episode_count: 88
total_duration: 35.99796637892723
[2023-05-17 14:00:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2321.6845827916495
avg_train_sample_per_sec: 2321.6845827916495
avg_episode_per_sec: 2.3216845827916495
collect_time: 0.4307217299938202
reward_mean: 932.2532825456609
reward_std: 0.0
reward_max: 932.2532825456609
reward_min: 932.2532825456609
total_envstep_count: 94390
total_train_sample_count: 94356
total_episode_count: 89
total_duration: 36.42868810892105
[2023-05-17 14:00:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2434.384048900725
avg_train_sample_per_sec: 2434.384048900725
avg_episode_per_sec: 2.434384048900725
collect_time: 2.8754706978797917
reward_mean: 912.2639025245952
reward_std: 27.68854665057634
reward_max: 944.5583023157407
reward_min: 869.1567820204783
total_envstep_count: 98390
total_train_sample_count: 98356
total_episode_count: 96
total_duration: 39.30415880680084
[2023-05-17 14:00:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2359.17892574581
avg_train_sample_per_sec: 2359.17892574581
avg_episode_per_sec: 2.35917892574581
collect_time: 0.4238762855529785
reward_mean: 914.8675829294422
reward_std: 0.0
reward_max: 914.8675829294422
reward_min: 914.8675829294422
total_envstep_count: 102389
total_train_sample_count: 102356
total_episode_count: 97
total_duration: 39.72803509235382
[2023-05-17 14:01:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2366.515395930113
avg_train_sample_per_sec: 2366.515395930113
avg_episode_per_sec: 2.366515395930113
collect_time: 2.95793554186821
reward_mean: 895.1808322157119
reward_std: 15.431276855025649
reward_max: 922.9609582963274
reward_min: 874.7980221143503
total_envstep_count: 106389
total_train_sample_count: 106356
total_episode_count: 104
total_duration: 42.68597063422203
[2023-05-17 14:01:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2487.0337038610564
avg_train_sample_per_sec: 2487.0337038610564
avg_episode_per_sec: 2.4870337038610564
collect_time: 0.40208542346954346
reward_mean: 832.9957886012592
reward_std: 0.0
reward_max: 832.9957886012592
reward_min: 832.9957886012592
total_envstep_count: 110388
total_train_sample_count: 110356
total_episode_count: 105
total_duration: 43.088056057691574
[2023-05-17 14:01:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2255.059154865157
avg_train_sample_per_sec: 2255.059154865157
avg_episode_per_sec: 2.255059154865157
collect_time: 3.104131430387497
reward_mean: 819.478440211259
reward_std: 16.132684714611827
reward_max: 837.2178023473772
reward_min: 789.5608444764861
total_envstep_count: 114388
total_train_sample_count: 114356
total_episode_count: 112
total_duration: 46.19218748807907
[2023-05-17 14:01:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2458.2403067830337
avg_train_sample_per_sec: 2458.2403067830337
avg_episode_per_sec: 2.458240306783034
collect_time: 0.40679505467414856
reward_mean: 830.8249070957714
reward_std: 0.0
reward_max: 830.8249070957714
reward_min: 830.8249070957714
total_envstep_count: 118387
total_train_sample_count: 118356
total_episode_count: 113
total_duration: 46.59898254275322
[2023-05-17 14:01:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2550.9298504951794
avg_train_sample_per_sec: 2550.9298504951794
avg_episode_per_sec: 2.5509298504951796
collect_time: 2.7440974116325383
reward_mean: 845.6604719109113
reward_std: 5.614349725082772
reward_max: 856.5222785238474
reward_min: 836.3587413900786
total_envstep_count: 122387
total_train_sample_count: 122356
total_episode_count: 120
total_duration: 49.34307995438576
[2023-05-17 14:01:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2584.1453319287093
avg_train_sample_per_sec: 2584.1453319287093
avg_episode_per_sec: 2.5841453319287093
collect_time: 0.38697513937950134
reward_mean: 876.3481602233148
reward_std: 0.0
reward_max: 876.3481602233148
reward_min: 876.3481602233148
total_envstep_count: 126386
total_train_sample_count: 126356
total_episode_count: 121
total_duration: 49.73005509376526
[2023-05-17 14:01:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 7000
train_sample_count: 7000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2632.9346108585455
avg_train_sample_per_sec: 2632.9346108585455
avg_episode_per_sec: 2.632934610858545
collect_time: 2.658630400896073
reward_mean: 877.9087765192523
reward_std: 8.824743225862761
reward_max: 888.9632652662045
reward_min: 864.6412722585314
total_envstep_count: 130386
total_train_sample_count: 130356
total_episode_count: 128
total_duration: 52.38868549466133
[2023-05-17 14:01:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1559
train_sample_count: 1559
avg_envstep_per_episode: 779.5
avg_sample_per_episode: 779.5
avg_envstep_per_sec: 2597.7584660182656
avg_train_sample_per_sec: 2597.7584660182656
avg_episode_per_sec: 3.332595851210091
collect_time: 0.6001327761581966
reward_mean: 688.6872230169363
reward_std: 198.55660186485912
reward_max: 887.2438248817954
reward_min: 490.13062115207714
total_envstep_count: 134464
total_train_sample_count: 134365
total_episode_count: 130
total_duration: 52.98881827081953
[2023-05-17 14:01:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2606.7837945188544
avg_train_sample_per_sec: 2606.7837945188544
avg_episode_per_sec: 2.6067837945188543
collect_time: 2.3016868574278697
reward_mean: 888.7405701921061
reward_std: 7.053789497860804
reward_max: 898.5797420721839
reward_min: 875.6870114137322
total_envstep_count: 138464
total_train_sample_count: 138365
total_episode_count: 136
total_duration: 55.290505128247396
[2023-05-17 14:01:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2612.1941156046555
avg_train_sample_per_sec: 2612.1941156046555
avg_episode_per_sec: 2.6121941156046553
collect_time: 0.7656398841312954
reward_mean: 891.050864539067
reward_std: 7.370012036103049
reward_max: 898.42087657517
reward_min: 883.680852502964
total_envstep_count: 142463
total_train_sample_count: 142365
total_episode_count: 138
total_duration: 56.05614501237869
[2023-05-17 14:01:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2612.1254114999856
avg_train_sample_per_sec: 2612.1254114999856
avg_episode_per_sec: 2.612125411499986
collect_time: 2.29698006595884
reward_mean: 899.7672823078492
reward_std: 9.50904851383033
reward_max: 910.9113721096336
reward_min: 882.4900659025938
total_envstep_count: 146463
total_train_sample_count: 146365
total_episode_count: 144
total_duration: 58.353125078337534
[2023-05-17 14:01:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1920.885178763029
avg_train_sample_per_sec: 1920.885178763029
avg_episode_per_sec: 1.920885178763029
collect_time: 1.041186647755759
reward_mean: 896.6206802225623
reward_std: 8.079659676202368
reward_max: 904.7003398987647
reward_min: 888.54102054636
total_envstep_count: 150462
total_train_sample_count: 150365
total_episode_count: 146
total_duration: 59.39431172609329
[2023-05-17 14:01:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2604.8881164508557
avg_train_sample_per_sec: 2604.8881164508557
avg_episode_per_sec: 2.604888116450856
collect_time: 2.303361884185246
reward_mean: 907.1680627282027
reward_std: 8.780086924951492
reward_max: 919.3136069757069
reward_min: 895.5517439534622
total_envstep_count: 154462
total_train_sample_count: 154365
total_episode_count: 152
total_duration: 61.697673610278535
[2023-05-17 14:02:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2595.156309036911
avg_train_sample_per_sec: 2595.156309036911
avg_episode_per_sec: 2.595156309036911
collect_time: 0.7706664885793413
reward_mean: 914.5971073233405
reward_std: 12.082767443986654
reward_max: 926.6798747673272
reward_min: 902.5143398793539
total_envstep_count: 158461
total_train_sample_count: 158365
total_episode_count: 154
total_duration: 62.46834009885788
[2023-05-17 14:02:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2627.975515045842
avg_train_sample_per_sec: 2627.975515045842
avg_episode_per_sec: 2.627975515045842
collect_time: 2.2831262946128845
reward_mean: 925.419660090372
reward_std: 8.071159134774572
reward_max: 935.570683892564
reward_min: 914.1274995188446
total_envstep_count: 162461
total_train_sample_count: 162365
total_episode_count: 160
total_duration: 64.75146639347076
[2023-05-17 14:02:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2593.2738048866745
avg_train_sample_per_sec: 2593.2738048866745
avg_episode_per_sec: 2.5932738048866746
collect_time: 0.7712259292602539
reward_mean: 936.6269996007268
reward_std: 3.5849053760495053
reward_max: 940.2119049767763
reward_min: 933.0420942246773
total_envstep_count: 166460
total_train_sample_count: 166365
total_episode_count: 162
total_duration: 65.52269232273102
[2023-05-17 14:02:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2646.8657351393176
avg_train_sample_per_sec: 2646.8657351393176
avg_episode_per_sec: 2.646865735139318
collect_time: 2.2668320196015497
reward_mean: 932.6868102736602
reward_std: 20.28082356977564
reward_max: 959.3825973615325
reward_min: 894.3321193840372
total_envstep_count: 170460
total_train_sample_count: 170365
total_episode_count: 168
total_duration: 67.78952434233257
[2023-05-17 14:02:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2622.426058539344
avg_train_sample_per_sec: 2622.426058539344
avg_episode_per_sec: 2.622426058539344
collect_time: 0.7626525802271706
reward_mean: 933.9137794032495
reward_std: 2.2801167069425787
reward_max: 936.1938961101921
reward_min: 931.6336626963069
total_envstep_count: 174459
total_train_sample_count: 174365
total_episode_count: 170
total_duration: 68.55217692255974
[2023-05-17 14:02:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2667.6664516813908
avg_train_sample_per_sec: 2667.6664516813908
avg_episode_per_sec: 2.6676664516813906
collect_time: 2.2491567475455145
reward_mean: 855.8120662878581
reward_std: 21.39357184017885
reward_max: 891.6459194976686
reward_min: 829.4528913265056
total_envstep_count: 178459
total_train_sample_count: 178365
total_episode_count: 176
total_duration: 70.80133367010525
[2023-05-17 14:02:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2623.171717842592
avg_train_sample_per_sec: 2623.171717842592
avg_episode_per_sec: 2.6231717178425917
collect_time: 0.7624357896191734
reward_mean: 857.7223813080932
reward_std: 0.5390280465960586
reward_max: 858.2614093546892
reward_min: 857.1833532614971
total_envstep_count: 182458
total_train_sample_count: 182365
total_episode_count: 178
total_duration: 71.56376945972443
[2023-05-17 14:02:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2388.7805746664217
avg_train_sample_per_sec: 2388.7805746664217
avg_episode_per_sec: 2.3887805746664212
collect_time: 2.51174179145268
reward_mean: 823.5917169315438
reward_std: 22.421563791473293
reward_max: 863.2257233158073
reward_min: 800.7619370865652
total_envstep_count: 186458
total_train_sample_count: 186365
total_episode_count: 184
total_duration: 74.0755112511771
[2023-05-17 14:02:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 806.6666666666666
avg_sample_per_episode: 806.6666666666666
avg_envstep_per_sec: 2716.3656885133664
avg_train_sample_per_sec: 2716.3656885133664
avg_episode_per_sec: 3.36739548162814
collect_time: 0.890896247965949
reward_mean: 622.074937663596
reward_std: 158.36578697587757
reward_max: 805.586480186973
reward_min: 419.13365004635125
total_envstep_count: 190583
total_train_sample_count: 190435
total_episode_count: 187
total_duration: 74.96640749914306
[2023-05-17 14:02:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 4889
train_sample_count: 4889
avg_envstep_per_episode: 814.8333333333334
avg_sample_per_episode: 814.8333333333334
avg_envstep_per_sec: 2742.85311301342
avg_train_sample_per_sec: 2742.85311301342
avg_episode_per_sec: 3.366152317054719
collect_time: 1.7824505354676932
reward_mean: 680.7644805691888
reward_std: 317.66973134608315
reward_max: 963.9281162585809
reward_min: -3.8228372052993884
total_envstep_count: 194701
total_train_sample_count: 194474
total_episode_count: 193
total_duration: 76.74885803461075
[2023-05-17 14:02:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2749.215261336773
avg_train_sample_per_sec: 2749.215261336773
avg_episode_per_sec: 2.749215261336773
collect_time: 1.0912204810551234
reward_mean: 811.6483379327224
reward_std: 29.15057328245274
reward_max: 843.0231917728238
reward_min: 772.8017272203253
total_envstep_count: 198698
total_train_sample_count: 198474
total_episode_count: 196
total_duration: 77.84007851566587
[2023-05-17 14:02:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2729.7168130581717
avg_train_sample_per_sec: 2729.7168130581717
avg_episode_per_sec: 2.7297168130581717
collect_time: 1.8316918356078014
reward_mean: 802.5261397966021
reward_std: 18.7655639896489
reward_max: 833.0708530563795
reward_min: 778.8837321280581
total_envstep_count: 202698
total_train_sample_count: 202474
total_episode_count: 201
total_duration: 79.67177035127366
[2023-05-17 14:02:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2659.3067071510736
avg_train_sample_per_sec: 2659.3067071510736
avg_episode_per_sec: 2.6593067071510736
collect_time: 1.1281135763440813
reward_mean: 939.4720252460717
reward_std: 16.902218487567904
reward_max: 960.8740041101211
reward_min: 919.5518189151281
total_envstep_count: 206695
total_train_sample_count: 206474
total_episode_count: 204
total_duration: 80.79988392761774
[2023-05-17 14:03:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2640.7233636495325
avg_train_sample_per_sec: 2640.7233636495325
avg_episode_per_sec: 2.6407233636495326
collect_time: 1.893420594079154
reward_mean: 826.6874554706462
reward_std: 55.82212933042929
reward_max: 907.9807022339558
reward_min: 741.7199552297866
total_envstep_count: 210695
total_train_sample_count: 210474
total_episode_count: 209
total_duration: 82.6933045216969
[2023-05-17 14:03:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2109.451938012799
avg_train_sample_per_sec: 2109.451938012799
avg_episode_per_sec: 2.109451938012799
collect_time: 1.4221703495298113
reward_mean: 796.5049521185537
reward_std: 22.698344757997805
reward_max: 827.063787021889
reward_min: 772.7143367992288
total_envstep_count: 214692
total_train_sample_count: 214474
total_episode_count: 212
total_duration: 84.11547487122671
[2023-05-17 14:03:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2628.970745382531
avg_train_sample_per_sec: 2628.970745382531
avg_episode_per_sec: 2.6289707453825306
collect_time: 1.9018849900790624
reward_mean: 868.4166138175858
reward_std: 46.79862352203183
reward_max: 911.6808914684771
reward_min: 785.1811521558537
total_envstep_count: 218692
total_train_sample_count: 218474
total_episode_count: 217
total_duration: 86.01735986130578
[2023-05-17 14:03:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2525.7674073002345
avg_train_sample_per_sec: 2525.7674073002345
avg_episode_per_sec: 2.5257674073002345
collect_time: 1.1877578241484505
reward_mean: 780.9937367317598
reward_std: 22.996207870465796
reward_max: 813.3417326087649
reward_min: 761.9139279445513
total_envstep_count: 222689
total_train_sample_count: 222474
total_episode_count: 220
total_duration: 87.20511768545423
[2023-05-17 14:03:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2514.279564163527
avg_train_sample_per_sec: 2514.279564163527
avg_episode_per_sec: 2.514279564163527
collect_time: 1.9886412279946462
reward_mean: 845.4602698811437
reward_std: 45.41193407361862
reward_max: 896.7906762051881
reward_min: 774.080759412359
total_envstep_count: 226689
total_train_sample_count: 226474
total_episode_count: 225
total_duration: 89.19375891344887
[2023-05-17 14:03:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2607.673299098716
avg_train_sample_per_sec: 2607.673299098716
avg_episode_per_sec: 2.607673299098716
collect_time: 1.1504508640084947
reward_mean: 863.9811566391131
reward_std: 31.07840743946214
reward_max: 899.8687927889878
reward_min: 824.0632790361668
total_envstep_count: 230686
total_train_sample_count: 230474
total_episode_count: 228
total_duration: 90.34420977745737
[2023-05-17 14:03:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2612.0496291091413
avg_train_sample_per_sec: 2612.0496291091413
avg_episode_per_sec: 2.612049629109141
collect_time: 1.9142055894647327
reward_mean: 874.3810576243993
reward_std: 18.791203432093234
reward_max: 903.2647253337057
reward_min: 848.8256990084699
total_envstep_count: 234686
total_train_sample_count: 234474
total_episode_count: 233
total_duration: 92.2584153669221
[2023-05-17 14:03:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 3887
train_sample_count: 3887
avg_envstep_per_episode: 647.8333333333334
avg_sample_per_episode: 647.8333333333334
avg_envstep_per_sec: 2618.07234640174
avg_train_sample_per_sec: 2618.07234640174
avg_episode_per_sec: 4.0412745249319375
collect_time: 1.484680133206504
reward_mean: 580.1096698314934
reward_std: 374.79770308832946
reward_max: 953.9308982869666
reward_min: 33.31799071882632
total_envstep_count: 238888
total_train_sample_count: 238711
total_episode_count: 239
total_duration: 93.7430955001286
[2023-05-17 14:03:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2626.286818185208
avg_train_sample_per_sec: 2626.286818185208
avg_episode_per_sec: 2.6262868181852084
collect_time: 1.5230628933225359
reward_mean: 891.6680944919036
reward_std: 39.17056980709379
reward_max: 926.8526607873422
reward_min: 826.2711077150587
total_envstep_count: 242888
total_train_sample_count: 242711
total_episode_count: 243
total_duration: 95.26615839345114
[2023-05-17 14:03:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4055
train_sample_count: 4055
avg_envstep_per_episode: 811.0
avg_sample_per_episode: 811.0
avg_envstep_per_sec: 2217.3706952325506
avg_train_sample_per_sec: 2217.3706952325506
avg_episode_per_sec: 2.7341192296332313
collect_time: 1.8287424870899744
reward_mean: 714.3626429386003
reward_std: 334.0432608845229
reward_max: 922.7511558893684
reward_min: 50.144216329407044
total_envstep_count: 246885
total_train_sample_count: 246716
total_episode_count: 248
total_duration: 97.0949008805411
[2023-05-17 14:03:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2601.8335579945374
avg_train_sample_per_sec: 2601.8335579945374
avg_episode_per_sec: 2.6018335579945373
collect_time: 1.5373773574829102
reward_mean: 840.1428033203396
reward_std: 63.08827431946171
reward_max: 933.5173455957813
reward_min: 771.1521099593886
total_envstep_count: 250885
total_train_sample_count: 250716
total_episode_count: 252
total_duration: 98.63227823802401
[2023-05-17 14:03:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4128
train_sample_count: 4128
avg_envstep_per_episode: 825.6
avg_sample_per_episode: 825.6
avg_envstep_per_sec: 2574.5394473413594
avg_train_sample_per_sec: 2574.5394473413594
avg_episode_per_sec: 3.118385958504554
collect_time: 1.6033935717173986
reward_mean: 688.2849448256433
reward_std: 282.31646813146756
reward_max: 847.1818630734489
reward_min: 123.98406139407886
total_envstep_count: 254921
total_train_sample_count: 254744
total_episode_count: 257
total_duration: 100.23567180974142
[2023-05-17 14:03:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4365
train_sample_count: 4365
avg_envstep_per_episode: 873.0
avg_sample_per_episode: 873.0
avg_envstep_per_sec: 2535.089724841288
avg_train_sample_per_sec: 2535.089724841288
avg_episode_per_sec: 2.9038828463244997
collect_time: 1.721832547869001
reward_mean: 705.7936631020814
reward_std: 195.0576270688363
reward_max: 873.3416049846908
reward_min: 323.4979937538214
total_envstep_count: 258920
total_train_sample_count: 258759
total_episode_count: 262
total_duration: 101.95750435761042
[2023-05-17 14:04:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2490.214937011944
avg_train_sample_per_sec: 2490.214937011944
avg_episode_per_sec: 2.490214937011944
collect_time: 1.2047152859824046
reward_mean: 885.5648577187899
reward_std: 18.73620831930458
reward_max: 911.8355166875563
reward_min: 869.4366013581453
total_envstep_count: 262918
total_train_sample_count: 262759
total_episode_count: 265
total_duration: 103.16221964359282
[2023-05-17 14:04:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2434.9440481572774
avg_train_sample_per_sec: 2434.9440481572774
avg_episode_per_sec: 2.4349440481572775
collect_time: 2.053435274532863
reward_mean: 816.6673152271763
reward_std: 39.95967920350292
reward_max: 854.8202849056482
reward_min: 741.6370646998628
total_envstep_count: 266917
total_train_sample_count: 266759
total_episode_count: 270
total_duration: 105.21565491812568
[2023-05-17 14:04:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2356.275817173617
avg_train_sample_per_sec: 2356.275817173617
avg_episode_per_sec: 2.3562758171736164
collect_time: 1.2731955988066537
reward_mean: 831.0083298534682
reward_std: 25.949718398823013
reward_max: 866.0207967820653
reward_min: 803.9796388729745
total_envstep_count: 270915
total_train_sample_count: 270759
total_episode_count: 273
total_duration: 106.48885051693233
[2023-05-17 14:04:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2344.440381306713
avg_train_sample_per_sec: 2344.440381306713
avg_episode_per_sec: 2.344440381306713
collect_time: 2.1327051179749628
reward_mean: 803.1476266210797
reward_std: 37.781384878198686
reward_max: 874.0801650257421
reward_min: 765.6999061807155
total_envstep_count: 274914
total_train_sample_count: 274759
total_episode_count: 278
total_duration: 108.6215556349073
[2023-05-17 14:04:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2421.9534355840924
avg_train_sample_per_sec: 2421.9534355840924
avg_episode_per_sec: 2.4219534355840926
collect_time: 1.2386695614882879
reward_mean: 911.211224524145
reward_std: 16.510765523297966
reward_max: 926.8047240932005
reward_min: 888.3632241058531
total_envstep_count: 278912
total_train_sample_count: 278759
total_episode_count: 281
total_duration: 109.86022519639559
[2023-05-17 14:04:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2431.648177159043
avg_train_sample_per_sec: 2431.648177159043
avg_episode_per_sec: 2.4316481771590426
collect_time: 2.05621851342065
reward_mean: 860.232020446362
reward_std: 17.712538208135328
reward_max: 887.1875105029702
reward_min: 838.8167815965016
total_envstep_count: 282911
total_train_sample_count: 282759
total_episode_count: 286
total_duration: 111.91644370981624
[2023-05-17 14:04:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2014.6656982147442
avg_train_sample_per_sec: 2014.6656982147442
avg_episode_per_sec: 2.014665698214744
collect_time: 1.4890807952199663
reward_mean: 875.8521913812098
reward_std: 25.541564482804553
reward_max: 899.2210131277515
reward_min: 840.3144599429177
total_envstep_count: 286909
total_train_sample_count: 286759
total_episode_count: 289
total_duration: 113.4055245050362
[2023-05-17 14:04:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2512.7197269840926
avg_train_sample_per_sec: 2512.7197269840926
avg_episode_per_sec: 2.5127197269840926
collect_time: 1.989875729594912
reward_mean: 824.8395667265297
reward_std: 58.52519309249617
reward_max: 892.425447284232
reward_min: 746.298198501308
total_envstep_count: 290909
total_train_sample_count: 290759
total_episode_count: 294
total_duration: 115.39540023463111
[2023-05-17 14:04:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2578.223393609068
avg_train_sample_per_sec: 2578.223393609068
avg_episode_per_sec: 2.578223393609068
collect_time: 1.1635919553892953
reward_mean: 862.5150691777354
reward_std: 13.742192139942425
reward_max: 881.5313612209032
reward_min: 849.5345687800317
total_envstep_count: 294907
total_train_sample_count: 294759
total_episode_count: 297
total_duration: 116.5589921900204
[2023-05-17 14:04:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2589.7140833162607
avg_train_sample_per_sec: 2589.7140833162607
avg_episode_per_sec: 2.5897140833162604
collect_time: 1.9307150670460291
reward_mean: 897.8778715966495
reward_std: 52.00627952409795
reward_max: 986.7057256297613
reward_min: 836.0043853529984
total_envstep_count: 298906
total_train_sample_count: 298759
total_episode_count: 302
total_duration: 118.48970725706643
[2023-05-17 14:04:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3059
train_sample_count: 3059
avg_envstep_per_episode: 764.75
avg_sample_per_episode: 764.75
avg_envstep_per_sec: 2631.923005686982
avg_train_sample_per_sec: 2631.923005686982
avg_episode_per_sec: 3.4415469181915426
collect_time: 1.162268042564392
reward_mean: 678.9800141671174
reward_std: 357.4206641576408
reward_max: 907.5302827315835
reward_min: 60.363706117830205
total_envstep_count: 302960
total_train_sample_count: 302768
total_episode_count: 306
total_duration: 119.65197529963082
[2023-05-17 14:04:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2612.9563606062343
avg_train_sample_per_sec: 2612.9563606062343
avg_episode_per_sec: 2.6129563606062343
collect_time: 1.9135413340159824
reward_mean: 847.7969471771361
reward_std: 50.15063475356101
reward_max: 908.448266335925
reward_min: 792.5372516438144
total_envstep_count: 306959
total_train_sample_count: 306768
total_episode_count: 311
total_duration: 121.56551663364681
[2023-05-17 14:04:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2626.0914840805485
avg_train_sample_per_sec: 2626.0914840805485
avg_episode_per_sec: 2.6260914840805487
collect_time: 1.1423821364130293
reward_mean: 853.656116398599
reward_std: 31.02827988961025
reward_max: 877.5378093282833
reward_min: 809.8345581087178
total_envstep_count: 310957
total_train_sample_count: 310768
total_episode_count: 314
total_duration: 122.70789877005984
[2023-05-17 14:05:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2613.7627138003068
avg_train_sample_per_sec: 2613.7627138003068
avg_episode_per_sec: 2.613762713800307
collect_time: 1.9129510010991777
reward_mean: 801.7262170671837
reward_std: 32.20413055746461
reward_max: 842.3269061408114
reward_min: 744.26455416769
total_envstep_count: 314956
total_train_sample_count: 314768
total_episode_count: 319
total_duration: 124.62084977115902
[2023-05-17 14:05:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 4814
train_sample_count: 4814
avg_envstep_per_episode: 687.7142857142857
avg_sample_per_episode: 687.7142857142857
avg_envstep_per_sec: 2137.4655781013744
avg_train_sample_per_sec: 2137.4655781013744
avg_episode_per_sec: 3.1080720911320356
collect_time: 2.2522000116961345
reward_mean: 573.1874950644411
reward_std: 292.6415080566368
reward_max: 858.5027049175904
reward_min: 108.86390401719775
total_envstep_count: 319062
total_train_sample_count: 318832
total_episode_count: 326
total_duration: 126.87304978285515
[2023-05-17 14:05:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2421.7684192533025
avg_train_sample_per_sec: 2421.7684192533025
avg_episode_per_sec: 2.4217684192533024
collect_time: 1.2387641923768178
reward_mean: 876.6662011832594
reward_std: 52.38387682749166
reward_max: 944.4084804756275
reward_min: 816.8269363751999
total_envstep_count: 323061
total_train_sample_count: 322832
total_episode_count: 329
total_duration: 128.11181397523197
[2023-05-17 14:05:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5770
train_sample_count: 5770
avg_envstep_per_episode: 961.6666666666666
avg_sample_per_episode: 961.6666666666666
avg_envstep_per_sec: 2469.225005841724
avg_train_sample_per_sec: 2469.225005841724
avg_episode_per_sec: 2.5676516525217234
collect_time: 2.3367655788149158
reward_mean: 819.8585302697344
reward_std: 94.51762419677489
reward_max: 931.6126379218889
reward_min: 650.8776667913185
total_envstep_count: 327056
total_train_sample_count: 326852
total_episode_count: 335
total_duration: 130.4485795540469
[2023-05-17 14:05:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2535.1858199023195
avg_train_sample_per_sec: 2535.1858199023195
avg_episode_per_sec: 2.5351858199023196
collect_time: 0.7888968076024738
reward_mean: 897.426586152859
reward_std: 56.70517209511547
reward_max: 954.1317582479745
reward_min: 840.7214140577436
total_envstep_count: 331054
total_train_sample_count: 330852
total_episode_count: 337
total_duration: 131.23747636164936
[2023-05-17 14:05:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2589.953950063098
avg_train_sample_per_sec: 2589.953950063098
avg_episode_per_sec: 2.5899539500630984
collect_time: 2.3166435062885284
reward_mean: 905.90110713904
reward_std: 75.91712907489926
reward_max: 1009.4762771486155
reward_min: 767.0034641332046
total_envstep_count: 335049
total_train_sample_count: 334852
total_episode_count: 343
total_duration: 133.55411986793789
[2023-05-17 14:05:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2606.0189555431557
avg_train_sample_per_sec: 2606.0189555431557
avg_episode_per_sec: 2.606018955543156
collect_time: 0.7674541260514941
reward_mean: 839.3720317206528
reward_std: 20.87250351470408
reward_max: 860.2445352353568
reward_min: 818.4995282059486
total_envstep_count: 339047
total_train_sample_count: 338852
total_episode_count: 345
total_duration: 134.32157399398938
[2023-05-17 14:05:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2371.8116224230703
avg_train_sample_per_sec: 2371.8116224230703
avg_episode_per_sec: 2.3718116224230705
collect_time: 2.529711863824299
reward_mean: 923.8003955370186
reward_std: 24.50830883020708
reward_max: 958.8631309207107
reward_min: 891.5559131389354
total_envstep_count: 343043
total_train_sample_count: 342852
total_episode_count: 351
total_duration: 136.85128585781368
[2023-05-17 14:05:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2373.4507290353877
avg_train_sample_per_sec: 2373.4507290353877
avg_episode_per_sec: 2.3734507290353877
collect_time: 0.8426549477236611
reward_mean: 883.0827691001225
reward_std: 17.118003627800533
reward_max: 900.200772727923
reward_min: 865.9647654723219
total_envstep_count: 347041
total_train_sample_count: 346852
total_episode_count: 353
total_duration: 137.69394080553735
[2023-05-17 14:05:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2060.6272772527673
avg_train_sample_per_sec: 2060.6272772527673
avg_episode_per_sec: 2.060627277252767
collect_time: 2.9117347257477895
reward_mean: 900.507327332722
reward_std: 36.2103991088548
reward_max: 946.3496030893657
reward_min: 859.3938569269247
total_envstep_count: 351037
total_train_sample_count: 350852
total_episode_count: 359
total_duration: 140.60567553128513
[2023-05-17 14:05:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2245.9465183257075
avg_train_sample_per_sec: 2245.9465183257075
avg_episode_per_sec: 2.2459465183257077
collect_time: 0.8904931545257568
reward_mean: 920.1852963164688
reward_std: 37.49999619625481
reward_max: 957.6852925127235
reward_min: 882.6853001202139
total_envstep_count: 355035
total_train_sample_count: 354852
total_episode_count: 361
total_duration: 141.4961686858109
[2023-05-17 14:05:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2413.656294327907
avg_train_sample_per_sec: 2413.656294327907
avg_episode_per_sec: 2.413656294327907
collect_time: 2.4858551791736057
reward_mean: 909.3002127838489
reward_std: 23.28177538648697
reward_max: 955.122286476318
reward_min: 879.750500752749
total_envstep_count: 359031
total_train_sample_count: 358852
total_episode_count: 367
total_duration: 143.98202386498448
[2023-05-17 14:06:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2454.577365014117
avg_train_sample_per_sec: 2454.577365014117
avg_episode_per_sec: 2.454577365014117
collect_time: 0.8148042219025748
reward_mean: 926.556275084147
reward_std: 12.613714449998781
reward_max: 939.1699895341459
reward_min: 913.9425606341483
total_envstep_count: 363029
total_train_sample_count: 362852
total_episode_count: 369
total_duration: 144.79682808688705
[2023-05-17 14:06:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2270.714780315635
avg_train_sample_per_sec: 2270.714780315635
avg_episode_per_sec: 2.270714780315635
collect_time: 2.6423397830554416
reward_mean: 908.9886845262517
reward_std: 24.890769208753778
reward_max: 947.9932216730315
reward_min: 873.7704656719017
total_envstep_count: 367025
total_train_sample_count: 366852
total_episode_count: 375
total_duration: 147.43916786994248
[2023-05-17 14:06:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2223.5161394755573
avg_train_sample_per_sec: 2223.5161394755573
avg_episode_per_sec: 2.2235161394755574
collect_time: 0.8994762684617723
reward_mean: 883.1397919927027
reward_std: 0.6412461436187868
reward_max: 883.7810381363215
reward_min: 882.4985458490839
total_envstep_count: 371023
total_train_sample_count: 370852
total_episode_count: 377
total_duration: 148.33864413840425
[2023-05-17 14:06:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2195.4574083026178
avg_train_sample_per_sec: 2195.4574083026178
avg_episode_per_sec: 2.1954574083026177
collect_time: 2.732915690967015
reward_mean: 930.2770647908937
reward_std: 18.744333993178515
reward_max: 952.762785660001
reward_min: 901.0668165398829
total_envstep_count: 375019
total_train_sample_count: 374852
total_episode_count: 383
total_duration: 151.07155982937127
[2023-05-17 14:06:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2186.2664863302534
avg_train_sample_per_sec: 2186.2664863302534
avg_episode_per_sec: 2.1862664863302537
collect_time: 0.9148015635354177
reward_mean: 916.0799136380742
reward_std: 28.246639093088277
reward_max: 944.3265527311625
reward_min: 887.8332745449859
total_envstep_count: 379017
total_train_sample_count: 378852
total_episode_count: 385
total_duration: 151.98636139290667
[2023-05-17 14:06:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2025.5571454411902
avg_train_sample_per_sec: 2025.5571454411902
avg_episode_per_sec: 2.0255571454411903
collect_time: 2.9621479766709466
reward_mean: 899.1268284182938
reward_std: 44.53279508764697
reward_max: 968.0911528806354
reward_min: 841.9105930441914
total_envstep_count: 383013
total_train_sample_count: 382852
total_episode_count: 391
total_duration: 154.9485093695776
[2023-05-17 14:06:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2305.617403032121
avg_train_sample_per_sec: 2305.617403032121
avg_episode_per_sec: 2.305617403032121
collect_time: 0.8674466099057879
reward_mean: 865.3286393219236
reward_std: 2.922878220084044
reward_max: 868.2515175420076
reward_min: 862.4057611018395
total_envstep_count: 387011
total_train_sample_count: 386852
total_episode_count: 393
total_duration: 155.8159559794834
[2023-05-17 14:06:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2243.917672616851
avg_train_sample_per_sec: 2243.917672616851
avg_episode_per_sec: 2.2439176726168513
collect_time: 2.673894890717098
reward_mean: 895.2631931655324
reward_std: 20.784884771615054
reward_max: 926.2498532245709
reward_min: 859.4237234786871
total_envstep_count: 391007
total_train_sample_count: 390852
total_episode_count: 399
total_duration: 158.48985087020048
[2023-05-17 14:06:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 816.0
avg_sample_per_episode: 816.0
avg_envstep_per_sec: 2258.486181446984
avg_train_sample_per_sec: 2258.486181446984
avg_episode_per_sec: 2.7677526733418922
collect_time: 1.0839118787220547
reward_mean: 720.2833369209839
reward_std: 233.69374402453488
reward_max: 885.6271991989405
reward_min: 389.7904938323411
total_envstep_count: 395092
total_train_sample_count: 394900
total_episode_count: 402
total_duration: 159.57376274892255
[2023-05-17 14:06:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4680
train_sample_count: 4680
avg_envstep_per_episode: 936.0
avg_sample_per_episode: 936.0
avg_envstep_per_sec: 2333.622050367317
avg_train_sample_per_sec: 2333.622050367317
avg_episode_per_sec: 2.4931859512471335
collect_time: 2.0054661376135687
reward_mean: 799.3141805567343
reward_std: 161.24740230595626
reward_max: 951.9385746009252
reward_min: 501.98473188542147
total_envstep_count: 399129
total_train_sample_count: 398930
total_episode_count: 407
total_duration: 161.57922888653613
[2023-05-17 14:06:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2376.3565212072845
avg_train_sample_per_sec: 2376.3565212072845
avg_episode_per_sec: 2.3763565212072844
collect_time: 1.2624368327004567
reward_mean: 893.8919223407206
reward_std: 19.093389723930006
reward_max: 915.3379422730014
reward_min: 868.9602013660835
total_envstep_count: 403127
total_train_sample_count: 402930
total_episode_count: 410
total_duration: 162.84166571923657
[2023-05-17 14:06:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2335.093912369306
avg_train_sample_per_sec: 2335.093912369306
avg_episode_per_sec: 2.335093912369306
collect_time: 2.141241503613336
reward_mean: 875.4911517562696
reward_std: 30.356608218715092
reward_max: 924.404019313498
reward_min: 841.323275591504
total_envstep_count: 407124
total_train_sample_count: 406930
total_episode_count: 415
total_duration: 164.98290722284992
[2023-05-17 14:06:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2361.285161377977
avg_train_sample_per_sec: 2361.285161377977
avg_episode_per_sec: 2.3612851613779773
collect_time: 1.2704945802688599
reward_mean: 930.4248981802635
reward_std: 46.7346540830835
reward_max: 996.2389744682748
reward_min: 892.266921056887
total_envstep_count: 411122
total_train_sample_count: 410930
total_episode_count: 418
total_duration: 166.25340180311878
[2023-05-17 14:07:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2080.4855055364465
avg_train_sample_per_sec: 2080.4855055364465
avg_episode_per_sec: 2.0804855055364464
collect_time: 2.403285188334329
reward_mean: 863.5963628782099
reward_std: 20.701268768573634
reward_max: 886.6149581576266
reward_min: 839.1793324090628
total_envstep_count: 415119
total_train_sample_count: 414930
total_episode_count: 423
total_duration: 168.6566869914531
[2023-05-17 14:07:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2392.497694501161
avg_train_sample_per_sec: 2392.497694501161
avg_episode_per_sec: 2.3924976945011607
collect_time: 1.2539197036198209
reward_mean: 889.560742749859
reward_std: 73.60607635070403
reward_max: 986.1017590539209
reward_min: 807.5759076454381
total_envstep_count: 419117
total_train_sample_count: 418930
total_episode_count: 426
total_duration: 169.91060669507294
[2023-05-17 14:07:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2318.1287946980174
avg_train_sample_per_sec: 2318.1287946980174
avg_episode_per_sec: 2.3181287946980174
collect_time: 2.156912079879216
reward_mean: 978.5571953538035
reward_std: 25.06444893970124
reward_max: 1015.9919250362319
reward_min: 938.9549455130083
total_envstep_count: 423115
total_train_sample_count: 422930
total_episode_count: 431
total_duration: 172.06751877495216
[2023-05-17 14:07:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2294.0615511051274
avg_train_sample_per_sec: 2294.0615511051274
avg_episode_per_sec: 2.2940615511051274
collect_time: 1.3077242842742376
reward_mean: 905.9259421413894
reward_std: 58.17062502945142
reward_max: 973.0788580001204
reward_min: 831.1961508934675
total_envstep_count: 427113
total_train_sample_count: 426930
total_episode_count: 434
total_duration: 173.3752430592264
[2023-05-17 14:07:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2129.384045205582
avg_train_sample_per_sec: 2129.384045205582
avg_episode_per_sec: 2.129384045205582
collect_time: 2.348096864564078
reward_mean: 976.435675669358
reward_std: 55.69520205509358
reward_max: 1059.1712633331465
reward_min: 901.7962128059496
total_envstep_count: 431110
total_train_sample_count: 430930
total_episode_count: 439
total_duration: 175.72333992379046
[2023-05-17 14:07:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2205.0457481629496
avg_train_sample_per_sec: 2205.0457481629496
avg_episode_per_sec: 2.2050457481629495
collect_time: 1.360515990427562
reward_mean: 881.1737009161247
reward_std: 17.399208166614613
reward_max: 905.2602878580639
reward_min: 864.774272190817
total_envstep_count: 435108
total_train_sample_count: 434930
total_episode_count: 442
total_duration: 177.08385591421802
[2023-05-17 14:07:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5626
train_sample_count: 5626
avg_envstep_per_episode: 937.6666666666666
avg_sample_per_episode: 937.6666666666666
avg_envstep_per_sec: 2343.5467281902484
avg_train_sample_per_sec: 2343.5467281902484
avg_episode_per_sec: 2.4993388498296283
collect_time: 2.4006348720618655
reward_mean: 865.1832336039297
reward_std: 116.90949524003959
reward_max: 950.9901436878022
reward_min: 607.730456792983
total_envstep_count: 439106
total_train_sample_count: 438956
total_episode_count: 448
total_duration: 179.48449078627988
[2023-05-17 14:07:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2425.2412073489486
avg_train_sample_per_sec: 2425.2412073489486
avg_episode_per_sec: 2.4252412073489484
collect_time: 0.8246602416038513
reward_mean: 887.5926742730862
reward_std: 18.439399546139896
reward_max: 906.0320738192262
reward_min: 869.1532747269464
total_envstep_count: 443105
total_train_sample_count: 442956
total_episode_count: 450
total_duration: 180.30915102788373
[2023-05-17 14:07:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2431.5014169557244
avg_train_sample_per_sec: 2431.5014169557244
avg_episode_per_sec: 2.4315014169557245
collect_time: 2.4676111468247006
reward_mean: 894.0857322529828
reward_std: 41.60885796559321
reward_max: 932.3350095250934
reward_min: 836.1630309689793
total_envstep_count: 447103
total_train_sample_count: 446956
total_episode_count: 456
total_duration: 182.77676217470844
[2023-05-17 14:07:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1781.4744424835267
avg_train_sample_per_sec: 1781.4744424835267
avg_episode_per_sec: 1.7814744424835267
collect_time: 1.122665558542524
reward_mean: 917.8787836214975
reward_std: 21.74524743648533
reward_max: 939.6240310579828
reward_min: 896.1335361850122
total_envstep_count: 451102
total_train_sample_count: 450956
total_episode_count: 458
total_duration: 183.89942773325097
[2023-05-17 14:07:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2373.7117061716413
avg_train_sample_per_sec: 2373.7117061716413
avg_episode_per_sec: 2.3737117061716413
collect_time: 2.527686906712396
reward_mean: 918.5684816770587
reward_std: 52.361430636464455
reward_max: 991.4241634714858
reward_min: 818.7030725857128
total_envstep_count: 455100
total_train_sample_count: 454956
total_episode_count: 464
total_duration: 186.42711463996338
[2023-05-17 14:07:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2391.3930222585564
avg_train_sample_per_sec: 2391.3930222585564
avg_episode_per_sec: 2.391393022258556
collect_time: 0.8363326234476907
reward_mean: 863.9268899245294
reward_std: 17.5953797898718
reward_max: 881.5222697144012
reward_min: 846.3315101346576
total_envstep_count: 459099
total_train_sample_count: 458956
total_episode_count: 466
total_duration: 187.26344726341108
[2023-05-17 14:08:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2407.6134703855673
avg_train_sample_per_sec: 2407.6134703855673
avg_episode_per_sec: 2.4076134703855674
collect_time: 2.492094380514963
reward_mean: 933.614571872001
reward_std: 36.15083870581772
reward_max: 980.2656720430721
reward_min: 885.8017738156459
total_envstep_count: 463097
total_train_sample_count: 462956
total_episode_count: 472
total_duration: 189.75554164392605
[2023-05-17 14:08:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2426.6655953623945
avg_train_sample_per_sec: 2426.6655953623945
avg_episode_per_sec: 2.4266655953623943
collect_time: 0.8241761880261558
reward_mean: 967.0503853930272
reward_std: 31.67786443628205
reward_max: 998.7282498293092
reward_min: 935.3725209567451
total_envstep_count: 467096
total_train_sample_count: 466956
total_episode_count: 474
total_duration: 190.5797178319522
[2023-05-17 14:08:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2290.877852688506
avg_train_sample_per_sec: 2290.877852688506
avg_episode_per_sec: 2.290877852688506
collect_time: 2.619083332163947
reward_mean: 908.4676070082093
reward_std: 48.69426564251127
reward_max: 975.1881904164815
reward_min: 812.7481748586611
total_envstep_count: 471094
total_train_sample_count: 470956
total_episode_count: 480
total_duration: 193.19880116411613
[2023-05-17 14:08:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2333.0877714858566
avg_train_sample_per_sec: 2333.0877714858566
avg_episode_per_sec: 2.3330877714858564
collect_time: 0.8572330730301992
reward_mean: 875.9287931317771
reward_std: 51.40268425543377
reward_max: 927.3314773872108
reward_min: 824.5261088763433
total_envstep_count: 475093
total_train_sample_count: 474956
total_episode_count: 482
total_duration: 194.05603423714632
[2023-05-17 14:08:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2361.3784485256947
avg_train_sample_per_sec: 2361.3784485256947
avg_episode_per_sec: 2.3613784485256946
collect_time: 2.540888777800969
reward_mean: 899.357148758163
reward_std: 52.56269047330937
reward_max: 969.0130628049776
reward_min: 819.3581317989684
total_envstep_count: 479091
total_train_sample_count: 478956
total_episode_count: 488
total_duration: 196.5969230149473
[2023-05-17 14:08:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2412.192194005298
avg_train_sample_per_sec: 2412.192194005298
avg_episode_per_sec: 2.412192194005298
collect_time: 0.8291213299546923
reward_mean: 856.1547679920677
reward_std: 54.60861051738908
reward_max: 910.7633785094567
reward_min: 801.5461574746786
total_envstep_count: 483090
total_train_sample_count: 482956
total_episode_count: 490
total_duration: 197.42604434490198
[2023-05-17 14:08:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2150.9622940233985
avg_train_sample_per_sec: 2150.9622940233985
avg_episode_per_sec: 2.1509622940233983
collect_time: 2.789449176618031
reward_mean: 932.4732147250679
reward_std: 64.00666388019977
reward_max: 1030.6900183566238
reward_min: 863.4321005404862
total_envstep_count: 487088
total_train_sample_count: 486956
total_episode_count: 496
total_duration: 200.21549352152002
[2023-05-17 14:08:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2449.7005189508563
avg_train_sample_per_sec: 2449.7005189508563
avg_episode_per_sec: 2.449700518950856
collect_time: 0.81642632825034
reward_mean: 856.3543585801419
reward_std: 81.58741197726312
reward_max: 937.941770557405
reward_min: 774.7669466028788
total_envstep_count: 491087
total_train_sample_count: 490956
total_episode_count: 498
total_duration: 201.03191984977036
[2023-05-17 14:08:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2420.7015290861173
avg_train_sample_per_sec: 2420.7015290861173
avg_episode_per_sec: 2.4207015290861174
collect_time: 2.4786203205585484
reward_mean: 796.8613990938273
reward_std: 44.207454275018826
reward_max: 879.4633258000715
reward_min: 744.1096574326959
total_envstep_count: 495085
total_train_sample_count: 494956
total_episode_count: 504
total_duration: 203.5105401703289
[2023-05-17 14:08:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2461.0287068767648
avg_train_sample_per_sec: 2461.0287068767648
avg_episode_per_sec: 2.4610287068767644
collect_time: 0.8126682937145233
reward_mean: 811.6335987360758
reward_std: 78.4464275681766
reward_max: 890.0800263042523
reward_min: 733.1871711678991
total_envstep_count: 499084
total_train_sample_count: 498956
total_episode_count: 506
total_duration: 204.32320846404343
[2023-05-17 14:08:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2433.1888705679016
avg_train_sample_per_sec: 2433.1888705679016
avg_episode_per_sec: 2.4331888705679017
collect_time: 2.465899820838656
reward_mean: 806.5445561633065
reward_std: 49.99557818664455
reward_max: 868.856741831214
reward_min: 725.7485241168351
total_envstep_count: 503082
total_train_sample_count: 502956
total_episode_count: 512
total_duration: 206.78910828488208
[2023-05-17 14:08:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2461.828902934931
avg_train_sample_per_sec: 2461.828902934931
avg_episode_per_sec: 2.4618289029349314
collect_time: 0.8124041429587774
reward_mean: 827.9895123645779
reward_std: 20.43388443440392
reward_max: 848.4233967989818
reward_min: 807.555627930174
total_envstep_count: 507081
total_train_sample_count: 506956
total_episode_count: 514
total_duration: 207.60151242784085
[2023-05-17 14:09:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2425.078548073561
avg_train_sample_per_sec: 2425.078548073561
avg_episode_per_sec: 2.425078548073561
collect_time: 2.474146664142608
reward_mean: 882.2713217648721
reward_std: 60.3801553187679
reward_max: 989.0543564970544
reward_min: 808.9904961587278
total_envstep_count: 511079
total_train_sample_count: 510956
total_episode_count: 520
total_duration: 210.07565909198345
[2023-05-17 14:09:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2463.9317339470535
avg_train_sample_per_sec: 2463.9317339470535
avg_episode_per_sec: 2.4639317339470534
collect_time: 0.8117108004433767
reward_mean: 971.5975005084646
reward_std: 4.784547965738739
reward_max: 976.3820484742033
reward_min: 966.8129525427258
total_envstep_count: 515078
total_train_sample_count: 514956
total_episode_count: 522
total_duration: 210.88736989242682
[2023-05-17 14:09:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2207.3533472284093
avg_train_sample_per_sec: 2207.3533472284093
avg_episode_per_sec: 2.2073533472284095
collect_time: 2.7181873747280663
reward_mean: 772.4531145735745
reward_std: 50.64956784245211
reward_max: 846.787722841363
reward_min: 695.3183151248737
total_envstep_count: 519076
total_train_sample_count: 518956
total_episode_count: 528
total_duration: 213.6055572671549
[2023-05-17 14:09:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2548.9741582213137
avg_train_sample_per_sec: 2548.9741582213137
avg_episode_per_sec: 2.5489741582213137
collect_time: 0.7846293747425079
reward_mean: 924.3370891054228
reward_std: 75.89729939157047
reward_max: 1000.2343884969933
reward_min: 848.4397897138524
total_envstep_count: 523075
total_train_sample_count: 522956
total_episode_count: 530
total_duration: 214.3901866418974
[2023-05-17 14:09:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2472.068684689167
avg_train_sample_per_sec: 2472.068684689167
avg_episode_per_sec: 2.472068684689167
collect_time: 2.4271170284066876
reward_mean: 859.3174327563079
reward_std: 56.2784336623539
reward_max: 913.4325303671068
reward_min: 744.531231997468
total_envstep_count: 527073
total_train_sample_count: 526956
total_episode_count: 536
total_duration: 216.81730367030409
[2023-05-17 14:09:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2482.683445663576
avg_train_sample_per_sec: 2482.683445663576
avg_episode_per_sec: 2.4826834456635765
collect_time: 0.805579947573798
reward_mean: 856.7592578744191
reward_std: 34.84112483865823
reward_max: 891.6003827130774
reward_min: 821.9181330357609
total_envstep_count: 531072
total_train_sample_count: 530956
total_episode_count: 538
total_duration: 217.62288361787787
[2023-05-17 14:09:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2500.6610927146476
avg_train_sample_per_sec: 2500.6610927146476
avg_episode_per_sec: 2.5006610927146475
collect_time: 2.399365518774305
reward_mean: 981.0482870886227
reward_std: 61.40495090670087
reward_max: 1068.7723492775096
reward_min: 883.8006746892258
total_envstep_count: 535070
total_train_sample_count: 534956
total_episode_count: 544
total_duration: 220.0222491366522
[2023-05-17 14:09:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2550.0957492288812
avg_train_sample_per_sec: 2550.0957492288812
avg_episode_per_sec: 2.5500957492288814
collect_time: 0.7842842766216822
reward_mean: 763.4538319362948
reward_std: 59.975310566158385
reward_max: 823.4291425024533
reward_min: 703.4785213701365
total_envstep_count: 539069
total_train_sample_count: 538956
total_episode_count: 546
total_duration: 220.80653341327388
[2023-05-17 14:09:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2518.9079772919845
avg_train_sample_per_sec: 2518.9079772919845
avg_episode_per_sec: 2.5189079772919847
collect_time: 2.3819845957415446
reward_mean: 836.8609940380416
reward_std: 137.91094841551106
reward_max: 1003.7927839549831
reward_min: 643.2226093762185
total_envstep_count: 543067
total_train_sample_count: 542956
total_episode_count: 552
total_duration: 223.18851800901544
[2023-05-17 14:09:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2526.711322429899
avg_train_sample_per_sec: 2526.711322429899
avg_episode_per_sec: 2.5267113224298994
collect_time: 0.7915427386760712
reward_mean: 880.8673031057585
reward_std: 35.50290015224016
reward_max: 916.3702032579987
reward_min: 845.3644029535184
total_envstep_count: 547066
total_train_sample_count: 546956
total_episode_count: 554
total_duration: 223.9800607476915
[2023-05-17 14:09:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2136.8549979912714
avg_train_sample_per_sec: 2136.8549979912714
avg_episode_per_sec: 2.1368549979912714
collect_time: 2.8078648320266177
reward_mean: 870.3286717343112
reward_std: 35.47546630027572
reward_max: 934.4519207254548
reward_min: 821.1651124052216
total_envstep_count: 551064
total_train_sample_count: 550956
total_episode_count: 560
total_duration: 226.78792557971812
[2023-05-17 14:09:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2476.3191051772205
avg_train_sample_per_sec: 2476.3191051772205
avg_episode_per_sec: 2.476319105177221
collect_time: 0.8076503532273429
reward_mean: 908.0684357381783
reward_std: 25.44821163517082
reward_max: 933.5166473733491
reward_min: 882.6202241030074
total_envstep_count: 555063
total_train_sample_count: 554956
total_episode_count: 562
total_duration: 227.59557593294545
[2023-05-17 14:09:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2489.7895919132548
avg_train_sample_per_sec: 2489.7895919132548
avg_episode_per_sec: 2.4897895919132544
collect_time: 2.409842188869204
reward_mean: 968.8469327443572
reward_std: 52.454121983304454
reward_max: 1049.6507353515442
reward_min: 874.7881972134325
total_envstep_count: 559061
total_train_sample_count: 558956
total_episode_count: 568
total_duration: 230.00541812181464
[2023-05-17 14:10:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2539.9467991170477
avg_train_sample_per_sec: 2539.9467991170477
avg_episode_per_sec: 2.539946799117048
collect_time: 0.7874180674552917
reward_mean: 924.8289236292568
reward_std: 84.57296914523533
reward_max: 1009.4018927744921
reward_min: 840.2559544840215
total_envstep_count: 563060
total_train_sample_count: 562956
total_episode_count: 570
total_duration: 230.79283618926993
[2023-05-17 14:10:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2418.946625804988
avg_train_sample_per_sec: 2418.946625804988
avg_episode_per_sec: 2.418946625804988
collect_time: 2.480418516056878
reward_mean: 910.6414473548998
reward_std: 41.160489283163926
reward_max: 956.6628957692922
reward_min: 846.986132364847
total_envstep_count: 567058
total_train_sample_count: 566956
total_episode_count: 576
total_duration: 233.27325470532682
[2023-05-17 14:10:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2343.7446928765626
avg_train_sample_per_sec: 2343.7446928765626
avg_episode_per_sec: 2.3437446928765624
collect_time: 0.8533352656023843
reward_mean: 927.0397175592238
reward_std: 9.280233888171267
reward_max: 936.319951447395
reward_min: 917.7594836710525
total_envstep_count: 571057
total_train_sample_count: 570956
total_episode_count: 578
total_duration: 234.12658997092922
[2023-05-17 14:10:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 6009
train_sample_count: 6009
avg_envstep_per_episode: 858.4285714285714
avg_sample_per_episode: 858.4285714285714
avg_envstep_per_sec: 2177.517461402695
avg_train_sample_per_sec: 2177.517461402695
avg_episode_per_sec: 2.5366320901678923
collect_time: 2.759564552988325
reward_mean: 785.820837542681
reward_std: 319.93876227305077
reward_max: 1011.4867571102717
reward_min: 11.71501981097186
total_envstep_count: 575053
total_train_sample_count: 574965
total_episode_count: 585
total_duration: 236.88615452391755
[2023-05-17 14:10:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2198.0906687953216
avg_train_sample_per_sec: 2198.0906687953216
avg_episode_per_sec: 2.1980906687953214
collect_time: 0.9098805742604392
reward_mean: 945.371320335567
reward_std: 20.758780375380866
reward_max: 966.1301007109479
reward_min: 924.6125399601862
total_envstep_count: 579052
total_train_sample_count: 578965
total_episode_count: 587
total_duration: 237.79603509817798
[2023-05-17 14:10:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1959.7155149257514
avg_train_sample_per_sec: 1959.7155149257514
avg_episode_per_sec: 1.9597155149257515
collect_time: 3.0616688770907263
reward_mean: 809.6224851195835
reward_std: 31.51254569933375
reward_max: 855.0833526890395
reward_min: 759.1123116213862
total_envstep_count: 583048
total_train_sample_count: 582965
total_episode_count: 593
total_duration: 240.85770397526872
[2023-05-17 14:10:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2177.85665921416
avg_train_sample_per_sec: 2177.85665921416
avg_episode_per_sec: 2.1778566592141604
collect_time: 0.918334083897727
reward_mean: 985.475020007827
reward_std: 40.842563187593385
reward_max: 1026.3175831954204
reward_min: 944.6324568202336
total_envstep_count: 587047
total_train_sample_count: 586965
total_episode_count: 595
total_duration: 241.77603805916644
[2023-05-17 14:10:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2147.1029539681294
avg_train_sample_per_sec: 2147.1029539681294
avg_episode_per_sec: 2.1471029539681297
collect_time: 2.794463110821588
reward_mean: 870.2960476293184
reward_std: 53.30770529110359
reward_max: 946.5092169418185
reward_min: 792.3227168121958
total_envstep_count: 591043
total_train_sample_count: 590965
total_episode_count: 601
total_duration: 244.57050116998803
[2023-05-17 14:10:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2225.7803533845863
avg_train_sample_per_sec: 2225.7803533845863
avg_episode_per_sec: 2.2257803533845864
collect_time: 0.8985612605299269
reward_mean: 894.4559757768968
reward_std: 68.6498538128165
reward_max: 963.1058295897134
reward_min: 825.8061219640804
total_envstep_count: 595042
total_train_sample_count: 594965
total_episode_count: 603
total_duration: 245.46906243051797
[2023-05-17 14:10:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2401.0624000562643
avg_train_sample_per_sec: 2401.0624000562643
avg_episode_per_sec: 2.401062400056264
collect_time: 2.4988938229424615
reward_mean: 900.949632766036
reward_std: 20.92723584757858
reward_max: 938.5103376556423
reward_min: 867.6083244131117
total_envstep_count: 599038
total_train_sample_count: 598965
total_episode_count: 609
total_duration: 247.96795625346041
[2023-05-17 14:10:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2424.0796587412706
avg_train_sample_per_sec: 2424.0796587412706
avg_episode_per_sec: 2.4240796587412707
collect_time: 0.8250553948538645
reward_mean: 915.0238337333544
reward_std: 2.8578345300447268
reward_max: 917.8816682633991
reward_min: 912.1659992033096
total_envstep_count: 603037
total_train_sample_count: 602965
total_episode_count: 611
total_duration: 248.7930116483143
[2023-05-17 14:11:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2451.1940797242078
avg_train_sample_per_sec: 2451.1940797242078
avg_episode_per_sec: 2.4511940797242078
collect_time: 2.44778659088271
reward_mean: 1016.0512325681483
reward_std: 70.32366142329157
reward_max: 1102.5402148383696
reward_min: 916.3978283404177
total_envstep_count: 607033
total_train_sample_count: 606965
total_episode_count: 617
total_duration: 251.240798239197
[2023-05-17 14:11:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2454.926769518223
avg_train_sample_per_sec: 2454.926769518223
avg_episode_per_sec: 2.454926769518223
collect_time: 0.8146882525512149
reward_mean: 1017.5968070345045
reward_std: 63.966983564126565
reward_max: 1081.5637905986312
reward_min: 953.629823470378
total_envstep_count: 611032
total_train_sample_count: 610965
total_episode_count: 619
total_duration: 252.0554864917482
[2023-05-17 14:11:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2496.4132178466666
avg_train_sample_per_sec: 2496.4132178466666
avg_episode_per_sec: 2.4964132178466665
collect_time: 2.4034482581274847
reward_mean: 980.1582497720501
reward_std: 120.36137775757517
reward_max: 1118.6310062426326
reward_min: 762.1155334168532
total_envstep_count: 615028
total_train_sample_count: 614965
total_episode_count: 625
total_duration: 254.4589347498757
[2023-05-17 14:11:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2271.260623878478
avg_train_sample_per_sec: 2271.260623878478
avg_episode_per_sec: 2.2712606238784776
collect_time: 0.880568253142493
reward_mean: 928.3932462804542
reward_std: 52.23840122688131
reward_max: 980.6316475073354
reward_min: 876.1548450535728
total_envstep_count: 619027
total_train_sample_count: 618965
total_episode_count: 627
total_duration: 255.3395030030182
[2023-05-17 14:11:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 5901
train_sample_count: 5901
avg_envstep_per_episode: 737.625
avg_sample_per_episode: 737.625
avg_envstep_per_sec: 2257.5555815452417
avg_train_sample_per_sec: 2257.5555815452417
avg_episode_per_sec: 3.0605735726761454
collect_time: 2.613889132227216
reward_mean: 710.7147046492994
reward_std: 430.2868326495234
reward_max: 1258.1503818194435
reward_min: 15.92860661040502
total_envstep_count: 623157
total_train_sample_count: 623016
total_episode_count: 635
total_duration: 257.9533921352454
[2023-05-17 14:11:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 546.0
avg_sample_per_episode: 546.0
avg_envstep_per_sec: 2515.8343473971113
avg_train_sample_per_sec: 2515.8343473971113
avg_episode_per_sec: 4.607755215013024
collect_time: 1.3021525059427534
reward_mean: 470.5344246040279
reward_std: 224.07685909168038
reward_max: 737.0124781350195
reward_min: 217.19049459539963
total_envstep_count: 627128
total_train_sample_count: 627042
total_episode_count: 641
total_duration: 259.2555446411881
[2023-05-17 14:11:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 822.25
avg_sample_per_episode: 822.25
avg_envstep_per_sec: 2514.9381539057845
avg_train_sample_per_sec: 2514.9381539057845
avg_episode_per_sec: 3.0586052343031733
collect_time: 1.3077856387410844
reward_mean: 502.2934904773491
reward_std: 160.7345543159103
reward_max: 648.4622561224406
reward_min: 236.18347068296177
total_envstep_count: 631260
total_train_sample_count: 631081
total_episode_count: 645
total_duration: 260.56333027992923
[2023-05-17 14:11:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5229
train_sample_count: 5229
avg_envstep_per_episode: 871.5
avg_sample_per_episode: 871.5
avg_envstep_per_sec: 2521.1442898147097
avg_train_sample_per_sec: 2521.1442898147097
avg_episode_per_sec: 2.8928792768958234
collect_time: 2.0740582048892975
reward_mean: 686.2433797057215
reward_std: 245.27142591502957
reward_max: 1034.0225162394331
reward_min: 205.6615675158447
total_envstep_count: 635256
total_train_sample_count: 635110
total_episode_count: 651
total_duration: 262.63738848481853
[2023-05-17 14:11:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2480.558061454861
avg_train_sample_per_sec: 2480.558061454861
avg_episode_per_sec: 2.480558061454861
collect_time: 0.806270182132721
reward_mean: 798.4522448927571
reward_std: 9.435890252688012
reward_max: 807.8881351454451
reward_min: 789.016354640069
total_envstep_count: 639254
total_train_sample_count: 639110
total_episode_count: 653
total_duration: 263.44365866695125
[2023-05-17 14:11:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2429.066617226956
avg_train_sample_per_sec: 2429.066617226956
avg_episode_per_sec: 2.4290666172269564
collect_time: 2.4700845820563178
reward_mean: 912.9944743754141
reward_std: 73.01603635571149
reward_max: 998.1163048911374
reward_min: 787.841686062415
total_envstep_count: 643249
total_train_sample_count: 643110
total_episode_count: 659
total_duration: 265.91374324900755
[2023-05-17 14:11:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 31
envstep_count: 5466
train_sample_count: 5466
avg_envstep_per_episode: 176.32258064516128
avg_sample_per_episode: 176.32258064516128
avg_envstep_per_sec: 2256.998033368507
avg_train_sample_per_sec: 2256.998033368507
avg_episode_per_sec: 12.800391334508548
collect_time: 2.4218009582587654
reward_mean: 172.8394961414951
reward_std: 219.71503607850073
reward_max: 758.6908636264957
reward_min: 4.257269473692945
total_envstep_count: 647382
total_train_sample_count: 647276
total_episode_count: 690
total_duration: 268.3355442072663
[2023-05-17 14:11:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 42
envstep_count: 3329
train_sample_count: 3329
avg_envstep_per_episode: 79.26190476190476
avg_sample_per_episode: 79.26190476190476
avg_envstep_per_sec: 1785.2546392807942
avg_train_sample_per_sec: 1785.2546392807942
avg_episode_per_sec: 22.523488990625818
collect_time: 1.864719982658114
reward_mean: 73.9182485247866
reward_std: 134.55579336863812
reward_max: 884.6021398113272
reward_min: -9.485292012593183
total_envstep_count: 651658
total_train_sample_count: 651455
total_episode_count: 732
total_duration: 270.20026418992444
[2023-05-17 14:11:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2242
train_sample_count: 2242
avg_envstep_per_episode: 373.6666666666667
avg_sample_per_episode: 373.6666666666667
avg_envstep_per_sec: 2089.5334377961326
avg_train_sample_per_sec: 2089.5334377961326
avg_episode_per_sec: 5.591971733620337
collect_time: 1.0729667970112393
reward_mean: 222.05884345569362
reward_std: 249.66124640837845
reward_max: 576.3745592468753
reward_min: 25.963802889210672
total_envstep_count: 655717
total_train_sample_count: 655547
total_episode_count: 738
total_duration: 271.2732309869357
[2023-05-17 14:12:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2018.6495105949643
avg_train_sample_per_sec: 2018.6495105949643
avg_episode_per_sec: 2.0186495105949644
collect_time: 2.476903481142861
reward_mean: 628.585413673097
reward_std: 86.04698727107298
reward_max: 723.7661370571986
reward_min: 474.3368452070254
total_envstep_count: 659714
total_train_sample_count: 659547
total_episode_count: 743
total_duration: 273.75013446807856
[2023-05-17 14:12:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1968.1797138670665
avg_train_sample_per_sec: 1968.1797138670665
avg_episode_per_sec: 1.9681797138670665
collect_time: 1.5242510523114883
reward_mean: 695.0745367779069
reward_std: 18.02273097544516
reward_max: 716.0437216933303
reward_min: 672.042107426651
total_envstep_count: 663712
total_train_sample_count: 663547
total_episode_count: 746
total_duration: 275.27438552039007
[2023-05-17 14:12:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1879.7556327690768
avg_train_sample_per_sec: 1879.7556327690768
avg_episode_per_sec: 1.8797556327690768
collect_time: 2.659920211349215
reward_mean: 838.6443963332962
reward_std: 61.02243233087586
reward_max: 909.7560860078167
reward_min: 738.6882859468201
total_envstep_count: 667709
total_train_sample_count: 667547
total_episode_count: 751
total_duration: 277.9343057317393
[2023-05-17 14:12:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1900.4574226046986
avg_train_sample_per_sec: 1900.4574226046986
avg_episode_per_sec: 1.9004574226046986
collect_time: 1.5785673303263525
reward_mean: 846.098827694529
reward_std: 36.757400367221805
reward_max: 897.6125614218738
reward_min: 814.3077955418113
total_envstep_count: 671707
total_train_sample_count: 671547
total_episode_count: 754
total_duration: 279.51287306206564
[2023-05-17 14:12:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2037.223477174631
avg_train_sample_per_sec: 2037.223477174631
avg_episode_per_sec: 2.037223477174631
collect_time: 2.4543208224432806
reward_mean: 775.094891026138
reward_std: 99.59336736203382
reward_max: 891.7869869537731
reward_min: 624.3186134655891
total_envstep_count: 675704
total_train_sample_count: 675547
total_episode_count: 759
total_duration: 281.9671938845089
[2023-05-17 14:12:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2102.6762185473895
avg_train_sample_per_sec: 2102.6762185473895
avg_episode_per_sec: 2.1026762185473893
collect_time: 1.426753188882555
reward_mean: 831.3781578408383
reward_std: 48.9060721221598
reward_max: 893.6294019169873
reward_min: 774.1509497617654
total_envstep_count: 679702
total_train_sample_count: 679547
total_episode_count: 762
total_duration: 283.3939470733915
[2023-05-17 14:12:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1935.5619717096865
avg_train_sample_per_sec: 1935.5619717096865
avg_episode_per_sec: 1.9355619717096866
collect_time: 2.5832290947437286
reward_mean: 898.3802848971476
reward_std: 58.899119673647704
reward_max: 950.9260923721297
reward_min: 783.4142878010736
total_envstep_count: 683699
total_train_sample_count: 683547
total_episode_count: 767
total_duration: 285.9771761681352
[2023-05-17 14:12:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2272.7220438450177
avg_train_sample_per_sec: 2272.7220438450177
avg_episode_per_sec: 2.2727220438450177
collect_time: 1.3200030369418008
reward_mean: 862.9229447287674
reward_std: 34.10058988283011
reward_max: 911.0140015304335
reward_min: 835.7608417163357
total_envstep_count: 687697
total_train_sample_count: 687547
total_episode_count: 770
total_duration: 287.297179205077
[2023-05-17 14:12:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2313.7155754080836
avg_train_sample_per_sec: 2313.7155754080836
avg_episode_per_sec: 2.3137155754080836
collect_time: 2.161026209592819
reward_mean: 867.1163661177064
reward_std: 53.60032678177893
reward_max: 951.8140495575872
reward_min: 810.0454295216916
total_envstep_count: 691694
total_train_sample_count: 691547
total_episode_count: 775
total_duration: 289.4582054146698
[2023-05-17 14:12:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2369.427656793747
avg_train_sample_per_sec: 2369.427656793747
avg_episode_per_sec: 2.369427656793747
collect_time: 1.266128548554012
reward_mean: 809.4094022566773
reward_std: 52.09326091373002
reward_max: 858.1286268525057
reward_min: 737.1917747990759
total_envstep_count: 695692
total_train_sample_count: 695547
total_episode_count: 778
total_duration: 290.72433396322384
[2023-05-17 14:12:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2516.1558828217944
avg_train_sample_per_sec: 2516.1558828217944
avg_episode_per_sec: 2.5161558828217947
collect_time: 1.987158281462533
reward_mean: 928.0852546741411
reward_std: 59.602734631153446
reward_max: 1010.1098133501938
reward_min: 841.9932202369237
total_envstep_count: 699689
total_train_sample_count: 699547
total_episode_count: 783
total_duration: 292.7114922446864
[2023-05-17 14:13:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3501
train_sample_count: 3501
avg_envstep_per_episode: 875.25
avg_sample_per_episode: 875.25
avg_envstep_per_sec: 2538.52369403205
avg_train_sample_per_sec: 2538.52369403205
avg_episode_per_sec: 2.9003412671031708
collect_time: 1.379148049013955
reward_mean: 722.7594332303942
reward_std: 207.87030867045567
reward_max: 883.5063279220553
reward_min: 366.5179660274543
total_envstep_count: 703686
total_train_sample_count: 703548
total_episode_count: 787
total_duration: 294.09064029370035
[2023-05-17 14:13:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2510.7485434965392
avg_train_sample_per_sec: 2510.7485434965392
avg_episode_per_sec: 2.5107485434965393
collect_time: 1.5931503815310342
reward_mean: 830.9073008196751
reward_std: 36.42291954602351
reward_max: 876.0809163336169
reward_min: 790.4497303652159
total_envstep_count: 707684
total_train_sample_count: 707548
total_episode_count: 791
total_duration: 295.68379067523136
[2023-05-17 14:13:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2521.7373850967415
avg_train_sample_per_sec: 2521.7373850967415
avg_episode_per_sec: 2.5217373850967415
collect_time: 1.5862079943929401
reward_mean: 909.1414412571924
reward_std: 23.32717975427992
reward_max: 933.492279990436
reward_min: 880.8161409949751
total_envstep_count: 711682
total_train_sample_count: 711548
total_episode_count: 795
total_duration: 297.26999866962433
[2023-05-17 14:13:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2504.733627863969
avg_train_sample_per_sec: 2504.733627863969
avg_episode_per_sec: 2.504733627863969
collect_time: 1.5969762035778592
reward_mean: 849.6733645958091
reward_std: 69.56929850600102
reward_max: 966.8407718306819
reward_min: 784.6541006584189
total_envstep_count: 715680
total_train_sample_count: 715548
total_episode_count: 799
total_duration: 298.8669748732022
[2023-05-17 14:13:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2506.871322161215
avg_train_sample_per_sec: 2506.871322161215
avg_episode_per_sec: 2.506871322161215
collect_time: 1.5956144077437266
reward_mean: 832.4352339810291
reward_std: 13.290732496813472
reward_max: 843.9520771426359
reward_min: 811.3359324027035
total_envstep_count: 719678
total_train_sample_count: 719548
total_episode_count: 803
total_duration: 300.4625892809459
[2023-05-17 14:13:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2065.760178060926
avg_train_sample_per_sec: 2065.760178060926
avg_episode_per_sec: 2.065760178060926
collect_time: 1.936333192246301
reward_mean: 799.1472090401751
reward_std: 66.95011077115325
reward_max: 906.7253947318716
reward_min: 725.6538507656876
total_envstep_count: 723676
total_train_sample_count: 723548
total_episode_count: 807
total_duration: 302.3989224731922
[2023-05-17 14:13:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2511.1669451665143
avg_train_sample_per_sec: 2511.1669451665143
avg_episode_per_sec: 2.511166945166514
collect_time: 1.5928849365030018
reward_mean: 882.6525935846257
reward_std: 26.08403155018886
reward_max: 909.8314093929348
reward_min: 839.7790572743165
total_envstep_count: 727674
total_train_sample_count: 727548
total_episode_count: 811
total_duration: 303.99180740969524
[2023-05-17 14:13:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2414.4049009985492
avg_train_sample_per_sec: 2414.4049009985492
avg_episode_per_sec: 2.4144049009985493
collect_time: 1.6567229458263941
reward_mean: 899.0526313433045
reward_std: 58.206309530459016
reward_max: 957.6844655242958
reward_min: 816.9599268138813
total_envstep_count: 731672
total_train_sample_count: 731548
total_episode_count: 815
total_duration: 305.64853035552164
[2023-05-17 14:13:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2425.767063319972
avg_train_sample_per_sec: 2425.767063319972
avg_episode_per_sec: 2.425767063319972
collect_time: 1.6489629447460175
reward_mean: 888.7250025064753
reward_std: 41.46675048089636
reward_max: 933.5562136730273
reward_min: 821.4679298288825
total_envstep_count: 735671
total_train_sample_count: 735548
total_episode_count: 819
total_duration: 307.29749330026766
[2023-05-17 14:13:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2524.85288701837
avg_train_sample_per_sec: 2524.85288701837
avg_episode_per_sec: 2.52485288701837
collect_time: 1.5842507183551788
reward_mean: 827.1464501800948
reward_std: 46.55482848334934
reward_max: 866.5466388349381
reward_min: 751.6976116336225
total_envstep_count: 739669
total_train_sample_count: 739548
total_episode_count: 823
total_duration: 308.88174401862284
[2023-05-17 14:13:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2532.3955528651964
avg_train_sample_per_sec: 2532.3955528651964
avg_episode_per_sec: 2.5323955528651965
collect_time: 1.5795320740767889
reward_mean: 841.4351213956663
reward_std: 28.68167435668004
reward_max: 871.253089838848
reward_min: 804.6513227028696
total_envstep_count: 743668
total_train_sample_count: 743548
total_episode_count: 827
total_duration: 310.4612760926996
[2023-05-17 14:13:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2500.0973296590464
avg_train_sample_per_sec: 2500.0973296590464
avg_episode_per_sec: 2.5000973296590465
collect_time: 1.5999377114432198
reward_mean: 741.8508464763561
reward_std: 29.926025102162225
reward_max: 777.0052091714953
reward_min: 695.0550135148911
total_envstep_count: 747667
total_train_sample_count: 747548
total_episode_count: 831
total_duration: 312.0612138041428
[2023-05-17 14:13:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2497.4844729497777
avg_train_sample_per_sec: 2497.4844729497777
avg_episode_per_sec: 2.4974844729497776
collect_time: 1.6016115588801247
reward_mean: 764.0343064209957
reward_std: 21.215075546240442
reward_max: 794.2864636495009
reward_min: 734.6581006167127
total_envstep_count: 751666
total_train_sample_count: 751548
total_episode_count: 835
total_duration: 313.66282536302293
[2023-05-17 14:14:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2499.1812392151255
avg_train_sample_per_sec: 2499.1812392151255
avg_episode_per_sec: 2.4991812392151256
collect_time: 1.6005241785730635
reward_mean: 863.3028782597491
reward_std: 48.62024680166433
reward_max: 915.4947092443856
reward_min: 798.0277607554802
total_envstep_count: 755665
total_train_sample_count: 755548
total_episode_count: 839
total_duration: 315.26334954159597
[2023-05-17 14:14:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2007.760831970132
avg_train_sample_per_sec: 2007.760831970132
avg_episode_per_sec: 2.0077608319701317
collect_time: 1.9922691668782915
reward_mean: 854.046000259112
reward_std: 24.31037619092962
reward_max: 873.9207662181924
reward_min: 813.1797201525447
total_envstep_count: 759664
total_train_sample_count: 759548
total_episode_count: 843
total_duration: 317.2556187084743
[2023-05-17 14:14:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4819
train_sample_count: 4819
avg_envstep_per_episode: 963.8
avg_sample_per_episode: 963.8
avg_envstep_per_sec: 2323.0066256233104
avg_train_sample_per_sec: 2323.0066256233104
avg_episode_per_sec: 2.4102579639171093
collect_time: 2.074466747897012
reward_mean: 817.4227020176049
reward_std: 73.3097468492953
reward_max: 918.9145301936813
reward_min: 692.4757581470968
total_envstep_count: 763718
total_train_sample_count: 763617
total_episode_count: 848
total_duration: 319.3300854563713
[2023-05-17 14:14:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 4552
train_sample_count: 4552
avg_envstep_per_episode: 569.0
avg_sample_per_episode: 569.0
avg_envstep_per_sec: 2256.701319792931
avg_train_sample_per_sec: 2256.701319792931
avg_episode_per_sec: 3.9660831630807225
collect_time: 2.017103442123958
reward_mean: 490.51514155665757
reward_std: 324.0192420977862
reward_max: 937.337582025896
reward_min: 28.055556194979104
total_envstep_count: 767984
total_train_sample_count: 767819
total_episode_count: 856
total_duration: 321.3471888984953
[2023-05-17 14:14:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 3189
train_sample_count: 3189
avg_envstep_per_episode: 637.8
avg_sample_per_episode: 637.8
avg_envstep_per_sec: 2230.1016693932556
avg_train_sample_per_sec: 2230.1016693932556
avg_episode_per_sec: 3.4965532602591027
collect_time: 1.429979647908892
reward_mean: 519.830400241882
reward_std: 360.6070295723304
reward_max: 852.6196047413536
reward_min: 9.299093841169196
total_envstep_count: 772013
total_train_sample_count: 771858
total_episode_count: 861
total_duration: 322.7771685464042
[2023-05-17 14:14:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2350.3322740498597
avg_train_sample_per_sec: 2350.3322740498597
avg_episode_per_sec: 2.3503322740498596
collect_time: 1.7018870243004391
reward_mean: 769.3352694845862
reward_std: 54.70975787157164
reward_max: 861.9429597434017
reward_min: 725.6515290420521
total_envstep_count: 776010
total_train_sample_count: 775858
total_episode_count: 865
total_duration: 324.47905557070465
[2023-05-17 14:14:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2394.741281999091
avg_train_sample_per_sec: 2394.741281999091
avg_episode_per_sec: 2.394741281999091
collect_time: 1.6703265735081265
reward_mean: 807.489899416372
reward_std: 30.775585227958317
reward_max: 833.0335731432825
reward_min: 754.9893653812851
total_envstep_count: 780008
total_train_sample_count: 779858
total_episode_count: 869
total_duration: 326.1493821442128
[2023-05-17 14:14:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2511.772729745792
avg_train_sample_per_sec: 2511.772729745792
avg_episode_per_sec: 2.511772729745792
collect_time: 1.5925007675375258
reward_mean: 888.2116368735574
reward_std: 118.41621138156133
reward_max: 1053.9499020511894
reward_min: 773.9751251056791
total_envstep_count: 784005
total_train_sample_count: 783858
total_episode_count: 873
total_duration: 327.7418829117503
[2023-05-17 14:14:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2466.3923377185397
avg_train_sample_per_sec: 2466.3923377185397
avg_episode_per_sec: 2.4663923377185397
collect_time: 1.6218019894191193
reward_mean: 804.7262667800114
reward_std: 35.50012880052792
reward_max: 864.7726325410233
reward_min: 772.3390891705749
total_envstep_count: 788003
total_train_sample_count: 787858
total_episode_count: 877
total_duration: 329.3636849011694
[2023-05-17 14:14:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2057.2682997117313
avg_train_sample_per_sec: 2057.2682997117313
avg_episode_per_sec: 2.057268299711731
collect_time: 1.9443258813449313
reward_mean: 882.0011804533799
reward_std: 54.95863113976149
reward_max: 942.3821833837121
reward_min: 795.67210084838
total_envstep_count: 792000
total_train_sample_count: 791858
total_episode_count: 881
total_duration: 331.3080107825143
[2023-05-17 14:14:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2506.248704710123
avg_train_sample_per_sec: 2506.248704710123
avg_episode_per_sec: 2.5062487047101234
collect_time: 1.5960107999188557
reward_mean: 884.5367931744029
reward_std: 25.77617551064565
reward_max: 916.2757626334337
reward_min: 847.9963506846937
total_envstep_count: 795998
total_train_sample_count: 795858
total_episode_count: 885
total_duration: 332.9040215824332
[2023-05-17 14:14:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4535
train_sample_count: 4535
avg_envstep_per_episode: 907.0
avg_sample_per_episode: 907.0
avg_envstep_per_sec: 2556.7319284929913
avg_train_sample_per_sec: 2556.7319284929913
avg_episode_per_sec: 2.818888565041887
collect_time: 1.7737487256526947
reward_mean: 772.7012321448136
reward_std: 156.72436898167587
reward_max: 882.5898497631243
reward_min: 461.25812980556395
total_envstep_count: 799995
total_train_sample_count: 799893
total_episode_count: 890
total_duration: 334.6777703080859
[2023-05-17 14:15:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2534.560699840149
avg_train_sample_per_sec: 2534.560699840149
avg_episode_per_sec: 2.534560699840149
collect_time: 1.1836370698043277
reward_mean: 921.548175653517
reward_std: 28.67458530923212
reward_max: 957.4714596808868
reward_min: 887.2927921265598
total_envstep_count: 803992
total_train_sample_count: 803893
total_episode_count: 893
total_duration: 335.8614073778902
[2023-05-17 14:15:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2589.057473454544
avg_train_sample_per_sec: 2589.057473454544
avg_episode_per_sec: 2.589057473454544
collect_time: 1.9312047149453844
reward_mean: 822.1728835834068
reward_std: 32.841402901318865
reward_max: 876.0320787774831
reward_min: 790.306971323638
total_envstep_count: 807991
total_train_sample_count: 807893
total_episode_count: 898
total_duration: 337.7926120928356
[2023-05-17 14:15:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2500.00351064755
avg_train_sample_per_sec: 2500.00351064755
avg_episode_per_sec: 2.5000035106475496
collect_time: 1.1999983148915425
reward_mean: 826.0628781692709
reward_std: 10.088116789736057
reward_max: 840.2403323109341
reward_min: 817.593935140406
total_envstep_count: 811988
total_train_sample_count: 811893
total_episode_count: 901
total_duration: 338.99261040772717
[2023-05-17 14:15:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2566.7824419505473
avg_train_sample_per_sec: 2566.7824419505473
avg_episode_per_sec: 2.566782441950547
collect_time: 1.9479640807424272
reward_mean: 765.003132676508
reward_std: 21.40490854646448
reward_max: 799.5619582819868
reward_min: 732.799652252372
total_envstep_count: 815987
total_train_sample_count: 815893
total_episode_count: 906
total_duration: 340.9405744884696
[2023-05-17 14:15:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1967.5710829005086
avg_train_sample_per_sec: 1967.5710829005086
avg_episode_per_sec: 1.9675710829005086
collect_time: 1.5247225505965096
reward_mean: 826.9438334482962
reward_std: 7.204912523547267
reward_max: 836.9274586811006
reward_min: 820.1880573639797
total_envstep_count: 819984
total_train_sample_count: 819893
total_episode_count: 909
total_duration: 342.4652970390661
[2023-05-17 14:15:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2530.150051333772
avg_train_sample_per_sec: 2530.150051333772
avg_episode_per_sec: 2.530150051333772
collect_time: 1.976167380809784
reward_mean: 845.4561567484701
reward_std: 59.4042885712866
reward_max: 928.6853790678313
reward_min: 755.7717987981813
total_envstep_count: 823983
total_train_sample_count: 823893
total_episode_count: 914
total_duration: 344.4414644198759
[2023-05-17 14:15:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2422.8367376120173
avg_train_sample_per_sec: 2422.8367376120173
avg_episode_per_sec: 2.4228367376120175
collect_time: 1.238217975412096
reward_mean: 907.1242918394547
reward_std: 39.95990780707879
reward_max: 963.3520233786588
reward_min: 874.1090994747615
total_envstep_count: 827980
total_train_sample_count: 827893
total_episode_count: 917
total_duration: 345.679682395288
[2023-05-17 14:15:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2401.7658137203953
avg_train_sample_per_sec: 2401.7658137203953
avg_episode_per_sec: 2.401765813720395
collect_time: 2.081801635878427
reward_mean: 823.4228934271484
reward_std: 20.003203420740274
reward_max: 852.620260733931
reward_min: 792.8574376150021
total_envstep_count: 831979
total_train_sample_count: 831893
total_episode_count: 922
total_duration: 347.76148403116645
[2023-05-17 14:15:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2379.1440088942
avg_train_sample_per_sec: 2379.1440088942
avg_episode_per_sec: 2.3791440088941997
collect_time: 1.2609577178955078
reward_mean: 805.8234957535497
reward_std: 54.11574296595549
reward_max: 882.2368587187987
reward_min: 763.9400051390998
total_envstep_count: 835977
total_train_sample_count: 835893
total_episode_count: 925
total_duration: 349.02244174906195
[2023-05-17 14:15:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2473.0835541766196
avg_train_sample_per_sec: 2473.0835541766196
avg_episode_per_sec: 2.4730835541766196
collect_time: 2.021767518350056
reward_mean: 865.9767280614567
reward_std: 61.220793830391116
reward_max: 959.5439822922986
reward_min: 779.4395403146311
total_envstep_count: 839976
total_train_sample_count: 839893
total_episode_count: 930
total_duration: 351.044209267412
[2023-05-17 14:15:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2461.4023395145796
avg_train_sample_per_sec: 2461.4023395145796
avg_episode_per_sec: 2.461402339514579
collect_time: 1.218817400080817
reward_mean: 801.5270824562617
reward_std: 63.24407539910431
reward_max: 888.4532745251012
reward_min: 739.8267317232911
total_envstep_count: 843974
total_train_sample_count: 843893
total_episode_count: 933
total_duration: 352.2630266674928
[2023-05-17 14:15:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2522.4906099386203
avg_train_sample_per_sec: 2522.4906099386203
avg_episode_per_sec: 2.5224906099386204
collect_time: 1.982167933668409
reward_mean: 890.0860120489967
reward_std: 68.51984342313723
reward_max: 1022.3621295767914
reward_min: 825.9908279140527
total_envstep_count: 847973
total_train_sample_count: 847893
total_episode_count: 938
total_duration: 354.2451946011612
[2023-05-17 14:15:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3138
train_sample_count: 3138
avg_envstep_per_episode: 784.5
avg_sample_per_episode: 784.5
avg_envstep_per_sec: 2506.8114672156676
avg_train_sample_per_sec: 2506.8114672156676
avg_episode_per_sec: 3.1954257070945413
collect_time: 1.251789391040802
reward_mean: 644.460011849136
reward_std: 335.07067281290693
reward_max: 1020.5108170852262
reward_min: 148.3126772350841
total_envstep_count: 852115
total_train_sample_count: 851981
total_episode_count: 942
total_duration: 355.496983992202
[2023-05-17 14:16:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5329
train_sample_count: 5329
avg_envstep_per_episode: 888.1666666666666
avg_sample_per_episode: 888.1666666666666
avg_envstep_per_sec: 2200.7794540054842
avg_train_sample_per_sec: 2200.7794540054842
avg_episode_per_sec: 2.47789017152053
collect_time: 2.4214148265974864
reward_mean: 754.4481086586726
reward_std: 157.2839555724801
reward_max: 990.6020260693871
reward_min: 495.4806417566794
total_envstep_count: 856152
total_train_sample_count: 856010
total_episode_count: 948
total_duration: 357.91839881879946
[2023-05-17 14:16:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2480.6784423181616
avg_train_sample_per_sec: 2480.6784423181616
avg_episode_per_sec: 2.480678442318162
collect_time: 0.8062310559409006
reward_mean: 902.0965342285924
reward_std: 43.6259271427046
reward_max: 945.7224613712971
reward_min: 858.4706070858879
total_envstep_count: 860151
total_train_sample_count: 860010
total_episode_count: 950
total_duration: 358.72462987474034
[2023-05-17 14:16:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2570.4392999282377
avg_train_sample_per_sec: 2570.4392999282377
avg_episode_per_sec: 2.5704392999282377
collect_time: 2.334231351103101
reward_mean: 877.5298795881649
reward_std: 97.9871022702878
reward_max: 991.0957709649116
reward_min: 714.8912484442375
total_envstep_count: 864149
total_train_sample_count: 864010
total_episode_count: 956
total_duration: 361.05886122584343
[2023-05-17 14:16:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2511.0439830987852
avg_train_sample_per_sec: 2511.0439830987852
avg_episode_per_sec: 2.511043983098785
collect_time: 0.7964814688478197
reward_mean: 758.7979747956539
reward_std: 68.08804695938034
reward_max: 826.8860217550342
reward_min: 690.7099278362736
total_envstep_count: 868148
total_train_sample_count: 868010
total_episode_count: 958
total_duration: 361.8553426946913
[2023-05-17 14:16:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2581.1540523745975
avg_train_sample_per_sec: 2581.1540523745975
avg_episode_per_sec: 2.5811540523745977
collect_time: 2.32454161133085
reward_mean: 925.091412880212
reward_std: 116.8942421673446
reward_max: 1137.0595176167756
reward_min: 799.0992977826144
total_envstep_count: 872146
total_train_sample_count: 872010
total_episode_count: 964
total_duration: 364.17988430602213
[2023-05-17 14:16:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2499.3850021219623
avg_train_sample_per_sec: 2499.3850021219623
avg_episode_per_sec: 2.4993850021219624
collect_time: 0.8001968477453504
reward_mean: 891.7005537676553
reward_std: 103.73782973723479
reward_max: 995.4383835048901
reward_min: 787.9627240304205
total_envstep_count: 876145
total_train_sample_count: 876010
total_episode_count: 966
total_duration: 364.98008115376746
[2023-05-17 14:16:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2566.5714853206096
avg_train_sample_per_sec: 2566.5714853206096
avg_episode_per_sec: 2.5665714853206096
collect_time: 2.3377490299088612
reward_mean: 917.2187095611592
reward_std: 45.64039064206615
reward_max: 995.5307411984141
reward_min: 850.9059337922761
total_envstep_count: 880143
total_train_sample_count: 880010
total_episode_count: 972
total_duration: 367.31783018367634
[2023-05-17 14:16:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2508.5202622496554
avg_train_sample_per_sec: 2508.5202622496554
avg_episode_per_sec: 2.508520262249655
collect_time: 0.7972827766622816
reward_mean: 827.1057607849853
reward_std: 88.82709256598349
reward_max: 915.9328533509688
reward_min: 738.2786682190018
total_envstep_count: 884142
total_train_sample_count: 884010
total_episode_count: 974
total_duration: 368.1151129603386
[2023-05-17 14:16:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2551.0886575128065
avg_train_sample_per_sec: 2551.0886575128065
avg_episode_per_sec: 2.5510886575128064
collect_time: 2.3519370768751418
reward_mean: 828.490038314172
reward_std: 56.1630356647439
reward_max: 887.670599208917
reward_min: 733.7840551796859
total_envstep_count: 888140
total_train_sample_count: 888010
total_episode_count: 980
total_duration: 370.4670500372137
[2023-05-17 14:16:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1743.676085666177
avg_train_sample_per_sec: 1743.676085666177
avg_episode_per_sec: 1.743676085666177
collect_time: 1.1470020243099759
reward_mean: 894.3674966283459
reward_std: 13.557842868400883
reward_max: 907.9253394967468
reward_min: 880.809653759945
total_envstep_count: 892139
total_train_sample_count: 892010
total_episode_count: 982
total_duration: 371.6140520615237
[2023-05-17 14:16:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2568.659967188815
avg_train_sample_per_sec: 2568.659967188815
avg_episode_per_sec: 2.5686599671888146
collect_time: 2.3358482931341444
reward_mean: 839.1250450374278
reward_std: 51.573289065677706
reward_max: 931.4382812031696
reward_min: 759.1167091543573
total_envstep_count: 896137
total_train_sample_count: 896010
total_episode_count: 988
total_duration: 373.9499003546578
[2023-05-17 14:16:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2523.030165783456
avg_train_sample_per_sec: 2523.030165783456
avg_episode_per_sec: 2.523030165783456
collect_time: 0.7926976169858659
reward_mean: 841.9926758961385
reward_std: 33.231493696598875
reward_max: 875.2241695927374
reward_min: 808.7611821995397
total_envstep_count: 900136
total_train_sample_count: 900010
total_episode_count: 990
total_duration: 374.7425979716437
[2023-05-17 14:16:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2556.3081823516923
avg_train_sample_per_sec: 2556.3081823516923
avg_episode_per_sec: 2.5563081823516924
collect_time: 2.3471348413399284
reward_mean: 822.4118904010207
reward_std: 52.71044978521469
reward_max: 868.6626308909844
reward_min: 746.0533595225008
total_envstep_count: 904134
total_train_sample_count: 904010
total_episode_count: 996
total_duration: 377.08973281298364
[2023-05-17 14:17:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2247
train_sample_count: 2247
avg_envstep_per_episode: 749.0
avg_sample_per_episode: 749.0
avg_envstep_per_sec: 2441.898112906581
avg_train_sample_per_sec: 2441.898112906581
avg_episode_per_sec: 3.2602110986736728
collect_time: 0.9201858128820147
reward_mean: 631.6561521137286
reward_std: 304.8391342673321
reward_max: 885.5758352119598
reward_min: 202.97799396325854
total_envstep_count: 908267
total_train_sample_count: 908057
total_episode_count: 999
total_duration: 378.0099186258657
[2023-05-17 14:17:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5029
train_sample_count: 5029
avg_envstep_per_episode: 838.1666666666666
avg_sample_per_episode: 838.1666666666666
avg_envstep_per_sec: 2340.635631725362
avg_train_sample_per_sec: 2340.635631725362
avg_episode_per_sec: 2.7925658759896943
collect_time: 2.148561669247491
reward_mean: 730.8302602409025
reward_std: 317.1610072911191
reward_max: 909.6691378048178
reward_min: 23.628849568215053
total_envstep_count: 912263
total_train_sample_count: 912086
total_episode_count: 1005
total_duration: 380.1584802951132
[2023-05-17 14:17:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2229.479906755979
avg_train_sample_per_sec: 2229.479906755979
avg_episode_per_sec: 2.2294799067559787
collect_time: 1.3456053095204488
reward_mean: 848.3614667359064
reward_std: 49.91331686306895
reward_max: 905.359591159215
reward_min: 783.8010795405738
total_envstep_count: 916261
total_train_sample_count: 916086
total_episode_count: 1008
total_duration: 381.50408560463364
[2023-05-17 14:17:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2296.260461702096
avg_train_sample_per_sec: 2296.260461702096
avg_episode_per_sec: 2.296260461702096
collect_time: 2.1774533348424097
reward_mean: 761.0202986848816
reward_std: 66.38874484210805
reward_max: 846.144785143169
reward_min: 690.9681802907511
total_envstep_count: 920256
total_train_sample_count: 920086
total_episode_count: 1013
total_duration: 383.68153893947607
[2023-05-17 14:17:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1819.4798012594679
avg_train_sample_per_sec: 1819.4798012594679
avg_episode_per_sec: 1.819479801259468
collect_time: 1.648822920663016
reward_mean: 877.3598672026252
reward_std: 44.66121868095626
reward_max: 939.6383349206351
reward_min: 837.1112412055631
total_envstep_count: 924254
total_train_sample_count: 924086
total_episode_count: 1016
total_duration: 385.3303618601391
[2023-05-17 14:17:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2333.6910491475296
avg_train_sample_per_sec: 2333.6910491475296
avg_episode_per_sec: 2.3336910491475296
collect_time: 2.1425286786896844
reward_mean: 824.7887701077549
reward_std: 52.61317788288646
reward_max: 885.0503630556343
reward_min: 758.2855555232798
total_envstep_count: 928249
total_train_sample_count: 928086
total_episode_count: 1021
total_duration: 387.4728905388288
[2023-05-17 14:17:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2286.860633776074
avg_train_sample_per_sec: 2286.860633776074
avg_episode_per_sec: 2.286860633776074
collect_time: 1.31184207541602
reward_mean: 828.1495726891638
reward_std: 42.69547309811628
reward_max: 887.9995281560015
reward_min: 791.3077851729681
total_envstep_count: 932247
total_train_sample_count: 932086
total_episode_count: 1024
total_duration: 388.7847326142448
[2023-05-17 14:17:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2252.2260743225916
avg_train_sample_per_sec: 2252.2260743225916
avg_episode_per_sec: 2.2522260743225915
collect_time: 2.2200258033616205
reward_mean: 850.7897258342167
reward_std: 92.91668083921418
reward_max: 957.48659732578
reward_min: 733.3475257149655
total_envstep_count: 936243
total_train_sample_count: 936086
total_episode_count: 1029
total_duration: 391.0047584176064
[2023-05-17 14:17:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2148.6239820902433
avg_train_sample_per_sec: 2148.6239820902433
avg_episode_per_sec: 2.1486239820902435
collect_time: 1.3962424440043313
reward_mean: 841.630822524724
reward_std: 98.62321599481271
reward_max: 957.4678199346076
reward_min: 716.4356516143573
total_envstep_count: 940241
total_train_sample_count: 940086
total_episode_count: 1032
total_duration: 392.4010008616107
[2023-05-17 14:17:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2255.6149475870184
avg_train_sample_per_sec: 2255.6149475870184
avg_episode_per_sec: 2.255614947587018
collect_time: 2.216690399817058
reward_mean: 867.9468928150675
reward_std: 71.44195436946886
reward_max: 943.8248177824667
reward_min: 760.511658083875
total_envstep_count: 944236
total_train_sample_count: 944086
total_episode_count: 1037
total_duration: 394.6176912614278
[2023-05-17 14:17:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2343.3771746992606
avg_train_sample_per_sec: 2343.3771746992606
avg_episode_per_sec: 2.3433771746992607
collect_time: 1.2802036447184426
reward_mean: 795.1992554740899
reward_std: 50.03117708415612
reward_max: 857.1836939874526
reward_min: 734.6583466140327
total_envstep_count: 948234
total_train_sample_count: 948086
total_episode_count: 1040
total_duration: 395.89789490614623
[2023-05-17 14:17:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4857
train_sample_count: 4857
avg_envstep_per_episode: 971.4
avg_sample_per_episode: 971.4
avg_envstep_per_sec: 2356.7093844704264
avg_train_sample_per_sec: 2356.7093844704264
avg_episode_per_sec: 2.4260957221231485
collect_time: 2.0609244533947537
reward_mean: 808.2620449992926
reward_std: 54.20594221121764
reward_max: 884.1770554126404
reward_min: 730.2084880832397
total_envstep_count: 952229
total_train_sample_count: 952093
total_episode_count: 1045
total_duration: 397.958819359541
[2023-05-17 14:18:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1877.4157264582043
avg_train_sample_per_sec: 1877.4157264582043
avg_episode_per_sec: 1.8774157264582043
collect_time: 1.597941232579095
reward_mean: 768.2381747322585
reward_std: 83.13578284608307
reward_max: 838.814690578123
reward_min: 651.5155620047325
total_envstep_count: 956227
total_train_sample_count: 956093
total_episode_count: 1048
total_duration: 399.5567605921201
[2023-05-17 14:18:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2487.6829568823196
avg_train_sample_per_sec: 2487.6829568823196
avg_episode_per_sec: 2.4876829568823196
collect_time: 2.009902421917234
reward_mean: 856.1902042993815
reward_std: 69.09381734640726
reward_max: 926.1710733700988
reward_min: 723.651587667632
total_envstep_count: 960222
total_train_sample_count: 960093
total_episode_count: 1053
total_duration: 401.5666630140373
[2023-05-17 14:18:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2477.4466791468762
avg_train_sample_per_sec: 2477.4466791468762
avg_episode_per_sec: 2.4774466791468766
collect_time: 1.2109241443020957
reward_mean: 804.9928223103676
reward_std: 24.026400851166784
reward_max: 835.8860769799355
reward_min: 777.294378019216
total_envstep_count: 964220
total_train_sample_count: 964093
total_episode_count: 1056
total_duration: 402.77758715833943
[2023-05-17 14:18:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2515.1853115737113
avg_train_sample_per_sec: 2515.1853115737113
avg_episode_per_sec: 2.515185311573711
collect_time: 1.9879250952175687
reward_mean: 859.9844971515216
reward_std: 31.592412119466065
reward_max: 908.8829395767845
reward_min: 821.956510050751
total_envstep_count: 968215
total_train_sample_count: 968093
total_episode_count: 1061
total_duration: 404.765512253557
[2023-05-17 14:18:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2493.1353347738195
avg_train_sample_per_sec: 2493.1353347738195
avg_episode_per_sec: 2.4931353347738194
collect_time: 1.20330411195755
reward_mean: 885.6035839630122
reward_std: 18.306155357461876
reward_max: 910.5123876166329
reward_min: 867.0388129684407
total_envstep_count: 972213
total_train_sample_count: 972093
total_episode_count: 1064
total_duration: 405.96881636551456
[2023-05-17 14:18:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2503.87842553178
avg_train_sample_per_sec: 2503.87842553178
avg_episode_per_sec: 2.50387842553178
collect_time: 1.9969020656176977
reward_mean: 867.9728462176193
reward_std: 36.46056887020731
reward_max: 922.6836124526733
reward_min: 808.8836184230094
total_envstep_count: 976208
total_train_sample_count: 976093
total_episode_count: 1069
total_duration: 407.96571843113225
[2023-05-17 14:18:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2508.357326117699
avg_train_sample_per_sec: 2508.357326117699
avg_episode_per_sec: 2.508357326117699
collect_time: 1.1960018490042004
reward_mean: 772.7542199547788
reward_std: 31.721076474767504
reward_max: 814.698657508679
reward_min: 738.0038243103221
total_envstep_count: 980206
total_train_sample_count: 980093
total_episode_count: 1072
total_duration: 409.1617202801364
[2023-05-17 14:18:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2536.913584256294
avg_train_sample_per_sec: 2536.913584256294
avg_episode_per_sec: 2.536913584256294
collect_time: 1.970898824078696
reward_mean: 757.483964193208
reward_std: 38.016468199622345
reward_max: 799.327103626458
reward_min: 704.6478796539201
total_envstep_count: 984201
total_train_sample_count: 984093
total_episode_count: 1077
total_duration: 411.1326191042151
[2023-05-17 14:18:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2444.4138994254968
avg_train_sample_per_sec: 2444.4138994254968
avg_episode_per_sec: 2.4444138994254967
collect_time: 1.227288063083376
reward_mean: 765.9656553388282
reward_std: 45.971264414400075
reward_max: 827.8920855328158
reward_min: 717.8596965769506
total_envstep_count: 988199
total_train_sample_count: 988093
total_episode_count: 1080
total_duration: 412.3599071672985
[2023-05-17 14:18:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2093.5449193043387
avg_train_sample_per_sec: 2093.5449193043387
avg_episode_per_sec: 2.0935449193043385
collect_time: 2.3882936324392046
reward_mean: 923.0315281385059
reward_std: 73.44602587645055
reward_max: 1008.5511137557527
reward_min: 786.1776023607636
total_envstep_count: 992194
total_train_sample_count: 992093
total_episode_count: 1085
total_duration: 414.74820079973773
[2023-05-17 14:18:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2465.5934605345265
avg_train_sample_per_sec: 2465.5934605345265
avg_episode_per_sec: 2.4655934605345267
collect_time: 1.2167456022330694
reward_mean: 845.4274981622881
reward_std: 67.01663140241335
reward_max: 923.0837707014498
reward_min: 759.5465104564448
total_envstep_count: 996192
total_train_sample_count: 996093
total_episode_count: 1088
total_duration: 415.9649464019708
[2023-05-17 14:18:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2533.3193023489944
avg_train_sample_per_sec: 2533.3193023489944
avg_episode_per_sec: 2.5333193023489944
collect_time: 1.9736951419285367
reward_mean: 847.7007700007665
reward_std: 59.20476463430437
reward_max: 894.8571805846174
reward_min: 732.8059909988716
total_envstep_count: 1000187
total_train_sample_count: 1000093
total_episode_count: 1093
total_duration: 417.93864154389934
[2023-05-17 14:19:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2533.073459094049
avg_train_sample_per_sec: 2533.073459094049
avg_episode_per_sec: 2.5330734590940494
collect_time: 1.1843320173876626
reward_mean: 809.7836084282407
reward_std: 14.594928149090528
reward_max: 827.9637688299076
reward_min: 792.230123632156
total_envstep_count: 1004185
total_train_sample_count: 1004093
total_episode_count: 1096
total_duration: 419.122973561287
[2023-05-17 14:19:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2560.731894453947
avg_train_sample_per_sec: 2560.731894453947
avg_episode_per_sec: 2.560731894453947
collect_time: 1.9525667684418815
reward_mean: 891.4610029592975
reward_std: 77.9282349767072
reward_max: 978.4258503227679
reward_min: 767.9265234898977
total_envstep_count: 1008180
total_train_sample_count: 1008093
total_episode_count: 1101
total_duration: 421.0755403297289
[2023-05-17 14:19:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2541.420235474845
avg_train_sample_per_sec: 2541.420235474845
avg_episode_per_sec: 2.541420235474845
collect_time: 1.1804423204490118
reward_mean: 869.7039774024239
reward_std: 81.10528820920379
reward_max: 942.3619768145853
reward_min: 756.513329234228
total_envstep_count: 1012178
total_train_sample_count: 1012093
total_episode_count: 1104
total_duration: 422.2559826501779
[2023-05-17 14:19:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2554.4248799446204
avg_train_sample_per_sec: 2554.4248799446204
avg_episode_per_sec: 2.5544248799446208
collect_time: 1.9573877624103
reward_mean: 872.953939185088
reward_std: 60.37723601408639
reward_max: 926.780905471346
reward_min: 754.9870853079682
total_envstep_count: 1016173
total_train_sample_count: 1016093
total_episode_count: 1109
total_duration: 424.2133704125882
[2023-05-17 14:19:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2515.5551281427956
avg_train_sample_per_sec: 2515.5551281427956
avg_episode_per_sec: 2.5155551281427955
collect_time: 1.1925797079290663
reward_mean: 901.8251299230932
reward_std: 12.039124133671013
reward_max: 917.9969936062337
reward_min: 889.1279202088123
total_envstep_count: 1020171
total_train_sample_count: 1020093
total_episode_count: 1112
total_duration: 425.4059501205172
[2023-05-17 14:19:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2161.705211607046
avg_train_sample_per_sec: 2161.705211607046
avg_episode_per_sec: 2.161705211607046
collect_time: 2.312988826206752
reward_mean: 906.0333672521543
reward_std: 80.61082194717953
reward_max: 994.269047865912
reward_min: 771.6244407719231
total_envstep_count: 1024167
total_train_sample_count: 1024093
total_episode_count: 1117
total_duration: 427.718938946724
[2023-05-17 14:19:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2505.201404227811
avg_train_sample_per_sec: 2505.201404227811
avg_episode_per_sec: 2.5052014042278112
collect_time: 1.1975085096699851
reward_mean: 951.9460219370894
reward_std: 19.37293500817275
reward_max: 971.1721001763545
reward_min: 925.4293041379632
total_envstep_count: 1028165
total_train_sample_count: 1028093
total_episode_count: 1120
total_duration: 428.916447456394
[2023-05-17 14:19:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2549.5653400816163
avg_train_sample_per_sec: 2549.5653400816163
avg_episode_per_sec: 2.549565340081616
collect_time: 1.9611185959407265
reward_mean: 830.3150337300027
reward_std: 70.38856052389944
reward_max: 942.3833621522361
reward_min: 739.1706520360754
total_envstep_count: 1032161
total_train_sample_count: 1032093
total_episode_count: 1125
total_duration: 430.8775660523347
[2023-05-17 14:19:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2560.1207739266874
avg_train_sample_per_sec: 2560.1207739266874
avg_episode_per_sec: 2.5601207739266876
collect_time: 1.1718197166919708
reward_mean: 922.3297315006995
reward_std: 48.48158337827055
reward_max: 968.4036742435106
reward_min: 855.3201579730032
total_envstep_count: 1036159
total_train_sample_count: 1036093
total_episode_count: 1128
total_duration: 432.0493857690267
[2023-05-17 14:19:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2566.964700227567
avg_train_sample_per_sec: 2566.964700227567
avg_episode_per_sec: 2.566964700227567
collect_time: 1.9478257724217007
reward_mean: 911.4071753307569
reward_std: 50.397509829531295
reward_max: 967.629502305172
reward_min: 848.5921722061671
total_envstep_count: 1040155
total_train_sample_count: 1040093
total_episode_count: 1133
total_duration: 433.9972115414484
[2023-05-17 14:19:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2529.3196926407545
avg_train_sample_per_sec: 2529.3196926407545
avg_episode_per_sec: 2.5293196926407546
collect_time: 1.18608968598502
reward_mean: 859.1009008395986
reward_std: 25.0768438965219
reward_max: 893.3332500015797
reward_min: 833.9608959479054
total_envstep_count: 1044153
total_train_sample_count: 1044093
total_episode_count: 1136
total_duration: 435.1833012274334
[2023-05-17 14:19:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2538.056877485633
avg_train_sample_per_sec: 2538.056877485633
avg_episode_per_sec: 2.5380568774856327
collect_time: 1.9700110128947665
reward_mean: 901.9141796964138
reward_std: 50.86609289501561
reward_max: 959.8057410182577
reward_min: 819.6424947620065
total_envstep_count: 1048151
total_train_sample_count: 1048093
total_episode_count: 1141
total_duration: 437.15331224032815
[2023-05-17 14:19:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2528.4697930362267
avg_train_sample_per_sec: 2528.4697930362267
avg_episode_per_sec: 2.5284697930362268
collect_time: 1.1864883686814989
reward_mean: 942.1163627539685
reward_std: 38.42241010658861
reward_max: 993.1267678796584
reward_min: 900.3976989849817
total_envstep_count: 1052149
total_train_sample_count: 1052093
total_episode_count: 1144
total_duration: 438.33980060900967
[2023-05-17 14:19:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2532.535171895248
avg_train_sample_per_sec: 2532.535171895248
avg_episode_per_sec: 2.532535171895248
collect_time: 1.9743062428065707
reward_mean: 878.3840957082309
reward_std: 118.55500026629771
reward_max: 1034.9062038569332
reward_min: 667.7754555910285
total_envstep_count: 1056146
total_train_sample_count: 1056093
total_episode_count: 1149
total_duration: 440.31410685181623
[2023-05-17 14:20:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1889.013757117539
avg_train_sample_per_sec: 1889.013757117539
avg_episode_per_sec: 1.889013757117539
collect_time: 1.5881303080490656
reward_mean: 772.8028139493132
reward_std: 67.68900114294588
reward_max: 868.5171460419001
reward_min: 723.612873485838
total_envstep_count: 1060144
total_train_sample_count: 1060093
total_episode_count: 1152
total_duration: 441.9022371598653
[2023-05-17 14:20:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2428.5543828574437
avg_train_sample_per_sec: 2428.5543828574437
avg_episode_per_sec: 2.4285543828574436
collect_time: 2.058837980031967
reward_mean: 932.8359120719211
reward_std: 124.04632821562643
reward_max: 1038.8222376257008
reward_min: 717.8603657278371
total_envstep_count: 1064142
total_train_sample_count: 1064093
total_episode_count: 1157
total_duration: 443.9610751398973
[2023-05-17 14:20:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2438.754429879263
avg_train_sample_per_sec: 2438.754429879263
avg_episode_per_sec: 2.438754429879263
collect_time: 1.2301361560821533
reward_mean: 757.5068879247659
reward_std: 47.4422300275757
reward_max: 800.3826280132769
reward_min: 691.3767258282902
total_envstep_count: 1068140
total_train_sample_count: 1068093
total_episode_count: 1160
total_duration: 445.19121129597943
[2023-05-17 14:20:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2459.3308518701074
avg_train_sample_per_sec: 2459.3308518701074
avg_episode_per_sec: 2.459330851870108
collect_time: 2.033073344400951
reward_mean: 1002.5872322458121
reward_std: 84.79099439789731
reward_max: 1105.0983294581572
reward_min: 899.8426484762962
total_envstep_count: 1072137
total_train_sample_count: 1072093
total_episode_count: 1165
total_duration: 447.2242846403804
[2023-05-17 14:20:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2410.091236215004
avg_train_sample_per_sec: 2410.091236215004
avg_episode_per_sec: 2.410091236215004
collect_time: 1.2447661544595445
reward_mean: 935.5002734303862
reward_std: 69.59713491894291
reward_max: 1013.5922750022326
reward_min: 844.5710262997577
total_envstep_count: 1076135
total_train_sample_count: 1076093
total_episode_count: 1168
total_duration: 448.46905079484
[2023-05-17 14:20:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2407.7325946935075
avg_train_sample_per_sec: 2407.7325946935075
avg_episode_per_sec: 2.4077325946935075
collect_time: 2.0766425686223164
reward_mean: 823.5476411439319
reward_std: 82.19169131064628
reward_max: 928.7824536911177
reward_min: 719.0576728148551
total_envstep_count: 1080132
total_train_sample_count: 1080093
total_episode_count: 1173
total_duration: 450.5456933634623
[2023-05-17 14:20:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2408.1484877076955
avg_train_sample_per_sec: 2408.1484877076955
avg_episode_per_sec: 2.4081484877076953
collect_time: 1.2457703564848217
reward_mean: 954.2626794155973
reward_std: 117.25765011739303
reward_max: 1093.3612894053733
reward_min: 806.5295059390105
total_envstep_count: 1084131
total_train_sample_count: 1084093
total_episode_count: 1176
total_duration: 451.7914637199471
[2023-05-17 14:20:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2393.5356069988193
avg_train_sample_per_sec: 2393.5356069988193
avg_episode_per_sec: 2.393535606998819
collect_time: 2.0889599408422197
reward_mean: 1008.3917444512447
reward_std: 51.7415999060247
reward_max: 1075.4423481167466
reward_min: 938.5867572195243
total_envstep_count: 1088128
total_train_sample_count: 1088093
total_episode_count: 1181
total_duration: 453.88042366078935
[2023-05-17 14:20:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2295.4715086379624
avg_train_sample_per_sec: 2295.4715086379624
avg_episode_per_sec: 2.2954715086379625
collect_time: 1.3069210350513458
reward_mean: 1030.9289307437593
reward_std: 7.450821357723201
reward_max: 1036.6932347729266
reward_min: 1020.4079497841377
total_envstep_count: 1092127
total_train_sample_count: 1092093
total_episode_count: 1184
total_duration: 455.1873446958407
[2023-05-17 14:20:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1991.9298122844841
avg_train_sample_per_sec: 1991.9298122844841
avg_episode_per_sec: 1.991929812284484
collect_time: 2.510128604514258
reward_mean: 968.7835741927286
reward_std: 91.28035558139305
reward_max: 1095.281647196673
reward_min: 812.7717900678842
total_envstep_count: 1096124
total_train_sample_count: 1096093
total_episode_count: 1189
total_duration: 457.69747330035494
[2023-05-17 14:20:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2397.0373612791345
avg_train_sample_per_sec: 2397.0373612791345
avg_episode_per_sec: 2.3970373612791347
collect_time: 1.2515449481351035
reward_mean: 1007.0269632811411
reward_std: 59.247715634226545
reward_max: 1090.6538332885661
reward_min: 960.7026889561729
total_envstep_count: 1100123
total_train_sample_count: 1100093
total_episode_count: 1192
total_duration: 458.94901824849006
[2023-05-17 14:21:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2481.292485253599
avg_train_sample_per_sec: 2481.292485253599
avg_episode_per_sec: 2.481292485253599
collect_time: 2.0150788468973975
reward_mean: 902.3657153824219
reward_std: 122.52883203401103
reward_max: 1086.514533674903
reward_min: 729.9826382464681
total_envstep_count: 1104120
total_train_sample_count: 1104093
total_episode_count: 1197
total_duration: 460.96409709538744
[2023-05-17 14:21:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2233.5597269838886
avg_train_sample_per_sec: 2233.5597269838886
avg_episode_per_sec: 2.2335597269838883
collect_time: 1.3431474268436432
reward_mean: 914.9074910515033
reward_std: 145.07621402707525
reward_max: 1042.890905682289
reward_min: 712.0422945481884
total_envstep_count: 1108120
total_train_sample_count: 1108093
total_episode_count: 1200
total_duration: 462.3072445222311
[2023-05-17 14:21:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2117.327728573961
avg_train_sample_per_sec: 2117.327728573961
avg_episode_per_sec: 2.1173277285739607
collect_time: 2.361467208181109
reward_mean: 1014.9440966665028
reward_std: 73.64360560437487
reward_max: 1113.3743027466276
reward_min: 888.1318902892917
total_envstep_count: 1112117
total_train_sample_count: 1112093
total_episode_count: 1205
total_duration: 464.6687117304122
[2023-05-17 14:21:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2049.907226858471
avg_train_sample_per_sec: 2049.907226858471
avg_episode_per_sec: 2.049907226858471
collect_time: 1.4634808642523631
reward_mean: 981.3319729793961
reward_std: 149.85102086025265
reward_max: 1108.406236714789
reward_min: 770.920434555041
total_envstep_count: 1116117
total_train_sample_count: 1116093
total_episode_count: 1208
total_duration: 466.13219259466456
[2023-05-17 14:21:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1823.3393291395614
avg_train_sample_per_sec: 1823.3393291395614
avg_episode_per_sec: 1.8233393291395614
collect_time: 2.742221329893385
reward_mean: 964.7992463745743
reward_std: 37.059858826230176
reward_max: 1025.3467662356793
reward_min: 924.0137871515568
total_envstep_count: 1120114
total_train_sample_count: 1120093
total_episode_count: 1213
total_duration: 468.8744139245579
[2023-05-17 14:21:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1629.4171295979165
avg_train_sample_per_sec: 1629.4171295979165
avg_episode_per_sec: 1.6294171295979165
collect_time: 1.841149172612599
reward_mean: 954.0300171914517
reward_std: 31.91632706869599
reward_max: 982.4009447442523
reward_min: 909.4423207227101
total_envstep_count: 1124114
total_train_sample_count: 1124093
total_episode_count: 1216
total_duration: 470.7155630971705
[2023-05-17 14:21:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1599.4402462937662
avg_train_sample_per_sec: 1599.4402462937662
avg_episode_per_sec: 1.5994402462937662
collect_time: 3.1260936515671864
reward_mean: 843.0122606818361
reward_std: 156.81249878176686
reward_max: 1064.49534236827
reward_min: 624.6095889434525
total_envstep_count: 1128112
total_train_sample_count: 1128093
total_episode_count: 1221
total_duration: 473.8416567487377
[2023-05-17 14:21:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1648.7681131265635
avg_train_sample_per_sec: 1648.7681131265635
avg_episode_per_sec: 1.6487681131265637
collect_time: 1.8195402835096632
reward_mean: 800.7584196592306
reward_std: 162.89811976033803
reward_max: 1031.0356083325423
reward_min: 679.8745303155993
total_envstep_count: 1132112
total_train_sample_count: 1132093
total_episode_count: 1224
total_duration: 475.66119703224734
[2023-05-17 14:21:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1830.9606785852438
avg_train_sample_per_sec: 1830.9606785852438
avg_episode_per_sec: 1.830960678585244
collect_time: 2.730806870119912
reward_mean: 930.351155345573
reward_std: 173.3537112155624
reward_max: 1186.6028742715573
reward_min: 678.2437528715035
total_envstep_count: 1136110
total_train_sample_count: 1136093
total_episode_count: 1229
total_duration: 478.39200390236726
[2023-05-17 14:21:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2022.3328993236737
avg_train_sample_per_sec: 2022.3328993236737
avg_episode_per_sec: 2.0223328993236738
collect_time: 1.4834352944578444
reward_mean: 991.0491393413243
reward_std: 31.937262130690765
reward_max: 1023.2211868359594
reward_min: 947.509471234671
total_envstep_count: 1140110
total_train_sample_count: 1140093
total_episode_count: 1232
total_duration: 479.8754391968251
[2023-05-17 14:22:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2230.0202163249555
avg_train_sample_per_sec: 2230.0202163249555
avg_episode_per_sec: 2.2300202163249554
collect_time: 2.2421321400574277
reward_mean: 941.7408411014761
reward_std: 91.6585902223563
reward_max: 1108.0997802424772
reward_min: 843.2198899624375
total_envstep_count: 1144108
total_train_sample_count: 1144093
total_episode_count: 1237
total_duration: 482.1175713368825
[2023-05-17 14:22:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2345.034734078134
avg_train_sample_per_sec: 2345.034734078134
avg_episode_per_sec: 2.3450347340781343
collect_time: 1.2792987482888358
reward_mean: 908.6241981734205
reward_std: 186.68714803535093
reward_max: 1053.7812323984856
reward_min: 645.0608297673965
total_envstep_count: 1148108
total_train_sample_count: 1148093
total_episode_count: 1240
total_duration: 483.3968700851714
[2023-05-17 14:22:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2406.728296034307
avg_train_sample_per_sec: 2406.728296034307
avg_episode_per_sec: 2.4067282960343066
collect_time: 2.077509126492909
reward_mean: 962.3419799291453
reward_std: 146.6831421192413
reward_max: 1180.8566120218888
reward_min: 796.5477816455182
total_envstep_count: 1152107
total_train_sample_count: 1152093
total_episode_count: 1245
total_duration: 485.47437921166426
[2023-05-17 14:22:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2396.2661178493936
avg_train_sample_per_sec: 2396.2661178493936
avg_episode_per_sec: 2.3962661178493936
collect_time: 1.2519477605819702
reward_mean: 844.6426071859147
reward_std: 75.09863112772817
reward_max: 930.3847125211648
reward_min: 747.4951772865968
total_envstep_count: 1156107
total_train_sample_count: 1156093
total_episode_count: 1248
total_duration: 486.7263269722462
[2023-05-17 14:22:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2144.6289728158595
avg_train_sample_per_sec: 2144.6289728158595
avg_episode_per_sec: 2.14462897281586
collect_time: 2.331405601331166
reward_mean: 863.006912233572
reward_std: 88.73956262241165
reward_max: 991.2429518304181
reward_min: 755.554578635307
total_envstep_count: 1160106
total_train_sample_count: 1160093
total_episode_count: 1253
total_duration: 489.05773257357737
[2023-05-17 14:22:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2474.9958317344694
avg_train_sample_per_sec: 2474.9958317344694
avg_episode_per_sec: 2.4749958317344696
collect_time: 1.2121232535157884
reward_mean: 892.378064571511
reward_std: 95.9899697454186
reward_max: 979.9338497981825
reward_min: 758.7580894322492
total_envstep_count: 1164106
total_train_sample_count: 1164093
total_episode_count: 1256
total_duration: 490.2698558270932
[2023-05-17 14:22:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2486.811402299044
avg_train_sample_per_sec: 2486.811402299044
avg_episode_per_sec: 2.4868114022990437
collect_time: 2.0106068338666643
reward_mean: 955.0801718999282
reward_std: 90.32221986523105
reward_max: 1097.8494972934145
reward_min: 855.5816004017448
total_envstep_count: 1168105
total_train_sample_count: 1168093
total_episode_count: 1261
total_duration: 492.28046266095987
[2023-05-17 14:22:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2297.9341015482078
avg_train_sample_per_sec: 2297.9341015482078
avg_episode_per_sec: 2.2979341015482078
collect_time: 1.305520466395787
reward_mean: 874.6776255782773
reward_std: 120.23445170949833
reward_max: 991.2956727049285
reward_min: 709.2021036112988
total_envstep_count: 1172105
total_train_sample_count: 1172093
total_episode_count: 1264
total_duration: 493.58598312735563
[2023-05-17 14:22:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2200.7459784250404
avg_train_sample_per_sec: 2200.7459784250404
avg_episode_per_sec: 2.2007459784250405
collect_time: 2.2719568950789313
reward_mean: 890.6306913134958
reward_std: 181.02153707993506
reward_max: 1128.5979778548126
reward_min: 594.2711618727136
total_envstep_count: 1176104
total_train_sample_count: 1176093
total_episode_count: 1269
total_duration: 495.85794002243455
[2023-05-17 14:22:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2154.883628381541
avg_train_sample_per_sec: 2154.883628381541
avg_episode_per_sec: 2.154883628381541
collect_time: 1.3921865480286735
reward_mean: 1026.6274615070643
reward_std: 185.5761698521199
reward_max: 1274.227527610731
reward_min: 827.4720857477015
total_envstep_count: 1180104
total_train_sample_count: 1180093
total_episode_count: 1272
total_duration: 497.25012657046324
[2023-05-17 14:22:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2169.113005684824
avg_train_sample_per_sec: 2169.113005684824
avg_episode_per_sec: 2.169113005684824
collect_time: 2.3050896780831476
reward_mean: 1049.3853430700262
reward_std: 143.82068046517418
reward_max: 1223.6710415812263
reward_min: 867.2566493580865
total_envstep_count: 1184103
total_train_sample_count: 1184093
total_episode_count: 1277
total_duration: 499.5552162485464
[2023-05-17 14:22:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1923.190700950608
avg_train_sample_per_sec: 1923.190700950608
avg_episode_per_sec: 1.9231907009506082
collect_time: 1.559907708849226
reward_mean: 876.7641661581084
reward_std: 68.25388454385849
reward_max: 959.4443091706488
reward_min: 792.2861230194243
total_envstep_count: 1188103
total_train_sample_count: 1188093
total_episode_count: 1280
total_duration: 501.1151239573956
[2023-05-17 14:23:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1586.9716487305082
avg_train_sample_per_sec: 1586.9716487305082
avg_episode_per_sec: 1.586971648730508
collect_time: 3.15065489922251
reward_mean: 996.7077960555623
reward_std: 197.24825836216465
reward_max: 1261.1459936846134
reward_min: 719.5002087086455
total_envstep_count: 1192102
total_train_sample_count: 1192093
total_episode_count: 1285
total_duration: 504.2657788566181
[2023-05-17 14:23:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1466.5185497158795
avg_train_sample_per_sec: 1466.5185497158795
avg_episode_per_sec: 1.4665185497158797
collect_time: 2.045661134379251
reward_mean: 950.0535342354539
reward_std: 257.54181744450625
reward_max: 1301.772659807017
reward_min: 692.2676378974479
total_envstep_count: 1196102
total_train_sample_count: 1196093
total_episode_count: 1288
total_duration: 506.31143999099737
[2023-05-17 14:23:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1579.1044197540289
avg_train_sample_per_sec: 1579.1044197540289
avg_episode_per_sec: 1.579104419754029
collect_time: 3.1663517228194644
reward_mean: 925.8209634304678
reward_std: 220.58427004626444
reward_max: 1249.9472588743995
reward_min: 623.9382593923483
total_envstep_count: 1200101
total_train_sample_count: 1200093
total_episode_count: 1293
total_duration: 509.4777917138168
[2023-05-17 14:23:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1549.647008646713
avg_train_sample_per_sec: 1549.647008646713
avg_episode_per_sec: 1.549647008646713
collect_time: 1.9359247514179774
reward_mean: 879.3721674090644
reward_std: 29.728558805625653
reward_max: 917.2934579301528
reward_min: 844.6901161394916
total_envstep_count: 1204101
total_train_sample_count: 1204093
total_episode_count: 1296
total_duration: 511.4137164652348
[2023-05-17 14:23:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1609.0951713111376
avg_train_sample_per_sec: 1609.0951713111376
avg_episode_per_sec: 1.6090951713111377
collect_time: 3.107336401939392
reward_mean: 1040.6325588294012
reward_std: 140.0789075527225
reward_max: 1218.9792051004415
reward_min: 791.7110120470512
total_envstep_count: 1208101
total_train_sample_count: 1208093
total_episode_count: 1301
total_duration: 514.5210528671741
[2023-05-17 14:23:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1642.7677997960823
avg_train_sample_per_sec: 1642.7677997960823
avg_episode_per_sec: 1.6427677997960821
collect_time: 1.8261862695217133
reward_mean: 858.7329860443409
reward_std: 59.49102830507524
reward_max: 928.9854078698545
reward_min: 783.5166068364713
total_envstep_count: 1212101
total_train_sample_count: 1212093
total_episode_count: 1304
total_duration: 516.3472391366959
[2023-05-17 14:23:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5087
train_sample_count: 5087
avg_envstep_per_episode: 847.8333333333334
avg_sample_per_episode: 847.8333333333334
avg_envstep_per_sec: 1748.284071359736
avg_train_sample_per_sec: 1748.284071359736
avg_episode_per_sec: 2.0620610238172628
collect_time: 2.909710202898298
reward_mean: 659.6298850783604
reward_std: 304.9730710934482
reward_max: 1055.3796883226573
reward_min: 108.29804384910756
total_envstep_count: 1216403
total_train_sample_count: 1216130
total_episode_count: 1310
total_duration: 519.2569493395941
[2023-05-17 14:23:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1847.3551977623736
avg_train_sample_per_sec: 1847.3551977623736
avg_episode_per_sec: 1.8473551977623737
collect_time: 1.623943247965404
reward_mean: 953.3317176879212
reward_std: 66.79492367167384
reward_max: 1025.2149240494566
reward_min: 864.3152030626133
total_envstep_count: 1220403
total_train_sample_count: 1220130
total_episode_count: 1313
total_duration: 520.8808925875595
[2023-05-17 14:23:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1953.9593838602611
avg_train_sample_per_sec: 1953.9593838602611
avg_episode_per_sec: 1.9539593838602611
collect_time: 2.5589068233966827
reward_mean: 706.8747841695177
reward_std: 110.73657339859427
reward_max: 860.5148102372405
reward_min: 534.2948990414748
total_envstep_count: 1224402
total_train_sample_count: 1224130
total_episode_count: 1318
total_duration: 523.4397994109562
[2023-05-17 14:24:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1611.8628563045122
avg_train_sample_per_sec: 1611.8628563045122
avg_episode_per_sec: 1.611862856304512
collect_time: 1.8612005284854345
reward_mean: 875.5576492419872
reward_std: 85.64825517987835
reward_max: 996.5950182200382
reward_min: 811.051245330829
total_envstep_count: 1228402
total_train_sample_count: 1228130
total_episode_count: 1321
total_duration: 525.3009999394417
[2023-05-17 14:24:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2066.2168376458335
avg_train_sample_per_sec: 2066.2168376458335
avg_episode_per_sec: 2.0662168376458334
collect_time: 2.419881548200335
reward_mean: 821.8910952668846
reward_std: 154.16621650764898
reward_max: 1057.2696378296675
reward_min: 648.8059886066527
total_envstep_count: 1232401
total_train_sample_count: 1232130
total_episode_count: 1326
total_duration: 527.720881487642
[2023-05-17 14:24:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2058.83716294738
avg_train_sample_per_sec: 2058.83716294738
avg_episode_per_sec: 2.05883716294738
collect_time: 1.4571332080023631
reward_mean: 838.2732029751638
reward_std: 47.21558584811034
reward_max: 904.950020639558
reward_min: 801.8333734874822
total_envstep_count: 1236401
total_train_sample_count: 1236130
total_episode_count: 1329
total_duration: 529.1780146956444
[2023-05-17 14:24:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 5776
train_sample_count: 5776
avg_envstep_per_episode: 825.1428571428571
avg_sample_per_episode: 825.1428571428571
avg_envstep_per_sec: 2128.022747759797
avg_train_sample_per_sec: 2128.022747759797
avg_episode_per_sec: 2.5789749366895043
collect_time: 2.714256699596133
reward_mean: 744.2738288408526
reward_std: 321.3383448359333
reward_max: 1210.9826610711762
reward_min: 130.3550630637075
total_envstep_count: 1240398
total_train_sample_count: 1240156
total_episode_count: 1336
total_duration: 531.8922713952405
[2023-05-17 14:24:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2078.871719950931
avg_train_sample_per_sec: 2078.871719950931
avg_episode_per_sec: 2.078871719950931
collect_time: 0.9620603237833296
reward_mean: 976.8998019984954
reward_std: 143.85566466756933
reward_max: 1120.7554666660646
reward_min: 833.044137330926
total_envstep_count: 1244398
total_train_sample_count: 1244156
total_episode_count: 1338
total_duration: 532.8543317190239
[2023-05-17 14:24:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 5880
train_sample_count: 5880
avg_envstep_per_episode: 840.0
avg_sample_per_episode: 840.0
avg_envstep_per_sec: 2025.914263862574
avg_train_sample_per_sec: 2025.914263862574
avg_episode_per_sec: 2.411802695074493
collect_time: 2.9023933070046564
reward_mean: 817.2496978232663
reward_std: 222.03467223780098
reward_max: 1056.337432005166
reward_min: 345.48147838156
total_envstep_count: 1248426
total_train_sample_count: 1248186
total_episode_count: 1345
total_duration: 535.7567250260286
[2023-05-17 14:24:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1771
train_sample_count: 1771
avg_envstep_per_episode: 885.5
avg_sample_per_episode: 885.5
avg_envstep_per_sec: 1708.4171373814447
avg_train_sample_per_sec: 1708.4171373814447
avg_episode_per_sec: 1.9293248304702932
collect_time: 1.0366320737770627
reward_mean: 813.2512089771095
reward_std: 108.69756509466117
reward_max: 921.9487740717707
reward_min: 704.5536438824483
total_envstep_count: 1252425
total_train_sample_count: 1252207
total_episode_count: 1347
total_duration: 536.7933570998056
[2023-05-17 14:24:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1507.0342351284735
avg_train_sample_per_sec: 1507.0342351284735
avg_episode_per_sec: 1.5070342351284736
collect_time: 3.9813295943396434
reward_mean: 765.6139511889573
reward_std: 121.94651830345795
reward_max: 938.240469397338
reward_min: 620.3147251713473
total_envstep_count: 1256422
total_train_sample_count: 1256207
total_episode_count: 1353
total_duration: 540.7746866941452
[2023-05-17 14:24:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1382.7149830590781
avg_train_sample_per_sec: 1382.7149830590781
avg_episode_per_sec: 1.382714983059078
collect_time: 1.4464296868869235
reward_mean: 964.416894091319
reward_std: 38.3815926617425
reward_max: 1002.7984867530615
reward_min: 926.0353014295765
total_envstep_count: 1260421
total_train_sample_count: 1260207
total_episode_count: 1355
total_duration: 542.2211163810322
[2023-05-17 14:25:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1382.836877486305
avg_train_sample_per_sec: 1382.836877486305
avg_episode_per_sec: 1.382836877486305
collect_time: 4.3389065606253485
reward_mean: 931.2804973703263
reward_std: 59.911503682859546
reward_max: 988.3438765484019
reward_min: 824.0707548875134
total_envstep_count: 1264417
total_train_sample_count: 1264207
total_episode_count: 1361
total_duration: 546.5600229416575
[2023-05-17 14:25:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1891.1457149762114
avg_train_sample_per_sec: 1891.1457149762114
avg_episode_per_sec: 1.8911457149762114
collect_time: 1.0575599670410156
reward_mean: 792.3379478343184
reward_std: 2.914360791544766
reward_max: 795.2523086258632
reward_min: 789.4235870427736
total_envstep_count: 1268416
total_train_sample_count: 1268207
total_episode_count: 1363
total_duration: 547.6175829086985
[2023-05-17 14:25:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2194.760238346484
avg_train_sample_per_sec: 2194.760238346484
avg_episode_per_sec: 2.194760238346484
collect_time: 2.733783807073321
reward_mean: 831.7264369524347
reward_std: 96.34062177451557
reward_max: 981.1907489305626
reward_min: 701.4373001922826
total_envstep_count: 1272412
total_train_sample_count: 1272207
total_episode_count: 1369
total_duration: 550.3513667157719
[2023-05-17 14:25:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2215.312078276232
avg_train_sample_per_sec: 2215.312078276232
avg_episode_per_sec: 2.215312078276232
collect_time: 0.9028073378971645
reward_mean: 808.1963764029563
reward_std: 63.87901277173091
reward_max: 872.0753891746872
reward_min: 744.3173636312254
total_envstep_count: 1276411
total_train_sample_count: 1276207
total_episode_count: 1371
total_duration: 551.254174053669
[2023-05-17 14:25:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2262.9457869195394
avg_train_sample_per_sec: 2262.9457869195394
avg_episode_per_sec: 2.2629457869195395
collect_time: 2.651411286422185
reward_mean: 805.6191287622624
reward_std: 118.61604977794251
reward_max: 932.9994006963989
reward_min: 646.280973812173
total_envstep_count: 1280408
total_train_sample_count: 1280207
total_episode_count: 1377
total_duration: 553.9055853400912
[2023-05-17 14:25:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2273.098544252121
avg_train_sample_per_sec: 2273.098544252121
avg_episode_per_sec: 2.273098544252121
collect_time: 0.8798562671457018
reward_mean: 943.5494492794335
reward_std: 104.56473354805803
reward_max: 1048.1141828274915
reward_min: 838.9847157313754
total_envstep_count: 1284407
total_train_sample_count: 1284207
total_episode_count: 1379
total_duration: 554.7854416072369
[2023-05-17 14:25:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2365.6854987094093
avg_train_sample_per_sec: 2365.6854987094093
avg_episode_per_sec: 2.3656854987094094
collect_time: 2.536262746368136
reward_mean: 993.5753558392436
reward_std: 103.49332341176873
reward_max: 1120.00911290686
reward_min: 794.1134460405959
total_envstep_count: 1288404
total_train_sample_count: 1288207
total_episode_count: 1385
total_duration: 557.321704353605
[2023-05-17 14:25:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1664.8974066380135
avg_train_sample_per_sec: 1664.8974066380135
avg_episode_per_sec: 1.6648974066380136
collect_time: 1.2012752209390913
reward_mean: 951.1916884380068
reward_std: 6.023019892359399
reward_max: 957.2147083303662
reward_min: 945.1686685456474
total_envstep_count: 1292403
total_train_sample_count: 1292207
total_episode_count: 1387
total_duration: 558.5229795745441
[2023-05-17 14:25:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2409.214750828254
avg_train_sample_per_sec: 2409.214750828254
avg_episode_per_sec: 2.409214750828254
collect_time: 2.490438014268875
reward_mean: 845.8415768238377
reward_std: 114.97113090433358
reward_max: 1017.2682411185455
reward_min: 663.817567543428
total_envstep_count: 1296400
total_train_sample_count: 1296207
total_episode_count: 1393
total_duration: 561.013417588813
[2023-05-17 14:25:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2719
train_sample_count: 2719
avg_envstep_per_episode: 906.3333333333334
avg_sample_per_episode: 906.3333333333334
avg_envstep_per_sec: 2407.762148797639
avg_train_sample_per_sec: 2407.762148797639
avg_episode_per_sec: 2.6565967070220364
collect_time: 1.1292643674782343
reward_mean: 636.302185511228
reward_std: 100.59788669772762
reward_max: 710.5682970716792
reward_min: 494.0819720125579
total_envstep_count: 1300462
total_train_sample_count: 1300326
total_episode_count: 1396
total_duration: 562.1426819562912
[2023-05-17 14:25:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2479.711747575622
avg_train_sample_per_sec: 2479.711747575622
avg_episode_per_sec: 2.4797117475756223
collect_time: 2.419636074985777
reward_mean: 861.3729609853198
reward_std: 93.4316516866812
reward_max: 1008.4111384469235
reward_min: 716.3149651468035
total_envstep_count: 1304459
total_train_sample_count: 1304326
total_episode_count: 1402
total_duration: 564.562318031277
[2023-05-17 14:25:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2440.4947339630503
avg_train_sample_per_sec: 2440.4947339630503
avg_episode_per_sec: 2.4404947339630505
collect_time: 0.819505968264171
reward_mean: 923.8804044528471
reward_std: 49.77138239391388
reward_max: 973.651786846761
reward_min: 874.1090220589332
total_envstep_count: 1308457
total_train_sample_count: 1308326
total_episode_count: 1404
total_duration: 565.3818239995411
[2023-05-17 14:25:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2409.7976767294003
avg_train_sample_per_sec: 2409.7976767294003
avg_episode_per_sec: 2.4097976767294003
collect_time: 2.489835581609181
reward_mean: 823.3478537930099
reward_std: 74.05732885102239
reward_max: 960.3437152880189
reward_min: 746.456076120755
total_envstep_count: 1312454
total_train_sample_count: 1312326
total_episode_count: 1410
total_duration: 567.8716595811503
[2023-05-17 14:26:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2392.5023451141983
avg_train_sample_per_sec: 2392.5023451141983
avg_episode_per_sec: 2.392502345114198
collect_time: 0.8359448441437313
reward_mean: 591.5889119091884
reward_std: 13.134172066609722
reward_max: 604.7230839757981
reward_min: 578.4547398425786
total_envstep_count: 1316452
total_train_sample_count: 1316326
total_episode_count: 1412
total_duration: 568.707604425294
[2023-05-17 14:26:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2386.8699757453314
avg_train_sample_per_sec: 2386.8699757453314
avg_episode_per_sec: 2.3868699757453316
collect_time: 2.5137523455279216
reward_mean: 795.0258789595897
reward_std: 66.74130020238422
reward_max: 927.5800207376021
reward_min: 731.9415773410741
total_envstep_count: 1320449
total_train_sample_count: 1320326
total_episode_count: 1418
total_duration: 571.2213567708219
[2023-05-17 14:26:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2310.261437134805
avg_train_sample_per_sec: 2310.261437134805
avg_episode_per_sec: 2.310261437134805
collect_time: 0.8657028887953078
reward_mean: 799.3401174547158
reward_std: 18.686706603894095
reward_max: 818.0268240586099
reward_min: 780.6534108508217
total_envstep_count: 1324448
total_train_sample_count: 1324326
total_episode_count: 1420
total_duration: 572.0870596596172
[2023-05-17 14:26:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 6048
train_sample_count: 6048
avg_envstep_per_episode: 864.0
avg_sample_per_episode: 864.0
avg_envstep_per_sec: 1898.7817662476343
avg_train_sample_per_sec: 1898.7817662476343
avg_episode_per_sec: 2.1976640813051325
collect_time: 3.1852001675537656
reward_mean: 732.2748901411418
reward_std: 292.8830153325854
reward_max: 949.6935059518697
reward_min: 43.459252527344226
total_envstep_count: 1328556
total_train_sample_count: 1328374
total_episode_count: 1427
total_duration: 575.272259827171
[2023-05-17 14:26:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2302
train_sample_count: 2302
avg_envstep_per_episode: 767.3333333333334
avg_sample_per_episode: 767.3333333333334
avg_envstep_per_sec: 2061.418336867539
avg_train_sample_per_sec: 2061.418336867539
avg_episode_per_sec: 2.6864704650749855
collect_time: 1.1167068609169553
reward_mean: 633.9324573226089
reward_std: 229.70870748646544
reward_max: 864.6879870469438
reward_min: 320.5318413323835
total_envstep_count: 1332554
total_train_sample_count: 1332376
total_episode_count: 1430
total_duration: 576.3889666880879
[2023-05-17 14:26:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2136.9364020166718
avg_train_sample_per_sec: 2136.9364020166718
avg_episode_per_sec: 2.136936402016672
collect_time: 2.3397982248238156
reward_mean: 849.4648082253165
reward_std: 118.37310203709029
reward_max: 1023.9550976527157
reward_min: 659.4935264316638
total_envstep_count: 1336552
total_train_sample_count: 1336376
total_episode_count: 1435
total_duration: 578.7287649129116
[2023-05-17 14:26:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2253.4367446843253
avg_train_sample_per_sec: 2253.4367446843253
avg_episode_per_sec: 2.253436744684325
collect_time: 1.3312998499189104
reward_mean: 740.3021775299927
reward_std: 104.66270872710123
reward_max: 834.5610614817364
reward_min: 594.3401953951741
total_envstep_count: 1340552
total_train_sample_count: 1340376
total_episode_count: 1438
total_duration: 580.0600647628305
[2023-05-17 14:26:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2291.222725908586
avg_train_sample_per_sec: 2291.222725908586
avg_episode_per_sec: 2.291222725908586
collect_time: 2.182240924664906
reward_mean: 659.441742054896
reward_std: 100.44596672446492
reward_max: 799.6466115601658
reward_min: 505.81873942312257
total_envstep_count: 1344550
total_train_sample_count: 1344376
total_episode_count: 1443
total_duration: 582.2423056874954
[2023-05-17 14:26:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2303.4196512417393
avg_train_sample_per_sec: 2303.4196512417393
avg_episode_per_sec: 2.3034196512417395
collect_time: 1.3024113944598608
reward_mean: 697.2959305163832
reward_std: 120.17090220743631
reward_max: 853.8811067621999
reward_min: 561.7986175792279
total_envstep_count: 1348550
total_train_sample_count: 1348376
total_episode_count: 1446
total_duration: 583.5447170819554
[2023-05-17 14:26:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2269.1931739921747
avg_train_sample_per_sec: 2269.1931739921747
avg_episode_per_sec: 2.2691931739921745
collect_time: 2.203426335539137
reward_mean: 872.919392095909
reward_std: 121.82564027458497
reward_max: 1029.2471127514175
reward_min: 731.7615096003238
total_envstep_count: 1352548
total_train_sample_count: 1352376
total_episode_count: 1451
total_duration: 585.7481434174945
[2023-05-17 14:26:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2227.9271461134613
avg_train_sample_per_sec: 2227.9271461134613
avg_episode_per_sec: 2.227927146113461
collect_time: 1.3465431332588196
reward_mean: 795.8858213972485
reward_std: 134.53253870667731
reward_max: 962.1638165003931
reward_min: 632.6704402194508
total_envstep_count: 1356548
total_train_sample_count: 1356376
total_episode_count: 1454
total_duration: 587.0946865507533
[2023-05-17 14:27:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5286
train_sample_count: 5286
avg_envstep_per_episode: 881.0
avg_sample_per_episode: 881.0
avg_envstep_per_sec: 2188.395377491472
avg_train_sample_per_sec: 2188.395377491472
avg_episode_per_sec: 2.483990212816654
collect_time: 2.415468454360962
reward_mean: 719.873864941439
reward_std: 282.63854037879844
reward_max: 1030.554748024916
reward_min: 229.4998727532879
total_envstep_count: 1360617
total_train_sample_count: 1360412
total_episode_count: 1460
total_duration: 589.5101550051143
[2023-05-17 14:27:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1721.4094807327813
avg_train_sample_per_sec: 1721.4094807327813
avg_episode_per_sec: 1.7214094807327813
collect_time: 1.7427579164505005
reward_mean: 774.458773143912
reward_std: 129.2717574106397
reward_max: 931.3402646189005
reward_min: 614.7288576450636
total_envstep_count: 1364616
total_train_sample_count: 1364412
total_episode_count: 1463
total_duration: 591.2529129215648
[2023-05-17 14:27:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 5623
train_sample_count: 5623
avg_envstep_per_episode: 803.2857142857143
avg_sample_per_episode: 803.2857142857143
avg_envstep_per_sec: 2168.210273831715
avg_train_sample_per_sec: 2168.210273831715
avg_episode_per_sec: 2.6991769370126275
collect_time: 2.5933831546987807
reward_mean: 671.066514527397
reward_std: 250.68403630744413
reward_max: 1009.402208930119
reward_min: 253.51781553747384
total_envstep_count: 1368676
total_train_sample_count: 1368435
total_episode_count: 1470
total_duration: 593.8462960762636
[2023-05-17 14:27:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2180.639901384407
avg_train_sample_per_sec: 2180.639901384407
avg_episode_per_sec: 2.180639901384407
collect_time: 0.9171619755881173
reward_mean: 779.6831897817032
reward_std: 8.805992746387801
reward_max: 788.489182528091
reward_min: 770.8771970353154
total_envstep_count: 1372675
total_train_sample_count: 1372435
total_episode_count: 1472
total_duration: 594.7634580518517
[2023-05-17 14:27:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2360.7145167304116
avg_train_sample_per_sec: 2360.7145167304116
avg_episode_per_sec: 2.3607145167304115
collect_time: 2.5416033821446558
reward_mean: 951.0635538289939
reward_std: 128.0327068309466
reward_max: 1161.6046631823183
reward_min: 827.4642433563865
total_envstep_count: 1376673
total_train_sample_count: 1376435
total_episode_count: 1478
total_duration: 597.3050614339963
[2023-05-17 14:27:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2460.274063573527
avg_train_sample_per_sec: 2460.274063573527
avg_episode_per_sec: 2.460274063573527
collect_time: 0.8129175645964487
reward_mean: 821.2736819645987
reward_std: 3.9943325405276937
reward_max: 825.2680145051264
reward_min: 817.279349424071
total_envstep_count: 1380672
total_train_sample_count: 1380435
total_episode_count: 1480
total_duration: 598.1179789985928
[2023-05-17 14:27:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 6430
train_sample_count: 6430
avg_envstep_per_episode: 918.5714285714286
avg_sample_per_episode: 918.5714285714286
avg_envstep_per_sec: 2431.150365067264
avg_train_sample_per_sec: 2431.150365067264
avg_episode_per_sec: 2.646664472079448
collect_time: 2.6448384651115964
reward_mean: 829.2247375303383
reward_std: 305.9278355013943
reward_max: 1209.0042459125252
reward_min: 250.2633128986892
total_envstep_count: 1384669
total_train_sample_count: 1384465
total_episode_count: 1487
total_duration: 600.7628174637043
[2023-05-17 14:27:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2320.1739340520107
avg_train_sample_per_sec: 2320.1739340520107
avg_episode_per_sec: 2.3201739340520104
collect_time: 0.8620043396949768
reward_mean: 947.1636113128818
reward_std: 226.05921713597036
reward_max: 1173.2228284488522
reward_min: 721.1043941769115
total_envstep_count: 1388669
total_train_sample_count: 1388465
total_episode_count: 1489
total_duration: 601.6248218033993
[2023-05-17 14:27:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2255.2160128280216
avg_train_sample_per_sec: 2255.2160128280216
avg_episode_per_sec: 2.2552160128280216
collect_time: 2.6604990235396793
reward_mean: 889.5938982904732
reward_std: 157.01430899237428
reward_max: 1124.8793522551007
reward_min: 697.3413961333266
total_envstep_count: 1392666
total_train_sample_count: 1392465
total_episode_count: 1495
total_duration: 604.285320826939
[2023-05-17 14:27:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2256.258949157355
avg_train_sample_per_sec: 2256.258949157355
avg_episode_per_sec: 2.2562589491573553
collect_time: 0.8864230769021171
reward_mean: 756.271777490442
reward_std: 60.37884076984449
reward_max: 816.6506182602865
reward_min: 695.8929367205975
total_envstep_count: 1396665
total_train_sample_count: 1396465
total_episode_count: 1497
total_duration: 605.1717439038412
[2023-05-17 14:27:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 6303
train_sample_count: 6303
avg_envstep_per_episode: 900.4285714285714
avg_sample_per_episode: 900.4285714285714
avg_envstep_per_sec: 1911.5577313465321
avg_train_sample_per_sec: 1911.5577313465321
avg_episode_per_sec: 2.1229421100151873
collect_time: 3.2973108249051233
reward_mean: 793.4758338033873
reward_std: 204.49679593911648
reward_max: 986.3259646778866
reward_min: 308.07451261128534
total_envstep_count: 1400660
total_train_sample_count: 1400468
total_episode_count: 1504
total_duration: 608.4690547287463
[2023-05-17 14:28:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2206
train_sample_count: 2206
avg_envstep_per_episode: 735.3333333333334
avg_sample_per_episode: 735.3333333333334
avg_envstep_per_sec: 2086.0169456961257
avg_train_sample_per_sec: 2086.0169456961257
avg_episode_per_sec: 2.8368317484534797
collect_time: 1.0575177754674638
reward_mean: 607.1731034673131
reward_std: 299.8298350831544
reward_max: 866.8752139254414
reward_min: 187.04114053558425
total_envstep_count: 1404657
total_train_sample_count: 1404474
total_episode_count: 1507
total_duration: 609.5265725042137
[2023-05-17 14:28:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2058.955370334767
avg_train_sample_per_sec: 2058.955370334767
avg_episode_per_sec: 2.058955370334767
collect_time: 2.42841592005321
reward_mean: 752.5510742756093
reward_std: 102.52669368029487
reward_max: 896.8063445061358
reward_min: 616.6278917801371
total_envstep_count: 1408652
total_train_sample_count: 1408474
total_episode_count: 1512
total_duration: 611.954988424267
[2023-05-17 14:28:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2095.1181079774456
avg_train_sample_per_sec: 2095.1181079774456
avg_episode_per_sec: 2.0951181079774455
collect_time: 1.4319001819406239
reward_mean: 888.6777504097557
reward_std: 53.02820374318431
reward_max: 961.4871593311656
reward_min: 836.7141877734264
total_envstep_count: 1412650
total_train_sample_count: 1412474
total_episode_count: 1515
total_duration: 613.3868886062075
[2023-05-17 14:28:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2159.0728602102936
avg_train_sample_per_sec: 2159.0728602102936
avg_episode_per_sec: 2.1590728602102938
collect_time: 2.3158088326454163
reward_mean: 880.3667101010885
reward_std: 45.37560244972547
reward_max: 944.2145952521688
reward_min: 809.5267826754759
total_envstep_count: 1416645
total_train_sample_count: 1416474
total_episode_count: 1520
total_duration: 615.702697438853
[2023-05-17 14:28:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2253.3062217621446
avg_train_sample_per_sec: 2253.3062217621446
avg_episode_per_sec: 2.253306221762145
collect_time: 1.3313769655568257
reward_mean: 821.5874488163348
reward_std: 51.406253815464446
reward_max: 867.7265496988879
reward_min: 749.8630741093997
total_envstep_count: 1420643
total_train_sample_count: 1420474
total_episode_count: 1523
total_duration: 617.0340744044098
[2023-05-17 14:28:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4865
train_sample_count: 4865
avg_envstep_per_episode: 973.0
avg_sample_per_episode: 973.0
avg_envstep_per_sec: 2299.8419299895186
avg_train_sample_per_sec: 2299.8419299895186
avg_episode_per_sec: 2.3636607708011494
collect_time: 2.1153627719197954
reward_mean: 744.0398113101178
reward_std: 65.8805388074931
reward_max: 804.9259466505722
reward_min: 649.4549950788119
total_envstep_count: 1424637
total_train_sample_count: 1424489
total_episode_count: 1528
total_duration: 619.1494371763296
[2023-05-17 14:28:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 808.25
avg_sample_per_episode: 808.25
avg_envstep_per_sec: 2357.1635156749962
avg_train_sample_per_sec: 2357.1635156749962
avg_episode_per_sec: 2.9163792337457424
collect_time: 1.3715637368815288
reward_mean: 628.5878053953868
reward_std: 251.4729850938922
reward_max: 824.8268322230655
reward_min: 196.77663892615573
total_envstep_count: 1428682
total_train_sample_count: 1428522
total_episode_count: 1532
total_duration: 620.5210009132111
[2023-05-17 14:28:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1950.151544164492
avg_train_sample_per_sec: 1950.151544164492
avg_episode_per_sec: 1.9501515441644919
collect_time: 2.051122648375375
reward_mean: 822.0152815382326
reward_std: 42.51737191158555
reward_max: 867.956691951549
reward_min: 778.260781798837
total_envstep_count: 1432678
total_train_sample_count: 1432522
total_episode_count: 1536
total_duration: 622.5721235615864
[2023-05-17 14:28:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2376.2692550204274
avg_train_sample_per_sec: 2376.2692550204274
avg_episode_per_sec: 2.376269255020427
collect_time: 1.6833109259605408
reward_mean: 797.5809305093941
reward_std: 64.16251974633812
reward_max: 867.8946289903935
reward_min: 703.4736092999249
total_envstep_count: 1436676
total_train_sample_count: 1436522
total_episode_count: 1540
total_duration: 624.255434487547
[2023-05-17 14:28:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2481.755873297099
avg_train_sample_per_sec: 2481.755873297099
avg_episode_per_sec: 2.481755873297099
collect_time: 1.6117620766162875
reward_mean: 775.924277106572
reward_std: 58.98397912687923
reward_max: 854.5252182873776
reward_min: 688.7726238777623
total_envstep_count: 1440673
total_train_sample_count: 1440522
total_episode_count: 1544
total_duration: 625.8671965641632
[2023-05-17 14:28:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2478.184774494464
avg_train_sample_per_sec: 2478.184774494464
avg_episode_per_sec: 2.4781847744944643
collect_time: 1.6140846482345037
reward_mean: 779.5265447897957
reward_std: 22.703999926445835
reward_max: 815.9188986953811
reward_min: 753.3934294890422
total_envstep_count: 1444671
total_train_sample_count: 1444522
total_episode_count: 1548
total_duration: 627.4812812123978
[2023-05-17 14:28:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2490.7576002869346
avg_train_sample_per_sec: 2490.7576002869346
avg_episode_per_sec: 2.4907576002869347
collect_time: 1.6059370849813732
reward_mean: 784.6800388359128
reward_std: 10.999229957691844
reward_max: 803.1936700524784
reward_min: 775.1793597421664
total_envstep_count: 1448668
total_train_sample_count: 1448522
total_episode_count: 1552
total_duration: 629.0872182973792
[2023-05-17 14:28:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2450.915253022441
avg_train_sample_per_sec: 2450.915253022441
avg_episode_per_sec: 2.450915253022441
collect_time: 1.632043374436242
reward_mean: 812.7453912195114
reward_std: 28.488827247960863
reward_max: 857.5546897070914
reward_min: 779.6103274664309
total_envstep_count: 1452666
total_train_sample_count: 1452522
total_episode_count: 1556
total_duration: 630.7192616718154
[2023-05-17 14:29:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3924
train_sample_count: 3924
avg_envstep_per_episode: 981.0
avg_sample_per_episode: 981.0
avg_envstep_per_sec: 2502.030935401822
avg_train_sample_per_sec: 2502.030935401822
avg_episode_per_sec: 2.5504902501547626
collect_time: 1.5683259325368062
reward_mean: 798.629463386636
reward_std: 73.11640754738383
reward_max: 909.5944591179148
reward_min: 722.2049772920061
total_envstep_count: 1456662
total_train_sample_count: 1456546
total_episode_count: 1560
total_duration: 632.2875876043522
[2023-05-17 14:29:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2477.6887633889305
avg_train_sample_per_sec: 2477.6887633889305
avg_episode_per_sec: 2.4776887633889304
collect_time: 1.6144077735287803
reward_mean: 883.2674445391979
reward_std: 156.57631942112116
reward_max: 1058.7303462828631
reward_min: 632.4396811456892
total_envstep_count: 1460660
total_train_sample_count: 1460546
total_episode_count: 1564
total_duration: 633.901995377881
[2023-05-17 14:29:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2029.4826431236647
avg_train_sample_per_sec: 2029.4826431236647
avg_episode_per_sec: 2.0294826431236648
collect_time: 1.970945656299591
reward_mean: 1033.319965189337
reward_std: 80.24478638049285
reward_max: 1105.9316200759783
reward_min: 907.9464949451434
total_envstep_count: 1464657
total_train_sample_count: 1464546
total_episode_count: 1568
total_duration: 635.8729410341806
[2023-05-17 14:29:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2456.1590153999127
avg_train_sample_per_sec: 2456.1590153999127
avg_episode_per_sec: 2.456159015399913
collect_time: 1.6285590529441833
reward_mean: 1002.0550364303949
reward_std: 13.463185655849388
reward_max: 1016.7727174945516
reward_min: 980.1882031404573
total_envstep_count: 1468655
total_train_sample_count: 1468546
total_episode_count: 1572
total_duration: 637.5015000871248
[2023-05-17 14:29:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2438.4719071168215
avg_train_sample_per_sec: 2438.4719071168215
avg_episode_per_sec: 2.4384719071168215
collect_time: 1.640371573822839
reward_mean: 919.645344624558
reward_std: 131.61643633275227
reward_max: 1086.148898277979
reward_min: 759.6996115330618
total_envstep_count: 1472652
total_train_sample_count: 1472546
total_episode_count: 1576
total_duration: 639.1418716609476
[2023-05-17 14:29:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2409.324045457668
avg_train_sample_per_sec: 2409.324045457668
avg_episode_per_sec: 2.409324045457668
collect_time: 1.6602166933672768
reward_mean: 767.263230417351
reward_std: 78.51724350244612
reward_max: 871.1478876378966
reward_min: 678.0059541829817
total_envstep_count: 1476650
total_train_sample_count: 1476546
total_episode_count: 1580
total_duration: 640.8020883543148
[2023-05-17 14:29:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4446
train_sample_count: 4446
avg_envstep_per_episode: 889.2
avg_sample_per_episode: 889.2
avg_envstep_per_sec: 2441.3997089442396
avg_train_sample_per_sec: 2441.3997089442396
avg_episode_per_sec: 2.745613707764552
collect_time: 1.8210864790848325
reward_mean: 838.39250258895
reward_std: 188.90535162268824
reward_max: 1033.7049470062811
reward_min: 481.8510491270578
total_envstep_count: 1480751
total_train_sample_count: 1480592
total_episode_count: 1585
total_duration: 642.6231748333996
[2023-05-17 14:29:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2469.6172997283475
avg_train_sample_per_sec: 2469.6172997283475
avg_episode_per_sec: 2.4696172997283474
collect_time: 1.214763113430568
reward_mean: 1010.9935035923223
reward_std: 70.80929961963689
reward_max: 1083.5951816041072
reward_min: 914.9625831254098
total_envstep_count: 1484749
total_train_sample_count: 1484592
total_episode_count: 1588
total_duration: 643.8379379468302
[2023-05-17 14:29:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4967
train_sample_count: 4967
avg_envstep_per_episode: 993.4
avg_sample_per_episode: 993.4
avg_envstep_per_sec: 2409.100335524677
avg_train_sample_per_sec: 2409.100335524677
avg_episode_per_sec: 2.42510603535804
collect_time: 2.061765517507281
reward_mean: 942.0466981231605
reward_std: 57.03011282836592
reward_max: 992.4749245049868
reward_min: 848.0268879193571
total_envstep_count: 1488746
total_train_sample_count: 1488609
total_episode_count: 1593
total_duration: 645.8997034643374
[2023-05-17 14:29:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3482
train_sample_count: 3482
avg_envstep_per_episode: 870.5
avg_sample_per_episode: 870.5
avg_envstep_per_sec: 2416.23881202773
avg_train_sample_per_sec: 2416.23881202773
avg_episode_per_sec: 2.7756907662581622
collect_time: 1.4410827202456338
reward_mean: 689.5975275336136
reward_std: 160.6358935656736
reward_max: 836.4934051987543
reward_min: 432.1703974140989
total_envstep_count: 1492872
total_train_sample_count: 1492641
total_episode_count: 1597
total_duration: 647.3407861845831
[2023-05-17 14:29:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2381.395409198024
avg_train_sample_per_sec: 2381.395409198024
avg_episode_per_sec: 2.381395409198024
collect_time: 1.6796874574252536
reward_mean: 816.4756794996399
reward_std: 142.99314326309863
reward_max: 970.341928772151
reward_min: 596.8196325044144
total_envstep_count: 1496870
total_train_sample_count: 1496641
total_episode_count: 1601
total_duration: 649.0204736420084
[2023-05-17 14:29:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2449.7628926312836
avg_train_sample_per_sec: 2449.7628926312836
avg_episode_per_sec: 2.4497628926312833
collect_time: 1.6328110822609494
reward_mean: 908.808724460533
reward_std: 109.53199100295262
reward_max: 1037.1926293969757
reward_min: 754.2517658431062
total_envstep_count: 1500868
total_train_sample_count: 1500641
total_episode_count: 1605
total_duration: 650.6532847242693
[2023-05-17 14:30:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4734
train_sample_count: 4734
avg_envstep_per_episode: 946.8
avg_sample_per_episode: 946.8
avg_envstep_per_sec: 2052.479300727704
avg_train_sample_per_sec: 2052.479300727704
avg_episode_per_sec: 2.167806612513418
collect_time: 2.306478802646909
reward_mean: 912.0029704717748
reward_std: 190.18099712198517
reward_max: 1172.7554426720008
reward_min: 721.5953259115305
total_envstep_count: 1504865
total_train_sample_count: 1504675
total_episode_count: 1610
total_duration: 652.9597635269162
[2023-05-17 14:30:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3100
train_sample_count: 3100
avg_envstep_per_episode: 775.0
avg_sample_per_episode: 775.0
avg_envstep_per_sec: 2383.4672921975316
avg_train_sample_per_sec: 2383.4672921975316
avg_episode_per_sec: 3.075441667351654
collect_time: 1.300626197031566
reward_mean: 803.8440591983933
reward_std: 413.5790622656303
reward_max: 1105.3451442972735
reward_min: 91.74573782221901
total_envstep_count: 1508863
total_train_sample_count: 1508675
total_episode_count: 1614
total_duration: 654.2603897239477
[2023-05-17 14:30:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2249.167904867078
avg_train_sample_per_sec: 2249.167904867078
avg_episode_per_sec: 2.2491679048670776
collect_time: 2.2230443486145566
reward_mean: 732.5614527852434
reward_std: 138.0221723369909
reward_max: 926.7241548694583
reward_min: 508.3576565948952
total_envstep_count: 1512861
total_train_sample_count: 1512675
total_episode_count: 1619
total_duration: 656.4834340725622
[2023-05-17 14:30:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3431
train_sample_count: 3431
avg_envstep_per_episode: 857.75
avg_sample_per_episode: 857.75
avg_envstep_per_sec: 2275.181834637445
avg_train_sample_per_sec: 2275.181834637445
avg_episode_per_sec: 2.6524999529436837
collect_time: 1.508011336837496
reward_mean: 536.8080808534737
reward_std: 140.718006821105
reward_max: 643.8125626237852
reward_min: 300.33992182131476
total_envstep_count: 1516979
total_train_sample_count: 1516806
total_episode_count: 1623
total_duration: 657.9914454093997
[2023-05-17 14:30:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4712
train_sample_count: 4712
avg_envstep_per_episode: 942.4
avg_sample_per_episode: 942.4
avg_envstep_per_sec: 2335.2097445304103
avg_train_sample_per_sec: 2335.2097445304103
avg_episode_per_sec: 2.477939032820894
collect_time: 2.0178058998925343
reward_mean: 769.6945031946756
reward_std: 196.1501965972439
reward_max: 1069.4498058474826
reward_min: 584.4829548078762
total_envstep_count: 1521015
total_train_sample_count: 1520818
total_episode_count: 1628
total_duration: 660.0092513092923
[2023-05-17 14:30:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2408.9176495482334
avg_train_sample_per_sec: 2408.9176495482334
avg_episode_per_sec: 2.408917649548233
collect_time: 1.2453725848879134
reward_mean: 991.333085803525
reward_std: 142.3869795960202
reward_max: 1182.68686208803
reward_min: 841.3526327326151
total_envstep_count: 1525015
total_train_sample_count: 1524818
total_episode_count: 1631
total_duration: 661.2546238941802
[2023-05-17 14:30:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2376.151666768842
avg_train_sample_per_sec: 2376.151666768842
avg_episode_per_sec: 2.376151666768842
collect_time: 2.1042427846363614
reward_mean: 805.8619028491892
reward_std: 194.2712695132817
reward_max: 1047.5238961246337
reward_min: 565.0035956236425
total_envstep_count: 1529012
total_train_sample_count: 1528818
total_episode_count: 1636
total_duration: 663.3588666788165
[2023-05-17 14:30:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3675
train_sample_count: 3675
avg_envstep_per_episode: 918.75
avg_sample_per_episode: 918.75
avg_envstep_per_sec: 2436.52154137441
avg_train_sample_per_sec: 2436.52154137441
avg_episode_per_sec: 2.6519962355095617
collect_time: 1.5082977669579645
reward_mean: 823.4124300264702
reward_std: 224.4727333779923
reward_max: 1062.9117194468906
reward_min: 461.59506646167233
total_envstep_count: 1533011
total_train_sample_count: 1532843
total_episode_count: 1640
total_duration: 664.8671644457745
[2023-05-17 14:30:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2003.8660292148754
avg_train_sample_per_sec: 2003.8660292148754
avg_episode_per_sec: 2.0038660292148753
collect_time: 1.9961414294583455
reward_mean: 839.5918871679726
reward_std: 105.93623840093336
reward_max: 978.9370985588727
reward_min: 731.7789022726644
total_envstep_count: 1537009
total_train_sample_count: 1536843
total_episode_count: 1644
total_duration: 666.8633058752329
[2023-05-17 14:30:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2535.9124811919814
avg_train_sample_per_sec: 2535.9124811919814
avg_episode_per_sec: 2.535912481191981
collect_time: 1.577341501201902
reward_mean: 783.7847038347381
reward_std: 84.0558177152641
reward_max: 904.3043143972467
reward_min: 679.2906383453998
total_envstep_count: 1541009
total_train_sample_count: 1540843
total_episode_count: 1648
total_duration: 668.4406473764348
[2023-05-17 14:30:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2471.9859373576573
avg_train_sample_per_sec: 2471.9859373576573
avg_episode_per_sec: 2.4719859373576574
collect_time: 1.6181321825299944
reward_mean: 829.811675698976
reward_std: 98.75990080315799
reward_max: 986.2851768639522
reward_min: 712.4936345869329
total_envstep_count: 1545008
total_train_sample_count: 1544843
total_episode_count: 1652
total_duration: 670.0587795589647
[2023-05-17 14:30:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2516.1330770426725
avg_train_sample_per_sec: 2516.1330770426725
avg_episode_per_sec: 2.5161330770426726
collect_time: 1.5897410341671534
reward_mean: 832.638661733482
reward_std: 157.1509864743113
reward_max: 982.3983359807963
reward_min: 606.405218571553
total_envstep_count: 1549008
total_train_sample_count: 1548843
total_episode_count: 1656
total_duration: 671.6485205931318
[2023-05-17 14:31:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3932
train_sample_count: 3932
avg_envstep_per_episode: 983.0
avg_sample_per_episode: 983.0
avg_envstep_per_sec: 2434.279534097686
avg_train_sample_per_sec: 2434.279534097686
avg_episode_per_sec: 2.4763779594076154
collect_time: 1.6152623168059759
reward_mean: 978.9215599830528
reward_std: 100.72516833823981
reward_max: 1084.217829142712
reward_min: 857.9435955488688
total_envstep_count: 1553030
total_train_sample_count: 1552925
total_episode_count: 1660
total_duration: 673.2637829099378
[2023-05-17 14:31:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2471.7110936330496
avg_train_sample_per_sec: 2471.7110936330496
avg_episode_per_sec: 2.4717110936330497
collect_time: 1.6183121119226729
reward_mean: 772.5412015532385
reward_std: 66.92881359873579
reward_max: 832.9753790231398
reward_min: 661.3506794455517
total_envstep_count: 1557029
total_train_sample_count: 1556925
total_episode_count: 1664
total_duration: 674.8820950218606
[2023-05-17 14:31:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3851
train_sample_count: 3851
avg_envstep_per_episode: 962.75
avg_sample_per_episode: 962.75
avg_envstep_per_sec: 2419.959992101613
avg_train_sample_per_sec: 2419.959992101613
avg_episode_per_sec: 2.513591266789523
collect_time: 1.5913486225264415
reward_mean: 905.8122434388613
reward_std: 117.72374011440833
reward_max: 1044.2591584300474
reward_min: 726.3193147554264
total_envstep_count: 1561026
total_train_sample_count: 1560926
total_episode_count: 1668
total_duration: 676.473443644387
[2023-05-17 14:31:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2439.202688889387
avg_train_sample_per_sec: 2439.202688889387
avg_episode_per_sec: 2.4392026888893867
collect_time: 1.6398801207542422
reward_mean: 832.2249900671467
reward_std: 52.144823575836014
reward_max: 888.0488740823007
reward_min: 750.1835444797497
total_envstep_count: 1565025
total_train_sample_count: 1564926
total_episode_count: 1672
total_duration: 678.1133237651412
[2023-05-17 14:31:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1929.9304651870332
avg_train_sample_per_sec: 1929.9304651870332
avg_episode_per_sec: 1.929930465187033
collect_time: 2.0726135330540796
reward_mean: 818.1486791587677
reward_std: 159.7881157846815
reward_max: 1024.7341037415117
reward_min: 648.467862375631
total_envstep_count: 1569022
total_train_sample_count: 1568926
total_episode_count: 1676
total_duration: 680.1859372981953
[2023-05-17 14:31:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2380.1989892097567
avg_train_sample_per_sec: 2380.1989892097567
avg_episode_per_sec: 2.380198989209757
collect_time: 1.6805317614759718
reward_mean: 798.2592221293453
reward_std: 110.71786453808402
reward_max: 937.6609903379405
reward_min: 633.0832805964567
total_envstep_count: 1573021
total_train_sample_count: 1572926
total_episode_count: 1680
total_duration: 681.8664690596713
[2023-05-17 14:31:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2253.8610576426245
avg_train_sample_per_sec: 2253.8610576426245
avg_episode_per_sec: 2.253861057642624
collect_time: 1.7747322916984558
reward_mean: 818.3412045879369
reward_std: 104.60513281450467
reward_max: 886.7459515513134
reward_min: 637.9654474987962
total_envstep_count: 1577018
total_train_sample_count: 1576926
total_episode_count: 1684
total_duration: 683.6412013513698
[2023-05-17 14:31:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2302.733848254717
avg_train_sample_per_sec: 2302.733848254717
avg_episode_per_sec: 2.302733848254717
collect_time: 1.7370657069342474
reward_mean: 862.2635894589671
reward_std: 99.77625225896159
reward_max: 961.6657648113039
reward_min: 741.5866086828776
total_envstep_count: 1581018
total_train_sample_count: 1580926
total_episode_count: 1688
total_duration: 685.378267058304
[2023-05-17 14:31:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2317.4502597527485
avg_train_sample_per_sec: 2317.4502597527485
avg_episode_per_sec: 2.3174502597527487
collect_time: 1.7260348881993974
reward_mean: 823.3912104485265
reward_std: 110.3511446230429
reward_max: 975.6584136121982
reward_min: 664.6728029788346
total_envstep_count: 1585015
total_train_sample_count: 1584926
total_episode_count: 1692
total_duration: 687.1043019465034
[2023-05-17 14:31:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2413.441770151535
avg_train_sample_per_sec: 2413.441770151535
avg_episode_per_sec: 2.413441770151535
collect_time: 1.6573840933186668
reward_mean: 832.2126495966018
reward_std: 35.45896154742974
reward_max: 866.4247075272962
reward_min: 772.8788776881427
total_envstep_count: 1589015
total_train_sample_count: 1588926
total_episode_count: 1696
total_duration: 688.761686039822
[2023-05-17 14:31:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2358.2569219955603
avg_train_sample_per_sec: 2358.2569219955603
avg_episode_per_sec: 2.3582569219955607
collect_time: 1.696168031011309
reward_mean: 882.0258832030463
reward_std: 107.0491272977118
reward_max: 1049.5981083906515
reward_min: 751.53026128615
total_envstep_count: 1593012
total_train_sample_count: 1592926
total_episode_count: 1700
total_duration: 690.4578540708334
[2023-05-17 14:31:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2436.6265786562253
avg_train_sample_per_sec: 2436.6265786562253
avg_episode_per_sec: 2.436626578656225
collect_time: 1.641613875116621
reward_mean: 806.655533586913
reward_std: 47.61056518724889
reward_max: 878.6418103902555
reward_min: 750.613619799251
total_envstep_count: 1597012
total_train_sample_count: 1596926
total_episode_count: 1704
total_duration: 692.09946794595
[2023-05-17 14:31:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2164.654558769767
avg_train_sample_per_sec: 2164.654558769767
avg_episode_per_sec: 2.164654558769767
collect_time: 1.8478698985917228
reward_mean: 852.066887620648
reward_std: 21.321322500005476
reward_max: 887.6100457161327
reward_min: 830.9519959777364
total_envstep_count: 1601009
total_train_sample_count: 1600926
total_episode_count: 1708
total_duration: 693.9473378445417
[2023-05-17 14:32:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2236.8244940661316
avg_train_sample_per_sec: 2236.8244940661316
avg_episode_per_sec: 2.236824494066132
collect_time: 1.7882493734359741
reward_mean: 823.3339401976231
reward_std: 50.99524234392024
reward_max: 896.9741159091157
reward_min: 765.3302010366015
total_envstep_count: 1605009
total_train_sample_count: 1604926
total_episode_count: 1712
total_duration: 695.7355872179777
[2023-05-17 14:32:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2459.167779497706
avg_train_sample_per_sec: 2459.167779497706
avg_episode_per_sec: 2.459167779497706
collect_time: 1.6265665292739868
reward_mean: 860.0524314710234
reward_std: 55.14699315131411
reward_max: 945.4653893844536
reward_min: 802.5759298292743
total_envstep_count: 1609006
total_train_sample_count: 1608926
total_episode_count: 1716
total_duration: 697.3621537472517
[2023-05-17 14:32:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2485.5954732538517
avg_train_sample_per_sec: 2485.5954732538517
avg_episode_per_sec: 2.4855954732538517
collect_time: 1.6092723224844252
reward_mean: 939.4751297058824
reward_std: 103.09725506632665
reward_max: 1010.3314415115016
reward_min: 761.3903811752607
total_envstep_count: 1613006
total_train_sample_count: 1612926
total_episode_count: 1720
total_duration: 698.9714260697361
[2023-05-17 14:32:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3629
train_sample_count: 3629
avg_envstep_per_episode: 907.25
avg_sample_per_episode: 907.25
avg_envstep_per_sec: 2433.4461752358307
avg_train_sample_per_sec: 2433.4461752358307
avg_episode_per_sec: 2.6822222929025417
collect_time: 1.4913007063525066
reward_mean: 706.3205599864477
reward_std: 201.33820717662414
reward_max: 1038.3347049591791
reward_min: 539.6560310843699
total_envstep_count: 1617020
total_train_sample_count: 1616955
total_episode_count: 1724
total_duration: 700.4627267760886
[2023-05-17 14:32:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2493.7178792756713
avg_train_sample_per_sec: 2493.7178792756713
avg_episode_per_sec: 2.493717879275671
collect_time: 1.6040306857654025
reward_mean: 845.7321311620844
reward_std: 78.30940723309155
reward_max: 979.5726816055301
reward_min: 790.0895873545198
total_envstep_count: 1621020
total_train_sample_count: 1620955
total_episode_count: 1728
total_duration: 702.0667574618541
[2023-05-17 14:32:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 4485
train_sample_count: 4485
avg_envstep_per_episode: 747.5
avg_sample_per_episode: 747.5
avg_envstep_per_sec: 2455.880800249137
avg_train_sample_per_sec: 2455.880800249137
avg_episode_per_sec: 3.2854592645473404
collect_time: 1.8262286995138441
reward_mean: 682.9830813777253
reward_std: 335.69003515951783
reward_max: 980.2730682918886
reward_min: 70.21859935306293
total_envstep_count: 1625232
total_train_sample_count: 1625040
total_episode_count: 1734
total_duration: 703.892986161368
[2023-05-17 14:32:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4045
train_sample_count: 4045
avg_envstep_per_episode: 809.0
avg_sample_per_episode: 809.0
avg_envstep_per_sec: 2510.7948892035683
avg_train_sample_per_sec: 2510.7948892035683
avg_episode_per_sec: 3.1035783550105913
collect_time: 1.611043585198266
reward_mean: 709.8170449211941
reward_std: 260.0624396161539
reward_max: 926.1941155813669
reward_min: 234.0583624730082
total_envstep_count: 1629285
total_train_sample_count: 1629085
total_episode_count: 1739
total_duration: 705.5040297465662
[2023-05-17 14:32:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2494.053004603498
avg_train_sample_per_sec: 2494.053004603498
avg_episode_per_sec: 2.494053004603498
collect_time: 1.2028613643986836
reward_mean: 875.0654405364845
reward_std: 79.23434062872666
reward_max: 986.7062581520916
reward_min: 810.9163473252053
total_envstep_count: 1633283
total_train_sample_count: 1633085
total_episode_count: 1742
total_duration: 706.7068911109649
[2023-05-17 14:32:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2111.9808549482427
avg_train_sample_per_sec: 2111.9808549482427
avg_episode_per_sec: 2.111980854948243
collect_time: 2.367445703063692
reward_mean: 860.3060582868302
reward_std: 49.60356223803777
reward_max: 912.0382850161191
reward_min: 772.2634563107026
total_envstep_count: 1637281
total_train_sample_count: 1637085
total_episode_count: 1747
total_duration: 709.0743368140286
[2023-05-17 14:32:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2463.838679802779
avg_train_sample_per_sec: 2463.838679802779
avg_episode_per_sec: 2.463838679802779
collect_time: 1.2176121856485096
reward_mean: 903.6063578606783
reward_std: 59.55272593737951
reward_max: 982.5089845032613
reward_min: 838.6487241161111
total_envstep_count: 1641279
total_train_sample_count: 1641085
total_episode_count: 1750
total_duration: 710.2919489996771
[2023-05-17 14:32:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2481.6320566330983
avg_train_sample_per_sec: 2481.6320566330983
avg_episode_per_sec: 2.4816320566330985
collect_time: 2.014803115810667
reward_mean: 938.8408123767595
reward_std: 137.98981718295298
reward_max: 1137.890500664953
reward_min: 787.3812749671262
total_envstep_count: 1645277
total_train_sample_count: 1645085
total_episode_count: 1755
total_duration: 712.3067521154877
[2023-05-17 14:32:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4209
train_sample_count: 4209
avg_envstep_per_episode: 841.8
avg_sample_per_episode: 841.8
avg_envstep_per_sec: 2401.3839808288076
avg_train_sample_per_sec: 2401.3839808288076
avg_episode_per_sec: 2.8526775728543687
collect_time: 1.7527392676898412
reward_mean: 695.1372874971637
reward_std: 257.9822287031926
reward_max: 887.1560514486105
reward_min: 190.1081028037053
total_envstep_count: 1649346
total_train_sample_count: 1649094
total_episode_count: 1760
total_duration: 714.0594913831776
[2023-05-17 14:33:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2315.9641022790684
avg_train_sample_per_sec: 2315.9641022790684
avg_episode_per_sec: 2.3159641022790685
collect_time: 1.295356865440096
reward_mean: 836.4726360753972
reward_std: 95.13463988380079
reward_max: 951.3575198876431
reward_min: 718.3919458245557
total_envstep_count: 1653345
total_train_sample_count: 1653094
total_episode_count: 1763
total_duration: 715.3548482486177
[2023-05-17 14:33:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2198.156638072437
avg_train_sample_per_sec: 2198.156638072437
avg_episode_per_sec: 2.198156638072437
collect_time: 2.2746331691741943
reward_mean: 924.0562961579429
reward_std: 37.478398637788466
reward_max: 982.497497065068
reward_min: 874.5186483753722
total_envstep_count: 1657342
total_train_sample_count: 1657094
total_episode_count: 1768
total_duration: 717.6294814177919
[2023-05-17 14:33:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2264.3436114110236
avg_train_sample_per_sec: 2264.3436114110236
avg_episode_per_sec: 2.264343611411024
collect_time: 1.3248872586659022
reward_mean: 1090.8659112761225
reward_std: 21.71940134903772
reward_max: 1121.574295146786
reward_min: 1074.9243842747094
total_envstep_count: 1661341
total_train_sample_count: 1661094
total_episode_count: 1771
total_duration: 718.9543686764578
[2023-05-17 14:33:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1870.4875391614696
avg_train_sample_per_sec: 1870.4875391614696
avg_episode_per_sec: 1.8704875391614697
collect_time: 2.67309987119266
reward_mean: 887.7952775009313
reward_std: 122.69396704285961
reward_max: 1040.1896123121726
reward_min: 712.5386398712975
total_envstep_count: 1665338
total_train_sample_count: 1665094
total_episode_count: 1776
total_duration: 721.6274685476504
[2023-05-17 14:33:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2212.9601219660317
avg_train_sample_per_sec: 2212.9601219660317
avg_episode_per_sec: 2.2129601219660318
collect_time: 1.3556502759456635
reward_mean: 805.2711178888198
reward_std: 251.51566346394114
reward_max: 1133.6711080340265
reward_min: 522.7272243421892
total_envstep_count: 1669337
total_train_sample_count: 1669094
total_episode_count: 1779
total_duration: 722.9831188235961
[2023-05-17 14:33:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2137.706179624376
avg_train_sample_per_sec: 2137.706179624376
avg_episode_per_sec: 2.1377061796243764
collect_time: 2.338955674852644
reward_mean: 967.9274746185625
reward_std: 203.91930592798252
reward_max: 1169.0653112605014
reward_min: 712.1171995660371
total_envstep_count: 1673334
total_train_sample_count: 1673094
total_episode_count: 1784
total_duration: 725.3220744984487
[2023-05-17 14:33:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2218.602556250731
avg_train_sample_per_sec: 2218.602556250731
avg_episode_per_sec: 2.218602556250731
collect_time: 1.3522025346755981
reward_mean: 1048.5835542022744
reward_std: 60.248802141962315
reward_max: 1099.344474584702
reward_min: 963.9378093938531
total_envstep_count: 1677333
total_train_sample_count: 1677094
total_episode_count: 1787
total_duration: 726.6742770331243
[2023-05-17 14:33:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2301.0016251282136
avg_train_sample_per_sec: 2301.0016251282136
avg_episode_per_sec: 2.301001625128214
collect_time: 2.1729667399610793
reward_mean: 939.6534632248968
reward_std: 65.96436571234354
reward_max: 1051.0058488569641
reward_min: 875.2579734769896
total_envstep_count: 1681330
total_train_sample_count: 1681094
total_episode_count: 1792
total_duration: 728.8472437730854
[2023-05-17 14:33:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2374.860568463795
avg_train_sample_per_sec: 2374.860568463795
avg_episode_per_sec: 2.374860568463795
collect_time: 1.263232056583677
reward_mean: 854.1023739040438
reward_std: 122.70226399349707
reward_max: 1026.9170336735808
reward_min: 754.090323873342
total_envstep_count: 1685329
total_train_sample_count: 1685094
total_episode_count: 1795
total_duration: 730.1104758296691
[2023-05-17 14:33:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2320.910000654631
avg_train_sample_per_sec: 2320.910000654631
avg_episode_per_sec: 2.3209100006546306
collect_time: 2.1543273968355994
reward_mean: 854.5873731511192
reward_std: 161.30198424259788
reward_max: 1080.6487527363802
reward_min: 697.1973942460891
total_envstep_count: 1689327
total_train_sample_count: 1689094
total_episode_count: 1800
total_duration: 732.2648032265047
[2023-05-17 14:33:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 3300
train_sample_count: 3300
avg_envstep_per_episode: 660.0
avg_sample_per_episode: 660.0
avg_envstep_per_sec: 2320.413629744597
avg_train_sample_per_sec: 2320.413629744597
avg_episode_per_sec: 3.5157782268857534
collect_time: 1.4221602380275726
reward_mean: 555.2827868991419
reward_std: 341.19822987148535
reward_max: 886.2102082985789
reward_min: 85.69675064395202
total_envstep_count: 1693366
total_train_sample_count: 1693294
total_episode_count: 1805
total_duration: 733.6869634645323
[2023-05-17 14:33:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5076
train_sample_count: 5076
avg_envstep_per_episode: 846.0
avg_sample_per_episode: 846.0
avg_envstep_per_sec: 2196.201595125922
avg_train_sample_per_sec: 2196.201595125922
avg_episode_per_sec: 2.5959829729620822
collect_time: 2.311263233423233
reward_mean: 825.3348895024527
reward_std: 352.5671310082772
reward_max: 1128.604470426367
reward_min: 79.09002317264296
total_envstep_count: 1697362
total_train_sample_count: 1697320
total_episode_count: 1811
total_duration: 735.9982266979555
[2023-05-17 14:34:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2276.778927484445
avg_train_sample_per_sec: 2276.778927484445
avg_episode_per_sec: 2.276778927484445
collect_time: 1.3176509865692685
reward_mean: 909.52675685889
reward_std: 122.80056073313776
reward_max: 1082.380408076557
reward_min: 808.5679657910958
total_envstep_count: 1701361
total_train_sample_count: 1701320
total_episode_count: 1814
total_duration: 737.3158776845247
[2023-05-17 14:34:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2343.7021598921324
avg_train_sample_per_sec: 2343.7021598921324
avg_episode_per_sec: 2.3437021598921324
collect_time: 2.13337687935148
reward_mean: 828.7328510276636
reward_std: 95.52109019507522
reward_max: 979.0439056684627
reward_min: 715.3864033797445
total_envstep_count: 1705359
total_train_sample_count: 1705320
total_episode_count: 1819
total_duration: 739.4492545638761
[2023-05-17 14:34:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1818.6611114190061
avg_train_sample_per_sec: 1818.6611114190061
avg_episode_per_sec: 1.818661111419006
collect_time: 1.649565156017031
reward_mean: 757.1347037187653
reward_std: 147.27957883642716
reward_max: 867.9677850411492
reward_min: 548.9964141912366
total_envstep_count: 1709358
total_train_sample_count: 1709320
total_episode_count: 1822
total_duration: 741.0988197198932
[2023-05-17 14:34:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2314.220849160621
avg_train_sample_per_sec: 2314.220849160621
avg_episode_per_sec: 2.3142208491606215
collect_time: 2.160554383482252
reward_mean: 710.7070433609401
reward_std: 113.18535936332341
reward_max: 882.5147906818877
reward_min: 536.8363836625938
total_envstep_count: 1713355
total_train_sample_count: 1713320
total_episode_count: 1827
total_duration: 743.2593741033754
[2023-05-17 14:34:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2329.322968755196
avg_train_sample_per_sec: 2329.322968755196
avg_episode_per_sec: 2.329322968755196
collect_time: 1.2879278830119543
reward_mean: 649.8833666555189
reward_std: 130.56551698237485
reward_max: 769.6919432157918
reward_min: 468.30138907178355
total_envstep_count: 1717354
total_train_sample_count: 1717320
total_episode_count: 1830
total_duration: 744.5473019863874
[2023-05-17 14:34:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2281.0001829880916
avg_train_sample_per_sec: 2281.0001829880916
avg_episode_per_sec: 2.2810001829880915
collect_time: 2.192020867552076
reward_mean: 783.0117595766781
reward_std: 99.95687008532222
reward_max: 927.9574371986689
reward_min: 648.1715869380263
total_envstep_count: 1721351
total_train_sample_count: 1721320
total_episode_count: 1835
total_duration: 746.7393228539395
[2023-05-17 14:34:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2243.052833547918
avg_train_sample_per_sec: 2243.052833547918
avg_episode_per_sec: 2.243052833547918
collect_time: 1.3374629233564648
reward_mean: 746.6395254027337
reward_std: 167.28220445262932
reward_max: 981.5977151164442
reward_min: 605.2650187553502
total_envstep_count: 1725350
total_train_sample_count: 1725320
total_episode_count: 1838
total_duration: 748.076785777296
[2023-05-17 14:34:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2205.171461670369
avg_train_sample_per_sec: 2205.171461670369
avg_episode_per_sec: 2.205171461670369
collect_time: 2.2673973824296683
reward_mean: 840.655317629025
reward_std: 69.04729835196069
reward_max: 947.8299829327239
reward_min: 752.6390575870271
total_envstep_count: 1729347
total_train_sample_count: 1729320
total_episode_count: 1843
total_duration: 750.3441831597256
[2023-05-17 14:34:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2194.005572850742
avg_train_sample_per_sec: 2194.005572850742
avg_episode_per_sec: 2.1940055728507417
collect_time: 1.3673620692321231
reward_mean: 883.057793367383
reward_std: 179.58673547534488
reward_max: 1086.6798886021004
reward_min: 649.7909543705457
total_envstep_count: 1733346
total_train_sample_count: 1733320
total_episode_count: 1846
total_duration: 751.7115452289578
[2023-05-17 14:34:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1940.2642621134653
avg_train_sample_per_sec: 1940.2642621134653
avg_episode_per_sec: 1.9402642621134651
collect_time: 2.576968559197017
reward_mean: 855.0266877890879
reward_std: 63.45008884576253
reward_max: 895.6101361625924
reward_min: 728.8144782880322
total_envstep_count: 1737344
total_train_sample_count: 1737320
total_episode_count: 1851
total_duration: 754.2885137881548
[2023-05-17 14:34:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3635
train_sample_count: 3635
avg_envstep_per_episode: 908.75
avg_sample_per_episode: 908.75
avg_envstep_per_sec: 2331.537791124624
avg_train_sample_per_sec: 2331.537791124624
avg_episode_per_sec: 2.5656536903709757
collect_time: 1.559056865317481
reward_mean: 783.0165854736518
reward_std: 129.84861364182268
reward_max: 961.9870907034826
reward_min: 609.4894185217468
total_envstep_count: 1741630
total_train_sample_count: 1741355
total_episode_count: 1855
total_duration: 755.8475706534723
[2023-05-17 14:35:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2311.2759619929607
avg_train_sample_per_sec: 2311.2759619929607
avg_episode_per_sec: 2.3112759619929606
collect_time: 1.730645784309932
reward_mean: 837.8680127711579
reward_std: 35.49683847339129
reward_max: 890.4499814308679
reward_min: 792.3738201869056
total_envstep_count: 1745628
total_train_sample_count: 1745355
total_episode_count: 1859
total_duration: 757.5782164377822
[2023-05-17 14:35:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4168
train_sample_count: 4168
avg_envstep_per_episode: 833.6
avg_sample_per_episode: 833.6
avg_envstep_per_sec: 2304.828287839483
avg_train_sample_per_sec: 2304.828287839483
avg_episode_per_sec: 2.7649091744715486
collect_time: 1.8083776661327906
reward_mean: 659.8857293001081
reward_std: 248.94290357732473
reward_max: 870.3228661553953
reward_min: 180.78198713923868
total_envstep_count: 1749674
total_train_sample_count: 1749373
total_episode_count: 1864
total_duration: 759.386594103915
[2023-05-17 14:35:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2268.354496099385
avg_train_sample_per_sec: 2268.354496099385
avg_episode_per_sec: 2.268354496099385
collect_time: 1.7633928060531616
reward_mean: 925.7275729462373
reward_std: 36.04926206893255
reward_max: 960.8993919690779
reward_min: 877.7058457800731
total_envstep_count: 1753672
total_train_sample_count: 1753373
total_episode_count: 1868
total_duration: 761.1499869099681
[2023-05-17 14:35:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2239.0924912282494
avg_train_sample_per_sec: 2239.0924912282494
avg_episode_per_sec: 2.2390924912282495
collect_time: 1.7864380393709456
reward_mean: 856.8054106557073
reward_std: 102.20415580152726
reward_max: 966.1542789637825
reward_min: 699.9150295347249
total_envstep_count: 1757671
total_train_sample_count: 1757373
total_episode_count: 1872
total_duration: 762.9364249493391
[2023-05-17 14:35:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2311.4106051662698
avg_train_sample_per_sec: 2311.4106051662698
avg_episode_per_sec: 2.31141060516627
collect_time: 1.730544971568244
reward_mean: 793.7388074282665
reward_std: 33.62607898078733
reward_max: 847.4872779412935
reward_min: 759.0029407512482
total_envstep_count: 1761669
total_train_sample_count: 1761373
total_episode_count: 1876
total_duration: 764.6669699209074
[2023-05-17 14:35:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4437
train_sample_count: 4437
avg_envstep_per_episode: 887.4
avg_sample_per_episode: 887.4
avg_envstep_per_sec: 2369.2613063163367
avg_train_sample_per_sec: 2369.2613063163367
avg_episode_per_sec: 2.66989103709301
collect_time: 1.872735602515084
reward_mean: 842.696411996339
reward_std: 206.83259050704174
reward_max: 1009.0333784491723
reward_min: 435.97674415283177
total_envstep_count: 1765667
total_train_sample_count: 1765410
total_episode_count: 1881
total_duration: 766.5397055234224
[2023-05-17 14:35:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2333.274126451443
avg_train_sample_per_sec: 2333.274126451443
avg_episode_per_sec: 2.333274126451443
collect_time: 1.285746910742351
reward_mean: 801.7220497078132
reward_std: 0.20125899157416288
reward_max: 801.8851993941586
reward_min: 801.4384986100505
total_envstep_count: 1769665
total_train_sample_count: 1769410
total_episode_count: 1884
total_duration: 767.8254524341647
[2023-05-17 14:35:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1936.1890624718158
avg_train_sample_per_sec: 1936.1890624718158
avg_episode_per_sec: 1.9361890624718159
collect_time: 2.582392441374915
reward_mean: 912.6437316138251
reward_std: 131.49327006024924
reward_max: 1013.4295518229652
reward_min: 666.4022653583548
total_envstep_count: 1773663
total_train_sample_count: 1773410
total_episode_count: 1889
total_duration: 770.4078448755397
[2023-05-17 14:35:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2285.646127373673
avg_train_sample_per_sec: 2285.646127373673
avg_episode_per_sec: 2.285646127373673
collect_time: 1.3125391389642442
reward_mean: 862.0151433772857
reward_std: 81.22751822379944
reward_max: 968.3452740957288
reward_min: 771.203138550883
total_envstep_count: 1777661
total_train_sample_count: 1777410
total_episode_count: 1892
total_duration: 771.7203840145039
[2023-05-17 14:35:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2327.7633902097496
avg_train_sample_per_sec: 2327.7633902097496
avg_episode_per_sec: 2.32776339020975
collect_time: 2.14798463668142
reward_mean: 672.1408633945991
reward_std: 84.87441584700576
reward_max: 818.8038601120519
reward_min: 560.9179653947498
total_envstep_count: 1781659
total_train_sample_count: 1781410
total_episode_count: 1897
total_duration: 773.8683686511853
[2023-05-17 14:35:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2341.4051481800057
avg_train_sample_per_sec: 2341.4051481800057
avg_episode_per_sec: 2.3414051481800056
collect_time: 1.2812818842274802
reward_mean: 658.7009732880255
reward_std: 29.33016848840149
reward_max: 683.1755483591736
reward_min: 617.4613659029621
total_envstep_count: 1785657
total_train_sample_count: 1785410
total_episode_count: 1900
total_duration: 775.1496505354128
[2023-05-17 14:35:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2274.344013994096
avg_train_sample_per_sec: 2274.344013994096
avg_episode_per_sec: 2.274344013994096
collect_time: 2.198436106954302
reward_mean: 769.4833896341618
reward_std: 25.27488291052859
reward_max: 800.9120044063882
reward_min: 732.9494147891817
total_envstep_count: 1789655
total_train_sample_count: 1789410
total_episode_count: 1905
total_duration: 777.3480866423671
[2023-05-17 14:36:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2318.033592096061
avg_train_sample_per_sec: 2318.033592096061
avg_episode_per_sec: 2.3180335920960613
collect_time: 1.2942003990922655
reward_mean: 714.4021216525592
reward_std: 81.17621781593535
reward_max: 823.666612702674
reward_min: 629.2687162311994
total_envstep_count: 1793654
total_train_sample_count: 1793410
total_episode_count: 1908
total_duration: 778.6422870414593
[2023-05-17 14:36:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2386.23208606653
avg_train_sample_per_sec: 2386.23208606653
avg_episode_per_sec: 2.3862320860665296
collect_time: 2.095353603363037
reward_mean: 823.7154780200437
reward_std: 95.53149963886551
reward_max: 970.4908481957207
reward_min: 695.6799121843459
total_envstep_count: 1797653
total_train_sample_count: 1797410
total_episode_count: 1913
total_duration: 780.7376406448224
[2023-05-17 14:36:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2275.195853458136
avg_train_sample_per_sec: 2275.195853458136
avg_episode_per_sec: 2.275195853458136
collect_time: 1.3185678039278304
reward_mean: 897.3684520168858
reward_std: 64.94962968761753
reward_max: 988.5725055440935
reward_min: 842.3299502762233
total_envstep_count: 1801652
total_train_sample_count: 1801410
total_episode_count: 1916
total_duration: 782.0562084487502
[2023-05-17 14:36:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2207.957212983866
avg_train_sample_per_sec: 2207.957212983866
avg_episode_per_sec: 2.207957212983866
collect_time: 2.2645366362162997
reward_mean: 853.3653654849401
reward_std: 31.986624259391643
reward_max: 896.260918521474
reward_min: 797.9897888207688
total_envstep_count: 1805651
total_train_sample_count: 1805410
total_episode_count: 1921
total_duration: 784.3207450849666
[2023-05-17 14:36:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3726
train_sample_count: 3726
avg_envstep_per_episode: 931.5
avg_sample_per_episode: 931.5
avg_envstep_per_sec: 2401.219201309614
avg_train_sample_per_sec: 2401.219201309614
avg_episode_per_sec: 2.5777983910999613
collect_time: 1.5517117295946394
reward_mean: 863.1248191606546
reward_std: 135.17637980907116
reward_max: 1016.1404150942374
reward_min: 645.8233539650389
total_envstep_count: 1809714
total_train_sample_count: 1809636
total_episode_count: 1925
total_duration: 785.8724568145612
[2023-05-17 14:36:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2356.8364228697187
avg_train_sample_per_sec: 2356.8364228697187
avg_episode_per_sec: 2.3568364228697187
collect_time: 1.6971903358186995
reward_mean: 876.1424417506137
reward_std: 95.80733868988247
reward_max: 969.8009863506202
reward_min: 720.1239456981461
total_envstep_count: 1813712
total_train_sample_count: 1813636
total_episode_count: 1929
total_duration: 787.56964715038
[2023-05-17 14:36:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2394.4303517475537
avg_train_sample_per_sec: 2394.4303517475537
avg_episode_per_sec: 2.3944303517475536
collect_time: 1.6705434748104642
reward_mean: 951.2142306006072
reward_std: 100.70992082255316
reward_max: 1051.7055417628958
reward_min: 830.4448282363315
total_envstep_count: 1817711
total_train_sample_count: 1817636
total_episode_count: 1933
total_duration: 789.2401906251904
[2023-05-17 14:36:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2461.9617948233276
avg_train_sample_per_sec: 2461.9617948233276
avg_episode_per_sec: 2.4619617948233277
collect_time: 1.6247205819402422
reward_mean: 811.8657699387687
reward_std: 165.00490384241152
reward_max: 1060.8642359571104
reward_min: 620.8821272655745
total_envstep_count: 1821709
total_train_sample_count: 1821636
total_episode_count: 1937
total_duration: 790.8649112071306
[2023-05-17 14:36:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2538.3022786521087
avg_train_sample_per_sec: 2538.3022786521087
avg_episode_per_sec: 2.538302278652109
collect_time: 1.5758564429623738
reward_mean: 961.2364694513949
reward_std: 83.15334063763288
reward_max: 1083.1234313530622
reward_min: 851.8593474011277
total_envstep_count: 1825708
total_train_sample_count: 1825636
total_episode_count: 1941
total_duration: 792.440767650093
[2023-05-17 14:36:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2462.2028173177955
avg_train_sample_per_sec: 2462.2028173177955
avg_episode_per_sec: 2.4622028173177957
collect_time: 1.624561539718083
reward_mean: 768.2110068288998
reward_std: 97.39511825662558
reward_max: 883.8524243613361
reward_min: 662.3061956700659
total_envstep_count: 1829706
total_train_sample_count: 1829636
total_episode_count: 1945
total_duration: 794.0653291898111
[2023-05-17 14:36:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2344.556212732323
avg_train_sample_per_sec: 2344.556212732323
avg_episode_per_sec: 2.3445562127323227
collect_time: 1.7060798023428234
reward_mean: 720.7311965111779
reward_std: 97.06866742638596
reward_max: 874.2799437642583
reward_min: 627.3416305991503
total_envstep_count: 1833705
total_train_sample_count: 1833636
total_episode_count: 1949
total_duration: 795.771408992154
[2023-05-17 14:36:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2308.775932574541
avg_train_sample_per_sec: 2308.775932574541
avg_episode_per_sec: 2.3087759325745414
collect_time: 1.7325197926589422
reward_mean: 922.7641661886927
reward_std: 46.523148790860375
reward_max: 986.3455850455133
reward_min: 861.6459802426875
total_envstep_count: 1837703
total_train_sample_count: 1837636
total_episode_count: 1953
total_duration: 797.503928784813
[2023-05-17 14:36:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2000.0682368738999
avg_train_sample_per_sec: 2000.0682368738999
avg_episode_per_sec: 2.0000682368739
collect_time: 1.9999317654541562
reward_mean: 957.0169183355472
reward_std: 77.78602363656262
reward_max: 1003.2362082463055
reward_min: 822.3043017458765
total_envstep_count: 1841702
total_train_sample_count: 1841636
total_episode_count: 1957
total_duration: 799.5038605502671
[2023-05-17 14:37:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2508.847549084771
avg_train_sample_per_sec: 2508.847549084771
avg_episode_per_sec: 2.508847549084771
collect_time: 1.5943575373717715
reward_mean: 1026.274651790749
reward_std: 54.9141905015386
reward_max: 1080.495094875228
reward_min: 937.8804972941509
total_envstep_count: 1845701
total_train_sample_count: 1845636
total_episode_count: 1961
total_duration: 801.0982180876389
[2023-05-17 14:37:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2562.9329252481307
avg_train_sample_per_sec: 2562.9329252481307
avg_episode_per_sec: 2.562932925248131
collect_time: 1.560711933033807
reward_mean: 966.528356905781
reward_std: 51.408556953083746
reward_max: 1035.049949144121
reward_min: 893.3262160501802
total_envstep_count: 1849700
total_train_sample_count: 1849636
total_episode_count: 1965
total_duration: 802.6589300206726
[2023-05-17 14:37:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2504.3411914363537
avg_train_sample_per_sec: 2504.3411914363537
avg_episode_per_sec: 2.5043411914363536
collect_time: 1.5972264536789487
reward_mean: 853.7787251439402
reward_std: 52.264802092456
reward_max: 921.2019555817772
reward_min: 778.7433623340628
total_envstep_count: 1853698
total_train_sample_count: 1853636
total_episode_count: 1969
total_duration: 804.2561564743515
[2023-05-17 14:37:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2528.980528334547
avg_train_sample_per_sec: 2528.980528334547
avg_episode_per_sec: 2.528980528334547
collect_time: 1.581665005002703
reward_mean: 875.5798831058546
reward_std: 159.80220840396436
reward_max: 1072.1879759443018
reward_min: 704.4572150080845
total_envstep_count: 1857697
total_train_sample_count: 1857636
total_episode_count: 1973
total_duration: 805.8378214793543
[2023-05-17 14:37:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2465.5483061925984
avg_train_sample_per_sec: 2465.5483061925984
avg_episode_per_sec: 2.4655483061925985
collect_time: 1.6223571811403548
reward_mean: 932.1853395823537
reward_std: 65.78998189924981
reward_max: 1022.850133902601
reward_min: 841.9075932446307
total_envstep_count: 1861696
total_train_sample_count: 1861636
total_episode_count: 1977
total_duration: 807.4601786604946
[2023-05-17 14:37:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2510.456728678479
avg_train_sample_per_sec: 2510.456728678479
avg_episode_per_sec: 2.510456728678479
collect_time: 1.5933355689048767
reward_mean: 783.3306196569766
reward_std: 55.012622841570106
reward_max: 874.5677619170215
reward_min: 727.1227476561434
total_envstep_count: 1865695
total_train_sample_count: 1865636
total_episode_count: 1981
total_duration: 809.0535142293995
[2023-05-17 14:37:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2450.000650752508
avg_train_sample_per_sec: 2450.000650752508
avg_episode_per_sec: 2.450000650752508
collect_time: 1.6326526275702888
reward_mean: 763.4309326239013
reward_std: 46.35662198413867
reward_max: 824.5674252780616
reward_min: 699.1927019126281
total_envstep_count: 1869694
total_train_sample_count: 1869636
total_episode_count: 1985
total_duration: 810.6861668569699
[2023-05-17 14:37:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2028.4663543341844
avg_train_sample_per_sec: 2028.4663543341844
avg_episode_per_sec: 2.0284663543341845
collect_time: 1.971933126449585
reward_mean: 887.5253801829376
reward_std: 92.01134524796578
reward_max: 988.909350662273
reward_min: 764.126006213123
total_envstep_count: 1873693
total_train_sample_count: 1873636
total_episode_count: 1989
total_duration: 812.6580999834194
[2023-05-17 14:37:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2481.4283480057616
avg_train_sample_per_sec: 2481.4283480057616
avg_episode_per_sec: 2.4814283480057613
collect_time: 1.6119748141084398
reward_mean: 744.7003727624389
reward_std: 65.2778923864609
reward_max: 839.0207035794368
reward_min: 655.2947814719292
total_envstep_count: 1877693
total_train_sample_count: 1877636
total_episode_count: 1993
total_duration: 814.2700747975279
[2023-05-17 14:37:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2541.785244648198
avg_train_sample_per_sec: 2541.785244648198
avg_episode_per_sec: 2.5417852446481977
collect_time: 1.5736970731190274
reward_mean: 754.9689914262856
reward_std: 45.74452195525653
reward_max: 827.2426122132463
reward_min: 700.428425055197
total_envstep_count: 1881692
total_train_sample_count: 1881636
total_episode_count: 1997
total_duration: 815.8437718706468
[2023-05-17 14:37:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2498.0070589236757
avg_train_sample_per_sec: 2498.0070589236757
avg_episode_per_sec: 2.4980070589236756
collect_time: 1.601276499884469
reward_mean: 858.8169473712678
reward_std: 67.7513629089247
reward_max: 916.485227120745
reward_min: 744.5122722332144
total_envstep_count: 1885691
total_train_sample_count: 1885636
total_episode_count: 2001
total_duration: 817.4450483705313
[2023-05-17 14:37:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2567.2639402190366
avg_train_sample_per_sec: 2567.2639402190366
avg_episode_per_sec: 2.5672639402190365
collect_time: 1.5580789872578211
reward_mean: 915.0457001858077
reward_std: 34.275102901318334
reward_max: 954.4398123171359
reward_min: 872.4693750934957
total_envstep_count: 1889690
total_train_sample_count: 1889636
total_episode_count: 2005
total_duration: 819.003127357789
[2023-05-17 14:37:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2511.9923127039056
avg_train_sample_per_sec: 2511.9923127039056
avg_episode_per_sec: 2.5119923127039057
collect_time: 1.5923615608896529
reward_mean: 882.8007259106295
reward_std: 69.24743544302504
reward_max: 974.3372460778129
reward_min: 779.3972261758846
total_envstep_count: 1893690
total_train_sample_count: 1893636
total_episode_count: 2009
total_duration: 820.5954889186787
[2023-05-17 14:38:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2515.856474323639
avg_train_sample_per_sec: 2515.856474323639
avg_episode_per_sec: 2.5158564743236385
collect_time: 1.589915816273008
reward_mean: 899.2531053542175
reward_std: 54.28203960001859
reward_max: 951.968626663652
reward_min: 808.6758443329657
total_envstep_count: 1897689
total_train_sample_count: 1897636
total_episode_count: 2013
total_duration: 822.1854047349517
[2023-05-17 14:38:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2428.5824210731216
avg_train_sample_per_sec: 2428.5824210731216
avg_episode_per_sec: 2.4285824210731217
collect_time: 1.6470513684409005
reward_mean: 956.7538087802503
reward_std: 38.18381626814883
reward_max: 1019.1642413280764
reward_min: 916.2112295533312
total_envstep_count: 1901689
total_train_sample_count: 1901636
total_episode_count: 2017
total_duration: 823.8324561033926
[2023-05-17 14:38:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1995.6890186876944
avg_train_sample_per_sec: 1995.6890186876944
avg_episode_per_sec: 1.9956890186876943
collect_time: 2.0043202936649323
reward_mean: 958.7679193036936
reward_std: 64.54761387636485
reward_max: 1036.0841324280182
reward_min: 868.2004484814892
total_envstep_count: 1905688
total_train_sample_count: 1905636
total_episode_count: 2021
total_duration: 825.8367763970575
[2023-05-17 14:38:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2333.071120578819
avg_train_sample_per_sec: 2333.071120578819
avg_episode_per_sec: 2.333071120578819
collect_time: 1.714478382042476
reward_mean: 964.2205349469376
reward_std: 48.37869797214163
reward_max: 1032.3257344275007
reward_min: 917.9395504907527
total_envstep_count: 1909687
total_train_sample_count: 1909636
total_episode_count: 2025
total_duration: 827.5512547791
[2023-05-17 14:38:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2256.348919630206
avg_train_sample_per_sec: 2256.348919630206
avg_episode_per_sec: 2.2563489196302062
collect_time: 1.7727754626955308
reward_mean: 878.5134424345827
reward_std: 53.573997056020545
reward_max: 926.4262562086845
reward_min: 787.9670652603968
total_envstep_count: 1913686
total_train_sample_count: 1913636
total_episode_count: 2029
total_duration: 829.3240302417955
[2023-05-17 14:38:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2231.0251099176153
avg_train_sample_per_sec: 2231.0251099176153
avg_episode_per_sec: 2.2310251099176153
collect_time: 1.7928977949278695
reward_mean: 785.1969991105889
reward_std: 64.26993791156639
reward_max: 864.4706242763791
reward_min: 694.2745579632718
total_envstep_count: 1917685
total_train_sample_count: 1917636
total_episode_count: 2033
total_duration: 831.1169280367234
[2023-05-17 14:38:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2353.576662268835
avg_train_sample_per_sec: 2353.576662268835
avg_episode_per_sec: 2.353576662268835
collect_time: 1.6995409854820795
reward_mean: 892.3370061262139
reward_std: 25.22799638261096
reward_max: 930.071182288556
reward_min: 861.1423808831426
total_envstep_count: 1921684
total_train_sample_count: 1921636
total_episode_count: 2037
total_duration: 832.8164690222054
[2023-05-17 14:38:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2361.9085819465577
avg_train_sample_per_sec: 2361.9085819465577
avg_episode_per_sec: 2.3619085819465577
collect_time: 1.6935456480298723
reward_mean: 878.9623025737229
reward_std: 166.89855729297776
reward_max: 1065.7719802741417
reward_min: 673.4405167902889
total_envstep_count: 1925683
total_train_sample_count: 1925636
total_episode_count: 2041
total_duration: 834.5100146702353
[2023-05-17 14:38:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2347.232242707872
avg_train_sample_per_sec: 2347.232242707872
avg_episode_per_sec: 2.347232242707872
collect_time: 1.7041347367422923
reward_mean: 1027.8195729864003
reward_std: 29.892556398235133
reward_max: 1055.6397952393459
reward_min: 982.027083367623
total_envstep_count: 1929682
total_train_sample_count: 1929636
total_episode_count: 2045
total_duration: 836.2141494069775
[2023-05-17 14:38:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2238.8526044807527
avg_train_sample_per_sec: 2238.8526044807527
avg_episode_per_sec: 2.2388526044807526
collect_time: 1.7866294511726923
reward_mean: 1018.0377224223818
reward_std: 68.1348829006854
reward_max: 1070.2510346142271
reward_min: 900.9923918407153
total_envstep_count: 1933681
total_train_sample_count: 1933636
total_episode_count: 2049
total_duration: 838.0007788581502
[2023-05-17 14:38:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1895.3914473650104
avg_train_sample_per_sec: 1895.3914473650104
avg_episode_per_sec: 1.8953914473650104
collect_time: 2.1103820034435814
reward_mean: 805.4500996799267
reward_std: 149.0152191582846
reward_max: 971.7683485970056
reward_min: 575.7869751028943
total_envstep_count: 1937680
total_train_sample_count: 1937636
total_episode_count: 2053
total_duration: 840.1111608615937
[2023-05-17 14:38:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2346.4678374181103
avg_train_sample_per_sec: 2346.4678374181103
avg_episode_per_sec: 2.34646783741811
collect_time: 1.7046898901462555
reward_mean: 880.8194592832278
reward_std: 125.16009199263544
reward_max: 1040.4182752353533
reward_min: 733.5152139025749
total_envstep_count: 1941679
total_train_sample_count: 1941636
total_episode_count: 2057
total_duration: 841.81585075174
[2023-05-17 14:39:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2482.419191929467
avg_train_sample_per_sec: 2482.419191929467
avg_episode_per_sec: 2.482419191929467
collect_time: 1.6113314032554626
reward_mean: 928.4527436504087
reward_std: 115.84329540630571
reward_max: 1065.5621603776074
reward_min: 748.3883670840029
total_envstep_count: 1945678
total_train_sample_count: 1945636
total_episode_count: 2061
total_duration: 843.4271821549954
[2023-05-17 14:39:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4536
train_sample_count: 4536
avg_envstep_per_episode: 907.2
avg_sample_per_episode: 907.2
avg_envstep_per_sec: 2404.111959564971
avg_train_sample_per_sec: 2404.111959564971
avg_episode_per_sec: 2.6500352287973667
collect_time: 1.8867673703602383
reward_mean: 798.5870981888818
reward_std: 108.38418285507093
reward_max: 912.2343193664631
reward_min: 611.2022011657326
total_envstep_count: 1949854
total_train_sample_count: 1949672
total_episode_count: 2066
total_duration: 845.3139495253556
[2023-05-17 14:39:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2350.4973721688043
avg_train_sample_per_sec: 2350.4973721688043
avg_episode_per_sec: 2.350497372168804
collect_time: 1.2763256132602692
reward_mean: 997.8524292647226
reward_std: 126.86751396369787
reward_max: 1102.0396349461369
reward_min: 819.2605308694206
total_envstep_count: 1953854
total_train_sample_count: 1953672
total_episode_count: 2069
total_duration: 846.5902751386159
[2023-05-17 14:39:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2338.518373866247
avg_train_sample_per_sec: 2338.518373866247
avg_episode_per_sec: 2.3385183738662474
collect_time: 2.1381059288978577
reward_mean: 875.7735856223495
reward_std: 112.52541023861235
reward_max: 1048.1111818504257
reward_min: 726.4802319160653
total_envstep_count: 1957854
total_train_sample_count: 1957672
total_episode_count: 2074
total_duration: 848.7283810675137
[2023-05-17 14:39:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 3667
train_sample_count: 3667
avg_envstep_per_episode: 733.4
avg_sample_per_episode: 733.4
avg_envstep_per_sec: 2463.910984971791
avg_train_sample_per_sec: 2463.910984971791
avg_episode_per_sec: 3.3595732001251584
collect_time: 1.488284285579409
reward_mean: 629.2872717612661
reward_std: 308.4316281873104
reward_max: 888.5401520331064
reward_min: 52.45086735377639
total_envstep_count: 1961964
total_train_sample_count: 1961739
total_episode_count: 2079
total_duration: 850.2166653530932
[2023-05-17 14:39:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 4000
train_sample_count: 4000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2468.832994232468
avg_train_sample_per_sec: 2468.832994232468
avg_episode_per_sec: 2.468832994232468
collect_time: 1.6201986968517303
reward_mean: 788.5321607482172
reward_std: 46.95388295035644
reward_max: 833.6141279969189
reward_min: 716.6751884359818
total_envstep_count: 1965964
total_train_sample_count: 1965739
total_episode_count: 2083
total_duration: 851.8368640499449
[2023-05-17 14:39:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4500
train_sample_count: 4500
avg_envstep_per_episode: 900.0
avg_sample_per_episode: 900.0
avg_envstep_per_sec: 2042.6919204048122
avg_train_sample_per_sec: 2042.6919204048122
avg_episode_per_sec: 2.2696576893386804
collect_time: 2.2029753753117154
reward_mean: 758.4412750679933
reward_std: 202.77359192913661
reward_max: 1011.4804315207831
reward_min: 388.88149769484784
total_envstep_count: 1969963
total_train_sample_count: 1969739
total_episode_count: 2088
total_duration: 854.0398394252566
[2023-05-17 14:39:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2447.9710690435236
avg_train_sample_per_sec: 2447.9710690435236
avg_episode_per_sec: 2.4479710690435237
collect_time: 1.2255046793392728
reward_mean: 813.959807232326
reward_std: 33.81139815935794
reward_max: 853.6039252310986
reward_min: 770.9844785003405
total_envstep_count: 1973963
total_train_sample_count: 1973739
total_episode_count: 2091
total_duration: 855.2653441045958
[2023-05-17 14:39:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2485.1414571202404
avg_train_sample_per_sec: 2485.1414571202404
avg_episode_per_sec: 2.4851414571202404
collect_time: 2.011957905122212
reward_mean: 817.5998391926576
reward_std: 144.64350096882737
reward_max: 978.8122406956903
reward_min: 570.8061022666589
total_envstep_count: 1977962
total_train_sample_count: 1977739
total_episode_count: 2096
total_duration: 857.277302009718
[2023-05-17 14:39:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2477.1520752795586
avg_train_sample_per_sec: 2477.1520752795586
avg_episode_per_sec: 2.4771520752795584
collect_time: 1.2110681576388223
reward_mean: 773.7041099325148
reward_std: 141.4183783043357
reward_max: 900.8345232287384
reward_min: 576.4335178480234
total_envstep_count: 1981962
total_train_sample_count: 1981739
total_episode_count: 2099
total_duration: 858.4883701673568
[2023-05-17 14:39:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2509.6245734255162
avg_train_sample_per_sec: 2509.6245734255162
avg_episode_per_sec: 2.5096245734255165
collect_time: 1.9923298699515208
reward_mean: 975.9874351468761
reward_std: 90.78546126421752
reward_max: 1108.7237012727692
reward_min: 862.3675692420833
total_envstep_count: 1985961
total_train_sample_count: 1985739
total_episode_count: 2104
total_duration: 860.4807000373083
[2023-05-17 14:39:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2472.589678233705
avg_train_sample_per_sec: 2472.589678233705
avg_episode_per_sec: 2.472589678233705
collect_time: 1.2133028081485202
reward_mean: 837.5454604128018
reward_std: 112.22602010207896
reward_max: 974.6982981733604
reward_min: 699.803705542608
total_envstep_count: 1989961
total_train_sample_count: 1989739
total_episode_count: 2107
total_duration: 861.6940028454569
[2023-05-17 14:40:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2407.1295439222067
avg_train_sample_per_sec: 2407.1295439222067
avg_episode_per_sec: 2.4071295439222067
collect_time: 2.077162823506764
reward_mean: 888.3068443442623
reward_std: 43.21072208514473
reward_max: 952.8483255681869
reward_min: 823.0693795993045
total_envstep_count: 1993960
total_train_sample_count: 1993739
total_episode_count: 2112
total_duration: 863.7711656689637
[2023-05-17 14:40:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2391.422405967746
avg_train_sample_per_sec: 2391.422405967746
avg_episode_per_sec: 2.3914224059677456
collect_time: 1.2544835209846497
reward_mean: 898.4995794103091
reward_std: 86.54908670178907
reward_max: 993.9211356551365
reward_min: 784.4023450921311
total_envstep_count: 1997960
total_train_sample_count: 1997739
total_episode_count: 2115
total_duration: 865.0256491899484
[2023-05-17 14:40:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2402.8509341942527
avg_train_sample_per_sec: 2402.8509341942527
avg_episode_per_sec: 2.402850934194253
collect_time: 2.0808615003313338
reward_mean: 970.8407060844213
reward_std: 34.545776914221705
reward_max: 1021.5143210948128
reward_min: 916.0023143120599
total_envstep_count: 2001959
total_train_sample_count: 2001739
total_episode_count: 2120
total_duration: 867.1065106902797
[2023-05-17 14:40:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2377.255183888426
avg_train_sample_per_sec: 2377.255183888426
avg_episode_per_sec: 2.3772551838884257
collect_time: 1.2619595995971133
reward_mean: 961.9437727889572
reward_std: 37.39449965731465
reward_max: 996.5807071200802
reward_min: 910.0169974873793
total_envstep_count: 2005959
total_train_sample_count: 2005739
total_episode_count: 2123
total_duration: 868.3684702898769
[2023-05-17 14:40:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2428.5129067702096
avg_train_sample_per_sec: 2428.5129067702096
avg_episode_per_sec: 2.4285129067702096
collect_time: 2.05887314251491
reward_mean: 885.7958403763689
reward_std: 61.415669998540956
reward_max: 963.0532681106598
reward_min: 814.4133271286862
total_envstep_count: 2009958
total_train_sample_count: 2009739
total_episode_count: 2128
total_duration: 870.4273434323918
[2023-05-17 14:40:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1848.0533266177338
avg_train_sample_per_sec: 1848.0533266177338
avg_episode_per_sec: 1.8480533266177337
collect_time: 1.6233297799314772
reward_mean: 833.4205546133725
reward_std: 72.29137282499327
reward_max: 935.122861081214
reward_min: 773.5392008432403
total_envstep_count: 2013958
total_train_sample_count: 2013739
total_episode_count: 2131
total_duration: 872.0506732123233
[2023-05-17 14:40:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2470.7506859979712
avg_train_sample_per_sec: 2470.7506859979712
avg_episode_per_sec: 2.470750685997971
collect_time: 2.023676459278379
reward_mean: 956.0077004062339
reward_std: 21.627857431090973
reward_max: 995.7174816616669
reward_min: 930.0239089223317
total_envstep_count: 2017957
total_train_sample_count: 2017739
total_episode_count: 2136
total_duration: 874.0743496716017
[2023-05-17 14:40:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2460.0964333068946
avg_train_sample_per_sec: 2460.0964333068946
avg_episode_per_sec: 2.4600964333068944
collect_time: 1.2194643914699554
reward_mean: 977.9935694877353
reward_std: 29.350500779785786
reward_max: 1003.3376458783906
reward_min: 936.8533703408326
total_envstep_count: 2021957
total_train_sample_count: 2021739
total_episode_count: 2139
total_duration: 875.2938140630716
[2023-05-17 14:40:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2467.569566269305
avg_train_sample_per_sec: 2467.569566269305
avg_episode_per_sec: 2.467569566269305
collect_time: 2.0262853247778754
reward_mean: 1013.5972356316003
reward_std: 34.608943849162664
reward_max: 1066.5933041358007
reward_min: 960.316405346468
total_envstep_count: 2025956
total_train_sample_count: 2025739
total_episode_count: 2144
total_duration: 877.3200993878495
[2023-05-17 14:40:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2400.9323852699267
avg_train_sample_per_sec: 2400.9323852699267
avg_episode_per_sec: 2.4009323852699267
collect_time: 1.249514571258
reward_mean: 976.824016937795
reward_std: 67.4865450924824
reward_max: 1038.0968898509045
reward_min: 882.8166333799862
total_envstep_count: 2029956
total_train_sample_count: 2029739
total_episode_count: 2147
total_duration: 878.5696139591075
[2023-05-17 14:40:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2311.725716372557
avg_train_sample_per_sec: 2311.725716372557
avg_episode_per_sec: 2.3117257163725573
collect_time: 2.1628863513469696
reward_mean: 1011.9266465716182
reward_std: 29.458964271057294
reward_max: 1064.1544574434913
reward_min: 981.2627666125281
total_envstep_count: 2033955
total_train_sample_count: 2033739
total_episode_count: 2152
total_duration: 880.7325003104545
[2023-05-17 14:40:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2302.7932462254867
avg_train_sample_per_sec: 2302.7932462254867
avg_episode_per_sec: 2.3027932462254865
collect_time: 1.3027656759534563
reward_mean: 1011.1146070493752
reward_std: 11.00264476737601
reward_max: 1020.3827717863625
reward_min: 995.6563328116633
total_envstep_count: 2037955
total_train_sample_count: 2037739
total_episode_count: 2155
total_duration: 882.0352659864079
[2023-05-17 14:40:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2000.5769281657451
avg_train_sample_per_sec: 2000.5769281657451
avg_episode_per_sec: 2.0005769281657453
collect_time: 2.499279047761645
reward_mean: 987.6562623006934
reward_std: 45.76979970813857
reward_max: 1068.3120224669894
reward_min: 929.7146848256765
total_envstep_count: 2041955
total_train_sample_count: 2041739
total_episode_count: 2160
total_duration: 884.5345450341696
[2023-05-17 14:41:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2399.011637661486
avg_train_sample_per_sec: 2399.011637661486
avg_episode_per_sec: 2.399011637661486
collect_time: 1.2505149841308594
reward_mean: 982.1053248029874
reward_std: 40.4099872767585
reward_max: 1038.7014997166423
reward_min: 946.9439038689848
total_envstep_count: 2045955
total_train_sample_count: 2045739
total_episode_count: 2163
total_duration: 885.7850600183004
[2023-05-17 14:41:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2356.2414863491713
avg_train_sample_per_sec: 2356.2414863491713
avg_episode_per_sec: 2.3562414863491714
collect_time: 2.122023582458496
reward_mean: 971.8540956049649
reward_std: 73.75341468432768
reward_max: 1066.7992815369394
reward_min: 868.8285150381267
total_envstep_count: 2049955
total_train_sample_count: 2049739
total_episode_count: 2168
total_duration: 887.9070836007589
[2023-05-17 14:41:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2341.3229623208435
avg_train_sample_per_sec: 2341.3229623208435
avg_episode_per_sec: 2.3413229623208434
collect_time: 1.2813268601894379
reward_mean: 1019.6582151094796
reward_std: 56.444546500228206
reward_max: 1073.189038117302
reward_min: 941.6110477317342
total_envstep_count: 2053955
total_train_sample_count: 2053739
total_episode_count: 2171
total_duration: 889.1884104609484
[2023-05-17 14:41:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2342.381709257083
avg_train_sample_per_sec: 2342.381709257083
avg_episode_per_sec: 2.342381709257083
collect_time: 2.134579509496689
reward_mean: 902.0088233900202
reward_std: 69.25564256300103
reward_max: 991.1639351072492
reward_min: 795.8369752966904
total_envstep_count: 2057955
total_train_sample_count: 2057739
total_episode_count: 2176
total_duration: 891.3229899704451
[2023-05-17 14:41:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2381.720061846981
avg_train_sample_per_sec: 2381.720061846981
avg_episode_per_sec: 2.3817200618469814
collect_time: 1.2595938742160797
reward_mean: 859.2453096080657
reward_std: 43.904197005786635
reward_max: 920.6671248067815
reward_min: 820.6674943979956
total_envstep_count: 2061955
total_train_sample_count: 2061739
total_episode_count: 2179
total_duration: 892.5825838446611
[2023-05-17 14:41:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2392.4635900164494
avg_train_sample_per_sec: 2392.4635900164494
avg_episode_per_sec: 2.3924635900164493
collect_time: 2.0898959636688232
reward_mean: 913.3964997187602
reward_std: 77.68383155208372
reward_max: 985.5292964504097
reward_min: 764.967355930633
total_envstep_count: 2065955
total_train_sample_count: 2065739
total_episode_count: 2184
total_duration: 894.67247980833
[2023-05-17 14:41:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2388.3823925085167
avg_train_sample_per_sec: 2388.3823925085167
avg_episode_per_sec: 2.388382392508517
collect_time: 1.2560802698135376
reward_mean: 871.4082104812304
reward_std: 58.5838394374673
reward_max: 953.2057441537005
reward_min: 819.1089182764755
total_envstep_count: 2069955
total_train_sample_count: 2069739
total_episode_count: 2187
total_duration: 895.9285600781435
[2023-05-17 14:41:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2343.837596344672
avg_train_sample_per_sec: 2343.837596344672
avg_episode_per_sec: 2.343837596344672
collect_time: 2.1332536041736603
reward_mean: 822.3654813183391
reward_std: 92.02942958383012
reward_max: 902.8447126505043
reward_min: 652.3636638871735
total_envstep_count: 2073955
total_train_sample_count: 2073739
total_episode_count: 2192
total_duration: 898.0618136823172
[2023-05-17 14:41:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1818.436357434642
avg_train_sample_per_sec: 1818.436357434642
avg_episode_per_sec: 1.818436357434642
collect_time: 1.6497690379619598
reward_mean: 970.5021361685012
reward_std: 33.54936423384082
reward_max: 1016.4190677803005
reward_min: 937.1963854887618
total_envstep_count: 2077955
total_train_sample_count: 2077739
total_episode_count: 2195
total_duration: 899.7115827202791
[2023-05-17 14:41:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2443.6812426727465
avg_train_sample_per_sec: 2443.6812426727465
avg_episode_per_sec: 2.4436812426727466
collect_time: 2.046093374490738
reward_mean: 977.6197487756612
reward_std: 77.31765215167002
reward_max: 1063.3809741931645
reward_min: 868.2085611366024
total_envstep_count: 2081955
total_train_sample_count: 2081739
total_episode_count: 2200
total_duration: 901.7576760947699
[2023-05-17 14:41:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2475.390905181419
avg_train_sample_per_sec: 2475.390905181419
avg_episode_per_sec: 2.475390905181419
collect_time: 1.2119297981262207
reward_mean: 1003.1845590142469
reward_std: 80.19534459302996
reward_max: 1069.7423613265785
reward_min: 890.3790324103314
total_envstep_count: 2085955
total_train_sample_count: 2085739
total_episode_count: 2203
total_duration: 902.9696058928961
[2023-05-17 14:42:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2367.795226864591
avg_train_sample_per_sec: 2367.795226864591
avg_episode_per_sec: 2.3677952268645908
collect_time: 2.1116690933704376
reward_mean: 1008.3014328516704
reward_std: 94.15367741964926
reward_max: 1114.5378134355747
reward_min: 835.6142080530757
total_envstep_count: 2089955
total_train_sample_count: 2089739
total_episode_count: 2208
total_duration: 905.0812749862665
[2023-05-17 14:42:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2338.555859639948
avg_train_sample_per_sec: 2338.555859639948
avg_episode_per_sec: 2.3385558596399476
collect_time: 1.282842993736267
reward_mean: 923.0188438691735
reward_std: 53.67038696561049
reward_max: 997.1476665210319
reward_min: 871.8316178540773
total_envstep_count: 2093955
total_train_sample_count: 2093739
total_episode_count: 2211
total_duration: 906.3641179800028
[2023-05-17 14:42:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2376.8415733862453
avg_train_sample_per_sec: 2376.8415733862453
avg_episode_per_sec: 2.3768415733862454
collect_time: 2.103632003068924
reward_mean: 715.6436872536892
reward_std: 39.081001418153214
reward_max: 769.2625069912418
reward_min: 656.9313871623012
total_envstep_count: 2097955
total_train_sample_count: 2097739
total_episode_count: 2216
total_duration: 908.4677499830717
[2023-05-17 14:42:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2452.020097819391
avg_train_sample_per_sec: 2452.020097819391
avg_episode_per_sec: 2.452020097819391
collect_time: 1.223480999469757
reward_mean: 930.328088477417
reward_std: 17.279717740120937
reward_max: 951.2412772908194
reward_min: 908.9233495699974
total_envstep_count: 2101955
total_train_sample_count: 2101739
total_episode_count: 2219
total_duration: 909.6912309825415
[2023-05-17 14:42:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4875
train_sample_count: 4875
avg_envstep_per_episode: 975.0
avg_sample_per_episode: 975.0
avg_envstep_per_sec: 2486.0164561352913
avg_train_sample_per_sec: 2486.0164561352913
avg_episode_per_sec: 2.5497604678310677
collect_time: 1.9609685157026564
reward_mean: 858.757563088486
reward_std: 40.94468477144726
reward_max: 905.6640519017715
reward_min: 789.5842262366899
total_envstep_count: 2105954
total_train_sample_count: 2105764
total_episode_count: 2224
total_duration: 911.6521994982442
[2023-05-17 14:42:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1878.1705204115842
avg_train_sample_per_sec: 1878.1705204115842
avg_episode_per_sec: 1.8781705204115842
collect_time: 1.5972990563937597
reward_mean: 920.1073820202209
reward_std: 57.208987702195365
reward_max: 986.3762530821845
reward_min: 846.7780468501736
total_envstep_count: 2109954
total_train_sample_count: 2109764
total_episode_count: 2227
total_duration: 913.249498554638
[2023-05-17 14:42:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2472.788943949425
avg_train_sample_per_sec: 2472.788943949425
avg_episode_per_sec: 2.4727889439494253
collect_time: 2.0220083934920177
reward_mean: 985.9244318314038
reward_std: 128.59192287861484
reward_max: 1141.5697305314839
reward_min: 773.8948941753889
total_envstep_count: 2113953
total_train_sample_count: 2113764
total_episode_count: 2232
total_duration: 915.27150694813
[2023-05-17 14:42:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2532.218205319661
avg_train_sample_per_sec: 2532.218205319661
avg_episode_per_sec: 2.532218205319661
collect_time: 1.1847320241587502
reward_mean: 1021.4675372758182
reward_std: 179.97619964715443
reward_max: 1173.2963634175705
reward_min: 768.6402803425991
total_envstep_count: 2117953
total_train_sample_count: 2117764
total_episode_count: 2235
total_duration: 916.4562389722887
[2023-05-17 14:42:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2525.7240778910636
avg_train_sample_per_sec: 2525.7240778910636
avg_episode_per_sec: 2.5257240778910637
collect_time: 1.979630334036691
reward_mean: 961.2188345163661
reward_std: 81.29262361919832
reward_max: 1117.5905681649792
reward_min: 897.1661027359554
total_envstep_count: 2121952
total_train_sample_count: 2121764
total_episode_count: 2240
total_duration: 918.4358693063253
[2023-05-17 14:42:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2560.5411299842876
avg_train_sample_per_sec: 2560.5411299842876
avg_episode_per_sec: 2.560541129984288
collect_time: 1.1716273427009583
reward_mean: 897.4878648648282
reward_std: 44.049464729823754
reward_max: 932.8815144472512
reward_min: 835.3950921571292
total_envstep_count: 2125952
total_train_sample_count: 2125764
total_episode_count: 2243
total_duration: 919.6074966490263
[2023-05-17 14:42:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2527.3663526956348
avg_train_sample_per_sec: 2527.3663526956348
avg_episode_per_sec: 2.5273663526956347
collect_time: 1.9783439763954709
reward_mean: 777.3765244305612
reward_std: 132.25344013837685
reward_max: 936.0517594779451
reward_min: 588.041137673266
total_envstep_count: 2129951
total_train_sample_count: 2129764
total_episode_count: 2248
total_duration: 921.5858406254217
[2023-05-17 14:42:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2538.8478965720305
avg_train_sample_per_sec: 2538.8478965720305
avg_episode_per_sec: 2.5388478965720305
collect_time: 1.1816383344786507
reward_mean: 809.346191882146
reward_std: 113.92432984553825
reward_max: 951.2419862500675
reward_min: 672.3126150719992
total_envstep_count: 2133951
total_train_sample_count: 2133764
total_episode_count: 2251
total_duration: 922.7674789599004
[2023-05-17 14:42:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2498.975193764051
avg_train_sample_per_sec: 2498.975193764051
avg_episode_per_sec: 2.4989751937640508
collect_time: 2.0008201811994826
reward_mean: 1058.9502920543648
reward_std: 104.42973808275475
reward_max: 1196.2685534733262
reward_min: 910.4012334365613
total_envstep_count: 2137950
total_train_sample_count: 2137764
total_episode_count: 2256
total_duration: 924.7682991410999
[2023-05-17 14:43:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2442.1267523553765
avg_train_sample_per_sec: 2442.1267523553765
avg_episode_per_sec: 2.4421267523553762
collect_time: 1.228437466280801
reward_mean: 830.3512898687927
reward_std: 85.79926887515319
reward_max: 931.5073816754699
reward_min: 721.7400153195691
total_envstep_count: 2141950
total_train_sample_count: 2141764
total_episode_count: 2259
total_duration: 925.9967366073806
[2023-05-17 14:43:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2185.853652368153
avg_train_sample_per_sec: 2185.853652368153
avg_episode_per_sec: 2.1858536523681527
collect_time: 2.287435846669333
reward_mean: 846.03701040279
reward_std: 175.02009043775934
reward_max: 1150.4448948778997
reward_min: 659.8652322001122
total_envstep_count: 2145949
total_train_sample_count: 2145764
total_episode_count: 2264
total_duration: 928.28417245405
[2023-05-17 14:43:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2238.563281710314
avg_train_sample_per_sec: 2238.563281710314
avg_episode_per_sec: 2.2385632817103143
collect_time: 1.3401452728680203
reward_mean: 874.7694346599961
reward_std: 19.39156214003957
reward_max: 895.5689560604259
reward_min: 848.891174178429
total_envstep_count: 2149949
total_train_sample_count: 2149764
total_episode_count: 2267
total_duration: 929.624317726918
[2023-05-17 14:43:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2447.060726572669
avg_train_sample_per_sec: 2447.060726572669
avg_episode_per_sec: 2.4470607265726687
collect_time: 2.043267641748701
reward_mean: 939.0185943872251
reward_std: 84.72831245627096
reward_max: 1059.8630464006474
reward_min: 820.7008976549766
total_envstep_count: 2153948
total_train_sample_count: 2153764
total_episode_count: 2272
total_duration: 931.6675853686667
[2023-05-17 14:43:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3749
train_sample_count: 3749
avg_envstep_per_episode: 937.25
avg_sample_per_episode: 937.25
avg_envstep_per_sec: 2425.0845437268554
avg_train_sample_per_sec: 2425.0845437268554
avg_episode_per_sec: 2.5874468324639697
collect_time: 1.545925485236304
reward_mean: 844.6725035481243
reward_std: 107.78067533374383
reward_max: 1006.9613705272657
reward_min: 716.6508389354899
total_envstep_count: 2158059
total_train_sample_count: 2158013
total_episode_count: 2276
total_duration: 933.213510853903
[2023-05-17 14:43:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2348.1574240582227
avg_train_sample_per_sec: 2348.1574240582227
avg_episode_per_sec: 2.3481574240582224
collect_time: 2.129329127924783
reward_mean: 836.5754426365918
reward_std: 122.91317163168776
reward_max: 1031.9008539717431
reward_min: 672.5179388860192
total_envstep_count: 2162058
total_train_sample_count: 2162013
total_episode_count: 2281
total_duration: 935.3428399818278
[2023-05-17 14:43:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2380.152444410869
avg_train_sample_per_sec: 2380.152444410869
avg_episode_per_sec: 2.3801524444108693
collect_time: 1.260423468691962
reward_mean: 1014.6272881610333
reward_std: 34.31540857334312
reward_max: 1061.1362515465194
reward_min: 979.3724672256338
total_envstep_count: 2166058
total_train_sample_count: 2166013
total_episode_count: 2284
total_duration: 936.6032634505198
[2023-05-17 14:43:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2315.924249973976
avg_train_sample_per_sec: 2315.924249973976
avg_episode_per_sec: 2.315924249973976
collect_time: 2.1589652597904205
reward_mean: 972.1143295012528
reward_std: 81.76952367736733
reward_max: 1051.8405687646418
reward_min: 825.0496510743437
total_envstep_count: 2170057
total_train_sample_count: 2170013
total_episode_count: 2289
total_duration: 938.7622287103102
[2023-05-17 14:43:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2250.2763469673023
avg_train_sample_per_sec: 2250.2763469673023
avg_episode_per_sec: 2.250276346967302
collect_time: 1.3331695922783442
reward_mean: 915.5387434228911
reward_std: 80.07201072909693
reward_max: 985.6667384487371
reward_min: 803.4757940434516
total_envstep_count: 2174057
total_train_sample_count: 2174013
total_episode_count: 2292
total_duration: 940.0953983025885
[2023-05-17 14:43:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1982.7720985803585
avg_train_sample_per_sec: 1982.7720985803585
avg_episode_per_sec: 1.9827720985803585
collect_time: 2.521721988916397
reward_mean: 938.1764226745884
reward_std: 101.11458979844339
reward_max: 1117.8663133386221
reward_min: 820.3274885466813
total_envstep_count: 2178056
total_train_sample_count: 2178013
total_episode_count: 2297
total_duration: 942.6171202915049
[2023-05-17 14:43:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2436.716585883637
avg_train_sample_per_sec: 2436.716585883637
avg_episode_per_sec: 2.4367165858836373
collect_time: 1.231164927993502
reward_mean: 829.459876419629
reward_std: 181.59010280583152
reward_max: 1086.2588864913666
reward_min: 699.2856953061665
total_envstep_count: 2182056
total_train_sample_count: 2182013
total_episode_count: 2300
total_duration: 943.8482852194984
[2023-05-17 14:43:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2425.279992387826
avg_train_sample_per_sec: 2425.279992387826
avg_episode_per_sec: 2.425279992387826
collect_time: 2.0616176341261183
reward_mean: 961.9306098104122
reward_std: 139.30512235657508
reward_max: 1120.5629912700524
reward_min: 733.3515915952413
total_envstep_count: 2186055
total_train_sample_count: 2186013
total_episode_count: 2305
total_duration: 945.9099028536245
[2023-05-17 14:44:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2372.4549085285153
avg_train_sample_per_sec: 2372.4549085285153
avg_episode_per_sec: 2.3724549085285154
collect_time: 1.2645129689148493
reward_mean: 935.2618719424673
reward_std: 98.10558709527146
reward_max: 1068.8278494564065
reward_min: 835.9649389919481
total_envstep_count: 2190055
total_train_sample_count: 2190013
total_episode_count: 2308
total_duration: 947.1744158225393
[2023-05-17 14:44:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2213.839753604631
avg_train_sample_per_sec: 2213.839753604631
avg_episode_per_sec: 2.213839753604631
collect_time: 2.258519385542188
reward_mean: 879.9730067630296
reward_std: 157.74090827258095
reward_max: 1077.6789835738014
reward_min: 726.9223517951087
total_envstep_count: 2194055
total_train_sample_count: 2194013
total_episode_count: 2313
total_duration: 949.4329352080815
[2023-05-17 14:44:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2233.7459362954564
avg_train_sample_per_sec: 2233.7459362954564
avg_episode_per_sec: 2.2337459362954566
collect_time: 1.3430354595184326
reward_mean: 1021.6437050446493
reward_std: 90.98241301817659
reward_max: 1088.560555878154
reward_min: 893.0101750899456
total_envstep_count: 2198055
total_train_sample_count: 2198013
total_episode_count: 2316
total_duration: 950.7759706676
[2023-05-17 14:44:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2200.1131423483466
avg_train_sample_per_sec: 2200.1131423483466
avg_episode_per_sec: 2.2001131423483464
collect_time: 2.2726103961467743
reward_mean: 802.7932868619785
reward_std: 116.44724424680825
reward_max: 986.8781006286191
reward_min: 690.8269047062503
total_envstep_count: 2202055
total_train_sample_count: 2202013
total_episode_count: 2321
total_duration: 953.0485810637467
[2023-05-17 14:44:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2236.812366318673
avg_train_sample_per_sec: 2236.812366318673
avg_episode_per_sec: 2.2368123663186728
collect_time: 1.3411943018436432
reward_mean: 831.2175898329082
reward_std: 231.0238592979995
reward_max: 1006.6098985381678
reward_min: 504.80363370862165
total_envstep_count: 2206055
total_train_sample_count: 2206013
total_episode_count: 2324
total_duration: 954.3897753655904
[2023-05-17 14:44:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2186.889592969258
avg_train_sample_per_sec: 2186.889592969258
avg_episode_per_sec: 2.186889592969258
collect_time: 2.286352276802063
reward_mean: 887.4234083252601
reward_std: 151.51592287825878
reward_max: 1118.891578697658
reward_min: 690.8574194143004
total_envstep_count: 2210055
total_train_sample_count: 2210013
total_episode_count: 2329
total_duration: 956.6761276423924
[2023-05-17 14:44:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1671.8910193941147
avg_train_sample_per_sec: 1671.8910193941147
avg_episode_per_sec: 1.6718910193941146
collect_time: 1.794375330209732
reward_mean: 959.0182078543372
reward_std: 38.19149755524737
reward_max: 1012.7056063683029
reward_min: 927.0624484577748
total_envstep_count: 2214055
total_train_sample_count: 2214013
total_episode_count: 2332
total_duration: 958.4705029726022
[2023-05-17 14:44:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2166.438746092193
avg_train_sample_per_sec: 2166.438746092193
avg_episode_per_sec: 2.166438746092193
collect_time: 2.3079350888729095
reward_mean: 725.3824454590789
reward_std: 138.86868301231954
reward_max: 877.2117637804395
reward_min: 520.4749867231886
total_envstep_count: 2218055
total_train_sample_count: 2218013
total_episode_count: 2337
total_duration: 960.7784380614751
[2023-05-17 14:44:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2280.3124437713323
avg_train_sample_per_sec: 2280.3124437713323
avg_episode_per_sec: 2.280312443771332
collect_time: 1.315609186887741
reward_mean: 828.2453488048023
reward_std: 106.95909047250645
reward_max: 973.489364456775
reward_min: 719.0377906887646
total_envstep_count: 2222055
total_train_sample_count: 2222013
total_episode_count: 2340
total_duration: 962.0940472483628
[2023-05-17 14:44:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 5000
train_sample_count: 5000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2358.3178360892794
avg_train_sample_per_sec: 2358.3178360892794
avg_episode_per_sec: 2.358317836089279
collect_time: 2.1201552748680115
reward_mean: 886.395565378908
reward_std: 85.85722553302327
reward_max: 977.4965697706078
reward_min: 776.3050141693057
total_envstep_count: 2226055
total_train_sample_count: 2226013
total_episode_count: 2345
total_duration: 964.2142025232308
[2023-05-17 14:44:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3000
train_sample_count: 3000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2362.566179200527
avg_train_sample_per_sec: 2362.566179200527
avg_episode_per_sec: 2.3625661792005275
collect_time: 1.2698056995868683
reward_mean: 878.4275423412014
reward_std: 130.4509616322498
reward_max: 1054.9110601073453
reward_min: 743.6416532822046
total_envstep_count: 2230055
total_train_sample_count: 2230013
total_episode_count: 2348
total_duration: 965.4840082228177
[2023-05-17 14:44:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 5450
train_sample_count: 5450
avg_envstep_per_episode: 908.3333333333334
avg_sample_per_episode: 908.3333333333334
avg_envstep_per_sec: 2238.7700188570625
avg_train_sample_per_sec: 2238.7700188570625
avg_episode_per_sec: 2.4647009381912617
collect_time: 2.4343724250793457
reward_mean: 836.2287457359131
reward_std: 222.97003149528868
reward_max: 1055.1586818326602
reward_min: 362.15737741537174
total_envstep_count: 2234055
total_train_sample_count: 2234013
total_episode_count: 2354
total_duration: 967.918380647897
[2023-05-17 14:45:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2260.2555738589995
avg_train_sample_per_sec: 2260.2555738589995
avg_episode_per_sec: 2.260255573859
collect_time: 0.8848556876182556
reward_mean: 871.0689647269801
reward_std: 92.97286905885198
reward_max: 964.0418337858321
reward_min: 778.0960956681281
total_envstep_count: 2238055
total_train_sample_count: 2238013
total_episode_count: 2356
total_duration: 968.8032363355153
[2023-05-17 14:45:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 2093.5554244359023
avg_train_sample_per_sec: 2093.5554244359023
avg_episode_per_sec: 2.0935554244359023
collect_time: 2.865937978029251
reward_mean: 960.0111843604914
reward_std: 96.16483031073679
reward_max: 1064.4505294150788
reward_min: 856.0653279734087
total_envstep_count: 2242055
total_train_sample_count: 2242013
total_episode_count: 2362
total_duration: 971.6691743135445
[2023-05-17 14:45:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1905.1226068355118
avg_train_sample_per_sec: 1905.1226068355118
avg_episode_per_sec: 1.9051226068355116
collect_time: 1.0498012006282806
reward_mean: 1012.5476318359364
reward_std: 46.47272959242139
reward_max: 1059.0203614283578
reward_min: 966.074902243515
total_envstep_count: 2246055
total_train_sample_count: 2246013
total_episode_count: 2364
total_duration: 972.7189755141728
[2023-05-17 14:45:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 6000
train_sample_count: 6000
avg_envstep_per_episode: 1000.0
avg_sample_per_episode: 1000.0
avg_envstep_per_sec: 1980.7005098651239
avg_train_sample_per_sec: 1980.7005098651239
avg_episode_per_sec: 1.980700509865124
collect_time: 3.029231309890747
reward_mean: 1000.0945782887092
reward_std: 59.317132577283886
reward_max: 1060.7158485089958
reward_min: 887.7416392087423
total_envstep_count: 2250055
total_train_sample_count: 2250013
total_episode_count: 2370
total_duration: 975.7482068240636
