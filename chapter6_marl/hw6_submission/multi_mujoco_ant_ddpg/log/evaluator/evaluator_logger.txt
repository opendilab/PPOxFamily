[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 977.7732, current episode: 1
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 989.9731, current episode: 2
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 989.4619, current episode: 3
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 981.8230, current episode: 4
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 984.2490, current episode: 5
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 982.5150, current episode: 6
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 984.4482, current episode: 7
[2023-05-17 13:59:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 982.4923, current episode: 8
[2023-05-17 13:59:03][interaction_serial_evaluator.py:279][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 8.000000      | 8000.000000   |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.005675      | 2661.631678         | 2.661632             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 984.091972  | 3.769897   | 989.973145 | 977.773193 |
+-------+-------------+------------+------------+------------+


[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 657.7527, current episode: 1
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 401.9315, current episode: 2
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 850.3030, current episode: 3
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 706.0672, current episode: 4
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 885.0460, current episode: 5
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 780.0268, current episode: 6
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 808.2148, current episode: 7
[2023-05-17 13:59:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 673.1819, current episode: 8
[2023-05-17 13:59:25][interaction_serial_evaluator.py:279][INFO] 
+-------+------------+-----------------------+---------------+---------------+
| Name  | train_iter | ckpt_name             | episode_count | envstep_count |
+-------+------------+-----------------------+---------------+---------------+
| Value | 500.000000 | iteration_500.pth.tar | 8.000000      | 8000.000000   |
+-------+------------+-----------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.210822      | 2491.573727         | 2.491574             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 720.315487  | 142.754903 | 885.046021 | 401.931488 |
+-------+-------------+------------+------------+------------+


[2023-05-17 13:59:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 963.9771, current episode: 1
[2023-05-17 13:59:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 962.4634, current episode: 2
[2023-05-17 13:59:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 960.5912, current episode: 3
[2023-05-17 13:59:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 974.4475, current episode: 4
[2023-05-17 13:59:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 963.2950, current episode: 5
[2023-05-17 13:59:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 978.4290, current episode: 6
[2023-05-17 13:59:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 967.5027, current episode: 7
[2023-05-17 13:59:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 971.1625, current episode: 8
[2023-05-17 13:59:48][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 1000.000000 | iteration_1000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.270087      | 2446.418089         | 2.446418             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 967.733551  | 5.956940   | 978.429016 | 960.591187 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 910.1113, current episode: 1
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 902.5411, current episode: 2
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 901.4553, current episode: 3
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 902.3707, current episode: 4
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 900.9399, current episode: 5
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 904.6224, current episode: 6
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 899.7380, current episode: 7
[2023-05-17 14:00:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 902.0082, current episode: 8
[2023-05-17 14:00:10][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 1500.000000 | iteration_1500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.320724      | 2409.113186         | 2.409113             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 902.973351  | 3.001195   | 910.111267 | 899.738037 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 964.1114, current episode: 1
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 969.8950, current episode: 2
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 957.9074, current episode: 3
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 961.3271, current episode: 4
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 965.2208, current episode: 5
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 966.2554, current episode: 6
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 964.5550, current episode: 7
[2023-05-17 14:00:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 973.8017, current episode: 8
[2023-05-17 14:00:33][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.346742      | 2390.384500         | 2.390385             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 965.384239  | 4.564225   | 973.801697 | 957.907410 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 911.8406, current episode: 1
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 925.8324, current episode: 2
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 912.1760, current episode: 3
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 925.1123, current episode: 4
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 931.0437, current episode: 5
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 936.4765, current episode: 6
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 922.3780, current episode: 7
[2023-05-17 14:00:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 925.2866, current episode: 8
[2023-05-17 14:00:57][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2500.000000 | iteration_2500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.289105      | 2432.272655         | 2.432273             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 923.768272  | 7.916635   | 936.476501 | 911.840637 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 884.8521, current episode: 1
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 890.1829, current episode: 2
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 886.1947, current episode: 3
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 889.2640, current episode: 4
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 887.9877, current episode: 5
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 893.0917, current episode: 6
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 886.5602, current episode: 7
[2023-05-17 14:01:20][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 888.3843, current episode: 8
[2023-05-17 14:01:20][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 3000.000000 | iteration_3000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.165324      | 2527.387233         | 2.527387             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 888.314720  | 2.420867   | 893.091675 | 884.852112 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 943.3777, current episode: 1
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 933.8774, current episode: 2
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 945.4736, current episode: 3
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 935.8216, current episode: 4
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 938.7723, current episode: 5
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 936.5121, current episode: 6
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 933.4130, current episode: 7
[2023-05-17 14:01:43][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 938.9644, current episode: 8
[2023-05-17 14:01:43][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 3500.000000 | iteration_3500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.160128      | 2531.543124         | 2.531543             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 938.276512  | 4.041739   | 945.473633 | 933.413025 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 937.6763, current episode: 1
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 930.3740, current episode: 2
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 931.6245, current episode: 3
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 928.4958, current episode: 4
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 932.2972, current episode: 5
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 919.8064, current episode: 6
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 938.3810, current episode: 7
[2023-05-17 14:02:06][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 934.8561, current episode: 8
[2023-05-17 14:02:06][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.097078      | 2583.079852         | 2.583080             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 931.688927  | 5.524465   | 938.380981 | 919.806396 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 873.0812, current episode: 1
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 887.1700, current episode: 2
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 868.0668, current episode: 3
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 844.7113, current episode: 4
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 868.0096, current episode: 5
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 876.8633, current episode: 6
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 897.5817, current episode: 7
[2023-05-17 14:02:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 865.0509, current episode: 8
[2023-05-17 14:02:28][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4500.000000 | iteration_4500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.065401      | 2609.772685         | 2.609773             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 872.566856  | 14.710364  | 897.581726 | 844.711304 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:02:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 369.5972, current episode: 1
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 910.2372, current episode: 2
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 952.6863, current episode: 3
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 942.5147, current episode: 4
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 940.5826, current episode: 5
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 991.7520, current episode: 6
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 968.6024, current episode: 7
[2023-05-17 14:02:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 945.4100, current episode: 8
[2023-05-17 14:02:50][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 5000.000000 | iteration_5000.pth.tar | 8.000000      | 7999.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.875000              | 3.102664      | 2578.107077         | 2.578429             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 877.672798  | 193.281188 | 991.751953 | 369.597229 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 880.9440, current episode: 1
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 883.9298, current episode: 2
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 885.4893, current episode: 3
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 885.1906, current episode: 4
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 884.5508, current episode: 5
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 883.6801, current episode: 6
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 885.4386, current episode: 7
[2023-05-17 14:03:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 890.1572, current episode: 8
[2023-05-17 14:03:13][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 5500.000000 | iteration_5500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.154953      | 2535.695458         | 2.535695             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 884.922554  | 2.412407   | 890.157227 | 880.943970 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 743.2242, current episode: 1
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 821.8520, current episode: 2
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 802.5733, current episode: 3
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 882.8370, current episode: 4
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 799.1304, current episode: 5
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 862.9095, current episode: 6
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 763.6822, current episode: 7
[2023-05-17 14:03:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 858.6998, current episode: 8
[2023-05-17 14:03:36][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.026470      | 2643.343613         | 2.643344             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 816.863556  | 46.121523  | 882.836975 | 743.224243 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 961.4263, current episode: 1
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 888.2005, current episode: 2
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 975.9991, current episode: 3
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 930.5818, current episode: 4
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 943.0502, current episode: 5
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 887.2352, current episode: 6
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 909.8288, current episode: 7
[2023-05-17 14:03:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 971.6541, current episode: 8
[2023-05-17 14:03:59][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6500.000000 | iteration_6500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.186616      | 2510.500211         | 2.510500             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 933.497002  | 33.343499  | 975.999084 | 887.235168 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 887.6100, current episode: 1
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 888.3754, current episode: 2
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 888.8637, current episode: 3
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 902.8026, current episode: 4
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 893.5991, current episode: 5
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 889.0873, current episode: 6
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 881.0509, current episode: 7
[2023-05-17 14:04:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 882.7619, current episode: 8
[2023-05-17 14:04:23][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 7000.000000 | iteration_7000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.109800      | 2572.512816         | 2.572513             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 889.268875  | 6.280286   | 902.802612 | 881.050903 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 882.2034, current episode: 1
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 947.8315, current episode: 2
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 870.5809, current episode: 3
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 897.9874, current episode: 4
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 982.2203, current episode: 5
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 905.9996, current episode: 6
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 840.0095, current episode: 7
[2023-05-17 14:04:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 902.3848, current episode: 8
[2023-05-17 14:04:46][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 7500.000000 | iteration_7500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 2.962777      | 2700.169561         | 2.700170             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 903.652168  | 41.485110  | 982.220276 | 840.009460 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 927.4989, current episode: 1
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 880.7584, current episode: 2
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 924.7305, current episode: 3
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 981.2805, current episode: 4
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 868.5192, current episode: 5
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 892.8361, current episode: 6
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 903.9629, current episode: 7
[2023-05-17 14:05:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1001.8486, current episode: 8
[2023-05-17 14:05:10][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.140935      | 2547.012320         | 2.547012             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 922.679390  | 44.244941  | 1001.848633 | 868.519226 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 947.8060, current episode: 1
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 901.2982, current episode: 2
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 917.9243, current episode: 3
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 955.3590, current episode: 4
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 874.8187, current episode: 5
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 930.8276, current episode: 6
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 949.7410, current episode: 7
[2023-05-17 14:05:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 899.1563, current episode: 8
[2023-05-17 14:05:33][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8500.000000 | iteration_8500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.304757      | 2420.752960         | 2.420753             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 922.116386  | 26.970467  | 955.359009 | 874.818665 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 989.1163, current episode: 1
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 966.9517, current episode: 2
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 982.9413, current episode: 3
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 975.5519, current episode: 4
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 991.0200, current episode: 5
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 984.2337, current episode: 6
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 977.0586, current episode: 7
[2023-05-17 14:05:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 983.7473, current episode: 8
[2023-05-17 14:05:58][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 9000.000000 | iteration_9000.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.589107      | 2228.966681         | 2.228967             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 981.327591  | 7.329391   | 991.020020 | 966.951721 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 876.4185, current episode: 1
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 873.9729, current episode: 2
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 867.8909, current episode: 3
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 870.8429, current episode: 4
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 865.5070, current episode: 5
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 875.1188, current episode: 6
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 875.0806, current episode: 7
[2023-05-17 14:06:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 867.7488, current episode: 8
[2023-05-17 14:06:24][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 9500.000000 | iteration_9500.pth.tar | 8.000000      | 8000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.217307      | 2486.551755         | 2.486552             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 871.572533  | 3.866956   | 876.418518 | 865.506958 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 944.4069, current episode: 1
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 942.1379, current episode: 2
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 939.5991, current episode: 3
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 940.7540, current episode: 4
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 940.5885, current episode: 5
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 947.2815, current episode: 6
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 947.8234, current episode: 7
[2023-05-17 14:06:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 938.9965, current episode: 8
[2023-05-17 14:06:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 10000.000000 | iteration_10000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.323016      | 2407.451596         | 2.407452             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 942.698456  | 3.202455   | 947.823364 | 938.996460 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 965.5020, current episode: 1
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 976.6108, current episode: 2
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 970.3947, current episode: 3
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 966.5520, current episode: 4
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 965.0660, current episode: 5
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 964.6625, current episode: 6
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 968.4940, current episode: 7
[2023-05-17 14:07:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 965.6433, current episode: 8
[2023-05-17 14:07:13][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 10500.000000 | iteration_10500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.322508      | 2407.819565         | 2.407820             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 967.865646  | 3.768587   | 976.610779 | 964.662476 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 998.9550, current episode: 1
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 979.9745, current episode: 2
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 987.1335, current episode: 3
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 979.8806, current episode: 4
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 982.1358, current episode: 5
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 983.4784, current episode: 6
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.2944, current episode: 7
[2023-05-17 14:07:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 983.6247, current episode: 8
[2023-05-17 14:07:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 11000.000000 | iteration_11000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.168493      | 2524.859584         | 2.524860             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 985.059616  | 5.736146   | 998.955017 | 979.880615 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 964.8519, current episode: 1
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 947.9365, current episode: 2
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1009.2324, current episode: 3
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 973.8993, current episode: 4
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 978.7183, current episode: 5
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 970.1707, current episode: 6
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 959.9133, current episode: 7
[2023-05-17 14:08:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 994.5506, current episode: 8
[2023-05-17 14:08:03][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 11500.000000 | iteration_11500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.279482      | 2439.409545         | 2.439410             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 974.909103  | 18.218815  | 1009.232361 | 947.936462 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 996.9985, current episode: 1
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 925.3820, current episode: 2
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 965.2354, current episode: 3
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 904.6235, current episode: 4
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 992.0226, current episode: 5
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 939.3140, current episode: 6
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 962.7860, current episode: 7
[2023-05-17 14:08:28][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 996.9960, current episode: 8
[2023-05-17 14:08:28][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 12000.000000 | iteration_12000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.155550      | 2535.215920         | 2.535216             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 960.419754  | 32.576209  | 996.998474 | 904.623474 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.0201, current episode: 1
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 930.6769, current episode: 2
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 910.1218, current episode: 3
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 906.1246, current episode: 4
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 918.5093, current episode: 5
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 926.3696, current episode: 6
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 911.3546, current episode: 7
[2023-05-17 14:08:52][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 907.9747, current episode: 8
[2023-05-17 14:08:52][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 12500.000000 | iteration_12500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.155885      | 2534.946631         | 2.534947             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 914.643951  | 8.889512   | 930.676941 | 906.020081 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 915.5743, current episode: 1
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 906.5249, current episode: 2
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 906.9128, current episode: 3
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 934.4457, current episode: 4
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 920.4440, current episode: 5
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 967.1812, current episode: 6
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 933.7126, current episode: 7
[2023-05-17 14:09:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 893.5695, current episode: 8
[2023-05-17 14:09:16][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 13000.000000 | iteration_13000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.083468      | 2594.481112         | 2.594481             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 922.295631  | 21.365366  | 967.181213 | 893.569458 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 969.3474, current episode: 1
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 986.1362, current episode: 2
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 980.9482, current episode: 3
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 976.5436, current episode: 4
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 983.2144, current episode: 5
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 968.6760, current episode: 6
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 977.0653, current episode: 7
[2023-05-17 14:09:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 975.8806, current episode: 8
[2023-05-17 14:09:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 13500.000000 | iteration_13500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.112787      | 2570.044137         | 2.570044             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 977.226456  | 5.772625   | 986.136230 | 968.675964 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 930.0705, current episode: 1
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 943.2066, current episode: 2
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 928.9829, current episode: 3
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 943.0422, current episode: 4
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 929.4293, current episode: 5
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 967.0432, current episode: 6
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 924.8727, current episode: 7
[2023-05-17 14:10:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 931.3278, current episode: 8
[2023-05-17 14:10:03][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 14000.000000 | iteration_14000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.196442      | 2502.782869         | 2.502783             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 937.246910  | 12.874340  | 967.043213 | 924.872742 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 932.5700, current episode: 1
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 924.2256, current episode: 2
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 900.9089, current episode: 3
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 978.1069, current episode: 4
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 993.7034, current episode: 5
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 901.6606, current episode: 6
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 925.0632, current episode: 7
[2023-05-17 14:10:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 959.8667, current episode: 8
[2023-05-17 14:10:29][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 14500.000000 | iteration_14500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.605509      | 2218.826775         | 2.218827             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 939.513161  | 32.121157  | 993.703430 | 900.908875 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 934.1624, current episode: 1
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 953.4846, current episode: 2
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 894.7805, current episode: 3
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 947.1076, current episode: 4
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 947.1846, current episode: 5
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 882.6173, current episode: 6
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 897.3036, current episode: 7
[2023-05-17 14:10:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 920.1455, current episode: 8
[2023-05-17 14:10:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 15000.000000 | iteration_15000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.117534      | 2566.130858         | 2.566131             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 922.098244  | 25.760991  | 953.484558 | 882.617310 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:11:15][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 27.9758, current episode: 1
[2023-05-17 14:11:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 338.1286, current episode: 2
[2023-05-17 14:11:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 307.8673, current episode: 3
[2023-05-17 14:11:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 101.7265, current episode: 3
[2023-05-17 14:11:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 74.1086, current episode: 3
[2023-05-17 14:11:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1032.8359, current episode: 4
[2023-05-17 14:11:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 896.6284, current episode: 5
[2023-05-17 14:11:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 773.1957, current episode: 6
[2023-05-17 14:11:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 853.8660, current episode: 7
[2023-05-17 14:11:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1155.3324, current episode: 8
[2023-05-17 14:11:18][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 15500.000000 | iteration_15500.pth.tar | 8.000000      | 7996.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.500000              | 3.116448      | 2565.741572         | 2.567025             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 644.008922  | 408.507945 | 1155.332397 | 27.975798  |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 921.6094, current episode: 1
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 926.1699, current episode: 2
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 921.8964, current episode: 3
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 931.4810, current episode: 4
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 924.3957, current episode: 5
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 923.8394, current episode: 6
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 919.5236, current episode: 7
[2023-05-17 14:11:41][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 915.7040, current episode: 8
[2023-05-17 14:11:41][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 16000.000000 | iteration_16000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.242246      | 2467.425425         | 2.467425             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 923.077408  | 4.373900   | 931.480957 | 915.703979 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 755.8401, current episode: 1
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 835.3993, current episode: 2
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 813.8626, current episode: 3
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 774.8965, current episode: 4
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 816.9952, current episode: 5
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 872.7888, current episode: 6
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 740.4757, current episode: 7
[2023-05-17 14:12:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 767.1956, current episode: 8
[2023-05-17 14:12:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 16500.000000 | iteration_16500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 4.034001      | 1983.142853         | 1.983143             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 797.181732  | 42.083752  | 872.788818 | 740.475708 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 978.0893, current episode: 1
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 867.3163, current episode: 2
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1037.2004, current episode: 3
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1165.6552, current episode: 4
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1001.3397, current episode: 5
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 889.5641, current episode: 6
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1161.9846, current episode: 7
[2023-05-17 14:12:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1048.2209, current episode: 8
[2023-05-17 14:12:37][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 17000.000000 | iteration_17000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.308303      | 2418.158280         | 2.418158             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1018.671326 | 103.007120 | 1165.655151 | 867.316345 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 846.2800, current episode: 1
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 793.1252, current episode: 2
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 877.9152, current episode: 3
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 847.1992, current episode: 4
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 875.3665, current episode: 5
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 719.1133, current episode: 6
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 732.5524, current episode: 7
[2023-05-17 14:13:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 801.2959, current episode: 8
[2023-05-17 14:13:01][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 17500.000000 | iteration_17500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.062172      | 2612.524556         | 2.612525             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 811.605965  | 57.209787  | 877.915222 | 719.113342 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 977.8639, current episode: 1
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 981.3124, current episode: 2
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 973.8367, current episode: 3
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 976.0979, current episode: 4
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 984.8750, current episode: 5
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 982.8184, current episode: 6
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 981.6179, current episode: 7
[2023-05-17 14:13:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 981.0366, current episode: 8
[2023-05-17 14:13:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 18000.000000 | iteration_18000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.144550      | 2544.084333         | 2.544084             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 979.932343  | 3.443508   | 984.875000 | 973.836731 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 850.6438, current episode: 1
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 999.4714, current episode: 2
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.2463, current episode: 3
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 992.3925, current episode: 4
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 977.9034, current episode: 5
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 976.2720, current episode: 6
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 984.4352, current episode: 7
[2023-05-17 14:13:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 982.8960, current episode: 8
[2023-05-17 14:13:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 18500.000000 | iteration_18500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.122340      | 2562.180958         | 2.562181             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 969.407578  | 45.471106  | 999.471375 | 850.643799 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:14:10][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 324.1364, current episode: 1
[2023-05-17 14:14:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 891.4839, current episode: 2
[2023-05-17 14:14:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 901.9062, current episode: 3
[2023-05-17 14:14:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 922.2354, current episode: 4
[2023-05-17 14:14:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 846.3490, current episode: 5
[2023-05-17 14:14:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 945.7315, current episode: 6
[2023-05-17 14:14:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 882.0189, current episode: 7
[2023-05-17 14:14:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 766.5336, current episode: 8
[2023-05-17 14:14:13][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 19000.000000 | iteration_19000.pth.tar | 8.000000      | 7999.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.875000              | 3.463456      | 2309.542895         | 2.309832             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 810.049385  | 190.580340 | 945.731506 | 324.136414 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 778.5865, current episode: 1
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 919.0809, current episode: 2
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 908.7526, current episode: 3
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 977.1400, current episode: 4
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 797.1084, current episode: 5
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 886.7208, current episode: 6
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 872.7578, current episode: 7
[2023-05-17 14:14:37][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 905.2111, current episode: 8
[2023-05-17 14:14:37][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 19500.000000 | iteration_19500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.119490      | 2564.521840         | 2.564522             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 880.669754  | 60.905208  | 977.140015 | 778.586487 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 799.6317, current episode: 1
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 875.3286, current episode: 2
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 768.4349, current episode: 3
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 809.6394, current episode: 4
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 838.5995, current episode: 5
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 829.3618, current episode: 6
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 783.0942, current episode: 7
[2023-05-17 14:15:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 764.3897, current episode: 8
[2023-05-17 14:15:01][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 20000.000000 | iteration_20000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 2.985545      | 2679.577837         | 2.679578             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 808.559990  | 35.502728  | 875.328552 | 764.389709 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 930.3350, current episode: 1
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 932.6299, current episode: 2
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 927.3442, current episode: 3
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 935.3506, current episode: 4
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 936.3054, current episode: 5
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 932.5588, current episode: 6
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 928.2911, current episode: 7
[2023-05-17 14:15:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 932.9642, current episode: 8
[2023-05-17 14:15:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 20500.000000 | iteration_20500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.110440      | 2571.983372         | 2.571983             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 931.972404  | 2.949585   | 936.305420 | 927.344177 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 900.0832, current episode: 1
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 909.4222, current episode: 2
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 925.1915, current episode: 3
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 921.8945, current episode: 4
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 892.1037, current episode: 5
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 902.2224, current episode: 6
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 920.9480, current episode: 7
[2023-05-17 14:15:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 917.3321, current episode: 8
[2023-05-17 14:15:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 21000.000000 | iteration_21000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.088629      | 2590.145978         | 2.590146             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 911.149689  | 11.262498  | 925.191467 | 892.103699 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 879.0658, current episode: 1
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 845.9417, current episode: 2
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 759.2043, current episode: 3
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 752.9803, current episode: 4
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 833.9590, current episode: 5
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 935.6819, current episode: 6
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 881.3325, current episode: 7
[2023-05-17 14:16:11][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 942.5977, current episode: 8
[2023-05-17 14:16:11][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 21500.000000 | iteration_21500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.015193      | 2653.229839         | 2.653230             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 853.845383  | 66.665622  | 942.597717 | 752.980286 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 809.3125, current episode: 1
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 812.6806, current episode: 2
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 923.9440, current episode: 3
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 858.3594, current episode: 4
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 876.4503, current episode: 5
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 938.1318, current episode: 6
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 853.4452, current episode: 7
[2023-05-17 14:16:34][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 868.6728, current episode: 8
[2023-05-17 14:16:34][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 22000.000000 | iteration_22000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.015155      | 2653.263197         | 2.653263             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 867.624580  | 43.197477  | 938.131836 | 809.312500 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 938.2595, current episode: 1
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 940.2475, current episode: 2
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 945.3294, current episode: 3
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 931.2137, current episode: 4
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 941.2310, current episode: 5
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 934.4558, current episode: 6
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 931.0353, current episode: 7
[2023-05-17 14:16:57][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 933.7817, current episode: 8
[2023-05-17 14:16:57][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 22500.000000 | iteration_22500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.140521      | 2547.348189         | 2.547348             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 936.944252  | 4.812445   | 945.329407 | 931.035339 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 967.3624, current episode: 1
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 941.4899, current episode: 2
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 954.2833, current episode: 3
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 971.7258, current episode: 4
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 954.4500, current episode: 5
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 938.4354, current episode: 6
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 943.1270, current episode: 7
[2023-05-17 14:17:23][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 944.3327, current episode: 8
[2023-05-17 14:17:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 23000.000000 | iteration_23000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.334306      | 2399.299883         | 2.399300             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 951.900787  | 11.555435  | 971.725769 | 938.435364 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 994.3840, current episode: 1
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 986.3639, current episode: 2
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 974.9653, current episode: 3
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 862.0178, current episode: 4
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 900.6465, current episode: 5
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1048.5551, current episode: 6
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1035.0558, current episode: 7
[2023-05-17 14:17:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 822.2247, current episode: 8
[2023-05-17 14:17:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 23500.000000 | iteration_23500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.320490      | 2409.282879         | 2.409283             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 953.026619  | 76.887100  | 1048.555054 | 822.224670 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 981.6252, current episode: 1
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 942.2874, current episode: 2
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 946.5673, current episode: 3
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.4795, current episode: 4
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 966.2195, current episode: 5
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 954.6907, current episode: 6
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 954.8651, current episode: 7
[2023-05-17 14:18:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 937.6323, current episode: 8
[2023-05-17 14:18:12][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 24000.000000 | iteration_24000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.076030      | 2600.754856         | 2.600755             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 955.045883  | 13.093065  | 981.625244 | 937.632263 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 964.3709, current episode: 1
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 954.7668, current episode: 2
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 957.7307, current episode: 3
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 992.0915, current episode: 4
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 965.3540, current episode: 5
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 957.6978, current episode: 6
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 941.6780, current episode: 7
[2023-05-17 14:18:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 948.2550, current episode: 8
[2023-05-17 14:18:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 24500.000000 | iteration_24500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.116987      | 2566.581329         | 2.566581             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 960.243080  | 14.091837  | 992.091492 | 941.677979 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1123.2668, current episode: 1
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 745.2319, current episode: 2
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1034.0853, current episode: 3
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1062.3384, current episode: 4
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 990.5714, current episode: 5
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 806.1995, current episode: 6
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 882.4323, current episode: 7
[2023-05-17 14:18:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 923.3572, current episode: 8
[2023-05-17 14:18:59][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 25000.000000 | iteration_25000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.022832      | 2646.524921         | 2.646525             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 945.935371  | 122.019102 | 1123.266846 | 745.231934 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 957.8466, current episode: 1
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 988.9966, current episode: 2
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 921.9596, current episode: 3
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 902.7657, current episode: 4
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 933.8613, current episode: 5
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 923.9064, current episode: 6
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 947.3231, current episode: 7
[2023-05-17 14:19:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 910.1270, current episode: 8
[2023-05-17 14:19:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 25500.000000 | iteration_25500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.051621      | 2621.557765         | 2.621558             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 935.848282  | 26.305506  | 988.996582 | 902.765686 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 712.3270, current episode: 1
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 776.0123, current episode: 2
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 786.6086, current episode: 3
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 764.5983, current episode: 4
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 785.2158, current episode: 5
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 775.4787, current episode: 6
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 704.4689, current episode: 7
[2023-05-17 14:19:45][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 779.5980, current episode: 8
[2023-05-17 14:19:45][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 26000.000000 | iteration_26000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.077451      | 2599.553989         | 2.599554             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 760.538460  | 30.820378  | 786.608643 | 704.468933 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 893.7877, current episode: 1
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 844.2786, current episode: 2
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 947.0411, current episode: 3
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 931.3110, current episode: 4
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 887.5650, current episode: 5
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 903.8307, current episode: 6
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 857.2159, current episode: 7
[2023-05-17 14:20:09][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 930.1857, current episode: 8
[2023-05-17 14:20:09][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 26500.000000 | iteration_26500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.136497      | 2550.616358         | 2.550616             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 899.401962  | 33.994144  | 947.041138 | 844.278564 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 702.7692, current episode: 1
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 833.7979, current episode: 2
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 845.3682, current episode: 3
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 763.4995, current episode: 4
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 973.0411, current episode: 5
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 923.5441, current episode: 6
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 788.3596, current episode: 7
[2023-05-17 14:20:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 776.7282, current episode: 8
[2023-05-17 14:20:33][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 27000.000000 | iteration_27000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.286952      | 2433.865768         | 2.433866             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 825.888474  | 82.544271  | 973.041138 | 702.769165 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 903.2761, current episode: 1
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 974.2223, current episode: 2
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 884.0679, current episode: 3
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 882.4135, current episode: 4
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 901.7709, current episode: 5
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 861.8346, current episode: 6
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 975.6141, current episode: 7
[2023-05-17 14:20:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 887.2095, current episode: 8
[2023-05-17 14:20:58][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 27500.000000 | iteration_27500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.299512      | 2424.600863         | 2.424601             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 908.801117  | 40.006170  | 975.614136 | 861.834595 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1331.8363, current episode: 1
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1032.2408, current episode: 2
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1284.6636, current episode: 3
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1076.9052, current episode: 4
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1100.3921, current episode: 5
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 613.2432, current episode: 6
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1020.4572, current episode: 7
[2023-05-17 14:21:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1105.9592, current episode: 8
[2023-05-17 14:21:29][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 28000.000000 | iteration_28000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 4.670617      | 1712.835761         | 1.712836             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1070.712196 | 202.918123 | 1331.836304 | 613.243164 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1079.4304, current episode: 1
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 857.8472, current episode: 2
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 955.5312, current episode: 3
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 888.1799, current episode: 4
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 923.2176, current episode: 5
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 921.6042, current episode: 6
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1094.6997, current episode: 7
[2023-05-17 14:21:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 972.4809, current episode: 8
[2023-05-17 14:21:58][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 28500.000000 | iteration_28500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.383200      | 2364.625089         | 2.364625             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 961.623901  | 79.830111  | 1094.699707 | 857.847229 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1228.7402, current episode: 1
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1026.1780, current episode: 2
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1078.2360, current episode: 3
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1116.2439, current episode: 4
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 977.1901, current episode: 5
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1193.8586, current episode: 6
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1165.7157, current episode: 7
[2023-05-17 14:22:22][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1186.3417, current episode: 8
[2023-05-17 14:22:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 29000.000000 | iteration_29000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.194920      | 2503.975011         | 2.503975             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1121.563026 | 82.694250  | 1228.740234 | 977.190125 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 980.1865, current episode: 1
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 923.1776, current episode: 2
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 981.5679, current episode: 3
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1031.7084, current episode: 4
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 919.9493, current episode: 5
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 996.7966, current episode: 6
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 760.3364, current episode: 7
[2023-05-17 14:22:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1091.5739, current episode: 8
[2023-05-17 14:22:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 29500.000000 | iteration_29500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 4.034271      | 1983.010065         | 1.983010             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 960.662071  | 91.857508  | 1091.573853 | 760.336426 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.4411, current episode: 1
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 845.1122, current episode: 2
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 846.1109, current episode: 3
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 869.1191, current episode: 4
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 755.5541, current episode: 5
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 832.4459, current episode: 6
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 990.8749, current episode: 7
[2023-05-17 14:23:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1000.8345, current episode: 8
[2023-05-17 14:23:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 30000.000000 | iteration_30000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 4.913033      | 1628.322054         | 1.628322             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 880.811592  | 77.314526  | 1000.834534 | 755.554077 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 840.2699, current episode: 1
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 837.0751, current episode: 2
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 853.2929, current episode: 3
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 842.4788, current episode: 4
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 858.1097, current episode: 5
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 855.6774, current episode: 6
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 849.6186, current episode: 7
[2023-05-17 14:23:56][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 849.2109, current episode: 8
[2023-05-17 14:23:56][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 30500.000000 | iteration_30500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.837768      | 2084.544933         | 2.084545             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 848.216660  | 7.092827   | 858.109741 | 837.075134 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 927.5030, current episode: 1
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 901.7216, current episode: 2
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 873.4022, current episode: 3
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 923.5084, current episode: 4
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1012.1863, current episode: 5
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 875.8944, current episode: 6
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 879.8203, current episode: 7
[2023-05-17 14:24:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 895.3619, current episode: 8
[2023-05-17 14:24:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 31000.000000 | iteration_31000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.720060      | 2150.503023         | 2.150503             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 911.174774  | 42.743491  | 1012.186340 | 873.402222 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1235.6786, current episode: 1
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1225.3859, current episode: 2
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 846.1179, current episode: 3
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 965.5999, current episode: 4
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1267.3276, current episode: 5
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 986.8187, current episode: 6
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1046.6610, current episode: 7
[2023-05-17 14:24:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 903.0765, current episode: 8
[2023-05-17 14:24:59][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 31500.000000 | iteration_31500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.622374      | 2208.496527         | 2.208497             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1059.583267 | 152.485310 | 1267.327637 | 846.117859 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 927.7098, current episode: 1
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 918.7309, current episode: 2
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 957.8799, current episode: 3
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 872.7064, current episode: 4
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 915.6283, current episode: 5
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 911.9256, current episode: 6
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 943.9543, current episode: 7
[2023-05-17 14:25:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 917.4854, current episode: 8
[2023-05-17 14:25:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 32000.000000 | iteration_32000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.250266      | 2461.337134         | 2.461337             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 920.752579  | 23.432191  | 957.879944 | 872.706360 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:25:46][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 175.7481, current episode: 1
[2023-05-17 14:25:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 129.2825, current episode: 2
[2023-05-17 14:25:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 705.0516, current episode: 3
[2023-05-17 14:25:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 634.3586, current episode: 4
[2023-05-17 14:25:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 744.3666, current episode: 5
[2023-05-17 14:25:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 707.2659, current episode: 6
[2023-05-17 14:25:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 474.7663, current episode: 7
[2023-05-17 14:25:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 514.7110, current episode: 8
[2023-05-17 14:25:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 32500.000000 | iteration_32500.pth.tar | 8.000000      | 7998.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.750000              | 3.169588      | 2523.356277         | 2.523987             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 510.693821  | 225.078223 | 744.366577 | 129.282471 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 989.6558, current episode: 1
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 964.1910, current episode: 2
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 900.4753, current episode: 3
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1014.1383, current episode: 4
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 983.5460, current episode: 5
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 943.6708, current episode: 6
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 883.1995, current episode: 7
[2023-05-17 14:26:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 850.9662, current episode: 8
[2023-05-17 14:26:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 33000.000000 | iteration_33000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.586611      | 2230.517870         | 2.230518             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 941.230362  | 53.805817  | 1014.138306 | 850.966187 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 932.9872, current episode: 1
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 888.3433, current episode: 2
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 960.2228, current episode: 3
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 927.7910, current episode: 4
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 909.3558, current episode: 5
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.7578, current episode: 6
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 923.5098, current episode: 7
[2023-05-17 14:26:40][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 819.3369, current episode: 8
[2023-05-17 14:26:40][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 33500.000000 | iteration_33500.pth.tar | 8.000000      | 7999.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.875000              | 3.396646      | 2354.970152         | 2.355265             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 915.038063  | 42.445943  | 960.222778 | 819.336914 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.8911, current episode: 1
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 994.7016, current episode: 2
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 825.3826, current episode: 3
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 768.2015, current episode: 4
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1103.1943, current episode: 5
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 935.9515, current episode: 6
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 597.6377, current episode: 7
[2023-05-17 14:27:07][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 659.9705, current episode: 8
[2023-05-17 14:27:07][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 34000.000000 | iteration_34000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.436226      | 2328.135812         | 2.328136             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 860.991356  | 166.559942 | 1103.194336 | 597.637695 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 904.5719, current episode: 1
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 839.3299, current episode: 2
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1017.4717, current episode: 3
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 962.8600, current episode: 4
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1018.8661, current episode: 5
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 923.5594, current episode: 6
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 983.6337, current episode: 7
[2023-05-17 14:27:32][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 949.8555, current episode: 8
[2023-05-17 14:27:32][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 34500.000000 | iteration_34500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.292719      | 2429.603095         | 2.429603             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 950.018532  | 56.571078  | 1018.866150 | 839.329895 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 836.3497, current episode: 1
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 823.5836, current episode: 2
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 846.0399, current episode: 3
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 827.1932, current episode: 4
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 823.5531, current episode: 5
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 821.9750, current episode: 6
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 814.7189, current episode: 7
[2023-05-17 14:27:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 858.1946, current episode: 8
[2023-05-17 14:27:58][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 35000.000000 | iteration_35000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.647060      | 2193.547729         | 2.193548             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 831.450996  | 13.528744  | 858.194641 | 814.718872 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 892.9342, current episode: 1
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 940.7558, current episode: 2
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 931.5402, current episode: 3
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 592.5206, current episode: 4
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 922.6075, current episode: 5
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 707.4800, current episode: 6
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 932.6557, current episode: 7
[2023-05-17 14:28:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 590.1042, current episode: 8
[2023-05-17 14:28:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 35500.000000 | iteration_35500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.214436      | 2488.772298         | 2.488772             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 813.824783  | 146.848905 | 940.755798 | 590.104248 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 901.5565, current episode: 1
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 898.4077, current episode: 2
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 899.7558, current episode: 3
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 894.3498, current episode: 4
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 892.5651, current episode: 5
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 906.5215, current episode: 6
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 901.2469, current episode: 7
[2023-05-17 14:28:48][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 892.4077, current episode: 8
[2023-05-17 14:28:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 36000.000000 | iteration_36000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.111118      | 2571.423010         | 2.571423             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 898.351372  | 4.639563   | 906.521484 | 892.407654 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1083.1428, current episode: 1
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1077.7374, current episode: 2
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1127.1333, current episode: 3
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1166.3070, current episode: 4
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 985.2898, current episode: 5
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1010.8354, current episode: 6
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 977.8948, current episode: 7
[2023-05-17 14:29:12][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1050.1207, current episode: 8
[2023-05-17 14:29:12][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 36500.000000 | iteration_36500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.119044      | 2564.888418         | 2.564888             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1059.807663 | 62.745121  | 1166.307007 | 977.894836 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1064.7988, current episode: 1
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1006.7397, current episode: 2
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 977.3579, current episode: 3
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1083.4872, current episode: 4
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 954.6284, current episode: 5
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.2002, current episode: 6
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1019.1532, current episode: 7
[2023-05-17 14:29:36][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1097.5886, current episode: 8
[2023-05-17 14:29:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 37000.000000 | iteration_37000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.208386      | 2493.465790         | 2.493466             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1034.119255 | 48.928173  | 1097.588623 | 954.628418 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:29:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 307.3527, current episode: 1
[2023-05-17 14:29:58][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 349.8504, current episode: 2
[2023-05-17 14:30:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1103.2666, current episode: 3
[2023-05-17 14:30:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1055.0323, current episode: 4
[2023-05-17 14:30:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1210.0414, current episode: 5
[2023-05-17 14:30:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 887.0839, current episode: 6
[2023-05-17 14:30:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1048.5819, current episode: 7
[2023-05-17 14:30:01][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1095.5732, current episode: 8
[2023-05-17 14:30:01][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 37500.000000 | iteration_37500.pth.tar | 8.000000      | 7998.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.750000              | 3.463326      | 2309.340805         | 2.309918             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 882.097805  | 330.397830 | 1210.041382 | 307.352661 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 938.7694, current episode: 1
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 853.6469, current episode: 2
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 938.6281, current episode: 3
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 879.6859, current episode: 4
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 691.2722, current episode: 5
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 836.8362, current episode: 6
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1027.5845, current episode: 7
[2023-05-17 14:30:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 931.0170, current episode: 8
[2023-05-17 14:30:26][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 38000.000000 | iteration_38000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.189754      | 2508.030205         | 2.508030             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 887.180031  | 92.896753  | 1027.584473 | 691.272217 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 970.3599, current episode: 1
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 801.1561, current episode: 2
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1305.8146, current episode: 3
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 767.9135, current episode: 4
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 728.9949, current episode: 5
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1273.4337, current episode: 6
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 883.3502, current episode: 7
[2023-05-17 14:30:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 928.4563, current episode: 8
[2023-05-17 14:30:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 38500.000000 | iteration_38500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.089005      | 2589.830512         | 2.589831             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 957.434906  | 206.229615 | 1305.814575 | 728.994934 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 924.5849, current episode: 1
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 925.8320, current episode: 2
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 935.8923, current episode: 3
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 903.8234, current episode: 4
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 879.8785, current episode: 5
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 930.2278, current episode: 6
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 919.0853, current episode: 7
[2023-05-17 14:31:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 922.5229, current episode: 8
[2023-05-17 14:31:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 39000.000000 | iteration_39000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.191895      | 2506.348103         | 2.506348             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 917.730865  | 16.769149  | 935.892273 | 879.878479 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1088.1750, current episode: 1
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 941.4257, current episode: 2
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1181.7660, current episode: 3
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 855.2706, current episode: 4
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1006.3233, current episode: 5
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1037.8861, current episode: 6
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1041.9974, current episode: 7
[2023-05-17 14:31:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 835.0524, current episode: 8
[2023-05-17 14:31:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 39500.000000 | iteration_39500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.263310      | 2451.498486         | 2.451498             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 998.487061  | 109.327382 | 1181.765991 | 835.052368 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 990.8080, current episode: 1
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 912.6987, current episode: 2
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 893.4639, current episode: 3
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 959.9562, current episode: 4
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 847.8474, current episode: 5
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 837.5381, current episode: 6
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 881.4680, current episode: 7
[2023-05-17 14:32:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 887.3948, current episode: 8
[2023-05-17 14:32:03][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 40000.000000 | iteration_40000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.115416      | 2567.875324         | 2.567875             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 901.396881  | 48.929688  | 990.807983 | 837.538147 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:32:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 474.7734, current episode: 1
[2023-05-17 14:32:26][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 502.2280, current episode: 2
[2023-05-17 14:32:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 782.6774, current episode: 3
[2023-05-17 14:32:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 732.2839, current episode: 4
[2023-05-17 14:32:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 851.4849, current episode: 5
[2023-05-17 14:32:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 867.9739, current episode: 6
[2023-05-17 14:32:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 865.1664, current episode: 7
[2023-05-17 14:32:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 781.2768, current episode: 8
[2023-05-17 14:32:27][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 40500.000000 | iteration_40500.pth.tar | 8.000000      | 7999.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.875000              | 3.063581      | 2610.996747         | 2.611323             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 732.233089  | 147.671746 | 867.973877 | 474.773438 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 566.9344, current episode: 1
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 682.8994, current episode: 2
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 674.8494, current episode: 3
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 643.7602, current episode: 4
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 709.1832, current episode: 5
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 532.7177, current episode: 6
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 786.5797, current episode: 7
[2023-05-17 14:32:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 649.2245, current episode: 8
[2023-05-17 14:32:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 41000.000000 | iteration_41000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.218751      | 2485.436157         | 2.485436             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 655.768555  | 74.401674  | 786.579651 | 532.717651 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 933.6821, current episode: 1
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 976.2808, current episode: 2
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 790.7653, current episode: 3
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 925.0616, current episode: 4
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 843.6465, current episode: 5
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 968.7644, current episode: 6
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 961.5617, current episode: 7
[2023-05-17 14:33:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 917.0037, current episode: 8
[2023-05-17 14:33:16][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 41500.000000 | iteration_41500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.674254      | 2177.312904         | 2.177313             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 914.595764  | 61.025089  | 976.280823 | 790.765259 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 827.7208, current episode: 1
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 832.0684, current episode: 2
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 829.4138, current episode: 3
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 831.6050, current episode: 4
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 829.7292, current episode: 5
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 830.5646, current episode: 6
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 847.0084, current episode: 7
[2023-05-17 14:33:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 826.6046, current episode: 8
[2023-05-17 14:33:42][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 42000.000000 | iteration_42000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.393751      | 2357.273607         | 2.357274             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 831.839340  | 5.984716   | 847.008423 | 826.604553 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 920.8325, current episode: 1
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 962.4109, current episode: 2
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 914.0068, current episode: 3
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 996.1815, current episode: 4
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 853.9323, current episode: 5
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 899.9886, current episode: 6
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 940.7291, current episode: 7
[2023-05-17 14:34:08][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 870.5120, current episode: 8
[2023-05-17 14:34:08][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 42500.000000 | iteration_42500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.239633      | 2469.415635         | 2.469416             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 919.824211  | 43.707586  | 996.181519 | 853.932312 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 840.0032, current episode: 1
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 836.7601, current episode: 2
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 838.6622, current episode: 3
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 840.6718, current episode: 4
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 838.4299, current episode: 5
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 838.1351, current episode: 6
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 836.7662, current episode: 7
[2023-05-17 14:34:33][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 840.1952, current episode: 8
[2023-05-17 14:34:33][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 43000.000000 | iteration_43000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.400368      | 2352.686385         | 2.352686             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 838.702972  | 1.401688   | 840.671814 | 836.760132 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 987.9669, current episode: 1
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 992.5823, current episode: 2
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 965.1965, current episode: 3
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 971.2929, current episode: 4
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 933.3730, current episode: 5
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 869.9319, current episode: 6
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 888.7125, current episode: 7
[2023-05-17 14:34:59][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 934.2513, current episode: 8
[2023-05-17 14:34:59][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 43500.000000 | iteration_43500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.303180      | 2421.908600         | 2.421909             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 942.913414  | 42.173500  | 992.582275 | 869.931885 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 893.7685, current episode: 1
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 925.2005, current episode: 2
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 813.9597, current episode: 3
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 854.3932, current episode: 4
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 950.1557, current episode: 5
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 929.3781, current episode: 6
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 833.0002, current episode: 7
[2023-05-17 14:35:24][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 898.0887, current episode: 8
[2023-05-17 14:35:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 44000.000000 | iteration_44000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.385962      | 2362.696326         | 2.362696             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 887.243073  | 45.724984  | 950.155701 | 813.959656 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 702.5166, current episode: 1
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 677.7562, current episode: 2
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 664.6456, current episode: 3
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 619.5471, current episode: 4
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 664.2593, current episode: 5
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 605.6755, current episode: 6
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 639.9252, current episode: 7
[2023-05-17 14:35:50][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 651.6940, current episode: 8
[2023-05-17 14:35:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 44500.000000 | iteration_44500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.423873      | 2336.535299         | 2.336535             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 653.252434  | 29.278857  | 702.516602 | 605.675476 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 739.6917, current episode: 1
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1055.7954, current episode: 2
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 759.0791, current episode: 3
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 822.2432, current episode: 4
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 891.3383, current episode: 5
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 939.0226, current episode: 6
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 947.3401, current episode: 7
[2023-05-17 14:36:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 925.4039, current episode: 8
[2023-05-17 14:36:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 45000.000000 | iteration_45000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.110796      | 2571.689068         | 2.571689             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 884.989281  | 99.094305  | 1055.795410 | 739.691650 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 890.4254, current episode: 1
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 950.6919, current episode: 2
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 854.3458, current episode: 3
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 944.1284, current episode: 4
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 910.8726, current episode: 5
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 932.5349, current episode: 6
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 928.7502, current episode: 7
[2023-05-17 14:36:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 902.4690, current episode: 8
[2023-05-17 14:36:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 45500.000000 | iteration_45500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.237297      | 2471.197377         | 2.471197             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 914.277260  | 29.731392  | 950.691895 | 854.345764 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 950.7771, current episode: 1
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 974.5391, current episode: 2
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 851.4278, current episode: 3
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 978.1420, current episode: 4
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 980.6046, current episode: 5
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 997.7620, current episode: 6
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 977.5179, current episode: 7
[2023-05-17 14:37:02][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 982.8043, current episode: 8
[2023-05-17 14:37:02][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 46000.000000 | iteration_46000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.047705      | 2624.925819         | 2.624926             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 961.696846  | 43.399160  | 997.761963 | 851.427795 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 870.5212, current episode: 1
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 877.3655, current episode: 2
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 881.7872, current episode: 3
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 839.9288, current episode: 4
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 900.2410, current episode: 5
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 865.5065, current episode: 6
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 883.1331, current episode: 7
[2023-05-17 14:37:25][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 908.8904, current episode: 8
[2023-05-17 14:37:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 46500.000000 | iteration_46500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.083755      | 2594.239801         | 2.594240             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 878.421730  | 19.843086  | 908.890381 | 839.928833 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1040.3313, current episode: 1
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1026.6381, current episode: 2
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1036.1604, current episode: 3
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1001.3882, current episode: 4
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1106.2412, current episode: 5
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1129.4684, current episode: 6
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 888.4960, current episode: 7
[2023-05-17 14:37:49][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 841.8844, current episode: 8
[2023-05-17 14:37:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 47000.000000 | iteration_47000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.054742      | 2618.879227         | 2.618879             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1008.825989 | 92.537469  | 1129.468384 | 841.884399 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 980.7313, current episode: 1
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 971.4951, current episode: 2
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 946.0348, current episode: 3
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 942.5606, current episode: 4
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 947.6927, current episode: 5
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1001.6631, current episode: 6
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 942.8093, current episode: 7
[2023-05-17 14:38:13][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 966.0095, current episode: 8
[2023-05-17 14:38:13][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 47500.000000 | iteration_47500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.320209      | 2409.486681         | 2.409487             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 962.374550  | 20.108764  | 1001.663147 | 942.560608 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1029.0050, current episode: 1
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1197.3007, current episode: 2
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1250.1334, current episode: 3
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1195.4851, current episode: 4
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1027.2736, current episode: 5
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1090.3901, current episode: 6
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1122.5135, current episode: 7
[2023-05-17 14:38:38][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1121.5818, current episode: 8
[2023-05-17 14:38:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 48000.000000 | iteration_48000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.329476      | 2402.780584         | 2.402781             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1129.210403 | 75.575537  | 1250.133423 | 1027.273560 |
+-------+-------------+------------+-------------+-------------+


[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1199.6639, current episode: 1
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1200.0524, current episode: 2
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1169.8055, current episode: 3
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1140.9331, current episode: 4
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1072.3295, current episode: 5
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1121.0217, current episode: 6
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 999.9966, current episode: 7
[2023-05-17 14:39:03][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1132.1473, current episode: 8
[2023-05-17 14:39:03][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 48500.000000 | iteration_48500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.183113      | 2513.263071         | 2.513263             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1129.493767 | 63.022165  | 1200.052368 | 999.996643 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 721.0780, current episode: 1
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 820.9031, current episode: 2
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 803.8764, current episode: 3
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 892.3565, current episode: 4
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 874.4845, current episode: 5
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 840.3289, current episode: 6
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 912.6974, current episode: 7
[2023-05-17 14:39:27][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 812.0858, current episode: 8
[2023-05-17 14:39:27][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 49000.000000 | iteration_49000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.091385      | 2587.836937         | 2.587837             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 834.726334  | 56.551046  | 912.697449 | 721.078003 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.0709, current episode: 1
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 956.8986, current episode: 2
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 959.1970, current episode: 3
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 952.5581, current episode: 4
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 889.7834, current episode: 5
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 952.5538, current episode: 6
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 940.0659, current episode: 7
[2023-05-17 14:39:51][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 880.1253, current episode: 8
[2023-05-17 14:39:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 49500.000000 | iteration_49500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.156988      | 2534.061023         | 2.534061             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 941.656624  | 36.923787  | 1002.070923 | 880.125305 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 904.4138, current episode: 1
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 919.2128, current episode: 2
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 916.1849, current episode: 3
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 913.9482, current episode: 4
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 919.4008, current episode: 5
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 918.5449, current episode: 6
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 921.1540, current episode: 7
[2023-05-17 14:40:16][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 929.2735, current episode: 8
[2023-05-17 14:40:16][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 50000.000000 | iteration_50000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.154089      | 2536.390085         | 2.536390             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 917.766609  | 6.563448   | 929.273499 | 904.413757 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1089.3385, current episode: 1
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 983.2692, current episode: 2
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1019.9427, current episode: 3
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1065.1349, current episode: 4
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 944.3705, current episode: 5
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 914.7977, current episode: 6
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1001.9448, current episode: 7
[2023-05-17 14:40:39][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 1019.0253, current episode: 8
[2023-05-17 14:40:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 50500.000000 | iteration_50500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.265746      | 2449.670090         | 2.449670             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1004.727951 | 54.132405  | 1089.338501 | 914.797729 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.4384, current episode: 1
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 922.9604, current episode: 2
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 931.5984, current episode: 3
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 907.2744, current episode: 4
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 979.8787, current episode: 5
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 939.4105, current episode: 6
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 932.3559, current episode: 7
[2023-05-17 14:41:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 910.6460, current episode: 8
[2023-05-17 14:41:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 51000.000000 | iteration_51000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.261495      | 2452.862968         | 2.452863             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 938.445343  | 26.949503  | 983.438416 | 907.274353 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 865.9282, current episode: 1
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 850.0213, current episode: 2
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 842.9237, current episode: 3
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 985.0538, current episode: 4
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 899.1683, current episode: 5
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 990.8740, current episode: 6
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1060.1196, current episode: 7
[2023-05-17 14:41:29][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 920.7311, current episode: 8
[2023-05-17 14:41:29][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 51500.000000 | iteration_51500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.225290      | 2480.397065         | 2.480397             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 926.852509  | 73.065909  | 1060.119629 | 842.923706 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 678.2999, current episode: 1
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 1201.1106, current episode: 2
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 805.4029, current episode: 3
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.6981, current episode: 4
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 689.5856, current episode: 5
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1051.4629, current episode: 6
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 1099.2690, current episode: 7
[2023-05-17 14:41:54][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 822.1937, current episode: 8
[2023-05-17 14:41:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 52000.000000 | iteration_52000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.288847      | 2432.463436         | 2.432463             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 940.502846  | 201.612977 | 1201.110596 | 678.299866 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 998.3033, current episode: 1
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 976.0905, current episode: 2
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1044.9425, current episode: 3
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 950.3062, current episode: 4
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1020.9976, current episode: 5
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1010.0985, current episode: 6
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 984.8107, current episode: 7
[2023-05-17 14:42:18][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 807.1943, current episode: 8
[2023-05-17 14:42:18][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 52500.000000 | iteration_52500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.118036      | 2565.717624         | 2.565718             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 974.092957  | 68.594886  | 1044.942505 | 807.194336 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 954.5235, current episode: 1
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 911.8447, current episode: 2
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 828.0742, current episode: 3
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 855.3931, current episode: 4
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 785.7987, current episode: 5
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 831.3757, current episode: 6
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 826.8013, current episode: 7
[2023-05-17 14:42:42][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 900.0358, current episode: 8
[2023-05-17 14:42:42][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 53000.000000 | iteration_53000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.012869      | 2655.276310         | 2.655276             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 861.730873  | 52.044774  | 954.523499 | 785.798706 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 992.9777, current episode: 1
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 977.8094, current episode: 2
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1048.4342, current episode: 3
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 993.8492, current episode: 4
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 997.2766, current episode: 5
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1000.3270, current episode: 6
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 994.8517, current episode: 7
[2023-05-17 14:43:05][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 979.3545, current episode: 8
[2023-05-17 14:43:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 53500.000000 | iteration_53500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.139623      | 2548.076692         | 2.548077             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 998.110046  | 20.485148  | 1048.434204 | 977.809387 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.4926, current episode: 1
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 911.2070, current episode: 2
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 910.2411, current episode: 3
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 905.5253, current episode: 4
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 909.2239, current episode: 5
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 899.7670, current episode: 6
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 904.9995, current episode: 7
[2023-05-17 14:43:30][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 907.7124, current episode: 8
[2023-05-17 14:43:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 54000.000000 | iteration_54000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.373771      | 2371.233884         | 2.371234             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 906.896103  | 3.397079   | 911.207031 | 899.767029 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 879.5782, current episode: 1
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 923.9231, current episode: 2
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 953.3573, current episode: 3
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 942.1288, current episode: 4
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 930.4119, current episode: 5
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 926.9212, current episode: 6
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 887.8049, current episode: 7
[2023-05-17 14:43:55][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 904.4565, current episode: 8
[2023-05-17 14:43:55][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 54500.000000 | iteration_54500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.109412      | 2572.833546         | 2.572834             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 918.572739  | 24.160533  | 953.357300 | 879.578186 |
+-------+-------------+------------+------------+------------+


[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 1170.9181, current episode: 1
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 896.7435, current episode: 2
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 1126.3925, current episode: 3
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 905.2311, current episode: 4
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 1097.6936, current episode: 5
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 874.5022, current episode: 6
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 845.3552, current episode: 7
[2023-05-17 14:44:21][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 826.5485, current episode: 8
[2023-05-17 14:44:21][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 55000.000000 | iteration_55000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.472678      | 2303.697485         | 2.303697             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 967.923080  | 130.333151 | 1170.918091 | 826.548523 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 909.4825, current episode: 1
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 873.6272, current episode: 2
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 892.3522, current episode: 3
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 963.7194, current episode: 4
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 822.2366, current episode: 5
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 1272.1841, current episode: 6
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 874.6875, current episode: 7
[2023-05-17 14:44:47][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 940.2834, current episode: 8
[2023-05-17 14:44:47][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 55500.000000 | iteration_55500.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.547719      | 2254.970023         | 2.254970             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 943.571602  | 130.646383 | 1272.184082 | 822.236633 |
+-------+-------------+------------+-------------+------------+


[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.9686, current episode: 1
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 1 finish episode, final reward: 980.1783, current episode: 2
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 2 finish episode, final reward: 979.6606, current episode: 3
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 3 finish episode, final reward: 976.4865, current episode: 4
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 4 finish episode, final reward: 975.1423, current episode: 5
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 5 finish episode, final reward: 968.1263, current episode: 6
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 6 finish episode, final reward: 996.4719, current episode: 7
[2023-05-17 14:45:14][interaction_serial_evaluator.py:255][INFO] [EVALUATOR]env 7 finish episode, final reward: 975.7040, current episode: 8
[2023-05-17 14:45:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 56000.000000 | iteration_56000.pth.tar | 8.000000      | 8000.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 3.568237      | 2242.003502         | 2.242004             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 979.467308  | 7.748648   | 996.471924 | 968.126343 |
+-------+-------------+------------+------------+------------+


