[2023-04-11 20:30:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 27
envstep_count: 6892
train_sample_count: 6892
avg_envstep_per_episode: 255.25925925925927
avg_sample_per_episode: 255.25925925925927
avg_envstep_per_sec: 1311.3750973138208
avg_train_sample_per_sec: 1311.3750973138208
avg_episode_per_sec: 5.137424205959542
collect_time: 5.255551988227742
reward_mean: -20.703703703703702
reward_std: 0.5972042776517444
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 9077
total_train_sample_count: 6892
total_episode_count: 27
total_duration: 5.255551988227742
[2023-04-11 20:30:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3368
train_sample_count: 3368
avg_envstep_per_episode: 224.53333333333333
avg_sample_per_episode: 224.53333333333333
avg_envstep_per_sec: 1339.2019054283257
avg_train_sample_per_sec: 1339.2019054283257
avg_episode_per_sec: 5.964379032489575
collect_time: 2.5149307108570684
reward_mean: -20.4
reward_std: 0.7999999999999999
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 13299
total_train_sample_count: 10260
total_episode_count: 42
total_duration: 7.770482699084811
[2023-04-11 20:30:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 231.07142857142858
avg_sample_per_episode: 231.07142857142858
avg_envstep_per_sec: 1275.2885564816993
avg_train_sample_per_sec: 1275.2885564816993
avg_episode_per_sec: 5.519023119240739
collect_time: 2.5366808033821036
reward_mean: -20.714285714285715
reward_std: 0.4517539514526256
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 17384
total_train_sample_count: 13495
total_episode_count: 56
total_duration: 10.307163502466913
[2023-04-11 20:30:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3427
train_sample_count: 3427
avg_envstep_per_episode: 244.78571428571428
avg_sample_per_episode: 244.78571428571428
avg_envstep_per_sec: 1371.7065259696435
avg_train_sample_per_sec: 1371.7065259696435
avg_episode_per_sec: 5.60370334507587
collect_time: 2.4983478135583654
reward_mean: -20.5
reward_std: 0.6267831705280087
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 22014
total_train_sample_count: 16922
total_episode_count: 70
total_duration: 12.805511316025278
[2023-04-11 20:30:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3353
train_sample_count: 3353
avg_envstep_per_episode: 223.53333333333333
avg_sample_per_episode: 223.53333333333333
avg_envstep_per_sec: 1250.150227957906
avg_train_sample_per_sec: 1250.150227957906
avg_episode_per_sec: 5.592679218421888
collect_time: 2.682077661559967
reward_mean: -20.4
reward_std: 0.8
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 26312
total_train_sample_count: 20275
total_episode_count: 85
total_duration: 15.487588977585245
[2023-04-11 20:30:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3421
train_sample_count: 3421
avg_envstep_per_episode: 228.06666666666666
avg_sample_per_episode: 228.06666666666666
avg_envstep_per_sec: 1287.8721715459603
avg_train_sample_per_sec: 1287.8721715459603
avg_episode_per_sec: 5.6469110123324775
collect_time: 2.656319528896595
reward_mean: -20.666666666666668
reward_std: 0.4714045207910317
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 30648
total_train_sample_count: 23696
total_episode_count: 100
total_duration: 18.14390850648184
[2023-04-11 20:30:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3514
train_sample_count: 3514
avg_envstep_per_episode: 234.26666666666668
avg_sample_per_episode: 234.26666666666668
avg_envstep_per_sec: 1277.0503103626609
avg_train_sample_per_sec: 1277.0503103626609
avg_episode_per_sec: 5.451267687945337
collect_time: 2.75165353430914
reward_mean: -20.466666666666665
reward_std: 0.618241233033047
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 34941
total_train_sample_count: 27210
total_episode_count: 115
total_duration: 20.895562040790978
[2023-04-11 20:31:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 229.21428571428572
avg_sample_per_episode: 229.21428571428572
avg_envstep_per_sec: 1379.8778418804402
avg_train_sample_per_sec: 1379.8778418804402
avg_episode_per_sec: 6.02003421200566
collect_time: 2.325568179011345
reward_mean: -20.642857142857142
reward_std: 0.6102859818083951
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 39241
total_train_sample_count: 30419
total_episode_count: 129
total_duration: 23.221130219802323
[2023-04-11 20:31:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3443
train_sample_count: 3443
avg_envstep_per_episode: 229.53333333333333
avg_sample_per_episode: 229.53333333333333
avg_envstep_per_sec: 1258.8158131335792
avg_train_sample_per_sec: 1258.8158131335792
avg_episode_per_sec: 5.484239673832033
collect_time: 2.735110223495934
reward_mean: -20.466666666666665
reward_std: 0.7180219742846006
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 43738
total_train_sample_count: 33862
total_episode_count: 144
total_duration: 25.956240443298256
[2023-04-11 20:31:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3519
train_sample_count: 3519
avg_envstep_per_episode: 234.6
avg_sample_per_episode: 234.6
avg_envstep_per_sec: 1335.1322498035372
avg_train_sample_per_sec: 1335.1322498035372
avg_episode_per_sec: 5.691100809051736
collect_time: 2.635693955050382
reward_mean: -20.333333333333332
reward_std: 0.8692269873603533
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 48516
total_train_sample_count: 37381
total_episode_count: 159
total_duration: 28.591934398348638
[2023-04-11 20:31:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 215.53333333333333
avg_sample_per_episode: 215.53333333333333
avg_envstep_per_sec: 1320.4802816511728
avg_train_sample_per_sec: 1320.4802816511728
avg_episode_per_sec: 6.126571056222578
collect_time: 2.4483515921626244
reward_mean: -20.133333333333333
reward_std: 0.9568466729604881
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 52681
total_train_sample_count: 40614
total_episode_count: 174
total_duration: 31.04028599051126
[2023-04-11 20:31:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3475
train_sample_count: 3475
avg_envstep_per_episode: 231.66666666666666
avg_sample_per_episode: 231.66666666666666
avg_envstep_per_sec: 1292.7421814453935
avg_train_sample_per_sec: 1292.7421814453935
avg_episode_per_sec: 5.580182078181555
collect_time: 2.688084329479108
reward_mean: -20.733333333333334
reward_std: 0.4422166387140533
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 56929
total_train_sample_count: 44089
total_episode_count: 189
total_duration: 33.72837031999037
[2023-04-11 20:31:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3424
train_sample_count: 3424
avg_envstep_per_episode: 244.57142857142858
avg_sample_per_episode: 244.57142857142858
avg_envstep_per_sec: 1334.8385906279293
avg_train_sample_per_sec: 1334.8385906279293
avg_episode_per_sec: 5.457868069156253
collect_time: 2.565104143707215
reward_mean: -20.714285714285715
reward_std: 0.5890150893739514
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 61068
total_train_sample_count: 47513
total_episode_count: 203
total_duration: 36.293474463697585
[2023-04-11 20:31:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3407
train_sample_count: 3407
avg_envstep_per_episode: 243.35714285714286
avg_sample_per_episode: 243.35714285714286
avg_envstep_per_sec: 1286.6328674384488
avg_train_sample_per_sec: 1286.6328674384488
avg_episode_per_sec: 5.287015011487608
collect_time: 2.6479970209240653
reward_mean: -20.642857142857142
reward_std: 0.4791574237499549
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 65373
total_train_sample_count: 50920
total_episode_count: 217
total_duration: 38.94147148462165
[2023-04-11 20:31:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3450
train_sample_count: 3450
avg_envstep_per_episode: 246.42857142857142
avg_sample_per_episode: 246.42857142857142
avg_envstep_per_sec: 1357.0568272342493
avg_train_sample_per_sec: 1357.0568272342493
avg_episode_per_sec: 5.5068972699360845
collect_time: 2.542266418593004
reward_mean: -20.285714285714285
reward_std: 0.8806305718527109
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 69992
total_train_sample_count: 54370
total_episode_count: 231
total_duration: 41.48373790321465
[2023-04-11 20:32:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3410
train_sample_count: 3410
avg_envstep_per_episode: 227.33333333333334
avg_sample_per_episode: 227.33333333333334
avg_envstep_per_sec: 1299.365349611368
avg_train_sample_per_sec: 1299.365349611368
avg_episode_per_sec: 5.715683356061736
collect_time: 2.6243581153059914
reward_mean: -20.733333333333334
reward_std: 0.5734883511361751
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 74168
total_train_sample_count: 57780
total_episode_count: 246
total_duration: 44.10809601852064
[2023-04-11 20:32:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3359
train_sample_count: 3359
avg_envstep_per_episode: 239.92857142857142
avg_sample_per_episode: 239.92857142857142
avg_envstep_per_sec: 1298.1260531035791
avg_train_sample_per_sec: 1298.1260531035791
avg_episode_per_sec: 5.410468813173596
collect_time: 2.5875761386725524
reward_mean: -20.571428571428573
reward_std: 0.82065180664829
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 78666
total_train_sample_count: 61139
total_episode_count: 260
total_duration: 46.695672157193194
[2023-04-11 20:32:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3341
train_sample_count: 3341
avg_envstep_per_episode: 238.64285714285714
avg_sample_per_episode: 238.64285714285714
avg_envstep_per_sec: 1345.8443116046149
avg_train_sample_per_sec: 1345.8443116046149
avg_episode_per_sec: 5.639575086041487
collect_time: 2.4824565302182786
reward_mean: -20.142857142857142
reward_std: 0.6388765649999399
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 83390
total_train_sample_count: 64480
total_episode_count: 274
total_duration: 49.17812868741147
[2023-04-11 20:32:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 2878
train_sample_count: 2878
avg_envstep_per_episode: 205.57142857142858
avg_sample_per_episode: 205.57142857142858
avg_envstep_per_sec: 1323.1094757090934
avg_train_sample_per_sec: 1323.1094757090934
avg_episode_per_sec: 6.436251792886487
collect_time: 2.17517904061385
reward_mean: -20.5
reward_std: 0.7319250547113999
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 87597
total_train_sample_count: 67758
total_episode_count: 288
total_duration: 51.35330772802532
[2023-04-11 20:32:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3259
train_sample_count: 3259
avg_envstep_per_episode: 232.78571428571428
avg_sample_per_episode: 232.78571428571428
avg_envstep_per_sec: 1337.8295016066434
avg_train_sample_per_sec: 1337.8295016066434
avg_episode_per_sec: 5.747042964864377
collect_time: 2.436035381254607
reward_mean: -19.857142857142858
reward_std: 0.832993127835043
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 92005
total_train_sample_count: 71017
total_episode_count: 302
total_duration: 53.789343109279926
[2023-04-11 20:32:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 16
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 213.375
avg_sample_per_episode: 213.375
avg_envstep_per_sec: 1316.236780227091
avg_train_sample_per_sec: 1316.236780227091
avg_episode_per_sec: 6.168655091866858
collect_time: 2.5937582441747153
reward_mean: -20.875
reward_std: 0.33071891388307384
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 96398
total_train_sample_count: 74431
total_episode_count: 318
total_duration: 56.38310135345464
[2023-04-11 20:32:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3308
train_sample_count: 3308
avg_envstep_per_episode: 236.28571428571428
avg_sample_per_episode: 236.28571428571428
avg_envstep_per_sec: 1290.592962754506
avg_train_sample_per_sec: 1290.592962754506
avg_episode_per_sec: 5.462001656155708
collect_time: 2.5631628991217745
reward_mean: -20.5
reward_std: 0.7319250547113999
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 101075
total_train_sample_count: 77739
total_episode_count: 332
total_duration: 58.94626425257641
[2023-04-11 20:32:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 16
envstep_count: 3425
train_sample_count: 3425
avg_envstep_per_episode: 214.0625
avg_sample_per_episode: 214.0625
avg_envstep_per_sec: 1396.0482669561065
avg_train_sample_per_sec: 1396.0482669561065
avg_episode_per_sec: 6.521685334685461
collect_time: 2.453353570265695
reward_mean: -20.6875
reward_std: 0.46351240544347894
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 105574
total_train_sample_count: 81164
total_episode_count: 348
total_duration: 61.39961782284211
[2023-04-11 20:32:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3485
train_sample_count: 3485
avg_envstep_per_episode: 232.33333333333334
avg_sample_per_episode: 232.33333333333334
avg_envstep_per_sec: 1323.1438650388852
avg_train_sample_per_sec: 1323.1438650388852
avg_episode_per_sec: 5.6950238093495775
collect_time: 2.6338783650692292
reward_mean: -20.6
reward_std: 0.6110100926607788
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 110084
total_train_sample_count: 84649
total_episode_count: 363
total_duration: 64.03349618791134
[2023-04-11 20:33:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3490
train_sample_count: 3490
avg_envstep_per_episode: 232.66666666666666
avg_sample_per_episode: 232.66666666666666
avg_envstep_per_sec: 1377.5018272125017
avg_train_sample_per_sec: 1377.5018272125017
avg_episode_per_sec: 5.920494959366053
collect_time: 2.533571956897021
reward_mean: -20.8
reward_std: 0.4
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 114489
total_train_sample_count: 88139
total_episode_count: 378
total_duration: 66.56706814480836
[2023-04-11 20:33:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3469
train_sample_count: 3469
avg_envstep_per_episode: 247.78571428571428
avg_sample_per_episode: 247.78571428571428
avg_envstep_per_sec: 1254.3724399547789
avg_train_sample_per_sec: 1254.3724399547789
avg_episode_per_sec: 5.062327517834219
collect_time: 2.765526321771754
reward_mean: -20.5
reward_std: 0.6267831705280087
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 119145
total_train_sample_count: 91608
total_episode_count: 392
total_duration: 69.33259446658012
[2023-04-11 20:33:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3260
train_sample_count: 3260
avg_envstep_per_episode: 232.85714285714286
avg_sample_per_episode: 232.85714285714286
avg_envstep_per_sec: 1409.9784597915102
avg_train_sample_per_sec: 1409.9784597915102
avg_episode_per_sec: 6.055122219963541
collect_time: 2.3120920588262375
reward_mean: -20.428571428571427
reward_std: 0.8206518066482897
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 123300
total_train_sample_count: 94868
total_episode_count: 406
total_duration: 71.64468652540636
[2023-04-11 20:33:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 3285
train_sample_count: 3285
avg_envstep_per_episode: 252.69230769230768
avg_sample_per_episode: 252.69230769230768
avg_envstep_per_sec: 1287.353409890072
avg_train_sample_per_sec: 1287.353409890072
avg_episode_per_sec: 5.094549262883086
collect_time: 2.5517468433788575
reward_mean: -20.46153846153846
reward_std: 0.9294650748918901
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 127592
total_train_sample_count: 98153
total_episode_count: 419
total_duration: 74.19643336878521
[2023-04-11 20:33:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3336
train_sample_count: 3336
avg_envstep_per_episode: 238.28571428571428
avg_sample_per_episode: 238.28571428571428
avg_envstep_per_sec: 1276.747995072945
avg_train_sample_per_sec: 1276.747995072945
avg_episode_per_sec: 5.35805513519821
collect_time: 2.612888379597105
reward_mean: -20.428571428571427
reward_std: 0.4948716593053935
reward_max: -20.0
reward_min: -21.0
total_envstep_count: 132352
total_train_sample_count: 101489
total_episode_count: 433
total_duration: 76.80932174838232
[2023-04-11 20:33:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3447
train_sample_count: 3447
avg_envstep_per_episode: 229.8
avg_sample_per_episode: 229.8
avg_envstep_per_sec: 1325.287497724815
avg_train_sample_per_sec: 1325.287497724815
avg_episode_per_sec: 5.767134454851241
collect_time: 2.600945082419951
reward_mean: -20.266666666666666
reward_std: 0.771722460186015
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 137214
total_train_sample_count: 104936
total_episode_count: 448
total_duration: 79.41026683080227
[2023-04-11 20:33:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 3403
train_sample_count: 3403
avg_envstep_per_episode: 226.86666666666667
avg_sample_per_episode: 226.86666666666667
avg_envstep_per_sec: 1277.4664004877507
avg_train_sample_per_sec: 1277.4664004877507
avg_episode_per_sec: 5.630912726216944
collect_time: 2.6638665398171706
reward_mean: -20.333333333333332
reward_std: 0.6992058987801011
reward_max: -19.0
reward_min: -21.0
total_envstep_count: 141793
total_train_sample_count: 108339
total_episode_count: 463
total_duration: 82.07413337061944
[2023-04-11 20:33:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3311
train_sample_count: 3311
avg_envstep_per_episode: 236.5
avg_sample_per_episode: 236.5
avg_envstep_per_sec: 1307.2968563866104
avg_train_sample_per_sec: 1307.2968563866104
avg_episode_per_sec: 5.527682268019495
collect_time: 2.5327070770686753
reward_mean: -20.214285714285715
reward_std: 0.9394961741404217
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 146376
total_train_sample_count: 111650
total_episode_count: 477
total_duration: 84.60684044768811
[2023-04-11 20:34:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 3297
train_sample_count: 3297
avg_envstep_per_episode: 253.6153846153846
avg_sample_per_episode: 253.6153846153846
avg_envstep_per_sec: 1281.6669534584803
avg_train_sample_per_sec: 1281.6669534584803
avg_episode_per_sec: 5.053585197136865
collect_time: 2.572431153899457
reward_mean: -20.23076923076923
reward_std: 0.890448992522325
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 151129
total_train_sample_count: 114947
total_episode_count: 490
total_duration: 87.17927160158757
[2023-04-11 20:34:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3391
train_sample_count: 3391
avg_envstep_per_episode: 242.21428571428572
avg_sample_per_episode: 242.21428571428572
avg_envstep_per_sec: 1267.54844906663
avg_train_sample_per_sec: 1267.54844906663
avg_episode_per_sec: 5.2331696511155466
collect_time: 2.675242908858428
reward_mean: -19.928571428571427
reward_std: 1.3343958351621001
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 155746
total_train_sample_count: 118338
total_episode_count: 504
total_duration: 89.854514510446
[2023-04-11 20:34:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 3338
train_sample_count: 3338
avg_envstep_per_episode: 256.7692307692308
avg_sample_per_episode: 256.7692307692308
avg_envstep_per_sec: 1347.98279018585
avg_train_sample_per_sec: 1347.98279018585
avg_episode_per_sec: 5.249783185265443
collect_time: 2.4762927422387797
reward_mean: -19.692307692307693
reward_std: 1.2639751327042297
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 159965
total_train_sample_count: 121676
total_episode_count: 517
total_duration: 92.33080725268478
[2023-04-11 20:34:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3245
train_sample_count: 3245
avg_envstep_per_episode: 270.4166666666667
avg_sample_per_episode: 270.4166666666667
avg_envstep_per_sec: 1235.0104837201811
avg_train_sample_per_sec: 1235.0104837201811
avg_episode_per_sec: 4.567064962909761
collect_time: 2.6275080598710336
reward_mean: -19.916666666666668
reward_std: 0.9537935951882998
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 164284
total_train_sample_count: 124921
total_episode_count: 529
total_duration: 94.95831531255581
[2023-04-11 20:34:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 268.9166666666667
avg_sample_per_episode: 268.9166666666667
avg_envstep_per_sec: 1356.8924105575634
avg_train_sample_per_sec: 1356.8924105575634
avg_episode_per_sec: 5.045772831326545
collect_time: 2.378228350967036
reward_mean: -20.0
reward_std: 0.816496580927726
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 168418
total_train_sample_count: 128148
total_episode_count: 541
total_duration: 97.33654366352285
[2023-04-11 20:34:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3371
train_sample_count: 3371
avg_envstep_per_episode: 280.9166666666667
avg_sample_per_episode: 280.9166666666667
avg_envstep_per_sec: 1288.7469529205841
avg_train_sample_per_sec: 1288.7469529205841
avg_episode_per_sec: 4.587648601319196
collect_time: 2.61571908461981
reward_mean: -19.833333333333332
reward_std: 0.9860132971832694
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 172832
total_train_sample_count: 131519
total_episode_count: 553
total_duration: 99.95226274814266
[2023-04-11 20:34:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3307
train_sample_count: 3307
avg_envstep_per_episode: 275.5833333333333
avg_sample_per_episode: 275.5833333333333
avg_envstep_per_sec: 1355.5351322877307
avg_train_sample_per_sec: 1355.5351322877307
avg_episode_per_sec: 4.918784876762252
collect_time: 2.439626920195562
reward_mean: -19.583333333333332
reward_std: 0.9537935951882998
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 177498
total_train_sample_count: 134826
total_episode_count: 565
total_duration: 102.39188966833822
[2023-04-11 20:34:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 3517
train_sample_count: 3517
avg_envstep_per_episode: 251.21428571428572
avg_sample_per_episode: 251.21428571428572
avg_envstep_per_sec: 1285.9533232295007
avg_train_sample_per_sec: 1285.9533232295007
avg_episode_per_sec: 5.118949822352292
collect_time: 2.734935970434387
reward_mean: -19.928571428571427
reward_std: 0.9609731462195509
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 182177
total_train_sample_count: 138343
total_episode_count: 579
total_duration: 105.12682563877262
[2023-04-11 20:34:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 3273
train_sample_count: 3273
avg_envstep_per_episode: 251.76923076923077
avg_sample_per_episode: 251.76923076923077
avg_envstep_per_sec: 1321.4649017010156
avg_train_sample_per_sec: 1321.4649017010156
avg_episode_per_sec: 5.248714855518852
collect_time: 2.476796769847561
reward_mean: -19.692307692307693
reward_std: 0.9910845174403942
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 186696
total_train_sample_count: 141616
total_episode_count: 592
total_duration: 107.60362240862018
[2023-04-11 20:35:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3033
train_sample_count: 3033
avg_envstep_per_episode: 252.75
avg_sample_per_episode: 252.75
avg_envstep_per_sec: 1307.0687895489368
avg_train_sample_per_sec: 1307.0687895489368
avg_episode_per_sec: 5.171389869629819
collect_time: 2.320459354741898
reward_mean: -19.5
reward_std: 1.2583057392117916
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 191357
total_train_sample_count: 145049
total_episode_count: 604
total_duration: 109.92408176336208
[2023-04-11 20:35:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 3426
train_sample_count: 3426
avg_envstep_per_episode: 263.53846153846155
avg_sample_per_episode: 263.53846153846155
avg_envstep_per_sec: 1316.5193944755881
avg_train_sample_per_sec: 1316.5193944755881
avg_episode_per_sec: 4.99554936607783
collect_time: 2.602316391521665
reward_mean: -19.53846153846154
reward_std: 1.0088366960464616
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 196141
total_train_sample_count: 148475
total_episode_count: 617
total_duration: 112.52639815488375
[2023-04-11 20:35:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 2582
train_sample_count: 2582
avg_envstep_per_episode: 234.72727272727272
avg_sample_per_episode: 234.72727272727272
avg_envstep_per_sec: 1279.1768065766967
avg_train_sample_per_sec: 1279.1768065766967
avg_episode_per_sec: 5.4496300822399935
collect_time: 2.0184856281985666
reward_mean: -19.545454545454547
reward_std: 1.304790917673393
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 200459
total_train_sample_count: 151857
total_episode_count: 628
total_duration: 114.54488378308231
[2023-04-11 20:35:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 2921
train_sample_count: 2921
avg_envstep_per_episode: 243.41666666666666
avg_sample_per_episode: 243.41666666666666
avg_envstep_per_sec: 1288.4434942867201
avg_train_sample_per_sec: 1288.4434942867201
avg_episode_per_sec: 5.293160537980364
collect_time: 2.2670765252433984
reward_mean: -19.25
reward_std: 1.1636866703140785
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 205374
total_train_sample_count: 155178
total_episode_count: 640
total_duration: 116.81196030832571
[2023-04-11 20:35:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3061
train_sample_count: 3061
avg_envstep_per_episode: 255.08333333333334
avg_sample_per_episode: 255.08333333333334
avg_envstep_per_sec: 1329.0505670407945
avg_train_sample_per_sec: 1329.0505670407945
avg_episode_per_sec: 5.210260308555875
collect_time: 2.3031478830903236
reward_mean: -19.0
reward_std: 1.1547005383792515
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 210407
total_train_sample_count: 158639
total_episode_count: 652
total_duration: 119.11510819141603
[2023-04-11 20:35:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 3314
train_sample_count: 3314
avg_envstep_per_episode: 254.92307692307693
avg_sample_per_episode: 254.92307692307693
avg_envstep_per_sec: 1367.735044508956
avg_train_sample_per_sec: 1367.735044508956
avg_episode_per_sec: 5.365285328490171
collect_time: 2.422983905621715
reward_mean: -19.23076923076923
reward_std: 1.186711432349347
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 215249
total_train_sample_count: 161953
total_episode_count: 665
total_duration: 121.53809209703775
[2023-04-11 20:35:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1830
train_sample_count: 1830
avg_envstep_per_episode: 228.75
avg_sample_per_episode: 228.75
avg_envstep_per_sec: 1286.0745402362875
avg_train_sample_per_sec: 1286.0745402362875
avg_episode_per_sec: 5.622183782453716
collect_time: 1.4229346299505925
reward_mean: -19.0
reward_std: 1.3228756555322954
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 219239
total_train_sample_count: 165383
total_episode_count: 673
total_duration: 122.96102672698834
[2023-04-11 20:35:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3092
train_sample_count: 3092
avg_envstep_per_episode: 257.6666666666667
avg_sample_per_episode: 257.6666666666667
avg_envstep_per_sec: 1327.8983696887196
avg_train_sample_per_sec: 1327.8983696887196
avg_episode_per_sec: 5.153551240706545
collect_time: 2.32849144978227
reward_mean: -18.666666666666668
reward_std: 1.247219128924647
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 224070
total_train_sample_count: 168875
total_episode_count: 685
total_duration: 125.28951817677061
[2023-04-11 20:36:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 254.25
avg_sample_per_episode: 254.25
avg_envstep_per_sec: 1360.1187437712588
avg_train_sample_per_sec: 1360.1187437712588
avg_episode_per_sec: 5.349532915521174
collect_time: 1.4954576644979116
reward_mean: -17.75
reward_std: 1.1989578808281798
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 228247
total_train_sample_count: 172109
total_episode_count: 693
total_duration: 126.78497584126852
[2023-04-11 20:36:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 3080
train_sample_count: 3080
avg_envstep_per_episode: 256.6666666666667
avg_sample_per_episode: 256.6666666666667
avg_envstep_per_sec: 1278.6430443538977
avg_train_sample_per_sec: 1278.6430443538977
avg_episode_per_sec: 4.981726146833368
collect_time: 2.4088036247491837
reward_mean: -19.166666666666668
reward_std: 0.8975274678557508
reward_max: -18.0
reward_min: -20.0
total_envstep_count: 232867
total_train_sample_count: 175589
total_episode_count: 705
total_duration: 129.1937794660177
[2023-04-11 20:36:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 2964
train_sample_count: 2964
avg_envstep_per_episode: 296.4
avg_sample_per_episode: 296.4
avg_envstep_per_sec: 1336.3728930972698
avg_train_sample_per_sec: 1336.3728930972698
avg_episode_per_sec: 4.508680476036672
collect_time: 2.2179438204036224
reward_mean: -18.0
reward_std: 1.2649110640673518
reward_max: -16.0
reward_min: -20.0
total_envstep_count: 237235
total_train_sample_count: 178953
total_episode_count: 715
total_duration: 131.41172328642133
[2023-04-11 20:36:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 305.5
avg_sample_per_episode: 305.5
avg_envstep_per_sec: 1279.6217062460544
avg_train_sample_per_sec: 1279.6217062460544
avg_episode_per_sec: 4.188614423064008
collect_time: 2.3874243341512713
reward_mean: -19.0
reward_std: 1.2649110640673518
reward_max: -16.0
reward_min: -20.0
total_envstep_count: 242268
total_train_sample_count: 182408
total_episode_count: 725
total_duration: 133.7991476205726
[2023-04-11 20:36:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 3162
train_sample_count: 3162
avg_envstep_per_episode: 287.45454545454544
avg_sample_per_episode: 287.45454545454544
avg_envstep_per_sec: 1409.9593304334985
avg_train_sample_per_sec: 1409.9593304334985
avg_episode_per_sec: 4.904981857928047
collect_time: 2.2426178768062965
reward_mean: -18.636363636363637
reward_std: 1.2264306875665492
reward_max: -16.0
reward_min: -20.0
total_envstep_count: 246840
total_train_sample_count: 185970
total_episode_count: 736
total_duration: 136.0417654973789
[2023-04-11 20:36:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2176
train_sample_count: 2176
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 1373.5986535086688
avg_train_sample_per_sec: 1373.5986535086688
avg_episode_per_sec: 5.049995049664224
collect_time: 1.58415996873738
reward_mean: -18.875
reward_std: 1.6909686573085854
reward_max: -15.0
reward_min: -20.0
total_envstep_count: 251012
total_train_sample_count: 189346
total_episode_count: 744
total_duration: 137.62592546611626
[2023-04-11 20:36:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2413
train_sample_count: 2413
avg_envstep_per_episode: 268.1111111111111
avg_sample_per_episode: 268.1111111111111
avg_envstep_per_sec: 1317.6180431402945
avg_train_sample_per_sec: 1317.6180431402945
avg_episode_per_sec: 4.914447736536531
collect_time: 1.8313349703750785
reward_mean: -18.22222222222222
reward_std: 1.4740554623801778
reward_max: -16.0
reward_min: -20.0
total_envstep_count: 255474
total_train_sample_count: 192559
total_episode_count: 753
total_duration: 139.45726043649134
[2023-04-11 20:36:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 289.55555555555554
avg_sample_per_episode: 289.55555555555554
avg_envstep_per_sec: 1286.3347231430296
avg_train_sample_per_sec: 1286.3347231430296
avg_episode_per_sec: 4.442445321675851
collect_time: 2.025911260198668
reward_mean: -17.0
reward_std: 1.5634719199411433
reward_max: -14.0
reward_min: -19.0
total_envstep_count: 260042
total_train_sample_count: 195965
total_episode_count: 762
total_duration: 141.48317169669
[2023-04-11 20:37:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2042
train_sample_count: 2042
avg_envstep_per_episode: 226.88888888888889
avg_sample_per_episode: 226.88888888888889
avg_envstep_per_sec: 1240.0178814522808
avg_train_sample_per_sec: 1240.0178814522808
avg_episode_per_sec: 5.46530897799732
collect_time: 1.646750446540703
reward_mean: -18.77777777777778
reward_std: 1.0304020550550783
reward_max: -17.0
reward_min: -21.0
total_envstep_count: 264229
total_train_sample_count: 199207
total_episode_count: 771
total_duration: 143.1299221432307
[2023-04-11 20:37:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 2277
train_sample_count: 2277
avg_envstep_per_episode: 227.7
avg_sample_per_episode: 227.7
avg_envstep_per_sec: 1293.7860074264534
avg_train_sample_per_sec: 1293.7860074264534
avg_episode_per_sec: 5.681976317200059
collect_time: 1.7599510173473865
reward_mean: -18.6
reward_std: 1.0198039027185568
reward_max: -17.0
reward_min: -20.0
total_envstep_count: 268237
total_train_sample_count: 202684
total_episode_count: 781
total_duration: 144.88987316057808
[2023-04-11 20:37:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2651
train_sample_count: 2651
avg_envstep_per_episode: 294.55555555555554
avg_sample_per_episode: 294.55555555555554
avg_envstep_per_sec: 1199.5352742416749
avg_train_sample_per_sec: 1199.5352742416749
avg_episode_per_sec: 4.072356645860081
collect_time: 2.2100225453360807
reward_mean: -17.666666666666668
reward_std: 1.4142135623730951
reward_max: -16.0
reward_min: -20.0
total_envstep_count: 272542
total_train_sample_count: 206135
total_episode_count: 790
total_duration: 147.09989570591415
[2023-04-11 20:37:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 3045
train_sample_count: 3045
avg_envstep_per_episode: 304.5
avg_sample_per_episode: 304.5
avg_envstep_per_sec: 1221.338118361688
avg_train_sample_per_sec: 1221.338118361688
avg_episode_per_sec: 4.010962621877465
collect_time: 2.493167087984272
reward_mean: -18.8
reward_std: 0.8717797887081347
reward_max: -17.0
reward_min: -20.0
total_envstep_count: 277094
total_train_sample_count: 209580
total_episode_count: 800
total_duration: 149.5930627938984
[2023-04-11 20:37:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 3002
train_sample_count: 3002
avg_envstep_per_episode: 333.55555555555554
avg_sample_per_episode: 333.55555555555554
avg_envstep_per_sec: 1306.1898407121207
avg_train_sample_per_sec: 1306.1898407121207
avg_episode_per_sec: 3.9159588828811085
collect_time: 2.298287665721961
reward_mean: -17.444444444444443
reward_std: 3.1661792997277796
reward_max: -10.0
reward_min: -21.0
total_envstep_count: 281976
total_train_sample_count: 212982
total_episode_count: 809
total_duration: 151.89135045962038
[2023-04-11 20:37:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2594
train_sample_count: 2594
avg_envstep_per_episode: 288.22222222222223
avg_sample_per_episode: 288.22222222222223
avg_envstep_per_sec: 1370.3989635286848
avg_train_sample_per_sec: 1370.3989635286848
avg_episode_per_sec: 4.754661014555961
collect_time: 1.8928794234641166
reward_mean: -17.22222222222222
reward_std: 1.314684396244359
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 286398
total_train_sample_count: 216376
total_episode_count: 818
total_duration: 153.7842298830845
[2023-04-11 20:37:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2753
train_sample_count: 2753
avg_envstep_per_episode: 305.8888888888889
avg_sample_per_episode: 305.8888888888889
avg_envstep_per_sec: 1311.9999845431093
avg_train_sample_per_sec: 1311.9999845431093
avg_episode_per_sec: 4.2891390704278916
collect_time: 2.0983231954524024
reward_mean: -17.77777777777778
reward_std: 1.617802197617893
reward_max: -15.0
reward_min: -20.0
total_envstep_count: 290556
total_train_sample_count: 219929
total_episode_count: 827
total_duration: 155.8825530785369
[2023-04-11 20:37:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 291.14285714285717
avg_sample_per_episode: 291.14285714285717
avg_envstep_per_sec: 1333.5358379998322
avg_train_sample_per_sec: 1333.5358379998322
avg_episode_per_sec: 4.580348805691279
collect_time: 1.528267888965618
reward_mean: -19.142857142857142
reward_std: 1.3552618543578767
reward_max: -18.0
reward_min: -21.0
total_envstep_count: 294642
total_train_sample_count: 223167
total_episode_count: 834
total_duration: 157.4108209675025
[2023-04-11 20:37:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 250.75
avg_sample_per_episode: 250.75
avg_envstep_per_sec: 1305.200625755524
avg_train_sample_per_sec: 1305.200625755524
avg_episode_per_sec: 5.2051869421955095
collect_time: 1.536928469398192
reward_mean: -17.0
reward_std: 1.5
reward_max: -15.0
reward_min: -20.0
total_envstep_count: 298921
total_train_sample_count: 226373
total_episode_count: 842
total_duration: 158.9477494369007
[2023-04-11 20:38:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1396
train_sample_count: 1396
avg_envstep_per_episode: 199.42857142857142
avg_sample_per_episode: 199.42857142857142
avg_envstep_per_sec: 1326.2052498750265
avg_train_sample_per_sec: 1326.2052498750265
avg_episode_per_sec: 6.650026324588242
collect_time: 1.0526274120326025
reward_mean: -17.571428571428573
reward_std: 1.9166296949998196
reward_max: -14.0
reward_min: -21.0
total_envstep_count: 303257
total_train_sample_count: 229769
total_episode_count: 849
total_duration: 160.00037684893329
[2023-04-11 20:38:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1718
train_sample_count: 1718
avg_envstep_per_episode: 190.88888888888889
avg_sample_per_episode: 190.88888888888889
avg_envstep_per_sec: 1311.7862958797966
avg_train_sample_per_sec: 1311.7862958797966
avg_episode_per_sec: 6.871988744422683
collect_time: 1.3096645432233012
reward_mean: -17.0
reward_std: 1.8257418583505538
reward_max: -14.0
reward_min: -20.0
total_envstep_count: 307996
total_train_sample_count: 233087
total_episode_count: 858
total_duration: 161.3100413921566
[2023-04-11 20:38:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1485
train_sample_count: 1485
avg_envstep_per_episode: 185.625
avg_sample_per_episode: 185.625
avg_envstep_per_sec: 1342.4288423068365
avg_train_sample_per_sec: 1342.4288423068365
avg_episode_per_sec: 7.231939891215281
collect_time: 1.10620388448163
reward_mean: -16.5
reward_std: 2.3979157616563596
reward_max: -12.0
reward_min: -20.0
total_envstep_count: 312255
total_train_sample_count: 236572
total_episode_count: 866
total_duration: 162.41624527663822
[2023-04-11 20:38:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1889
train_sample_count: 1889
avg_envstep_per_episode: 209.88888888888889
avg_sample_per_episode: 209.88888888888889
avg_envstep_per_sec: 1241.9890520555145
avg_train_sample_per_sec: 1241.9890520555145
avg_episode_per_sec: 5.9173644618844
collect_time: 1.520947384257269
reward_mean: -17.22222222222222
reward_std: 2.57240820062005
reward_max: -11.0
reward_min: -21.0
total_envstep_count: 316510
total_train_sample_count: 240061
total_episode_count: 875
total_duration: 163.93719266089548
[2023-04-11 20:38:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2292
train_sample_count: 2292
avg_envstep_per_episode: 286.5
avg_sample_per_episode: 286.5
avg_envstep_per_sec: 1380.6625515958858
avg_train_sample_per_sec: 1380.6625515958858
avg_episode_per_sec: 4.819066497716879
collect_time: 1.6600725480318952
reward_mean: -15.875
reward_std: 2.4717149916606487
reward_max: -11.0
reward_min: -20.0
total_envstep_count: 320784
total_train_sample_count: 243553
total_episode_count: 883
total_duration: 165.59726520892738
[2023-04-11 20:38:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1929
train_sample_count: 1929
avg_envstep_per_episode: 275.57142857142856
avg_sample_per_episode: 275.57142857142856
avg_envstep_per_sec: 1198.7373818136873
avg_train_sample_per_sec: 1198.7373818136873
avg_episode_per_sec: 4.350006051164236
collect_time: 1.6091931637949146
reward_mean: -16.857142857142858
reward_std: 1.456862718169367
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 325612
total_train_sample_count: 247082
total_episode_count: 890
total_duration: 167.2064583727223
[2023-04-11 20:38:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 244.88888888888889
avg_sample_per_episode: 244.88888888888889
avg_envstep_per_sec: 1318.1971362887036
avg_train_sample_per_sec: 1318.1971362887036
avg_episode_per_sec: 5.382837670870387
collect_time: 1.671980570527725
reward_mean: -15.777777777777779
reward_std: 1.547598697464902
reward_max: -13.0
reward_min: -18.0
total_envstep_count: 330346
total_train_sample_count: 250486
total_episode_count: 899
total_duration: 168.87843894325002
[2023-04-11 20:38:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2111
train_sample_count: 2111
avg_envstep_per_episode: 263.875
avg_sample_per_episode: 263.875
avg_envstep_per_sec: 1329.0211699327585
avg_train_sample_per_sec: 1329.0211699327585
avg_episode_per_sec: 5.036555831104722
collect_time: 1.5883870383395062
reward_mean: -16.125
reward_std: 1.3635890143294642
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 334718
total_train_sample_count: 253797
total_episode_count: 907
total_duration: 170.46682598158952
[2023-04-11 20:38:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 3021
train_sample_count: 3021
avg_envstep_per_episode: 335.6666666666667
avg_sample_per_episode: 335.6666666666667
avg_envstep_per_sec: 1337.5013040347983
avg_train_sample_per_sec: 1337.5013040347983
avg_episode_per_sec: 3.984611630689568
collect_time: 2.2586893866096758
reward_mean: -15.88888888888889
reward_std: 1.5947444549341472
reward_max: -13.0
reward_min: -18.0
total_envstep_count: 339399
total_train_sample_count: 257218
total_episode_count: 916
total_duration: 172.7255153681992
[2023-04-11 20:39:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2514
train_sample_count: 2514
avg_envstep_per_episode: 314.25
avg_sample_per_episode: 314.25
avg_envstep_per_sec: 1111.6764034260057
avg_train_sample_per_sec: 1111.6764034260057
avg_episode_per_sec: 3.537554187513144
collect_time: 2.261449458000783
reward_mean: -17.625
reward_std: 2.2325713874364688
reward_max: -13.0
reward_min: -20.0
total_envstep_count: 343887
total_train_sample_count: 260532
total_episode_count: 924
total_duration: 174.9869648262
[2023-04-11 20:39:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2349
train_sample_count: 2349
avg_envstep_per_episode: 293.625
avg_sample_per_episode: 293.625
avg_envstep_per_sec: 1189.8497754528798
avg_train_sample_per_sec: 1189.8497754528798
avg_episode_per_sec: 4.052276800180093
collect_time: 1.974198800941846
reward_mean: -17.375
reward_std: 1.1110243021644486
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 348226
total_train_sample_count: 264081
total_episode_count: 932
total_duration: 176.96116362714184
[2023-04-11 20:39:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 293.2857142857143
avg_sample_per_episode: 293.2857142857143
avg_envstep_per_sec: 1372.0385679047301
avg_train_sample_per_sec: 1372.0385679047301
avg_episode_per_sec: 4.678163650917249
collect_time: 1.4963136226813076
reward_mean: -16.428571428571427
reward_std: 2.194613070819602
reward_max: -12.0
reward_min: -19.0
total_envstep_count: 352841
total_train_sample_count: 267334
total_episode_count: 939
total_duration: 178.45747724982314
[2023-04-11 20:39:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1842
train_sample_count: 1842
avg_envstep_per_episode: 263.14285714285717
avg_sample_per_episode: 263.14285714285717
avg_envstep_per_sec: 1349.7274925938773
avg_train_sample_per_sec: 1349.7274925938773
avg_episode_per_sec: 5.129257572289436
collect_time: 1.3647199231750728
reward_mean: -15.571428571428571
reward_std: 2.498979383505129
reward_max: -12.0
reward_min: -20.0
total_envstep_count: 357660
total_train_sample_count: 270776
total_episode_count: 946
total_duration: 179.82219717299822
[2023-04-11 20:39:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 137.85714285714286
avg_sample_per_episode: 137.85714285714286
avg_envstep_per_sec: 1317.9216663002444
avg_train_sample_per_sec: 1317.9216663002444
avg_episode_per_sec: 9.560053537929234
collect_time: 0.7322134726785476
reward_mean: -16.857142857142858
reward_std: 1.456862718169367
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 361978
total_train_sample_count: 274141
total_episode_count: 953
total_duration: 180.55441064567677
[2023-04-11 20:39:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1679
train_sample_count: 1679
avg_envstep_per_episode: 209.875
avg_sample_per_episode: 209.875
avg_envstep_per_sec: 1326.714646954073
avg_train_sample_per_sec: 1326.714646954073
avg_episode_per_sec: 6.3214515638073765
collect_time: 1.265532120154638
reward_mean: -15.25
reward_std: 2.0463381929681126
reward_max: -12.0
reward_min: -18.0
total_envstep_count: 366645
total_train_sample_count: 277420
total_episode_count: 961
total_duration: 181.8199427658314
[2023-04-11 20:39:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1912
train_sample_count: 1912
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 1332.5264985050276
avg_train_sample_per_sec: 1332.5264985050276
avg_episode_per_sec: 5.5754246799373535
collect_time: 1.434868276274497
reward_mean: -16.0
reward_std: 1.9364916731037085
reward_max: -12.0
reward_min: -18.0
total_envstep_count: 371183
total_train_sample_count: 280932
total_episode_count: 969
total_duration: 183.2548110421059
[2023-04-11 20:39:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2141
train_sample_count: 2141
avg_envstep_per_episode: 267.625
avg_sample_per_episode: 267.625
avg_envstep_per_sec: 1342.4669707275937
avg_train_sample_per_sec: 1342.4669707275937
avg_episode_per_sec: 5.016224084923283
collect_time: 1.5948250844783283
reward_mean: -16.25
reward_std: 2.680951323690902
reward_max: -12.0
reward_min: -19.0
total_envstep_count: 375723
total_train_sample_count: 284273
total_episode_count: 977
total_duration: 184.84963612658422
[2023-04-11 20:40:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2463
train_sample_count: 2463
avg_envstep_per_episode: 307.875
avg_sample_per_episode: 307.875
avg_envstep_per_sec: 1373.5641079512823
avg_train_sample_per_sec: 1373.5641079512823
avg_episode_per_sec: 4.461434374181997
collect_time: 1.7931452822203169
reward_mean: -17.5
reward_std: 1.6583123951777
reward_max: -15.0
reward_min: -20.0
total_envstep_count: 380315
total_train_sample_count: 287536
total_episode_count: 985
total_duration: 186.64278140880452
[2023-04-11 20:40:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2738
train_sample_count: 2738
avg_envstep_per_episode: 342.25
avg_sample_per_episode: 342.25
avg_envstep_per_sec: 1342.6249323871891
avg_train_sample_per_sec: 1342.6249323871891
avg_episode_per_sec: 3.92293625240961
collect_time: 2.0392888095201926
reward_mean: -17.375
reward_std: 1.5761900266148114
reward_max: -15.0
reward_min: -20.0
total_envstep_count: 384817
total_train_sample_count: 291074
total_episode_count: 993
total_duration: 188.68207021832472
[2023-04-11 20:40:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2102
train_sample_count: 2102
avg_envstep_per_episode: 350.3333333333333
avg_sample_per_episode: 350.3333333333333
avg_envstep_per_sec: 1284.7075313942046
avg_train_sample_per_sec: 1284.7075313942046
avg_episode_per_sec: 3.6671004702022967
collect_time: 1.6361700609934497
reward_mean: -16.333333333333332
reward_std: 1.699673171197595
reward_max: -15.0
reward_min: -20.0
total_envstep_count: 388961
total_train_sample_count: 294376
total_episode_count: 999
total_duration: 190.31824027931816
[2023-04-11 20:40:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1768
train_sample_count: 1768
avg_envstep_per_episode: 294.6666666666667
avg_sample_per_episode: 294.6666666666667
avg_envstep_per_sec: 1299.3102142881128
avg_train_sample_per_sec: 1299.3102142881128
avg_episode_per_sec: 4.409423804145179
collect_time: 1.3607220050745776
reward_mean: -15.0
reward_std: 2.0
reward_max: -13.0
reward_min: -19.0
total_envstep_count: 393460
total_train_sample_count: 297744
total_episode_count: 1005
total_duration: 191.67896228439272
[2023-04-11 20:40:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 175.28571428571428
avg_sample_per_episode: 175.28571428571428
avg_envstep_per_sec: 1289.1158328589393
avg_train_sample_per_sec: 1289.1158328589393
avg_episode_per_sec: 7.354369054614975
collect_time: 0.9518151656541355
reward_mean: -17.428571428571427
reward_std: 2.871393034605969
reward_max: -13.0
reward_min: -21.0
total_envstep_count: 397254
total_train_sample_count: 300971
total_episode_count: 1012
total_duration: 192.63077745004685
[2023-04-11 20:40:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1744
train_sample_count: 1744
avg_envstep_per_episode: 249.14285714285714
avg_sample_per_episode: 249.14285714285714
avg_envstep_per_sec: 1321.0915254795432
avg_train_sample_per_sec: 1321.0915254795432
avg_episode_per_sec: 5.3025462605256894
collect_time: 1.3201204960927633
reward_mean: -15.857142857142858
reward_std: 1.4568627181693672
reward_max: -14.0
reward_min: -18.0
total_envstep_count: 401842
total_train_sample_count: 304315
total_episode_count: 1019
total_duration: 193.9508979461396
[2023-04-11 20:40:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1451
train_sample_count: 1451
avg_envstep_per_episode: 207.28571428571428
avg_sample_per_episode: 207.28571428571428
avg_envstep_per_sec: 1260.865896930449
avg_train_sample_per_sec: 1260.865896930449
avg_episode_per_sec: 6.082743817031801
collect_time: 1.1507964514960936
reward_mean: -15.714285714285714
reward_std: 2.9137254363387344
reward_max: -12.0
reward_min: -20.0
total_envstep_count: 406926
total_train_sample_count: 307766
total_episode_count: 1026
total_duration: 195.1016943976357
[2023-04-11 20:40:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1287
train_sample_count: 1287
avg_envstep_per_episode: 160.875
avg_sample_per_episode: 160.875
avg_envstep_per_sec: 1379.9840196664504
avg_train_sample_per_sec: 1379.9840196664504
avg_episode_per_sec: 8.5779892442359
collect_time: 0.9326194953410221
reward_mean: -15.5
reward_std: 2.9154759474226504
reward_max: -11.0
reward_min: -21.0
total_envstep_count: 411385
total_train_sample_count: 311053
total_episode_count: 1034
total_duration: 196.0343138929767
[2023-04-11 20:40:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1613
train_sample_count: 1613
avg_envstep_per_episode: 201.625
avg_sample_per_episode: 201.625
avg_envstep_per_sec: 1215.0740038829529
avg_train_sample_per_sec: 1215.0740038829529
avg_episode_per_sec: 6.02640547493095
collect_time: 1.3274911609049445
reward_mean: -16.0
reward_std: 1.118033988749895
reward_max: -15.0
reward_min: -18.0
total_envstep_count: 415805
total_train_sample_count: 314266
total_episode_count: 1042
total_duration: 197.36180505388165
[2023-04-11 20:41:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1974
train_sample_count: 1974
avg_envstep_per_episode: 246.75
avg_sample_per_episode: 246.75
avg_envstep_per_sec: 1381.160572476421
avg_train_sample_per_sec: 1381.160572476421
avg_episode_per_sec: 5.597408601728151
collect_time: 1.4292328056111663
reward_mean: -17.0
reward_std: 1.7320508075688772
reward_max: -14.0
reward_min: -19.0
total_envstep_count: 420398
total_train_sample_count: 317840
total_episode_count: 1050
total_duration: 198.79103785949283
[2023-04-11 20:41:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1731
train_sample_count: 1731
avg_envstep_per_episode: 247.28571428571428
avg_sample_per_episode: 247.28571428571428
avg_envstep_per_sec: 1312.494935040311
avg_train_sample_per_sec: 1312.494935040311
avg_episode_per_sec: 5.307605167696232
collect_time: 1.3188622323687942
reward_mean: -16.714285714285715
reward_std: 1.979486637221574
reward_max: -14.0
reward_min: -20.0
total_envstep_count: 424961
total_train_sample_count: 321171
total_episode_count: 1057
total_duration: 200.10990009186162
[2023-04-11 20:41:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2240
train_sample_count: 2240
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 1362.5578627028647
avg_train_sample_per_sec: 1362.5578627028647
avg_episode_per_sec: 4.866278081081659
collect_time: 1.6439668811984103
reward_mean: -15.125
reward_std: 1.5360257159305635
reward_max: -13.0
reward_min: -18.0
total_envstep_count: 429688
total_train_sample_count: 324611
total_episode_count: 1065
total_duration: 201.75386697306004
[2023-04-11 20:41:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2593
train_sample_count: 2593
avg_envstep_per_episode: 324.125
avg_sample_per_episode: 324.125
avg_envstep_per_sec: 1339.2910169590832
avg_train_sample_per_sec: 1339.2910169590832
avg_episode_per_sec: 4.1320201063141795
collect_time: 1.936099001012876
reward_mean: -15.125
reward_std: 2.368411915187052
reward_max: -11.0
reward_min: -19.0
total_envstep_count: 434433
total_train_sample_count: 328004
total_episode_count: 1073
total_duration: 203.68996597407292
[2023-04-11 20:41:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2369
train_sample_count: 2369
avg_envstep_per_episode: 338.42857142857144
avg_sample_per_episode: 338.42857142857144
avg_envstep_per_sec: 1299.884134449475
avg_train_sample_per_sec: 1299.884134449475
avg_episode_per_sec: 3.8409408784914834
collect_time: 1.8224701242340462
reward_mean: -15.857142857142858
reward_std: 3.0904725218262765
reward_max: -11.0
reward_min: -20.0
total_envstep_count: 439157
total_train_sample_count: 331573
total_episode_count: 1080
total_duration: 205.51243609830698
[2023-04-11 20:41:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2048
train_sample_count: 2048
avg_envstep_per_episode: 292.57142857142856
avg_sample_per_episode: 292.57142857142856
avg_envstep_per_sec: 1310.9997626525796
avg_train_sample_per_sec: 1310.9997626525796
avg_episode_per_sec: 4.480956220003934
collect_time: 1.5621665680977919
reward_mean: -17.0
reward_std: 2.2677868380553634
reward_max: -13.0
reward_min: -20.0
total_envstep_count: 443018
total_train_sample_count: 334821
total_episode_count: 1087
total_duration: 207.07460266640476
[2023-04-11 20:41:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2767
train_sample_count: 2767
avg_envstep_per_episode: 345.875
avg_sample_per_episode: 345.875
avg_envstep_per_sec: 1359.580796357506
avg_train_sample_per_sec: 1359.580796357506
avg_episode_per_sec: 3.9308443696639133
collect_time: 2.0351861451803037
reward_mean: -15.875
reward_std: 2.368411915187052
reward_max: -13.0
reward_min: -20.0
total_envstep_count: 447309
total_train_sample_count: 338388
total_episode_count: 1095
total_duration: 209.10978881158505
[2023-04-11 20:41:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2664
train_sample_count: 2664
avg_envstep_per_episode: 380.57142857142856
avg_sample_per_episode: 380.57142857142856
avg_envstep_per_sec: 1253.1283384134042
avg_train_sample_per_sec: 1253.1283384134042
avg_episode_per_sec: 3.292754642978164
collect_time: 2.1258796232897517
reward_mean: -15.714285714285714
reward_std: 2.1852940772540506
reward_max: -12.0
reward_min: -20.0
total_envstep_count: 452018
total_train_sample_count: 341852
total_episode_count: 1102
total_duration: 211.2356684348748
[2023-04-11 20:42:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2845
train_sample_count: 2845
avg_envstep_per_episode: 355.625
avg_sample_per_episode: 355.625
avg_envstep_per_sec: 1328.1763501816395
avg_train_sample_per_sec: 1328.1763501816395
avg_episode_per_sec: 3.7347665382963497
collect_time: 2.142034828139292
reward_mean: -15.125
reward_std: 1.7633419974582356
reward_max: -12.0
reward_min: -18.0
total_envstep_count: 456510
total_train_sample_count: 345097
total_episode_count: 1110
total_duration: 213.3777032630141
[2023-04-11 20:42:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2510
train_sample_count: 2510
avg_envstep_per_episode: 358.57142857142856
avg_sample_per_episode: 358.57142857142856
avg_envstep_per_sec: 1169.8030457652808
avg_train_sample_per_sec: 1169.8030457652808
avg_episode_per_sec: 3.2623989324131335
collect_time: 2.1456603392222897
reward_mean: -16.285714285714285
reward_std: 1.749635530559413
reward_max: -14.0
reward_min: -20.0
total_envstep_count: 461279
total_train_sample_count: 348407
total_episode_count: 1117
total_duration: 215.5233636022364
[2023-04-11 20:42:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1770
train_sample_count: 1770
avg_envstep_per_episode: 295.0
avg_sample_per_episode: 295.0
avg_envstep_per_sec: 1332.1880477993377
avg_train_sample_per_sec: 1332.1880477993377
avg_episode_per_sec: 4.515891687455382
collect_time: 1.3286412552070939
reward_mean: -15.5
reward_std: 1.8027756377319946
reward_max: -12.0
reward_min: -18.0
total_envstep_count: 466013
total_train_sample_count: 351777
total_episode_count: 1123
total_duration: 216.8520048574435
[2023-04-11 20:42:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1783
train_sample_count: 1783
avg_envstep_per_episode: 254.71428571428572
avg_sample_per_episode: 254.71428571428572
avg_envstep_per_sec: 1327.4724703337763
avg_train_sample_per_sec: 1327.4724703337763
avg_episode_per_sec: 5.211613736588017
collect_time: 1.343154031323668
reward_mean: -14.714285714285714
reward_std: 2.0503857277724746
reward_max: -13.0
reward_min: -18.0
total_envstep_count: 470710
total_train_sample_count: 355160
total_episode_count: 1130
total_duration: 218.19515888876717
[2023-04-11 20:42:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2156
train_sample_count: 2156
avg_envstep_per_episode: 269.5
avg_sample_per_episode: 269.5
avg_envstep_per_sec: 1316.6645866218735
avg_train_sample_per_sec: 1316.6645866218735
avg_episode_per_sec: 4.885582881713816
collect_time: 1.6374709412756243
reward_mean: -15.75
reward_std: 1.920286436967152
reward_max: -12.0
reward_min: -19.0
total_envstep_count: 475757
total_train_sample_count: 358516
total_episode_count: 1138
total_duration: 219.8326298300428
[2023-04-11 20:42:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 258.125
avg_sample_per_episode: 258.125
avg_envstep_per_sec: 1385.7077415594758
avg_train_sample_per_sec: 1385.7077415594758
avg_episode_per_sec: 5.368359289334531
collect_time: 1.4902132232270338
reward_mean: -15.875
reward_std: 2.7128168017763383
reward_max: -10.0
reward_min: -19.0
total_envstep_count: 479977
total_train_sample_count: 361781
total_episode_count: 1146
total_duration: 221.32284305326985
[2023-04-11 20:42:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 285.7142857142857
avg_sample_per_episode: 285.7142857142857
avg_envstep_per_sec: 1298.3701719133207
avg_train_sample_per_sec: 1298.3701719133207
avg_episode_per_sec: 4.544295601696623
collect_time: 1.540392750283792
reward_mean: -16.571428571428573
reward_std: 1.2936264483053455
reward_max: -15.0
reward_min: -19.0
total_envstep_count: 483949
total_train_sample_count: 364981
total_episode_count: 1153
total_duration: 222.86323580355364
