[2023-06-29 09:50:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 268
envstep_count: 6453
train_sample_count: 6453
avg_envstep_per_episode: 24.078358208955223
avg_sample_per_episode: 24.078358208955223
avg_envstep_per_sec: 2473.0327387995208
avg_train_sample_per_sec: 2473.0327387995208
avg_episode_per_sec: 102.70769781470193
collect_time: 2.6093467744112706
reward_mean: 23.47382104342489
reward_std: 24.07548717139379
reward_max: 184.39582137923975
reward_min: 4.921450022967458
total_envstep_count: 6736
total_train_sample_count: 6453
total_episode_count: 268
total_duration: 2.6093467744112706
[2023-06-29 09:50:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 86
envstep_count: 3248
train_sample_count: 3248
avg_envstep_per_episode: 37.76744186046512
avg_sample_per_episode: 37.76744186046512
avg_envstep_per_sec: 2486.4352138432673
avg_train_sample_per_sec: 2486.4352138432673
avg_episode_per_sec: 65.83541514486484
collect_time: 1.3062878058984642
reward_mean: 49.9251335212395
reward_std: 44.09679131886595
reward_max: 222.87007150098228
reward_min: 6.049939235186293
total_envstep_count: 10128
total_train_sample_count: 9701
total_episode_count: 354
total_duration: 3.9156345803097348
[2023-06-29 09:50:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 76
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 42.11842105263158
avg_sample_per_episode: 42.11842105263158
avg_envstep_per_sec: 2393.707834814721
avg_train_sample_per_sec: 2393.707834814721
avg_episode_per_sec: 56.83280082659132
collect_time: 1.337255931339576
reward_mean: 62.12766845870309
reward_std: 38.633610051299584
reward_max: 157.71690926333773
reward_min: 7.51265905491678
total_envstep_count: 13488
total_train_sample_count: 12902
total_episode_count: 430
total_duration: 5.25289051164931
[2023-06-29 09:50:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 65
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 49.323076923076925
avg_sample_per_episode: 49.323076923076925
avg_envstep_per_sec: 2422.695453343641
avg_train_sample_per_sec: 2422.695453343641
avg_episode_per_sec: 49.11890345207007
collect_time: 1.3233194438761566
reward_mean: 83.84988359976478
reward_std: 42.60469436469271
reward_max: 215.97694125366618
reward_min: 9.400442975116647
total_envstep_count: 16960
total_train_sample_count: 16108
total_episode_count: 495
total_duration: 6.576209955525467
[2023-06-29 09:50:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 70
envstep_count: 3272
train_sample_count: 3272
avg_envstep_per_episode: 46.74285714285714
avg_sample_per_episode: 46.74285714285714
avg_envstep_per_sec: 2465.818436030756
avg_train_sample_per_sec: 2465.818436030756
avg_episode_per_sec: 52.752839401635974
collect_time: 1.3269427919709125
reward_mean: 76.73908291607472
reward_std: 39.608176179604314
reward_max: 174.92276525592794
reward_min: 10.647979290755513
total_envstep_count: 20512
total_train_sample_count: 19380
total_episode_count: 565
total_duration: 7.90315274749638
[2023-06-29 09:50:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 66
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 48.63636363636363
avg_sample_per_episode: 48.63636363636363
avg_envstep_per_sec: 2461.978134352424
avg_train_sample_per_sec: 2461.978134352424
avg_episode_per_sec: 50.620111173601245
collect_time: 1.303829613760696
reward_mean: 81.32300427125668
reward_std: 36.14408781854909
reward_max: 193.02259784628973
reward_min: 14.533637896941864
total_envstep_count: 23840
total_train_sample_count: 22590
total_episode_count: 631
total_duration: 9.206982361257076
[2023-06-29 09:50:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 62
envstep_count: 3282
train_sample_count: 3282
avg_envstep_per_episode: 52.935483870967744
avg_sample_per_episode: 52.935483870967744
avg_envstep_per_sec: 2522.2076139589985
avg_train_sample_per_sec: 2522.2076139589985
avg_episode_per_sec: 47.646822689048726
collect_time: 1.3012410167331105
reward_mean: 81.31855427298522
reward_std: 39.67948171079601
reward_max: 190.40278593521228
reward_min: 12.597854299568986
total_envstep_count: 27328
total_train_sample_count: 25872
total_episode_count: 693
total_duration: 10.508223377990186
[2023-06-29 09:50:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 58
envstep_count: 3236
train_sample_count: 3236
avg_envstep_per_episode: 55.793103448275865
avg_sample_per_episode: 55.793103448275865
avg_envstep_per_sec: 2679.144499710756
avg_train_sample_per_sec: 2679.144499710756
avg_episode_per_sec: 48.019277188882526
collect_time: 1.2078482516898073
reward_mean: 86.8178945245792
reward_std: 45.92723436466882
reward_max: 202.82859102306986
reward_min: 11.326804106623594
total_envstep_count: 30920
total_train_sample_count: 29108
total_episode_count: 751
total_duration: 11.716071629679993
[2023-06-29 09:50:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 62
envstep_count: 3254
train_sample_count: 3254
avg_envstep_per_episode: 52.483870967741936
avg_sample_per_episode: 52.483870967741936
avg_envstep_per_sec: 2701.1980117653993
avg_train_sample_per_sec: 2701.1980117653993
avg_episode_per_sec: 51.467202436833055
collect_time: 1.2046506719710306
reward_mean: 84.85585102036681
reward_std: 41.36800303719943
reward_max: 234.24687176289783
reward_min: 9.961986655586818
total_envstep_count: 34416
total_train_sample_count: 32362
total_episode_count: 813
total_duration: 12.920722301651024
[2023-06-29 09:50:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 51
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 62.96078431372549
avg_sample_per_episode: 62.96078431372549
avg_envstep_per_sec: 2671.514260842142
avg_train_sample_per_sec: 2671.514260842142
avg_episode_per_sec: 42.43140059263446
collect_time: 1.2019400558946653
reward_mean: 94.29303722834379
reward_std: 33.81024231351239
reward_max: 153.68197508421005
reward_min: 10.228230947130147
total_envstep_count: 37816
total_train_sample_count: 35573
total_episode_count: 864
total_duration: 14.122662357545689
[2023-06-29 09:50:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 57
envstep_count: 3245
train_sample_count: 3245
avg_envstep_per_episode: 56.92982456140351
avg_sample_per_episode: 56.92982456140351
avg_envstep_per_sec: 2688.0002302279504
avg_train_sample_per_sec: 2688.0002302279504
avg_episode_per_sec: 47.21602869737848
collect_time: 1.2072171585062752
reward_mean: 70.67550156707084
reward_std: 47.902221354778945
reward_max: 225.21826153446042
reward_min: 6.129833741138567
total_envstep_count: 41272
total_train_sample_count: 38818
total_episode_count: 921
total_duration: 15.329879516051964
[2023-06-29 09:50:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 61
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 52.459016393442624
avg_sample_per_episode: 52.459016393442624
avg_envstep_per_sec: 2637.7789466766258
avg_train_sample_per_sec: 2637.7789466766258
avg_episode_per_sec: 50.28266117102318
collect_time: 1.2131418381482362
reward_mean: 74.92769894064206
reward_std: 35.70671352115983
reward_max: 159.0787181627125
reward_min: 9.339696438601676
total_envstep_count: 44664
total_train_sample_count: 42018
total_episode_count: 982
total_duration: 16.5430213542002
[2023-06-29 09:51:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 57
envstep_count: 3278
train_sample_count: 3278
avg_envstep_per_episode: 57.50877192982456
avg_sample_per_episode: 57.50877192982456
avg_envstep_per_sec: 2417.054571527437
avg_train_sample_per_sec: 2417.054571527437
avg_episode_per_sec: 42.02931988317996
collect_time: 1.3561961068708912
reward_mean: 89.81600513731145
reward_std: 39.22741477213879
reward_max: 215.6660565378858
reward_min: 14.665170140216091
total_envstep_count: 48128
total_train_sample_count: 45296
total_episode_count: 1039
total_duration: 17.89921746107109
[2023-06-29 09:51:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 54
envstep_count: 3255
train_sample_count: 3255
avg_envstep_per_episode: 60.27777777777778
avg_sample_per_episode: 60.27777777777778
avg_envstep_per_sec: 2393.565368811515
avg_train_sample_per_sec: 2393.565368811515
avg_episode_per_sec: 39.70891856092836
collect_time: 1.3598960122055141
reward_mean: 93.91862781935855
reward_std: 46.01178033137571
reward_max: 208.50866050665857
reward_min: 11.811323455258183
total_envstep_count: 51688
total_train_sample_count: 48551
total_episode_count: 1093
total_duration: 19.259113473276603
[2023-06-29 09:51:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 58
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 55.44827586206897
avg_sample_per_episode: 55.44827586206897
avg_envstep_per_sec: 2336.5118970929802
avg_train_sample_per_sec: 2336.5118970929802
avg_episode_per_sec: 42.138585208766436
collect_time: 1.3764107103418788
reward_mean: 91.80119269148457
reward_std: 40.92370140451939
reward_max: 258.3751061238566
reward_min: 19.636395903463722
total_envstep_count: 55136
total_train_sample_count: 51767
total_episode_count: 1151
total_duration: 20.635524183618482
[2023-06-29 09:51:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 50
envstep_count: 3257
train_sample_count: 3257
avg_envstep_per_episode: 65.14
avg_sample_per_episode: 65.14
avg_envstep_per_sec: 2593.0881531163145
avg_train_sample_per_sec: 2593.0881531163145
avg_episode_per_sec: 39.80792375063424
collect_time: 1.2560313447446094
reward_mean: 96.35774385273542
reward_std: 47.833120523298575
reward_max: 223.5335578664338
reward_min: 8.809469394568177
total_envstep_count: 58616
total_train_sample_count: 55024
total_episode_count: 1201
total_duration: 21.891555528363092
[2023-06-29 09:51:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 52
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 63.32692307692308
avg_sample_per_episode: 63.32692307692308
avg_envstep_per_sec: 2462.5741453660435
avg_train_sample_per_sec: 2462.5741453660435
avg_episode_per_sec: 38.88668556302286
collect_time: 1.3372186198724667
reward_mean: 99.7611179931538
reward_std: 42.72588576449996
reward_max: 200.37091533343522
reward_min: 27.259173365958898
total_envstep_count: 62280
total_train_sample_count: 58317
total_episode_count: 1253
total_duration: 23.22877414823556
[2023-06-29 09:51:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 47
envstep_count: 3257
train_sample_count: 3257
avg_envstep_per_episode: 69.29787234042553
avg_sample_per_episode: 69.29787234042553
avg_envstep_per_sec: 2526.390312533561
avg_train_sample_per_sec: 2526.390312533561
avg_episode_per_sec: 36.456967973312054
collect_time: 1.2891911371896276
reward_mean: 113.63476541447868
reward_std: 51.182421489111114
reward_max: 244.90337557344327
reward_min: 28.028168957050788
total_envstep_count: 65808
total_train_sample_count: 61574
total_episode_count: 1300
total_duration: 24.517965285425188
[2023-06-29 09:51:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 51
envstep_count: 3242
train_sample_count: 3242
avg_envstep_per_episode: 63.568627450980394
avg_sample_per_episode: 63.568627450980394
avg_envstep_per_sec: 2354.0044795049685
avg_train_sample_per_sec: 2354.0044795049685
avg_episode_per_sec: 37.030915624538366
collect_time: 1.377227625616826
reward_mean: 109.70228341410012
reward_std: 55.70403452582963
reward_max: 237.18415865738896
reward_min: 13.45720612046792
total_envstep_count: 69296
total_train_sample_count: 64816
total_episode_count: 1351
total_duration: 25.895192911042013
[2023-06-29 09:51:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 48
envstep_count: 3245
train_sample_count: 3245
avg_envstep_per_episode: 67.60416666666667
avg_sample_per_episode: 67.60416666666667
avg_envstep_per_sec: 2652.5879558894094
avg_train_sample_per_sec: 2652.5879558894094
avg_episode_per_sec: 39.23704834597586
collect_time: 1.2233336100298908
reward_mean: 120.62135285889042
reward_std: 50.18629793599198
reward_max: 225.7153775210082
reward_min: 12.603067511536427
total_envstep_count: 72744
total_train_sample_count: 68061
total_episode_count: 1399
total_duration: 27.118526521071903
[2023-06-29 09:51:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3251
train_sample_count: 3251
avg_envstep_per_episode: 73.88636363636364
avg_sample_per_episode: 73.88636363636364
avg_envstep_per_sec: 2506.711286705038
avg_train_sample_per_sec: 2506.711286705038
avg_episode_per_sec: 33.92657539680766
collect_time: 1.2969184035044166
reward_mean: 141.76495457360355
reward_std: 61.09953882040637
reward_max: 262.2118681057888
reward_min: 19.754490109915295
total_envstep_count: 76232
total_train_sample_count: 71312
total_episode_count: 1443
total_duration: 28.41544492457632
[2023-06-29 09:51:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 52
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 61.86538461538461
avg_sample_per_episode: 61.86538461538461
avg_envstep_per_sec: 2492.315007922202
avg_train_sample_per_sec: 2492.315007922202
avg_episode_per_sec: 40.28609897791561
collect_time: 1.2907678161766376
reward_mean: 118.52914501890581
reward_std: 53.40577350255412
reward_max: 247.61879066564398
reward_min: 7.964092752554901
total_envstep_count: 79736
total_train_sample_count: 74529
total_episode_count: 1495
total_duration: 29.706212740752957
[2023-06-29 09:51:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 47
envstep_count: 3255
train_sample_count: 3255
avg_envstep_per_episode: 69.25531914893617
avg_sample_per_episode: 69.25531914893617
avg_envstep_per_sec: 2569.6956880618427
avg_train_sample_per_sec: 2569.6956880618427
avg_episode_per_sec: 37.104668921323075
collect_time: 1.266686952514225
reward_mean: 137.80015668352394
reward_std: 55.671175693941684
reward_max: 254.45564542121897
reward_min: 49.62165855386163
total_envstep_count: 83248
total_train_sample_count: 77784
total_episode_count: 1542
total_duration: 30.97289969326718
[2023-06-29 09:51:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 45
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 72.8
avg_sample_per_episode: 72.8
avg_envstep_per_sec: 2532.0187240193436
avg_train_sample_per_sec: 2532.0187240193436
avg_episode_per_sec: 34.78047697828769
collect_time: 1.2938292947532612
reward_mean: 142.5760394380666
reward_std: 59.65259880312412
reward_max: 234.8631465919045
reward_min: 36.00138428734681
total_envstep_count: 86880
total_train_sample_count: 81060
total_episode_count: 1587
total_duration: 32.26672898802044
[2023-06-29 09:51:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 51
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 63.27450980392157
avg_sample_per_episode: 63.27450980392157
avg_envstep_per_sec: 2536.6337077074336
avg_train_sample_per_sec: 2536.6337077074336
avg_episode_per_sec: 40.089345860886
collect_time: 1.2721584477076542
reward_mean: 124.60862674660822
reward_std: 54.63592806706492
reward_max: 231.02960350807695
reward_min: 49.64831041290323
total_envstep_count: 90384
total_train_sample_count: 84287
total_episode_count: 1638
total_duration: 33.53888743572809
[2023-06-29 09:51:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3239
train_sample_count: 3239
avg_envstep_per_episode: 73.61363636363636
avg_sample_per_episode: 73.61363636363636
avg_envstep_per_sec: 2418.155047361415
avg_train_sample_per_sec: 2418.155047361415
avg_episode_per_sec: 32.8492812855518
collect_time: 1.3394509188045054
reward_mean: 146.1953308763383
reward_std: 49.585038520071016
reward_max: 252.40971587882163
reward_min: 62.48338475981469
total_envstep_count: 93976
total_train_sample_count: 87526
total_episode_count: 1682
total_duration: 34.878338354532595
[2023-06-29 09:51:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 53
envstep_count: 3305
train_sample_count: 3305
avg_envstep_per_episode: 62.35849056603774
avg_sample_per_episode: 62.35849056603774
avg_envstep_per_sec: 2571.706326735388
avg_train_sample_per_sec: 2571.706326735388
avg_episode_per_sec: 41.24067634401681
collect_time: 1.2851389622684797
reward_mean: 118.3577840490253
reward_std: 51.06328734133392
reward_max: 260.9356199745825
reward_min: 16.48273357034219
total_envstep_count: 97448
total_train_sample_count: 90831
total_episode_count: 1735
total_duration: 36.16347731680107
[2023-06-29 09:51:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 56
envstep_count: 3268
train_sample_count: 3268
avg_envstep_per_episode: 58.357142857142854
avg_sample_per_episode: 58.357142857142854
avg_envstep_per_sec: 2465.2377857832616
avg_train_sample_per_sec: 2465.2377857832616
avg_episode_per_sec: 42.24397674536801
collect_time: 1.3256327721594137
reward_mean: 98.2739288029438
reward_std: 35.41504975867405
reward_max: 193.96056888502974
reward_min: 24.415549254654465
total_envstep_count: 101048
total_train_sample_count: 94099
total_episode_count: 1791
total_duration: 37.48911008896049
[2023-06-29 09:51:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 76.47619047619048
avg_sample_per_episode: 76.47619047619048
avg_envstep_per_sec: 2504.555893698606
avg_train_sample_per_sec: 2504.555893698606
avg_episode_per_sec: 32.74948553404154
collect_time: 1.2824628941527336
reward_mean: 127.43487673344359
reward_std: 49.35948159844806
reward_max: 235.48096377820997
reward_min: 11.318179844216626
total_envstep_count: 104744
total_train_sample_count: 97311
total_episode_count: 1833
total_duration: 38.771572983113224
[2023-06-29 09:51:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3241
train_sample_count: 3241
avg_envstep_per_episode: 73.6590909090909
avg_sample_per_episode: 73.6590909090909
avg_envstep_per_sec: 2439.085815705197
avg_train_sample_per_sec: 2439.085815705197
avg_episode_per_sec: 33.113167507259696
collect_time: 1.328776535508223
reward_mean: 127.9754190820011
reward_std: 52.25620833506918
reward_max: 274.25973184489385
reward_min: 16.06479545007181
total_envstep_count: 108160
total_train_sample_count: 100552
total_episode_count: 1877
total_duration: 40.10034951862145
[2023-06-29 09:51:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 39
envstep_count: 3308
train_sample_count: 3308
avg_envstep_per_episode: 84.82051282051282
avg_sample_per_episode: 84.82051282051282
avg_envstep_per_sec: 2680.91566674061
avg_train_sample_per_sec: 2680.91566674061
avg_episode_per_sec: 31.60692593799389
collect_time: 1.2339067733606792
reward_mean: 119.08712977087033
reward_std: 58.93155788103083
reward_max: 273.73813748575657
reward_min: 13.361020477919771
total_envstep_count: 112088
total_train_sample_count: 103860
total_episode_count: 1916
total_duration: 41.33425629198213
[2023-06-29 09:51:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 3278
train_sample_count: 3278
avg_envstep_per_episode: 76.23255813953489
avg_sample_per_episode: 76.23255813953489
avg_envstep_per_sec: 2458.2181677571716
avg_train_sample_per_sec: 2458.2181677571716
avg_episode_per_sec: 32.246302993764
collect_time: 1.3334861986602193
reward_mean: 129.99533058035902
reward_std: 58.468909865193
reward_max: 304.9039008149267
reward_min: 42.792545200109494
total_envstep_count: 115536
total_train_sample_count: 107138
total_episode_count: 1959
total_duration: 42.66774249064235
[2023-06-29 09:51:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 72.86363636363636
avg_sample_per_episode: 72.86363636363636
avg_envstep_per_sec: 2614.146544526258
avg_train_sample_per_sec: 2614.146544526258
avg_episode_per_sec: 35.87724515257497
collect_time: 1.2264040846191349
reward_mean: 89.01686262462351
reward_std: 64.10154200874076
reward_max: 311.9423132974493
reward_min: 7.248682276814021
total_envstep_count: 119032
total_train_sample_count: 110344
total_episode_count: 2003
total_duration: 43.89414657526148
[2023-06-29 09:51:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 84.94736842105263
avg_sample_per_episode: 84.94736842105263
avg_envstep_per_sec: 2386.610909155115
avg_train_sample_per_sec: 2386.610909155115
avg_episode_per_sec: 28.095171793027998
collect_time: 1.3525455647660412
reward_mean: 132.11780607163902
reward_std: 75.45191524486675
reward_max: 392.77225292600247
reward_min: 8.738497767408749
total_envstep_count: 122432
total_train_sample_count: 113572
total_episode_count: 2041
total_duration: 45.24669214002752
[2023-06-29 09:52:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 3229
train_sample_count: 3229
avg_envstep_per_episode: 80.725
avg_sample_per_episode: 80.725
avg_envstep_per_sec: 2552.716254851366
avg_train_sample_per_sec: 2552.716254851366
avg_episode_per_sec: 31.62237540850252
collect_time: 1.2649271119982002
reward_mean: 137.168517055393
reward_std: 62.74605517265541
reward_max: 269.107955798661
reward_min: 33.91260259694975
total_envstep_count: 125992
total_train_sample_count: 116801
total_episode_count: 2081
total_duration: 46.51161925202572
[2023-06-29 09:52:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 48
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 66.70833333333333
avg_sample_per_episode: 66.70833333333333
avg_envstep_per_sec: 2606.816625555233
avg_train_sample_per_sec: 2606.816625555233
avg_episode_per_sec: 39.0778257422396
collect_time: 1.228318082910031
reward_mean: 116.6581893703197
reward_std: 56.648236978961016
reward_max: 346.14575820800746
reward_min: 48.1511579296287
total_envstep_count: 129344
total_train_sample_count: 120003
total_episode_count: 2129
total_duration: 47.739937334935746
[2023-06-29 09:52:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 81.9
avg_sample_per_episode: 81.9
avg_envstep_per_sec: 2521.0087377030063
avg_train_sample_per_sec: 2521.0087377030063
avg_episode_per_sec: 30.781547468901177
collect_time: 1.299479827660136
reward_mean: 121.39630567477295
reward_std: 41.4075755983533
reward_max: 213.07676087587797
reward_min: 41.7514554826379
total_envstep_count: 132952
total_train_sample_count: 123279
total_episode_count: 2169
total_duration: 49.03941716259588
[2023-06-29 09:52:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 73.11363636363636
avg_sample_per_episode: 73.11363636363636
avg_envstep_per_sec: 2576.3594670136895
avg_train_sample_per_sec: 2576.3594670136895
avg_episode_per_sec: 35.2377421661804
collect_time: 1.2486611597444863
reward_mean: 129.03570333557158
reward_std: 51.897376962211275
reward_max: 283.1743642094293
reward_min: 18.983963733569517
total_envstep_count: 136416
total_train_sample_count: 126496
total_episode_count: 2213
total_duration: 50.28807832234037
[2023-06-29 09:52:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 52
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 62.21153846153846
avg_sample_per_episode: 62.21153846153846
avg_envstep_per_sec: 2360.68561685335
avg_train_sample_per_sec: 2360.68561685335
avg_episode_per_sec: 37.94610574231042
collect_time: 1.3703645995488622
reward_mean: 109.81488674939462
reward_std: 37.08003598715851
reward_max: 221.376453717131
reward_min: 47.87681847409467
total_envstep_count: 139976
total_train_sample_count: 129731
total_episode_count: 2265
total_duration: 51.65844292188923
[2023-06-29 09:52:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 47
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 68.14893617021276
avg_sample_per_episode: 68.14893617021276
avg_envstep_per_sec: 2597.214958024857
avg_train_sample_per_sec: 2597.214958024857
avg_episode_per_sec: 38.110865759340705
collect_time: 1.2332440909842262
reward_mean: 116.83054399433598
reward_std: 45.968792541783756
reward_max: 263.0802627921082
reward_min: 52.36289935699373
total_envstep_count: 143424
total_train_sample_count: 132934
total_episode_count: 2312
total_duration: 52.89168701287346
[2023-06-29 09:52:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 3330
train_sample_count: 3330
avg_envstep_per_episode: 81.21951219512195
avg_sample_per_episode: 81.21951219512195
avg_envstep_per_sec: 2487.9894892837397
avg_train_sample_per_sec: 2487.9894892837397
avg_episode_per_sec: 30.63290362181181
collect_time: 1.33843009158317
reward_mean: 116.89304180078926
reward_std: 43.669930735965515
reward_max: 221.99196865994242
reward_min: 29.424723473362288
total_envstep_count: 147024
total_train_sample_count: 136264
total_episode_count: 2353
total_duration: 54.23011710445663
[2023-06-29 09:52:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 76.76190476190476
avg_sample_per_episode: 76.76190476190476
avg_envstep_per_sec: 2575.276778793341
avg_train_sample_per_sec: 2575.276778793341
avg_episode_per_sec: 33.54889103887106
collect_time: 1.251904271629639
reward_mean: 128.25476749254275
reward_std: 43.42354520758563
reward_max: 263.1085051078491
reward_min: 61.58206708720862
total_envstep_count: 150536
total_train_sample_count: 139488
total_episode_count: 2395
total_duration: 55.48202137608627
[2023-06-29 09:52:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 3322
train_sample_count: 3322
avg_envstep_per_episode: 92.27777777777777
avg_sample_per_episode: 92.27777777777777
avg_envstep_per_sec: 2288.571302079427
avg_train_sample_per_sec: 2288.571302079427
avg_episode_per_sec: 24.80089309899439
collect_time: 1.4515606295428007
reward_mean: 125.02567809847197
reward_std: 63.83760197307194
reward_max: 288.09549562815135
reward_min: 7.846180914947755
total_envstep_count: 154016
total_train_sample_count: 142810
total_episode_count: 2431
total_duration: 56.93358200562908
[2023-06-29 09:52:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 38
envstep_count: 3313
train_sample_count: 3313
avg_envstep_per_episode: 87.1842105263158
avg_sample_per_episode: 87.1842105263158
avg_envstep_per_sec: 2401.3294022811615
avg_train_sample_per_sec: 2401.3294022811615
avg_episode_per_sec: 27.543168513940277
collect_time: 1.3796524528674783
reward_mean: 134.99181159373757
reward_std: 56.26589504406856
reward_max: 259.72190461672983
reward_min: 21.61333229144908
total_envstep_count: 157496
total_train_sample_count: 146123
total_episode_count: 2469
total_duration: 58.31323445849655
[2023-06-29 09:52:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 76.69047619047619
avg_sample_per_episode: 76.69047619047619
avg_envstep_per_sec: 2628.164446158312
avg_train_sample_per_sec: 2628.164446158312
avg_episode_per_sec: 34.26976303590472
collect_time: 1.225570190140978
reward_mean: 132.40680205131775
reward_std: 45.92622254245572
reward_max: 252.19119170813465
reward_min: 61.00247116736015
total_envstep_count: 161000
total_train_sample_count: 149344
total_episode_count: 2511
total_duration: 59.53880464863753
[2023-06-29 09:52:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 91.71428571428571
avg_sample_per_episode: 91.71428571428571
avg_envstep_per_sec: 2450.1114408034555
avg_train_sample_per_sec: 2450.1114408034555
avg_episode_per_sec: 26.714610725271324
collect_time: 1.310144488345133
reward_mean: 139.42463813103424
reward_std: 56.361534004504136
reward_max: 240.05232262899148
reward_min: 21.414599693872177
total_envstep_count: 164624
total_train_sample_count: 152554
total_episode_count: 2546
total_duration: 60.84894913698266
[2023-06-29 09:52:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 47
envstep_count: 3307
train_sample_count: 3307
avg_envstep_per_episode: 70.36170212765957
avg_sample_per_episode: 70.36170212765957
avg_envstep_per_sec: 2604.776970832192
avg_train_sample_per_sec: 2604.776970832192
avg_episode_per_sec: 37.01981180196947
collect_time: 1.2695904628423742
reward_mean: 119.65474045189829
reward_std: 42.238109480567395
reward_max: 232.90258647570062
reward_min: 61.679787486935055
total_envstep_count: 168336
total_train_sample_count: 155861
total_episode_count: 2593
total_duration: 62.118539599825034
[2023-06-29 09:52:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 73.1590909090909
avg_sample_per_episode: 73.1590909090909
avg_envstep_per_sec: 2388.665558886941
avg_train_sample_per_sec: 2388.665558886941
avg_episode_per_sec: 32.65029033582647
collect_time: 1.347614356486127
reward_mean: 115.27790497782168
reward_std: 53.82708726133657
reward_max: 249.335417433778
reward_min: 9.202326546117996
total_envstep_count: 171888
total_train_sample_count: 159080
total_episode_count: 2637
total_duration: 63.46615395631116
[2023-06-29 09:52:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 46
envstep_count: 3260
train_sample_count: 3260
avg_envstep_per_episode: 70.8695652173913
avg_sample_per_episode: 70.8695652173913
avg_envstep_per_sec: 2423.689893391016
avg_train_sample_per_sec: 2423.689893391016
avg_episode_per_sec: 34.19930524416771
collect_time: 1.3450565639149865
reward_mean: 118.53776275444761
reward_std: 43.149242053665695
reward_max: 254.1053767390725
reward_min: 50.26549192462928
total_envstep_count: 175560
total_train_sample_count: 162340
total_episode_count: 2683
total_duration: 64.81121052022614
[2023-06-29 09:52:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 97.33333333333333
avg_sample_per_episode: 97.33333333333333
avg_envstep_per_sec: 2601.0839551039203
avg_train_sample_per_sec: 2601.0839551039203
avg_episode_per_sec: 26.723465292163564
collect_time: 1.2348697909951438
reward_mean: 149.4295970797447
reward_std: 63.851879024358496
reward_max: 322.7248003435387
reward_min: 19.246957852364712
total_envstep_count: 179168
total_train_sample_count: 165552
total_episode_count: 2716
total_duration: 66.04608031122129
[2023-06-29 09:52:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 43
envstep_count: 3286
train_sample_count: 3286
avg_envstep_per_episode: 76.4186046511628
avg_sample_per_episode: 76.4186046511628
avg_envstep_per_sec: 2368.1184069872797
avg_train_sample_per_sec: 2368.1184069872797
avg_episode_per_sec: 30.988767955098304
collect_time: 1.3875995348477737
reward_mean: 114.78391026340074
reward_std: 42.32963307210974
reward_max: 301.15940384677947
reward_min: 65.52719315951208
total_envstep_count: 182800
total_train_sample_count: 168838
total_episode_count: 2759
total_duration: 67.43367984606907
[2023-06-29 09:52:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 73.22727272727273
avg_sample_per_episode: 73.22727272727273
avg_envstep_per_sec: 2622.092137202023
avg_train_sample_per_sec: 2622.092137202023
avg_episode_per_sec: 35.80758970729019
collect_time: 1.228789772215299
reward_mean: 121.36769658261964
reward_std: 57.90551416899905
reward_max: 266.949349250449
reward_min: 18.53417139956554
total_envstep_count: 186560
total_train_sample_count: 172060
total_episode_count: 2803
total_duration: 68.66246961828436
[2023-06-29 09:52:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 44
envstep_count: 3247
train_sample_count: 3247
avg_envstep_per_episode: 73.79545454545455
avg_sample_per_episode: 73.79545454545455
avg_envstep_per_sec: 2360.723772338055
avg_train_sample_per_sec: 2360.723772338055
avg_episode_per_sec: 31.990097315329354
collect_time: 1.3754256376993144
reward_mean: 135.9805683161513
reward_std: 68.6801408611285
reward_max: 414.3607823885187
reward_min: 57.268581206726246
total_envstep_count: 190144
total_train_sample_count: 175307
total_episode_count: 2847
total_duration: 70.03789525598367
[2023-06-29 09:52:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 3273
train_sample_count: 3273
avg_envstep_per_episode: 81.825
avg_sample_per_episode: 81.825
avg_envstep_per_sec: 2527.0895231610375
avg_train_sample_per_sec: 2527.0895231610375
avg_episode_per_sec: 30.884076054519248
collect_time: 1.2951658300992568
reward_mean: 135.31969065963534
reward_std: 52.32352194894671
reward_max: 283.7689986874104
reward_min: 16.566901879943295
total_envstep_count: 193736
total_train_sample_count: 178580
total_episode_count: 2887
total_duration: 71.33306108608292
[2023-06-29 09:52:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 47
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 68.44680851063829
avg_sample_per_episode: 68.44680851063829
avg_envstep_per_sec: 2333.3753949805205
avg_train_sample_per_sec: 2333.3753949805205
avg_episode_per_sec: 34.090346149855286
collect_time: 1.3786894328792116
reward_mean: 117.74751162480608
reward_std: 42.21148650905213
reward_max: 238.99938457990612
reward_min: 52.21283787456548
total_envstep_count: 197088
total_train_sample_count: 181797
total_episode_count: 2934
total_duration: 72.71175051896213
[2023-06-29 09:52:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 3252
train_sample_count: 3252
avg_envstep_per_episode: 81.3
avg_sample_per_episode: 81.3
avg_envstep_per_sec: 2436.617892009017
avg_train_sample_per_sec: 2436.617892009017
avg_episode_per_sec: 29.9706997787087
collect_time: 1.3346368384903764
reward_mean: 138.47533858224455
reward_std: 44.57106455344019
reward_max: 231.48607617741564
reward_min: 66.21911307802426
total_envstep_count: 200504
total_train_sample_count: 185049
total_episode_count: 2974
total_duration: 74.04638735745252
[2023-06-29 09:52:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 45
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 71.68888888888888
avg_sample_per_episode: 71.68888888888888
avg_envstep_per_sec: 2568.5743701723986
avg_train_sample_per_sec: 2568.5743701723986
avg_episode_per_sec: 35.829462696143196
collect_time: 1.2559496183805166
reward_mean: 125.46335502861639
reward_std: 48.5728956065186
reward_max: 259.80233887564947
reward_min: 56.89305822163139
total_envstep_count: 204216
total_train_sample_count: 188275
total_episode_count: 3019
total_duration: 75.30233697583303
[2023-06-29 09:53:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 41
envstep_count: 3256
train_sample_count: 3256
avg_envstep_per_episode: 79.41463414634147
avg_sample_per_episode: 79.41463414634147
avg_envstep_per_sec: 2393.650846174533
avg_train_sample_per_sec: 2393.650846174533
avg_episode_per_sec: 30.141180802566293
collect_time: 1.3602652221411697
reward_mean: 143.50110616827914
reward_std: 55.69506531588635
reward_max: 256.9012680932089
reward_min: 18.651487737155605
total_envstep_count: 207744
total_train_sample_count: 191531
total_episode_count: 3060
total_duration: 76.6626021979742
[2023-06-29 09:53:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 42
envstep_count: 3270
train_sample_count: 3270
avg_envstep_per_episode: 77.85714285714286
avg_sample_per_episode: 77.85714285714286
avg_envstep_per_sec: 2497.4525071289872
avg_train_sample_per_sec: 2497.4525071289872
avg_episode_per_sec: 32.077371651198
collect_time: 1.309334207824082
reward_mean: 138.03383172637047
reward_std: 52.99020651652195
reward_max: 252.69288469957164
reward_min: 21.354044720316868
total_envstep_count: 211344
total_train_sample_count: 194801
total_episode_count: 3102
total_duration: 77.97193640579827
[2023-06-29 09:53:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 40
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 82.325
avg_sample_per_episode: 82.325
avg_envstep_per_sec: 2440.589729119617
avg_train_sample_per_sec: 2440.589729119617
avg_episode_per_sec: 29.645790818337286
collect_time: 1.3492640572522072
reward_mean: 144.72680094913034
reward_std: 51.96663464943549
reward_max: 284.2676985038206
reward_min: 60.46819301058288
total_envstep_count: 215032
total_train_sample_count: 198094
total_episode_count: 3142
total_duration: 79.32120046305049
[2023-06-29 09:53:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 37
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 86.67567567567568
avg_sample_per_episode: 86.67567567567568
avg_envstep_per_sec: 2608.225341929216
avg_train_sample_per_sec: 2608.225341929216
avg_episode_per_sec: 30.091779747858123
collect_time: 1.229571674059378
reward_mean: 169.03407084049257
reward_std: 56.72448191397129
reward_max: 259.9604853493352
reward_min: 60.38899119343846
total_envstep_count: 218584
total_train_sample_count: 201301
total_episode_count: 3179
total_duration: 80.55077213710986
[2023-06-29 09:53:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 3254
train_sample_count: 3254
avg_envstep_per_episode: 116.21428571428571
avg_sample_per_episode: 116.21428571428571
avg_envstep_per_sec: 2470.3919998665333
avg_train_sample_per_sec: 2470.3919998665333
avg_episode_per_sec: 21.257214504075883
collect_time: 1.3171998614696787
reward_mean: 204.85827984833324
reward_std: 78.44703054270674
reward_max: 418.56044929807285
reward_min: 79.99586545322019
total_envstep_count: 222360
total_train_sample_count: 204555
total_episode_count: 3207
total_duration: 81.86797199857953
[2023-06-29 09:53:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 36
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 89.52777777777777
avg_sample_per_episode: 89.52777777777777
avg_envstep_per_sec: 2574.879785223383
avg_train_sample_per_sec: 2574.879785223383
avg_episode_per_sec: 28.760680194862484
collect_time: 1.251708921906189
reward_mean: 185.33091578698685
reward_std: 56.914700091212005
reward_max: 307.9227574022833
reward_min: 68.3192593327485
total_envstep_count: 225984
total_train_sample_count: 207778
total_episode_count: 3243
total_duration: 83.11968092048572
[2023-06-29 09:53:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 31
envstep_count: 3280
train_sample_count: 3280
avg_envstep_per_episode: 105.80645161290323
avg_sample_per_episode: 105.80645161290323
avg_envstep_per_sec: 2546.3795312896573
avg_train_sample_per_sec: 2546.3795312896573
avg_episode_per_sec: 24.06639191157908
collect_time: 1.2881033481834454
reward_mean: 217.4023071356766
reward_std: 33.33788534548821
reward_max: 282.62866391853555
reward_min: 116.74054924758319
total_envstep_count: 229696
total_train_sample_count: 211058
total_episode_count: 3274
total_duration: 84.40778426866916
[2023-06-29 09:53:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 100.03125
avg_sample_per_episode: 100.03125
avg_envstep_per_sec: 2475.317843919525
avg_train_sample_per_sec: 2475.317843919525
avg_episode_per_sec: 24.74544548748041
collect_time: 1.2931672624843196
reward_mean: 215.24664508050734
reward_std: 36.99651447135627
reward_max: 279.6842763932263
reward_min: 106.47967875257321
total_envstep_count: 233272
total_train_sample_count: 214259
total_episode_count: 3306
total_duration: 85.70095153115348
[2023-06-29 09:53:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 34
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 94.88235294117646
avg_sample_per_episode: 94.88235294117646
avg_envstep_per_sec: 2563.2446526339418
avg_train_sample_per_sec: 2563.2446526339418
avg_episode_per_sec: 27.01497774009734
collect_time: 1.2585610962593927
reward_mean: 216.61318318850613
reward_std: 39.45733575004699
reward_max: 269.6819482888363
reward_min: 54.028382828413726
total_envstep_count: 236880
total_train_sample_count: 217485
total_episode_count: 3340
total_duration: 86.95951262741288
[2023-06-29 09:53:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 3320
train_sample_count: 3320
avg_envstep_per_episode: 100.60606060606061
avg_sample_per_episode: 100.60606060606061
avg_envstep_per_sec: 2374.7276789907364
avg_train_sample_per_sec: 2374.7276789907364
avg_episode_per_sec: 23.60422090563081
collect_time: 1.3980550398987248
reward_mean: 224.24788319798017
reward_std: 33.37761587424558
reward_max: 287.0453910921175
reward_min: 88.03668288874563
total_envstep_count: 240592
total_train_sample_count: 220805
total_episode_count: 3373
total_duration: 88.3575676673116
[2023-06-29 09:53:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 35
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 92.37142857142857
avg_sample_per_episode: 92.37142857142857
avg_envstep_per_sec: 2632.1589888387657
avg_train_sample_per_sec: 2632.1589888387657
avg_episode_per_sec: 28.49538033076301
collect_time: 1.2282692700969056
reward_mean: 203.81757328103367
reward_std: 43.38419456327301
reward_max: 302.62570080897694
reward_min: 105.60084674022912
total_envstep_count: 244264
total_train_sample_count: 224038
total_episode_count: 3408
total_duration: 89.5858369374085
[2023-06-29 09:53:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 3333
train_sample_count: 3333
avg_envstep_per_episode: 101.0
avg_sample_per_episode: 101.0
avg_envstep_per_sec: 2448.8308420296034
avg_train_sample_per_sec: 2448.8308420296034
avg_episode_per_sec: 24.24584992108518
collect_time: 1.3610576699685768
reward_mean: 229.7186545544523
reward_std: 27.244754868350412
reward_max: 273.06283673334667
reward_min: 105.07693238713576
total_envstep_count: 248008
total_train_sample_count: 227371
total_episode_count: 3441
total_duration: 90.94689460737708
[2023-06-29 09:53:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 3265
train_sample_count: 3265
avg_envstep_per_episode: 98.93939393939394
avg_sample_per_episode: 98.93939393939394
avg_envstep_per_sec: 2533.021559688477
avg_train_sample_per_sec: 2533.021559688477
avg_episode_per_sec: 25.601749301598694
collect_time: 1.2889744216790422
reward_mean: 227.86094921039899
reward_std: 18.35295694147059
reward_max: 263.33900270115987
reward_min: 191.18676661679504
total_envstep_count: 251792
total_train_sample_count: 230636
total_episode_count: 3474
total_duration: 92.23586902905612
[2023-06-29 09:53:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3277
train_sample_count: 3277
avg_envstep_per_episode: 102.40625
avg_sample_per_episode: 102.40625
avg_envstep_per_sec: 2660.236132323156
avg_train_sample_per_sec: 2660.236132323156
avg_episode_per_sec: 25.977282952194386
collect_time: 1.2318455343805252
reward_mean: 231.7476862080344
reward_std: 36.36869187648822
reward_max: 300.4599753724966
reward_min: 122.95382046874472
total_envstep_count: 255488
total_train_sample_count: 233913
total_episode_count: 3506
total_duration: 93.46771456343664
[2023-06-29 09:53:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3261
train_sample_count: 3261
avg_envstep_per_episode: 101.90625
avg_sample_per_episode: 101.90625
avg_envstep_per_sec: 2485.2110261755256
avg_train_sample_per_sec: 2485.2110261755256
avg_episode_per_sec: 24.38722871438725
collect_time: 1.312162213048898
reward_mean: 224.14094706019554
reward_std: 40.85103380142945
reward_max: 333.09061055251675
reward_min: 85.89293957952681
total_envstep_count: 259016
total_train_sample_count: 237174
total_episode_count: 3538
total_duration: 94.77987677648554
[2023-06-29 09:53:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3300
train_sample_count: 3300
avg_envstep_per_episode: 103.125
avg_sample_per_episode: 103.125
avg_envstep_per_sec: 2475.1229972042765
avg_train_sample_per_sec: 2475.1229972042765
avg_episode_per_sec: 24.00119270016268
collect_time: 1.3332670755059228
reward_mean: 233.08743738292333
reward_std: 15.875442647499133
reward_max: 279.5277059437982
reward_min: 206.0976533363136
total_envstep_count: 262632
total_train_sample_count: 240474
total_episode_count: 3570
total_duration: 96.11314385199147
[2023-06-29 09:53:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3303
train_sample_count: 3303
avg_envstep_per_episode: 103.21875
avg_sample_per_episode: 103.21875
avg_envstep_per_sec: 2403.0223509033717
avg_train_sample_per_sec: 2403.0223509033717
avg_episode_per_sec: 23.280870490132575
collect_time: 1.3745190504608908
reward_mean: 229.80615805989544
reward_std: 24.616845097634837
reward_max: 272.1695174046082
reward_min: 157.70931872141875
total_envstep_count: 266096
total_train_sample_count: 243777
total_episode_count: 3602
total_duration: 97.48766290245236
[2023-06-29 09:53:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 3292
train_sample_count: 3292
avg_envstep_per_episode: 117.57142857142857
avg_sample_per_episode: 117.57142857142857
avg_envstep_per_sec: 2469.5551130458425
avg_train_sample_per_sec: 2469.5551130458425
avg_episode_per_sec: 21.004721496137176
collect_time: 1.3330336231855906
reward_mean: 242.78612909861104
reward_std: 33.76388218224595
reward_max: 294.72034614475166
reward_min: 129.87210632155808
total_envstep_count: 270056
total_train_sample_count: 247069
total_episode_count: 3630
total_duration: 98.82069652563794
[2023-06-29 09:53:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 30
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 107.0
avg_sample_per_episode: 107.0
avg_envstep_per_sec: 2622.29640506603
avg_train_sample_per_sec: 2622.29640506603
avg_episode_per_sec: 24.507443038000282
collect_time: 1.2241179119944572
reward_mean: 252.3731658931154
reward_std: 30.277342550774875
reward_max: 335.9009918283621
reward_min: 208.90319461538007
total_envstep_count: 273696
total_train_sample_count: 250279
total_episode_count: 3660
total_duration: 100.0448144376324
[2023-06-29 09:53:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3290
train_sample_count: 3290
avg_envstep_per_episode: 102.8125
avg_sample_per_episode: 102.8125
avg_envstep_per_sec: 2281.7883838406306
avg_train_sample_per_sec: 2281.7883838406306
avg_episode_per_sec: 22.193686408176347
collect_time: 1.4418514982806516
reward_mean: 240.13337998712694
reward_std: 17.327372566921262
reward_max: 288.2884541694535
reward_min: 216.87889372867653
total_envstep_count: 277200
total_train_sample_count: 253569
total_episode_count: 3692
total_duration: 101.48666593591305
[2023-06-29 09:53:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 119.0
avg_sample_per_episode: 119.0
avg_envstep_per_sec: 2219.3139503960037
avg_train_sample_per_sec: 2219.3139503960037
avg_episode_per_sec: 18.64969706215129
collect_time: 1.4477446957996583
reward_mean: 251.57273460958876
reward_std: 46.99540152811958
reward_max: 454.28409457376654
reward_min: 165.830991755115
total_envstep_count: 280776
total_train_sample_count: 256782
total_episode_count: 3719
total_duration: 102.93441063171271
[2023-06-29 09:54:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 29
envstep_count: 3270
train_sample_count: 3270
avg_envstep_per_episode: 112.75862068965517
avg_sample_per_episode: 112.75862068965517
avg_envstep_per_sec: 2504.281823951136
avg_train_sample_per_sec: 2504.281823951136
avg_episode_per_sec: 22.20922718488775
collect_time: 1.3057635800912974
reward_mean: 248.12767081818834
reward_std: 43.45237989576144
reward_max: 347.4904673249934
reward_min: 87.6965492623025
total_envstep_count: 284584
total_train_sample_count: 260052
total_episode_count: 3748
total_duration: 104.240174211804
[2023-06-29 09:54:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 30
envstep_count: 3277
train_sample_count: 3277
avg_envstep_per_episode: 109.23333333333333
avg_sample_per_episode: 109.23333333333333
avg_envstep_per_sec: 2355.8701531655174
avg_train_sample_per_sec: 2355.8701531655174
avg_episode_per_sec: 21.567319070785942
collect_time: 1.3909934703306062
reward_mean: 252.35853051212152
reward_std: 32.16171212484345
reward_max: 329.50369681036193
reward_min: 215.51011478957378
total_envstep_count: 288496
total_train_sample_count: 263329
total_episode_count: 3778
total_duration: 105.6311676821346
[2023-06-29 09:54:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 128.52
avg_sample_per_episode: 128.52
avg_envstep_per_sec: 2650.657734027279
avg_train_sample_per_sec: 2650.657734027279
avg_episode_per_sec: 20.62447661085651
collect_time: 1.2121519722270313
reward_mean: 284.09713697205245
reward_std: 56.76205830922532
reward_max: 411.5593538968221
reward_min: 225.5297562899314
total_envstep_count: 292232
total_train_sample_count: 266542
total_episode_count: 3803
total_duration: 106.84331965436164
[2023-06-29 09:54:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 129.2
avg_sample_per_episode: 129.2
avg_envstep_per_sec: 2511.8411889102476
avg_train_sample_per_sec: 2511.8411889102476
avg_episode_per_sec: 19.441495270203156
collect_time: 1.2859093219190831
reward_mean: 276.5853355224484
reward_std: 66.63483053344574
reward_max: 397.11022235971694
reward_min: 75.90936964605521
total_envstep_count: 295928
total_train_sample_count: 269772
total_episode_count: 3828
total_duration: 108.12922897628071
[2023-06-29 09:54:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 29
envstep_count: 3307
train_sample_count: 3307
avg_envstep_per_episode: 114.03448275862068
avg_sample_per_episode: 114.03448275862068
avg_envstep_per_sec: 2426.1459451684227
avg_train_sample_per_sec: 2426.1459451684227
avg_episode_per_sec: 21.275546540636306
collect_time: 1.3630672163749111
reward_mean: 254.04268405244267
reward_std: 38.89208960874564
reward_max: 331.6151822528585
reward_min: 131.4252984164627
total_envstep_count: 299624
total_train_sample_count: 273079
total_episode_count: 3857
total_duration: 109.49229619265563
[2023-06-29 09:54:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 29
envstep_count: 3256
train_sample_count: 3256
avg_envstep_per_episode: 112.27586206896552
avg_sample_per_episode: 112.27586206896552
avg_envstep_per_sec: 2551.815603268224
avg_train_sample_per_sec: 2551.815603268224
avg_episode_per_sec: 22.72808737554622
collect_time: 1.2759542640267172
reward_mean: 247.70720354940426
reward_std: 57.07505481561784
reward_max: 405.4027380903536
reward_min: 80.15062461359943
total_envstep_count: 303368
total_train_sample_count: 276335
total_episode_count: 3886
total_duration: 110.76825045668235
[2023-06-29 09:54:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 32
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 101.03125
avg_sample_per_episode: 101.03125
avg_envstep_per_sec: 2488.30530531303
avg_train_sample_per_sec: 2488.30530531303
avg_episode_per_sec: 24.62906581194462
collect_time: 1.2992778631693216
reward_mean: 231.63355326253455
reward_std: 38.97217013481963
reward_max: 286.0579804374207
reward_min: 77.46507015941454
total_envstep_count: 307024
total_train_sample_count: 279568
total_episode_count: 3918
total_duration: 112.06752831985168
[2023-06-29 09:54:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 3242
train_sample_count: 3242
avg_envstep_per_episode: 98.24242424242425
avg_sample_per_episode: 98.24242424242425
avg_envstep_per_sec: 2414.5816013628178
avg_train_sample_per_sec: 2414.5816013628178
avg_episode_per_sec: 24.577789279757244
collect_time: 1.3426756826814956
reward_mean: 231.92149384214352
reward_std: 26.56749554735667
reward_max: 292.238617088879
reward_min: 130.69971153325557
total_envstep_count: 310648
total_train_sample_count: 282810
total_episode_count: 3951
total_duration: 113.41020400253318
[2023-06-29 09:54:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 33
envstep_count: 3241
train_sample_count: 3241
avg_envstep_per_episode: 98.21212121212122
avg_sample_per_episode: 98.21212121212122
avg_envstep_per_sec: 2616.694683071662
avg_train_sample_per_sec: 2616.694683071662
avg_episode_per_sec: 26.643296680458146
collect_time: 1.2385854646960508
reward_mean: 229.24454470693533
reward_std: 14.95934889237411
reward_max: 262.9781585608253
reward_min: 201.68191575307694
total_envstep_count: 314312
total_train_sample_count: 286051
total_episode_count: 3984
total_duration: 114.64878946722922
[2023-06-29 09:54:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 30
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 107.6
avg_sample_per_episode: 107.6
avg_envstep_per_sec: 2395.811835127903
avg_train_sample_per_sec: 2395.811835127903
avg_episode_per_sec: 22.26590924840059
collect_time: 1.3473512204382567
reward_mean: 250.16079899091397
reward_std: 24.222825570657342
reward_max: 304.63829619553286
reward_min: 212.28722129083104
total_envstep_count: 318160
total_train_sample_count: 289279
total_episode_count: 4014
total_duration: 115.99614068766748
[2023-06-29 09:54:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 3335
train_sample_count: 3335
avg_envstep_per_episode: 119.10714285714286
avg_sample_per_episode: 119.10714285714286
avg_envstep_per_sec: 2461.4826249177045
avg_train_sample_per_sec: 2461.4826249177045
avg_episode_per_sec: 20.666120988814313
collect_time: 1.354874483467662
reward_mean: 264.7914720563228
reward_std: 39.854791798254624
reward_max: 377.4881900238072
reward_min: 153.36450327938013
total_envstep_count: 322128
total_train_sample_count: 292614
total_episode_count: 4042
total_duration: 117.35101517113515
[2023-06-29 09:54:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3288
train_sample_count: 3288
avg_envstep_per_episode: 121.77777777777777
avg_sample_per_episode: 121.77777777777777
avg_envstep_per_sec: 2679.597240403015
avg_train_sample_per_sec: 2679.597240403015
avg_episode_per_sec: 22.003991937615996
collect_time: 1.2270500769382344
reward_mean: 262.80244776328595
reward_std: 86.28679972297442
reward_max: 521.2416857115948
reward_min: 85.29739652367475
total_envstep_count: 325960
total_train_sample_count: 295902
total_episode_count: 4069
total_duration: 118.57806524807339
[2023-06-29 09:54:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 31
envstep_count: 3313
train_sample_count: 3313
avg_envstep_per_episode: 106.87096774193549
avg_sample_per_episode: 106.87096774193549
avg_envstep_per_sec: 2536.6698408666093
avg_train_sample_per_sec: 2536.6698408666093
avg_episode_per_sec: 23.735818009919978
collect_time: 1.3060430437680337
reward_mean: 245.3331317779883
reward_std: 50.34886706315292
reward_max: 390.72878950827516
reward_min: 99.7245252443563
total_envstep_count: 329648
total_train_sample_count: 299215
total_episode_count: 4100
total_duration: 119.88410829184141
[2023-06-29 09:54:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 31
envstep_count: 3234
train_sample_count: 3234
avg_envstep_per_episode: 104.3225806451613
avg_sample_per_episode: 104.3225806451613
avg_envstep_per_sec: 2660.181838357641
avg_train_sample_per_sec: 2660.181838357641
avg_episode_per_sec: 25.499578537132614
collect_time: 1.2157063676506514
reward_mean: 239.4249481028121
reward_std: 36.3699837071019
reward_max: 309.95067989235247
reward_min: 105.36077568132004
total_envstep_count: 333512
total_train_sample_count: 302449
total_episode_count: 4131
total_duration: 121.09981465949207
[2023-06-29 09:54:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 30
envstep_count: 3262
train_sample_count: 3262
avg_envstep_per_episode: 108.73333333333333
avg_sample_per_episode: 108.73333333333333
avg_envstep_per_sec: 2425.6431637974583
avg_train_sample_per_sec: 2425.6431637974583
avg_episode_per_sec: 22.30818360328748
collect_time: 1.344797968920204
reward_mean: 253.13144481229418
reward_std: 53.38857121815648
reward_max: 378.29959593783013
reward_min: 88.921442527709
total_envstep_count: 337160
total_train_sample_count: 305711
total_episode_count: 4161
total_duration: 122.44461262841227
[2023-06-29 09:54:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3335
train_sample_count: 3335
avg_envstep_per_episode: 123.51851851851852
avg_sample_per_episode: 123.51851851851852
avg_envstep_per_sec: 2498.4151324617274
avg_train_sample_per_sec: 2498.4151324617274
avg_episode_per_sec: 20.227049048415783
collect_time: 1.334846221778193
reward_mean: 269.8553980881485
reward_std: 43.462545391519186
reward_max: 364.43525186847205
reward_min: 175.91561963690742
total_envstep_count: 341272
total_train_sample_count: 309046
total_episode_count: 4188
total_duration: 123.77945885019047
[2023-06-29 09:54:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 29
envstep_count: 3285
train_sample_count: 3285
avg_envstep_per_episode: 113.27586206896552
avg_sample_per_episode: 113.27586206896552
avg_envstep_per_sec: 2614.532782005426
avg_train_sample_per_sec: 2614.532782005426
avg_episode_per_sec: 23.081111317551706
collect_time: 1.256438635081984
reward_mean: 266.15496678236764
reward_std: 56.09633079683782
reward_max: 372.44684171975337
reward_min: 118.10400601302732
total_envstep_count: 345168
total_train_sample_count: 312331
total_episode_count: 4217
total_duration: 125.03589748527244
[2023-06-29 09:54:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3287
train_sample_count: 3287
avg_envstep_per_episode: 121.74074074074075
avg_sample_per_episode: 121.74074074074075
avg_envstep_per_sec: 2530.404308777965
avg_train_sample_per_sec: 2530.404308777965
avg_episode_per_sec: 20.785189028599042
collect_time: 1.2990018980751048
reward_mean: 283.12915669213044
reward_std: 78.20190957287694
reward_max: 540.5498534313456
reward_min: 82.26122673139477
total_envstep_count: 348848
total_train_sample_count: 315618
total_episode_count: 4244
total_duration: 126.33489938334755
[2023-06-29 09:54:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 22
envstep_count: 2971
train_sample_count: 2971
avg_envstep_per_episode: 135.04545454545453
avg_sample_per_episode: 135.04545454545453
avg_envstep_per_sec: 2677.02924136006
avg_train_sample_per_sec: 2677.02924136006
avg_episode_per_sec: 19.823171763689437
collect_time: 1.109812307649874
reward_mean: 289.8382387511035
reward_std: 85.08800063021424
reward_max: 425.13513822088294
reward_min: 73.79919476811304
total_envstep_count: 352760
total_train_sample_count: 318989
total_episode_count: 4266
total_duration: 127.44471169099742
[2023-06-29 09:54:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3257
train_sample_count: 3257
avg_envstep_per_episode: 125.26923076923077
avg_sample_per_episode: 125.26923076923077
avg_envstep_per_sec: 2554.177048612876
avg_train_sample_per_sec: 2554.177048612876
avg_episode_per_sec: 20.389500541582677
collect_time: 1.2751661055637522
reward_mean: 309.453980619226
reward_std: 79.91796113213145
reward_max: 576.2044689616808
reward_min: 231.8428271218598
total_envstep_count: 356640
total_train_sample_count: 322246
total_episode_count: 4292
total_duration: 128.71987779656118
[2023-06-29 09:54:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3283
train_sample_count: 3283
avg_envstep_per_episode: 121.5925925925926
avg_sample_per_episode: 121.5925925925926
avg_envstep_per_sec: 2466.564141029177
avg_train_sample_per_sec: 2466.564141029177
avg_episode_per_sec: 20.28548029478763
collect_time: 1.331001268278458
reward_mean: 299.6069844338945
reward_std: 61.734365703150196
reward_max: 388.34603461908944
reward_min: 65.57334823376198
total_envstep_count: 360392
total_train_sample_count: 325529
total_episode_count: 4319
total_duration: 130.05087906483965
[2023-06-29 09:54:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 24
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 133.54166666666666
avg_sample_per_episode: 133.54166666666666
avg_envstep_per_sec: 2567.865719087681
avg_train_sample_per_sec: 2567.865719087681
avg_episode_per_sec: 19.228947662435054
collect_time: 1.248118223696947
reward_mean: 320.7031211497668
reward_std: 68.931255765903
reward_max: 408.9283604651032
reward_min: 83.59748184165181
total_envstep_count: 364232
total_train_sample_count: 328734
total_episode_count: 4343
total_duration: 131.29899728853658
[2023-06-29 09:55:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 24
envstep_count: 3247
train_sample_count: 3247
avg_envstep_per_episode: 135.29166666666666
avg_sample_per_episode: 135.29166666666666
avg_envstep_per_sec: 2051.2306378075978
avg_train_sample_per_sec: 2051.2306378075978
avg_episode_per_sec: 15.161544597284369
collect_time: 1.5829521752222206
reward_mean: 332.2275844679612
reward_std: 59.8362296534172
reward_max: 470.7122479636256
reward_min: 114.31938933453998
total_envstep_count: 367736
total_train_sample_count: 331981
total_episode_count: 4367
total_duration: 132.88194946375881
[2023-06-29 09:55:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 24
envstep_count: 3288
train_sample_count: 3288
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 2486.6934580275397
avg_train_sample_per_sec: 2486.6934580275397
avg_episode_per_sec: 18.15104713888715
collect_time: 1.3222377649266273
reward_mean: 322.2669821017903
reward_std: 58.097354675779826
reward_max: 390.3972198452605
reward_min: 79.95928742237389
total_envstep_count: 371512
total_train_sample_count: 335269
total_episode_count: 4391
total_duration: 134.20418722868544
[2023-06-29 09:55:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3320
train_sample_count: 3320
avg_envstep_per_episode: 122.96296296296296
avg_sample_per_episode: 122.96296296296296
avg_envstep_per_sec: 2611.208173090048
avg_train_sample_per_sec: 2611.208173090048
avg_episode_per_sec: 21.235729118503404
collect_time: 1.2714420988010247
reward_mean: 313.6122075125353
reward_std: 87.23654275321586
reward_max: 400.7358308374682
reward_min: 51.009729750441466
total_envstep_count: 375352
total_train_sample_count: 338589
total_episode_count: 4418
total_duration: 135.47562932748647
[2023-06-29 09:55:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3263
train_sample_count: 3263
avg_envstep_per_episode: 125.5
avg_sample_per_episode: 125.5
avg_envstep_per_sec: 2352.778433892084
avg_train_sample_per_sec: 2352.778433892084
avg_episode_per_sec: 18.7472385170684
collect_time: 1.3868709237538281
reward_mean: 335.26435383002115
reward_std: 22.1204399125839
reward_max: 380.08799626298327
reward_min: 269.78635409785613
total_envstep_count: 379176
total_train_sample_count: 341852
total_episode_count: 4444
total_duration: 136.8625002512403
[2023-06-29 09:55:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3350
train_sample_count: 3350
avg_envstep_per_episode: 124.07407407407408
avg_sample_per_episode: 124.07407407407408
avg_envstep_per_sec: 2373.9130729400217
avg_train_sample_per_sec: 2373.9130729400217
avg_episode_per_sec: 19.133030737128532
collect_time: 1.4111721436586233
reward_mean: 331.0340909914274
reward_std: 41.92488541188117
reward_max: 403.3287647269338
reward_min: 160.535870973518
total_envstep_count: 383032
total_train_sample_count: 345202
total_episode_count: 4471
total_duration: 138.27367239489894
[2023-06-29 09:55:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 126.65384615384616
avg_sample_per_episode: 126.65384615384616
avg_envstep_per_sec: 2443.446878977258
avg_train_sample_per_sec: 2443.446878977258
avg_episode_per_sec: 19.29232276143599
collect_time: 1.3476863476476866
reward_mean: 338.50884938098955
reward_std: 20.28608589156913
reward_max: 394.5276655544887
reward_min: 294.38224505634906
total_envstep_count: 386992
total_train_sample_count: 348495
total_episode_count: 4497
total_duration: 139.62135874254662
[2023-06-29 09:55:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 29
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 110.6896551724138
avg_sample_per_episode: 110.6896551724138
avg_envstep_per_sec: 2397.317916312393
avg_train_sample_per_sec: 2397.317916312393
avg_episode_per_sec: 21.65801232805589
collect_time: 1.3389963751398029
reward_mean: 329.2762238922872
reward_std: 21.46278556069628
reward_max: 376.06887782427776
reward_min: 288.6776134779801
total_envstep_count: 390752
total_train_sample_count: 351705
total_episode_count: 4526
total_duration: 140.96035511768642
[2023-06-29 09:55:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 3252
train_sample_count: 3252
avg_envstep_per_episode: 116.14285714285714
avg_sample_per_episode: 116.14285714285714
avg_envstep_per_sec: 2571.208035471574
avg_train_sample_per_sec: 2571.208035471574
avg_episode_per_sec: 22.13832256863594
collect_time: 1.2647751388205213
reward_mean: 343.68741797559284
reward_std: 16.96310366059406
reward_max: 371.2786789833881
reward_min: 298.7256266889517
total_envstep_count: 394480
total_train_sample_count: 354957
total_episode_count: 4554
total_duration: 142.22513025650693
[2023-06-29 09:55:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3331
train_sample_count: 3331
avg_envstep_per_episode: 123.37037037037037
avg_sample_per_episode: 123.37037037037037
avg_envstep_per_sec: 2337.0230219589525
avg_train_sample_per_sec: 2337.0230219589525
avg_episode_per_sec: 18.943146680543897
collect_time: 1.4253175808289087
reward_mean: 348.1299985367136
reward_std: 17.92690999227199
reward_max: 389.9918223097834
reward_min: 304.9754572048315
total_envstep_count: 398336
total_train_sample_count: 358288
total_episode_count: 4581
total_duration: 143.65044783733583
[2023-06-29 09:55:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3277
train_sample_count: 3277
avg_envstep_per_episode: 121.37037037037037
avg_sample_per_episode: 121.37037037037037
avg_envstep_per_sec: 2458.176863657311
avg_train_sample_per_sec: 2458.176863657311
avg_episode_per_sec: 20.253517033490205
collect_time: 1.333101799324737
reward_mean: 353.7257741779057
reward_std: 20.61233944801372
reward_max: 418.60952242157265
reward_min: 320.7279013206079
total_envstep_count: 402208
total_train_sample_count: 361565
total_episode_count: 4608
total_duration: 144.98354963666057
[2023-06-29 09:55:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 117.46428571428571
avg_sample_per_episode: 117.46428571428571
avg_envstep_per_sec: 2661.764072282541
avg_train_sample_per_sec: 2661.764072282541
avg_episode_per_sec: 22.66019885190366
collect_time: 1.235646702970029
reward_mean: 350.11072101395365
reward_std: 39.03578532076775
reward_max: 388.07394240903204
reward_min: 160.955459418122
total_envstep_count: 406128
total_train_sample_count: 364854
total_episode_count: 4636
total_duration: 146.2191963396306
[2023-06-29 09:55:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 3295
train_sample_count: 3295
avg_envstep_per_episode: 117.67857142857143
avg_sample_per_episode: 117.67857142857143
avg_envstep_per_sec: 2722.616110971057
avg_train_sample_per_sec: 2722.616110971057
avg_episode_per_sec: 23.136039789738874
collect_time: 1.2102330500148237
reward_mean: 366.9787999353234
reward_std: 13.830501155106372
reward_max: 388.5051607209104
reward_min: 336.23011440605677
total_envstep_count: 409880
total_train_sample_count: 368149
total_episode_count: 4664
total_duration: 147.42942938964543
[2023-06-29 09:55:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 123.4074074074074
avg_sample_per_episode: 123.4074074074074
avg_envstep_per_sec: 2326.7389194825905
avg_train_sample_per_sec: 2326.7389194825905
avg_episode_per_sec: 18.854126898568413
collect_time: 1.4320472194366158
reward_mean: 369.75696249178617
reward_std: 16.76915190530343
reward_max: 399.6716642729175
reward_min: 338.09101779090645
total_envstep_count: 413616
total_train_sample_count: 371481
total_episode_count: 4691
total_duration: 148.86147660908205
[2023-06-29 09:55:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 128.56
avg_sample_per_episode: 128.56
avg_envstep_per_sec: 2619.1962466457258
avg_train_sample_per_sec: 2619.1962466457258
avg_episode_per_sec: 20.373337326117966
collect_time: 1.2270940003506838
reward_mean: 388.0513989348313
reward_std: 20.15734629040817
reward_max: 421.74828948068114
reward_min: 323.6577499339847
total_envstep_count: 417344
total_train_sample_count: 374695
total_episode_count: 4716
total_duration: 150.08857060943274
[2023-06-29 09:55:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3247
train_sample_count: 3247
avg_envstep_per_episode: 124.88461538461539
avg_sample_per_episode: 124.88461538461539
avg_envstep_per_sec: 2474.4898706744475
avg_train_sample_per_sec: 2474.4898706744475
avg_episode_per_sec: 19.814209004476634
collect_time: 1.3121896510794757
reward_mean: 394.96075767299266
reward_std: 14.833536426213774
reward_max: 416.8064706658445
reward_min: 350.18163414455495
total_envstep_count: 421208
total_train_sample_count: 377942
total_episode_count: 4742
total_duration: 151.40076026051221
[2023-06-29 09:55:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 123.1923076923077
avg_sample_per_episode: 123.1923076923077
avg_envstep_per_sec: 2556.9180641731186
avg_train_sample_per_sec: 2556.9180641731186
avg_episode_per_sec: 20.755500989229187
collect_time: 1.2526799528227424
reward_mean: 403.44401843099143
reward_std: 18.475722724318537
reward_max: 464.411982483904
reward_min: 381.84735520274745
total_envstep_count: 425096
total_train_sample_count: 381145
total_episode_count: 4768
total_duration: 152.65344021333496
[2023-06-29 09:55:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 27
envstep_count: 3252
train_sample_count: 3252
avg_envstep_per_episode: 120.44444444444444
avg_sample_per_episode: 120.44444444444444
avg_envstep_per_sec: 2634.9055297963796
avg_train_sample_per_sec: 2634.9055297963796
avg_episode_per_sec: 21.876521926353703
collect_time: 1.2341998463418566
reward_mean: 398.7508151691081
reward_std: 60.336456886140674
reward_max: 478.9199571136177
reward_min: 194.9716605485976
total_envstep_count: 428728
total_train_sample_count: 384397
total_episode_count: 4795
total_duration: 153.8876400596768
[2023-06-29 09:55:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3257
train_sample_count: 3257
avg_envstep_per_episode: 130.28
avg_sample_per_episode: 130.28
avg_envstep_per_sec: 2410.8997486061226
avg_train_sample_per_sec: 2410.8997486061226
avg_episode_per_sec: 18.505524628539472
collect_time: 1.3509479197063485
reward_mean: 407.9939520900751
reward_std: 27.943142913112492
reward_max: 436.5690114841529
reward_min: 292.92853630767195
total_envstep_count: 432392
total_train_sample_count: 387654
total_episode_count: 4820
total_duration: 155.23858797938317
[2023-06-29 09:55:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3338
train_sample_count: 3338
avg_envstep_per_episode: 133.52
avg_sample_per_episode: 133.52
avg_envstep_per_sec: 2538.035284379272
avg_train_sample_per_sec: 2538.035284379272
avg_episode_per_sec: 19.008652519317497
collect_time: 1.3151905414965006
reward_mean: 418.83994796550076
reward_std: 24.795421183197792
reward_max: 506.4827561544884
reward_min: 366.26490647974657
total_envstep_count: 436256
total_train_sample_count: 390992
total_episode_count: 4845
total_duration: 156.55377852087966
[2023-06-29 09:55:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3254
train_sample_count: 3254
avg_envstep_per_episode: 130.16
avg_sample_per_episode: 130.16
avg_envstep_per_sec: 2485.5692918105024
avg_train_sample_per_sec: 2485.5692918105024
avg_episode_per_sec: 19.09626069307393
collect_time: 1.309156824040809
reward_mean: 431.6174418767034
reward_std: 39.617521474341814
reward_max: 612.761391708248
reward_min: 393.37660442776956
total_envstep_count: 439984
total_train_sample_count: 394246
total_episode_count: 4870
total_duration: 157.86293534492046
[2023-06-29 09:55:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 2481.188063320556
avg_train_sample_per_sec: 2481.188063320556
avg_episode_per_sec: 19.234015994732992
collect_time: 1.2997805558051918
reward_mean: 418.77442758395875
reward_std: 33.54469064752629
reward_max: 469.9352829352091
reward_min: 279.56695564373047
total_envstep_count: 443832
total_train_sample_count: 397471
total_episode_count: 4895
total_duration: 159.16271590072566
[2023-06-29 09:56:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3298
train_sample_count: 3298
avg_envstep_per_episode: 126.84615384615384
avg_sample_per_episode: 126.84615384615384
avg_envstep_per_sec: 2457.749215852384
avg_train_sample_per_sec: 2457.749215852384
avg_episode_per_sec: 19.37582765681079
collect_time: 1.3418781618271025
reward_mean: 433.35824973320985
reward_std: 36.84874816099963
reward_max: 558.6239312309762
reward_min: 388.6064498610459
total_envstep_count: 447496
total_train_sample_count: 400769
total_episode_count: 4921
total_duration: 160.50459406255277
[2023-06-29 09:56:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 24
envstep_count: 3318
train_sample_count: 3318
avg_envstep_per_episode: 138.25
avg_sample_per_episode: 138.25
avg_envstep_per_sec: 2414.269848530551
avg_train_sample_per_sec: 2414.269848530551
avg_episode_per_sec: 17.46307304542894
collect_time: 1.3743285581847886
reward_mean: 439.61839438608905
reward_std: 23.650454956523344
reward_max: 527.787735443853
reward_min: 406.9278025670134
total_envstep_count: 451296
total_train_sample_count: 404087
total_episode_count: 4945
total_duration: 161.87892262073757
[2023-06-29 09:56:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3303
train_sample_count: 3303
avg_envstep_per_episode: 132.12
avg_sample_per_episode: 132.12
avg_envstep_per_sec: 2547.3099518938566
avg_train_sample_per_sec: 2547.3099518938566
avg_episode_per_sec: 19.280275143005273
collect_time: 1.296661993388087
reward_mean: 434.94296231464136
reward_std: 22.20364523278636
reward_max: 487.94047786078033
reward_min: 379.44202605489727
total_envstep_count: 455208
total_train_sample_count: 407390
total_episode_count: 4970
total_duration: 163.17558461412565
[2023-06-29 09:56:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3285
train_sample_count: 3285
avg_envstep_per_episode: 131.4
avg_sample_per_episode: 131.4
avg_envstep_per_sec: 2542.425031538683
avg_train_sample_per_sec: 2542.425031538683
avg_episode_per_sec: 19.34874453225786
collect_time: 1.2920734964648726
reward_mean: 451.7056850689337
reward_std: 72.70481672635691
reward_max: 571.1429616953077
reward_min: 261.29268054645286
total_envstep_count: 459120
total_train_sample_count: 410675
total_episode_count: 4995
total_duration: 164.46765811059052
[2023-06-29 09:56:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3266
train_sample_count: 3266
avg_envstep_per_episode: 130.64
avg_sample_per_episode: 130.64
avg_envstep_per_sec: 2470.823189045309
avg_train_sample_per_sec: 2470.823189045309
avg_episode_per_sec: 18.913220981669543
collect_time: 1.321826674802229
reward_mean: 450.2043332707058
reward_std: 32.87957895497486
reward_max: 540.3208863784063
reward_min: 406.5565508413962
total_envstep_count: 462944
total_train_sample_count: 413941
total_episode_count: 5020
total_duration: 165.78948478539274
[2023-06-29 09:56:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 26
envstep_count: 3247
train_sample_count: 3247
avg_envstep_per_episode: 124.88461538461539
avg_sample_per_episode: 124.88461538461539
avg_envstep_per_sec: 2498.552153767576
avg_train_sample_per_sec: 2498.552153767576
avg_episode_per_sec: 20.006885124101316
collect_time: 1.2995526209464296
reward_mean: 422.68526139134946
reward_std: 40.053023852976324
reward_max: 509.56190857885395
reward_min: 288.09158033738964
total_envstep_count: 466744
total_train_sample_count: 417188
total_episode_count: 5046
total_duration: 167.08903740633917
[2023-06-29 09:56:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 24
envstep_count: 3263
train_sample_count: 3263
avg_envstep_per_episode: 135.95833333333334
avg_sample_per_episode: 135.95833333333334
avg_envstep_per_sec: 2595.006319426444
avg_train_sample_per_sec: 2595.006319426444
avg_episode_per_sec: 19.08677648367596
collect_time: 1.2574150496562946
reward_mean: 470.8116117650499
reward_std: 93.38569726313047
reward_max: 580.2195450132533
reward_min: 98.48961071723338
total_envstep_count: 470768
total_train_sample_count: 420451
total_episode_count: 5070
total_duration: 168.34645245599546
[2023-06-29 09:56:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 25
envstep_count: 3356
train_sample_count: 3356
avg_envstep_per_episode: 134.24
avg_sample_per_episode: 134.24
avg_envstep_per_sec: 2470.194279219417
avg_train_sample_per_sec: 2470.194279219417
avg_episode_per_sec: 18.401328063315084
collect_time: 1.3585975921944482
reward_mean: 490.0801361850652
reward_std: 139.25528494354643
reward_max: 664.5292150601219
reward_min: 108.50560464052823
total_envstep_count: 474744
total_train_sample_count: 423807
total_episode_count: 5095
total_duration: 169.70505004818992
[2023-06-29 09:56:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 24
envstep_count: 3526
train_sample_count: 3526
avg_envstep_per_episode: 146.91666666666666
avg_sample_per_episode: 146.91666666666666
avg_envstep_per_sec: 2440.1259020542275
avg_train_sample_per_sec: 2440.1259020542275
avg_episode_per_sec: 16.60891141500325
collect_time: 1.445007405983284
reward_mean: 523.0910238350045
reward_std: 77.37750941040599
reward_max: 634.7390862321112
reward_min: 301.59810524317885
total_envstep_count: 478864
total_train_sample_count: 427333
total_episode_count: 5119
total_duration: 171.1500574541732
[2023-06-29 09:56:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 21
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 153.28571428571428
avg_sample_per_episode: 153.28571428571428
avg_envstep_per_sec: 2650.732429033009
avg_train_sample_per_sec: 2650.732429033009
avg_episode_per_sec: 17.29275582780155
collect_time: 1.2143813403204546
reward_mean: 553.1226912082825
reward_std: 91.8679013345516
reward_max: 678.5630499161106
reward_min: 255.00305860460912
total_envstep_count: 482688
total_train_sample_count: 430552
total_episode_count: 5140
total_duration: 172.36443879449365
[2023-06-29 09:56:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 20
envstep_count: 3262
train_sample_count: 3262
avg_envstep_per_episode: 163.1
avg_sample_per_episode: 163.1
avg_envstep_per_sec: 2341.0331190913703
avg_train_sample_per_sec: 2341.0331190913703
avg_episode_per_sec: 14.353360632074619
collect_time: 1.393401901663863
reward_mean: 601.4987891827179
reward_std: 75.00629833101722
reward_max: 710.5141122758105
reward_min: 432.7602071870228
total_envstep_count: 486392
total_train_sample_count: 433814
total_episode_count: 5160
total_duration: 173.7578406961575
[2023-06-29 09:56:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3306
train_sample_count: 3306
avg_envstep_per_episode: 183.66666666666666
avg_sample_per_episode: 183.66666666666666
avg_envstep_per_sec: 2071.5340071291826
avg_train_sample_per_sec: 2071.5340071291826
avg_episode_per_sec: 11.278769548797726
collect_time: 1.5959187677452573
reward_mean: 647.884914484095
reward_std: 49.739473607904145
reward_max: 709.4324220579313
reward_min: 533.8505038230355
total_envstep_count: 490224
total_train_sample_count: 437120
total_episode_count: 5178
total_duration: 175.35375946390275
[2023-06-29 09:56:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 169.52631578947367
avg_sample_per_episode: 169.52631578947367
avg_envstep_per_sec: 2583.075562871612
avg_train_sample_per_sec: 2583.075562871612
avg_episode_per_sec: 15.237018222465268
collect_time: 1.2469631342953071
reward_mean: 600.8325280738779
reward_std: 148.77912538440444
reward_max: 727.6116035875244
reward_min: 178.80026556082103
total_envstep_count: 494064
total_train_sample_count: 440341
total_episode_count: 5197
total_duration: 176.60072259819805
[2023-06-29 09:56:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3244
train_sample_count: 3244
avg_envstep_per_episode: 170.73684210526315
avg_sample_per_episode: 170.73684210526315
avg_envstep_per_sec: 2362.5776096861746
avg_train_sample_per_sec: 2362.5776096861746
avg_episode_per_sec: 13.837538404450468
collect_time: 1.3730765866484727
reward_mean: 639.4188149548996
reward_std: 92.43222311927086
reward_max: 706.8299926070806
reward_min: 292.6051753125543
total_envstep_count: 498216
total_train_sample_count: 443585
total_episode_count: 5216
total_duration: 177.9737991848465
[2023-06-29 09:56:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 20
envstep_count: 3406
train_sample_count: 3406
avg_envstep_per_episode: 170.3
avg_sample_per_episode: 170.3
avg_envstep_per_sec: 2448.788751802006
avg_train_sample_per_sec: 2448.788751802006
avg_episode_per_sec: 14.379264543758111
collect_time: 1.3908917204448952
reward_mean: 666.367136741826
reward_std: 98.18236881356721
reward_max: 725.7073492081228
reward_min: 245.75327608501888
total_envstep_count: 502040
total_train_sample_count: 446991
total_episode_count: 5236
total_duration: 179.3646909052914
[2023-06-29 09:56:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 178.5
avg_sample_per_episode: 178.5
avg_envstep_per_sec: 2584.1980173600277
avg_train_sample_per_sec: 2584.1980173600277
avg_episode_per_sec: 14.477299817143013
collect_time: 1.243325773959979
reward_mean: 619.7133166641681
reward_std: 177.24031290765666
reward_max: 739.7836416863737
reward_min: 190.0345800699007
total_envstep_count: 505944
total_train_sample_count: 450204
total_episode_count: 5254
total_duration: 180.6080166792514
[2023-06-29 09:56:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 179.05555555555554
avg_sample_per_episode: 179.05555555555554
avg_envstep_per_sec: 2459.4368882493754
avg_train_sample_per_sec: 2459.4368882493754
avg_episode_per_sec: 13.735607815230765
collect_time: 1.310462575965561
reward_mean: 671.9801417316913
reward_std: 122.44489581519575
reward_max: 895.8896007493332
reward_min: 247.5370664511846
total_envstep_count: 510080
total_train_sample_count: 453427
total_episode_count: 5272
total_duration: 181.91847925521697
[2023-06-29 09:56:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 21
envstep_count: 3402
train_sample_count: 3402
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 2713.3521355394537
avg_train_sample_per_sec: 2713.3521355394537
avg_episode_per_sec: 16.74908725641638
collect_time: 1.2537996655283496
reward_mean: 647.3738042330699
reward_std: 68.11588846130729
reward_max: 765.7861403589435
reward_min: 430.7746011226275
total_envstep_count: 514000
total_train_sample_count: 456829
total_episode_count: 5293
total_duration: 183.17227892074533
[2023-06-29 09:56:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3412
train_sample_count: 3412
avg_envstep_per_episode: 179.57894736842104
avg_sample_per_episode: 179.57894736842104
avg_envstep_per_sec: 2599.5834131693987
avg_train_sample_per_sec: 2599.5834131693987
avg_episode_per_sec: 14.475992042854214
collect_time: 1.3125179914269829
reward_mean: 655.7689140332029
reward_std: 73.27114514424647
reward_max: 766.4974707726736
reward_min: 461.9504047935568
total_envstep_count: 518056
total_train_sample_count: 460241
total_episode_count: 5312
total_duration: 184.4847969121723
[2023-06-29 09:56:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3239
train_sample_count: 3239
avg_envstep_per_episode: 170.47368421052633
avg_sample_per_episode: 170.47368421052633
avg_envstep_per_sec: 2496.2186797331187
avg_train_sample_per_sec: 2496.2186797331187
avg_episode_per_sec: 14.642838812883378
collect_time: 1.2975625999026235
reward_mean: 638.9319766811974
reward_std: 169.4923788074112
reward_max: 809.6241335168037
reward_min: 154.96259469218543
total_envstep_count: 521960
total_train_sample_count: 463480
total_episode_count: 5331
total_duration: 185.78235951207492
[2023-06-29 09:56:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 176.10526315789474
avg_sample_per_episode: 176.10526315789474
avg_envstep_per_sec: 2522.470633781317
avg_train_sample_per_sec: 2522.470633781317
avg_episode_per_sec: 14.323652732171256
collect_time: 1.3264772858759386
reward_mean: 656.4692866863711
reward_std: 169.96097463464358
reward_max: 840.898701521195
reward_min: 188.97591046059327
total_envstep_count: 526048
total_train_sample_count: 466826
total_episode_count: 5350
total_duration: 187.10883679795086
[2023-06-29 09:57:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3368
train_sample_count: 3368
avg_envstep_per_episode: 187.11111111111111
avg_sample_per_episode: 187.11111111111111
avg_envstep_per_sec: 2668.6628200607065
avg_train_sample_per_sec: 2668.6628200607065
avg_episode_per_sec: 14.262449750918265
collect_time: 1.2620552790267394
reward_mean: 727.8552273988078
reward_std: 64.13767321182456
reward_max: 860.748125763131
reward_min: 596.7171458322176
total_envstep_count: 530136
total_train_sample_count: 470194
total_episode_count: 5368
total_duration: 188.37089207697758
[2023-06-29 09:57:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3374
train_sample_count: 3374
avg_envstep_per_episode: 177.57894736842104
avg_sample_per_episode: 177.57894736842104
avg_envstep_per_sec: 2535.783244999396
avg_train_sample_per_sec: 2535.783244999396
avg_episode_per_sec: 14.279751527856705
collect_time: 1.330555364561849
reward_mean: 687.552988085704
reward_std: 123.3809714020619
reward_max: 848.9066170495611
reward_min: 350.72342731437584
total_envstep_count: 534360
total_train_sample_count: 473568
total_episode_count: 5387
total_duration: 189.70144744153944
[2023-06-29 09:57:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 189.05882352941177
avg_sample_per_episode: 189.05882352941177
avg_envstep_per_sec: 2467.610422376628
avg_train_sample_per_sec: 2467.610422376628
avg_episode_per_sec: 13.052077529683471
collect_time: 1.30247464140004
reward_mean: 753.9967500320481
reward_std: 81.07787590652235
reward_max: 891.643058297374
reward_min: 609.9974206359308
total_envstep_count: 538112
total_train_sample_count: 476782
total_episode_count: 5404
total_duration: 191.00392208293948
[2023-06-29 09:57:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3370
train_sample_count: 3370
avg_envstep_per_episode: 198.23529411764707
avg_sample_per_episode: 198.23529411764707
avg_envstep_per_sec: 2519.8198107398757
avg_train_sample_per_sec: 2519.8198107398757
avg_episode_per_sec: 12.711257205512727
collect_time: 1.3373972161170096
reward_mean: 738.6606978009963
reward_std: 83.59417726412116
reward_max: 952.4769557691199
reward_min: 613.7569733849205
total_envstep_count: 542648
total_train_sample_count: 480152
total_episode_count: 5421
total_duration: 192.3413192990565
[2023-06-29 09:57:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3259
train_sample_count: 3259
avg_envstep_per_episode: 171.52631578947367
avg_sample_per_episode: 171.52631578947367
avg_envstep_per_sec: 2649.6364316379977
avg_train_sample_per_sec: 2649.6364316379977
avg_episode_per_sec: 15.447404787088663
collect_time: 1.2299800686184315
reward_mean: 748.5042162018972
reward_std: 172.2105180607569
reward_max: 884.9636633811049
reward_min: 69.30301197049621
total_envstep_count: 546552
total_train_sample_count: 483411
total_episode_count: 5440
total_duration: 193.57129936767492
[2023-06-29 09:57:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 189.11764705882354
avg_sample_per_episode: 189.11764705882354
avg_envstep_per_sec: 2572.5049860176305
avg_train_sample_per_sec: 2572.5049860176305
avg_episode_per_sec: 13.602670221555123
collect_time: 1.2497546234019101
reward_mean: 711.6080349467505
reward_std: 202.5987995533289
reward_max: 960.6617644003506
reward_min: 88.47081930646492
total_envstep_count: 550400
total_train_sample_count: 486626
total_episode_count: 5457
total_duration: 194.82105399107684
[2023-06-29 09:57:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3460
train_sample_count: 3460
avg_envstep_per_episode: 192.22222222222223
avg_sample_per_episode: 192.22222222222223
avg_envstep_per_sec: 2664.2598979185004
avg_train_sample_per_sec: 2664.2598979185004
avg_episode_per_sec: 13.860311607668498
collect_time: 1.2986721012853084
reward_mean: 722.3235647213182
reward_std: 157.67065239462795
reward_max: 901.5506685393133
reward_min: 160.5402953408452
total_envstep_count: 554992
total_train_sample_count: 490086
total_episode_count: 5475
total_duration: 196.11972609236216
[2023-06-29 09:57:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3432
train_sample_count: 3432
avg_envstep_per_episode: 180.6315789473684
avg_sample_per_episode: 180.6315789473684
avg_envstep_per_sec: 2631.055107498609
avg_train_sample_per_sec: 2631.055107498609
avg_episode_per_sec: 14.565864522865258
collect_time: 1.3044196566687893
reward_mean: 726.9543198899929
reward_std: 232.52000414286252
reward_max: 1013.3266656602176
reward_min: 88.55339488726183
total_envstep_count: 559400
total_train_sample_count: 493518
total_episode_count: 5494
total_duration: 197.42414574903094
[2023-06-29 09:57:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3733
train_sample_count: 3733
avg_envstep_per_episode: 219.58823529411765
avg_sample_per_episode: 219.58823529411765
avg_envstep_per_sec: 2516.8523324455095
avg_train_sample_per_sec: 2516.8523324455095
avg_episode_per_sec: 11.461690236156889
collect_time: 1.4832018358315109
reward_mean: 837.9976629403836
reward_std: 197.56736524497643
reward_max: 1042.9314298447532
reward_min: 151.45407483434923
total_envstep_count: 564000
total_train_sample_count: 497251
total_episode_count: 5511
total_duration: 198.90734758486246
[2023-06-29 09:57:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3427
train_sample_count: 3427
avg_envstep_per_episode: 228.46666666666667
avg_sample_per_episode: 228.46666666666667
avg_envstep_per_sec: 2460.8513787940215
avg_train_sample_per_sec: 2460.8513787940215
avg_episode_per_sec: 10.771161564607622
collect_time: 1.3926074648520443
reward_mean: 876.1174676014107
reward_std: 210.35097143272492
reward_max: 1086.437624166004
reward_min: 178.42570736391193
total_envstep_count: 568472
total_train_sample_count: 500678
total_episode_count: 5526
total_duration: 200.2999550497145
[2023-06-29 09:57:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3401
train_sample_count: 3401
avg_envstep_per_episode: 212.5625
avg_sample_per_episode: 212.5625
avg_envstep_per_sec: 2526.5425755407546
avg_train_sample_per_sec: 2526.5425755407546
avg_episode_per_sec: 11.886116203661297
collect_time: 1.3461083272155372
reward_mean: 871.2926321761577
reward_std: 113.51303077200757
reward_max: 1068.5138090664145
reward_min: 709.5804906606568
total_envstep_count: 572672
total_train_sample_count: 504079
total_episode_count: 5542
total_duration: 201.64606337693004
[2023-06-29 09:57:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3308
train_sample_count: 3308
avg_envstep_per_episode: 220.53333333333333
avg_sample_per_episode: 220.53333333333333
avg_envstep_per_sec: 2560.806207908952
avg_train_sample_per_sec: 2560.806207908952
avg_episode_per_sec: 11.611878209986179
collect_time: 1.2917806860134002
reward_mean: 852.4481312580012
reward_std: 84.23226147244351
reward_max: 993.0491782025869
reward_min: 683.6472337629364
total_envstep_count: 576848
total_train_sample_count: 507387
total_episode_count: 5557
total_duration: 202.93784406294344
[2023-06-29 09:57:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3367
train_sample_count: 3367
avg_envstep_per_episode: 240.5
avg_sample_per_episode: 240.5
avg_envstep_per_sec: 2569.2698434538197
avg_train_sample_per_sec: 2569.2698434538197
avg_episode_per_sec: 10.683034692115674
collect_time: 1.3104890514239669
reward_mean: 938.9054205877101
reward_std: 87.98493787424539
reward_max: 1106.582441831182
reward_min: 824.9386402360473
total_envstep_count: 581328
total_train_sample_count: 510754
total_episode_count: 5571
total_duration: 204.2483331143674
[2023-06-29 09:57:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 213.375
avg_sample_per_episode: 213.375
avg_envstep_per_sec: 2352.1296588413156
avg_train_sample_per_sec: 2352.1296588413156
avg_episode_per_sec: 11.023454757311379
collect_time: 1.4514505980430403
reward_mean: 873.065159598886
reward_std: 73.89225998574004
reward_max: 1009.1857148153919
reward_min: 745.5835362604722
total_envstep_count: 586032
total_train_sample_count: 514168
total_episode_count: 5587
total_duration: 205.69978371241044
[2023-06-29 09:57:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 213.53333333333333
avg_sample_per_episode: 213.53333333333333
avg_envstep_per_sec: 2321.28624302238
avg_train_sample_per_sec: 2321.28624302238
avg_episode_per_sec: 10.870837853679582
collect_time: 1.3798384450121084
reward_mean: 928.7300830563503
reward_std: 93.63798112436434
reward_max: 1097.9043113425946
reward_min: 762.8844660186867
total_envstep_count: 589920
total_train_sample_count: 517371
total_episode_count: 5602
total_duration: 207.07962215742253
[2023-06-29 09:57:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3369
train_sample_count: 3369
avg_envstep_per_episode: 224.6
avg_sample_per_episode: 224.6
avg_envstep_per_sec: 2580.999623842584
avg_train_sample_per_sec: 2580.999623842584
avg_episode_per_sec: 11.49153884168559
collect_time: 1.3053082103841007
reward_mean: 835.4757298649673
reward_std: 215.10588160749177
reward_max: 1058.6389776239323
reward_min: 172.50644726994457
total_envstep_count: 594552
total_train_sample_count: 520740
total_episode_count: 5617
total_duration: 208.38493036780665
[2023-06-29 09:57:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3443
train_sample_count: 3443
avg_envstep_per_episode: 229.53333333333333
avg_sample_per_episode: 229.53333333333333
avg_envstep_per_sec: 2308.613439461618
avg_train_sample_per_sec: 2308.613439461618
avg_episode_per_sec: 10.057856982841786
collect_time: 1.49137137519347
reward_mean: 954.8777514753212
reward_std: 121.09417819200527
reward_max: 1156.330363408368
reward_min: 742.5702061170384
total_envstep_count: 599264
total_train_sample_count: 524183
total_episode_count: 5632
total_duration: 209.8763017430001
[2023-06-29 09:57:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3374
train_sample_count: 3374
avg_envstep_per_episode: 224.93333333333334
avg_sample_per_episode: 224.93333333333334
avg_envstep_per_sec: 2359.5903707803004
avg_train_sample_per_sec: 2359.5903707803004
avg_episode_per_sec: 10.49017651502801
collect_time: 1.429909208726022
reward_mean: 932.5889469489274
reward_std: 218.047315508465
reward_max: 1140.3492542004788
reward_min: 275.28692083981156
total_envstep_count: 603568
total_train_sample_count: 527557
total_episode_count: 5647
total_duration: 211.30621095172614
[2023-06-29 09:57:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3494
train_sample_count: 3494
avg_envstep_per_episode: 268.7692307692308
avg_sample_per_episode: 268.7692307692308
avg_envstep_per_sec: 2544.507378263375
avg_train_sample_per_sec: 2544.507378263375
avg_episode_per_sec: 9.467256988386914
collect_time: 1.3731538095930589
reward_mean: 1029.192668713116
reward_std: 96.23843219847419
reward_max: 1201.635462909802
reward_min: 763.6340791975667
total_envstep_count: 608048
total_train_sample_count: 531051
total_episode_count: 5660
total_duration: 212.6793647613192
[2023-06-29 09:57:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3452
train_sample_count: 3452
avg_envstep_per_episode: 230.13333333333333
avg_sample_per_episode: 230.13333333333333
avg_envstep_per_sec: 2642.711585037352
avg_train_sample_per_sec: 2642.711585037352
avg_episode_per_sec: 11.483393330115957
collect_time: 1.3062341042226178
reward_mean: 892.9086691323281
reward_std: 220.29969042058508
reward_max: 1141.6514846698947
reward_min: 183.00742127377683
total_envstep_count: 612552
total_train_sample_count: 534503
total_episode_count: 5675
total_duration: 213.98559886554182
[2023-06-29 09:58:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3372
train_sample_count: 3372
avg_envstep_per_episode: 240.85714285714286
avg_sample_per_episode: 240.85714285714286
avg_envstep_per_sec: 2499.0243024395277
avg_train_sample_per_sec: 2499.0243024395277
avg_episode_per_sec: 10.375545739665892
collect_time: 1.3493266138741749
reward_mean: 961.4464433825748
reward_std: 78.17239910234133
reward_max: 1070.3991071339483
reward_min: 827.3118687615624
total_envstep_count: 617224
total_train_sample_count: 537875
total_episode_count: 5689
total_duration: 215.334925479416
[2023-06-29 09:58:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3436
train_sample_count: 3436
avg_envstep_per_episode: 180.8421052631579
avg_sample_per_episode: 180.8421052631579
avg_envstep_per_sec: 2485.854830777647
avg_train_sample_per_sec: 2485.854830777647
avg_episode_per_sec: 13.745995862856605
collect_time: 1.3822206982718779
reward_mean: 773.4579101725352
reward_std: 315.09342965290733
reward_max: 1013.0490619718029
reward_min: 66.44890332638958
total_envstep_count: 622136
total_train_sample_count: 541311
total_episode_count: 5708
total_duration: 216.71714617768788
[2023-06-29 09:58:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3305
train_sample_count: 3305
avg_envstep_per_episode: 194.41176470588235
avg_sample_per_episode: 194.41176470588235
avg_envstep_per_sec: 2360.0385381138162
avg_train_sample_per_sec: 2360.0385381138162
avg_episode_per_sec: 12.13938128530556
collect_time: 1.4004008606746792
reward_mean: 859.4634248984788
reward_std: 221.2498447424769
reward_max: 1113.1183232210083
reward_min: 58.10214239290576
total_envstep_count: 626736
total_train_sample_count: 544616
total_episode_count: 5725
total_duration: 218.11754703836255
[2023-06-29 09:58:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 229.71428571428572
avg_sample_per_episode: 229.71428571428572
avg_envstep_per_sec: 2548.0992927769303
avg_train_sample_per_sec: 2548.0992927769303
avg_episode_per_sec: 11.092472045670718
collect_time: 1.2621172216939742
reward_mean: 982.9994239615087
reward_std: 103.70329118247707
reward_max: 1211.4813916610478
reward_min: 823.5353538822264
total_envstep_count: 630672
total_train_sample_count: 547832
total_episode_count: 5739
total_duration: 219.37966426005653
[2023-06-29 09:58:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3340
train_sample_count: 3340
avg_envstep_per_episode: 256.9230769230769
avg_sample_per_episode: 256.9230769230769
avg_envstep_per_sec: 2583.9634148618134
avg_train_sample_per_sec: 2583.9634148618134
avg_episode_per_sec: 10.057342632695681
collect_time: 1.2925879603363573
reward_mean: 951.1998502892917
reward_std: 97.95666178382609
reward_max: 1126.2998283630156
reward_min: 743.2536364401916
total_envstep_count: 635472
total_train_sample_count: 551172
total_episode_count: 5752
total_duration: 220.6722522203929
[2023-06-29 09:58:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3269
train_sample_count: 3269
avg_envstep_per_episode: 217.93333333333334
avg_sample_per_episode: 217.93333333333334
avg_envstep_per_sec: 2524.0672260970778
avg_train_sample_per_sec: 2524.0672260970778
avg_episode_per_sec: 11.581831872577597
collect_time: 1.2951319070272147
reward_mean: 963.0625311830631
reward_std: 117.6017959648244
reward_max: 1176.3521739655068
reward_min: 762.9880887401362
total_envstep_count: 640024
total_train_sample_count: 554441
total_episode_count: 5767
total_duration: 221.9673841274201
[2023-06-29 09:58:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3263
train_sample_count: 3263
avg_envstep_per_episode: 217.53333333333333
avg_sample_per_episode: 217.53333333333333
avg_envstep_per_sec: 2572.523303783502
avg_train_sample_per_sec: 2572.523303783502
avg_episode_per_sec: 11.825880955180057
collect_time: 1.2684044475713745
reward_mean: 928.9741247352799
reward_std: 81.46720683183972
reward_max: 1080.4522509626067
reward_min: 751.2162481692604
total_envstep_count: 643928
total_train_sample_count: 557704
total_episode_count: 5782
total_duration: 223.2357885749915
[2023-06-29 09:58:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3301
train_sample_count: 3301
avg_envstep_per_episode: 253.92307692307693
avg_sample_per_episode: 253.92307692307693
avg_envstep_per_sec: 2700.6516278203353
avg_train_sample_per_sec: 2700.6516278203353
avg_episode_per_sec: 10.635707713318498
collect_time: 1.222297598844394
reward_mean: 947.2540299701567
reward_std: 70.76314599265652
reward_max: 1055.244753162624
reward_min: 775.509372919389
total_envstep_count: 648432
total_train_sample_count: 561005
total_episode_count: 5795
total_duration: 224.45808617383588
[2023-06-29 09:58:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 222.13333333333333
avg_sample_per_episode: 222.13333333333333
avg_envstep_per_sec: 2752.173252488395
avg_train_sample_per_sec: 2752.173252488395
avg_episode_per_sec: 12.389735530409942
collect_time: 1.2106795954750853
reward_mean: 935.9271836190857
reward_std: 79.51760395978663
reward_max: 1040.0508523728713
reward_min: 763.288051134374
total_envstep_count: 652760
total_train_sample_count: 564337
total_episode_count: 5810
total_duration: 225.66876576931097
[2023-06-29 09:58:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3404
train_sample_count: 3404
avg_envstep_per_episode: 226.93333333333334
avg_sample_per_episode: 226.93333333333334
avg_envstep_per_sec: 2575.1279158766906
avg_train_sample_per_sec: 2575.1279158766906
avg_episode_per_sec: 11.347508442464854
collect_time: 1.3218760819658637
reward_mean: 923.7421733788344
reward_std: 80.51615774487973
reward_max: 1131.1368764274612
reward_min: 821.7379504396858
total_envstep_count: 657264
total_train_sample_count: 567741
total_episode_count: 5825
total_duration: 226.99064185127682
[2023-06-29 09:58:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3372
train_sample_count: 3372
avg_envstep_per_episode: 224.8
avg_sample_per_episode: 224.8
avg_envstep_per_sec: 2564.3709451115274
avg_train_sample_per_sec: 2564.3709451115274
avg_episode_per_sec: 11.40734406188402
collect_time: 1.3149423668319358
reward_mean: 932.2551034982656
reward_std: 63.371848388284725
reward_max: 1018.1341224964218
reward_min: 811.3508200253641
total_envstep_count: 661768
total_train_sample_count: 571113
total_episode_count: 5840
total_duration: 228.30558421810875
[2023-06-29 09:58:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 230.71428571428572
avg_sample_per_episode: 230.71428571428572
avg_envstep_per_sec: 2628.2953797609835
avg_train_sample_per_sec: 2628.2953797609835
avg_episode_per_sec: 11.391992358097143
collect_time: 1.228933408654295
reward_mean: 970.940410198128
reward_std: 74.4311954251516
reward_max: 1097.1512742129873
reward_min: 828.9314568178295
total_envstep_count: 666280
total_train_sample_count: 574343
total_episode_count: 5854
total_duration: 229.53451762676303
[2023-06-29 09:58:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 2580.2906712296153
avg_train_sample_per_sec: 2580.2906712296153
avg_episode_per_sec: 10.79619527711136
collect_time: 1.2967531283618883
reward_mean: 1015.9768188875588
reward_std: 72.398023545698
reward_max: 1114.7970072150317
reward_min: 900.2394265799661
total_envstep_count: 670432
total_train_sample_count: 577689
total_episode_count: 5868
total_duration: 230.83127075512493
[2023-06-29 09:58:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3248
train_sample_count: 3248
avg_envstep_per_episode: 249.84615384615384
avg_sample_per_episode: 249.84615384615384
avg_envstep_per_sec: 2520.6821006322875
avg_train_sample_per_sec: 2520.6821006322875
avg_episode_per_sec: 10.088936979131693
collect_time: 1.288540113481693
reward_mean: 960.9227417237133
reward_std: 71.24520180504646
reward_max: 1091.716021340558
reward_min: 831.34258636052
total_envstep_count: 674800
total_train_sample_count: 580937
total_episode_count: 5881
total_duration: 232.11981086860663
[2023-06-29 09:58:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3345
train_sample_count: 3345
avg_envstep_per_episode: 257.3076923076923
avg_sample_per_episode: 257.3076923076923
avg_envstep_per_sec: 2364.8632151113466
avg_train_sample_per_sec: 2364.8632151113466
avg_episode_per_sec: 9.190798743332588
collect_time: 1.4144581295973624
reward_mean: 1029.3616269501028
reward_std: 77.71258612840518
reward_max: 1185.2514903398169
reward_min: 923.7835638305519
total_envstep_count: 679224
total_train_sample_count: 584282
total_episode_count: 5894
total_duration: 233.534268998204
[2023-06-29 09:58:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3256
train_sample_count: 3256
avg_envstep_per_episode: 250.46153846153845
avg_sample_per_episode: 250.46153846153845
avg_envstep_per_sec: 2566.5886596196524
avg_train_sample_per_sec: 2566.5886596196524
avg_episode_per_sec: 10.247436294550209
collect_time: 1.2686099846176804
reward_mean: 1023.0390747671702
reward_std: 66.66593394892686
reward_max: 1143.854178896536
reward_min: 933.6983761293951
total_envstep_count: 683632
total_train_sample_count: 587538
total_episode_count: 5907
total_duration: 234.80287898282168
[2023-06-29 09:58:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3305
train_sample_count: 3305
avg_envstep_per_episode: 236.07142857142858
avg_sample_per_episode: 236.07142857142858
avg_envstep_per_sec: 2404.5527678284407
avg_train_sample_per_sec: 2404.5527678284407
avg_episode_per_sec: 10.185700075521382
collect_time: 1.3744759708412455
reward_mean: 989.4477699501962
reward_std: 60.544928364877435
reward_max: 1093.6387555202875
reward_min: 890.319492474789
total_envstep_count: 687720
total_train_sample_count: 590843
total_episode_count: 5921
total_duration: 236.17735495366293
[2023-06-29 09:58:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3297
train_sample_count: 3297
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 2438.9848982139206
avg_train_sample_per_sec: 2438.9848982139206
avg_episode_per_sec: 10.356623771609005
collect_time: 1.3517918878523634
reward_mean: 911.4699473480916
reward_std: 68.95639065492436
reward_max: 1034.68325219177
reward_min: 790.4036861781243
total_envstep_count: 691992
total_train_sample_count: 594140
total_episode_count: 5935
total_duration: 237.52914684151528
[2023-06-29 09:58:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 214.4
avg_sample_per_episode: 214.4
avg_envstep_per_sec: 2519.885447965642
avg_train_sample_per_sec: 2519.885447965642
avg_episode_per_sec: 11.753197052078553
collect_time: 1.276248490817845
reward_mean: 878.5857186000862
reward_std: 68.67015831834108
reward_max: 991.9506393391849
reward_min: 724.3774416432973
total_envstep_count: 696232
total_train_sample_count: 597356
total_episode_count: 5950
total_duration: 238.80539533233312
[2023-06-29 09:58:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3282
train_sample_count: 3282
avg_envstep_per_episode: 218.8
avg_sample_per_episode: 218.8
avg_envstep_per_sec: 2637.1279810659253
avg_train_sample_per_sec: 2637.1279810659253
avg_episode_per_sec: 12.052687299204411
collect_time: 1.2445357311302798
reward_mean: 902.81550113294
reward_std: 37.96005982342373
reward_max: 971.7738752147014
reward_min: 843.5086712372357
total_envstep_count: 700624
total_train_sample_count: 600638
total_episode_count: 5965
total_duration: 240.0499310634634
[2023-06-29 09:59:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3291
train_sample_count: 3291
avg_envstep_per_episode: 219.4
avg_sample_per_episode: 219.4
avg_envstep_per_sec: 2503.558861128028
avg_train_sample_per_sec: 2503.558861128028
avg_episode_per_sec: 11.410933733491468
collect_time: 1.3145287099489942
reward_mean: 922.8131500272343
reward_std: 39.721204986545516
reward_max: 995.1288783187113
reward_min: 864.4504585336298
total_envstep_count: 705104
total_train_sample_count: 603929
total_episode_count: 5980
total_duration: 241.3644597734124
[2023-06-29 09:59:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3380
train_sample_count: 3380
avg_envstep_per_episode: 211.25
avg_sample_per_episode: 211.25
avg_envstep_per_sec: 2380.344397224016
avg_train_sample_per_sec: 2380.344397224016
avg_episode_per_sec: 11.26790247206635
collect_time: 1.419962591943331
reward_mean: 900.6487850841156
reward_std: 32.159683247483535
reward_max: 978.8648474987542
reward_min: 864.4284880222147
total_envstep_count: 709472
total_train_sample_count: 607309
total_episode_count: 5996
total_duration: 242.7844223653557
[2023-06-29 09:59:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3338
train_sample_count: 3338
avg_envstep_per_episode: 222.53333333333333
avg_sample_per_episode: 222.53333333333333
avg_envstep_per_sec: 2614.610807579135
avg_train_sample_per_sec: 2614.610807579135
avg_episode_per_sec: 11.749299614645603
collect_time: 1.2766718435967341
reward_mean: 901.4428803702175
reward_std: 49.59768702667884
reward_max: 970.1261182981817
reward_min: 804.8439675421154
total_envstep_count: 714080
total_train_sample_count: 610647
total_episode_count: 6011
total_duration: 244.06109420895245
[2023-06-29 09:59:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3409
train_sample_count: 3409
avg_envstep_per_episode: 213.0625
avg_sample_per_episode: 213.0625
avg_envstep_per_sec: 2519.561155537926
avg_train_sample_per_sec: 2519.561155537926
avg_episode_per_sec: 11.82545570214339
collect_time: 1.3530133977923544
reward_mean: 909.509167742193
reward_std: 48.357093576936045
reward_max: 990.179979037536
reward_min: 834.9486643620714
total_envstep_count: 718712
total_train_sample_count: 614056
total_episode_count: 6027
total_duration: 245.4141076067448
[2023-06-29 09:59:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3440
train_sample_count: 3440
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 2498.2542978765914
avg_train_sample_per_sec: 2498.2542978765914
avg_episode_per_sec: 11.619787431984145
collect_time: 1.3769615058498457
reward_mean: 909.3919277176755
reward_std: 45.84559323726124
reward_max: 1032.2652664249892
reward_min: 846.9064454555435
total_envstep_count: 723296
total_train_sample_count: 617496
total_episode_count: 6043
total_duration: 246.79106911259464
[2023-06-29 09:59:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3363
train_sample_count: 3363
avg_envstep_per_episode: 224.2
avg_sample_per_episode: 224.2
avg_envstep_per_sec: 2537.6519132307485
avg_train_sample_per_sec: 2537.6519132307485
avg_episode_per_sec: 11.31869720441904
collect_time: 1.3252408584747464
reward_mean: 935.6778597869574
reward_std: 37.819107047225636
reward_max: 994.2656940386329
reward_min: 862.1116252030859
total_envstep_count: 727888
total_train_sample_count: 620859
total_episode_count: 6058
total_duration: 248.1163099710694
[2023-06-29 09:59:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3246
train_sample_count: 3246
avg_envstep_per_episode: 216.4
avg_sample_per_episode: 216.4
avg_envstep_per_sec: 2703.8305213115295
avg_train_sample_per_sec: 2703.8305213115295
avg_episode_per_sec: 12.49459575467435
collect_time: 1.2005190319493413
reward_mean: 932.4676502136298
reward_std: 34.86584137519199
reward_max: 995.272227450784
reward_min: 886.4304758819999
total_envstep_count: 732016
total_train_sample_count: 624105
total_episode_count: 6073
total_duration: 249.31682900301874
[2023-06-29 09:59:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 2518.7931423392756
avg_train_sample_per_sec: 2518.7931423392756
avg_episode_per_sec: 10.999096691437884
collect_time: 1.2728317963508888
reward_mean: 917.566605147519
reward_std: 37.64800523303789
reward_max: 990.4485894407552
reward_min: 848.8179982704848
total_envstep_count: 736280
total_train_sample_count: 627311
total_episode_count: 6087
total_duration: 250.58966079936963
[2023-06-29 09:59:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3380
train_sample_count: 3380
avg_envstep_per_episode: 225.33333333333334
avg_sample_per_episode: 225.33333333333334
avg_envstep_per_sec: 2495.319978113506
avg_train_sample_per_sec: 2495.319978113506
avg_episode_per_sec: 11.073905228314375
collect_time: 1.354535702693858
reward_mean: 930.4880625646929
reward_std: 33.95682577463346
reward_max: 974.2067895534855
reward_min: 867.2376768608875
total_envstep_count: 740696
total_train_sample_count: 630691
total_episode_count: 6102
total_duration: 251.94419650206348
[2023-06-29 09:59:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3400
train_sample_count: 3400
avg_envstep_per_episode: 226.66666666666666
avg_sample_per_episode: 226.66666666666666
avg_envstep_per_sec: 2483.560388568179
avg_train_sample_per_sec: 2483.560388568179
avg_episode_per_sec: 10.956884067212554
collect_time: 1.3690023466512793
reward_mean: 929.694621450028
reward_std: 43.000530783229294
reward_max: 990.919284827562
reward_min: 827.1110009287337
total_envstep_count: 745192
total_train_sample_count: 634091
total_episode_count: 6117
total_duration: 253.31319884871476
[2023-06-29 09:59:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3338
train_sample_count: 3338
avg_envstep_per_episode: 222.53333333333333
avg_sample_per_episode: 222.53333333333333
avg_envstep_per_sec: 2624.661387388815
avg_train_sample_per_sec: 2624.661387388815
avg_episode_per_sec: 11.794463993658544
collect_time: 1.2717831016369168
reward_mean: 936.7202640257801
reward_std: 29.146584242607137
reward_max: 980.7293693472219
reward_min: 883.7485884084798
total_envstep_count: 749704
total_train_sample_count: 637429
total_episode_count: 6132
total_duration: 254.58498195035168
[2023-06-29 09:59:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3373
train_sample_count: 3373
avg_envstep_per_episode: 224.86666666666667
avg_sample_per_episode: 224.86666666666667
avg_envstep_per_sec: 2542.582426844193
avg_train_sample_per_sec: 2542.582426844193
avg_episode_per_sec: 11.30706682557453
collect_time: 1.3266039930066325
reward_mean: 945.6261200600771
reward_std: 45.0133621352811
reward_max: 1054.0267888578728
reward_min: 866.1863168626069
total_envstep_count: 754096
total_train_sample_count: 640802
total_episode_count: 6147
total_duration: 255.91158594335832
[2023-06-29 09:59:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3307
train_sample_count: 3307
avg_envstep_per_episode: 236.21428571428572
avg_sample_per_episode: 236.21428571428572
avg_envstep_per_sec: 2415.9647981807434
avg_train_sample_per_sec: 2415.9647981807434
avg_episode_per_sec: 10.2278521846176
collect_time: 1.368811334705795
reward_mean: 958.7205353366763
reward_std: 32.876458216852406
reward_max: 993.3177634999374
reward_min: 896.6589840947379
total_envstep_count: 758568
total_train_sample_count: 644109
total_episode_count: 6161
total_duration: 257.28039727806413
[2023-06-29 09:59:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3250
train_sample_count: 3250
avg_envstep_per_episode: 216.66666666666666
avg_sample_per_episode: 216.66666666666666
avg_envstep_per_sec: 2441.42278378862
avg_train_sample_per_sec: 2441.42278378862
avg_episode_per_sec: 11.268105155947477
collect_time: 1.331190984855406
reward_mean: 920.4043866371005
reward_std: 53.46675388454043
reward_max: 1028.8944764022435
reward_min: 833.6536943702034
total_envstep_count: 762680
total_train_sample_count: 647359
total_episode_count: 6176
total_duration: 258.61158826291955
[2023-06-29 09:59:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3359
train_sample_count: 3359
avg_envstep_per_episode: 239.92857142857142
avg_sample_per_episode: 239.92857142857142
avg_envstep_per_sec: 2651.0810230540105
avg_train_sample_per_sec: 2651.0810230540105
avg_episode_per_sec: 11.049459458992601
collect_time: 1.2670303060486912
reward_mean: 947.6507185562801
reward_std: 35.78894816116728
reward_max: 999.442927507366
reward_min: 868.2900138041831
total_envstep_count: 766960
total_train_sample_count: 650718
total_episode_count: 6190
total_duration: 259.87861856896825
[2023-06-29 09:59:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3315
train_sample_count: 3315
avg_envstep_per_episode: 236.78571428571428
avg_sample_per_episode: 236.78571428571428
avg_envstep_per_sec: 2487.6417692138493
avg_train_sample_per_sec: 2487.6417692138493
avg_episode_per_sec: 10.505877758369198
collect_time: 1.3325873688990253
reward_mean: 960.4132318894916
reward_std: 47.21909908428807
reward_max: 1058.4900340539812
reward_min: 884.6977361496124
total_envstep_count: 771536
total_train_sample_count: 654033
total_episode_count: 6204
total_duration: 261.21120593786725
[2023-06-29 09:59:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3280
train_sample_count: 3280
avg_envstep_per_episode: 218.66666666666666
avg_sample_per_episode: 218.66666666666666
avg_envstep_per_sec: 2574.3374196649047
avg_train_sample_per_sec: 2574.3374196649047
avg_episode_per_sec: 11.772884541150479
collect_time: 1.274114253611304
reward_mean: 958.7956798842591
reward_std: 41.69710129765182
reward_max: 1058.2697337617642
reward_min: 901.1992133720189
total_envstep_count: 776216
total_train_sample_count: 657313
total_episode_count: 6219
total_duration: 262.48532019147854
[2023-06-29 09:59:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 213.46666666666667
avg_sample_per_episode: 213.46666666666667
avg_envstep_per_sec: 2565.992235060108
avg_train_sample_per_sec: 2565.992235060108
avg_episode_per_sec: 12.020575742005503
collect_time: 1.2478603622606026
reward_mean: 968.565284546961
reward_std: 40.959233269287786
reward_max: 1013.3660883395206
reward_min: 864.2811056395187
total_envstep_count: 780664
total_train_sample_count: 660515
total_episode_count: 6234
total_duration: 263.73318055373915
[2023-06-29 09:59:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3316
train_sample_count: 3316
avg_envstep_per_episode: 221.06666666666666
avg_sample_per_episode: 221.06666666666666
avg_envstep_per_sec: 2609.5198669386327
avg_train_sample_per_sec: 2609.5198669386327
avg_episode_per_sec: 11.804221352255576
collect_time: 1.2707318468857556
reward_mean: 959.3453054849031
reward_std: 76.7577487861209
reward_max: 1154.372265338013
reward_min: 886.4154195886955
total_envstep_count: 785704
total_train_sample_count: 663831
total_episode_count: 6249
total_duration: 265.0039124006249
[2023-06-29 09:59:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3265
train_sample_count: 3265
avg_envstep_per_episode: 204.0625
avg_sample_per_episode: 204.0625
avg_envstep_per_sec: 2471.5350353956396
avg_train_sample_per_sec: 2471.5350353956396
avg_episode_per_sec: 12.11165714129563
collect_time: 1.3210413582008331
reward_mean: 981.824756381711
reward_std: 62.3949025376701
reward_max: 1187.281021061442
reward_min: 921.9678968458938
total_envstep_count: 790512
total_train_sample_count: 667096
total_episode_count: 6265
total_duration: 266.32495375882576
[2023-06-29 10:00:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3245
train_sample_count: 3245
avg_envstep_per_episode: 216.33333333333334
avg_sample_per_episode: 216.33333333333334
avg_envstep_per_sec: 2485.3852189704126
avg_train_sample_per_sec: 2485.3852189704126
avg_episode_per_sec: 11.488683600787732
collect_time: 1.3056326139029115
reward_mean: 1003.0566599278399
reward_std: 90.74063417882837
reward_max: 1263.8300608594923
reward_min: 905.4678658922512
total_envstep_count: 795152
total_train_sample_count: 670341
total_episode_count: 6280
total_duration: 267.63058637272866
[2023-06-29 10:00:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3102
train_sample_count: 3102
avg_envstep_per_episode: 221.57142857142858
avg_sample_per_episode: 221.57142857142858
avg_envstep_per_sec: 2462.253932547278
avg_train_sample_per_sec: 2462.253932547278
avg_episode_per_sec: 11.112686994088296
collect_time: 1.2598213202124464
reward_mean: 1002.3101034638723
reward_std: 109.4292200502496
reward_max: 1270.195817434844
reward_min: 920.4811966737442
total_envstep_count: 799896
total_train_sample_count: 673843
total_episode_count: 6294
total_duration: 268.8904076929411
[2023-06-29 10:00:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3086
train_sample_count: 3086
avg_envstep_per_episode: 220.42857142857142
avg_sample_per_episode: 220.42857142857142
avg_envstep_per_sec: 2447.5546679391537
avg_train_sample_per_sec: 2447.5546679391537
avg_episode_per_sec: 11.103618065828954
collect_time: 1.2608502847449854
reward_mean: 1053.8523561267962
reward_std: 120.38446168381763
reward_max: 1288.058519613988
reward_min: 954.8717004193154
total_envstep_count: 804296
total_train_sample_count: 677329
total_episode_count: 6308
total_duration: 270.1512579776861
[2023-06-29 10:00:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3131
train_sample_count: 3131
avg_envstep_per_episode: 240.84615384615384
avg_sample_per_episode: 240.84615384615384
avg_envstep_per_sec: 2367.527587969353
avg_train_sample_per_sec: 2367.527587969353
avg_episode_per_sec: 9.830041087065345
collect_time: 1.3224766697166486
reward_mean: 1055.3452946487866
reward_std: 129.34413117232012
reward_max: 1287.681585506033
reward_min: 897.1290851914655
total_envstep_count: 809352
total_train_sample_count: 680860
total_episode_count: 6321
total_duration: 271.47373464740275
[2023-06-29 10:00:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 219.53333333333333
avg_sample_per_episode: 219.53333333333333
avg_envstep_per_sec: 2461.245016594242
avg_train_sample_per_sec: 2461.245016594242
avg_episode_per_sec: 11.211258806229464
collect_time: 1.3379407486040145
reward_mean: 1076.42802307151
reward_std: 133.18960947610182
reward_max: 1276.3257219513769
reward_min: 941.5049700579175
total_envstep_count: 813752
total_train_sample_count: 684153
total_episode_count: 6336
total_duration: 272.81167539600676
[2023-06-29 10:00:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3464
train_sample_count: 3464
avg_envstep_per_episode: 247.42857142857142
avg_sample_per_episode: 247.42857142857142
avg_envstep_per_sec: 2421.425437158723
avg_train_sample_per_sec: 2421.425437158723
avg_episode_per_sec: 9.786361466576825
collect_time: 1.4305623236801477
reward_mean: 1021.3558873239577
reward_std: 100.7359551766124
reward_max: 1272.1591713801718
reward_min: 919.6729080976686
total_envstep_count: 817992
total_train_sample_count: 687617
total_episode_count: 6350
total_duration: 274.2422377196869
[2023-06-29 10:00:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3730
train_sample_count: 3730
avg_envstep_per_episode: 248.66666666666666
avg_sample_per_episode: 248.66666666666666
avg_envstep_per_sec: 2530.8492210820377
avg_train_sample_per_sec: 2530.8492210820377
avg_episode_per_sec: 10.17767783276959
collect_time: 1.4738135993756585
reward_mean: 958.9552311704448
reward_std: 87.25499063262212
reward_max: 1205.2188972881522
reward_min: 779.7080375366228
total_envstep_count: 822600
total_train_sample_count: 691347
total_episode_count: 6365
total_duration: 275.71605131906256
[2023-06-29 10:00:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3569
train_sample_count: 3569
avg_envstep_per_episode: 237.93333333333334
avg_sample_per_episode: 237.93333333333334
avg_envstep_per_sec: 2673.4820291393116
avg_train_sample_per_sec: 2673.4820291393116
avg_episode_per_sec: 11.236265182709351
collect_time: 1.334963153333403
reward_mean: 949.3117149638966
reward_std: 28.433601761604873
reward_max: 1007.2883998520507
reward_min: 885.857387738896
total_envstep_count: 827152
total_train_sample_count: 694916
total_episode_count: 6380
total_duration: 277.05101447239593
[2023-06-29 10:00:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3419
train_sample_count: 3419
avg_envstep_per_episode: 227.93333333333334
avg_sample_per_episode: 227.93333333333334
avg_envstep_per_sec: 2568.1382524343708
avg_train_sample_per_sec: 2568.1382524343708
avg_episode_per_sec: 11.267058726679018
collect_time: 1.3313146193586294
reward_mean: 951.7446485770723
reward_std: 29.9654595012224
reward_max: 1004.267822311039
reward_min: 904.2856989941411
total_envstep_count: 831920
total_train_sample_count: 698335
total_episode_count: 6395
total_duration: 278.38232909175457
[2023-06-29 10:00:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 200.0625
avg_sample_per_episode: 200.0625
avg_envstep_per_sec: 2458.980133864985
avg_train_sample_per_sec: 2458.980133864985
avg_episode_per_sec: 12.291059713164561
collect_time: 1.3017591951703653
reward_mean: 914.674986898912
reward_std: 157.13587758211764
reward_max: 1092.9198800638117
reward_min: 352.08803390899885
total_envstep_count: 836240
total_train_sample_count: 701536
total_episode_count: 6411
total_duration: 279.6840882869249
[2023-06-29 10:00:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3417
train_sample_count: 3417
avg_envstep_per_episode: 213.5625
avg_sample_per_episode: 213.5625
avg_envstep_per_sec: 2531.9632893618827
avg_train_sample_per_sec: 2531.9632893618827
avg_episode_per_sec: 11.855842150948236
collect_time: 1.3495456329705193
reward_mean: 924.0434984927348
reward_std: 47.77120957536628
reward_max: 972.6122991736789
reward_min: 791.9794085735867
total_envstep_count: 840904
total_train_sample_count: 704953
total_episode_count: 6427
total_duration: 281.03363391989546
[2023-06-29 10:00:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3505
train_sample_count: 3505
avg_envstep_per_episode: 233.66666666666666
avg_sample_per_episode: 233.66666666666666
avg_envstep_per_sec: 2680.876889702591
avg_train_sample_per_sec: 2680.876889702591
avg_episode_per_sec: 11.47308226691551
collect_time: 1.3074080400569363
reward_mean: 1010.8864543282297
reward_std: 83.70082876354995
reward_max: 1229.0612942351179
reward_min: 893.344300773464
total_envstep_count: 845336
total_train_sample_count: 708458
total_episode_count: 6442
total_duration: 282.3410419599524
[2023-06-29 10:00:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3173
train_sample_count: 3173
avg_envstep_per_episode: 264.4166666666667
avg_sample_per_episode: 264.4166666666667
avg_envstep_per_sec: 2470.456924533018
avg_train_sample_per_sec: 2470.456924533018
avg_episode_per_sec: 9.343045412668205
collect_time: 1.2843777879672122
reward_mean: 1070.8349882585073
reward_std: 150.18946819213784
reward_max: 1389.4621672360518
reward_min: 919.3504142063712
total_envstep_count: 849888
total_train_sample_count: 712031
total_episode_count: 6454
total_duration: 283.62541974791964
[2023-06-29 10:00:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3492
train_sample_count: 3492
avg_envstep_per_episode: 232.8
avg_sample_per_episode: 232.8
avg_envstep_per_sec: 2588.7523814733763
avg_train_sample_per_sec: 2588.7523814733763
avg_episode_per_sec: 11.120070367153678
collect_time: 1.3489123274171726
reward_mean: 1013.1374302274417
reward_std: 114.49449272850948
reward_max: 1245.7948670644332
reward_min: 758.2880131940378
total_envstep_count: 854672
total_train_sample_count: 715523
total_episode_count: 6469
total_duration: 284.9743320753368
[2023-06-29 10:00:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 230.14285714285714
avg_sample_per_episode: 230.14285714285714
avg_envstep_per_sec: 2728.9333212139954
avg_train_sample_per_sec: 2728.9333212139954
avg_episode_per_sec: 11.85756253786342
collect_time: 1.180681101642549
reward_mean: 1014.1101847816768
reward_std: 108.26965358871374
reward_max: 1265.0935272500485
reward_min: 852.6709176560279
total_envstep_count: 858648
total_train_sample_count: 718745
total_episode_count: 6483
total_duration: 286.15501317697937
[2023-06-29 10:00:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3411
train_sample_count: 3411
avg_envstep_per_episode: 243.64285714285714
avg_sample_per_episode: 243.64285714285714
avg_envstep_per_sec: 2723.530824108357
avg_train_sample_per_sec: 2723.530824108357
avg_episode_per_sec: 11.17837336192231
collect_time: 1.2524183570115128
reward_mean: 938.2050065883952
reward_std: 179.00111664994864
reward_max: 1097.8620060782707
reward_min: 351.951078701603
total_envstep_count: 863456
total_train_sample_count: 722156
total_episode_count: 6497
total_duration: 287.40743153399086
[2023-06-29 10:00:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3305
train_sample_count: 3305
avg_envstep_per_episode: 236.07142857142858
avg_sample_per_episode: 236.07142857142858
avg_envstep_per_sec: 2535.752998830485
avg_train_sample_per_sec: 2535.752998830485
avg_episode_per_sec: 10.741465047996003
collect_time: 1.303360383098945
reward_mean: 1070.2393907728135
reward_std: 122.55649867741188
reward_max: 1308.4685118425084
reward_min: 940.1735304100354
total_envstep_count: 867608
total_train_sample_count: 725461
total_episode_count: 6511
total_duration: 288.7107919170898
[2023-06-29 10:00:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3375
train_sample_count: 3375
avg_envstep_per_episode: 259.61538461538464
avg_sample_per_episode: 259.61538461538464
avg_envstep_per_sec: 2508.7246414195965
avg_train_sample_per_sec: 2508.7246414195965
avg_episode_per_sec: 9.663235655838447
collect_time: 1.345305078236968
reward_mean: 1007.702851718776
reward_std: 55.94463778098918
reward_max: 1186.2764138644732
reward_min: 953.8316361888787
total_envstep_count: 872328
total_train_sample_count: 728836
total_episode_count: 6524
total_duration: 290.05609699532675
[2023-06-29 10:00:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3459
train_sample_count: 3459
avg_envstep_per_episode: 266.0769230769231
avg_sample_per_episode: 266.0769230769231
avg_envstep_per_sec: 2527.134069280691
avg_train_sample_per_sec: 2527.134069280691
avg_episode_per_sec: 9.49775741562561
collect_time: 1.3687441604491326
reward_mean: 1153.8857574503809
reward_std: 140.50656728047457
reward_max: 1449.5478245230088
reward_min: 976.3760751973264
total_envstep_count: 877080
total_train_sample_count: 732295
total_episode_count: 6537
total_duration: 291.4248411557759
[2023-06-29 10:00:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3410
train_sample_count: 3410
avg_envstep_per_episode: 243.57142857142858
avg_sample_per_episode: 243.57142857142858
avg_envstep_per_sec: 2690.7998145500387
avg_train_sample_per_sec: 2690.7998145500387
avg_episode_per_sec: 11.047271965894588
collect_time: 1.267281193331815
reward_mean: 1043.6025593667766
reward_std: 107.50360978008777
reward_max: 1282.7076961776845
reward_min: 904.3693886361732
total_envstep_count: 881536
total_train_sample_count: 735705
total_episode_count: 6551
total_duration: 292.6921223491077
[2023-06-29 10:01:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 278.8333333333333
avg_sample_per_episode: 278.8333333333333
avg_envstep_per_sec: 2575.6935933586783
avg_train_sample_per_sec: 2575.6935933586783
avg_episode_per_sec: 9.237394835715524
collect_time: 1.2990675632487985
reward_mean: 1147.2248228911533
reward_std: 111.71690292470677
reward_max: 1269.93970500243
reward_min: 964.4886977266788
total_envstep_count: 886224
total_train_sample_count: 739051
total_episode_count: 6563
total_duration: 293.9911899123565
[2023-06-29 10:01:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3427
train_sample_count: 3427
avg_envstep_per_episode: 263.61538461538464
avg_sample_per_episode: 263.61538461538464
avg_envstep_per_sec: 2486.314238409264
avg_train_sample_per_sec: 2486.314238409264
avg_episode_per_sec: 9.431597636218392
collect_time: 1.3783454830683768
reward_mean: 1122.5146365707337
reward_std: 95.08002168067458
reward_max: 1234.5435298097104
reward_min: 968.036956224316
total_envstep_count: 891032
total_train_sample_count: 742478
total_episode_count: 6576
total_duration: 295.36953539542486
[2023-06-29 10:01:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3141
train_sample_count: 3141
avg_envstep_per_episode: 261.75
avg_sample_per_episode: 261.75
avg_envstep_per_sec: 2721.097907239424
avg_train_sample_per_sec: 2721.097907239424
avg_episode_per_sec: 10.395789521449565
collect_time: 1.154313481938094
reward_mean: 1168.6879128001538
reward_std: 69.05015150112439
reward_max: 1247.8399261364711
reward_min: 982.5983320855267
total_envstep_count: 895816
total_train_sample_count: 746019
total_episode_count: 6588
total_duration: 296.523848877363
[2023-06-29 10:01:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3302
train_sample_count: 3302
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2723.521818221548
avg_train_sample_per_sec: 2723.521818221548
avg_episode_per_sec: 10.722526843391922
collect_time: 1.2124007885335013
reward_mean: 1175.1675363969289
reward_std: 87.28606000846032
reward_max: 1279.4111140173175
reward_min: 966.2725318362866
total_envstep_count: 900808
total_train_sample_count: 749321
total_episode_count: 6601
total_duration: 297.7362496658965
[2023-06-29 10:01:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3463
train_sample_count: 3463
avg_envstep_per_episode: 266.38461538461536
avg_sample_per_episode: 266.38461538461536
avg_envstep_per_sec: 2604.0551009194755
avg_train_sample_per_sec: 2604.0551009194755
avg_episode_per_sec: 9.7755461484127
collect_time: 1.3298489723881943
reward_mean: 1248.174151306551
reward_std: 150.42436051708924
reward_max: 1488.0930566252384
reward_min: 965.0851139382843
total_envstep_count: 905488
total_train_sample_count: 752784
total_episode_count: 6614
total_duration: 299.0660986382847
[2023-06-29 10:01:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3190
train_sample_count: 3190
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 2566.044506376295
avg_train_sample_per_sec: 2566.044506376295
avg_episode_per_sec: 8.848429332332053
collect_time: 1.243158484614454
reward_mean: 1242.8747069324236
reward_std: 145.57044336797173
reward_max: 1532.3633371290584
reward_min: 971.5147643241315
total_envstep_count: 910544
total_train_sample_count: 756374
total_episode_count: 6625
total_duration: 300.30925712289917
[2023-06-29 10:01:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3305
train_sample_count: 3305
avg_envstep_per_episode: 236.07142857142858
avg_sample_per_episode: 236.07142857142858
avg_envstep_per_sec: 2577.7314642047486
avg_train_sample_per_sec: 2577.7314642047486
avg_episode_per_sec: 10.91928608135143
collect_time: 1.2821351044103502
reward_mean: 1145.41787583092
reward_std: 147.8291474584617
reward_max: 1411.6255475833557
reward_min: 962.1318973817748
total_envstep_count: 915232
total_train_sample_count: 759679
total_episode_count: 6639
total_duration: 301.59139222730954
[2023-06-29 10:01:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 243.91666666666666
avg_sample_per_episode: 243.91666666666666
avg_envstep_per_sec: 2596.2777935209915
avg_train_sample_per_sec: 2596.2777935209915
avg_episode_per_sec: 10.644118046550016
collect_time: 1.1273832127302885
reward_mean: 1109.2892992447905
reward_std: 174.84808535112515
reward_max: 1492.946542384189
reward_min: 932.3764794758524
total_envstep_count: 920088
total_train_sample_count: 763006
total_episode_count: 6651
total_duration: 302.71877544003985
[2023-06-29 10:01:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 207.41666666666666
avg_sample_per_episode: 207.41666666666666
avg_envstep_per_sec: 2515.1120730323682
avg_train_sample_per_sec: 2515.1120730323682
avg_episode_per_sec: 12.125891874804507
collect_time: 0.9896179286353288
reward_mean: 1163.0614940692815
reward_std: 111.2693286969604
reward_max: 1337.8128027644536
reward_min: 976.3933663576952
total_envstep_count: 924696
total_train_sample_count: 766295
total_episode_count: 6663
total_duration: 303.70839336867516
[2023-06-29 10:01:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3431
train_sample_count: 3431
avg_envstep_per_episode: 228.73333333333332
avg_sample_per_episode: 228.73333333333332
avg_envstep_per_sec: 2514.5851499781274
avg_train_sample_per_sec: 2514.5851499781274
avg_episode_per_sec: 10.99352295239636
collect_time: 1.364439776489511
reward_mean: 1161.863729732948
reward_std: 131.64555473102698
reward_max: 1343.0668486109805
reward_min: 952.0433715090694
total_envstep_count: 929688
total_train_sample_count: 770126
total_episode_count: 6678
total_duration: 305.0728331451647
[2023-06-29 10:01:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3296
train_sample_count: 3296
avg_envstep_per_episode: 253.53846153846155
avg_sample_per_episode: 253.53846153846155
avg_envstep_per_sec: 2495.940119923608
avg_train_sample_per_sec: 2495.940119923608
avg_episode_per_sec: 9.844424016688988
collect_time: 1.3205445009237156
reward_mean: 1176.7993738295002
reward_std: 140.70654443472347
reward_max: 1439.2628253040693
reward_min: 962.4463626555533
total_envstep_count: 934256
total_train_sample_count: 773422
total_episode_count: 6691
total_duration: 306.39337764608837
[2023-06-29 10:01:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3478
train_sample_count: 3478
avg_envstep_per_episode: 267.53846153846155
avg_sample_per_episode: 267.53846153846155
avg_envstep_per_sec: 2272.995747371873
avg_train_sample_per_sec: 2272.995747371873
avg_episode_per_sec: 8.495958802712579
collect_time: 1.5301392464202364
reward_mean: 1152.7421339497905
reward_std: 191.1515250428345
reward_max: 1672.5153892567203
reward_min: 980.3733381062001
total_envstep_count: 938992
total_train_sample_count: 776900
total_episode_count: 6704
total_duration: 307.9235168925086
[2023-06-29 10:01:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2905
train_sample_count: 2905
avg_envstep_per_episode: 242.08333333333334
avg_sample_per_episode: 242.08333333333334
avg_envstep_per_sec: 2640.4113413129257
avg_train_sample_per_sec: 2640.4113413129257
avg_episode_per_sec: 10.907034800604169
collect_time: 1.1002073633555556
reward_mean: 1086.822630411577
reward_std: 147.18981656226734
reward_max: 1417.8361794537059
reward_min: 891.4598434854694
total_envstep_count: 943704
total_train_sample_count: 780205
total_episode_count: 6716
total_duration: 309.0237242558641
[2023-06-29 10:01:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3507
train_sample_count: 3507
avg_envstep_per_episode: 219.1875
avg_sample_per_episode: 219.1875
avg_envstep_per_sec: 2708.98429577209
avg_train_sample_per_sec: 2708.98429577209
avg_episode_per_sec: 12.35920978966451
collect_time: 1.2945811481717975
reward_mean: 1045.6379542930279
reward_std: 160.13610658615985
reward_max: 1425.3464129086642
reward_min: 779.6037895330845
total_envstep_count: 948648
total_train_sample_count: 783712
total_episode_count: 6732
total_duration: 310.3183054040359
[2023-06-29 10:01:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3358
train_sample_count: 3358
avg_envstep_per_episode: 239.85714285714286
avg_sample_per_episode: 239.85714285714286
avg_envstep_per_sec: 2471.011633117861
avg_train_sample_per_sec: 2471.011633117861
avg_episode_per_sec: 10.302013955821934
collect_time: 1.3589575844136998
reward_mean: 1082.1209187387396
reward_std: 115.56887326437385
reward_max: 1329.4211632254924
reward_min: 964.5109536848415
total_envstep_count: 953024
total_train_sample_count: 787070
total_episode_count: 6746
total_duration: 311.6772629884496
[2023-06-29 10:01:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 269.75
avg_sample_per_episode: 269.75
avg_envstep_per_sec: 2529.0789134557854
avg_train_sample_per_sec: 2529.0789134557854
avg_episode_per_sec: 9.375640086953792
collect_time: 1.2799126127610216
reward_mean: 1138.2042877508272
reward_std: 186.33457155901252
reward_max: 1375.02302898294
reward_min: 819.3473903525583
total_envstep_count: 957576
total_train_sample_count: 790307
total_episode_count: 6758
total_duration: 312.9571756012106
[2023-06-29 10:01:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3174
train_sample_count: 3174
avg_envstep_per_episode: 244.15384615384616
avg_sample_per_episode: 244.15384615384616
avg_envstep_per_sec: 2502.26770077629
avg_train_sample_per_sec: 2502.26770077629
avg_episode_per_sec: 10.248733494042776
collect_time: 1.2684494145112113
reward_mean: 1114.1429876334169
reward_std: 142.90694120131286
reward_max: 1344.9617792781607
reward_min: 923.7450692871524
total_envstep_count: 962360
total_train_sample_count: 793881
total_episode_count: 6771
total_duration: 314.22562501572185
[2023-06-29 10:01:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3368
train_sample_count: 3368
avg_envstep_per_episode: 224.53333333333333
avg_sample_per_episode: 224.53333333333333
avg_envstep_per_sec: 2597.0582189927104
avg_train_sample_per_sec: 2597.0582189927104
avg_episode_per_sec: 11.566470690288199
collect_time: 1.2968519440069795
reward_mean: 1065.2705702191095
reward_std: 149.56405682793607
reward_max: 1329.1199059664627
reward_min: 752.5942678214228
total_envstep_count: 966984
total_train_sample_count: 797249
total_episode_count: 6786
total_duration: 315.5224769597288
[2023-06-29 10:01:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3409
train_sample_count: 3409
avg_envstep_per_episode: 227.26666666666668
avg_sample_per_episode: 227.26666666666668
avg_envstep_per_sec: 2479.660424005466
avg_train_sample_per_sec: 2479.660424005466
avg_episode_per_sec: 10.910796820205922
collect_time: 1.3747850177377696
reward_mean: 1005.2845828763147
reward_std: 110.49810481171514
reward_max: 1225.8192665346571
reward_min: 767.7338033762238
total_envstep_count: 971640
total_train_sample_count: 800658
total_episode_count: 6801
total_duration: 316.8972619774666
[2023-06-29 10:01:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 213.46666666666667
avg_sample_per_episode: 213.46666666666667
avg_envstep_per_sec: 2496.853280198648
avg_train_sample_per_sec: 2496.853280198648
avg_episode_per_sec: 11.696689320106096
collect_time: 1.2824141592113298
reward_mean: 971.9535275993475
reward_std: 150.7950306036326
reward_max: 1255.998373609023
reward_min: 724.5100150906517
total_envstep_count: 976232
total_train_sample_count: 803860
total_episode_count: 6816
total_duration: 318.1796761366779
[2023-06-29 10:02:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 202.1875
avg_sample_per_episode: 202.1875
avg_envstep_per_sec: 2383.649153460213
avg_train_sample_per_sec: 2383.649153460213
avg_episode_per_sec: 11.78930029532099
collect_time: 1.357162817063043
reward_mean: 948.1825814350491
reward_std: 175.50252491254756
reward_max: 1297.1571511484872
reward_min: 664.1157034503468
total_envstep_count: 980560
total_train_sample_count: 807095
total_episode_count: 6832
total_duration: 319.536838953741
[2023-06-29 10:02:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3488
train_sample_count: 3488
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2129.69233469305
avg_train_sample_per_sec: 2129.69233469305
avg_episode_per_sec: 9.769230893087384
collect_time: 1.637795254826196
reward_mean: 939.8058426144441
reward_std: 81.32875611202837
reward_max: 1027.0186430432027
reward_min: 749.2882439717117
total_envstep_count: 985296
total_train_sample_count: 810583
total_episode_count: 6848
total_duration: 321.17463420856717
[2023-06-29 10:02:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3459
train_sample_count: 3459
avg_envstep_per_episode: 216.1875
avg_sample_per_episode: 216.1875
avg_envstep_per_sec: 2271.6505322304574
avg_train_sample_per_sec: 2271.6505322304574
avg_episode_per_sec: 10.50777927600096
collect_time: 1.5226813943972817
reward_mean: 974.4997626626455
reward_std: 101.62790716881177
reward_max: 1122.0704725185042
reward_min: 743.5399636867468
total_envstep_count: 989728
total_train_sample_count: 814042
total_episode_count: 6864
total_duration: 322.69731560296447
[2023-06-29 10:02:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3379
train_sample_count: 3379
avg_envstep_per_episode: 241.35714285714286
avg_sample_per_episode: 241.35714285714286
avg_envstep_per_sec: 2370.715215062375
avg_train_sample_per_sec: 2370.715215062375
avg_episode_per_sec: 9.82243652289827
collect_time: 1.4253082692224996
reward_mean: 1017.3940008451643
reward_std: 74.9325418556518
reward_max: 1115.9622290936225
reward_min: 796.1096085832436
total_envstep_count: 994240
total_train_sample_count: 817421
total_episode_count: 6878
total_duration: 324.122623872187
[2023-06-29 10:02:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3352
train_sample_count: 3352
avg_envstep_per_episode: 257.84615384615387
avg_sample_per_episode: 257.84615384615387
avg_envstep_per_sec: 2589.156786715528
avg_train_sample_per_sec: 2589.156786715528
avg_episode_per_sec: 10.041479184755927
collect_time: 1.2946299803853036
reward_mean: 1126.0343208830786
reward_std: 160.04225478896026
reward_max: 1502.6203858331621
reward_min: 843.3372048842231
total_envstep_count: 998096
total_train_sample_count: 820773
total_episode_count: 6891
total_duration: 325.4172538525723
[2023-06-29 10:02:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3272
train_sample_count: 3272
avg_envstep_per_episode: 272.6666666666667
avg_sample_per_episode: 272.6666666666667
avg_envstep_per_sec: 2620.2845174351796
avg_train_sample_per_sec: 2620.2845174351796
avg_episode_per_sec: 9.60984541846643
collect_time: 1.2487193578515439
reward_mean: 1028.683772649677
reward_std: 81.73527321576177
reward_max: 1248.3648530574296
reward_min: 921.6301552701373
total_envstep_count: 1003016
total_train_sample_count: 824045
total_episode_count: 6903
total_duration: 326.66597321042383
[2023-06-29 10:02:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3352
train_sample_count: 3352
avg_envstep_per_episode: 223.46666666666667
avg_sample_per_episode: 223.46666666666667
avg_envstep_per_sec: 2473.946437732189
avg_train_sample_per_sec: 2473.946437732189
avg_episode_per_sec: 11.07076269868223
collect_time: 1.3549201991101727
reward_mean: 1090.7456364704042
reward_std: 255.8607743232397
reward_max: 1352.5132198798221
reward_min: 240.87376614453697
total_envstep_count: 1007816
total_train_sample_count: 827397
total_episode_count: 6918
total_duration: 328.020893409534
[2023-06-29 10:02:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3369
train_sample_count: 3369
avg_envstep_per_episode: 224.6
avg_sample_per_episode: 224.6
avg_envstep_per_sec: 2541.7640050842206
avg_train_sample_per_sec: 2541.7640050842206
avg_episode_per_sec: 11.316847751933306
collect_time: 1.3254574355687947
reward_mean: 1049.3458704881964
reward_std: 129.97221839060592
reward_max: 1317.895552799328
reward_min: 807.8785135629001
total_envstep_count: 1012024
total_train_sample_count: 830766
total_episode_count: 6933
total_duration: 329.3463508451028
[2023-06-29 10:02:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3436
train_sample_count: 3436
avg_envstep_per_episode: 264.3076923076923
avg_sample_per_episode: 264.3076923076923
avg_envstep_per_sec: 2703.7591508033543
avg_train_sample_per_sec: 2703.7591508033543
avg_episode_per_sec: 10.229589336566823
collect_time: 1.270823253239505
reward_mean: 1070.5701015576444
reward_std: 161.60308169120216
reward_max: 1453.5111758244414
reward_min: 732.0669502081412
total_envstep_count: 1016768
total_train_sample_count: 834202
total_episode_count: 6946
total_duration: 330.6171740983423
[2023-06-29 10:02:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3324
train_sample_count: 3324
avg_envstep_per_episode: 237.42857142857142
avg_sample_per_episode: 237.42857142857142
avg_envstep_per_sec: 2659.0522218975743
avg_train_sample_per_sec: 2659.0522218975743
avg_episode_per_sec: 11.199377589219628
collect_time: 1.2500694693494587
reward_mean: 1079.9019154979233
reward_std: 65.20276609892207
reward_max: 1219.7810441018266
reward_min: 1002.1766706870733
total_envstep_count: 1021352
total_train_sample_count: 837526
total_episode_count: 6960
total_duration: 331.86724356769173
[2023-06-29 10:02:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3417
train_sample_count: 3417
avg_envstep_per_episode: 244.07142857142858
avg_sample_per_episode: 244.07142857142858
avg_envstep_per_sec: 2474.627096890386
avg_train_sample_per_sec: 2474.627096890386
avg_episode_per_sec: 10.138946255916126
collect_time: 1.3808141049994154
reward_mean: 1098.5927500061418
reward_std: 140.56874044864796
reward_max: 1485.6864217992663
reward_min: 979.8348622525748
total_envstep_count: 1025944
total_train_sample_count: 840943
total_episode_count: 6974
total_duration: 333.2480576726911
[2023-06-29 10:02:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3378
train_sample_count: 3378
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 2279.1133048806405
avg_train_sample_per_sec: 2279.1133048806405
avg_episode_per_sec: 8.096317246467638
collect_time: 1.4821553596155719
reward_mean: 1227.4719030251742
reward_std: 134.80617492465072
reward_max: 1421.7333490888175
reward_min: 1002.0656089143235
total_envstep_count: 1030376
total_train_sample_count: 844321
total_episode_count: 6986
total_duration: 334.73021303230666
[2023-06-29 10:02:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3175
train_sample_count: 3175
avg_envstep_per_episode: 264.5833333333333
avg_sample_per_episode: 264.5833333333333
avg_envstep_per_sec: 2465.0227976540427
avg_train_sample_per_sec: 2465.0227976540427
avg_episode_per_sec: 9.3166215974326
collect_time: 1.2880205420500133
reward_mean: 1132.787944039831
reward_std: 143.89021223732752
reward_max: 1380.7409511232952
reward_min: 993.5900591575494
total_envstep_count: 1035136
total_train_sample_count: 847896
total_episode_count: 6998
total_duration: 336.01823357435666
[2023-06-29 10:02:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3286
train_sample_count: 3286
avg_envstep_per_episode: 234.71428571428572
avg_sample_per_episode: 234.71428571428572
avg_envstep_per_sec: 2656.8527931743406
avg_train_sample_per_sec: 2656.8527931743406
avg_episode_per_sec: 11.319518899708084
collect_time: 1.2368016807110982
reward_mean: 1135.6459680250746
reward_std: 161.55506521905295
reward_max: 1506.6224208618696
reward_min: 967.4069391965542
total_envstep_count: 1039952
total_train_sample_count: 851182
total_episode_count: 7012
total_duration: 337.25503525506775
[2023-06-29 10:02:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2999
train_sample_count: 2999
avg_envstep_per_episode: 214.21428571428572
avg_sample_per_episode: 214.21428571428572
avg_envstep_per_sec: 2415.3504113544036
avg_train_sample_per_sec: 2415.3504113544036
avg_episode_per_sec: 11.275393717559737
collect_time: 1.2416417865920812
reward_mean: 1050.058648614409
reward_std: 77.1991940195779
reward_max: 1287.8672654229547
reward_min: 956.1112435698716
total_envstep_count: 1044528
total_train_sample_count: 854581
total_episode_count: 7026
total_duration: 338.49667704165984
[2023-06-29 10:02:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 230.92857142857142
avg_sample_per_episode: 230.92857142857142
avg_envstep_per_sec: 2457.0053592523686
avg_train_sample_per_sec: 2457.0053592523686
avg_episode_per_sec: 10.639676779936021
collect_time: 1.3158294457215818
reward_mean: 1123.6009107570267
reward_std: 126.95134852035949
reward_max: 1341.5757160438923
reward_min: 952.1181304947565
total_envstep_count: 1048712
total_train_sample_count: 857814
total_episode_count: 7040
total_duration: 339.8125064873814
[2023-06-29 10:02:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3464
train_sample_count: 3464
avg_envstep_per_episode: 247.42857142857142
avg_sample_per_episode: 247.42857142857142
avg_envstep_per_sec: 2475.670366050009
avg_train_sample_per_sec: 2475.670366050009
avg_episode_per_sec: 10.005596167638604
collect_time: 1.399216974724666
reward_mean: 1027.5745542410518
reward_std: 66.81604725474384
reward_max: 1152.036835549042
reward_min: 865.1159731939327
total_envstep_count: 1053096
total_train_sample_count: 861278
total_episode_count: 7054
total_duration: 341.2117234621061
[2023-06-29 10:02:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 248.46153846153845
avg_sample_per_episode: 248.46153846153845
avg_envstep_per_sec: 2689.5888140372927
avg_train_sample_per_sec: 2689.5888140372927
avg_episode_per_sec: 10.824970458973624
collect_time: 1.2009270648146049
reward_mean: 1048.641853214364
reward_std: 64.36988043502794
reward_max: 1232.7295231427836
reward_min: 1000.4668003002084
total_envstep_count: 1057512
total_train_sample_count: 864508
total_episode_count: 7067
total_duration: 342.4126505269207
[2023-06-29 10:02:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 238.14285714285714
avg_sample_per_episode: 238.14285714285714
avg_envstep_per_sec: 2669.3492973669136
avg_train_sample_per_sec: 2669.3492973669136
avg_episode_per_sec: 11.209025243892258
collect_time: 1.2489935293551533
reward_mean: 1061.3272668337315
reward_std: 86.78731264518885
reward_max: 1273.0992879506566
reward_min: 956.5153719873327
total_envstep_count: 1062064
total_train_sample_count: 867842
total_episode_count: 7081
total_duration: 343.66164405627586
[2023-06-29 10:03:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3357
train_sample_count: 3357
avg_envstep_per_episode: 223.8
avg_sample_per_episode: 223.8
avg_envstep_per_sec: 2474.038473067126
avg_train_sample_per_sec: 2474.038473067126
avg_episode_per_sec: 11.05468486625168
collect_time: 1.3568907826393843
reward_mean: 1001.0248692091659
reward_std: 73.9936033802403
reward_max: 1102.0963163752533
reward_min: 758.3183791763669
total_envstep_count: 1066432
total_train_sample_count: 871199
total_episode_count: 7096
total_duration: 345.01853483891523
[2023-06-29 10:03:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3306
train_sample_count: 3306
avg_envstep_per_episode: 236.14285714285714
avg_sample_per_episode: 236.14285714285714
avg_envstep_per_sec: 2530.7867968682594
avg_train_sample_per_sec: 2530.7867968682594
avg_episode_per_sec: 10.71718546768168
collect_time: 1.306313121315092
reward_mean: 1013.5411000713547
reward_std: 133.26195164591098
reward_max: 1355.369250046426
reward_min: 774.9036042622
total_envstep_count: 1070600
total_train_sample_count: 874505
total_episode_count: 7110
total_duration: 346.32484796023033
[2023-06-29 10:03:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3295
train_sample_count: 3295
avg_envstep_per_episode: 299.54545454545456
avg_sample_per_episode: 299.54545454545456
avg_envstep_per_sec: 2393.924519985086
avg_train_sample_per_sec: 2393.924519985086
avg_episode_per_sec: 7.991857274608786
collect_time: 1.3764009568775073
reward_mean: 1227.4915360101359
reward_std: 137.54031712706364
reward_max: 1466.5471682267062
reward_min: 1010.2867103766454
total_envstep_count: 1075248
total_train_sample_count: 877800
total_episode_count: 7121
total_duration: 347.7012489171078
[2023-06-29 10:03:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2641
train_sample_count: 2641
avg_envstep_per_episode: 240.0909090909091
avg_sample_per_episode: 240.0909090909091
avg_envstep_per_sec: 2608.1844749149964
avg_train_sample_per_sec: 2608.1844749149964
avg_episode_per_sec: 10.863320418048072
collect_time: 1.0125817500259728
reward_mean: 1171.6657307683074
reward_std: 233.2245316783775
reward_max: 1660.0397801769216
reward_min: 932.1934680011345
total_envstep_count: 1079128
total_train_sample_count: 881241
total_episode_count: 7132
total_duration: 348.7138306671338
[2023-06-29 10:03:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3395
train_sample_count: 3395
avg_envstep_per_episode: 282.9166666666667
avg_sample_per_episode: 282.9166666666667
avg_envstep_per_sec: 2434.655177075875
avg_train_sample_per_sec: 2434.655177075875
avg_episode_per_sec: 8.605555854170987
collect_time: 1.394447982599959
reward_mean: 1201.4109543843642
reward_std: 271.6587667059567
reward_max: 1664.7931785915785
reward_min: 656.4193853067873
total_envstep_count: 1084368
total_train_sample_count: 884636
total_episode_count: 7144
total_duration: 350.10827864973373
[2023-06-29 10:03:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 244.0909090909091
avg_sample_per_episode: 244.0909090909091
avg_envstep_per_sec: 2463.995895764993
avg_train_sample_per_sec: 2463.995895764993
avg_episode_per_sec: 10.094582813189916
collect_time: 1.08969337352179
reward_mean: 1294.432679468192
reward_std: 121.48201558184998
reward_max: 1479.1557471028175
reward_min: 1044.890061693061
total_envstep_count: 1088688
total_train_sample_count: 888121
total_episode_count: 7155
total_duration: 351.19797202325555
[2023-06-29 10:03:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3261
train_sample_count: 3261
avg_envstep_per_episode: 271.75
avg_sample_per_episode: 271.75
avg_envstep_per_sec: 2560.2400062724373
avg_train_sample_per_sec: 2560.2400062724373
avg_episode_per_sec: 9.421306370827736
collect_time: 1.2737087116874755
reward_mean: 1298.6443092765655
reward_std: 232.5671886730503
reward_max: 1746.4669299361328
reward_min: 994.6259665017824
total_envstep_count: 1093344
total_train_sample_count: 891382
total_episode_count: 7167
total_duration: 352.471680734943
[2023-06-29 10:03:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3880
train_sample_count: 3880
avg_envstep_per_episode: 277.14285714285717
avg_sample_per_episode: 277.14285714285717
avg_envstep_per_sec: 2544.7141715848484
avg_train_sample_per_sec: 2544.7141715848484
avg_episode_per_sec: 9.18195835107935
collect_time: 1.5247291987938807
reward_mean: 1219.2893415200324
reward_std: 156.3416860445989
reward_max: 1517.3349153780205
reward_min: 974.9525383897228
total_envstep_count: 1098040
total_train_sample_count: 895262
total_episode_count: 7181
total_duration: 353.99640993373686
[2023-06-29 10:03:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 261.3076923076923
avg_sample_per_episode: 261.3076923076923
avg_envstep_per_sec: 2448.823648889446
avg_train_sample_per_sec: 2448.823648889446
avg_episode_per_sec: 9.371418144116218
collect_time: 1.3871966654440622
reward_mean: 1043.294469994237
reward_std: 129.46685660985108
reward_max: 1395.6013741362538
reward_min: 880.6511498274139
total_envstep_count: 1102872
total_train_sample_count: 898659
total_episode_count: 7194
total_duration: 355.3836065991809
[2023-06-29 10:03:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3496
train_sample_count: 3496
avg_envstep_per_episode: 249.71428571428572
avg_sample_per_episode: 249.71428571428572
avg_envstep_per_sec: 2327.1163412758715
avg_train_sample_per_sec: 2327.1163412758715
avg_episode_per_sec: 9.319115783141362
collect_time: 1.5022884494392201
reward_mean: 1141.3284333854622
reward_std: 102.60157160169598
reward_max: 1361.4592047732838
reward_min: 990.1590965993324
total_envstep_count: 1107928
total_train_sample_count: 902155
total_episode_count: 7208
total_duration: 356.8858950486201
[2023-06-29 10:03:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3402
train_sample_count: 3402
avg_envstep_per_episode: 226.8
avg_sample_per_episode: 226.8
avg_envstep_per_sec: 2422.194481759714
avg_train_sample_per_sec: 2422.194481759714
avg_episode_per_sec: 10.679869849028721
collect_time: 1.404511497990228
reward_mean: 1075.1886974950587
reward_std: 149.52850977582426
reward_max: 1422.921535759787
reward_min: 891.9847854251456
total_envstep_count: 1112320
total_train_sample_count: 905557
total_episode_count: 7223
total_duration: 358.29040654661037
[2023-06-29 10:03:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3006
train_sample_count: 3006
avg_envstep_per_episode: 273.27272727272725
avg_sample_per_episode: 273.27272727272725
avg_envstep_per_sec: 2307.4042830608228
avg_train_sample_per_sec: 2307.4042830608228
avg_episode_per_sec: 8.443595180861294
collect_time: 1.3027625986775384
reward_mean: 1152.171895246512
reward_std: 172.66092367686682
reward_max: 1548.3936889411732
reward_min: 969.2492312872434
total_envstep_count: 1117408
total_train_sample_count: 908963
total_episode_count: 7234
total_duration: 359.5931691452879
[2023-06-29 10:03:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3398
train_sample_count: 3398
avg_envstep_per_episode: 226.53333333333333
avg_sample_per_episode: 226.53333333333333
avg_envstep_per_sec: 2500.0743078682185
avg_train_sample_per_sec: 2500.0743078682185
avg_episode_per_sec: 11.036231494415325
collect_time: 1.3591596014989775
reward_mean: 1167.0527839872293
reward_std: 192.17245328826343
reward_max: 1585.7736571963387
reward_min: 812.7336654820331
total_envstep_count: 1122072
total_train_sample_count: 912361
total_episode_count: 7249
total_duration: 360.95232874678686
[2023-06-29 10:03:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3568
train_sample_count: 3568
avg_envstep_per_episode: 237.86666666666667
avg_sample_per_episode: 237.86666666666667
avg_envstep_per_sec: 2588.1704370588955
avg_train_sample_per_sec: 2588.1704370588955
avg_episode_per_sec: 10.880761366559259
collect_time: 1.3785799995670098
reward_mean: 1042.6352730806157
reward_std: 204.3144982391681
reward_max: 1258.0894265584682
reward_min: 412.6875883256652
total_envstep_count: 1126904
total_train_sample_count: 915929
total_episode_count: 7264
total_duration: 362.3309087463539
[2023-06-29 10:03:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3398
train_sample_count: 3398
avg_envstep_per_episode: 226.53333333333333
avg_sample_per_episode: 226.53333333333333
avg_envstep_per_sec: 2424.822280374462
avg_train_sample_per_sec: 2424.822280374462
avg_episode_per_sec: 10.704041849798978
collect_time: 1.4013398126130925
reward_mean: 1029.41915677529
reward_std: 81.90324042528451
reward_max: 1237.2309090181914
reward_min: 944.4020606416251
total_envstep_count: 1131600
total_train_sample_count: 919327
total_episode_count: 7279
total_duration: 363.732248558967
[2023-06-29 10:03:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3445
train_sample_count: 3445
avg_envstep_per_episode: 229.66666666666666
avg_sample_per_episode: 229.66666666666666
avg_envstep_per_sec: 2570.3667339172366
avg_train_sample_per_sec: 2570.3667339172366
avg_episode_per_sec: 11.191727433601901
collect_time: 1.3402756713824346
reward_mean: 1046.6222222129827
reward_std: 188.71229108735903
reward_max: 1442.088005407375
reward_min: 723.147654093062
total_envstep_count: 1136184
total_train_sample_count: 922772
total_episode_count: 7294
total_duration: 365.0725242303494
[2023-06-29 10:03:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3330
train_sample_count: 3330
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2555.967187695995
avg_train_sample_per_sec: 2555.967187695995
avg_episode_per_sec: 11.51336571034232
collect_time: 1.3028336263587699
reward_mean: 997.131414594195
reward_std: 109.53229513218527
reward_max: 1189.95308020376
reward_min: 718.5668094430979
total_envstep_count: 1140504
total_train_sample_count: 926102
total_episode_count: 7309
total_duration: 366.3753578567082
[2023-06-29 10:03:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3475
train_sample_count: 3475
avg_envstep_per_episode: 217.1875
avg_sample_per_episode: 217.1875
avg_envstep_per_sec: 2679.7436222061133
avg_train_sample_per_sec: 2679.7436222061133
avg_episode_per_sec: 12.338387900805127
collect_time: 1.2967658440172674
reward_mean: 915.2828971196255
reward_std: 103.52735189820557
reward_max: 1023.933025081053
reward_min: 720.4384379949089
total_envstep_count: 1145184
total_train_sample_count: 929577
total_episode_count: 7325
total_duration: 367.6721237007255
[2023-06-29 10:03:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3295
train_sample_count: 3295
avg_envstep_per_episode: 219.66666666666666
avg_sample_per_episode: 219.66666666666666
avg_envstep_per_sec: 2671.759685331013
avg_train_sample_per_sec: 2671.759685331013
avg_episode_per_sec: 12.16279067677244
collect_time: 1.2332696005897597
reward_mean: 994.170378902803
reward_std: 111.84647193420923
reward_max: 1323.295926994458
reward_min: 814.0923070474169
total_envstep_count: 1149624
total_train_sample_count: 932872
total_episode_count: 7340
total_duration: 368.90539330131526
[2023-06-29 10:03:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 2542.1718724002876
avg_train_sample_per_sec: 2542.1718724002876
avg_episode_per_sec: 11.824055220466454
collect_time: 1.2686003000084312
reward_mean: 963.6780400286635
reward_std: 66.75227320618892
reward_max: 1055.8508951426684
reward_min: 842.1826815806191
total_envstep_count: 1154104
total_train_sample_count: 936097
total_episode_count: 7355
total_duration: 370.1739936013237
[2023-06-29 10:04:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3275
train_sample_count: 3275
avg_envstep_per_episode: 218.33333333333334
avg_sample_per_episode: 218.33333333333334
avg_envstep_per_sec: 2545.4580814903015
avg_train_sample_per_sec: 2545.4580814903015
avg_episode_per_sec: 11.658586632780008
collect_time: 1.2866053555604302
reward_mean: 995.4974083667919
reward_std: 129.88143387012832
reward_max: 1296.5078096042828
reward_min: 720.6325962867176
total_envstep_count: 1158216
total_train_sample_count: 939372
total_episode_count: 7370
total_duration: 371.4605989568841
[2023-06-29 10:04:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3255
train_sample_count: 3255
avg_envstep_per_episode: 232.5
avg_sample_per_episode: 232.5
avg_envstep_per_sec: 2442.2621320903468
avg_train_sample_per_sec: 2442.2621320903468
avg_episode_per_sec: 10.504353256302567
collect_time: 1.3327807679735124
reward_mean: 967.9364709037449
reward_std: 100.90089857600235
reward_max: 1123.0115999941972
reward_min: 752.8176733256425
total_envstep_count: 1162360
total_train_sample_count: 942627
total_episode_count: 7384
total_duration: 372.79337972485763
[2023-06-29 10:04:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3396
train_sample_count: 3396
avg_envstep_per_episode: 226.4
avg_sample_per_episode: 226.4
avg_envstep_per_sec: 2513.707604177841
avg_train_sample_per_sec: 2513.707604177841
avg_episode_per_sec: 11.102948781704244
collect_time: 1.3509924520878118
reward_mean: 933.7963823107879
reward_std: 189.51112182531926
reward_max: 1125.7026209858252
reward_min: 303.7878628332203
total_envstep_count: 1166992
total_train_sample_count: 946023
total_episode_count: 7399
total_duration: 374.14437217694547
[2023-06-29 10:04:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3504
train_sample_count: 3504
avg_envstep_per_episode: 233.6
avg_sample_per_episode: 233.6
avg_envstep_per_sec: 2559.384121897586
avg_train_sample_per_sec: 2559.384121897586
avg_episode_per_sec: 10.956267645109529
collect_time: 1.3690793695328758
reward_mean: 1038.426658263872
reward_std: 90.61220337463634
reward_max: 1238.782348714079
reward_min: 939.7241257910126
total_envstep_count: 1171776
total_train_sample_count: 949527
total_episode_count: 7414
total_duration: 375.51345154647834
[2023-06-29 10:04:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3303
train_sample_count: 3303
avg_envstep_per_episode: 220.2
avg_sample_per_episode: 220.2
avg_envstep_per_sec: 2529.2296122305906
avg_train_sample_per_sec: 2529.2296122305906
avg_episode_per_sec: 11.486056367986334
collect_time: 1.3059312543343986
reward_mean: 1004.8272099062118
reward_std: 72.41667219676555
reward_max: 1179.2746672918586
reward_min: 908.4376673709517
total_envstep_count: 1175640
total_train_sample_count: 952830
total_episode_count: 7429
total_duration: 376.8193828008127
[2023-06-29 10:04:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 266.6666666666667
avg_sample_per_episode: 266.6666666666667
avg_envstep_per_sec: 2721.018061148961
avg_train_sample_per_sec: 2721.018061148961
avg_episode_per_sec: 10.203817729308604
collect_time: 1.176030415119254
reward_mean: 1024.2606987845604
reward_std: 88.44706208527842
reward_max: 1301.7287915976854
reward_min: 945.0608913807959
total_envstep_count: 1180144
total_train_sample_count: 956030
total_episode_count: 7441
total_duration: 377.995413215932
[2023-06-29 10:04:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3461
train_sample_count: 3461
avg_envstep_per_episode: 247.21428571428572
avg_sample_per_episode: 247.21428571428572
avg_envstep_per_sec: 2529.2154465154376
avg_train_sample_per_sec: 2529.2154465154376
avg_episode_per_sec: 10.230862829013617
collect_time: 1.3684085334716363
reward_mean: 1099.506857903981
reward_std: 115.99792309735274
reward_max: 1317.4448333972373
reward_min: 919.923946538294
total_envstep_count: 1184752
total_train_sample_count: 959491
total_episode_count: 7455
total_duration: 379.3638217494036
[2023-06-29 10:04:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 2526.927784050178
avg_train_sample_per_sec: 2526.927784050178
avg_episode_per_sec: 10.962810342950881
collect_time: 1.2770448053041472
reward_mean: 1017.194532134928
reward_std: 144.8335900643843
reward_max: 1251.8918728370757
reward_min: 713.8462065293185
total_envstep_count: 1189392
total_train_sample_count: 962718
total_episode_count: 7469
total_duration: 380.64086655470777
[2023-06-29 10:04:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3042
train_sample_count: 3042
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 2489.820593168791
avg_train_sample_per_sec: 2489.820593168791
avg_episode_per_sec: 10.640258945165774
collect_time: 1.2217747770044953
reward_mean: 1115.7207237105665
reward_std: 121.52434081541854
reward_max: 1312.2543059687607
reward_min: 951.1555062817323
total_envstep_count: 1194152
total_train_sample_count: 966160
total_episode_count: 7482
total_duration: 381.86264133171227
[2023-06-29 10:04:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3432
train_sample_count: 3432
avg_envstep_per_episode: 228.8
avg_sample_per_episode: 228.8
avg_envstep_per_sec: 2591.4671793072393
avg_train_sample_per_sec: 2591.4671793072393
avg_episode_per_sec: 11.32634256690227
collect_time: 1.3243463113885374
reward_mean: 1133.0921983129324
reward_std: 101.7985463416053
reward_max: 1323.159702824024
reward_min: 953.318952618792
total_envstep_count: 1198448
total_train_sample_count: 969592
total_episode_count: 7497
total_duration: 383.1869876431008
[2023-06-29 10:04:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3507
train_sample_count: 3507
avg_envstep_per_episode: 292.25
avg_sample_per_episode: 292.25
avg_envstep_per_sec: 2679.1228875484594
avg_train_sample_per_sec: 2679.1228875484594
avg_episode_per_sec: 9.167229726427577
collect_time: 1.309010503511876
reward_mean: 1208.4975194949611
reward_std: 162.82151991984074
reward_max: 1457.7738670636745
reward_min: 971.9089858296879
total_envstep_count: 1202800
total_train_sample_count: 973099
total_episode_count: 7509
total_duration: 384.4959981466127
[2023-06-29 10:04:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3097
train_sample_count: 3097
avg_envstep_per_episode: 281.54545454545456
avg_sample_per_episode: 281.54545454545456
avg_envstep_per_sec: 2354.7224506150915
avg_train_sample_per_sec: 2354.7224506150915
avg_episode_per_sec: 8.363560528500487
collect_time: 1.315229316810146
reward_mean: 1173.9926277289885
reward_std: 249.7205786074849
reward_max: 1550.193423742489
reward_min: 735.1092815542218
total_envstep_count: 1208256
total_train_sample_count: 976596
total_episode_count: 7520
total_duration: 385.8112274634228
[2023-06-29 10:04:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3005
train_sample_count: 3005
avg_envstep_per_episode: 200.33333333333334
avg_sample_per_episode: 200.33333333333334
avg_envstep_per_sec: 2539.325875450247
avg_train_sample_per_sec: 2539.325875450247
avg_episode_per_sec: 12.6755035380212
collect_time: 1.1833849404882641
reward_mean: 1160.516214678752
reward_std: 193.2113597643246
reward_max: 1552.5268735785999
reward_min: 817.0089546337113
total_envstep_count: 1212512
total_train_sample_count: 980001
total_episode_count: 7535
total_duration: 386.9946124039111
[2023-06-29 10:04:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3316
train_sample_count: 3316
avg_envstep_per_episode: 255.07692307692307
avg_sample_per_episode: 255.07692307692307
avg_envstep_per_sec: 2593.549297472186
avg_train_sample_per_sec: 2593.549297472186
avg_episode_per_sec: 10.167714374890958
collect_time: 1.2785567651372403
reward_mean: 1150.5864405581879
reward_std: 168.2344724829687
reward_max: 1450.2082324059584
reward_min: 868.756149998466
total_envstep_count: 1216872
total_train_sample_count: 983317
total_episode_count: 7548
total_duration: 388.27316916904834
[2023-06-29 10:04:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3483
train_sample_count: 3483
avg_envstep_per_episode: 248.78571428571428
avg_sample_per_episode: 248.78571428571428
avg_envstep_per_sec: 2554.1048296086524
avg_train_sample_per_sec: 2554.1048296086524
avg_episode_per_sec: 10.266284127051719
collect_time: 1.3636871751006694
reward_mean: 1072.7628936652836
reward_std: 98.45704801419565
reward_max: 1305.8366082036978
reward_min: 984.7496008728574
total_envstep_count: 1221800
total_train_sample_count: 986800
total_episode_count: 7562
total_duration: 389.636856344149
[2023-06-29 10:04:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3336
train_sample_count: 3336
avg_envstep_per_episode: 222.4
avg_sample_per_episode: 222.4
avg_envstep_per_sec: 2635.032582890335
avg_train_sample_per_sec: 2635.032582890335
avg_episode_per_sec: 11.84816808853568
collect_time: 1.2660185007430846
reward_mean: 1041.6830669893964
reward_std: 221.9843027993785
reward_max: 1306.3182222135217
reward_min: 285.8296927310454
total_envstep_count: 1226144
total_train_sample_count: 990136
total_episode_count: 7577
total_duration: 390.9028748448921
[2023-06-29 10:04:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3193
train_sample_count: 3193
avg_envstep_per_episode: 266.0833333333333
avg_sample_per_episode: 266.0833333333333
avg_envstep_per_sec: 2508.0363261537923
avg_train_sample_per_sec: 2508.0363261537923
avg_episode_per_sec: 9.425755062275448
collect_time: 1.2731075569773092
reward_mean: 1171.5264948095835
reward_std: 93.9271667621864
reward_max: 1374.354752052197
reward_min: 1024.0629702144395
total_envstep_count: 1230720
total_train_sample_count: 993729
total_episode_count: 7589
total_duration: 392.1759824018694
[2023-06-29 10:04:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 229.35714285714286
avg_sample_per_episode: 229.35714285714286
avg_envstep_per_sec: 2530.5325572484844
avg_train_sample_per_sec: 2530.5325572484844
avg_episode_per_sec: 11.033153472899029
collect_time: 1.2689028603099286
reward_mean: 1082.9531282801315
reward_std: 274.490397235131
reward_max: 1430.8223455104176
reward_min: 300.334368063287
total_envstep_count: 1235168
total_train_sample_count: 996940
total_episode_count: 7603
total_duration: 393.44488526217935
[2023-06-29 10:04:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2861
train_sample_count: 2861
avg_envstep_per_episode: 260.09090909090907
avg_sample_per_episode: 260.09090909090907
avg_envstep_per_sec: 2456.1151066854823
avg_train_sample_per_sec: 2456.1151066854823
avg_episode_per_sec: 9.443294712876723
collect_time: 1.1648476865813135
reward_mean: 1223.8054983448171
reward_std: 195.26434231741518
reward_max: 1620.0234457603292
reward_min: 989.5968477501616
total_envstep_count: 1239552
total_train_sample_count: 1000201
total_episode_count: 7614
total_duration: 394.60973294876067
[2023-06-29 10:04:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3449
train_sample_count: 3449
avg_envstep_per_episode: 246.35714285714286
avg_sample_per_episode: 246.35714285714286
avg_envstep_per_sec: 2721.2585968258536
avg_train_sample_per_sec: 2721.2585968258536
avg_episode_per_sec: 11.045990245161482
collect_time: 1.2674282422196121
reward_mean: 1169.238575195042
reward_std: 187.04079796902943
reward_max: 1458.559286589412
reward_min: 721.5015393140104
total_envstep_count: 1244328
total_train_sample_count: 1003650
total_episode_count: 7628
total_duration: 395.8771611909803
[2023-06-29 10:05:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 222.26666666666668
avg_sample_per_episode: 222.26666666666668
avg_envstep_per_sec: 2581.389986847449
avg_train_sample_per_sec: 2581.389986847449
avg_episode_per_sec: 11.613932154382645
collect_time: 1.2915522323194892
reward_mean: 1043.3848607932648
reward_std: 164.1181537796189
reward_max: 1272.643889822556
reward_min: 689.1503512523601
total_envstep_count: 1249064
total_train_sample_count: 1006984
total_episode_count: 7643
total_duration: 397.1687134232998
[2023-06-29 10:05:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3501
train_sample_count: 3501
avg_envstep_per_episode: 233.4
avg_sample_per_episode: 233.4
avg_envstep_per_sec: 2216.7619517853436
avg_train_sample_per_sec: 2216.7619517853436
avg_episode_per_sec: 9.497694737726407
collect_time: 1.5793306075017899
reward_mean: 1094.2081062094817
reward_std: 156.57625775685938
reward_max: 1349.0243167612732
reward_min: 707.7358718260801
total_envstep_count: 1254176
total_train_sample_count: 1010485
total_episode_count: 7658
total_duration: 398.74804403080157
[2023-06-29 10:05:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3275
train_sample_count: 3275
avg_envstep_per_episode: 233.92857142857142
avg_sample_per_episode: 233.92857142857142
avg_envstep_per_sec: 2498.718897359336
avg_train_sample_per_sec: 2498.718897359336
avg_episode_per_sec: 10.681546431459756
collect_time: 1.3106716419606237
reward_mean: 1179.6970290575284
reward_std: 143.49871625219976
reward_max: 1478.6507441800288
reward_min: 978.4324241082523
total_envstep_count: 1258520
total_train_sample_count: 1013760
total_episode_count: 7672
total_duration: 400.05871567276216
[2023-06-29 10:05:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3169
train_sample_count: 3169
avg_envstep_per_episode: 264.0833333333333
avg_sample_per_episode: 264.0833333333333
avg_envstep_per_sec: 2586.1380244859943
avg_train_sample_per_sec: 2586.1380244859943
avg_episode_per_sec: 9.792886176658861
collect_time: 1.2253792991694061
reward_mean: 1175.1884968008028
reward_std: 151.37177998761206
reward_max: 1556.8763082805433
reward_min: 970.1252688291715
total_envstep_count: 1263408
total_train_sample_count: 1017329
total_episode_count: 7684
total_duration: 401.28409497193155
[2023-06-29 10:05:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3246
train_sample_count: 3246
avg_envstep_per_episode: 231.85714285714286
avg_sample_per_episode: 231.85714285714286
avg_envstep_per_sec: 2414.1415593162105
avg_train_sample_per_sec: 2414.1415593162105
avg_episode_per_sec: 10.412194032787106
collect_time: 1.344577325001359
reward_mean: 1169.5584380229845
reward_std: 314.00957990102944
reward_max: 1507.4216144632485
reward_min: 296.1933876930242
total_envstep_count: 1267472
total_train_sample_count: 1020575
total_episode_count: 7698
total_duration: 402.6286722969329
[2023-06-29 10:05:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2815
train_sample_count: 2815
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 2251.2213825634963
avg_train_sample_per_sec: 2251.2213825634963
avg_episode_per_sec: 7.99723404107814
collect_time: 1.250432330557611
reward_mean: 1188.7149959031244
reward_std: 346.8130094050594
reward_max: 1519.0793509567857
reward_min: 252.10647246347395
total_envstep_count: 1272296
total_train_sample_count: 1023790
total_episode_count: 7708
total_duration: 403.8791046274905
[2023-06-29 10:05:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3194
train_sample_count: 3194
avg_envstep_per_episode: 245.69230769230768
avg_sample_per_episode: 245.69230769230768
avg_envstep_per_sec: 2444.818591803217
avg_train_sample_per_sec: 2444.818591803217
avg_episode_per_sec: 9.950733153864062
collect_time: 1.306436400111066
reward_mean: 1309.0815191694214
reward_std: 187.08289755206087
reward_max: 1621.1156100191079
reward_min: 1054.6185190135463
total_envstep_count: 1276984
total_train_sample_count: 1027384
total_episode_count: 7721
total_duration: 405.1855410276016
[2023-06-29 10:05:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 255.875
avg_sample_per_episode: 255.875
avg_envstep_per_sec: 2645.0355911823945
avg_train_sample_per_sec: 2645.0355911823945
avg_episode_per_sec: 10.337217747659578
collect_time: 0.7739026298262178
reward_mean: 1461.84910483573
reward_std: 339.346798781748
reward_max: 2087.086400837015
reward_min: 1038.0092160143236
total_envstep_count: 1281408
total_train_sample_count: 1030631
total_episode_count: 7729
total_duration: 405.9594436574278
[2023-06-29 10:05:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2681
train_sample_count: 2681
avg_envstep_per_episode: 206.23076923076923
avg_sample_per_episode: 206.23076923076923
avg_envstep_per_sec: 2613.181532211438
avg_train_sample_per_sec: 2613.181532211438
avg_episode_per_sec: 12.671152524710442
collect_time: 1.025952451811172
reward_mean: 1284.0364936674428
reward_std: 268.44381785291534
reward_max: 1762.4285360797805
reward_min: 934.2737576997467
total_envstep_count: 1285816
total_train_sample_count: 1034112
total_episode_count: 7742
total_duration: 406.985396109239
[2023-06-29 10:05:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2889
train_sample_count: 2889
avg_envstep_per_episode: 262.6363636363636
avg_sample_per_episode: 262.6363636363636
avg_envstep_per_sec: 2266.6764282670597
avg_train_sample_per_sec: 2266.6764282670597
avg_episode_per_sec: 8.630474458614627
collect_time: 1.2745533345527948
reward_mean: 1363.2779844191646
reward_std: 222.84688179345173
reward_max: 1644.03851535723
reward_min: 979.9590064452148
total_envstep_count: 1290816
total_train_sample_count: 1037401
total_episode_count: 7753
total_duration: 408.2599494437918
[2023-06-29 10:05:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3018
train_sample_count: 3018
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2515.0373605505943
avg_train_sample_per_sec: 2515.0373605505943
avg_episode_per_sec: 10.000148550896995
collect_time: 1.199982174157165
reward_mean: 1422.0935183498698
reward_std: 229.36629358709092
reward_max: 1866.6233685875982
reward_min: 1151.275085366046
total_envstep_count: 1295264
total_train_sample_count: 1040819
total_episode_count: 7765
total_duration: 409.459931617949
[2023-06-29 10:05:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3088
train_sample_count: 3088
avg_envstep_per_episode: 280.72727272727275
avg_sample_per_episode: 280.72727272727275
avg_envstep_per_sec: 2595.2780524451673
avg_train_sample_per_sec: 2595.2780524451673
avg_episode_per_sec: 9.244837622052085
collect_time: 1.189853240230121
reward_mean: 1354.2627844666122
reward_std: 201.9020214818906
reward_max: 1825.0199380236825
reward_min: 1043.9700683066642
total_envstep_count: 1300336
total_train_sample_count: 1044307
total_episode_count: 7776
total_duration: 410.6497848581791
[2023-06-29 10:05:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2852
train_sample_count: 2852
avg_envstep_per_episode: 259.27272727272725
avg_sample_per_episode: 259.27272727272725
avg_envstep_per_sec: 2556.310145497396
avg_train_sample_per_sec: 2556.310145497396
avg_episode_per_sec: 9.859541234386873
collect_time: 1.1156705711251127
reward_mean: 1438.5649344180863
reward_std: 261.1153289602998
reward_max: 1833.7606521996668
reward_min: 1013.8868403624413
total_envstep_count: 1305024
total_train_sample_count: 1047559
total_episode_count: 7787
total_duration: 411.7654554293042
[2023-06-29 10:05:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2288
train_sample_count: 2288
avg_envstep_per_episode: 228.8
avg_sample_per_episode: 228.8
avg_envstep_per_sec: 2497.1522903868563
avg_train_sample_per_sec: 2497.1522903868563
avg_episode_per_sec: 10.914127143299197
collect_time: 0.9162436783723532
reward_mean: 1320.9436056529576
reward_std: 242.3031201509787
reward_max: 1672.3469921486424
reward_min: 715.4751463452294
total_envstep_count: 1309256
total_train_sample_count: 1051047
total_episode_count: 7797
total_duration: 412.68169910767654
[2023-06-29 10:05:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2356
train_sample_count: 2356
avg_envstep_per_episode: 261.77777777777777
avg_sample_per_episode: 261.77777777777777
avg_envstep_per_sec: 2506.1434873898625
avg_train_sample_per_sec: 2506.1434873898625
avg_episode_per_sec: 9.57355322008012
collect_time: 0.9400898279985412
reward_mean: 1558.12882988668
reward_std: 236.19871767943917
reward_max: 2018.5863884029225
reward_min: 1088.0010229385573
total_envstep_count: 1314408
total_train_sample_count: 1054603
total_episode_count: 7806
total_duration: 413.62178893567506
[2023-06-29 10:05:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3142
train_sample_count: 3142
avg_envstep_per_episode: 241.69230769230768
avg_sample_per_episode: 241.69230769230768
avg_envstep_per_sec: 2514.5455339427294
avg_train_sample_per_sec: 2514.5455339427294
avg_episode_per_sec: 10.4039121391647
collect_time: 1.2495299677764997
reward_mean: 1516.0326819751413
reward_std: 243.821840189776
reward_max: 2033.596089492855
reward_min: 1142.7801188068374
total_envstep_count: 1318968
total_train_sample_count: 1058145
total_episode_count: 7819
total_duration: 414.87131890345154
[2023-06-29 10:05:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3152
train_sample_count: 3152
avg_envstep_per_episode: 315.2
avg_sample_per_episode: 315.2
avg_envstep_per_sec: 2548.8746489658497
avg_train_sample_per_sec: 2548.8746489658497
avg_episode_per_sec: 8.086531246719067
collect_time: 1.2366241710940375
reward_mean: 1522.9046827508423
reward_std: 305.92785140265283
reward_max: 2045.597966049077
reward_min: 1067.8986531518387
total_envstep_count: 1323800
total_train_sample_count: 1061697
total_episode_count: 7829
total_duration: 416.1079430745456
[2023-06-29 10:05:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2775
train_sample_count: 2775
avg_envstep_per_episode: 277.5
avg_sample_per_episode: 277.5
avg_envstep_per_sec: 2665.86667681661
avg_train_sample_per_sec: 2665.86667681661
avg_episode_per_sec: 9.606726763303099
collect_time: 1.040937277221121
reward_mean: 1426.9843788105748
reward_std: 440.37670415844735
reward_max: 2575.663500800956
reward_min: 804.0201046175309
total_envstep_count: 1328544
total_train_sample_count: 1065272
total_episode_count: 7839
total_duration: 417.1488803517667
[2023-06-29 10:05:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2956
train_sample_count: 2956
avg_envstep_per_episode: 295.6
avg_sample_per_episode: 295.6
avg_envstep_per_sec: 2661.8766466435522
avg_train_sample_per_sec: 2661.8766466435522
avg_episode_per_sec: 9.004995421662896
collect_time: 1.1104947345051912
reward_mean: 1628.6301570557573
reward_std: 295.68602682652653
reward_max: 2168.8189813817676
reward_min: 1064.1651239221949
total_envstep_count: 1333480
total_train_sample_count: 1068628
total_episode_count: 7849
total_duration: 418.2593750862719
[2023-06-29 10:06:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 222.88888888888889
avg_sample_per_episode: 222.88888888888889
avg_envstep_per_sec: 2458.5008451888093
avg_train_sample_per_sec: 2458.5008451888093
avg_episode_per_sec: 11.030163313409414
collect_time: 0.8159444012092426
reward_mean: 1416.4395432608578
reward_std: 495.80787930247106
reward_max: 2010.3796637004905
reward_min: 293.8391291359302
total_envstep_count: 1337928
total_train_sample_count: 1071834
total_episode_count: 7858
total_duration: 419.0753194874812
[2023-06-29 10:06:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 158.125
avg_sample_per_episode: 158.125
avg_envstep_per_sec: 2470.1220007003026
avg_train_sample_per_sec: 2470.1220007003026
avg_episode_per_sec: 15.62132490561456
collect_time: 0.5121204538242892
reward_mean: 1464.347873765282
reward_std: 333.0743902934978
reward_max: 2152.3938989384956
reward_min: 977.8380608728355
total_envstep_count: 1342096
total_train_sample_count: 1075099
total_episode_count: 7866
total_duration: 419.5874399413055
[2023-06-29 10:06:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 205.45454545454547
avg_sample_per_episode: 205.45454545454547
avg_envstep_per_sec: 2333.5397926665005
avg_train_sample_per_sec: 2333.5397926665005
avg_episode_per_sec: 11.357937043951994
collect_time: 0.9684857344633203
reward_mean: 1443.0943707116248
reward_std: 814.7925468595031
reward_max: 2493.5476693374862
reward_min: 134.66952123571116
total_envstep_count: 1346328
total_train_sample_count: 1078559
total_episode_count: 7877
total_duration: 420.55592567576883
[2023-06-29 10:06:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 1934
train_sample_count: 1934
avg_envstep_per_episode: 113.76470588235294
avg_sample_per_episode: 113.76470588235294
avg_envstep_per_sec: 2540.009745056587
avg_train_sample_per_sec: 2540.009745056587
avg_episode_per_sec: 22.326869527384684
collect_time: 0.7614144015643979
reward_mean: 511.7423929919421
reward_std: 599.8204698993358
reward_max: 1651.0935089788031
reward_min: 110.41044523858221
total_envstep_count: 1350744
total_train_sample_count: 1082093
total_episode_count: 7894
total_duration: 421.31734007733326
[2023-06-29 10:06:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2115
train_sample_count: 2115
avg_envstep_per_episode: 211.5
avg_sample_per_episode: 211.5
avg_envstep_per_sec: 2402.7261589926356
avg_train_sample_per_sec: 2402.7261589926356
avg_episode_per_sec: 11.360407371123571
collect_time: 0.8802501242533326
reward_mean: 977.4596310919244
reward_std: 940.2444695315729
reward_max: 2490.1144188185644
reward_min: 124.84565995742355
total_envstep_count: 1354696
total_train_sample_count: 1085408
total_episode_count: 7904
total_duration: 422.1975902015866
[2023-06-29 10:06:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 2544
train_sample_count: 2544
avg_envstep_per_episode: 159.0
avg_sample_per_episode: 159.0
avg_envstep_per_sec: 2452.8458598570855
avg_train_sample_per_sec: 2452.8458598570855
avg_episode_per_sec: 15.426703521113746
collect_time: 1.0371626043180004
reward_mean: 674.0704071913008
reward_std: 663.4658807662083
reward_max: 1879.640943686662
reward_min: 122.42635365574323
total_envstep_count: 1359408
total_train_sample_count: 1088752
total_episode_count: 7920
total_duration: 423.2347528059046
[2023-06-29 10:06:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1651
train_sample_count: 1651
avg_envstep_per_episode: 235.85714285714286
avg_sample_per_episode: 235.85714285714286
avg_envstep_per_sec: 2682.971672944881
avg_train_sample_per_sec: 2682.971672944881
avg_episode_per_sec: 11.375409879233294
collect_time: 0.6153624418210241
reward_mean: 1591.9458622537215
reward_std: 464.32956037834043
reward_max: 2465.6624870234255
reward_min: 1077.2382063700406
total_envstep_count: 1363920
total_train_sample_count: 1092003
total_episode_count: 7927
total_duration: 423.8501152477256
[2023-06-29 10:06:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 203.5
avg_sample_per_episode: 203.5
avg_envstep_per_sec: 2477.6538110373476
avg_train_sample_per_sec: 2477.6538110373476
avg_episode_per_sec: 12.17520300264053
collect_time: 0.6570732330512254
reward_mean: 1615.5485647388098
reward_std: 956.346414032155
reward_max: 3164.5583054111958
reward_min: 192.83813694137135
total_envstep_count: 1368496
total_train_sample_count: 1095231
total_episode_count: 7935
total_duration: 424.50718848077685
[2023-06-29 10:06:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1802
train_sample_count: 1802
avg_envstep_per_episode: 225.25
avg_sample_per_episode: 225.25
avg_envstep_per_sec: 2536.439867734507
avg_train_sample_per_sec: 2536.439867734507
avg_episode_per_sec: 11.260554351762517
collect_time: 0.7104445971390235
reward_mean: 1917.449862048195
reward_std: 906.3760105241702
reward_max: 3149.0567490003586
reward_min: 247.14178522190153
total_envstep_count: 1373144
total_train_sample_count: 1098633
total_episode_count: 7943
total_duration: 425.2176330779159
[2023-06-29 10:06:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1771
train_sample_count: 1771
avg_envstep_per_episode: 295.1666666666667
avg_sample_per_episode: 295.1666666666667
avg_envstep_per_sec: 2482.676115685497
avg_train_sample_per_sec: 2482.676115685497
avg_episode_per_sec: 8.411099206162044
collect_time: 0.7133431496806444
reward_mean: 2222.0935323193157
reward_std: 626.6910961316697
reward_max: 3202.075175376867
reward_min: 1345.561818907388
total_envstep_count: 1377864
total_train_sample_count: 1102004
total_episode_count: 7949
total_duration: 425.93097622759655
[2023-06-29 10:06:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 2562
train_sample_count: 2562
avg_envstep_per_episode: 160.125
avg_sample_per_episode: 160.125
avg_envstep_per_sec: 2562.7919854011825
avg_train_sample_per_sec: 2562.7919854011825
avg_episode_per_sec: 16.00494604466
collect_time: 0.9996909677392103
reward_mean: 1046.0126494229758
reward_std: 986.4991517581109
reward_max: 3205.8563698437297
reward_min: 133.65690725410244
total_envstep_count: 1381816
total_train_sample_count: 1105366
total_episode_count: 7965
total_duration: 426.93066719533573
[2023-06-29 10:06:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2464
train_sample_count: 2464
avg_envstep_per_episode: 189.53846153846155
avg_sample_per_episode: 189.53846153846155
avg_envstep_per_sec: 2661.278156230437
avg_train_sample_per_sec: 2661.278156230437
avg_episode_per_sec: 14.040834428163832
collect_time: 0.9258708993764593
reward_mean: 733.2765106379034
reward_std: 824.2672224147278
reward_max: 3077.7992892372367
reward_min: 149.22634630946877
total_envstep_count: 1386240
total_train_sample_count: 1108630
total_episode_count: 7978
total_duration: 427.85653809471216
[2023-06-29 10:06:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1492
train_sample_count: 1492
avg_envstep_per_episode: 298.4
avg_sample_per_episode: 298.4
avg_envstep_per_sec: 2597.2592118023094
avg_train_sample_per_sec: 2597.2592118023094
avg_episode_per_sec: 8.70395178217932
collect_time: 0.5744517117198558
reward_mean: 1583.711422843095
reward_std: 1022.6197050810332
reward_max: 2767.1636441461633
reward_min: 137.1828215935893
total_envstep_count: 1390592
total_train_sample_count: 1112122
total_episode_count: 7983
total_duration: 428.430989806432
[2023-06-29 10:06:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2870
train_sample_count: 2870
avg_envstep_per_episode: 318.8888888888889
avg_sample_per_episode: 318.8888888888889
avg_envstep_per_sec: 2587.2513723328293
avg_train_sample_per_sec: 2587.2513723328293
avg_episode_per_sec: 8.113331829615145
collect_time: 1.1092853329563515
reward_mean: 2113.0381406209813
reward_std: 1050.7530531963494
reward_max: 3108.160219682842
reward_min: 200.72243443606416
total_envstep_count: 1395008
total_train_sample_count: 1115392
total_episode_count: 7992
total_duration: 429.54027513938837
[2023-06-29 10:06:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 832
train_sample_count: 832
avg_envstep_per_episode: 208.0
avg_sample_per_episode: 208.0
avg_envstep_per_sec: 2693.2110131615786
avg_train_sample_per_sec: 2693.2110131615786
avg_episode_per_sec: 12.94812987096913
collect_time: 0.3089249211940915
reward_mean: 1422.7219041682163
reward_std: 509.1214376927505
reward_max: 2218.520173090041
reward_min: 968.4623593050164
total_envstep_count: 1398600
total_train_sample_count: 1118624
total_episode_count: 7996
total_duration: 429.84920006058246
[2023-06-29 10:06:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2048
train_sample_count: 2048
avg_envstep_per_episode: 256.0
avg_sample_per_episode: 256.0
avg_envstep_per_sec: 2670.0194214732132
avg_train_sample_per_sec: 2670.0194214732132
avg_episode_per_sec: 10.42976336512974
collect_time: 0.7670356191154568
reward_mean: 2141.636922801791
reward_std: 862.1848515359138
reward_max: 2904.8906743261555
reward_min: 263.33745230105285
total_envstep_count: 1403168
total_train_sample_count: 1121872
total_episode_count: 8004
total_duration: 430.6162356796979
[2023-06-29 10:06:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1295
train_sample_count: 1295
avg_envstep_per_episode: 215.83333333333334
avg_sample_per_episode: 215.83333333333334
avg_envstep_per_sec: 2581.599990338365
avg_train_sample_per_sec: 2581.599990338365
avg_episode_per_sec: 11.961081036316747
collect_time: 0.5016268999250605
reward_mean: 1813.762235314298
reward_std: 515.2760435089123
reward_max: 2584.0273967425687
reward_min: 1119.4769831954145
total_envstep_count: 1407576
total_train_sample_count: 1125167
total_episode_count: 8010
total_duration: 431.11786257962297
[2023-06-29 10:06:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 287.7142857142857
avg_sample_per_episode: 287.7142857142857
avg_envstep_per_sec: 2246.2911533637043
avg_train_sample_per_sec: 2246.2911533637043
avg_episode_per_sec: 7.807367464521317
collect_time: 0.8965890271989628
reward_mean: 2339.744040474301
reward_std: 805.9179239565497
reward_max: 3205.340417591587
reward_min: 956.5879187469393
total_envstep_count: 1411936
total_train_sample_count: 1128381
total_episode_count: 8017
total_duration: 432.0144516068219
[2023-06-29 10:06:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1739
train_sample_count: 1739
avg_envstep_per_episode: 347.8
avg_sample_per_episode: 347.8
avg_envstep_per_sec: 2365.473397915366
avg_train_sample_per_sec: 2365.473397915366
avg_episode_per_sec: 6.801246112465114
collect_time: 0.7351593983396888
reward_mean: 2562.3406405805194
reward_std: 690.9651346951622
reward_max: 3195.894877875298
reward_min: 1413.900379422281
total_envstep_count: 1416736
total_train_sample_count: 1131720
total_episode_count: 8022
total_duration: 432.7496110051616
[2023-06-29 10:07:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2168
train_sample_count: 2168
avg_envstep_per_episode: 240.88888888888889
avg_sample_per_episode: 240.88888888888889
avg_envstep_per_sec: 2342.985304214035
avg_train_sample_per_sec: 2342.985304214035
avg_episode_per_sec: 9.726415008268594
collect_time: 0.9253152361223476
reward_mean: 2011.4240089014877
reward_std: 815.8574015891398
reward_max: 3163.9646078683345
reward_min: 979.0957359320482
total_envstep_count: 1421424
total_train_sample_count: 1135088
total_episode_count: 8031
total_duration: 433.67492624128397
[2023-06-29 10:07:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1678
train_sample_count: 1678
avg_envstep_per_episode: 279.6666666666667
avg_sample_per_episode: 279.6666666666667
avg_envstep_per_sec: 2630.8321028212426
avg_train_sample_per_sec: 2630.8321028212426
avg_episode_per_sec: 9.407027781244015
collect_time: 0.6378210141956806
reward_mean: 2122.9925527201626
reward_std: 800.4081733934072
reward_max: 3127.610764277477
reward_min: 997.5884887518523
total_envstep_count: 1426208
total_train_sample_count: 1138366
total_episode_count: 8037
total_duration: 434.3127472554797
[2023-06-29 10:07:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3270
train_sample_count: 3270
avg_envstep_per_episode: 327.0
avg_sample_per_episode: 327.0
avg_envstep_per_sec: 2524.0886343084867
avg_train_sample_per_sec: 2524.0886343084867
avg_episode_per_sec: 7.718925487181916
collect_time: 1.2955171048879857
reward_mean: 2123.52276309866
reward_std: 589.4091849215754
reward_max: 3137.345904530699
reward_min: 1007.2166815475814
total_envstep_count: 1431136
total_train_sample_count: 1141636
total_episode_count: 8047
total_duration: 435.6082643603677
[2023-06-29 10:07:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2814
train_sample_count: 2814
avg_envstep_per_episode: 281.4
avg_sample_per_episode: 281.4
avg_envstep_per_sec: 2380.492613251265
avg_train_sample_per_sec: 2380.492613251265
avg_episode_per_sec: 8.459462022925605
collect_time: 1.1821082679843533
reward_mean: 1406.6157865731525
reward_std: 435.3589862307694
reward_max: 2369.7472058175263
reward_min: 953.5972127219999
total_envstep_count: 1434936
total_train_sample_count: 1144850
total_episode_count: 8057
total_duration: 436.79037262835203
[2023-06-29 10:07:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2533
train_sample_count: 2533
avg_envstep_per_episode: 316.625
avg_sample_per_episode: 316.625
avg_envstep_per_sec: 2596.3560542909668
avg_train_sample_per_sec: 2596.3560542909668
avg_episode_per_sec: 8.200098079087144
collect_time: 0.9755980871012436
reward_mean: 1490.1087045108893
reward_std: 398.9056144096277
reward_max: 2068.062366341136
reward_min: 864.9543313340927
total_envstep_count: 1439888
total_train_sample_count: 1148183
total_episode_count: 8065
total_duration: 437.76597071545325
[2023-06-29 10:07:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 184.54545454545453
avg_sample_per_episode: 184.54545454545453
avg_envstep_per_sec: 2537.918832211745
avg_train_sample_per_sec: 2537.918832211745
avg_episode_per_sec: 13.752269534152314
collect_time: 0.7998679761680542
reward_mean: 1240.5768381433713
reward_std: 584.6698605051282
reward_max: 2463.4450113419934
reward_min: 288.47483205290814
total_envstep_count: 1443912
total_train_sample_count: 1151413
total_episode_count: 8076
total_duration: 438.5658386916213
[2023-06-29 10:07:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2988
train_sample_count: 2988
avg_envstep_per_episode: 298.8
avg_sample_per_episode: 298.8
avg_envstep_per_sec: 2449.3680347100626
avg_train_sample_per_sec: 2449.3680347100626
avg_episode_per_sec: 8.19734951375523
collect_time: 1.2199065055381506
reward_mean: 1693.9692354507654
reward_std: 840.5861737975233
reward_max: 3243.430439501514
reward_min: 810.7817427571576
total_envstep_count: 1448992
total_train_sample_count: 1154801
total_episode_count: 8086
total_duration: 439.7857451971595
[2023-06-29 10:07:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3155
train_sample_count: 3155
avg_envstep_per_episode: 315.5
avg_sample_per_episode: 315.5
avg_envstep_per_sec: 2622.301132312773
avg_train_sample_per_sec: 2622.301132312773
avg_episode_per_sec: 8.311572527140326
collect_time: 1.2031417601598662
reward_mean: 1780.482120604638
reward_std: 589.3881866334624
reward_max: 3162.4595345737253
reward_min: 981.2225583272485
total_envstep_count: 1454280
total_train_sample_count: 1158356
total_episode_count: 8096
total_duration: 440.9888869573193
[2023-06-29 10:07:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2385
train_sample_count: 2385
avg_envstep_per_episode: 238.5
avg_sample_per_episode: 238.5
avg_envstep_per_sec: 2496.9652549384195
avg_train_sample_per_sec: 2496.9652549384195
avg_episode_per_sec: 10.469455995548929
collect_time: 0.9551594661892159
reward_mean: 1517.2266312119946
reward_std: 487.6880511168207
reward_max: 2376.1962082784516
reward_min: 959.3069014533992
total_envstep_count: 1458904
total_train_sample_count: 1161941
total_episode_count: 8106
total_duration: 441.94404642350855
[2023-06-29 10:07:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2547
train_sample_count: 2547
avg_envstep_per_episode: 254.7
avg_sample_per_episode: 254.7
avg_envstep_per_sec: 2497.646542615624
avg_train_sample_per_sec: 2497.646542615624
avg_episode_per_sec: 9.806229064058202
collect_time: 1.0197599846664818
reward_mean: 1580.742646998279
reward_std: 736.0758645857057
reward_max: 3030.3811344489172
reward_min: 903.755809949397
total_envstep_count: 1463648
total_train_sample_count: 1165288
total_episode_count: 8116
total_duration: 442.96380640817506
[2023-06-29 10:07:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 2380.3573491652173
avg_train_sample_per_sec: 2380.3573491652173
avg_episode_per_sec: 10.844452615786867
collect_time: 0.5532782716266812
reward_mean: 1802.9434055061763
reward_std: 419.7755782051248
reward_max: 2373.854904289449
reward_min: 961.4306246710145
total_envstep_count: 1468288
total_train_sample_count: 1168605
total_episode_count: 8122
total_duration: 443.51708467980177
[2023-06-29 10:07:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2374
train_sample_count: 2374
avg_envstep_per_episode: 263.77777777777777
avg_sample_per_episode: 263.77777777777777
avg_envstep_per_sec: 2450.209193583287
avg_train_sample_per_sec: 2450.209193583287
avg_episode_per_sec: 9.288914381739502
collect_time: 0.9688968624463304
reward_mean: 1984.838613856427
reward_std: 859.7625030454661
reward_max: 3107.2353717688306
reward_min: 797.061233890683
total_envstep_count: 1473320
total_train_sample_count: 1172179
total_episode_count: 8131
total_duration: 444.4859815422481
[2023-06-29 10:07:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 637
train_sample_count: 637
avg_envstep_per_episode: 127.4
avg_sample_per_episode: 127.4
avg_envstep_per_sec: 2660.334156092867
avg_train_sample_per_sec: 2660.334156092867
avg_episode_per_sec: 20.881743768389853
collect_time: 0.23944360468443482
reward_mean: 1775.023384009516
reward_std: 831.110725733136
reward_max: 3057.6274064659156
reward_min: 822.5137805005701
total_envstep_count: 1478136
total_train_sample_count: 1175616
total_episode_count: 8136
total_duration: 444.72542514693254
[2023-06-29 10:07:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2353
train_sample_count: 2353
avg_envstep_per_episode: 261.44444444444446
avg_sample_per_episode: 261.44444444444446
avg_envstep_per_sec: 2630.9130544260834
avg_train_sample_per_sec: 2630.9130544260834
avg_episode_per_sec: 10.062990858408309
collect_time: 0.8943663098411634
reward_mean: 2508.915641681284
reward_std: 967.6314212569888
reward_max: 3252.719094396726
reward_min: 762.054942343945
total_envstep_count: 1482152
total_train_sample_count: 1179169
total_episode_count: 8145
total_duration: 445.6197914567737
[2023-06-29 10:07:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 266.2
avg_sample_per_episode: 266.2
avg_envstep_per_sec: 2571.5411207594934
avg_train_sample_per_sec: 2571.5411207594934
avg_episode_per_sec: 9.660184525768194
collect_time: 0.517588456686586
reward_mean: 1779.062369892597
reward_std: 762.4857383655188
reward_max: 2954.7139906556754
reward_min: 890.3020637550364
total_envstep_count: 1486456
total_train_sample_count: 1182500
total_episode_count: 8150
total_duration: 446.13737991346034
[2023-06-29 10:07:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2378
train_sample_count: 2378
avg_envstep_per_episode: 237.8
avg_sample_per_episode: 237.8
avg_envstep_per_sec: 2315.1954868778016
avg_train_sample_per_sec: 2315.1954868778016
avg_episode_per_sec: 9.735893552892353
collect_time: 1.027127088610083
reward_mean: 1842.0941960334153
reward_std: 921.8106370591347
reward_max: 3206.999416870793
reward_min: 832.0700636716248
total_envstep_count: 1491816
total_train_sample_count: 1186078
total_episode_count: 8160
total_duration: 447.1645070020704
[2023-06-29 10:07:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1276
train_sample_count: 1276
avg_envstep_per_episode: 182.28571428571428
avg_sample_per_episode: 182.28571428571428
avg_envstep_per_sec: 2153.3853317686558
avg_train_sample_per_sec: 2153.3853317686558
avg_episode_per_sec: 11.813242415658769
collect_time: 0.5925553504871205
reward_mean: 1465.486725033461
reward_std: 546.9477078780449
reward_max: 2427.751683900827
reward_min: 1035.0910865554936
total_envstep_count: 1495824
total_train_sample_count: 1189354
total_episode_count: 8167
total_duration: 447.75706235255757
[2023-06-29 10:07:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1306
train_sample_count: 1306
avg_envstep_per_episode: 217.66666666666666
avg_sample_per_episode: 217.66666666666666
avg_envstep_per_sec: 1968.0690782510537
avg_train_sample_per_sec: 1968.0690782510537
avg_episode_per_sec: 9.041664984308056
collect_time: 0.663594593519345
reward_mean: 2242.8802513637925
reward_std: 976.1200961943736
reward_max: 3068.546061844442
reward_min: 857.2923722309191
total_envstep_count: 1500184
total_train_sample_count: 1192660
total_episode_count: 8173
total_duration: 448.4206569460769
[2023-06-29 10:08:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2386
train_sample_count: 2386
avg_envstep_per_episode: 265.1111111111111
avg_sample_per_episode: 265.1111111111111
avg_envstep_per_sec: 2641.442321759899
avg_train_sample_per_sec: 2641.442321759899
avg_episode_per_sec: 9.963529294148824
collect_time: 0.903294378357008
reward_mean: 2109.3842766724374
reward_std: 710.1071808004401
reward_max: 3056.9622584600584
reward_min: 1063.4374942278846
total_envstep_count: 1505064
total_train_sample_count: 1196246
total_episode_count: 8182
total_duration: 449.32395132443395
[2023-06-29 10:08:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1390
train_sample_count: 1390
avg_envstep_per_episode: 231.66666666666666
avg_sample_per_episode: 231.66666666666666
avg_envstep_per_sec: 2194.959724846308
avg_train_sample_per_sec: 2194.959724846308
avg_episode_per_sec: 9.47464629430061
collect_time: 0.633269022782333
reward_mean: 1709.321948532662
reward_std: 527.9850966201967
reward_max: 2666.9125944956468
reward_min: 1162.792173408425
total_envstep_count: 1509496
total_train_sample_count: 1199636
total_episode_count: 8188
total_duration: 449.95722034721626
[2023-06-29 10:08:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2011
train_sample_count: 2011
avg_envstep_per_episode: 223.44444444444446
avg_sample_per_episode: 223.44444444444446
avg_envstep_per_sec: 2340.828020025593
avg_train_sample_per_sec: 2340.828020025593
avg_episode_per_sec: 10.476107498871377
collect_time: 0.8590977136278525
reward_mean: 1801.5979276556432
reward_std: 838.5983366760933
reward_max: 2996.576488597417
reward_min: 720.4746605159085
total_envstep_count: 1513528
total_train_sample_count: 1202847
total_episode_count: 8197
total_duration: 450.81631806084414
[2023-06-29 10:08:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3019
train_sample_count: 3019
avg_envstep_per_episode: 301.9
avg_sample_per_episode: 301.9
avg_envstep_per_sec: 2249.004802178473
avg_train_sample_per_sec: 2249.004802178473
avg_episode_per_sec: 7.449502491482189
collect_time: 1.3423715223176402
reward_mean: 1705.87950425065
reward_std: 876.4837027317269
reward_max: 3120.9171522550823
reward_min: 840.0229382338824
total_envstep_count: 1518184
total_train_sample_count: 1206266
total_episode_count: 8207
total_duration: 452.1586895831618
[2023-06-29 10:08:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3035
train_sample_count: 3035
avg_envstep_per_episode: 252.91666666666666
avg_sample_per_episode: 252.91666666666666
avg_envstep_per_sec: 2711.2211760682144
avg_train_sample_per_sec: 2711.2211760682144
avg_episode_per_sec: 10.7198201360193
collect_time: 1.1194217671320075
reward_mean: 1285.8463562816955
reward_std: 367.98107253295296
reward_max: 2211.4400829790916
reward_min: 948.2302460200922
total_envstep_count: 1523200
total_train_sample_count: 1209701
total_episode_count: 8219
total_duration: 453.2781113502938
[2023-06-29 10:08:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2580.611923297777
avg_train_sample_per_sec: 2580.611923297777
avg_episode_per_sec: 9.593352874712927
collect_time: 0.9381495831059292
reward_mean: 1507.3964676585983
reward_std: 520.0668470318125
reward_max: 2420.744112900914
reward_min: 761.8172248776159
total_envstep_count: 1527800
total_train_sample_count: 1212922
total_episode_count: 8228
total_duration: 454.2162609333997
[2023-06-29 10:08:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2130
train_sample_count: 2130
avg_envstep_per_episode: 236.66666666666666
avg_sample_per_episode: 236.66666666666666
avg_envstep_per_sec: 2507.03871085638
avg_train_sample_per_sec: 2507.03871085638
avg_episode_per_sec: 10.593121313477662
collect_time: 0.8496079421415925
reward_mean: 1678.1783942375678
reward_std: 764.0154606761089
reward_max: 2714.7130107020325
reward_min: 309.43240553339194
total_envstep_count: 1532048
total_train_sample_count: 1216252
total_episode_count: 8237
total_duration: 455.0658688755413
[2023-06-29 10:08:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1606
train_sample_count: 1606
avg_envstep_per_episode: 229.42857142857142
avg_sample_per_episode: 229.42857142857142
avg_envstep_per_sec: 2224.6039225068384
avg_train_sample_per_sec: 2224.6039225068384
avg_episode_per_sec: 9.696281106816857
collect_time: 0.7219262646045537
reward_mean: 1599.4465746494993
reward_std: 477.8963286699656
reward_max: 2371.5426991229447
reward_min: 995.3414839712725
total_envstep_count: 1536000
total_train_sample_count: 1219458
total_episode_count: 8244
total_duration: 455.7877951401459
[2023-06-29 10:08:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2865
train_sample_count: 2865
avg_envstep_per_episode: 358.125
avg_sample_per_episode: 358.125
avg_envstep_per_sec: 2379.565986666728
avg_train_sample_per_sec: 2379.565986666728
avg_episode_per_sec: 6.6445123536941795
collect_time: 1.2040010724868626
reward_mean: 2244.2807400987913
reward_std: 784.2327815113234
reward_max: 3306.226901502298
reward_min: 963.6040051352048
total_envstep_count: 1540752
total_train_sample_count: 1222723
total_episode_count: 8252
total_duration: 456.9917962126327
[2023-06-29 10:08:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2697
train_sample_count: 2697
avg_envstep_per_episode: 192.64285714285714
avg_sample_per_episode: 192.64285714285714
avg_envstep_per_sec: 2527.67725174513
avg_train_sample_per_sec: 2527.67725174513
avg_episode_per_sec: 13.121053587108571
collect_time: 1.0669874874800445
reward_mean: 924.5588571526371
reward_std: 634.4012623211686
reward_max: 2265.5408085100757
reward_min: 283.6064597388722
total_envstep_count: 1545344
total_train_sample_count: 1226220
total_episode_count: 8266
total_duration: 458.05878370011277
[2023-06-29 10:08:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2236
train_sample_count: 2236
avg_envstep_per_episode: 223.6
avg_sample_per_episode: 223.6
avg_envstep_per_sec: 2217.4633786370578
avg_train_sample_per_sec: 2217.4633786370578
avg_episode_per_sec: 9.917099188895607
collect_time: 1.0083593810574385
reward_mean: 1441.1157706225972
reward_std: 866.4602115934948
reward_max: 3254.4523430286686
reward_min: 270.17409402906196
total_envstep_count: 1549888
total_train_sample_count: 1229656
total_episode_count: 8276
total_duration: 459.06714308117023
[2023-06-29 10:08:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3422
train_sample_count: 3422
avg_envstep_per_episode: 285.1666666666667
avg_sample_per_episode: 285.1666666666667
avg_envstep_per_sec: 2454.15242799864
avg_train_sample_per_sec: 2454.15242799864
avg_episode_per_sec: 8.606028385734566
collect_time: 1.3943714175857604
reward_mean: 1507.981901563979
reward_std: 882.6789650550271
reward_max: 3142.0562540605865
reward_min: 292.2500371651795
total_envstep_count: 1554328
total_train_sample_count: 1233078
total_episode_count: 8288
total_duration: 460.461514498756
[2023-06-29 10:08:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 223.45454545454547
avg_sample_per_episode: 223.45454545454547
avg_envstep_per_sec: 2501.3003542120214
avg_train_sample_per_sec: 2501.3003542120214
avg_episode_per_sec: 11.19377701234021
collect_time: 0.9826888625593857
reward_mean: 1013.1526991508177
reward_std: 419.22176833998697
reward_max: 1740.0215731080452
reward_min: 288.89939958496177
total_envstep_count: 1558904
total_train_sample_count: 1236336
total_episode_count: 8299
total_duration: 461.4442033613154
[2023-06-29 10:08:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2683
train_sample_count: 2683
avg_envstep_per_episode: 223.58333333333334
avg_sample_per_episode: 223.58333333333334
avg_envstep_per_sec: 2479.9050589091125
avg_train_sample_per_sec: 2479.9050589091125
avg_episode_per_sec: 11.09163649158008
collect_time: 1.0818962566172703
reward_mean: 1238.5707354847625
reward_std: 513.8691046107742
reward_max: 2076.2480489006807
reward_min: 290.3251901708111
total_envstep_count: 1563784
total_train_sample_count: 1239819
total_episode_count: 8311
total_duration: 462.52609961793263
[2023-06-29 10:08:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2586
train_sample_count: 2586
avg_envstep_per_episode: 235.0909090909091
avg_sample_per_episode: 235.0909090909091
avg_envstep_per_sec: 2605.5084778747914
avg_train_sample_per_sec: 2605.5084778747914
avg_episode_per_sec: 11.082982697843272
collect_time: 0.9925126024188938
reward_mean: 1515.3513525380863
reward_std: 723.5894014758602
reward_max: 3329.199765441832
reward_min: 302.2349142657889
total_envstep_count: 1568304
total_train_sample_count: 1243205
total_episode_count: 8322
total_duration: 463.51861222035154
[2023-06-29 10:08:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2291
train_sample_count: 2291
avg_envstep_per_episode: 190.91666666666666
avg_sample_per_episode: 190.91666666666666
avg_envstep_per_sec: 2284.4461867260484
avg_train_sample_per_sec: 2284.4461867260484
avg_episode_per_sec: 11.965671864125962
collect_time: 1.0028688849455212
reward_mean: 1185.1819307073854
reward_std: 226.06497395716568
reward_max: 1522.2194811840018
reward_min: 782.1690260801835
total_envstep_count: 1573336
total_train_sample_count: 1246696
total_episode_count: 8334
total_duration: 464.5214811052971
[2023-06-29 10:08:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 210.14285714285714
avg_sample_per_episode: 210.14285714285714
avg_envstep_per_sec: 2399.876752808618
avg_train_sample_per_sec: 2399.876752808618
avg_episode_per_sec: 11.42021568297779
collect_time: 1.2258962867809462
reward_mean: 1348.8043286615018
reward_std: 321.42461717481973
reward_max: 2004.653885616766
reward_min: 853.7778839466682
total_envstep_count: 1577544
total_train_sample_count: 1250038
total_episode_count: 8348
total_duration: 465.747377392078
[2023-06-29 10:08:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3420
train_sample_count: 3420
avg_envstep_per_episode: 244.28571428571428
avg_sample_per_episode: 244.28571428571428
avg_envstep_per_sec: 2417.125959801006
avg_train_sample_per_sec: 2417.125959801006
avg_episode_per_sec: 9.894667671700025
collect_time: 1.4149035080826144
reward_mean: 1113.4543354710556
reward_std: 347.48390606157005
reward_max: 1607.7531625183428
reward_min: 281.99922120611285
total_envstep_count: 1582136
total_train_sample_count: 1253458
total_episode_count: 8362
total_duration: 467.1622809001606
[2023-06-29 10:09:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3737
train_sample_count: 3737
avg_envstep_per_episode: 233.5625
avg_sample_per_episode: 233.5625
avg_envstep_per_sec: 2402.858416673265
avg_train_sample_per_sec: 2402.858416673265
avg_episode_per_sec: 10.287860494185775
collect_time: 1.5552310423573943
reward_mean: 1009.7301757973987
reward_std: 347.78864765043375
reward_max: 1511.6951562396036
reward_min: 274.61514612524684
total_envstep_count: 1586776
total_train_sample_count: 1257195
total_episode_count: 8378
total_duration: 468.717511942518
[2023-06-29 10:09:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3384
train_sample_count: 3384
avg_envstep_per_episode: 282.0
avg_sample_per_episode: 282.0
avg_envstep_per_sec: 2458.913111079206
avg_train_sample_per_sec: 2458.913111079206
avg_episode_per_sec: 8.719550039287965
collect_time: 1.3762178032044319
reward_mean: 1203.576487488632
reward_std: 152.9774330090419
reward_max: 1403.6104681335516
reward_min: 885.3828089285828
total_envstep_count: 1591568
total_train_sample_count: 1260579
total_episode_count: 8390
total_duration: 470.09372974572244
[2023-06-29 10:09:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2967
train_sample_count: 2967
avg_envstep_per_episode: 211.92857142857142
avg_sample_per_episode: 211.92857142857142
avg_envstep_per_sec: 2461.286264191981
avg_train_sample_per_sec: 2461.286264191981
avg_episode_per_sec: 11.613753858674666
collect_time: 1.2054672563550994
reward_mean: 1030.5718488608652
reward_std: 289.15939766364136
reward_max: 1594.6505637841792
reward_min: 283.29232698092846
total_envstep_count: 1595600
total_train_sample_count: 1263946
total_episode_count: 8404
total_duration: 471.29919700207756
[2023-06-29 10:09:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3069
train_sample_count: 3069
avg_envstep_per_episode: 255.75
avg_sample_per_episode: 255.75
avg_envstep_per_sec: 2461.1169338569352
avg_train_sample_per_sec: 2461.1169338569352
avg_episode_per_sec: 9.6231356162539
collect_time: 1.246994792397134
reward_mean: 1151.1812186656234
reward_std: 280.28731999562456
reward_max: 1716.4927195914008
reward_min: 764.6698002369659
total_envstep_count: 1600432
total_train_sample_count: 1267415
total_episode_count: 8416
total_duration: 472.5461917944747
[2023-06-29 10:09:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 228.71428571428572
avg_sample_per_episode: 228.71428571428572
avg_envstep_per_sec: 2704.92227044329
avg_train_sample_per_sec: 2704.92227044329
avg_episode_per_sec: 11.826643281138683
collect_time: 1.1837678424213083
reward_mean: 1196.7467029801521
reward_std: 328.10570971786615
reward_max: 1888.5754074392341
reward_min: 771.552039039556
total_envstep_count: 1604624
total_train_sample_count: 1270617
total_episode_count: 8430
total_duration: 473.729959636896
[2023-06-29 10:09:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3049
train_sample_count: 3049
avg_envstep_per_episode: 277.1818181818182
avg_sample_per_episode: 277.1818181818182
avg_envstep_per_sec: 2544.83270551958
avg_train_sample_per_sec: 2544.83270551958
avg_episode_per_sec: 9.181095362648534
collect_time: 1.1981141209742052
reward_mean: 1205.3094375134262
reward_std: 264.11123082872285
reward_max: 1725.9484092286261
reward_min: 801.7315856236235
total_envstep_count: 1609104
total_train_sample_count: 1274066
total_episode_count: 8441
total_duration: 474.9280737578702
[2023-06-29 10:09:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2297
train_sample_count: 2297
avg_envstep_per_episode: 255.22222222222223
avg_sample_per_episode: 255.22222222222223
avg_envstep_per_sec: 2633.3386179561103
avg_train_sample_per_sec: 2633.3386179561103
avg_episode_per_sec: 10.317826539662601
collect_time: 0.8722767305113375
reward_mean: 1316.2549008096412
reward_std: 484.6133528008826
reward_max: 2453.8279859444165
reward_min: 717.043549869716
total_envstep_count: 1613208
total_train_sample_count: 1277563
total_episode_count: 8450
total_duration: 475.8003504883815
[2023-06-29 10:09:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 246.84615384615384
avg_sample_per_episode: 246.84615384615384
avg_envstep_per_sec: 2500.0559017297132
avg_train_sample_per_sec: 2500.0559017297132
avg_episode_per_sec: 10.127992122931216
collect_time: 1.2835712984576824
reward_mean: 1340.766576132715
reward_std: 690.7499408171475
reward_max: 3237.830383936707
reward_min: 718.0611225271865
total_envstep_count: 1617720
total_train_sample_count: 1280772
total_episode_count: 8463
total_duration: 477.0839217868392
[2023-06-29 10:09:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3156
train_sample_count: 3156
avg_envstep_per_episode: 210.4
avg_sample_per_episode: 210.4
avg_envstep_per_sec: 2622.499845355381
avg_train_sample_per_sec: 2622.499845355381
avg_episode_per_sec: 12.464352877164357
collect_time: 1.2034319108119236
reward_mean: 1006.5984014627811
reward_std: 241.79177277485118
reward_max: 1600.280944425309
reward_min: 730.1083757847057
total_envstep_count: 1622240
total_train_sample_count: 1284328
total_episode_count: 8478
total_duration: 478.2873536976511
[2023-06-29 10:09:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3306
train_sample_count: 3306
avg_envstep_per_episode: 275.5
avg_sample_per_episode: 275.5
avg_envstep_per_sec: 2650.3074566129
avg_train_sample_per_sec: 2650.3074566129
avg_episode_per_sec: 9.6199907681049
collect_time: 1.2474024444790557
reward_mean: 1316.1244431773173
reward_std: 392.55045499017797
reward_max: 2267.714194595486
reward_min: 809.950873931311
total_envstep_count: 1626880
total_train_sample_count: 1287634
total_episode_count: 8490
total_duration: 479.53475614213016
[2023-06-29 10:09:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3139
train_sample_count: 3139
avg_envstep_per_episode: 224.21428571428572
avg_sample_per_episode: 224.21428571428572
avg_envstep_per_sec: 2501.1448891323307
avg_train_sample_per_sec: 2501.1448891323307
avg_episode_per_sec: 11.155154013333108
collect_time: 1.2550252540903166
reward_mean: 1081.1584257778484
reward_std: 240.93581014360726
reward_max: 1587.6416478095584
reward_min: 703.6403669652356
total_envstep_count: 1631312
total_train_sample_count: 1291173
total_episode_count: 8504
total_duration: 480.78978139622046
[2023-06-29 10:09:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3326
train_sample_count: 3326
avg_envstep_per_episode: 237.57142857142858
avg_sample_per_episode: 237.57142857142858
avg_envstep_per_sec: 2405.695150198692
avg_train_sample_per_sec: 2405.695150198692
avg_episode_per_sec: 10.126197264817103
collect_time: 1.382552564785816
reward_mean: 1120.5508102322276
reward_std: 229.844975204379
reward_max: 1505.799240465825
reward_min: 812.1418274176305
total_envstep_count: 1635504
total_train_sample_count: 1294499
total_episode_count: 8518
total_duration: 482.1723339610063
[2023-06-29 10:09:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3498
train_sample_count: 3498
avg_envstep_per_episode: 269.0769230769231
avg_sample_per_episode: 269.0769230769231
avg_envstep_per_sec: 2691.846855580609
avg_train_sample_per_sec: 2691.846855580609
avg_episode_per_sec: 10.004004894953663
collect_time: 1.299479572081938
reward_mean: 1149.053974059555
reward_std: 243.021132723314
reward_max: 1553.5542312503453
reward_min: 724.7731516962316
total_envstep_count: 1639768
total_train_sample_count: 1297997
total_episode_count: 8531
total_duration: 483.47181353308827
[2023-06-29 10:09:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3273
train_sample_count: 3273
avg_envstep_per_episode: 297.54545454545456
avg_sample_per_episode: 297.54545454545456
avg_envstep_per_sec: 2328.7654388843494
avg_train_sample_per_sec: 2328.7654388843494
avg_episode_per_sec: 7.826587176207712
collect_time: 1.4054657224593683
reward_mean: 1247.780566122941
reward_std: 333.1447927776611
reward_max: 1911.7733839721932
reward_min: 759.2386460491576
total_envstep_count: 1643880
total_train_sample_count: 1301270
total_episode_count: 8542
total_duration: 484.87727925554765
[2023-06-29 10:09:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2494
train_sample_count: 2494
avg_envstep_per_episode: 277.1111111111111
avg_sample_per_episode: 277.1111111111111
avg_envstep_per_sec: 2434.8825947291707
avg_train_sample_per_sec: 2434.8825947291707
avg_episode_per_sec: 8.78666533783582
collect_time: 1.0242793658301232
reward_mean: 1257.0229603341277
reward_std: 216.45907972152543
reward_max: 1673.5448500466423
reward_min: 898.6963063761522
total_envstep_count: 1648584
total_train_sample_count: 1304564
total_episode_count: 8551
total_duration: 485.9015586213778
[2023-06-29 10:09:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2442
train_sample_count: 2442
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2401.0971172100044
avg_train_sample_per_sec: 2401.0971172100044
avg_episode_per_sec: 10.815752780225244
collect_time: 1.0170350805458146
reward_mean: 1427.8838431484166
reward_std: 356.0473651482498
reward_max: 1879.466988421852
reward_min: 889.1216664852046
total_envstep_count: 1652840
total_train_sample_count: 1307806
total_episode_count: 8562
total_duration: 486.9185937019236
[2023-06-29 10:09:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 248.4
avg_sample_per_episode: 248.4
avg_envstep_per_sec: 2596.689591492295
avg_train_sample_per_sec: 2596.689591492295
avg_episode_per_sec: 10.453661801498773
collect_time: 0.956602594371885
reward_mean: 1430.1545426783805
reward_std: 307.5176172731817
reward_max: 1974.4556875508501
reward_min: 958.313606915533
total_envstep_count: 1657352
total_train_sample_count: 1311090
total_episode_count: 8572
total_duration: 487.8751962962955
[2023-06-29 10:09:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2711
train_sample_count: 2711
avg_envstep_per_episode: 225.91666666666666
avg_sample_per_episode: 225.91666666666666
avg_envstep_per_sec: 2437.618232110297
avg_train_sample_per_sec: 2437.618232110297
avg_episode_per_sec: 10.789899957699582
collect_time: 1.1121511827768988
reward_mean: 1353.506290094005
reward_std: 494.97062101749674
reward_max: 2752.9009003680917
reward_min: 931.0109167473232
total_envstep_count: 1662192
total_train_sample_count: 1314601
total_episode_count: 8584
total_duration: 488.9873474790724
[2023-06-29 10:09:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3437
train_sample_count: 3437
avg_envstep_per_episode: 286.4166666666667
avg_sample_per_episode: 286.4166666666667
avg_envstep_per_sec: 2411.746217248813
avg_train_sample_per_sec: 2411.746217248813
avg_episode_per_sec: 8.420411581898678
collect_time: 1.4251084858840328
reward_mean: 1540.9845552018116
reward_std: 300.4797323004953
reward_max: 1897.0975523700772
reward_min: 878.8450384358457
total_envstep_count: 1666968
total_train_sample_count: 1318038
total_episode_count: 8596
total_duration: 490.41245596495645
[2023-06-29 10:10:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 307.7142857142857
avg_sample_per_episode: 307.7142857142857
avg_envstep_per_sec: 2554.4003918994167
avg_train_sample_per_sec: 2554.4003918994167
avg_episode_per_sec: 8.301208330220947
collect_time: 0.8432507318863647
reward_mean: 1600.8715703157795
reward_std: 466.936670762187
reward_max: 2613.199957451284
reward_min: 1059.6941394002674
total_envstep_count: 1671176
total_train_sample_count: 1321392
total_episode_count: 8603
total_duration: 491.2557066968428
[2023-06-29 10:10:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1341
train_sample_count: 1341
avg_envstep_per_episode: 191.57142857142858
avg_sample_per_episode: 191.57142857142858
avg_envstep_per_sec: 2568.3972097938135
avg_train_sample_per_sec: 2568.3972097938135
avg_episode_per_sec: 13.406995129423338
collect_time: 0.5221155025735498
reward_mean: 1536.1125434927405
reward_std: 620.5252475508296
reward_max: 2694.2965630470308
reward_min: 907.2154967281369
total_envstep_count: 1675480
total_train_sample_count: 1324733
total_episode_count: 8610
total_duration: 491.7778221994164
[2023-06-29 10:10:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2121
train_sample_count: 2121
avg_envstep_per_episode: 212.1
avg_sample_per_episode: 212.1
avg_envstep_per_sec: 2199.571814978025
avg_train_sample_per_sec: 2199.571814978025
avg_episode_per_sec: 10.370447029599363
collect_time: 0.9642785862034652
reward_mean: 1792.192060628608
reward_std: 659.4193243083797
reward_max: 3129.4931322403722
reward_min: 976.0232130070551
total_envstep_count: 1680096
total_train_sample_count: 1328054
total_episode_count: 8620
total_duration: 492.74210078561987
[2023-06-29 10:10:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2418
train_sample_count: 2418
avg_envstep_per_episode: 201.5
avg_sample_per_episode: 201.5
avg_envstep_per_sec: 2481.6699205145783
avg_train_sample_per_sec: 2481.6699205145783
avg_episode_per_sec: 12.315979754414782
collect_time: 0.9743439206043258
reward_mean: 1344.0395103881337
reward_std: 374.6963265247064
reward_max: 2108.400630928089
reward_min: 994.0703418897208
total_envstep_count: 1684384
total_train_sample_count: 1331272
total_episode_count: 8632
total_duration: 493.7164447062242
[2023-06-29 10:10:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3321
train_sample_count: 3321
avg_envstep_per_episode: 255.46153846153845
avg_sample_per_episode: 255.46153846153845
avg_envstep_per_sec: 2523.278017849029
avg_train_sample_per_sec: 2523.278017849029
avg_episode_per_sec: 9.877330392061841
collect_time: 1.3161451003449038
reward_mean: 1327.7642964915713
reward_std: 456.1836589819654
reward_max: 1964.330277974692
reward_min: 313.5413579982012
total_envstep_count: 1688896
total_train_sample_count: 1334593
total_episode_count: 8645
total_duration: 495.0325898065691
[2023-06-29 10:10:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2872
train_sample_count: 2872
avg_envstep_per_episode: 287.2
avg_sample_per_episode: 287.2
avg_envstep_per_sec: 2477.87710366981
avg_train_sample_per_sec: 2477.87710366981
avg_episode_per_sec: 8.62770579272218
collect_time: 1.1590566762760277
reward_mean: 1362.9353380204197
reward_std: 479.5624016097786
reward_max: 2572.6083897072735
reward_min: 968.7245759299851
total_envstep_count: 1692696
total_train_sample_count: 1337865
total_episode_count: 8655
total_duration: 496.1916464828451
[2023-06-29 10:10:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 338.22222222222223
avg_sample_per_episode: 338.22222222222223
avg_envstep_per_sec: 2684.5183899495555
avg_train_sample_per_sec: 2684.5183899495555
avg_episode_per_sec: 7.937143728497372
collect_time: 1.1339091627743327
reward_mean: 1456.2660240424407
reward_std: 450.5996301869505
reward_max: 2401.4789184880565
reward_min: 916.4647103549103
total_envstep_count: 1697648
total_train_sample_count: 1341309
total_episode_count: 8664
total_duration: 497.32555564561943
[2023-06-29 10:10:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2785
train_sample_count: 2785
avg_envstep_per_episode: 253.1818181818182
avg_sample_per_episode: 253.1818181818182
avg_envstep_per_sec: 2470.5405566904783
avg_train_sample_per_sec: 2470.5405566904783
avg_episode_per_sec: 9.757969882799017
collect_time: 1.1272836596257985
reward_mean: 1432.532141653213
reward_std: 269.09904572982106
reward_max: 1829.5814335507562
reward_min: 827.9173059066329
total_envstep_count: 1702392
total_train_sample_count: 1344894
total_episode_count: 8675
total_duration: 498.4528393052452
[2023-06-29 10:10:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3026
train_sample_count: 3026
avg_envstep_per_episode: 302.6
avg_sample_per_episode: 302.6
avg_envstep_per_sec: 2488.735292479199
avg_train_sample_per_sec: 2488.735292479199
avg_episode_per_sec: 8.224505262654326
collect_time: 1.2158786067543548
reward_mean: 1689.845169686767
reward_std: 698.7278662774391
reward_max: 3057.4164100589464
reward_min: 997.1767360116132
total_envstep_count: 1707272
total_train_sample_count: 1348320
total_episode_count: 8685
total_duration: 499.6687179119996
[2023-06-29 10:10:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3132
train_sample_count: 3132
avg_envstep_per_episode: 240.92307692307693
avg_sample_per_episode: 240.92307692307693
avg_envstep_per_sec: 2469.8261831920645
avg_train_sample_per_sec: 2469.8261831920645
avg_episode_per_sec: 10.251513531767829
collect_time: 1.268105432404205
reward_mean: 1243.2289297115017
reward_std: 268.49023211822066
reward_max: 2023.5089158118735
reward_min: 969.5044360802253
total_envstep_count: 1711816
total_train_sample_count: 1351852
total_episode_count: 8698
total_duration: 500.93682334440376
[2023-06-29 10:10:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3249
train_sample_count: 3249
avg_envstep_per_episode: 249.92307692307693
avg_sample_per_episode: 249.92307692307693
avg_envstep_per_sec: 2711.3305953010613
avg_train_sample_per_sec: 2711.3305953010613
avg_episode_per_sec: 10.848660430567497
collect_time: 1.198304627857171
reward_mean: 1261.9131555528015
reward_std: 414.2782157930603
reward_max: 2453.6201105143914
reward_min: 803.0931950672483
total_envstep_count: 1716184
total_train_sample_count: 1355101
total_episode_count: 8711
total_duration: 502.13512797226093
[2023-06-29 10:10:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3345
train_sample_count: 3345
avg_envstep_per_episode: 334.5
avg_sample_per_episode: 334.5
avg_envstep_per_sec: 2541.1389559844756
avg_train_sample_per_sec: 2541.1389559844756
avg_episode_per_sec: 7.596827970058223
collect_time: 1.3163388771489264
reward_mean: 1511.656376103585
reward_std: 555.781875105296
reward_max: 2628.5761222409214
reward_min: 996.004699570659
total_envstep_count: 1720808
total_train_sample_count: 1358446
total_episode_count: 8721
total_duration: 503.4514668494099
[2023-06-29 10:10:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2833
train_sample_count: 2833
avg_envstep_per_episode: 283.3
avg_sample_per_episode: 283.3
avg_envstep_per_sec: 2524.989697560572
avg_train_sample_per_sec: 2524.989697560572
avg_episode_per_sec: 8.91277690632041
collect_time: 1.1219847759129478
reward_mean: 1359.4895884309121
reward_std: 316.67321777472273
reward_max: 1924.261412544162
reward_min: 965.1871803738634
total_envstep_count: 1725352
total_train_sample_count: 1361679
total_episode_count: 8731
total_duration: 504.57345162532283
[2023-06-29 10:10:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2532
train_sample_count: 2532
avg_envstep_per_episode: 253.2
avg_sample_per_episode: 253.2
avg_envstep_per_sec: 2624.9759812463303
avg_train_sample_per_sec: 2624.9759812463303
avg_episode_per_sec: 10.36720371740257
collect_time: 0.9645802544821055
reward_mean: 1494.4745034791536
reward_std: 688.5317982369631
reward_max: 2802.5465680666516
reward_min: 859.03383918895
total_envstep_count: 1729864
total_train_sample_count: 1365011
total_episode_count: 8741
total_duration: 505.5380318798049
[2023-06-29 10:10:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2263
train_sample_count: 2263
avg_envstep_per_episode: 251.44444444444446
avg_sample_per_episode: 251.44444444444446
avg_envstep_per_sec: 2616.4037003059475
avg_train_sample_per_sec: 2616.4037003059475
avg_episode_per_sec: 10.40549416825167
collect_time: 0.864927686708048
reward_mean: 1419.4877495864077
reward_std: 682.1471284467722
reward_max: 3085.651941867103
reward_min: 745.491289532141
total_envstep_count: 1734240
total_train_sample_count: 1368474
total_episode_count: 8750
total_duration: 506.40295956651295
[2023-06-29 10:10:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1865
train_sample_count: 1865
avg_envstep_per_episode: 207.22222222222223
avg_sample_per_episode: 207.22222222222223
avg_envstep_per_sec: 2601.979280400682
avg_train_sample_per_sec: 2601.979280400682
avg_episode_per_sec: 12.556468377268706
collect_time: 0.7167620488172398
reward_mean: 1695.3903251773818
reward_std: 760.5619646990227
reward_max: 3211.450180848949
reward_min: 964.2888774519697
total_envstep_count: 1738752
total_train_sample_count: 1371939
total_episode_count: 8759
total_duration: 507.1197216153302
[2023-06-29 10:10:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2499
train_sample_count: 2499
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 2533.016449206544
avg_train_sample_per_sec: 2533.016449206544
avg_episode_per_sec: 12.163344293908974
collect_time: 0.9865707744546233
reward_mean: 1375.5321730280154
reward_std: 439.7133150488638
reward_max: 2360.9147332573043
reward_min: 938.7746925212454
total_envstep_count: 1743544
total_train_sample_count: 1375238
total_episode_count: 8771
total_duration: 508.1062923897848
[2023-06-29 10:10:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1712
train_sample_count: 1712
avg_envstep_per_episode: 190.22222222222223
avg_sample_per_episode: 190.22222222222223
avg_envstep_per_sec: 2332.786108422982
avg_train_sample_per_sec: 2332.786108422982
avg_episode_per_sec: 12.263478373718948
collect_time: 0.7338864003941415
reward_mean: 1495.785296281122
reward_std: 707.1672887216143
reward_max: 3394.835808364241
reward_min: 982.4429797399183
total_envstep_count: 1747600
total_train_sample_count: 1378550
total_episode_count: 8780
total_duration: 508.840178790179
[2023-06-29 10:10:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2444
train_sample_count: 2444
avg_envstep_per_episode: 244.4
avg_sample_per_episode: 244.4
avg_envstep_per_sec: 2578.90501589655
avg_train_sample_per_sec: 2578.90501589655
avg_episode_per_sec: 10.551984516761662
collect_time: 0.9476890327231959
reward_mean: 1711.0199772403903
reward_std: 709.8974825569683
reward_max: 2991.571768354285
reward_min: 799.3869081541271
total_envstep_count: 1751864
total_train_sample_count: 1381794
total_episode_count: 8790
total_duration: 509.7878678229022
[2023-06-29 10:10:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3398
train_sample_count: 3398
avg_envstep_per_episode: 283.1666666666667
avg_sample_per_episode: 283.1666666666667
avg_envstep_per_sec: 2675.0270625924795
avg_train_sample_per_sec: 2675.0270625924795
avg_episode_per_sec: 9.446828943822764
collect_time: 1.2702675227168945
reward_mean: 1509.1948944113617
reward_std: 810.9809309787737
reward_max: 3375.935447183656
reward_min: 881.3653246618949
total_envstep_count: 1756264
total_train_sample_count: 1385192
total_episode_count: 8802
total_duration: 511.05813534561906
[2023-06-29 10:11:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3033
train_sample_count: 3033
avg_envstep_per_episode: 275.72727272727275
avg_sample_per_episode: 275.72727272727275
avg_envstep_per_sec: 2651.0756076610305
avg_train_sample_per_sec: 2651.0756076610305
avg_episode_per_sec: 9.61484724176437
collect_time: 1.1440639381371438
reward_mean: 1242.9191283561458
reward_std: 404.1863525516071
reward_max: 2153.2551057789765
reward_min: 718.2924711345455
total_envstep_count: 1760728
total_train_sample_count: 1388625
total_episode_count: 8813
total_duration: 512.2021992837562
[2023-06-29 10:11:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3168
train_sample_count: 3168
avg_envstep_per_episode: 243.69230769230768
avg_sample_per_episode: 243.69230769230768
avg_envstep_per_sec: 2442.425783333257
avg_train_sample_per_sec: 2442.425783333257
avg_episode_per_sec: 10.0225805502943
collect_time: 1.2970711419843137
reward_mean: 1201.7921600886364
reward_std: 350.81220079627434
reward_max: 1894.7858504117328
reward_min: 764.9241003696999
total_envstep_count: 1765536
total_train_sample_count: 1392193
total_episode_count: 8826
total_duration: 513.4992704257405
[2023-06-29 10:11:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3066
train_sample_count: 3066
avg_envstep_per_episode: 255.5
avg_sample_per_episode: 255.5
avg_envstep_per_sec: 2462.3724184373496
avg_train_sample_per_sec: 2462.3724184373496
avg_episode_per_sec: 9.637465434197063
collect_time: 1.2451406525848432
reward_mean: 1322.7560563721584
reward_std: 502.4877201425743
reward_max: 2494.72042349151
reward_min: 863.2640245402828
total_envstep_count: 1770392
total_train_sample_count: 1395659
total_episode_count: 8838
total_duration: 514.7444110783254
[2023-06-29 10:11:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3468
train_sample_count: 3468
avg_envstep_per_episode: 231.2
avg_sample_per_episode: 231.2
avg_envstep_per_sec: 2487.351375460588
avg_train_sample_per_sec: 2487.351375460588
avg_episode_per_sec: 10.758440205279358
collect_time: 1.394254158947617
reward_mean: 1197.7146528105338
reward_std: 381.1346696382899
reward_max: 2485.801034007126
reward_min: 864.9545481223886
total_envstep_count: 1774928
total_train_sample_count: 1399127
total_episode_count: 8853
total_duration: 516.138665237273
[2023-06-29 10:11:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3529
train_sample_count: 3529
avg_envstep_per_episode: 294.0833333333333
avg_sample_per_episode: 294.0833333333333
avg_envstep_per_sec: 2664.409940010706
avg_train_sample_per_sec: 2664.409940010706
avg_episode_per_sec: 9.060050801963296
collect_time: 1.3244958844380454
reward_mean: 1309.2630877884692
reward_std: 445.6852195859941
reward_max: 2151.5831464320645
reward_min: 554.7049080914769
total_envstep_count: 1779888
total_train_sample_count: 1402656
total_episode_count: 8865
total_duration: 517.4631611217111
[2023-06-29 10:11:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3116
train_sample_count: 3116
avg_envstep_per_episode: 283.27272727272725
avg_sample_per_episode: 283.27272727272725
avg_envstep_per_sec: 2681.9767665399495
avg_train_sample_per_sec: 2681.9767665399495
avg_episode_per_sec: 9.467825555821387
collect_time: 1.1618296022824945
reward_mean: 1398.6488950072935
reward_std: 231.54805368312344
reward_max: 1824.9749930560656
reward_min: 1054.7865958720638
total_envstep_count: 1784784
total_train_sample_count: 1406172
total_episode_count: 8876
total_duration: 518.6249907239936
[2023-06-29 10:11:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2419
train_sample_count: 2419
avg_envstep_per_episode: 201.58333333333334
avg_sample_per_episode: 201.58333333333334
avg_envstep_per_sec: 2420.1947396741725
avg_train_sample_per_sec: 2420.1947396741725
avg_episode_per_sec: 12.005926778044676
collect_time: 0.9995063456445933
reward_mean: 1198.557730908089
reward_std: 492.5199245781147
reward_max: 2670.7467059653104
reward_min: 712.5871530056959
total_envstep_count: 1789088
total_train_sample_count: 1409391
total_episode_count: 8888
total_duration: 519.6244970696382
[2023-06-29 10:11:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3401
train_sample_count: 3401
avg_envstep_per_episode: 261.61538461538464
avg_sample_per_episode: 261.61538461538464
avg_envstep_per_sec: 2486.893396444678
avg_train_sample_per_sec: 2486.893396444678
avg_episode_per_sec: 9.505914188115499
collect_time: 1.367569677438587
reward_mean: 1383.3082406076016
reward_std: 447.84183429016764
reward_max: 2362.7594849914844
reward_min: 786.8477225725788
total_envstep_count: 1794120
total_train_sample_count: 1412792
total_episode_count: 8901
total_duration: 520.9920667470768
[2023-06-29 10:11:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3014
train_sample_count: 3014
avg_envstep_per_episode: 274.0
avg_sample_per_episode: 274.0
avg_envstep_per_sec: 2631.9442773929877
avg_train_sample_per_sec: 2631.9442773929877
avg_episode_per_sec: 9.605636048879518
collect_time: 1.1451610225522892
reward_mean: 1440.8675250825067
reward_std: 488.78313778408074
reward_max: 2422.471565530496
reward_min: 854.0271223336664
total_envstep_count: 1798952
total_train_sample_count: 1416206
total_episode_count: 8912
total_duration: 522.1372277696291
[2023-06-29 10:11:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3375
train_sample_count: 3375
avg_envstep_per_episode: 241.07142857142858
avg_sample_per_episode: 241.07142857142858
avg_envstep_per_sec: 2663.808301379926
avg_train_sample_per_sec: 2663.808301379926
avg_episode_per_sec: 11.049871472390803
collect_time: 1.2669830626519398
reward_mean: 1268.9582372355012
reward_std: 401.12086287718466
reward_max: 2216.2598177666873
reward_min: 848.0583577865968
total_envstep_count: 1803440
total_train_sample_count: 1419581
total_episode_count: 8926
total_duration: 523.404210832281
[2023-06-29 10:11:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3471
train_sample_count: 3471
avg_envstep_per_episode: 347.1
avg_sample_per_episode: 347.1
avg_envstep_per_sec: 2507.7940558743776
avg_train_sample_per_sec: 2507.7940558743776
avg_episode_per_sec: 7.224990077425462
collect_time: 1.3840849458388986
reward_mean: 1559.8832819590828
reward_std: 547.4903587505439
reward_max: 2398.7629645324114
reward_min: 966.9767073499861
total_envstep_count: 1808384
total_train_sample_count: 1423052
total_episode_count: 8936
total_duration: 524.78829577812
[2023-06-29 10:11:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2749
train_sample_count: 2749
avg_envstep_per_episode: 249.9090909090909
avg_sample_per_episode: 249.9090909090909
avg_envstep_per_sec: 2411.042525110623
avg_train_sample_per_sec: 2411.042525110623
avg_episode_per_sec: 9.64767834711417
collect_time: 1.1401706819226969
reward_mean: 1215.2577965301762
reward_std: 244.16098157789756
reward_max: 1856.093385170129
reward_min: 901.7781736055616
total_envstep_count: 1813464
total_train_sample_count: 1426601
total_episode_count: 8947
total_duration: 525.9284664600426
[2023-06-29 10:11:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3117
train_sample_count: 3117
avg_envstep_per_episode: 239.76923076923077
avg_sample_per_episode: 239.76923076923077
avg_envstep_per_sec: 2532.2328550692964
avg_train_sample_per_sec: 2532.2328550692964
avg_episode_per_sec: 10.561125157491452
collect_time: 1.2309294517524538
reward_mean: 1500.3335201642012
reward_std: 736.6586335798147
reward_max: 3298.130498274324
reward_min: 861.06279206606
total_envstep_count: 1818440
total_train_sample_count: 1430118
total_episode_count: 8960
total_duration: 527.1593959117951
[2023-06-29 10:11:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2496
train_sample_count: 2496
avg_envstep_per_episode: 249.6
avg_sample_per_episode: 249.6
avg_envstep_per_sec: 2729.0279173513945
avg_train_sample_per_sec: 2729.0279173513945
avg_episode_per_sec: 10.933605438106548
collect_time: 0.9146113838301972
reward_mean: 1490.945567723738
reward_std: 390.0154804072097
reward_max: 2492.54219569268
reward_min: 1039.6275149739063
total_envstep_count: 1822744
total_train_sample_count: 1433414
total_episode_count: 8970
total_duration: 528.0740072956253
[2023-06-29 10:11:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2499
train_sample_count: 2499
avg_envstep_per_episode: 249.9
avg_sample_per_episode: 249.9
avg_envstep_per_sec: 2641.0366771139534
avg_train_sample_per_sec: 2641.0366771139534
avg_episode_per_sec: 10.568374058079046
collect_time: 0.94621934699174
reward_mean: 1458.2485937126899
reward_std: 325.22283362351146
reward_max: 1879.8288385971116
reward_min: 840.0115202417844
total_envstep_count: 1827432
total_train_sample_count: 1436713
total_episode_count: 8980
total_duration: 529.020226642617
[2023-06-29 10:11:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3051
train_sample_count: 3051
avg_envstep_per_episode: 217.92857142857142
avg_sample_per_episode: 217.92857142857142
avg_envstep_per_sec: 2466.963431306564
avg_train_sample_per_sec: 2466.963431306564
avg_episode_per_sec: 11.320055076464074
collect_time: 1.2367430993430317
reward_mean: 1280.3063677497048
reward_std: 394.6344025455098
reward_max: 2371.9336310984077
reward_min: 882.1485891348492
total_envstep_count: 1832176
total_train_sample_count: 1440164
total_episode_count: 8994
total_duration: 530.25696974196
[2023-06-29 10:11:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3457
train_sample_count: 3457
avg_envstep_per_episode: 265.9230769230769
avg_sample_per_episode: 265.9230769230769
avg_envstep_per_sec: 2548.0260934862563
avg_train_sample_per_sec: 2548.0260934862563
avg_episode_per_sec: 9.581816377009353
collect_time: 1.3567364984359593
reward_mean: 1339.568006555728
reward_std: 476.6995264589299
reward_max: 2135.690495231145
reward_min: 277.85931774080393
total_envstep_count: 1837200
total_train_sample_count: 1443621
total_episode_count: 9007
total_duration: 531.6137062403959
[2023-06-29 10:11:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2661
train_sample_count: 2661
avg_envstep_per_episode: 241.9090909090909
avg_sample_per_episode: 241.9090909090909
avg_envstep_per_sec: 2531.881521978379
avg_train_sample_per_sec: 2531.881521978379
avg_episode_per_sec: 10.466252063796382
collect_time: 1.0509970458336175
reward_mean: 1324.815100374468
reward_std: 309.3282853666948
reward_max: 1855.1500041494533
reward_min: 941.1873769645749
total_envstep_count: 1841400
total_train_sample_count: 1447082
total_episode_count: 9018
total_duration: 532.6647032862295
[2023-06-29 10:12:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3388
train_sample_count: 3388
avg_envstep_per_episode: 282.3333333333333
avg_sample_per_episode: 282.3333333333333
avg_envstep_per_sec: 2642.5334375278917
avg_train_sample_per_sec: 2642.5334375278917
avg_episode_per_sec: 9.359622565033854
collect_time: 1.2821029818905518
reward_mean: 1412.8193471417699
reward_std: 361.00832618074804
reward_max: 2163.6212696710068
reward_min: 963.0936952379362
total_envstep_count: 1846048
total_train_sample_count: 1450470
total_episode_count: 9030
total_duration: 533.9468062681201
[2023-06-29 10:12:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2880
train_sample_count: 2880
avg_envstep_per_episode: 221.53846153846155
avg_sample_per_episode: 221.53846153846155
avg_envstep_per_sec: 2669.82486159477
avg_train_sample_per_sec: 2669.82486159477
avg_episode_per_sec: 12.051292778031947
collect_time: 1.0787224440930878
reward_mean: 1097.8837368483973
reward_std: 247.39486792003893
reward_max: 1710.3782546667235
reward_min: 758.3767870112498
total_envstep_count: 1850272
total_train_sample_count: 1453750
total_episode_count: 9043
total_duration: 535.0255287122131
[2023-06-29 10:12:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3420
train_sample_count: 3420
avg_envstep_per_episode: 244.28571428571428
avg_sample_per_episode: 244.28571428571428
avg_envstep_per_sec: 2541.710608695876
avg_train_sample_per_sec: 2541.710608695876
avg_episode_per_sec: 10.404663310450955
collect_time: 1.3455505077168344
reward_mean: 1173.3542433589298
reward_std: 175.14427426728156
reward_max: 1495.9452717171678
reward_min: 951.5840942658466
total_envstep_count: 1854776
total_train_sample_count: 1457170
total_episode_count: 9057
total_duration: 536.3710792199299
[2023-06-29 10:12:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3329
train_sample_count: 3329
avg_envstep_per_episode: 221.93333333333334
avg_sample_per_episode: 221.93333333333334
avg_envstep_per_sec: 2491.53989226882
avg_train_sample_per_sec: 2491.53989226882
avg_episode_per_sec: 11.226523996405017
collect_time: 1.3361214927081022
reward_mean: 1012.0298697346541
reward_std: 232.07479908475716
reward_max: 1623.5915128284041
reward_min: 664.8102818654022
total_envstep_count: 1859416
total_train_sample_count: 1460499
total_episode_count: 9072
total_duration: 537.707200712638
[2023-06-29 10:12:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3415
train_sample_count: 3415
avg_envstep_per_episode: 213.4375
avg_sample_per_episode: 213.4375
avg_envstep_per_sec: 2653.2518228122667
avg_train_sample_per_sec: 2653.2518228122667
avg_episode_per_sec: 12.43104807174122
collect_time: 1.2870998412733896
reward_mean: 1014.9871890771001
reward_std: 256.9579769944618
reward_max: 1505.635298309333
reward_min: 684.4170222654142
total_envstep_count: 1863568
total_train_sample_count: 1463914
total_episode_count: 9088
total_duration: 538.9943005539114
[2023-06-29 10:12:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 209.78571428571428
avg_sample_per_episode: 209.78571428571428
avg_envstep_per_sec: 2663.3759427781206
avg_train_sample_per_sec: 2663.3759427781206
avg_episode_per_sec: 12.695697377900473
collect_time: 1.1027357996394858
reward_mean: 880.1902546128307
reward_std: 359.8751856785835
reward_max: 1607.5609379606028
reward_min: 252.90342887808646
total_envstep_count: 1868000
total_train_sample_count: 1467251
total_episode_count: 9102
total_duration: 540.097036353551
[2023-06-29 10:12:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3422
train_sample_count: 3422
avg_envstep_per_episode: 201.2941176470588
avg_sample_per_episode: 201.2941176470588
avg_envstep_per_sec: 2469.940187908027
avg_train_sample_per_sec: 2469.940187908027
avg_episode_per_sec: 12.270304849338533
collect_time: 1.3854586506802589
reward_mean: 995.4098824532584
reward_std: 254.48584687514298
reward_max: 1590.31418061285
reward_min: 720.5331378297947
total_envstep_count: 1872736
total_train_sample_count: 1470673
total_episode_count: 9119
total_duration: 541.4824950042312
[2023-06-29 10:12:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 189.8235294117647
avg_sample_per_episode: 189.8235294117647
avg_envstep_per_sec: 2472.6677305415874
avg_train_sample_per_sec: 2472.6677305415874
avg_episode_per_sec: 13.026139268424847
collect_time: 1.3050681901741774
reward_mean: 914.4192483036885
reward_std: 226.61846397601926
reward_max: 1458.3188441015136
reward_min: 685.6579277640559
total_envstep_count: 1877016
total_train_sample_count: 1473900
total_episode_count: 9136
total_duration: 542.7875631944054
[2023-06-29 10:12:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3291
train_sample_count: 3291
avg_envstep_per_episode: 205.6875
avg_sample_per_episode: 205.6875
avg_envstep_per_sec: 2691.444278614526
avg_train_sample_per_sec: 2691.444278614526
avg_episode_per_sec: 13.085113478527017
collect_time: 1.2227635645847765
reward_mean: 903.922081482518
reward_std: 320.858269550425
reward_max: 1696.6308025357669
reward_min: 122.79804765636007
total_envstep_count: 1881272
total_train_sample_count: 1477191
total_episode_count: 9152
total_duration: 544.0103267589901
[2023-06-29 10:12:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 186.23076923076923
avg_sample_per_episode: 186.23076923076923
avg_envstep_per_sec: 2481.725142203743
avg_train_sample_per_sec: 2481.725142203743
avg_episode_per_sec: 13.326074699978793
collect_time: 0.9755310766808689
reward_mean: 882.9765998454403
reward_std: 146.37227612396723
reward_max: 1255.3392030590867
reward_min: 704.731999756275
total_envstep_count: 1885008
total_train_sample_count: 1480412
total_episode_count: 9165
total_duration: 544.985857835671
[2023-06-29 10:12:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2255
train_sample_count: 2255
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2470.101969004611
avg_train_sample_per_sec: 2470.101969004611
avg_episode_per_sec: 12.049277897583469
collect_time: 0.9129177776044235
reward_mean: 1063.948749991603
reward_std: 349.12286714858027
reward_max: 1802.0176346582214
reward_min: 750.2326800060532
total_envstep_count: 1889880
total_train_sample_count: 1483867
total_episode_count: 9176
total_duration: 545.8987756132755
[2023-06-29 10:12:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2325
train_sample_count: 2325
avg_envstep_per_episode: 211.36363636363637
avg_sample_per_episode: 211.36363636363637
avg_envstep_per_sec: 2573.822160556195
avg_train_sample_per_sec: 2573.822160556195
avg_episode_per_sec: 12.177223125212103
collect_time: 0.9033258146699518
reward_mean: 1563.6610718067254
reward_std: 791.6152071687909
reward_max: 3238.7349214254355
reward_min: 866.3358690799366
total_envstep_count: 1894544
total_train_sample_count: 1487392
total_episode_count: 9187
total_duration: 546.8021014279454
[2023-06-29 10:12:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2741
train_sample_count: 2741
avg_envstep_per_episode: 210.84615384615384
avg_sample_per_episode: 210.84615384615384
avg_envstep_per_sec: 2670.1133161488974
avg_train_sample_per_sec: 2670.1133161488974
avg_episode_per_sec: 12.663799018582877
collect_time: 1.0265481930756941
reward_mean: 1342.0128206926104
reward_std: 396.922032647521
reward_max: 2122.723654897316
reward_min: 861.2529158837605
total_envstep_count: 1899136
total_train_sample_count: 1490933
total_episode_count: 9200
total_duration: 547.8286496210211
[2023-06-29 10:12:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2405
train_sample_count: 2405
avg_envstep_per_episode: 218.63636363636363
avg_sample_per_episode: 218.63636363636363
avg_envstep_per_sec: 2341.6343995453312
avg_train_sample_per_sec: 2341.6343995453312
avg_episode_per_sec: 10.710178126818564
collect_time: 1.0270604157792405
reward_mean: 1331.645899792383
reward_std: 645.0416438232595
reward_max: 3070.864551505659
reward_min: 702.0006074892617
total_envstep_count: 1903680
total_train_sample_count: 1494138
total_episode_count: 9211
total_duration: 548.8557100368004
[2023-06-29 10:12:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 237.28571428571428
avg_sample_per_episode: 237.28571428571428
avg_envstep_per_sec: 2362.058947700514
avg_train_sample_per_sec: 2362.058947700514
avg_episode_per_sec: 9.954492856052738
collect_time: 0.7032000626474622
reward_mean: 1664.3944807136156
reward_std: 652.1484924103534
reward_max: 2487.9196826587927
reward_min: 713.4814861926423
total_envstep_count: 1908016
total_train_sample_count: 1497399
total_episode_count: 9218
total_duration: 549.5589100994479
[2023-06-29 10:12:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2590
train_sample_count: 2590
avg_envstep_per_episode: 215.83333333333334
avg_sample_per_episode: 215.83333333333334
avg_envstep_per_sec: 2450.472266496423
avg_train_sample_per_sec: 2450.472266496423
avg_episode_per_sec: 11.353539458670685
collect_time: 1.056939119618386
reward_mean: 1626.503341496308
reward_std: 844.9250500639481
reward_max: 3287.1416158663765
reward_min: 975.6947117753185
total_envstep_count: 1912616
total_train_sample_count: 1500789
total_episode_count: 9230
total_duration: 550.6158492190663
[2023-06-29 10:12:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2364
train_sample_count: 2364
avg_envstep_per_episode: 262.6666666666667
avg_sample_per_episode: 262.6666666666667
avg_envstep_per_sec: 2644.586750383306
avg_train_sample_per_sec: 2644.586750383306
avg_episode_per_sec: 10.068223668971976
collect_time: 0.893901476159692
reward_mean: 1544.0868517410318
reward_std: 485.1833088964477
reward_max: 2238.8452091906306
reward_min: 931.879070793496
total_envstep_count: 1917344
total_train_sample_count: 1504353
total_episode_count: 9239
total_duration: 551.509750695226
[2023-06-29 10:12:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1285
train_sample_count: 1285
avg_envstep_per_episode: 183.57142857142858
avg_sample_per_episode: 183.57142857142858
avg_envstep_per_sec: 2576.697129195549
avg_train_sample_per_sec: 2576.697129195549
avg_episode_per_sec: 14.036482415851241
collect_time: 0.49870044307503847
reward_mean: 1843.6030937659489
reward_std: 850.5965519172082
reward_max: 3233.359373026624
reward_min: 934.6468424828405
total_envstep_count: 1921512
total_train_sample_count: 1507638
total_episode_count: 9246
total_duration: 552.008451138301
[2023-06-29 10:12:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2288
train_sample_count: 2288
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2634.5417651110824
avg_train_sample_per_sec: 2634.5417651110824
avg_episode_per_sec: 9.211684493395392
collect_time: 0.8684622237915174
reward_mean: 2133.3514595862616
reward_std: 971.6672128210971
reward_max: 3418.0900002535745
reward_min: 862.9588428930626
total_envstep_count: 1926224
total_train_sample_count: 1511126
total_episode_count: 9254
total_duration: 552.8769133620925
[2023-06-29 10:12:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1558
train_sample_count: 1558
avg_envstep_per_episode: 194.75
avg_sample_per_episode: 194.75
avg_envstep_per_sec: 2592.6657473027594
avg_train_sample_per_sec: 2592.6657473027594
avg_episode_per_sec: 13.31278945983445
collect_time: 0.6009259009268132
reward_mean: 1850.0655104184743
reward_std: 864.2970945868879
reward_max: 3290.582763827688
reward_min: 907.1018915473884
total_envstep_count: 1930832
total_train_sample_count: 1514684
total_episode_count: 9262
total_duration: 553.4778392630193
[2023-06-29 10:13:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 273.2
avg_sample_per_episode: 273.2
avg_envstep_per_sec: 2576.708789543383
avg_train_sample_per_sec: 2576.708789543383
avg_episode_per_sec: 9.431584149133906
collect_time: 0.5301336361886932
reward_mean: 2324.820773572371
reward_std: 820.4888856352908
reward_max: 3422.54837830057
reward_min: 1260.9814022580322
total_envstep_count: 1934616
total_train_sample_count: 1518050
total_episode_count: 9267
total_duration: 554.007972899208
[2023-06-29 10:13:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2640
train_sample_count: 2640
avg_envstep_per_episode: 293.3333333333333
avg_sample_per_episode: 293.3333333333333
avg_envstep_per_sec: 2529.9563793664875
avg_train_sample_per_sec: 2529.9563793664875
avg_episode_per_sec: 8.624851293294842
collect_time: 1.0434962521611018
reward_mean: 2264.7836300591
reward_std: 1003.2100794110379
reward_max: 3356.2001053888084
reward_min: 955.2311652351787
total_envstep_count: 1939416
total_train_sample_count: 1521490
total_episode_count: 9276
total_duration: 555.051469151369
[2023-06-29 10:13:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2317
train_sample_count: 2317
avg_envstep_per_episode: 289.625
avg_sample_per_episode: 289.625
avg_envstep_per_sec: 2495.3900378101134
avg_train_sample_per_sec: 2495.3900378101134
avg_episode_per_sec: 8.615934528476869
collect_time: 0.9285121623845771
reward_mean: 1778.5491048234776
reward_std: 742.7982124064652
reward_max: 2823.324000548619
reward_min: 811.9870644496586
total_envstep_count: 1944336
total_train_sample_count: 1525007
total_episode_count: 9284
total_duration: 555.9799813137536
[2023-06-29 10:13:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 274.0833333333333
avg_sample_per_episode: 274.0833333333333
avg_envstep_per_sec: 2500.83617892216
avg_train_sample_per_sec: 2500.83617892216
avg_episode_per_sec: 9.124364289165678
collect_time: 1.315160116332583
reward_mean: 1778.37124895372
reward_std: 1002.232962089682
reward_max: 3406.524833223014
reward_min: 806.7350369191034
total_envstep_count: 1948704
total_train_sample_count: 1528296
total_episode_count: 9296
total_duration: 557.2951414300861
[2023-06-29 10:13:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 292.45454545454544
avg_sample_per_episode: 292.45454545454544
avg_envstep_per_sec: 2480.4866203844676
avg_train_sample_per_sec: 2480.4866203844676
avg_episode_per_sec: 8.481614182228519
collect_time: 1.296922939863056
reward_mean: 1350.1304342696383
reward_std: 489.78255484415007
reward_max: 2437.466608660445
reward_min: 510.6912419931659
total_envstep_count: 1953488
total_train_sample_count: 1531513
total_episode_count: 9307
total_duration: 558.5920643699492
[2023-06-29 10:13:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3249
train_sample_count: 3249
avg_envstep_per_episode: 249.92307692307693
avg_sample_per_episode: 249.92307692307693
avg_envstep_per_sec: 2499.6027850398636
avg_train_sample_per_sec: 2499.6027850398636
avg_episode_per_sec: 10.001488521242914
collect_time: 1.2998065210381757
reward_mean: 1263.5877501082964
reward_std: 522.922779502182
reward_max: 2080.8945773288488
reward_min: 306.79522795448
total_envstep_count: 1958048
total_train_sample_count: 1534762
total_episode_count: 9320
total_duration: 559.8918708909873
[2023-06-29 10:13:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3536
train_sample_count: 3536
avg_envstep_per_episode: 321.45454545454544
avg_sample_per_episode: 321.45454545454544
avg_envstep_per_sec: 2716.2431761818484
avg_train_sample_per_sec: 2716.2431761818484
avg_episode_per_sec: 8.44985150961548
collect_time: 1.3017980241999032
reward_mean: 1515.2883324812626
reward_std: 497.3505886879487
reward_max: 2343.104779308935
reward_min: 878.3498833552169
total_envstep_count: 1962984
total_train_sample_count: 1538298
total_episode_count: 9331
total_duration: 561.1936689151872
[2023-06-29 10:13:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2403
train_sample_count: 2403
avg_envstep_per_episode: 218.45454545454547
avg_sample_per_episode: 218.45454545454547
avg_envstep_per_sec: 2522.2411643240152
avg_train_sample_per_sec: 2522.2411643240152
avg_episode_per_sec: 11.545839703522335
collect_time: 0.9527241224944589
reward_mean: 1195.6903829163577
reward_std: 247.17633284630915
reward_max: 1585.1325554794867
reward_min: 838.2007391901021
total_envstep_count: 1967528
total_train_sample_count: 1541501
total_episode_count: 9342
total_duration: 562.1463930376817
[2023-06-29 10:13:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1449
train_sample_count: 1449
avg_envstep_per_episode: 289.8
avg_sample_per_episode: 289.8
avg_envstep_per_sec: 2341.8023249697803
avg_train_sample_per_sec: 2341.8023249697803
avg_episode_per_sec: 8.080753364284956
collect_time: 0.6187541896896437
reward_mean: 2183.188824192204
reward_std: 717.2911302852426
reward_max: 3319.8701820007036
reward_min: 1052.936720343376
total_envstep_count: 1972568
total_train_sample_count: 1544950
total_episode_count: 9347
total_duration: 562.7651472273714
[2023-06-29 10:13:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2489.990840718254
avg_train_sample_per_sec: 2489.990840718254
avg_episode_per_sec: 10.59570570518406
collect_time: 1.226912143628113
reward_mean: 1761.9710601361994
reward_std: 940.8369616292492
reward_max: 3344.6426268351174
reward_min: 276.5325905192985
total_envstep_count: 1977144
total_train_sample_count: 1548405
total_episode_count: 9360
total_duration: 563.9920593709995
[2023-06-29 10:13:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2545
train_sample_count: 2545
avg_envstep_per_episode: 318.125
avg_sample_per_episode: 318.125
avg_envstep_per_sec: 2594.2982434752444
avg_train_sample_per_sec: 2594.2982434752444
avg_episode_per_sec: 8.154965008959511
collect_time: 0.9809974648831409
reward_mean: 1874.4481178691613
reward_std: 784.2858457758451
reward_max: 3361.5242426376717
reward_min: 996.9482137580483
total_envstep_count: 1981688
total_train_sample_count: 1551750
total_episode_count: 9368
total_duration: 564.9730568358826
[2023-06-29 10:13:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1290
train_sample_count: 1290
avg_envstep_per_episode: 184.28571428571428
avg_sample_per_episode: 184.28571428571428
avg_envstep_per_sec: 2657.0172583319936
avg_train_sample_per_sec: 2657.0172583319936
avg_episode_per_sec: 14.417923107227871
collect_time: 0.48550682008359575
reward_mean: 1511.8596583169244
reward_std: 878.2782006628647
reward_max: 3251.6120640197996
reward_min: 298.48866848444
total_envstep_count: 1985920
total_train_sample_count: 1555040
total_episode_count: 9375
total_duration: 565.4585636559663
[2023-06-29 10:13:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1618
train_sample_count: 1618
avg_envstep_per_episode: 161.8
avg_sample_per_episode: 161.8
avg_envstep_per_sec: 2299.997933138326
avg_train_sample_per_sec: 2299.997933138326
avg_episode_per_sec: 14.215067571930321
collect_time: 0.7034788930406793
reward_mean: 1210.0305443599857
reward_std: 1148.3759476631708
reward_max: 3379.0492589930154
reward_min: 189.2562760747482
total_envstep_count: 1990264
total_train_sample_count: 1558258
total_episode_count: 9385
total_duration: 566.162042549007
[2023-06-29 10:13:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1310
train_sample_count: 1310
avg_envstep_per_episode: 218.33333333333334
avg_sample_per_episode: 218.33333333333334
avg_envstep_per_sec: 2659.378835968877
avg_train_sample_per_sec: 2659.378835968877
avg_episode_per_sec: 12.180361080773482
collect_time: 0.49259623423404997
reward_mean: 2358.8851225732305
reward_std: 1189.0138399576167
reward_max: 3398.9283558016364
reward_min: 311.93273264668466
total_envstep_count: 1993920
total_train_sample_count: 1561568
total_episode_count: 9391
total_duration: 566.654638783241
[2023-06-29 10:13:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 127.42857142857143
avg_sample_per_episode: 127.42857142857143
avg_envstep_per_sec: 2658.5143275908804
avg_train_sample_per_sec: 2658.5143275908804
avg_episode_per_sec: 20.86278059768628
collect_time: 0.3355257448652991
reward_mean: 1540.092927997222
reward_std: 1094.6301970358556
reward_max: 3384.1545511029326
reward_min: 262.39181933082193
total_envstep_count: 1998208
total_train_sample_count: 1564860
total_episode_count: 9398
total_duration: 566.9901645281063
[2023-06-29 10:13:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1254
train_sample_count: 1254
avg_envstep_per_episode: 250.8
avg_sample_per_episode: 250.8
avg_envstep_per_sec: 2728.442497926179
avg_train_sample_per_sec: 2728.442497926179
avg_episode_per_sec: 10.878957328254302
collect_time: 0.4596028690189125
reward_mean: 3264.7430973166643
reward_std: 274.5729039548761
reward_max: 3433.905865948002
reward_min: 2718.068236166451
total_envstep_count: 2002008
total_train_sample_count: 1568114
total_episode_count: 9403
total_duration: 567.4497673971252
[2023-06-29 10:13:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1884
train_sample_count: 1884
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 2553.2842639704345
avg_train_sample_per_sec: 2553.2842639704345
avg_episode_per_sec: 10.841971396902057
collect_time: 0.7378731881072744
reward_mean: 2034.3357507133423
reward_std: 1078.294440743971
reward_max: 3385.2839012219097
reward_min: 295.20148886701355
total_envstep_count: 2007280
total_train_sample_count: 1571598
total_episode_count: 9411
total_duration: 568.1876405852325
[2023-06-29 10:13:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2528
train_sample_count: 2528
avg_envstep_per_episode: 361.14285714285717
avg_sample_per_episode: 361.14285714285717
avg_envstep_per_sec: 2548.1703867778137
avg_train_sample_per_sec: 2548.1703867778137
avg_episode_per_sec: 7.055851545666414
collect_time: 0.9920843649692832
reward_mean: 2881.6129753262426
reward_std: 433.69485266209006
reward_max: 3338.260303290603
reward_min: 2291.139287597716
total_envstep_count: 2012200
total_train_sample_count: 1574926
total_episode_count: 9418
total_duration: 569.1797249502018
[2023-06-29 10:13:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1517
train_sample_count: 1517
avg_envstep_per_episode: 252.83333333333334
avg_sample_per_episode: 252.83333333333334
avg_envstep_per_sec: 2735.7066469908696
avg_train_sample_per_sec: 2735.7066469908696
avg_episode_per_sec: 10.820197680913129
collect_time: 0.5545185196185485
reward_mean: 1936.3336025499866
reward_std: 1134.6960000684292
reward_max: 3480.841476678525
reward_min: 212.72029171883037
total_envstep_count: 2016704
total_train_sample_count: 1578443
total_episode_count: 9424
total_duration: 569.7342434698204
[2023-06-29 10:14:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 290.2857142857143
avg_sample_per_episode: 290.2857142857143
avg_envstep_per_sec: 2703.7613602332954
avg_train_sample_per_sec: 2703.7613602332954
avg_episode_per_sec: 9.314138544110762
collect_time: 0.7515456171119583
reward_mean: 2598.8441088509703
reward_std: 848.9598065385742
reward_max: 3442.6606645897923
reward_min: 1291.9852584549033
total_envstep_count: 2020968
total_train_sample_count: 1581675
total_episode_count: 9431
total_duration: 570.4857890869324
[2023-06-29 10:14:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2810
train_sample_count: 2810
avg_envstep_per_episode: 255.45454545454547
avg_sample_per_episode: 255.45454545454547
avg_envstep_per_sec: 2527.1002564909845
avg_train_sample_per_sec: 2527.1002564909845
avg_episode_per_sec: 9.892563281637306
collect_time: 1.111946387082338
reward_mean: 1599.440834236687
reward_std: 1171.7528739635036
reward_max: 3371.19999507692
reward_min: 274.9645642817305
total_envstep_count: 2025240
total_train_sample_count: 1584885
total_episode_count: 9442
total_duration: 571.5977354740147
[2023-06-29 10:14:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2898
train_sample_count: 2898
avg_envstep_per_episode: 289.8
avg_sample_per_episode: 289.8
avg_envstep_per_sec: 2488.6554733770963
avg_train_sample_per_sec: 2488.6554733770963
avg_episode_per_sec: 8.58749300682228
collect_time: 1.164484208843671
reward_mean: 1476.0387935617478
reward_std: 845.6181910107956
reward_max: 2862.7698230139376
reward_min: 304.3335272916308
total_envstep_count: 2029272
total_train_sample_count: 1588183
total_episode_count: 9452
total_duration: 572.7622196828584
[2023-06-29 10:14:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1369
train_sample_count: 1369
avg_envstep_per_episode: 171.125
avg_sample_per_episode: 171.125
avg_envstep_per_sec: 2570.9048230757608
avg_train_sample_per_sec: 2570.9048230757608
avg_episode_per_sec: 15.023549002634104
collect_time: 0.532497347903438
reward_mean: 1034.5089712107656
reward_std: 621.3694181715238
reward_max: 2296.8707548925854
reward_min: 302.98365603978806
total_envstep_count: 2033416
total_train_sample_count: 1591552
total_episode_count: 9460
total_duration: 573.2947170307618
[2023-06-29 10:14:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2064
train_sample_count: 2064
avg_envstep_per_episode: 344.0
avg_sample_per_episode: 344.0
avg_envstep_per_sec: 2641.5457576470767
avg_train_sample_per_sec: 2641.5457576470767
avg_episode_per_sec: 7.678912086183363
collect_time: 0.7813606839952989
reward_mean: 2758.9608028946473
reward_std: 874.5511242174908
reward_max: 3429.655354248519
reward_min: 937.1375359154694
total_envstep_count: 2037344
total_train_sample_count: 1594816
total_episode_count: 9466
total_duration: 574.0760777147572
[2023-06-29 10:14:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2445
train_sample_count: 2445
avg_envstep_per_episode: 222.27272727272728
avg_sample_per_episode: 222.27272727272728
avg_envstep_per_sec: 2743.2644467955397
avg_train_sample_per_sec: 2743.2644467955397
avg_episode_per_sec: 12.34188503670795
collect_time: 0.8912738991882652
reward_mean: 1309.3620548408078
reward_std: 899.4744943352048
reward_max: 3389.763506639526
reward_min: 249.56623312214018
total_envstep_count: 2041264
total_train_sample_count: 1598061
total_episode_count: 9477
total_duration: 574.9673516139454
[2023-06-29 10:14:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2334
train_sample_count: 2334
avg_envstep_per_episode: 259.3333333333333
avg_sample_per_episode: 259.3333333333333
avg_envstep_per_sec: 2693.2436076393346
avg_train_sample_per_sec: 2693.2436076393346
avg_episode_per_sec: 10.385258127143963
collect_time: 0.8666130287582056
reward_mean: 1260.3048244513845
reward_std: 971.1851561482893
reward_max: 3314.6062386647545
reward_min: 244.8406067134392
total_envstep_count: 2045480
total_train_sample_count: 1601595
total_episode_count: 9486
total_duration: 575.8339646427037
[2023-06-29 10:14:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2972
train_sample_count: 2972
avg_envstep_per_episode: 247.66666666666666
avg_sample_per_episode: 247.66666666666666
avg_envstep_per_sec: 2717.987874085683
avg_train_sample_per_sec: 2717.987874085683
avg_episode_per_sec: 10.974379033993335
collect_time: 1.0934559452366084
reward_mean: 1469.7579483712227
reward_std: 842.6355033607662
reward_max: 3341.5322386958414
reward_min: 273.2967759375533
total_envstep_count: 2050016
total_train_sample_count: 1604967
total_episode_count: 9498
total_duration: 576.9274205879403
[2023-06-29 10:14:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 202.9
avg_sample_per_episode: 202.9
avg_envstep_per_sec: 2378.1135035876005
avg_train_sample_per_sec: 2378.1135035876005
avg_episode_per_sec: 11.720618548977823
collect_time: 0.8531972914409127
reward_mean: 1232.078704006087
reward_std: 408.9974297954958
reward_max: 1964.6378136051678
reward_min: 289.43472429932854
total_envstep_count: 2054376
total_train_sample_count: 1608196
total_episode_count: 9508
total_duration: 577.7806178793812
[2023-06-29 10:14:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3146
train_sample_count: 3146
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2684.9282448202543
avg_train_sample_per_sec: 2684.9282448202543
avg_episode_per_sec: 11.094744813306837
collect_time: 1.1717259133718907
reward_mean: 1450.9254866627696
reward_std: 406.5888819695772
reward_max: 2199.133129984788
reward_min: 890.2919562699714
total_envstep_count: 2059072
total_train_sample_count: 1611742
total_episode_count: 9521
total_duration: 578.9523437927531
[2023-06-29 10:14:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2067
train_sample_count: 2067
avg_envstep_per_episode: 295.2857142857143
avg_sample_per_episode: 295.2857142857143
avg_envstep_per_sec: 2693.0362362996366
avg_train_sample_per_sec: 2693.0362362996366
avg_episode_per_sec: 9.12010336434323
collect_time: 0.767535160551779
reward_mean: 1802.8230533772964
reward_std: 450.63859363140784
reward_max: 2400.1904647928104
reward_min: 997.824108071895
total_envstep_count: 2062824
total_train_sample_count: 1615009
total_episode_count: 9528
total_duration: 579.7198789533049
[2023-06-29 10:14:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2092
train_sample_count: 2092
avg_envstep_per_episode: 298.85714285714283
avg_sample_per_episode: 298.85714285714283
avg_envstep_per_sec: 2660.4166042074544
avg_train_sample_per_sec: 2660.4166042074544
avg_episode_per_sec: 8.90196760490066
collect_time: 0.7863430098472163
reward_mean: 1895.0688228525808
reward_std: 754.0798286503131
reward_max: 3233.859482600919
reward_min: 756.1340833337574
total_envstep_count: 2066720
total_train_sample_count: 1618301
total_episode_count: 9535
total_duration: 580.5062219631521
[2023-06-29 10:14:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3032
train_sample_count: 3032
avg_envstep_per_episode: 275.6363636363636
avg_sample_per_episode: 275.6363636363636
avg_envstep_per_sec: 2579.7196691182235
avg_train_sample_per_sec: 2579.7196691182235
avg_episode_per_sec: 9.359141279782474
collect_time: 1.1753215034548194
reward_mean: 1583.602595471348
reward_std: 481.09008763842974
reward_max: 2440.2145723636518
reward_min: 869.560293761332
total_envstep_count: 2071224
total_train_sample_count: 1621733
total_episode_count: 9546
total_duration: 581.681543466607
[2023-06-29 10:14:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2543
train_sample_count: 2543
avg_envstep_per_episode: 231.1818181818182
avg_sample_per_episode: 231.1818181818182
avg_envstep_per_sec: 2605.2386546458292
avg_train_sample_per_sec: 2605.2386546458292
avg_episode_per_sec: 11.2692195049564
collect_time: 0.9761101906979457
reward_mean: 1211.6030345447687
reward_std: 248.90846291850337
reward_max: 1709.9381823842236
reward_min: 951.4781639332971
total_envstep_count: 2075760
total_train_sample_count: 1625076
total_episode_count: 9557
total_duration: 582.6576536573049
[2023-06-29 10:14:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3089
train_sample_count: 3089
avg_envstep_per_episode: 257.4166666666667
avg_sample_per_episode: 257.4166666666667
avg_envstep_per_sec: 2479.3634474225228
avg_train_sample_per_sec: 2479.3634474225228
avg_episode_per_sec: 9.631712971534565
collect_time: 1.2458843027678086
reward_mean: 1512.6682193272281
reward_std: 644.0534296010312
reward_max: 3117.9635226477644
reward_min: 847.9190003231926
total_envstep_count: 2080288
total_train_sample_count: 1628565
total_episode_count: 9569
total_duration: 583.9035379600726
[2023-06-29 10:14:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2187
train_sample_count: 2187
avg_envstep_per_episode: 312.42857142857144
avg_sample_per_episode: 312.42857142857144
avg_envstep_per_sec: 2586.3071525772684
avg_train_sample_per_sec: 2586.3071525772684
avg_episode_per_sec: 8.27807501968033
collect_time: 0.8456072194753215
reward_mean: 1568.7093359993266
reward_std: 594.5131383456063
reward_max: 2465.242439457963
reward_min: 939.9415735344207
total_envstep_count: 2085400
total_train_sample_count: 1631952
total_episode_count: 9576
total_duration: 584.749145179548
[2023-06-29 10:14:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 205.9
avg_sample_per_episode: 205.9
avg_envstep_per_sec: 2468.7462898015438
avg_train_sample_per_sec: 2468.7462898015438
avg_episode_per_sec: 11.990025691119689
collect_time: 0.8340265698852019
reward_mean: 1835.428092003024
reward_std: 1009.2516685698985
reward_max: 3400.220883774754
reward_min: 310.59339716927377
total_envstep_count: 2089272
total_train_sample_count: 1635211
total_episode_count: 9586
total_duration: 585.5831717494332
[2023-06-29 10:14:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2412
train_sample_count: 2412
avg_envstep_per_episode: 301.5
avg_sample_per_episode: 301.5
avg_envstep_per_sec: 2439.1609184823874
avg_train_sample_per_sec: 2439.1609184823874
avg_episode_per_sec: 8.090085965115714
collect_time: 0.9888646467411889
reward_mean: 1579.525901445517
reward_std: 847.2258466462415
reward_max: 3107.7784735764144
reward_min: 765.2745399221386
total_envstep_count: 2093256
total_train_sample_count: 1638423
total_episode_count: 9594
total_duration: 586.5720363961743
[2023-06-29 10:14:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1716
train_sample_count: 1716
avg_envstep_per_episode: 245.14285714285714
avg_sample_per_episode: 245.14285714285714
avg_envstep_per_sec: 2719.279392029268
avg_train_sample_per_sec: 2719.279392029268
avg_episode_per_sec: 11.092631552566944
collect_time: 0.63104953651689
reward_mean: 1848.0570649502454
reward_std: 1035.6922955292835
reward_max: 3465.098128130624
reward_min: 774.3838569215873
total_envstep_count: 2097272
total_train_sample_count: 1641739
total_episode_count: 9601
total_duration: 587.2030859326912
[2023-06-29 10:14:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 230.57142857142858
avg_sample_per_episode: 230.57142857142858
avg_envstep_per_sec: 2533.8739534373713
avg_train_sample_per_sec: 2533.8739534373713
avg_episode_per_sec: 10.989540070670134
collect_time: 1.2739386644000188
reward_mean: 1363.6148298158403
reward_std: 770.4064902493878
reward_max: 3287.862394221842
reward_min: 288.9400788730995
total_envstep_count: 2101664
total_train_sample_count: 1644967
total_episode_count: 9615
total_duration: 588.4770245970913
[2023-06-29 10:15:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2018
train_sample_count: 2018
avg_envstep_per_episode: 224.22222222222223
avg_sample_per_episode: 224.22222222222223
avg_envstep_per_sec: 2476.518814972681
avg_train_sample_per_sec: 2476.518814972681
avg_episode_per_sec: 11.044930294724542
collect_time: 0.8148534902296961
reward_mean: 1022.2707448363822
reward_std: 623.9195270367281
reward_max: 2513.4426859343307
reward_min: 270.7048947023635
total_envstep_count: 2106024
total_train_sample_count: 1648185
total_episode_count: 9624
total_duration: 589.2918780873209
[2023-06-29 10:15:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2922
train_sample_count: 2922
avg_envstep_per_episode: 324.6666666666667
avg_sample_per_episode: 324.6666666666667
avg_envstep_per_sec: 2505.2092354033125
avg_train_sample_per_sec: 2505.2092354033125
avg_episode_per_sec: 7.716250211714515
collect_time: 1.166369642386213
reward_mean: 2178.482366070715
reward_std: 862.0587017883332
reward_max: 3424.6909569096624
reward_min: 770.6852226375998
total_envstep_count: 2110816
total_train_sample_count: 1651507
total_episode_count: 9633
total_duration: 590.4582477297072
[2023-06-29 10:15:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2811
train_sample_count: 2811
avg_envstep_per_episode: 351.375
avg_sample_per_episode: 351.375
avg_envstep_per_sec: 2659.0874518222877
avg_train_sample_per_sec: 2659.0874518222877
avg_episode_per_sec: 7.5676626163565635
collect_time: 1.0571295795757323
reward_mean: 1935.4466834018117
reward_std: 802.1561442877303
reward_max: 3184.736129921651
reward_min: 1007.8341177103862
total_envstep_count: 2116024
total_train_sample_count: 1654718
total_episode_count: 9641
total_duration: 591.5153773092829
[2023-06-29 10:15:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 309.875
avg_sample_per_episode: 309.875
avg_envstep_per_sec: 2714.312960740709
avg_train_sample_per_sec: 2714.312960740709
avg_episode_per_sec: 8.759380268626733
collect_time: 0.9133066215487199
reward_mean: 1909.6717685787128
reward_std: 721.8885047661635
reward_max: 2950.942894023022
reward_min: 939.2088115906464
total_envstep_count: 2119904
total_train_sample_count: 1657997
total_episode_count: 9649
total_duration: 592.4286839308317
[2023-06-29 10:15:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 242.6
avg_sample_per_episode: 242.6
avg_envstep_per_sec: 2408.996062158065
avg_train_sample_per_sec: 2408.996062158065
avg_episode_per_sec: 9.929909571962344
collect_time: 1.0070585162462666
reward_mean: 1422.9747602579923
reward_std: 795.9049768804298
reward_max: 3253.264300647558
reward_min: 674.5644579174243
total_envstep_count: 2124384
total_train_sample_count: 1661223
total_episode_count: 9659
total_duration: 593.4357424470779
[2023-06-29 10:15:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2520
train_sample_count: 2520
avg_envstep_per_episode: 360.0
avg_sample_per_episode: 360.0
avg_envstep_per_sec: 2690.6404623396847
avg_train_sample_per_sec: 2690.6404623396847
avg_episode_per_sec: 7.474001284276903
collect_time: 0.9365799835659566
reward_mean: 1888.9510434979134
reward_std: 688.0913198646961
reward_max: 3311.6391884845493
reward_min: 1036.0471048822158
total_envstep_count: 2128824
total_train_sample_count: 1664543
total_episode_count: 9666
total_duration: 594.3723224306439
[2023-06-29 10:15:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2833
train_sample_count: 2833
avg_envstep_per_episode: 202.35714285714286
avg_sample_per_episode: 202.35714285714286
avg_envstep_per_sec: 2672.7991830546193
avg_train_sample_per_sec: 2672.7991830546193
avg_episode_per_sec: 13.20832635466455
collect_time: 1.0599374685389924
reward_mean: 1298.2781676382654
reward_std: 871.6482418251863
reward_max: 3157.9282945851623
reward_min: 279.95803964192794
total_envstep_count: 2133064
total_train_sample_count: 1667776
total_episode_count: 9680
total_duration: 595.4322598991829
[2023-06-29 10:15:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2061
train_sample_count: 2061
avg_envstep_per_episode: 257.625
avg_sample_per_episode: 257.625
avg_envstep_per_sec: 2564.6835646270238
avg_train_sample_per_sec: 2564.6835646270238
avg_episode_per_sec: 9.955103598746332
collect_time: 0.8036079103192314
reward_mean: 1463.9546726264775
reward_std: 759.5888752374628
reward_max: 2545.9256092781766
reward_min: 227.52652284150219
total_envstep_count: 2137184
total_train_sample_count: 1671037
total_episode_count: 9688
total_duration: 596.2358678095021
[2023-06-29 10:15:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3047
train_sample_count: 3047
avg_envstep_per_episode: 277.0
avg_sample_per_episode: 277.0
avg_envstep_per_sec: 2546.4925403188395
avg_train_sample_per_sec: 2546.4925403188395
avg_episode_per_sec: 9.193113863966929
collect_time: 1.1965477816080676
reward_mean: 1551.8485661776563
reward_std: 896.0658354492716
reward_max: 3496.486310429886
reward_min: 304.4889351804393
total_envstep_count: 2141312
total_train_sample_count: 1674484
total_episode_count: 9699
total_duration: 597.4324155911102
[2023-06-29 10:15:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2668
train_sample_count: 2668
avg_envstep_per_episode: 333.5
avg_sample_per_episode: 333.5
avg_envstep_per_sec: 2486.178082946006
avg_train_sample_per_sec: 2486.178082946006
avg_episode_per_sec: 7.45480684541531
collect_time: 1.073133102693329
reward_mean: 1473.3848153931074
reward_std: 581.4085275570097
reward_max: 2849.6384370332958
reward_min: 888.6713494822263
total_envstep_count: 2145359
total_train_sample_count: 1677952
total_episode_count: 9707
total_duration: 598.5055486938035
[2023-06-29 10:15:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3271
train_sample_count: 3271
avg_envstep_per_episode: 327.1
avg_sample_per_episode: 327.1
avg_envstep_per_sec: 2675.1107546563303
avg_train_sample_per_sec: 2675.1107546563303
avg_episode_per_sec: 8.178265835085082
collect_time: 1.2227531119249764
reward_mean: 1670.31033930772
reward_std: 1005.6877008406079
reward_max: 3319.2532580812467
reward_min: 74.54564732835203
total_envstep_count: 2149975
total_train_sample_count: 1681223
total_episode_count: 9717
total_duration: 599.7283018057284
[2023-06-29 10:15:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3004
train_sample_count: 3004
avg_envstep_per_episode: 250.33333333333334
avg_sample_per_episode: 250.33333333333334
avg_envstep_per_sec: 2527.8039946364297
avg_train_sample_per_sec: 2527.8039946364297
avg_episode_per_sec: 10.097752308800652
collect_time: 1.188383279073052
reward_mean: 1249.0477178910312
reward_std: 321.5690121174839
reward_max: 2041.1813132197883
reward_min: 706.8338555091887
total_envstep_count: 2154351
total_train_sample_count: 1684627
total_episode_count: 9729
total_duration: 600.9166850848014
[2023-06-29 10:15:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1786
train_sample_count: 1786
avg_envstep_per_episode: 178.6
avg_sample_per_episode: 178.6
avg_envstep_per_sec: 2353.3972013430825
avg_train_sample_per_sec: 2353.3972013430825
avg_episode_per_sec: 13.176916020957908
collect_time: 0.7589029165925458
reward_mean: 998.4346976555629
reward_std: 433.0555254007918
reward_max: 2038.702372404582
reward_min: 581.0999107270196
total_envstep_count: 2158343
total_train_sample_count: 1688013
total_episode_count: 9739
total_duration: 601.675588001394
[2023-06-29 10:15:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3077
train_sample_count: 3077
avg_envstep_per_episode: 236.69230769230768
avg_sample_per_episode: 236.69230769230768
avg_envstep_per_sec: 2519.0249329227636
avg_train_sample_per_sec: 2519.0249329227636
avg_episode_per_sec: 10.64261427624177
collect_time: 1.221504384408705
reward_mean: 1441.60143148638
reward_std: 725.2179404071068
reward_max: 2580.150487459117
reward_min: 312.3732788103847
total_envstep_count: 2162887
total_train_sample_count: 1691490
total_episode_count: 9752
total_duration: 602.8970923858027
[2023-06-29 10:15:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2866
train_sample_count: 2866
avg_envstep_per_episode: 260.54545454545456
avg_sample_per_episode: 260.54545454545456
avg_envstep_per_sec: 2460.0919574275986
avg_train_sample_per_sec: 2460.0919574275986
avg_episode_per_sec: 9.44208357700753
collect_time: 1.1649971015704796
reward_mean: 1324.7257828982958
reward_std: 367.73016172275
reward_max: 1921.8021659265
reward_min: 631.4632215955177
total_envstep_count: 2167535
total_train_sample_count: 1694756
total_episode_count: 9763
total_duration: 604.0620894873732
[2023-06-29 10:15:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2424
train_sample_count: 2424
avg_envstep_per_episode: 220.36363636363637
avg_sample_per_episode: 220.36363636363637
avg_envstep_per_sec: 2664.357125733903
avg_train_sample_per_sec: 2664.357125733903
avg_episode_per_sec: 12.090729530970684
collect_time: 0.909787947189063
reward_mean: 1301.3961517363266
reward_std: 686.3693101066071
reward_max: 3270.432087076729
reward_min: 471.3322490965192
total_envstep_count: 2171511
total_train_sample_count: 1697980
total_episode_count: 9774
total_duration: 604.9718774345623
[2023-06-29 10:15:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2862
train_sample_count: 2862
avg_envstep_per_episode: 318.0
avg_sample_per_episode: 318.0
avg_envstep_per_sec: 2522.8264845419294
avg_train_sample_per_sec: 2522.8264845419294
avg_episode_per_sec: 7.933416618056382
collect_time: 1.1344418720575047
reward_mean: 1691.457042904043
reward_std: 789.8554400292986
reward_max: 3104.1385015444735
reward_min: 759.4591995276178
total_envstep_count: 2175591
total_train_sample_count: 1701242
total_episode_count: 9783
total_duration: 606.1063193066199
[2023-06-29 10:15:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 247.4
avg_sample_per_episode: 247.4
avg_envstep_per_sec: 2483.507551374019
avg_train_sample_per_sec: 2483.507551374019
avg_episode_per_sec: 10.038429876208646
collect_time: 0.9961717243948951
reward_mean: 1135.6980546399886
reward_std: 240.23060083959803
reward_max: 1421.7059751718605
reward_min: 601.6697633738584
total_envstep_count: 2179871
total_train_sample_count: 1704516
total_episode_count: 9793
total_duration: 607.1024910310148
[2023-06-29 10:15:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3486
train_sample_count: 3486
avg_envstep_per_episode: 232.4
avg_sample_per_episode: 232.4
avg_envstep_per_sec: 2674.0404700140716
avg_train_sample_per_sec: 2674.0404700140716
avg_episode_per_sec: 11.506198235860893
collect_time: 1.3036451912717895
reward_mean: 1326.2758431655477
reward_std: 671.9344389742585
reward_max: 3468.8461716634865
reward_min: 804.7302738034393
total_envstep_count: 2184695
total_train_sample_count: 1708002
total_episode_count: 9808
total_duration: 608.4061362222866
[2023-06-29 10:16:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2013
train_sample_count: 2013
avg_envstep_per_episode: 183.0
avg_sample_per_episode: 183.0
avg_envstep_per_sec: 2478.967177812222
avg_train_sample_per_sec: 2478.967177812222
avg_episode_per_sec: 13.546268731214328
collect_time: 0.8120317275747657
reward_mean: 970.585775502976
reward_std: 350.78544724215675
reward_max: 1329.6877209052493
reward_min: 278.5578735075035
total_envstep_count: 2188295
total_train_sample_count: 1711215
total_episode_count: 9819
total_duration: 609.2181679498614
[2023-06-29 10:16:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3349
train_sample_count: 3349
avg_envstep_per_episode: 239.21428571428572
avg_sample_per_episode: 239.21428571428572
avg_envstep_per_sec: 2567.098836890249
avg_train_sample_per_sec: 2567.098836890249
avg_episode_per_sec: 10.731377640030901
collect_time: 1.3045855312906207
reward_mean: 1206.699008416869
reward_std: 557.3771546537772
reward_max: 2365.541702395268
reward_min: 253.8113879061892
total_envstep_count: 2192759
total_train_sample_count: 1714564
total_episode_count: 9833
total_duration: 610.522753481152
[2023-06-29 10:16:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2540.5956105270643
avg_train_sample_per_sec: 2540.5956105270643
avg_episode_per_sec: 9.479834367638299
collect_time: 1.2658449013587088
reward_mean: 1232.5248478601156
reward_std: 520.7079025723327
reward_max: 2498.2199713307587
reward_min: 629.371330797127
total_envstep_count: 2197271
total_train_sample_count: 1717780
total_episode_count: 9845
total_duration: 611.7885983825107
[2023-06-29 10:16:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1684
train_sample_count: 1684
avg_envstep_per_episode: 168.4
avg_sample_per_episode: 168.4
avg_envstep_per_sec: 2697.877147936197
avg_train_sample_per_sec: 2697.877147936197
avg_episode_per_sec: 16.02064814688953
collect_time: 0.6241944713043047
reward_mean: 988.2049214626919
reward_std: 215.2754663223175
reward_max: 1299.3369319461262
reward_min: 577.7495263789539
total_envstep_count: 2201743
total_train_sample_count: 1721064
total_episode_count: 9855
total_duration: 612.4127928538151
[2023-06-29 10:16:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2802
train_sample_count: 2802
avg_envstep_per_episode: 215.53846153846155
avg_sample_per_episode: 215.53846153846155
avg_envstep_per_sec: 2501.7372873893023
avg_train_sample_per_sec: 2501.7372873893023
avg_episode_per_sec: 11.606918178465714
collect_time: 1.1200216801837086
reward_mean: 1442.7316248230431
reward_std: 329.3668614160808
reward_max: 1985.8658883302398
reward_min: 890.1367068202757
total_envstep_count: 2206287
total_train_sample_count: 1724266
total_episode_count: 9868
total_duration: 613.5328145339988
[2023-06-29 10:16:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2518
train_sample_count: 2518
avg_envstep_per_episode: 314.75
avg_sample_per_episode: 314.75
avg_envstep_per_sec: 2604.9060981537677
avg_train_sample_per_sec: 2604.9060981537677
avg_episode_per_sec: 8.276111511211335
collect_time: 0.9666375313047321
reward_mean: 1848.8314189339815
reward_std: 623.4140736842495
reward_max: 2695.5183505462846
reward_min: 956.2272346460612
total_envstep_count: 2210647
total_train_sample_count: 1727584
total_episode_count: 9876
total_duration: 614.4994520653036
[2023-06-29 10:16:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3412
train_sample_count: 3412
avg_envstep_per_episode: 262.46153846153845
avg_sample_per_episode: 262.46153846153845
avg_envstep_per_sec: 2641.8194043111353
avg_train_sample_per_sec: 2641.8194043111353
avg_episode_per_sec: 10.065548726859541
collect_time: 1.2915341580245878
reward_mean: 1413.3973138078622
reward_std: 668.912095222251
reward_max: 2782.789723388221
reward_min: 698.5117856954732
total_envstep_count: 2215039
total_train_sample_count: 1730996
total_episode_count: 9889
total_duration: 615.7909862233281
[2023-06-29 10:16:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2558
train_sample_count: 2558
avg_envstep_per_episode: 232.54545454545453
avg_sample_per_episode: 232.54545454545453
avg_envstep_per_sec: 2720.185580767641
avg_train_sample_per_sec: 2720.185580767641
avg_episode_per_sec: 11.697436039266636
collect_time: 0.9403770162174478
reward_mean: 1121.1176030068464
reward_std: 165.20505093859597
reward_max: 1479.6947581830996
reward_min: 867.7911186433862
total_envstep_count: 2219527
total_train_sample_count: 1734354
total_episode_count: 9900
total_duration: 616.7313632395455
[2023-06-29 10:16:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3004
train_sample_count: 3004
avg_envstep_per_episode: 200.26666666666668
avg_sample_per_episode: 200.26666666666668
avg_envstep_per_sec: 2519.743410752941
avg_train_sample_per_sec: 2519.743410752941
avg_episode_per_sec: 12.581941132255032
collect_time: 1.192184881675057
reward_mean: 1145.031810387649
reward_std: 436.74785619328753
reward_max: 1954.623056580725
reward_min: 266.826308668569
total_envstep_count: 2223799
total_train_sample_count: 1737758
total_episode_count: 9915
total_duration: 617.9235481212206
[2023-06-29 10:16:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3280
train_sample_count: 3280
avg_envstep_per_episode: 252.30769230769232
avg_sample_per_episode: 252.30769230769232
avg_envstep_per_sec: 2500.301136163324
avg_train_sample_per_sec: 2500.301136163324
avg_episode_per_sec: 9.90973011284244
collect_time: 1.311841982775368
reward_mean: 1210.8721496101355
reward_std: 306.8781012946534
reward_max: 2053.622268331303
reward_min: 847.9351805610905
total_envstep_count: 2228151
total_train_sample_count: 1741038
total_episode_count: 9928
total_duration: 619.235390103996
[2023-06-29 10:16:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2919
train_sample_count: 2919
avg_envstep_per_episode: 243.25
avg_sample_per_episode: 243.25
avg_envstep_per_sec: 2657.830343821298
avg_train_sample_per_sec: 2657.830343821298
avg_episode_per_sec: 10.926332348700093
collect_time: 1.0982642314946278
reward_mean: 1159.3919109360752
reward_std: 405.736929336967
reward_max: 1919.6449094939264
reward_min: 632.875410089394
total_envstep_count: 2232535
total_train_sample_count: 1744357
total_episode_count: 9940
total_duration: 620.3336543354907
[2023-06-29 10:16:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2813
train_sample_count: 2813
avg_envstep_per_episode: 216.3846153846154
avg_sample_per_episode: 216.3846153846154
avg_envstep_per_sec: 2709.919774335932
avg_train_sample_per_sec: 2709.919774335932
avg_episode_per_sec: 12.523624979156457
collect_time: 1.0380381097035716
reward_mean: 1140.822341068171
reward_std: 533.5051238978202
reward_max: 2192.2285751713416
reward_min: 292.8339513451951
total_envstep_count: 2237199
total_train_sample_count: 1747570
total_episode_count: 9953
total_duration: 621.3716924451943
[2023-06-29 10:16:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3282
train_sample_count: 3282
avg_envstep_per_episode: 234.42857142857142
avg_sample_per_episode: 234.42857142857142
avg_envstep_per_sec: 2535.35541688007
avg_train_sample_per_sec: 2535.35541688007
avg_episode_per_sec: 10.815044435198349
collect_time: 1.294493063240312
reward_mean: 1278.6871677727
reward_std: 702.464816249994
reward_max: 3490.6428017909716
reward_min: 695.6856108821228
total_envstep_count: 2241527
total_train_sample_count: 1750852
total_episode_count: 9967
total_duration: 622.6661855084346
[2023-06-29 10:16:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3328
train_sample_count: 3328
avg_envstep_per_episode: 221.86666666666667
avg_sample_per_episode: 221.86666666666667
avg_envstep_per_sec: 2403.1816705785773
avg_train_sample_per_sec: 2403.1816705785773
avg_episode_per_sec: 10.831648154651038
collect_time: 1.384830801908858
reward_mean: 1018.6969345077482
reward_std: 214.7001508971532
reward_max: 1588.3928165856382
reward_min: 808.8699042866866
total_envstep_count: 2245871
total_train_sample_count: 1754180
total_episode_count: 9982
total_duration: 624.0510163103435
[2023-06-29 10:16:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3134
train_sample_count: 3134
avg_envstep_per_episode: 208.93333333333334
avg_sample_per_episode: 208.93333333333334
avg_envstep_per_sec: 2505.351550027029
avg_train_sample_per_sec: 2505.351550027029
avg_episode_per_sec: 11.991152919720944
collect_time: 1.2509222507979723
reward_mean: 955.6964763494768
reward_std: 238.5188415066499
reward_max: 1585.2118445232156
reward_min: 692.9271312373454
total_envstep_count: 2250319
total_train_sample_count: 1757714
total_episode_count: 9997
total_duration: 625.3019385611415
[2023-06-29 10:16:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2862
train_sample_count: 2862
avg_envstep_per_episode: 204.42857142857142
avg_sample_per_episode: 204.42857142857142
avg_envstep_per_sec: 2661.6072524684228
avg_train_sample_per_sec: 2661.6072524684228
avg_episode_per_sec: 13.01974197573652
collect_time: 1.0752901268005373
reward_mean: 1042.5006325941201
reward_std: 238.29482454476286
reward_max: 1588.8859781527538
reward_min: 701.7751920132339
total_envstep_count: 2254471
total_train_sample_count: 1760976
total_episode_count: 10011
total_duration: 626.377228687942
[2023-06-29 10:16:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3365
train_sample_count: 3365
avg_envstep_per_episode: 210.3125
avg_sample_per_episode: 210.3125
avg_envstep_per_sec: 2543.1261251474352
avg_train_sample_per_sec: 2543.1261251474352
avg_episode_per_sec: 12.092130164148282
collect_time: 1.3231746419202537
reward_mean: 1010.0270732749736
reward_std: 249.97608366905567
reward_max: 1675.1630117857887
reward_min: 652.6674213224665
total_envstep_count: 2258583
total_train_sample_count: 1764341
total_episode_count: 10027
total_duration: 627.7004033298622
[2023-06-29 10:16:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2520.972324104825
avg_train_sample_per_sec: 2520.972324104825
avg_episode_per_sec: 10.727541804701383
collect_time: 1.2118340097544718
reward_mean: 1030.9305755791008
reward_std: 167.22077707444055
reward_max: 1351.4603516232944
reward_min: 690.203306650157
total_envstep_count: 2263255
total_train_sample_count: 1767796
total_episode_count: 10040
total_duration: 628.9122373396167
[2023-06-29 10:16:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3229
train_sample_count: 3229
avg_envstep_per_episode: 215.26666666666668
avg_sample_per_episode: 215.26666666666668
avg_envstep_per_sec: 2351.1294450550167
avg_train_sample_per_sec: 2351.1294450550167
avg_episode_per_sec: 10.921939199698127
collect_time: 1.3733824850823733
reward_mean: 1132.5197207465017
reward_std: 365.12904470942243
reward_max: 1908.2494323043322
reward_min: 579.3550622169668
total_envstep_count: 2267375
total_train_sample_count: 1771025
total_episode_count: 10055
total_duration: 630.2856198246991
[2023-06-29 10:16:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3454
train_sample_count: 3454
avg_envstep_per_episode: 246.71428571428572
avg_sample_per_episode: 246.71428571428572
avg_envstep_per_sec: 2702.8567850631716
avg_train_sample_per_sec: 2702.8567850631716
avg_episode_per_sec: 10.955412562502723
collect_time: 1.2779071459086844
reward_mean: 1088.175811912029
reward_std: 198.14838162682994
reward_max: 1449.8514191710065
reward_min: 726.4327275279179
total_envstep_count: 2271967
total_train_sample_count: 1774479
total_episode_count: 10069
total_duration: 631.5635269706078
[2023-06-29 10:17:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2950
train_sample_count: 2950
avg_envstep_per_episode: 245.83333333333334
avg_sample_per_episode: 245.83333333333334
avg_envstep_per_sec: 2531.022379671444
avg_train_sample_per_sec: 2531.022379671444
avg_episode_per_sec: 10.29568425629062
collect_time: 1.1655369086001302
reward_mean: 1203.8631181827081
reward_std: 395.3289103291751
reward_max: 2204.1664126073533
reward_min: 709.9906936179665
total_envstep_count: 2276471
total_train_sample_count: 1777829
total_episode_count: 10081
total_duration: 632.7290638792078
[2023-06-29 10:17:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 238.14285714285714
avg_sample_per_episode: 238.14285714285714
avg_envstep_per_sec: 2603.5310811105746
avg_train_sample_per_sec: 2603.5310811105746
avg_episode_per_sec: 10.932644011862042
collect_time: 1.280568541773595
reward_mean: 1230.3072145605624
reward_std: 380.6231235374972
reward_max: 2406.3126891783472
reward_min: 850.0420374509329
total_envstep_count: 2281343
total_train_sample_count: 1781163
total_episode_count: 10095
total_duration: 634.0096324209815
[2023-06-29 10:17:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2624.601460591948
avg_train_sample_per_sec: 2624.601460591948
avg_episode_per_sec: 9.75688275312992
collect_time: 0.9224257611492648
reward_mean: 1525.6978618574644
reward_std: 560.1763073111399
reward_max: 2413.5947732064037
reward_min: 860.688931734894
total_envstep_count: 2285615
total_train_sample_count: 1784384
total_episode_count: 10104
total_duration: 634.9320581821307
[2023-06-29 10:17:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 292.6363636363636
avg_sample_per_episode: 292.6363636363636
avg_envstep_per_sec: 2706.567457906186
avg_train_sample_per_sec: 2706.567457906186
avg_episode_per_sec: 9.248910232049719
collect_time: 1.1893293073471867
reward_mean: 1629.4478817674606
reward_std: 581.654473415632
reward_max: 3140.8750086221357
reward_min: 957.2863671727762
total_envstep_count: 2290535
total_train_sample_count: 1787603
total_episode_count: 10115
total_duration: 636.1213874894779
[2023-06-29 10:17:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2786
train_sample_count: 2786
avg_envstep_per_episode: 253.27272727272728
avg_sample_per_episode: 253.27272727272728
avg_envstep_per_sec: 2458.926421781097
avg_train_sample_per_sec: 2458.926421781097
avg_episode_per_sec: 9.70861114127497
collect_time: 1.13301478861738
reward_mean: 1406.333417300124
reward_std: 373.16420696936905
reward_max: 2080.6866271889517
reward_min: 860.4933999361101
total_envstep_count: 2295527
total_train_sample_count: 1791189
total_episode_count: 10126
total_duration: 637.2544022780953
[2023-06-29 10:17:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1236
train_sample_count: 1236
avg_envstep_per_episode: 176.57142857142858
avg_sample_per_episode: 176.57142857142858
avg_envstep_per_sec: 2649.0593548662646
avg_train_sample_per_sec: 2649.0593548662646
avg_episode_per_sec: 15.002763336621241
collect_time: 0.4665807120287791
reward_mean: 1602.828825532562
reward_std: 570.6483040820619
reward_max: 2801.900169129538
reward_min: 997.9774213452072
total_envstep_count: 2299383
total_train_sample_count: 1794425
total_episode_count: 10133
total_duration: 637.7209829901241
[2023-06-29 10:17:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1823
train_sample_count: 1823
avg_envstep_per_episode: 227.875
avg_sample_per_episode: 227.875
avg_envstep_per_sec: 2648.7207094231117
avg_train_sample_per_sec: 2648.7207094231117
avg_episode_per_sec: 11.623568664500764
collect_time: 0.6882567850640045
reward_mean: 2064.9120482440676
reward_std: 847.8934031507922
reward_max: 3452.8799471601938
reward_min: 1107.5269391435752
total_envstep_count: 2303663
total_train_sample_count: 1797848
total_episode_count: 10141
total_duration: 638.4092397751881
[2023-06-29 10:17:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 257.1818181818182
avg_sample_per_episode: 257.1818181818182
avg_envstep_per_sec: 2661.276387466213
avg_train_sample_per_sec: 2661.276387466213
avg_episode_per_sec: 10.347840318885947
collect_time: 1.0630237480495124
reward_mean: 1734.3462750527449
reward_std: 741.1526868344348
reward_max: 3501.4983129809843
reward_min: 820.9881025858022
total_envstep_count: 2308007
total_train_sample_count: 1801077
total_episode_count: 10152
total_duration: 639.4722635232376
[2023-06-29 10:17:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2682
train_sample_count: 2682
avg_envstep_per_episode: 298.0
avg_sample_per_episode: 298.0
avg_envstep_per_sec: 2565.4033862027723
avg_train_sample_per_sec: 2565.4033862027723
avg_episode_per_sec: 8.608736195311316
collect_time: 1.0454496218506246
reward_mean: 1478.0788479502244
reward_std: 870.5343238110391
reward_max: 3461.648132256041
reward_min: 239.02683810095823
total_envstep_count: 2312999
total_train_sample_count: 1804559
total_episode_count: 10161
total_duration: 640.5177131450882
[2023-06-29 10:17:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 222.55555555555554
avg_sample_per_episode: 222.55555555555554
avg_envstep_per_sec: 2443.0202273330183
avg_train_sample_per_sec: 2443.0202273330183
avg_episode_per_sec: 10.977125334996089
collect_time: 0.8198867850499229
reward_mean: 1661.5683473748254
reward_std: 941.6251287080393
reward_max: 3418.0186466128907
reward_min: 311.50934711264034
total_envstep_count: 2317023
total_train_sample_count: 1807762
total_episode_count: 10170
total_duration: 641.3375999301381
[2023-06-29 10:17:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 727
train_sample_count: 727
avg_envstep_per_episode: 145.4
avg_sample_per_episode: 145.4
avg_envstep_per_sec: 2657.2712516972033
avg_train_sample_per_sec: 2657.2712516972033
avg_episode_per_sec: 18.27559320286935
collect_time: 0.2735889305751771
reward_mean: 1777.6924516879815
reward_std: 828.1799971653884
reward_max: 3205.542863816706
reward_min: 738.7414038764076
total_envstep_count: 2321239
total_train_sample_count: 1811289
total_episode_count: 10175
total_duration: 641.6111888607134
[2023-06-29 10:17:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3059
train_sample_count: 3059
avg_envstep_per_episode: 254.91666666666666
avg_sample_per_episode: 254.91666666666666
avg_envstep_per_sec: 2659.493310033162
avg_train_sample_per_sec: 2659.493310033162
avg_episode_per_sec: 10.432794939652808
collect_time: 1.1502190994275736
reward_mean: 2092.135864509715
reward_std: 787.6651453721098
reward_max: 3560.586482192122
reward_min: 1052.3867925855584
total_envstep_count: 2326423
total_train_sample_count: 1814748
total_episode_count: 10187
total_duration: 642.7614079601409
[2023-06-29 10:17:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2818
train_sample_count: 2818
avg_envstep_per_episode: 281.8
avg_sample_per_episode: 281.8
avg_envstep_per_sec: 2474.864316982745
avg_train_sample_per_sec: 2474.864316982745
avg_episode_per_sec: 8.782343211436286
collect_time: 1.1386482809027656
reward_mean: 1746.1974052055295
reward_std: 456.334788318064
reward_max: 2570.8871954919446
reward_min: 1075.4183234518825
total_envstep_count: 2330959
total_train_sample_count: 1817966
total_episode_count: 10197
total_duration: 643.9000562410437
[2023-06-29 10:17:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3391
train_sample_count: 3391
avg_envstep_per_episode: 308.27272727272725
avg_sample_per_episode: 308.27272727272725
avg_envstep_per_sec: 2553.366680173834
avg_train_sample_per_sec: 2553.366680173834
avg_episode_per_sec: 8.2828173051938
collect_time: 1.3280505406176677
reward_mean: 1655.4169246716299
reward_std: 446.42221658701044
reward_max: 2565.6128495122002
reward_min: 1001.5584822381528
total_envstep_count: 2335743
total_train_sample_count: 1821357
total_episode_count: 10208
total_duration: 645.2281067816614
[2023-06-29 10:17:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 854
train_sample_count: 854
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 2091.563877455844
avg_train_sample_per_sec: 2091.563877455844
avg_episode_per_sec: 9.796552119231118
collect_time: 0.408306917711161
reward_mean: 1685.4204046622644
reward_std: 637.3234922137102
reward_max: 2723.7514088017065
reward_min: 1111.0614973814534
total_envstep_count: 2339823
total_train_sample_count: 1824611
total_episode_count: 10212
total_duration: 645.6364136993725
[2023-06-29 10:17:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2804
train_sample_count: 2804
avg_envstep_per_episode: 280.4
avg_sample_per_episode: 280.4
avg_envstep_per_sec: 2639.888328823157
avg_train_sample_per_sec: 2639.888328823157
avg_episode_per_sec: 9.414722998656051
collect_time: 1.0621661414178087
reward_mean: 2229.956592522097
reward_std: 919.6358321542824
reward_max: 3468.6311420436286
reward_min: 1063.578111150151
total_envstep_count: 2344167
total_train_sample_count: 1827815
total_episode_count: 10222
total_duration: 646.6985798407903
[2023-06-29 10:17:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3123
train_sample_count: 3123
avg_envstep_per_episode: 312.3
avg_sample_per_episode: 312.3
avg_envstep_per_sec: 2567.161205801911
avg_train_sample_per_sec: 2567.161205801911
avg_episode_per_sec: 8.220176771700002
collect_time: 1.2165188508387654
reward_mean: 1639.685101904724
reward_std: 609.2434610304535
reward_max: 2655.2497736127975
reward_min: 970.5926671901894
total_envstep_count: 2349383
total_train_sample_count: 1831338
total_episode_count: 10232
total_duration: 647.915098691629
[2023-06-29 10:17:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2892
train_sample_count: 2892
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2594.937548545249
avg_train_sample_per_sec: 2594.937548545249
avg_episode_per_sec: 10.767375720104766
collect_time: 1.1144776881514116
reward_mean: 1494.8617875801594
reward_std: 321.9290895461737
reward_max: 2392.1293210009517
reward_min: 1138.3225053510089
total_envstep_count: 2354383
total_train_sample_count: 1834630
total_episode_count: 10244
total_duration: 649.0295763797805
[2023-06-29 10:17:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2659
train_sample_count: 2659
avg_envstep_per_episode: 241.72727272727272
avg_sample_per_episode: 241.72727272727272
avg_envstep_per_sec: 2697.5729420633256
avg_train_sample_per_sec: 2697.5729420633256
avg_episode_per_sec: 11.159572155959602
collect_time: 0.9857008715271952
reward_mean: 1550.4610184375595
reward_std: 405.49054116846304
reward_max: 2559.7246520893027
reward_min: 1019.3537914623645
total_envstep_count: 2358775
total_train_sample_count: 1838089
total_episode_count: 10255
total_duration: 650.0152772513077
[2023-06-29 10:18:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2791
train_sample_count: 2791
avg_envstep_per_episode: 253.72727272727272
avg_sample_per_episode: 253.72727272727272
avg_envstep_per_sec: 2647.4765234212823
avg_train_sample_per_sec: 2647.4765234212823
avg_episode_per_sec: 10.434339576364781
collect_time: 1.0542114256005735
reward_mean: 1458.5610139661258
reward_std: 654.5458576235783
reward_max: 3384.765178042148
reward_min: 988.8957498108433
total_envstep_count: 2363751
total_train_sample_count: 1841680
total_episode_count: 10266
total_duration: 651.0694886769082
[2023-06-29 10:18:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 255.375
avg_sample_per_episode: 255.375
avg_envstep_per_sec: 2630.2314253338304
avg_train_sample_per_sec: 2630.2314253338304
avg_episode_per_sec: 10.29948673650056
collect_time: 0.7767377350609752
reward_mean: 1863.8905001518624
reward_std: 790.4358755416806
reward_max: 3501.585129322963
reward_min: 881.9065947328403
total_envstep_count: 2368175
total_train_sample_count: 1844923
total_episode_count: 10274
total_duration: 651.8462264119692
[2023-06-29 10:18:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2579
train_sample_count: 2579
avg_envstep_per_episode: 286.55555555555554
avg_sample_per_episode: 286.55555555555554
avg_envstep_per_sec: 2520.7680189885746
avg_train_sample_per_sec: 2520.7680189885746
avg_episode_per_sec: 8.796786417563851
collect_time: 1.0231008885279298
reward_mean: 1793.154231775172
reward_std: 689.8344429727184
reward_max: 3406.1731481643524
reward_min: 1049.4479099051362
total_envstep_count: 2372975
total_train_sample_count: 1848302
total_episode_count: 10283
total_duration: 652.869327300497
[2023-06-29 10:18:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 252.875
avg_sample_per_episode: 252.875
avg_envstep_per_sec: 2525.532259152854
avg_train_sample_per_sec: 2525.532259152854
avg_episode_per_sec: 9.987275369858047
collect_time: 0.8010192673914134
reward_mean: 1922.879220248205
reward_std: 850.5737743176477
reward_max: 3447.312304490567
reward_min: 875.6972252471495
total_envstep_count: 2377503
total_train_sample_count: 1851525
total_episode_count: 10291
total_duration: 653.6703465678885
[2023-06-29 10:18:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2279
train_sample_count: 2279
avg_envstep_per_episode: 227.9
avg_sample_per_episode: 227.9
avg_envstep_per_sec: 2435.7467609627233
avg_train_sample_per_sec: 2435.7467609627233
avg_episode_per_sec: 10.687787454860567
collect_time: 0.9356473491108044
reward_mean: 1688.9840694374664
reward_std: 483.6078708209489
reward_max: 2570.608665564086
reward_min: 994.1776928556361
total_envstep_count: 2382799
total_train_sample_count: 1855004
total_episode_count: 10301
total_duration: 654.6059939169993
[2023-06-29 10:18:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2956
train_sample_count: 2956
avg_envstep_per_episode: 295.6
avg_sample_per_episode: 295.6
avg_envstep_per_sec: 2619.075598325048
avg_train_sample_per_sec: 2619.075598325048
avg_episode_per_sec: 8.860201618149688
collect_time: 1.128642488170415
reward_mean: 1993.1912542499012
reward_std: 695.6703988439318
reward_max: 3078.5368072106776
reward_min: 897.1780102372742
total_envstep_count: 2387783
total_train_sample_count: 1858360
total_episode_count: 10311
total_duration: 655.7346364051697
[2023-06-29 10:18:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 178.2
avg_sample_per_episode: 178.2
avg_envstep_per_sec: 2681.3524618544875
avg_train_sample_per_sec: 2681.3524618544875
avg_episode_per_sec: 15.04687127864471
collect_time: 0.3322949939165264
reward_mean: 1931.8200639478605
reward_std: 860.4255026971136
reward_max: 3458.9135050798504
reward_min: 1217.6331338577852
total_envstep_count: 2392175
total_train_sample_count: 1861651
total_episode_count: 10316
total_duration: 656.0669313990862
[2023-06-29 10:18:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2590
train_sample_count: 2590
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2713.309476162277
avg_train_sample_per_sec: 2713.309476162277
avg_episode_per_sec: 10.476098363560915
collect_time: 0.9545538475262001
reward_mean: 2351.354024989777
reward_std: 978.0387999613298
reward_max: 3606.6070573855914
reward_min: 1035.5587506137267
total_envstep_count: 2396615
total_train_sample_count: 1865041
total_episode_count: 10326
total_duration: 657.0214852466124
[2023-06-29 10:18:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 171.25
avg_sample_per_episode: 171.25
avg_envstep_per_sec: 2072.729151907679
avg_train_sample_per_sec: 2072.729151907679
avg_episode_per_sec: 12.10352789435141
collect_time: 0.33048215651791557
reward_mean: 1625.8873152754888
reward_std: 396.7951237539274
reward_max: 2015.1776275917896
reward_min: 1079.8109697226535
total_envstep_count: 2401111
total_train_sample_count: 1868526
total_episode_count: 10330
total_duration: 657.3519674031303
[2023-06-29 10:18:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2150
train_sample_count: 2150
avg_envstep_per_episode: 238.88888888888889
avg_sample_per_episode: 238.88888888888889
avg_envstep_per_sec: 2641.5507479391
avg_train_sample_per_sec: 2641.5507479391
avg_episode_per_sec: 11.057654293698558
collect_time: 0.8139158415477723
reward_mean: 2557.523605905409
reward_std: 859.0094444439268
reward_max: 3451.3584501549813
reward_min: 866.0289334890799
total_envstep_count: 2405911
total_train_sample_count: 1871876
total_episode_count: 10339
total_duration: 658.1658832446781
[2023-06-29 10:18:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2149
train_sample_count: 2149
avg_envstep_per_episode: 238.77777777777777
avg_sample_per_episode: 238.77777777777777
avg_envstep_per_sec: 2656.7442802804544
avg_train_sample_per_sec: 2656.7442802804544
avg_episode_per_sec: 11.126430210574263
collect_time: 0.8088847752306612
reward_mean: 1811.7504589865114
reward_std: 844.0659753350825
reward_max: 3208.403328666593
reward_min: 995.1424046573618
total_envstep_count: 2410823
total_train_sample_count: 1875225
total_episode_count: 10348
total_duration: 658.9747680199088
[2023-06-29 10:18:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2201
train_sample_count: 2201
avg_envstep_per_episode: 314.42857142857144
avg_sample_per_episode: 314.42857142857144
avg_envstep_per_sec: 2671.279435934937
avg_train_sample_per_sec: 2671.279435934937
avg_episode_per_sec: 8.495663812605432
collect_time: 0.8239497412331402
reward_mean: 2061.3059286554876
reward_std: 881.6270712900963
reward_max: 3505.901346757294
reward_min: 992.5051728978792
total_envstep_count: 2415039
total_train_sample_count: 1878626
total_episode_count: 10355
total_duration: 659.7987177611419
[2023-06-29 10:18:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2314
train_sample_count: 2314
avg_envstep_per_episode: 289.25
avg_sample_per_episode: 289.25
avg_envstep_per_sec: 2524.2236785287414
avg_train_sample_per_sec: 2524.2236785287414
avg_episode_per_sec: 8.726788862674992
collect_time: 0.9167174920681864
reward_mean: 2055.4833783964564
reward_std: 878.6947940755746
reward_max: 3558.7400124176006
reward_min: 1068.677884128656
total_envstep_count: 2419207
total_train_sample_count: 1882140
total_episode_count: 10363
total_duration: 660.7154352532101
[2023-06-29 10:18:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 868
train_sample_count: 868
avg_envstep_per_episode: 173.6
avg_sample_per_episode: 173.6
avg_envstep_per_sec: 2656.9611600937556
avg_train_sample_per_sec: 2656.9611600937556
avg_episode_per_sec: 15.305075806991677
collect_time: 0.3266890058601275
reward_mean: 1990.5650112862277
reward_std: 991.3186280855338
reward_max: 3499.3222608007254
reward_min: 897.5344583393772
total_envstep_count: 2423967
total_train_sample_count: 1885408
total_episode_count: 10368
total_duration: 661.0421242590702
[2023-06-29 10:18:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2973
train_sample_count: 2973
avg_envstep_per_episode: 270.27272727272725
avg_sample_per_episode: 270.27272727272725
avg_envstep_per_sec: 2663.716668219539
avg_train_sample_per_sec: 2663.716668219539
avg_episode_per_sec: 9.855662075484336
collect_time: 1.1161096957009282
reward_mean: 2251.5163657313274
reward_std: 1058.0210986002114
reward_max: 3553.1634565793943
reward_min: 876.0957357875549
total_envstep_count: 2428663
total_train_sample_count: 1888781
total_episode_count: 10379
total_duration: 662.1582339547712
[2023-06-29 10:18:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1538
train_sample_count: 1538
avg_envstep_per_episode: 219.71428571428572
avg_sample_per_episode: 219.71428571428572
avg_envstep_per_sec: 2651.973413321524
avg_train_sample_per_sec: 2651.973413321524
avg_episode_per_sec: 12.070100060631123
collect_time: 0.5799454822111875
reward_mean: 1305.7153064646718
reward_std: 462.74583636781574
reward_max: 2323.524681404802
reward_min: 769.4693393624357
total_envstep_count: 2432935
total_train_sample_count: 1892319
total_episode_count: 10386
total_duration: 662.7381794369824
[2023-06-29 10:18:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1665
train_sample_count: 1665
avg_envstep_per_episode: 277.5
avg_sample_per_episode: 277.5
avg_envstep_per_sec: 2615.4433346522674
avg_train_sample_per_sec: 2615.4433346522674
avg_episode_per_sec: 9.425021025773937
collect_time: 0.636603354368359
reward_mean: 2615.235871028685
reward_std: 921.1947094632719
reward_max: 3502.2136465921326
reward_min: 1276.993295842933
total_envstep_count: 2437335
total_train_sample_count: 1895584
total_episode_count: 10392
total_duration: 663.3747827913508
[2023-06-29 10:18:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1653
train_sample_count: 1653
avg_envstep_per_episode: 236.14285714285714
avg_sample_per_episode: 236.14285714285714
avg_envstep_per_sec: 2709.3022871473477
avg_train_sample_per_sec: 2709.3022871473477
avg_episode_per_sec: 11.47314943135598
collect_time: 0.6101201803289587
reward_mean: 2158.4593434553753
reward_std: 946.0652325302094
reward_max: 3493.426615658951
reward_min: 988.8753195830667
total_envstep_count: 2441167
total_train_sample_count: 1898837
total_episode_count: 10399
total_duration: 663.9849029716797
[2023-06-29 10:18:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1795
train_sample_count: 1795
avg_envstep_per_episode: 224.375
avg_sample_per_episode: 224.375
avg_envstep_per_sec: 2698.7413098022353
avg_train_sample_per_sec: 2698.7413098022353
avg_episode_per_sec: 12.027816422516926
collect_time: 0.6651248837672175
reward_mean: 1654.4280519136237
reward_std: 1169.3818617069444
reward_max: 3410.9882639155426
reward_min: 305.62486801232717
total_envstep_count: 2445495
total_train_sample_count: 1902232
total_episode_count: 10407
total_duration: 664.650027855447
[2023-06-29 10:19:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1780
train_sample_count: 1780
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 2399.5502403240966
avg_train_sample_per_sec: 2399.5502403240966
avg_episode_per_sec: 13.480619327663463
collect_time: 0.7418056809511033
reward_mean: 1542.6422997987952
reward_std: 1118.3638655418426
reward_max: 3443.0210581736073
reward_min: 259.0809468344174
total_envstep_count: 2450175
total_train_sample_count: 1905612
total_episode_count: 10417
total_duration: 665.391833536398
[2023-06-29 10:19:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1982
train_sample_count: 1982
avg_envstep_per_episode: 283.14285714285717
avg_sample_per_episode: 283.14285714285717
avg_envstep_per_sec: 2427.3513445173426
avg_train_sample_per_sec: 2427.3513445173426
avg_episode_per_sec: 8.572885676902825
collect_time: 0.8165278604915364
reward_mean: 2278.6313702552425
reward_std: 1148.3626230845118
reward_max: 3493.8974817802796
reward_min: 285.6902332440252
total_envstep_count: 2454575
total_train_sample_count: 1909194
total_episode_count: 10424
total_duration: 666.2083613968896
[2023-06-29 10:19:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 251.11111111111111
avg_sample_per_episode: 251.11111111111111
avg_envstep_per_sec: 2627.6930902685563
avg_train_sample_per_sec: 2627.6930902685563
avg_episode_per_sec: 10.464264518768587
collect_time: 0.8600700014661997
reward_mean: 1898.292929016404
reward_std: 1037.4876457906603
reward_max: 3480.3784787876475
reward_min: 1009.8635822964269
total_envstep_count: 2459063
total_train_sample_count: 1912654
total_episode_count: 10433
total_duration: 667.0684313983558
[2023-06-29 10:19:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1646
train_sample_count: 1646
avg_envstep_per_episode: 274.3333333333333
avg_sample_per_episode: 274.3333333333333
avg_envstep_per_sec: 2648.751180307059
avg_train_sample_per_sec: 2648.751180307059
avg_episode_per_sec: 9.655229089819171
collect_time: 0.6214249236537144
reward_mean: 2176.739922084949
reward_std: 1076.5075305520033
reward_max: 3526.7348086145516
reward_min: 703.2439213209728
total_envstep_count: 2463199
total_train_sample_count: 1915900
total_episode_count: 10439
total_duration: 667.6898563220095
[2023-06-29 10:19:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2525
train_sample_count: 2525
avg_envstep_per_episode: 315.625
avg_sample_per_episode: 315.625
avg_envstep_per_sec: 2700.0104260234516
avg_train_sample_per_sec: 2700.0104260234516
avg_episode_per_sec: 8.554488478490144
collect_time: 0.9351815739907325
reward_mean: 2237.4238550822843
reward_std: 1000.573686059426
reward_max: 3522.395562548149
reward_min: 1042.6241255118246
total_envstep_count: 2467711
total_train_sample_count: 1919225
total_episode_count: 10447
total_duration: 668.6250378960002
[2023-06-29 10:19:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 296.8
avg_sample_per_episode: 296.8
avg_envstep_per_sec: 2549.49397831208
avg_train_sample_per_sec: 2549.49397831208
avg_episode_per_sec: 8.589939280027224
collect_time: 1.1641525829235324
reward_mean: 1680.5080486923694
reward_std: 973.7917068093143
reward_max: 3329.639025140486
reward_min: 286.39432577997144
total_envstep_count: 2472559
total_train_sample_count: 1922593
total_episode_count: 10457
total_duration: 669.7891904789237
[2023-06-29 10:19:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1263
train_sample_count: 1263
avg_envstep_per_episode: 252.6
avg_sample_per_episode: 252.6
avg_envstep_per_sec: 2641.2891834246866
avg_train_sample_per_sec: 2641.2891834246866
avg_episode_per_sec: 10.456410068981342
collect_time: 0.47817558483406897
reward_mean: 1790.7266664353417
reward_std: 903.9386024252037
reward_max: 3592.079746936151
reward_min: 1205.9869455153462
total_envstep_count: 2477031
total_train_sample_count: 1925856
total_episode_count: 10462
total_duration: 670.2673660637578
[2023-06-29 10:19:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1863
train_sample_count: 1863
avg_envstep_per_episode: 232.875
avg_sample_per_episode: 232.875
avg_envstep_per_sec: 2603.653471812409
avg_train_sample_per_sec: 2603.653471812409
avg_episode_per_sec: 11.180476529521885
collect_time: 0.7155330078173427
reward_mean: 2350.6270982799197
reward_std: 1062.0200389094775
reward_max: 3480.1345742058356
reward_min: 701.8672435761366
total_envstep_count: 2481487
total_train_sample_count: 1929319
total_episode_count: 10470
total_duration: 670.9828990715752
[2023-06-29 10:19:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1904
train_sample_count: 1904
avg_envstep_per_episode: 211.55555555555554
avg_sample_per_episode: 211.55555555555554
avg_envstep_per_sec: 2665.555132694268
avg_train_sample_per_sec: 2665.555132694268
avg_episode_per_sec: 12.599787917147275
collect_time: 0.7142977373255418
reward_mean: 1818.9306000881854
reward_std: 1133.1289280599938
reward_max: 3495.04969476098
reward_min: 506.6135130985723
total_envstep_count: 2486143
total_train_sample_count: 1932823
total_episode_count: 10479
total_duration: 671.6971968089007
[2023-06-29 10:19:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 198.85714285714286
avg_sample_per_episode: 198.85714285714286
avg_envstep_per_sec: 2306.0392818835317
avg_train_sample_per_sec: 2306.0392818835317
avg_episode_per_sec: 11.596461906023507
collect_time: 0.603632388630882
reward_mean: 2078.8068966337714
reward_std: 1190.4594090773846
reward_max: 3506.6130187641857
reward_min: 711.3164991508044
total_envstep_count: 2490935
total_train_sample_count: 1936215
total_episode_count: 10486
total_duration: 672.3008291975316
[2023-06-29 10:19:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 236.91666666666666
avg_sample_per_episode: 236.91666666666666
avg_envstep_per_sec: 2499.304656670834
avg_train_sample_per_sec: 2499.304656670834
avg_episode_per_sec: 10.549298586018294
collect_time: 1.1375163857722654
reward_mean: 1936.8663336889813
reward_std: 919.2815881669206
reward_max: 3494.3835450014567
reward_min: 843.7503688093392
total_envstep_count: 2496007
total_train_sample_count: 1939458
total_episode_count: 10498
total_duration: 673.4383455833039
[2023-06-29 10:19:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2533
train_sample_count: 2533
avg_envstep_per_episode: 211.08333333333334
avg_sample_per_episode: 211.08333333333334
avg_envstep_per_sec: 2576.397272338543
avg_train_sample_per_sec: 2576.397272338543
avg_episode_per_sec: 12.20559307858765
collect_time: 0.9831558305062353
reward_mean: 1425.4901115798793
reward_std: 687.1557181619511
reward_max: 3058.3438209776973
reward_min: 876.9923735064054
total_envstep_count: 2500927
total_train_sample_count: 1942791
total_episode_count: 10510
total_duration: 674.4215014138101
[2023-06-29 10:19:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2451
train_sample_count: 2451
avg_envstep_per_episode: 245.1
avg_sample_per_episode: 245.1
avg_envstep_per_sec: 2679.3728840477015
avg_train_sample_per_sec: 2679.3728840477015
avg_episode_per_sec: 10.931753912883318
collect_time: 0.9147662927368658
reward_mean: 1601.9726802661876
reward_std: 649.5124228595006
reward_max: 2571.866090846485
reward_min: 932.366954323038
total_envstep_count: 2505255
total_train_sample_count: 1946042
total_episode_count: 10520
total_duration: 675.336267706547
[2023-06-29 10:19:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3288
train_sample_count: 3288
avg_envstep_per_episode: 252.92307692307693
avg_sample_per_episode: 252.92307692307693
avg_envstep_per_sec: 2520.3546340146745
avg_train_sample_per_sec: 2520.3546340146745
avg_episode_per_sec: 9.96490579142055
collect_time: 1.3045783143471927
reward_mean: 1482.105615371328
reward_std: 785.3374223358543
reward_max: 3551.29033392364
reward_min: 587.5516983998507
total_envstep_count: 2509607
total_train_sample_count: 1949330
total_episode_count: 10533
total_duration: 676.6408460208942
[2023-06-29 10:19:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3048
train_sample_count: 3048
avg_envstep_per_episode: 217.71428571428572
avg_sample_per_episode: 217.71428571428572
avg_envstep_per_sec: 2701.7626619097605
avg_train_sample_per_sec: 2701.7626619097605
avg_episode_per_sec: 12.409671019270554
collect_time: 1.1281523884283378
reward_mean: 1011.4781153972564
reward_std: 254.82058578338692
reward_max: 1589.464930402426
reward_min: 574.7327292727671
total_envstep_count: 2513943
total_train_sample_count: 1952778
total_episode_count: 10547
total_duration: 677.7689984093225
[2023-06-29 10:19:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2523
train_sample_count: 2523
avg_envstep_per_episode: 280.3333333333333
avg_sample_per_episode: 280.3333333333333
avg_envstep_per_sec: 2702.954492130773
avg_train_sample_per_sec: 2702.954492130773
avg_episode_per_sec: 9.641930411881473
collect_time: 0.9334230403602124
reward_mean: 1530.3062795606304
reward_std: 451.9719247014885
reward_max: 2490.371390140428
reward_min: 1057.4184248606457
total_envstep_count: 2518215
total_train_sample_count: 1956101
total_episode_count: 10556
total_duration: 678.7024214496828
[2023-06-29 10:19:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2111
train_sample_count: 2111
avg_envstep_per_episode: 234.55555555555554
avg_sample_per_episode: 234.55555555555554
avg_envstep_per_sec: 2566.51601920833
avg_train_sample_per_sec: 2566.51601920833
avg_episode_per_sec: 10.942038926042146
collect_time: 0.8225158090582115
reward_mean: 1431.9137307007832
reward_std: 654.7801839798619
reward_max: 2233.782383158026
reward_min: 297.35931524710645
total_envstep_count: 2522431
total_train_sample_count: 1959412
total_episode_count: 10565
total_duration: 679.524937258741
[2023-06-29 10:19:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1634
train_sample_count: 1634
avg_envstep_per_episode: 233.42857142857142
avg_sample_per_episode: 233.42857142857142
avg_envstep_per_sec: 2326.3970377861733
avg_train_sample_per_sec: 2326.3970377861733
avg_episode_per_sec: 9.966205180234525
collect_time: 0.7023736591218038
reward_mean: 1732.8389674045663
reward_std: 1068.98473466511
reward_max: 3497.4522042392896
reward_min: 737.346268287776
total_envstep_count: 2526487
total_train_sample_count: 1962646
total_episode_count: 10572
total_duration: 680.2273109178628
[2023-06-29 10:19:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2051
train_sample_count: 2051
avg_envstep_per_episode: 205.1
avg_sample_per_episode: 205.1
avg_envstep_per_sec: 2702.750065442543
avg_train_sample_per_sec: 2702.750065442543
avg_episode_per_sec: 13.17771850532688
collect_time: 0.7588567016329618
reward_mean: 1767.7514640411223
reward_std: 830.9287600393762
reward_max: 3582.218879732152
reward_min: 902.8771053272682
total_envstep_count: 2530775
total_train_sample_count: 1965897
total_episode_count: 10582
total_duration: 680.9861676194957
[2023-06-29 10:20:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 302.25
avg_sample_per_episode: 302.25
avg_envstep_per_sec: 2700.172353729999
avg_train_sample_per_sec: 2700.172353729999
avg_episode_per_sec: 8.933572717055414
collect_time: 0.4477491958355532
reward_mean: 2058.2250655226508
reward_std: 948.5102145751267
reward_max: 3419.6588843942927
reward_min: 838.9861495179584
total_envstep_count: 2535039
total_train_sample_count: 1969106
total_episode_count: 10586
total_duration: 681.4339168153313
[2023-06-29 10:20:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 223.11111111111111
avg_sample_per_episode: 223.11111111111111
avg_envstep_per_sec: 2439.39488183078
avg_train_sample_per_sec: 2439.39488183078
avg_episode_per_sec: 10.93354279705031
collect_time: 0.82315496148495
reward_mean: 2275.717969698547
reward_std: 1047.0619042567014
reward_max: 3467.697659541008
reward_min: 1003.9593703449301
total_envstep_count: 2538807
total_train_sample_count: 1972314
total_episode_count: 10595
total_duration: 682.2570717768162
[2023-06-29 10:20:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 285.8333333333333
avg_sample_per_episode: 285.8333333333333
avg_envstep_per_sec: 2738.1797833145965
avg_train_sample_per_sec: 2738.1797833145965
avg_episode_per_sec: 9.57963772588197
collect_time: 0.6263284867014736
reward_mean: 2054.7584078413333
reward_std: 1030.242303701579
reward_max: 3427.4677951927993
reward_min: 826.0776193620286
total_envstep_count: 2543095
total_train_sample_count: 1975629
total_episode_count: 10601
total_duration: 682.8834002635177
[2023-06-29 10:20:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2533
train_sample_count: 2533
avg_envstep_per_episode: 316.625
avg_sample_per_episode: 316.625
avg_envstep_per_sec: 2453.027155755694
avg_train_sample_per_sec: 2453.027155755694
avg_episode_per_sec: 7.747420941984032
collect_time: 1.032601695442572
reward_mean: 2220.880144533024
reward_std: 924.1285972810115
reward_max: 3412.467384917
reward_min: 658.7465587030639
total_envstep_count: 2547959
total_train_sample_count: 1978962
total_episode_count: 10609
total_duration: 683.9160019589604
[2023-06-29 10:20:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1261
train_sample_count: 1261
avg_envstep_per_episode: 315.25
avg_sample_per_episode: 315.25
avg_envstep_per_sec: 2686.849196239565
avg_train_sample_per_sec: 2686.849196239565
avg_episode_per_sec: 8.52291576919767
collect_time: 0.46932295335549845
reward_mean: 2039.8112643105624
reward_std: 941.2536435187407
reward_max: 3363.5896497802473
reward_min: 857.719556042852
total_envstep_count: 2552407
total_train_sample_count: 1982223
total_episode_count: 10613
total_duration: 684.3853249123158
[2023-06-29 10:20:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2230
train_sample_count: 2230
avg_envstep_per_episode: 278.75
avg_sample_per_episode: 278.75
avg_envstep_per_sec: 2468.419603778428
avg_train_sample_per_sec: 2468.419603778428
avg_episode_per_sec: 8.855316964227544
collect_time: 0.9034120441218837
reward_mean: 2735.842901459762
reward_std: 789.3565618490568
reward_max: 3472.25780223006
reward_min: 1414.913960217565
total_envstep_count: 2557199
total_train_sample_count: 1985653
total_episode_count: 10621
total_duration: 685.2887369564377
[2023-06-29 10:20:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1574
train_sample_count: 1574
avg_envstep_per_episode: 262.3333333333333
avg_sample_per_episode: 262.3333333333333
avg_envstep_per_sec: 2580.7649031554524
avg_train_sample_per_sec: 2580.7649031554524
avg_episode_per_sec: 9.837731524099564
collect_time: 0.6098967008097096
reward_mean: 2253.7024160148144
reward_std: 727.488968740623
reward_max: 3103.5275405194357
reward_min: 1031.2333848651883
total_envstep_count: 2561943
total_train_sample_count: 1989227
total_episode_count: 10627
total_duration: 685.8986336572474
[2023-06-29 10:20:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1647
train_sample_count: 1647
avg_envstep_per_episode: 235.28571428571428
avg_sample_per_episode: 235.28571428571428
avg_envstep_per_sec: 2355.266907369703
avg_train_sample_per_sec: 2355.266907369703
avg_episode_per_sec: 10.010241864959271
collect_time: 0.6992838029721753
reward_mean: 2553.3114985426296
reward_std: 802.1530174066659
reward_max: 3448.7216624595144
reward_min: 1156.5152439699143
total_envstep_count: 2566263
total_train_sample_count: 1992474
total_episode_count: 10634
total_duration: 686.5979174602196
[2023-06-29 10:20:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1218
train_sample_count: 1218
avg_envstep_per_episode: 406.0
avg_sample_per_episode: 406.0
avg_envstep_per_sec: 2690.8077098102563
avg_train_sample_per_sec: 2690.8077098102563
avg_episode_per_sec: 6.627605196576987
collect_time: 0.4526521889911962
reward_mean: 2998.6581955940223
reward_std: 368.6205594623092
reward_max: 3438.5082244745263
reward_min: 2536.4097622322315
total_envstep_count: 2569911
total_train_sample_count: 1995692
total_episode_count: 10637
total_duration: 687.0505696492108
[2023-06-29 10:20:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1906
train_sample_count: 1906
avg_envstep_per_episode: 238.25
avg_sample_per_episode: 238.25
avg_envstep_per_sec: 2640.2200640290753
avg_train_sample_per_sec: 2640.2200640290753
avg_episode_per_sec: 11.081721150174502
collect_time: 0.721909520334215
reward_mean: 2434.573291178811
reward_std: 934.4652650111263
reward_max: 3423.5432217775306
reward_min: 1059.970039869214
total_envstep_count: 2575111
total_train_sample_count: 1999198
total_episode_count: 10645
total_duration: 687.772479169545
[2023-06-29 10:20:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 275.44444444444446
avg_sample_per_episode: 275.44444444444446
avg_envstep_per_sec: 2456.042707278338
avg_train_sample_per_sec: 2456.042707278338
avg_episode_per_sec: 8.916653636750723
collect_time: 1.0093472693506629
reward_mean: 2219.6992927830565
reward_std: 945.0922115596992
reward_max: 3512.6426500646535
reward_min: 1145.4328933162312
total_envstep_count: 2580175
total_train_sample_count: 2002477
total_episode_count: 10654
total_duration: 688.7818264388957
[2023-06-29 10:20:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1273
train_sample_count: 1273
avg_envstep_per_episode: 212.16666666666666
avg_sample_per_episode: 212.16666666666666
avg_envstep_per_sec: 2283.3705463081537
avg_train_sample_per_sec: 2283.3705463081537
avg_episode_per_sec: 10.762154970816121
collect_time: 0.5575091620841996
reward_mean: 1997.0798197650856
reward_std: 914.9735732610093
reward_max: 3395.629732007398
reward_min: 1095.842754149357
total_envstep_count: 2584055
total_train_sample_count: 2005750
total_episode_count: 10660
total_duration: 689.3393356009799
[2023-06-29 10:20:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2946
train_sample_count: 2946
avg_envstep_per_episode: 327.3333333333333
avg_sample_per_episode: 327.3333333333333
avg_envstep_per_sec: 2638.0984697057447
avg_train_sample_per_sec: 2638.0984697057447
avg_episode_per_sec: 8.059363960404516
collect_time: 1.11671343349386
reward_mean: 2206.0711771071688
reward_std: 1030.4470707309542
reward_max: 3450.96926259861
reward_min: 989.4202331805802
total_envstep_count: 2588439
total_train_sample_count: 2009096
total_episode_count: 10669
total_duration: 690.4560490344737
[2023-06-29 10:20:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3345
train_sample_count: 3345
avg_envstep_per_episode: 209.0625
avg_sample_per_episode: 209.0625
avg_envstep_per_sec: 2668.7992118760385
avg_train_sample_per_sec: 2668.7992118760385
avg_episode_per_sec: 12.765556768315879
collect_time: 1.2533726722920548
reward_mean: 1114.5643786482133
reward_std: 769.9880070168239
reward_max: 3446.8626906613763
reward_min: 411.7861732578119
total_envstep_count: 2593239
total_train_sample_count: 2012441
total_episode_count: 10685
total_duration: 691.7094217067657
[2023-06-29 10:20:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2951
train_sample_count: 2951
avg_envstep_per_episode: 245.91666666666666
avg_sample_per_episode: 245.91666666666666
avg_envstep_per_sec: 2661.0978865238785
avg_train_sample_per_sec: 2661.0978865238785
avg_episode_per_sec: 10.821136780171651
collect_time: 1.108940792799927
reward_mean: 1278.2310070641404
reward_std: 728.5000711763837
reward_max: 3443.537547161261
reward_min: 584.9976252653579
total_envstep_count: 2598063
total_train_sample_count: 2015792
total_episode_count: 10697
total_duration: 692.8183624995656
[2023-06-29 10:20:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1842
train_sample_count: 1842
avg_envstep_per_episode: 263.14285714285717
avg_sample_per_episode: 263.14285714285717
avg_envstep_per_sec: 2652.196607375717
avg_train_sample_per_sec: 2652.196607375717
avg_episode_per_sec: 10.078923046487525
collect_time: 0.6945186472516506
reward_mean: 1709.6531566685403
reward_std: 579.2506101932391
reward_max: 2589.526737007871
reward_min: 713.0892293627518
total_envstep_count: 2602911
total_train_sample_count: 2019234
total_episode_count: 10704
total_duration: 693.5128811468173
[2023-06-29 10:20:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 189.16666666666666
avg_sample_per_episode: 189.16666666666666
avg_envstep_per_sec: 2591.156425369392
avg_train_sample_per_sec: 2591.156425369392
avg_episode_per_sec: 13.697743217811762
collect_time: 0.43802836018987
reward_mean: 2329.412302247532
reward_std: 848.7242918703827
reward_max: 3379.3102544527505
reward_min: 1359.851049513729
total_envstep_count: 2607535
total_train_sample_count: 2022769
total_episode_count: 10710
total_duration: 693.9509095070072
[2023-06-29 10:20:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1350
train_sample_count: 1350
avg_envstep_per_episode: 270.0
avg_sample_per_episode: 270.0
avg_envstep_per_sec: 2655.981777275033
avg_train_sample_per_sec: 2655.981777275033
avg_episode_per_sec: 9.836969545463084
collect_time: 0.5082866198671981
reward_mean: 3142.8515242532385
reward_std: 330.7473997334245
reward_max: 3474.5697502302096
reward_min: 2635.724391466324
total_envstep_count: 2611759
total_train_sample_count: 2026119
total_episode_count: 10715
total_duration: 694.4591961268744
[2023-06-29 10:20:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2422
train_sample_count: 2422
avg_envstep_per_episode: 242.2
avg_sample_per_episode: 242.2
avg_envstep_per_sec: 2725.630393169174
avg_train_sample_per_sec: 2725.630393169174
avg_episode_per_sec: 11.253634984183211
collect_time: 0.8886017730319871
reward_mean: 2039.0994196939932
reward_std: 1085.9328198845205
reward_max: 3417.652917863646
reward_min: 688.8737380549989
total_envstep_count: 2616079
total_train_sample_count: 2029341
total_episode_count: 10725
total_duration: 695.3477978999064
[2023-06-29 10:21:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 224.4
avg_sample_per_episode: 224.4
avg_envstep_per_sec: 2684.998648555623
avg_train_sample_per_sec: 2684.998648555623
avg_episode_per_sec: 11.96523461923183
collect_time: 0.41787730530276895
reward_mean: 1938.70626503877
reward_std: 831.6043406165069
reward_max: 2859.0357933274936
reward_min: 935.9478865190898
total_envstep_count: 2620663
total_train_sample_count: 2032863
total_episode_count: 10730
total_duration: 695.7656752052092
[2023-06-29 10:21:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1691
train_sample_count: 1691
avg_envstep_per_episode: 211.375
avg_sample_per_episode: 211.375
avg_envstep_per_sec: 2551.8617886380102
avg_train_sample_per_sec: 2551.8617886380102
avg_episode_per_sec: 12.072675522829144
collect_time: 0.6626534428820016
reward_mean: 2291.3945675683567
reward_std: 1030.6598011772285
reward_max: 3571.139167239409
reward_min: 550.507467404636
total_envstep_count: 2625087
total_train_sample_count: 2036154
total_episode_count: 10738
total_duration: 696.4283286480911
[2023-06-29 10:21:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2509
train_sample_count: 2509
avg_envstep_per_episode: 250.9
avg_sample_per_episode: 250.9
avg_envstep_per_sec: 2658.631077638856
avg_train_sample_per_sec: 2658.631077638856
avg_episode_per_sec: 10.596377352087908
collect_time: 0.9437187510153744
reward_mean: 1865.0642292207965
reward_std: 852.5735673633117
reward_max: 3158.3822916691624
reward_min: 981.7057338681732
total_envstep_count: 2629415
total_train_sample_count: 2039463
total_episode_count: 10748
total_duration: 697.3720473991065
[2023-06-29 10:21:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2656
train_sample_count: 2656
avg_envstep_per_episode: 241.45454545454547
avg_sample_per_episode: 241.45454545454547
avg_envstep_per_sec: 2602.3262583154806
avg_train_sample_per_sec: 2602.3262583154806
avg_episode_per_sec: 10.777706642119838
collect_time: 1.0206252930480988
reward_mean: 1503.8709734129202
reward_std: 714.6938327057935
reward_max: 3463.090734417458
reward_min: 721.7800932292208
total_envstep_count: 2633527
total_train_sample_count: 2042919
total_episode_count: 10759
total_duration: 698.3926726921545
[2023-06-29 10:21:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2376
train_sample_count: 2376
avg_envstep_per_episode: 264.0
avg_sample_per_episode: 264.0
avg_envstep_per_sec: 2552.036105069857
avg_train_sample_per_sec: 2552.036105069857
avg_episode_per_sec: 9.666803428294912
collect_time: 0.9310213108975438
reward_mean: 1522.9327187083177
reward_std: 798.3509752042352
reward_max: 3372.102133667311
reward_min: 753.8884940664274
total_envstep_count: 2638183
total_train_sample_count: 2046495
total_episode_count: 10768
total_duration: 699.3236940030521
[2023-06-29 10:21:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1926
train_sample_count: 1926
avg_envstep_per_episode: 321.0
avg_sample_per_episode: 321.0
avg_envstep_per_sec: 2647.449442845649
avg_train_sample_per_sec: 2647.449442845649
avg_episode_per_sec: 8.247506052478657
collect_time: 0.7274926458764822
reward_mean: 2237.0137099503954
reward_std: 837.4383019730086
reward_max: 3443.597156463102
reward_min: 1083.6170341163183
total_envstep_count: 2643063
total_train_sample_count: 2050021
total_episode_count: 10774
total_duration: 700.0511866489286
[2023-06-29 10:21:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1680
train_sample_count: 1680
avg_envstep_per_episode: 210.0
avg_sample_per_episode: 210.0
avg_envstep_per_sec: 2640.054036546787
avg_train_sample_per_sec: 2640.054036546787
avg_episode_per_sec: 12.571685888318033
collect_time: 0.6363506112918258
reward_mean: 1745.4958046313418
reward_std: 1075.5609793356562
reward_max: 3443.130375281464
reward_min: 541.1406435262222
total_envstep_count: 2647055
total_train_sample_count: 2053301
total_episode_count: 10782
total_duration: 700.6875372602204
[2023-06-29 10:21:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2024
train_sample_count: 2024
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 2690.60457764664
avg_train_sample_per_sec: 2690.60457764664
avg_episode_per_sec: 14.62285096547087
collect_time: 0.7522472892580554
reward_mean: 1373.7428765404638
reward_std: 1072.8388233803917
reward_max: 3407.726124188467
reward_min: 486.3591878859313
total_envstep_count: 2651095
total_train_sample_count: 2056525
total_episode_count: 10793
total_duration: 701.4397845494785
[2023-06-29 10:21:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 199.4
avg_sample_per_episode: 199.4
avg_envstep_per_sec: 2487.289505424914
avg_train_sample_per_sec: 2487.289505424914
avg_episode_per_sec: 12.473869134528154
collect_time: 0.4008379393815994
reward_mean: 1857.5438354000312
reward_std: 1132.4141477695323
reward_max: 3302.1093384879564
reward_min: 615.2685811428876
total_envstep_count: 2654991
total_train_sample_count: 2059922
total_episode_count: 10798
total_duration: 701.8406224888602
[2023-06-29 10:21:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1499
train_sample_count: 1499
avg_envstep_per_episode: 299.8
avg_sample_per_episode: 299.8
avg_envstep_per_sec: 2609.4315997875196
avg_train_sample_per_sec: 2609.4315997875196
avg_episode_per_sec: 8.70390793791701
collect_time: 0.5744546054098756
reward_mean: 3083.4300527002283
reward_std: 278.45395407923667
reward_max: 3448.6257332590344
reward_min: 2738.162642081194
total_envstep_count: 2659639
total_train_sample_count: 2063421
total_episode_count: 10803
total_duration: 702.41507709427
[2023-06-29 10:21:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2364
train_sample_count: 2364
avg_envstep_per_episode: 295.5
avg_sample_per_episode: 295.5
avg_envstep_per_sec: 2439.938517463385
avg_train_sample_per_sec: 2439.938517463385
avg_episode_per_sec: 8.256983138623976
collect_time: 0.9688768725441769
reward_mean: 2433.6134849017767
reward_std: 970.3255396722919
reward_max: 3412.4456070693345
reward_min: 646.5199725772303
total_envstep_count: 2664799
total_train_sample_count: 2066985
total_episode_count: 10811
total_duration: 703.3839539668143
[2023-06-29 10:21:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2316
train_sample_count: 2316
avg_envstep_per_episode: 289.5
avg_sample_per_episode: 289.5
avg_envstep_per_sec: 2702.418591870682
avg_train_sample_per_sec: 2702.418591870682
avg_episode_per_sec: 9.334779246530854
collect_time: 0.8570100897643715
reward_mean: 2182.840673036022
reward_std: 784.2029504454263
reward_max: 3492.8777010943677
reward_min: 1062.9552318685608
total_envstep_count: 2669871
total_train_sample_count: 2070501
total_episode_count: 10819
total_duration: 704.2409640565786
[2023-06-29 10:21:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1683
train_sample_count: 1683
avg_envstep_per_episode: 210.375
avg_sample_per_episode: 210.375
avg_envstep_per_sec: 2518.0259071387204
avg_train_sample_per_sec: 2518.0259071387204
avg_episode_per_sec: 11.969225940053336
collect_time: 0.6683807323938236
reward_mean: 1698.1177878594026
reward_std: 926.1612025323856
reward_max: 3392.1498051487474
reward_min: 207.92135663684954
total_envstep_count: 2674151
total_train_sample_count: 2073784
total_episode_count: 10827
total_duration: 704.9093447889725
[2023-06-29 10:21:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2181
train_sample_count: 2181
avg_envstep_per_episode: 242.33333333333334
avg_sample_per_episode: 242.33333333333334
avg_envstep_per_sec: 2425.3157795793263
avg_train_sample_per_sec: 2425.3157795793263
avg_episode_per_sec: 10.008180658511662
collect_time: 0.8992643425501882
reward_mean: 2080.321314520564
reward_std: 924.6149467985829
reward_max: 3392.2269652483433
reward_min: 969.9945006445663
total_envstep_count: 2677887
total_train_sample_count: 2077165
total_episode_count: 10836
total_duration: 705.8086091315226
[2023-06-29 10:21:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 263.1818181818182
avg_sample_per_episode: 263.1818181818182
avg_envstep_per_sec: 2683.0397520061133
avg_train_sample_per_sec: 2683.0397520061133
avg_episode_per_sec: 10.194624273598357
collect_time: 1.0790000400983264
reward_mean: 1215.42860731016
reward_std: 678.8697359710958
reward_max: 3035.252237355332
reward_min: 425.88955775196524
total_envstep_count: 2682511
total_train_sample_count: 2080460
total_episode_count: 10847
total_duration: 706.887609171621
[2023-06-29 10:21:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2341
train_sample_count: 2341
avg_envstep_per_episode: 212.8181818181818
avg_sample_per_episode: 212.8181818181818
avg_envstep_per_sec: 2696.811164070906
avg_train_sample_per_sec: 2696.811164070906
avg_episode_per_sec: 12.671902095164446
collect_time: 0.8680622622705996
reward_mean: 1233.9364815862652
reward_std: 759.3433998792386
reward_max: 3177.475010921669
reward_min: 350.06436318814286
total_envstep_count: 2687655
total_train_sample_count: 2084401
total_episode_count: 10858
total_duration: 707.7556714338916
[2023-06-29 10:21:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2511
train_sample_count: 2511
avg_envstep_per_episode: 251.1
avg_sample_per_episode: 251.1
avg_envstep_per_sec: 2610.9132066401644
avg_train_sample_per_sec: 2610.9132066401644
avg_episode_per_sec: 10.397902057507624
collect_time: 0.9617324672508984
reward_mean: 1668.5239229757613
reward_std: 928.9477619501339
reward_max: 3356.1838234383545
reward_min: 730.5597283746105
total_envstep_count: 2692239
total_train_sample_count: 2087712
total_episode_count: 10868
total_duration: 708.7174039011426
[2023-06-29 10:21:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3315
train_sample_count: 3315
avg_envstep_per_episode: 301.3636363636364
avg_sample_per_episode: 301.3636363636364
avg_envstep_per_sec: 2508.059186414665
avg_train_sample_per_sec: 2508.059186414665
avg_episode_per_sec: 8.322368341044138
collect_time: 1.321739143141545
reward_mean: 1571.935515574078
reward_std: 894.7203504516427
reward_max: 3206.179179965021
reward_min: 316.76029130076836
total_envstep_count: 2696327
total_train_sample_count: 2091027
total_episode_count: 10879
total_duration: 710.0391430442842
[2023-06-29 10:21:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1320
train_sample_count: 1320
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 2313.086101784141
avg_train_sample_per_sec: 2313.086101784141
avg_episode_per_sec: 7.009351823588306
collect_time: 0.5706661757994443
reward_mean: 1236.6884200591817
reward_std: 362.6855485600635
reward_max: 1789.8840667021711
reward_min: 772.6494003143497
total_envstep_count: 2701087
total_train_sample_count: 2094347
total_episode_count: 10883
total_duration: 710.6098092200837
[2023-06-29 10:22:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2105
train_sample_count: 2105
avg_envstep_per_episode: 233.88888888888889
avg_sample_per_episode: 233.88888888888889
avg_envstep_per_sec: 2455.9486651277793
avg_train_sample_per_sec: 2455.9486651277793
avg_episode_per_sec: 10.500493105059387
collect_time: 0.8571026055589318
reward_mean: 1818.3799400483522
reward_std: 759.734012302114
reward_max: 3029.136032378198
reward_min: 746.386597549764
total_envstep_count: 2705391
total_train_sample_count: 2097652
total_episode_count: 10892
total_duration: 711.4669118256426
[2023-06-29 10:22:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3393
train_sample_count: 3393
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2627.5753546027813
avg_train_sample_per_sec: 2627.5753546027813
avg_episode_per_sec: 10.067338523382304
collect_time: 1.291304545864463
reward_mean: 1503.2179248728814
reward_std: 884.2311412216798
reward_max: 3172.001172887937
reward_min: 202.2390946070869
total_envstep_count: 2710319
total_train_sample_count: 2101045
total_episode_count: 10905
total_duration: 712.758216371507
[2023-06-29 10:22:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1622
train_sample_count: 1622
avg_envstep_per_episode: 202.75
avg_sample_per_episode: 202.75
avg_envstep_per_sec: 2657.239435089858
avg_train_sample_per_sec: 2657.239435089858
avg_episode_per_sec: 13.105989815486353
collect_time: 0.6104079213114455
reward_mean: 1075.847944649062
reward_std: 483.46819009278494
reward_max: 2216.402708902207
reward_min: 688.9547511603959
total_envstep_count: 2715303
total_train_sample_count: 2104267
total_episode_count: 10913
total_duration: 713.3686242928185
[2023-06-29 10:22:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2578
train_sample_count: 2578
avg_envstep_per_episode: 257.8
avg_sample_per_episode: 257.8
avg_envstep_per_sec: 2666.784793407794
avg_train_sample_per_sec: 2666.784793407794
avg_episode_per_sec: 10.344394078385546
collect_time: 0.9667071772618221
reward_mean: 1959.3784156804072
reward_std: 893.7584024832081
reward_max: 3458.2285338566676
reward_min: 694.4552577627067
total_envstep_count: 2720103
total_train_sample_count: 2107645
total_episode_count: 10923
total_duration: 714.3353314700803
[2023-06-29 10:22:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1132
train_sample_count: 1132
avg_envstep_per_episode: 161.71428571428572
avg_sample_per_episode: 161.71428571428572
avg_envstep_per_sec: 2195.6191893051964
avg_train_sample_per_sec: 2195.6191893051964
avg_episode_per_sec: 13.577150463901392
collect_time: 0.5155721017168835
reward_mean: 1715.7513657672407
reward_std: 779.0683642730553
reward_max: 3093.3103061591673
reward_min: 650.3551954579087
total_envstep_count: 2724847
total_train_sample_count: 2111177
total_episode_count: 10930
total_duration: 714.8509035717972
[2023-06-29 10:22:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2738
train_sample_count: 2738
avg_envstep_per_episode: 304.22222222222223
avg_sample_per_episode: 304.22222222222223
avg_envstep_per_sec: 2584.3514639665805
avg_train_sample_per_sec: 2584.3514639665805
avg_episode_per_sec: 8.494946375346686
collect_time: 1.0594534211680298
reward_mean: 2005.2983300989565
reward_std: 638.0369257257885
reward_max: 3053.587872790032
reward_min: 962.4561326857761
total_envstep_count: 2729631
total_train_sample_count: 2114715
total_episode_count: 10939
total_duration: 715.9103569929653
[2023-06-29 10:22:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1683
train_sample_count: 1683
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 2648.061792704466
avg_train_sample_per_sec: 2648.061792704466
avg_episode_per_sec: 14.160758249756503
collect_time: 0.6355591869633646
reward_mean: 1576.9339688076318
reward_std: 926.3394927287693
reward_max: 3218.3307519904115
reward_min: 294.9155353477389
total_envstep_count: 2734111
total_train_sample_count: 2117998
total_episode_count: 10948
total_duration: 716.5459161799287
[2023-06-29 10:22:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2997
train_sample_count: 2997
avg_envstep_per_episode: 214.07142857142858
avg_sample_per_episode: 214.07142857142858
avg_envstep_per_sec: 2437.1900720006356
avg_train_sample_per_sec: 2437.1900720006356
avg_episode_per_sec: 11.384938607944244
collect_time: 1.2296948171710829
reward_mean: 1384.2201990024919
reward_std: 785.5970396848173
reward_max: 2357.7854051181266
reward_min: 188.31013080558415
total_envstep_count: 2738655
total_train_sample_count: 2121395
total_episode_count: 10962
total_duration: 717.7756109970998
[2023-06-29 10:22:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2162
train_sample_count: 2162
avg_envstep_per_episode: 240.22222222222223
avg_sample_per_episode: 240.22222222222223
avg_envstep_per_sec: 2418.2763724053575
avg_train_sample_per_sec: 2418.2763724053575
avg_episode_per_sec: 10.06683041241823
collect_time: 0.8940251927655192
reward_mean: 1335.7022463116139
reward_std: 935.2338948480419
reward_max: 3192.796247141104
reward_min: 309.3224735371362
total_envstep_count: 2743519
total_train_sample_count: 2124757
total_episode_count: 10971
total_duration: 718.6696361898653
[2023-06-29 10:22:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2194
train_sample_count: 2194
avg_envstep_per_episode: 274.25
avg_sample_per_episode: 274.25
avg_envstep_per_sec: 2407.283792605752
avg_train_sample_per_sec: 2407.283792605752
avg_episode_per_sec: 8.777698423357345
collect_time: 0.9114006444687255
reward_mean: 1889.478139639327
reward_std: 643.8861724201366
reward_max: 3110.16145465321
reward_min: 959.0964853084797
total_envstep_count: 2747855
total_train_sample_count: 2128151
total_episode_count: 10979
total_duration: 719.581036834334
[2023-06-29 10:22:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2285
train_sample_count: 2285
avg_envstep_per_episode: 207.72727272727272
avg_sample_per_episode: 207.72727272727272
avg_envstep_per_sec: 2798.47660273317
avg_train_sample_per_sec: 2798.47660273317
avg_episode_per_sec: 13.471878612719856
collect_time: 0.8165156706217676
reward_mean: 1448.4266165173685
reward_std: 830.3831454502177
reward_max: 3190.2930523375453
reward_min: 254.54249536499643
total_envstep_count: 2752191
total_train_sample_count: 2131636
total_episode_count: 10990
total_duration: 720.3975525049558
[2023-06-29 10:22:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3229
train_sample_count: 3229
avg_envstep_per_episode: 293.54545454545456
avg_sample_per_episode: 293.54545454545456
avg_envstep_per_sec: 2734.4325959233906
avg_train_sample_per_sec: 2734.4325959233906
avg_episode_per_sec: 9.315193110918953
collect_time: 1.1808665552092714
reward_mean: 1642.8022512896953
reward_std: 814.3317121386729
reward_max: 3317.7147867718613
reward_min: 768.9979026267753
total_envstep_count: 2756735
total_train_sample_count: 2134865
total_episode_count: 11001
total_duration: 721.5784190601651
[2023-06-29 10:22:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2982
train_sample_count: 2982
avg_envstep_per_episode: 271.09090909090907
avg_sample_per_episode: 271.09090909090907
avg_envstep_per_sec: 2398.765082329651
avg_train_sample_per_sec: 2398.765082329651
avg_episode_per_sec: 8.848563348633856
collect_time: 1.2431396563034505
reward_mean: 1317.907581806957
reward_std: 433.4571549501237
reward_max: 1828.1925599509073
reward_min: 563.6830245059986
total_envstep_count: 2761359
total_train_sample_count: 2138247
total_episode_count: 11012
total_duration: 722.8215587164685
[2023-06-29 10:22:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3315
train_sample_count: 3315
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2595.391024000833
avg_train_sample_per_sec: 2595.391024000833
avg_episode_per_sec: 10.178004015689542
collect_time: 1.2772641846043988
reward_mean: 1330.6675136386293
reward_std: 452.7083950086856
reward_max: 2236.7783225750577
reward_min: 703.829167548967
total_envstep_count: 2765607
total_train_sample_count: 2141562
total_episode_count: 11025
total_duration: 724.0988229010729
[2023-06-29 10:22:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3196
train_sample_count: 3196
avg_envstep_per_episode: 245.84615384615384
avg_sample_per_episode: 245.84615384615384
avg_envstep_per_sec: 2700.2478205967
avg_train_sample_per_sec: 2700.2478205967
avg_episode_per_sec: 10.983486128835137
collect_time: 1.183595066949725
reward_mean: 1096.413504611932
reward_std: 387.026048212477
reward_max: 1877.3862146609108
reward_min: 638.3869824442223
total_envstep_count: 2770407
total_train_sample_count: 2145158
total_episode_count: 11038
total_duration: 725.2824179680226
[2023-06-29 10:22:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3234
train_sample_count: 3234
avg_envstep_per_episode: 269.5
avg_sample_per_episode: 269.5
avg_envstep_per_sec: 2772.8830205371855
avg_train_sample_per_sec: 2772.8830205371855
avg_episode_per_sec: 10.288990799766923
collect_time: 1.1662951433751731
reward_mean: 1405.4997301992516
reward_std: 477.0946972976844
reward_max: 2583.3570308468406
reward_min: 716.1122628537571
total_envstep_count: 2775271
total_train_sample_count: 2148392
total_episode_count: 11050
total_duration: 726.4487131113978
[2023-06-29 10:22:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2491
train_sample_count: 2491
avg_envstep_per_episode: 191.6153846153846
avg_sample_per_episode: 191.6153846153846
avg_envstep_per_sec: 2486.4088717151694
avg_train_sample_per_sec: 2486.4088717151694
avg_episode_per_sec: 12.976039876474188
collect_time: 1.0018464896650983
reward_mean: 1012.7784970885859
reward_std: 484.0666816569268
reward_max: 1895.4784774000068
reward_min: 179.36625190201502
total_envstep_count: 2779879
total_train_sample_count: 2151683
total_episode_count: 11063
total_duration: 727.4505596010629
[2023-06-29 10:22:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2510.2776767853247
avg_train_sample_per_sec: 2510.2776767853247
avg_episode_per_sec: 10.682032667171594
collect_time: 1.2169968399321662
reward_mean: 1354.4179023370355
reward_std: 405.9293600726205
reward_max: 2067.392616277437
reward_min: 683.8651747138379
total_envstep_count: 2784671
total_train_sample_count: 2155138
total_episode_count: 11076
total_duration: 728.6675564409951
[2023-06-29 10:22:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2262
train_sample_count: 2262
avg_envstep_per_episode: 226.2
avg_sample_per_episode: 226.2
avg_envstep_per_sec: 2491.07779172035
avg_train_sample_per_sec: 2491.07779172035
avg_episode_per_sec: 11.01272233298121
collect_time: 0.9080406912695618
reward_mean: 1370.8402723773838
reward_std: 642.5848582185148
reward_max: 2946.7763962530994
reward_min: 687.2710343365966
total_envstep_count: 2788991
total_train_sample_count: 2158600
total_episode_count: 11086
total_duration: 729.5755971322646
[2023-06-29 10:23:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3376
train_sample_count: 3376
avg_envstep_per_episode: 259.6923076923077
avg_sample_per_episode: 259.6923076923077
avg_envstep_per_sec: 2793.052413644802
avg_train_sample_per_sec: 2793.052413644802
avg_episode_per_sec: 10.755237374817069
collect_time: 1.2087134432233868
reward_mean: 1438.969641615942
reward_std: 517.0655007895881
reward_max: 2512.470448582564
reward_min: 667.5740912859684
total_envstep_count: 2793623
total_train_sample_count: 2161976
total_episode_count: 11099
total_duration: 730.784310575488
[2023-06-29 10:23:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2266
train_sample_count: 2266
avg_envstep_per_episode: 226.6
avg_sample_per_episode: 226.6
avg_envstep_per_sec: 2684.1085258708063
avg_train_sample_per_sec: 2684.1085258708063
avg_episode_per_sec: 11.845139125643453
collect_time: 0.8442281592413782
reward_mean: 1224.2564314603858
reward_std: 374.11397115337684
reward_max: 1884.6988845140668
reward_min: 555.20375288871
total_envstep_count: 2797991
total_train_sample_count: 2165442
total_episode_count: 11109
total_duration: 731.6285387347294
[2023-06-29 10:23:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2486
train_sample_count: 2486
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 2613.5823745544926
avg_train_sample_per_sec: 2613.5823745544926
avg_episode_per_sec: 11.56452378121457
collect_time: 0.9511848657242953
reward_mean: 1442.1444566569992
reward_std: 571.8253251145047
reward_max: 2148.110981160514
reward_min: 109.9999783807705
total_envstep_count: 2802375
total_train_sample_count: 2168728
total_episode_count: 11120
total_duration: 732.5797236004537
[2023-06-29 10:23:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3475
train_sample_count: 3475
avg_envstep_per_episode: 267.3076923076923
avg_sample_per_episode: 267.3076923076923
avg_envstep_per_sec: 2676.005175225463
avg_train_sample_per_sec: 2676.005175225463
avg_episode_per_sec: 10.01095461235425
collect_time: 1.2985774587327614
reward_mean: 1404.7961577828946
reward_std: 704.2612449888205
reward_max: 3224.0115488052197
reward_min: 194.73391064973615
total_envstep_count: 2807103
total_train_sample_count: 2172203
total_episode_count: 11133
total_duration: 733.8783010591865
[2023-06-29 10:23:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 254.63636363636363
avg_sample_per_episode: 254.63636363636363
avg_envstep_per_sec: 2736.2919204537084
avg_train_sample_per_sec: 2736.2919204537084
avg_episode_per_sec: 10.745880444480825
collect_time: 1.0236480907108634
reward_mean: 1265.38023742791
reward_std: 411.3974641656951
reward_max: 2084.6189014855754
reward_min: 750.7081705802171
total_envstep_count: 2811519
total_train_sample_count: 2175404
total_episode_count: 11144
total_duration: 734.9019491498973
[2023-06-29 10:23:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2821
train_sample_count: 2821
avg_envstep_per_episode: 282.1
avg_sample_per_episode: 282.1
avg_envstep_per_sec: 2570.4127168013397
avg_train_sample_per_sec: 2570.4127168013397
avg_episode_per_sec: 9.111707610072102
collect_time: 1.0974891236573459
reward_mean: 1563.5402935339603
reward_std: 531.0150277326172
reward_max: 2662.063531370951
reward_min: 562.6972509677578
total_envstep_count: 2815847
total_train_sample_count: 2178625
total_episode_count: 11154
total_duration: 735.9994382735547
[2023-06-29 10:23:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3292
train_sample_count: 3292
avg_envstep_per_episode: 299.27272727272725
avg_sample_per_episode: 299.27272727272725
avg_envstep_per_sec: 2602.8553819014073
avg_train_sample_per_sec: 2602.8553819014073
avg_episode_per_sec: 8.697268894567278
collect_time: 1.2647648512823508
reward_mean: 1526.8547401658652
reward_std: 350.57423384016056
reward_max: 2151.498917190984
reward_min: 1150.0553473086127
total_envstep_count: 2820191
total_train_sample_count: 2181917
total_episode_count: 11165
total_duration: 737.2642031248371
[2023-06-29 10:23:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2714
train_sample_count: 2714
avg_envstep_per_episode: 246.72727272727272
avg_sample_per_episode: 246.72727272727272
avg_envstep_per_sec: 2550.0026494151857
avg_train_sample_per_sec: 2550.0026494151857
avg_episode_per_sec: 10.335309190702668
collect_time: 1.064312619683915
reward_mean: 1195.8134026739165
reward_std: 255.18468563995376
reward_max: 1694.716445382255
reward_min: 948.8403224939299
total_envstep_count: 2824863
total_train_sample_count: 2185431
total_episode_count: 11176
total_duration: 738.328515744521
[2023-06-29 10:23:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2502
train_sample_count: 2502
avg_envstep_per_episode: 312.75
avg_sample_per_episode: 312.75
avg_envstep_per_sec: 2808.486900381559
avg_train_sample_per_sec: 2808.486900381559
avg_episode_per_sec: 8.979974101939437
collect_time: 0.8908711661286653
reward_mean: 1831.7869898118865
reward_std: 669.713281302771
reward_max: 2761.8879458225606
reward_min: 750.2101334394085
total_envstep_count: 2829039
total_train_sample_count: 2188733
total_episode_count: 11184
total_duration: 739.2193869106497
[2023-06-29 10:23:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3465
train_sample_count: 3465
avg_envstep_per_episode: 247.5
avg_sample_per_episode: 247.5
avg_envstep_per_sec: 2613.765228656904
avg_train_sample_per_sec: 2613.765228656904
avg_episode_per_sec: 10.560667590532946
collect_time: 1.3256737682521345
reward_mean: 1334.1913694163627
reward_std: 558.3177792278501
reward_max: 2860.7986370435638
reward_min: 732.405598411588
total_envstep_count: 2833911
total_train_sample_count: 2192198
total_episode_count: 11198
total_duration: 740.5450606789019
[2023-06-29 10:23:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3329
train_sample_count: 3329
avg_envstep_per_episode: 277.4166666666667
avg_sample_per_episode: 277.4166666666667
avg_envstep_per_sec: 2575.0810477749596
avg_train_sample_per_sec: 2575.0810477749596
avg_episode_per_sec: 9.28235883847988
collect_time: 1.2927748440681026
reward_mean: 1361.3068009571775
reward_std: 502.00784420248544
reward_max: 2745.7472406030047
reward_min: 828.9302640696758
total_envstep_count: 2838031
total_train_sample_count: 2195527
total_episode_count: 11210
total_duration: 741.83783552297
[2023-06-29 10:23:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3417
train_sample_count: 3417
avg_envstep_per_episode: 244.07142857142858
avg_sample_per_episode: 244.07142857142858
avg_envstep_per_sec: 2604.4564593239097
avg_train_sample_per_sec: 2604.4564593239097
avg_episode_per_sec: 10.670878089123422
collect_time: 1.311982002143748
reward_mean: 1043.767324190124
reward_std: 237.212988869269
reward_max: 1517.9666464990275
reward_min: 726.9741941097061
total_envstep_count: 2843039
total_train_sample_count: 2198944
total_episode_count: 11224
total_duration: 743.1498175251137
[2023-06-29 10:23:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 200.4375
avg_sample_per_episode: 200.4375
avg_envstep_per_sec: 2725.626424409087
avg_train_sample_per_sec: 2725.626424409087
avg_episode_per_sec: 13.59838565342856
collect_time: 1.1766102541713046
reward_mean: 1021.7108183082468
reward_std: 268.7326766036069
reward_max: 1610.6640659127524
reward_min: 570.8070850164708
total_envstep_count: 2847327
total_train_sample_count: 2202151
total_episode_count: 11240
total_duration: 744.326427779285
[2023-06-29 10:23:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 248.46153846153845
avg_sample_per_episode: 248.46153846153845
avg_envstep_per_sec: 2602.196590165902
avg_train_sample_per_sec: 2602.196590165902
avg_episode_per_sec: 10.47323705020332
collect_time: 1.2412590240901333
reward_mean: 1153.3369442434416
reward_std: 242.5229676484882
reward_max: 1592.5375628382244
reward_min: 734.3284242176278
total_envstep_count: 2851631
total_train_sample_count: 2205381
total_episode_count: 11253
total_duration: 745.5676868033752
[2023-06-29 10:23:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 230.57142857142858
avg_sample_per_episode: 230.57142857142858
avg_envstep_per_sec: 2581.422826681025
avg_train_sample_per_sec: 2581.422826681025
avg_episode_per_sec: 11.195761949669873
collect_time: 1.2504731757370757
reward_mean: 1071.685770336014
reward_std: 215.680230021994
reward_max: 1381.013404854642
reward_min: 739.4332241959628
total_envstep_count: 2856423
total_train_sample_count: 2208609
total_episode_count: 11267
total_duration: 746.8181599791122
[2023-06-29 10:23:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2817
train_sample_count: 2817
avg_envstep_per_episode: 201.21428571428572
avg_sample_per_episode: 201.21428571428572
avg_envstep_per_sec: 2551.1613016812425
avg_train_sample_per_sec: 2551.1613016812425
avg_episode_per_sec: 12.678827910378912
collect_time: 1.104203014581464
reward_mean: 1058.9472459755664
reward_std: 302.49527364854447
reward_max: 1868.2662152104785
reward_min: 697.9098061328799
total_envstep_count: 2860767
total_train_sample_count: 2211826
total_episode_count: 11281
total_duration: 747.9223629936937
[2023-06-29 10:23:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1637
train_sample_count: 1637
avg_envstep_per_episode: 233.85714285714286
avg_sample_per_episode: 233.85714285714286
avg_envstep_per_sec: 2722.7923816773955
avg_train_sample_per_sec: 2722.7923816773955
avg_episode_per_sec: 11.642972921039565
collect_time: 0.6012210152400657
reward_mean: 1540.5315766614515
reward_std: 831.2816296884344
reward_max: 3404.5586470919384
reward_min: 918.7467330820797
total_envstep_count: 2864823
total_train_sample_count: 2215063
total_episode_count: 11288
total_duration: 748.5235840089338
[2023-06-29 10:23:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3125
train_sample_count: 3125
avg_envstep_per_episode: 240.3846153846154
avg_sample_per_episode: 240.3846153846154
avg_envstep_per_sec: 2634.7109419708927
avg_train_sample_per_sec: 2634.7109419708927
avg_episode_per_sec: 10.960397518598914
collect_time: 1.186088367501274
reward_mean: 1512.9031746366063
reward_std: 608.400283723931
reward_max: 2847.000476457614
reward_min: 786.5209112478016
total_envstep_count: 2869511
total_train_sample_count: 2218588
total_episode_count: 11301
total_duration: 749.709672376435
[2023-06-29 10:23:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 308.8181818181818
avg_sample_per_episode: 308.8181818181818
avg_envstep_per_sec: 2674.9384477045287
avg_train_sample_per_sec: 2674.9384477045287
avg_episode_per_sec: 8.661855438548665
collect_time: 1.2699357635369521
reward_mean: 1618.9740796088727
reward_std: 834.6142362769187
reward_max: 3465.3888034020197
reward_min: 766.8059076965175
total_envstep_count: 2874639
total_train_sample_count: 2221985
total_episode_count: 11312
total_duration: 750.979608139972
[2023-06-29 10:23:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2477
train_sample_count: 2477
avg_envstep_per_episode: 225.1818181818182
avg_sample_per_episode: 225.1818181818182
avg_envstep_per_sec: 2686.632283891951
avg_train_sample_per_sec: 2686.632283891951
avg_episode_per_sec: 11.930946759310238
collect_time: 0.9219720967588947
reward_mean: 1222.1932741494077
reward_std: 239.1582238214213
reward_max: 1511.0126780877104
reward_min: 765.9973942936948
total_envstep_count: 2879519
total_train_sample_count: 2225262
total_episode_count: 11323
total_duration: 751.9015802367309
[2023-06-29 10:24:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2894
train_sample_count: 2894
avg_envstep_per_episode: 206.71428571428572
avg_sample_per_episode: 206.71428571428572
avg_envstep_per_sec: 2651.3675711966625
avg_train_sample_per_sec: 2651.3675711966625
avg_episode_per_sec: 12.826242569714331
collect_time: 1.0915121808983386
reward_mean: 1417.6403105203178
reward_std: 678.3012489289466
reward_max: 3419.1352981507202
reward_min: 711.1140028699455
total_envstep_count: 2883319
total_train_sample_count: 2228556
total_episode_count: 11337
total_duration: 752.9930924176292
[2023-06-29 10:24:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2876
train_sample_count: 2876
avg_envstep_per_episode: 261.45454545454544
avg_sample_per_episode: 261.45454545454544
avg_envstep_per_sec: 2720.7527920990833
avg_train_sample_per_sec: 2720.7527920990833
avg_episode_per_sec: 10.40621721595616
collect_time: 1.0570603872397912
reward_mean: 1194.9319575246275
reward_std: 448.35896570228687
reward_max: 1979.6406589273265
reward_min: 603.4605983070942
total_envstep_count: 2887767
total_train_sample_count: 2231832
total_episode_count: 11348
total_duration: 754.050152804869
[2023-06-29 10:24:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2424
train_sample_count: 2424
avg_envstep_per_episode: 202.0
avg_sample_per_episode: 202.0
avg_envstep_per_sec: 2654.4673454414897
avg_train_sample_per_sec: 2654.4673454414897
avg_episode_per_sec: 13.140927452680643
collect_time: 0.9131775548728182
reward_mean: 1175.2161103931003
reward_std: 379.83092177486395
reward_max: 2152.0562617640344
reward_min: 758.2270868680297
total_envstep_count: 2891919
total_train_sample_count: 2235056
total_episode_count: 11360
total_duration: 754.9633303597418
[2023-06-29 10:24:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2166
train_sample_count: 2166
avg_envstep_per_episode: 216.6
avg_sample_per_episode: 216.6
avg_envstep_per_sec: 2726.6162076429036
avg_train_sample_per_sec: 2726.6162076429036
avg_episode_per_sec: 12.588255806292262
collect_time: 0.7943912289263683
reward_mean: 1350.4468679938768
reward_std: 294.8693451464167
reward_max: 1891.0865089444394
reward_min: 743.3545150695276
total_envstep_count: 2895935
total_train_sample_count: 2238422
total_episode_count: 11370
total_duration: 755.7577215886681
[2023-06-29 10:24:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2965
train_sample_count: 2965
avg_envstep_per_episode: 228.07692307692307
avg_sample_per_episode: 228.07692307692307
avg_envstep_per_sec: 2691.4361276012273
avg_train_sample_per_sec: 2691.4361276012273
avg_episode_per_sec: 11.800563122703526
collect_time: 1.1016423423886301
reward_mean: 1311.0210500009002
reward_std: 378.6232542761421
reward_max: 1888.7402300440367
reward_min: 749.1498327583183
total_envstep_count: 2900455
total_train_sample_count: 2241787
total_episode_count: 11383
total_duration: 756.8593639310568
[2023-06-29 10:24:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3267
train_sample_count: 3267
avg_envstep_per_episode: 217.8
avg_sample_per_episode: 217.8
avg_envstep_per_sec: 2530.079578944998
avg_train_sample_per_sec: 2530.079578944998
avg_episode_per_sec: 11.616526992401278
collect_time: 1.2912637322507798
reward_mean: 1134.7687030039333
reward_std: 326.4661419921499
reward_max: 1941.4649544582442
reward_min: 766.7308916056033
total_envstep_count: 2904879
total_train_sample_count: 2245054
total_episode_count: 11398
total_duration: 758.1506276633075
[2023-06-29 10:24:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3070
train_sample_count: 3070
avg_envstep_per_episode: 279.09090909090907
avg_sample_per_episode: 279.09090909090907
avg_envstep_per_sec: 2574.8998336670716
avg_train_sample_per_sec: 2574.8998336670716
avg_episode_per_sec: 9.226025462650746
collect_time: 1.1922793888365848
reward_mean: 1339.082188196391
reward_std: 543.6698067326503
reward_max: 2468.3259310590424
reward_min: 767.0325727899763
total_envstep_count: 2909271
total_train_sample_count: 2248524
total_episode_count: 11409
total_duration: 759.3429070521441
[2023-06-29 10:24:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2475
train_sample_count: 2475
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2566.526973063368
avg_train_sample_per_sec: 2566.526973063368
avg_episode_per_sec: 9.332825356594066
collect_time: 0.9643381994329392
reward_mean: 1377.2518383923848
reward_std: 773.7828158462547
reward_max: 3447.5656757639904
reward_min: 733.4368197733359
total_envstep_count: 2913911
total_train_sample_count: 2251799
total_episode_count: 11418
total_duration: 760.3072452515771
[2023-06-29 10:24:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1685
train_sample_count: 1685
avg_envstep_per_episode: 210.625
avg_sample_per_episode: 210.625
avg_envstep_per_sec: 2733.2507039860993
avg_train_sample_per_sec: 2733.2507039860993
avg_episode_per_sec: 12.976857941773766
collect_time: 0.6164820510400459
reward_mean: 1794.6937453265427
reward_std: 607.5197626596722
reward_max: 3066.61723479593
reward_min: 1192.1602854722876
total_envstep_count: 2918159
total_train_sample_count: 2255084
total_episode_count: 11426
total_duration: 760.9237273026172
[2023-06-29 10:24:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2831
train_sample_count: 2831
avg_envstep_per_episode: 217.76923076923077
avg_sample_per_episode: 217.76923076923077
avg_envstep_per_sec: 2512.013681319355
avg_train_sample_per_sec: 2512.013681319355
avg_episode_per_sec: 11.535209416160939
collect_time: 1.1269843078693376
reward_mean: 1457.6840486438427
reward_std: 556.2418288736008
reward_max: 2593.4665801691835
reward_min: 780.2715522313191
total_envstep_count: 2922543
total_train_sample_count: 2258315
total_episode_count: 11439
total_duration: 762.0507116104865
[2023-06-29 10:24:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 228.11111111111111
avg_sample_per_episode: 228.11111111111111
avg_envstep_per_sec: 2653.7557615060314
avg_train_sample_per_sec: 2653.7557615060314
avg_episode_per_sec: 11.633610255019136
collect_time: 0.7736205530967564
reward_mean: 1418.6231462625744
reward_std: 586.2343485288205
reward_max: 2804.608271817717
reward_min: 758.7390154269683
total_envstep_count: 2926967
total_train_sample_count: 2261568
total_episode_count: 11448
total_duration: 762.8243321635832
[2023-06-29 10:24:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1815
train_sample_count: 1815
avg_envstep_per_episode: 201.66666666666666
avg_sample_per_episode: 201.66666666666666
avg_envstep_per_sec: 2772.7363922458985
avg_train_sample_per_sec: 2772.7363922458985
avg_episode_per_sec: 13.749106077252389
collect_time: 0.6545880109900609
reward_mean: 1519.2937666914552
reward_std: 513.3511504632522
reward_max: 2615.969351652351
reward_min: 963.2527038401197
total_envstep_count: 2931255
total_train_sample_count: 2264983
total_episode_count: 11457
total_duration: 763.4789201745733
[2023-06-29 10:24:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2270
train_sample_count: 2270
avg_envstep_per_episode: 283.75
avg_sample_per_episode: 283.75
avg_envstep_per_sec: 2641.032545542617
avg_train_sample_per_sec: 2641.032545542617
avg_episode_per_sec: 9.307603684731689
collect_time: 0.8595123160565271
reward_mean: 2231.590003443597
reward_std: 997.9315018303475
reward_max: 3572.499792114494
reward_min: 1286.8483932721094
total_envstep_count: 2935527
total_train_sample_count: 2268453
total_episode_count: 11465
total_duration: 764.3384324906299
[2023-06-29 10:24:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2092
train_sample_count: 2092
avg_envstep_per_episode: 348.6666666666667
avg_sample_per_episode: 348.6666666666667
avg_envstep_per_sec: 2772.665544779969
avg_train_sample_per_sec: 2772.665544779969
avg_episode_per_sec: 7.952195635124194
collect_time: 0.7545086005553603
reward_mean: 2134.948187604188
reward_std: 658.5792742159754
reward_max: 3056.255038477002
reward_min: 1196.8037629607088
total_envstep_count: 2939207
total_train_sample_count: 2271745
total_episode_count: 11471
total_duration: 765.0929410911853
[2023-06-29 10:24:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2624.233544443751
avg_train_sample_per_sec: 2624.233544443751
avg_episode_per_sec: 9.338909410831853
collect_time: 0.4283155370755122
reward_mean: 2701.4841006758306
reward_std: 836.2942330380532
reward_max: 3520.269535844677
reward_min: 1547.8895138865173
total_envstep_count: 2943527
total_train_sample_count: 2275269
total_episode_count: 11475
total_duration: 765.5212566282607
[2023-06-29 10:24:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2848
train_sample_count: 2848
avg_envstep_per_episode: 284.8
avg_sample_per_episode: 284.8
avg_envstep_per_sec: 2583.3382515237663
avg_train_sample_per_sec: 2583.3382515237663
avg_episode_per_sec: 9.070710152822214
collect_time: 1.102449514042586
reward_mean: 2063.124970074548
reward_std: 775.0550548939484
reward_max: 3311.395556902088
reward_min: 1011.1758077997197
total_envstep_count: 2947919
total_train_sample_count: 2278517
total_episode_count: 11485
total_duration: 766.6237061423034
[2023-06-29 10:24:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1760
train_sample_count: 1760
avg_envstep_per_episode: 195.55555555555554
avg_sample_per_episode: 195.55555555555554
avg_envstep_per_sec: 2769.8127276341615
avg_train_sample_per_sec: 2769.8127276341615
avg_episode_per_sec: 14.163815084492871
collect_time: 0.6354220205722377
reward_mean: 1389.4951679245003
reward_std: 728.8739202909712
reward_max: 3419.21844083772
reward_min: 959.8672060570901
total_envstep_count: 2952631
total_train_sample_count: 2281877
total_episode_count: 11494
total_duration: 767.2591281628756
[2023-06-29 10:24:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2667
train_sample_count: 2667
avg_envstep_per_episode: 222.25
avg_sample_per_episode: 222.25
avg_envstep_per_sec: 2733.3872250114814
avg_train_sample_per_sec: 2733.3872250114814
avg_episode_per_sec: 12.298705174404866
collect_time: 0.9757124697137624
reward_mean: 1709.2706789888873
reward_std: 577.5607422031196
reward_max: 2749.930494142427
reward_min: 872.8834279888055
total_envstep_count: 2957391
total_train_sample_count: 2285344
total_episode_count: 11506
total_duration: 768.2348406325895
[2023-06-29 10:24:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 225.44444444444446
avg_sample_per_episode: 225.44444444444446
avg_envstep_per_sec: 2569.8699491448215
avg_train_sample_per_sec: 2569.8699491448215
avg_episode_per_sec: 11.399127423510791
collect_time: 0.7895341165708376
reward_mean: 1535.4771331378306
reward_std: 600.6118177859579
reward_max: 2502.773489846284
reward_min: 633.8116106010044
total_envstep_count: 2961935
total_train_sample_count: 2288573
total_episode_count: 11515
total_duration: 769.0243747491603
[2023-06-29 10:25:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1850
train_sample_count: 1850
avg_envstep_per_episode: 308.3333333333333
avg_sample_per_episode: 308.3333333333333
avg_envstep_per_sec: 2735.9155478535786
avg_train_sample_per_sec: 2735.9155478535786
avg_episode_per_sec: 8.873239614660255
collect_time: 0.6761904626227917
reward_mean: 2507.8252635241147
reward_std: 774.1610012722905
reward_max: 3453.76883956611
reward_min: 1504.1609930719055
total_envstep_count: 2966423
total_train_sample_count: 2292023
total_episode_count: 11521
total_duration: 769.7005652117831
[2023-06-29 10:25:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2585
train_sample_count: 2585
avg_envstep_per_episode: 258.5
avg_sample_per_episode: 258.5
avg_envstep_per_sec: 2552.0287144375748
avg_train_sample_per_sec: 2552.0287144375748
avg_episode_per_sec: 9.872451506528336
collect_time: 1.0129196373755112
reward_mean: 1965.020053478093
reward_std: 952.6013320042105
reward_max: 3498.406640907599
reward_min: 964.6542208227191
total_envstep_count: 2971327
total_train_sample_count: 2295408
total_episode_count: 11531
total_duration: 770.7134848491586
[2023-06-29 10:25:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 271.1111111111111
avg_sample_per_episode: 271.1111111111111
avg_envstep_per_sec: 2742.783745469901
avg_train_sample_per_sec: 2742.783745469901
avg_episode_per_sec: 10.116825290667668
collect_time: 0.8896071387436244
reward_mean: 1872.296628519465
reward_std: 755.1257675286514
reward_max: 3045.4178368929297
reward_min: 742.744147226589
total_envstep_count: 2975871
total_train_sample_count: 2298648
total_episode_count: 11540
total_duration: 771.6030919879022
[2023-06-29 10:25:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1276
train_sample_count: 1276
avg_envstep_per_episode: 159.5
avg_sample_per_episode: 159.5
avg_envstep_per_sec: 2529.2539828349713
avg_train_sample_per_sec: 2529.2539828349713
avg_episode_per_sec: 15.857391741912046
collect_time: 0.5044965862106765
reward_mean: 1388.9658034367155
reward_std: 422.31912139606857
reward_max: 2305.894780572034
reward_min: 924.9654945880203
total_envstep_count: 2979951
total_train_sample_count: 2301924
total_episode_count: 11548
total_duration: 772.1075885741128
[2023-06-29 10:25:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2103
train_sample_count: 2103
avg_envstep_per_episode: 233.66666666666666
avg_sample_per_episode: 233.66666666666666
avg_envstep_per_sec: 2573.399527106339
avg_train_sample_per_sec: 2573.399527106339
avg_episode_per_sec: 11.013122084620568
collect_time: 0.8172069582855328
reward_mean: 1780.7404180572494
reward_std: 939.9781994060137
reward_max: 3509.139253972901
reward_min: 361.5338578806242
total_envstep_count: 2984063
total_train_sample_count: 2305227
total_episode_count: 11557
total_duration: 772.9247955323983
[2023-06-29 10:25:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 821
train_sample_count: 821
avg_envstep_per_episode: 205.25
avg_sample_per_episode: 205.25
avg_envstep_per_sec: 2769.804912231817
avg_train_sample_per_sec: 2769.804912231817
avg_episode_per_sec: 13.494786417694602
collect_time: 0.2964107675505801
reward_mean: 2310.528592833951
reward_std: 656.3398480614452
reward_max: 3416.241491855381
reward_min: 1791.4229509387833
total_envstep_count: 2988119
total_train_sample_count: 2308448
total_episode_count: 11561
total_duration: 773.2212062999489
[2023-06-29 10:25:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2765.871920255546
avg_train_sample_per_sec: 2765.871920255546
avg_episode_per_sec: 10.997502665031991
collect_time: 0.7274378778226673
reward_mean: 2345.787440208072
reward_std: 895.3829976400651
reward_max: 3470.004959964129
reward_min: 1300.970775504513
total_envstep_count: 2992063
total_train_sample_count: 2311660
total_episode_count: 11569
total_duration: 773.9486441777716
[2023-06-29 10:25:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1901
train_sample_count: 1901
avg_envstep_per_episode: 237.625
avg_sample_per_episode: 237.625
avg_envstep_per_sec: 2535.5963891884157
avg_train_sample_per_sec: 2535.5963891884157
avg_episode_per_sec: 10.670579228567767
collect_time: 0.7497249988624826
reward_mean: 1881.116475991637
reward_std: 1029.0831443933841
reward_max: 3490.9171803160384
reward_min: 687.577804944384
total_envstep_count: 2997095
total_train_sample_count: 2315161
total_episode_count: 11577
total_duration: 774.6983691766341
[2023-06-29 10:25:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1681
train_sample_count: 1681
avg_envstep_per_episode: 240.14285714285714
avg_sample_per_episode: 240.14285714285714
avg_envstep_per_sec: 2450.8430150248114
avg_train_sample_per_sec: 2450.8430150248114
avg_episode_per_sec: 10.205771032227055
collect_time: 0.6858864438459279
reward_mean: 2012.1513372542727
reward_std: 990.3935614919931
reward_max: 3477.678604664594
reward_min: 973.647722476289
total_envstep_count: 3000863
total_train_sample_count: 2318442
total_episode_count: 11584
total_duration: 775.38425562048
[2023-06-29 10:25:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1813
train_sample_count: 1813
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2696.1328603872407
avg_train_sample_per_sec: 2696.1328603872407
avg_episode_per_sec: 10.40977938373452
collect_time: 0.6724446063609796
reward_mean: 2273.810108267289
reward_std: 1044.849999350154
reward_max: 3497.931145081026
reward_min: 1060.9330074124086
total_envstep_count: 3005711
total_train_sample_count: 2322255
total_episode_count: 11591
total_duration: 776.0567002268409
[2023-06-29 10:25:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1704
train_sample_count: 1704
avg_envstep_per_episode: 243.42857142857142
avg_sample_per_episode: 243.42857142857142
avg_envstep_per_sec: 2809.6148925852353
avg_train_sample_per_sec: 2809.6148925852353
avg_episode_per_sec: 11.541845216019158
collect_time: 0.606488812576048
reward_mean: 2205.412179189244
reward_std: 990.7885758875908
reward_max: 3591.3289603676612
reward_min: 1020.0924888334227
total_envstep_count: 3010447
total_train_sample_count: 2325559
total_episode_count: 11598
total_duration: 776.6631890394169
[2023-06-29 10:25:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2475
train_sample_count: 2475
avg_envstep_per_episode: 225.0
avg_sample_per_episode: 225.0
avg_envstep_per_sec: 2527.838926276978
avg_train_sample_per_sec: 2527.838926276978
avg_episode_per_sec: 11.234839672342124
collect_time: 0.9790971941575409
reward_mean: 1893.2379068526961
reward_std: 933.1700627506192
reward_max: 3453.9604194375815
reward_min: 353.5171380411427
total_envstep_count: 3015079
total_train_sample_count: 2328834
total_episode_count: 11609
total_duration: 777.6422862335745
[2023-06-29 10:25:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2906
train_sample_count: 2906
avg_envstep_per_episode: 264.1818181818182
avg_sample_per_episode: 264.1818181818182
avg_envstep_per_sec: 2581.9910053394456
avg_train_sample_per_sec: 2581.9910053394456
avg_episode_per_sec: 9.773537872929767
collect_time: 1.1254880415890365
reward_mean: 1616.0440619839233
reward_std: 822.9875999210369
reward_max: 3355.212013773266
reward_min: 291.0414687240878
total_envstep_count: 3019399
total_train_sample_count: 2332140
total_episode_count: 11620
total_duration: 778.7677742751636
[2023-06-29 10:25:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 236.91666666666666
avg_sample_per_episode: 236.91666666666666
avg_envstep_per_sec: 2611.83780103791
avg_train_sample_per_sec: 2611.83780103791
avg_episode_per_sec: 11.024288994883896
collect_time: 1.0885055721569805
reward_mean: 1255.0234220168636
reward_std: 314.3316213768417
reward_max: 1678.147512150641
reward_min: 753.0507019480874
total_envstep_count: 3024199
total_train_sample_count: 2335383
total_episode_count: 11632
total_duration: 779.8562798473206
[2023-06-29 10:25:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 219.9
avg_sample_per_episode: 219.9
avg_envstep_per_sec: 2431.748260775875
avg_train_sample_per_sec: 2431.748260775875
avg_episode_per_sec: 11.058427743410075
collect_time: 0.904287682845257
reward_mean: 1344.4446421433308
reward_std: 426.8282251064149
reward_max: 2265.0508281104867
reward_min: 838.6886563523599
total_envstep_count: 3028687
total_train_sample_count: 2338782
total_episode_count: 11642
total_duration: 780.7605675301659
[2023-06-29 10:25:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2932
train_sample_count: 2932
avg_envstep_per_episode: 244.33333333333334
avg_sample_per_episode: 244.33333333333334
avg_envstep_per_sec: 2700.8769669250782
avg_train_sample_per_sec: 2700.8769669250782
avg_episode_per_sec: 11.054066713199502
collect_time: 1.0855733289243652
reward_mean: 1582.759308876057
reward_std: 698.6965063950847
reward_max: 3382.324427801706
reward_min: 672.414423649768
total_envstep_count: 3032663
total_train_sample_count: 2342114
total_episode_count: 11654
total_duration: 781.8461408590903
[2023-06-29 10:25:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 320.3
avg_sample_per_episode: 320.3
avg_envstep_per_sec: 2648.3226661005365
avg_train_sample_per_sec: 2648.3226661005365
avg_episode_per_sec: 8.26825684077595
collect_time: 1.20944477083534
reward_mean: 1506.4872158846931
reward_std: 708.9036480291433
reward_max: 3440.725488300754
reward_min: 920.8841123036823
total_envstep_count: 3036855
total_train_sample_count: 2345317
total_episode_count: 11664
total_duration: 783.0555856299256
[2023-06-29 10:25:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3279
train_sample_count: 3279
avg_envstep_per_episode: 298.09090909090907
avg_sample_per_episode: 298.09090909090907
avg_envstep_per_sec: 2477.2792530112215
avg_train_sample_per_sec: 2477.2792530112215
avg_episode_per_sec: 8.310482398024837
collect_time: 1.3236295407610015
reward_mean: 1355.6208968587057
reward_std: 469.06357841662447
reward_max: 2118.2806790435993
reward_min: 665.9453238211546
total_envstep_count: 3041615
total_train_sample_count: 2348596
total_episode_count: 11675
total_duration: 784.3792151706866
[2023-06-29 10:25:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3167
train_sample_count: 3167
avg_envstep_per_episode: 263.9166666666667
avg_sample_per_episode: 263.9166666666667
avg_envstep_per_sec: 2514.280147571622
avg_train_sample_per_sec: 2514.280147571622
avg_episode_per_sec: 9.526795633362633
collect_time: 1.2596050615357233
reward_mean: 1374.1114589171405
reward_std: 388.66336592761036
reward_max: 2221.822346420088
reward_min: 851.1895932579292
total_envstep_count: 3046655
total_train_sample_count: 2352163
total_episode_count: 11687
total_duration: 785.6388202322223
[2023-06-29 10:25:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3295
train_sample_count: 3295
avg_envstep_per_episode: 235.35714285714286
avg_sample_per_episode: 235.35714285714286
avg_envstep_per_sec: 2753.7035462752688
avg_train_sample_per_sec: 2753.7035462752688
avg_episode_per_sec: 11.70010611467489
collect_time: 1.1965703441305084
reward_mean: 1285.9361770051516
reward_std: 602.3600152682485
reward_max: 2390.5265220503516
reward_min: 675.1792277317389
total_envstep_count: 3051007
total_train_sample_count: 2355458
total_episode_count: 11701
total_duration: 786.8353905763528
[2023-06-29 10:26:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2508
train_sample_count: 2508
avg_envstep_per_episode: 278.6666666666667
avg_sample_per_episode: 278.6666666666667
avg_envstep_per_sec: 2509.7887065478194
avg_train_sample_per_sec: 2509.7887065478194
avg_episode_per_sec: 9.006418803401266
collect_time: 0.9992873079143464
reward_mean: 1216.3179413348382
reward_std: 318.12122311946274
reward_max: 1809.8392082376856
reward_min: 689.3037102737682
total_envstep_count: 3054983
total_train_sample_count: 2358766
total_episode_count: 11710
total_duration: 787.8346778842671
[2023-06-29 10:26:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 254.63636363636363
avg_sample_per_episode: 254.63636363636363
avg_envstep_per_sec: 2527.3143408657406
avg_train_sample_per_sec: 2527.3143408657406
avg_episode_per_sec: 9.925190199758353
collect_time: 1.1082911036070437
reward_mean: 1434.1079842114889
reward_std: 991.5386306483138
reward_max: 3469.233822568219
reward_min: 634.1758018090364
total_envstep_count: 3059239
total_train_sample_count: 2361967
total_episode_count: 11721
total_duration: 788.9429689878741
[2023-06-29 10:26:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2491
train_sample_count: 2491
avg_envstep_per_episode: 311.375
avg_sample_per_episode: 311.375
avg_envstep_per_sec: 2763.988832355623
avg_train_sample_per_sec: 2763.988832355623
avg_episode_per_sec: 8.876720457183854
collect_time: 0.901233742640354
reward_mean: 1745.7798966134542
reward_std: 529.5270140036969
reward_max: 2575.9649442532805
reward_min: 957.796601460663
total_envstep_count: 3063095
total_train_sample_count: 2365258
total_episode_count: 11729
total_duration: 789.8442027305144
[2023-06-29 10:26:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 2744.2400866363823
avg_train_sample_per_sec: 2744.2400866363823
avg_episode_per_sec: 13.353966358327895
collect_time: 0.5990729484660551
reward_mean: 1247.014895174221
reward_std: 582.6920491549395
reward_max: 2465.3874409094856
reward_min: 654.5812621934347
total_envstep_count: 3067023
total_train_sample_count: 2368502
total_episode_count: 11737
total_duration: 790.4432756789805
[2023-06-29 10:26:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2548
train_sample_count: 2548
avg_envstep_per_episode: 254.8
avg_sample_per_episode: 254.8
avg_envstep_per_sec: 2644.4570092581384
avg_train_sample_per_sec: 2644.4570092581384
avg_episode_per_sec: 10.378559690966005
collect_time: 0.9635248336726798
reward_mean: 1663.9658395482195
reward_std: 1116.0211222154578
reward_max: 3467.9222854324353
reward_min: 645.4278981962933
total_envstep_count: 3071639
total_train_sample_count: 2371850
total_episode_count: 11747
total_duration: 791.4068005126531
[2023-06-29 10:26:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2524
train_sample_count: 2524
avg_envstep_per_episode: 210.33333333333334
avg_sample_per_episode: 210.33333333333334
avg_envstep_per_sec: 2779.1494068103507
avg_train_sample_per_sec: 2779.1494068103507
avg_episode_per_sec: 13.213071664708483
collect_time: 0.9081915473183618
reward_mean: 1237.0614249651085
reward_std: 622.9459769040866
reward_max: 2510.419669919649
reward_min: 696.7773767699631
total_envstep_count: 3076431
total_train_sample_count: 2375174
total_episode_count: 11759
total_duration: 792.3149920599715
[2023-06-29 10:26:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2924
train_sample_count: 2924
avg_envstep_per_episode: 194.93333333333334
avg_sample_per_episode: 194.93333333333334
avg_envstep_per_sec: 2675.9558978209216
avg_train_sample_per_sec: 2675.9558978209216
avg_episode_per_sec: 13.727543935469843
collect_time: 1.0926936435615644
reward_mean: 1184.3557709138865
reward_std: 750.1459701873807
reward_max: 3511.2829611653965
reward_min: 504.01486563556125
total_envstep_count: 3081207
total_train_sample_count: 2378498
total_episode_count: 11774
total_duration: 793.407685703533
[2023-06-29 10:26:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2398
train_sample_count: 2398
avg_envstep_per_episode: 266.44444444444446
avg_sample_per_episode: 266.44444444444446
avg_envstep_per_sec: 2725.165133617815
avg_train_sample_per_sec: 2725.165133617815
avg_episode_per_sec: 10.227892494812483
collect_time: 0.8799466756777838
reward_mean: 1498.4551379489192
reward_std: 998.9450016648814
reward_max: 3406.7604157584915
reward_min: 486.7825427301516
total_envstep_count: 3086159
total_train_sample_count: 2382096
total_episode_count: 11783
total_duration: 794.2876323792108
[2023-06-29 10:26:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3412
train_sample_count: 3412
avg_envstep_per_episode: 227.46666666666667
avg_sample_per_episode: 227.46666666666667
avg_envstep_per_sec: 2566.5242692652705
avg_train_sample_per_sec: 2566.5242692652705
avg_episode_per_sec: 11.283078557731258
collect_time: 1.3294244051612913
reward_mean: 1383.562537691253
reward_std: 752.2184243519636
reward_max: 3055.484127163578
reward_min: 498.8100887600995
total_envstep_count: 3090887
total_train_sample_count: 2385508
total_episode_count: 11798
total_duration: 795.617056784372
[2023-06-29 10:26:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2547
train_sample_count: 2547
avg_envstep_per_episode: 231.54545454545453
avg_sample_per_episode: 231.54545454545453
avg_envstep_per_sec: 2542.928421378044
avg_train_sample_per_sec: 2542.928421378044
avg_episode_per_sec: 10.982415640030814
collect_time: 1.0016011377228422
reward_mean: 1141.1989158973913
reward_std: 250.54332356458525
reward_max: 1511.9478273673176
reward_min: 682.9806768558948
total_envstep_count: 3095583
total_train_sample_count: 2388855
total_episode_count: 11809
total_duration: 796.6186579220948
[2023-06-29 10:26:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2151
train_sample_count: 2151
avg_envstep_per_episode: 195.54545454545453
avg_sample_per_episode: 195.54545454545453
avg_envstep_per_sec: 2700.162702498158
avg_train_sample_per_sec: 2700.162702498158
avg_episode_per_sec: 13.808363425141673
collect_time: 0.7966186622790992
reward_mean: 1171.0109222269193
reward_std: 726.3569708606235
reward_max: 2826.983817752345
reward_min: 345.93578224160825
total_envstep_count: 3099919
total_train_sample_count: 2392206
total_episode_count: 11820
total_duration: 797.4152765843739
[2023-06-29 10:26:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2618
train_sample_count: 2618
avg_envstep_per_episode: 201.3846153846154
avg_sample_per_episode: 201.3846153846154
avg_envstep_per_sec: 2778.8448266793375
avg_train_sample_per_sec: 2778.8448266793375
avg_episode_per_sec: 13.798694708491745
collect_time: 0.9421180970110001
reward_mean: 1183.2036466156374
reward_std: 867.7112905592215
reward_max: 3246.399235938009
reward_min: 276.5093079289564
total_envstep_count: 3104159
total_train_sample_count: 2395624
total_episode_count: 11833
total_duration: 798.3573946813849
[2023-06-29 10:26:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 274.44444444444446
avg_sample_per_episode: 274.44444444444446
avg_envstep_per_sec: 2745.7388341885135
avg_train_sample_per_sec: 2745.7388341885135
avg_episode_per_sec: 10.004716399877175
collect_time: 0.8995757241165268
reward_mean: 1314.3721737107223
reward_std: 616.3597085739422
reward_max: 2364.37401066333
reward_min: 398.18640358995606
total_envstep_count: 3108383
total_train_sample_count: 2398894
total_episode_count: 11842
total_duration: 799.2569704055014
[2023-06-29 10:26:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2435
train_sample_count: 2435
avg_envstep_per_episode: 221.36363636363637
avg_sample_per_episode: 221.36363636363637
avg_envstep_per_sec: 2562.5740096206664
avg_train_sample_per_sec: 2562.5740096206664
avg_episode_per_sec: 11.57630969438494
collect_time: 0.9502164584742858
reward_mean: 1194.9158572446038
reward_std: 807.2024953906083
reward_max: 3223.5788621168062
reward_min: 280.7354432193267
total_envstep_count: 3112351
total_train_sample_count: 2402129
total_episode_count: 11853
total_duration: 800.2071868639757
[2023-06-29 10:26:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2181
train_sample_count: 2181
avg_envstep_per_episode: 181.75
avg_sample_per_episode: 181.75
avg_envstep_per_sec: 2717.772380086368
avg_train_sample_per_sec: 2717.772380086368
avg_episode_per_sec: 14.953355598824581
collect_time: 0.8024954613493755
reward_mean: 966.7293709291986
reward_std: 740.5030072372612
reward_max: 3141.341856104457
reward_min: 405.6659626495344
total_envstep_count: 3116767
total_train_sample_count: 2405510
total_episode_count: 11865
total_duration: 801.0096823253251
[2023-06-29 10:26:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2946
train_sample_count: 2946
avg_envstep_per_episode: 226.6153846153846
avg_sample_per_episode: 226.6153846153846
avg_envstep_per_sec: 2671.5871962019637
avg_train_sample_per_sec: 2671.5871962019637
avg_episode_per_sec: 11.789081313857952
collect_time: 1.1027152713518589
reward_mean: 1338.8184344833696
reward_std: 1016.8693625749944
reward_max: 3336.8919178445562
reward_min: 395.316431185464
total_envstep_count: 3121191
total_train_sample_count: 2408856
total_episode_count: 11878
total_duration: 802.1123975966769
[2023-06-29 10:26:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3295
train_sample_count: 3295
avg_envstep_per_episode: 299.54545454545456
avg_sample_per_episode: 299.54545454545456
avg_envstep_per_sec: 2717.1933978787415
avg_train_sample_per_sec: 2717.1933978787415
avg_episode_per_sec: 9.071055349519318
collect_time: 1.2126483166683464
reward_mean: 1420.3356916712742
reward_std: 646.9484758532827
reward_max: 3140.494011678566
reward_min: 873.2794771764418
total_envstep_count: 3125799
total_train_sample_count: 2412151
total_episode_count: 11889
total_duration: 803.3250459133453
[2023-06-29 10:26:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2856
train_sample_count: 2856
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 2639.38234457071
avg_train_sample_per_sec: 2639.38234457071
avg_episode_per_sec: 11.089841783910545
collect_time: 1.0820713436516234
reward_mean: 1173.1595275269117
reward_std: 403.45023130117215
reward_max: 2016.369869727756
reward_min: 756.2270691793548
total_envstep_count: 3129871
total_train_sample_count: 2415407
total_episode_count: 11901
total_duration: 804.4071172569969
[2023-06-29 10:26:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1664
train_sample_count: 1664
avg_envstep_per_episode: 184.88888888888889
avg_sample_per_episode: 184.88888888888889
avg_envstep_per_sec: 2730.9741750710728
avg_train_sample_per_sec: 2730.9741750710728
avg_episode_per_sec: 14.770893975744984
collect_time: 0.6093063842160628
reward_mean: 778.1918665135327
reward_std: 302.41616541480676
reward_max: 1282.4445509509771
reward_min: 171.8537321161665
total_envstep_count: 3134295
total_train_sample_count: 2418671
total_episode_count: 11910
total_duration: 805.016423641213
[2023-06-29 10:27:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1604
train_sample_count: 1604
avg_envstep_per_episode: 178.22222222222223
avg_sample_per_episode: 178.22222222222223
avg_envstep_per_sec: 2684.018094143943
avg_train_sample_per_sec: 2684.018094143943
avg_episode_per_sec: 15.059951899810153
collect_time: 0.5976114704664797
reward_mean: 1511.710664517818
reward_std: 1134.0591142972046
reward_max: 3378.08750965074
reward_min: 523.1820189992142
total_envstep_count: 3138471
total_train_sample_count: 2421875
total_episode_count: 11919
total_duration: 805.6140351116795
[2023-06-29 10:27:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2423
train_sample_count: 2423
avg_envstep_per_episode: 186.3846153846154
avg_sample_per_episode: 186.3846153846154
avg_envstep_per_sec: 2732.2185668154166
avg_train_sample_per_sec: 2732.2185668154166
avg_episode_per_sec: 14.659034819892865
collect_time: 0.8868250986319036
reward_mean: 1439.369521113931
reward_std: 960.7124896691564
reward_max: 3336.9719168285783
reward_min: 690.2935689801153
total_envstep_count: 3142599
total_train_sample_count: 2425098
total_episode_count: 11932
total_duration: 806.5008602103114
[2023-06-29 10:27:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 225.92307692307693
avg_sample_per_episode: 225.92307692307693
avg_envstep_per_sec: 2671.832626582691
avg_train_sample_per_sec: 2671.832626582691
avg_episode_per_sec: 11.826293546331284
collect_time: 1.0992455031722783
reward_mean: 1191.2677738428226
reward_std: 750.5880579146987
reward_max: 3403.3309766740385
reward_min: 652.224921241341
total_envstep_count: 3147615
total_train_sample_count: 2428435
total_episode_count: 11945
total_duration: 807.6001057134837
[2023-06-29 10:27:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 187.92307692307693
avg_sample_per_episode: 187.92307692307693
avg_envstep_per_sec: 2704.095995432451
avg_train_sample_per_sec: 2704.095995432451
avg_episode_per_sec: 14.389376971191922
collect_time: 0.9034442579429598
reward_mean: 1100.9819465147214
reward_std: 837.7210069102711
reward_max: 3393.1135552561313
reward_min: 182.88081783582172
total_envstep_count: 3151463
total_train_sample_count: 2431678
total_episode_count: 11958
total_duration: 808.5035499714267
[2023-06-29 10:27:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 19
envstep_count: 3344
train_sample_count: 3344
avg_envstep_per_episode: 176.0
avg_sample_per_episode: 176.0
avg_envstep_per_sec: 2771.000484225631
avg_train_sample_per_sec: 2771.000484225631
avg_episode_per_sec: 15.744320933100177
collect_time: 1.206784343429841
reward_mean: 902.2878661697721
reward_std: 628.6416307976558
reward_max: 3197.295074089782
reward_min: 448.72695198587076
total_envstep_count: 3156215
total_train_sample_count: 2435022
total_episode_count: 11977
total_duration: 809.7103343148565
[2023-06-29 10:27:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 217.6153846153846
avg_sample_per_episode: 217.6153846153846
avg_envstep_per_sec: 2528.323762524779
avg_train_sample_per_sec: 2528.323762524779
avg_episode_per_sec: 11.618313507536984
collect_time: 1.1189231545152138
reward_mean: 1083.4364253143044
reward_std: 559.7743322954353
reward_max: 2307.3196749235244
reward_min: 511.8654218784988
total_envstep_count: 3160239
total_train_sample_count: 2438251
total_episode_count: 11990
total_duration: 810.8292574693717
[2023-06-29 10:27:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3291
train_sample_count: 3291
avg_envstep_per_episode: 235.07142857142858
avg_sample_per_episode: 235.07142857142858
avg_envstep_per_sec: 2553.431142543147
avg_train_sample_per_sec: 2553.431142543147
avg_episode_per_sec: 10.862362806321501
collect_time: 1.2888540227962657
reward_mean: 1112.7860663279212
reward_std: 699.1756224231214
reward_max: 3180.5153276368437
reward_min: 695.6147147499296
total_envstep_count: 3164287
total_train_sample_count: 2441542
total_episode_count: 12004
total_duration: 812.1181114921679
[2023-06-29 10:27:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2558
train_sample_count: 2558
avg_envstep_per_episode: 213.16666666666666
avg_sample_per_episode: 213.16666666666666
avg_envstep_per_sec: 2522.4509671555784
avg_train_sample_per_sec: 2522.4509671555784
avg_episode_per_sec: 11.833233622309203
collect_time: 1.0140930520780382
reward_mean: 887.2577089237692
reward_std: 306.9564048719535
reward_max: 1643.03844590711
reward_min: 676.4999961529624
total_envstep_count: 3168215
total_train_sample_count: 2444900
total_episode_count: 12016
total_duration: 813.132204544246
[2023-06-29 10:27:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2345
train_sample_count: 2345
avg_envstep_per_episode: 213.1818181818182
avg_sample_per_episode: 213.1818181818182
avg_envstep_per_sec: 2766.0860626965928
avg_train_sample_per_sec: 2766.0860626965928
avg_episode_per_sec: 12.975243790900862
collect_time: 0.8477682714303958
reward_mean: 1167.2819492701367
reward_std: 735.8780119010838
reward_max: 2870.126830229546
reward_min: 558.4478331382487
total_envstep_count: 3172951
total_train_sample_count: 2448445
total_episode_count: 12027
total_duration: 813.9799728156763
[2023-06-29 10:27:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1774
train_sample_count: 1774
avg_envstep_per_episode: 221.75
avg_sample_per_episode: 221.75
avg_envstep_per_sec: 2497.3029166113683
avg_train_sample_per_sec: 2497.3029166113683
avg_episode_per_sec: 11.261794437931764
collect_time: 0.7103663669312371
reward_mean: 1646.9491827727848
reward_std: 718.1424803726362
reward_max: 2504.560506146507
reward_min: 657.7461537480511
total_envstep_count: 3177375
total_train_sample_count: 2451819
total_episode_count: 12035
total_duration: 814.6903391826075
[2023-06-29 10:27:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 197.53333333333333
avg_sample_per_episode: 197.53333333333333
avg_envstep_per_sec: 2622.1720995238074
avg_train_sample_per_sec: 2622.1720995238074
avg_episode_per_sec: 13.274580321585256
collect_time: 1.1299792262064292
reward_mean: 1367.3667788490518
reward_std: 861.892382340212
reward_max: 3522.6677517270546
reward_min: 534.9375634851007
total_envstep_count: 3181959
total_train_sample_count: 2455182
total_episode_count: 12050
total_duration: 815.8203184088139
[2023-06-29 10:27:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3348
train_sample_count: 3348
avg_envstep_per_episode: 239.14285714285714
avg_sample_per_episode: 239.14285714285714
avg_envstep_per_sec: 2645.285544826974
avg_train_sample_per_sec: 2645.285544826974
avg_episode_per_sec: 11.061528562597859
collect_time: 1.2656478641964493
reward_mean: 1193.039832377801
reward_std: 728.9065383933369
reward_max: 3047.3595652738923
reward_min: 504.2048481316332
total_envstep_count: 3186135
total_train_sample_count: 2458530
total_episode_count: 12064
total_duration: 817.0859662730104
[2023-06-29 10:27:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 246.76923076923077
avg_sample_per_episode: 246.76923076923077
avg_envstep_per_sec: 2595.304625094658
avg_train_sample_per_sec: 2595.304625094658
avg_episode_per_sec: 10.517132208924735
collect_time: 1.2360784044312314
reward_mean: 1036.487112396182
reward_std: 451.1368328529054
reward_max: 1831.4895230792404
reward_min: 490.6660583573831
total_envstep_count: 3190231
total_train_sample_count: 2461738
total_episode_count: 12077
total_duration: 818.3220446774417
[2023-06-29 10:27:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3443
train_sample_count: 3443
avg_envstep_per_episode: 264.84615384615387
avg_sample_per_episode: 264.84615384615387
avg_envstep_per_sec: 2634.0294013112834
avg_train_sample_per_sec: 2634.0294013112834
avg_episode_per_sec: 9.945507469371679
collect_time: 1.307122843156569
reward_mean: 1120.8244590557365
reward_std: 383.32054472699053
reward_max: 1890.6539595204738
reward_min: 655.4804132526996
total_envstep_count: 3194927
total_train_sample_count: 2465181
total_episode_count: 12090
total_duration: 819.6291675205982
[2023-06-29 10:27:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2567
train_sample_count: 2567
avg_envstep_per_episode: 213.91666666666666
avg_sample_per_episode: 213.91666666666666
avg_envstep_per_sec: 2507.154083476398
avg_train_sample_per_sec: 2507.154083476398
avg_episode_per_sec: 11.72023724258542
collect_time: 1.023870059250854
reward_mean: 1056.2186348604764
reward_std: 348.99987332398234
reward_max: 1659.310445072622
reward_min: 487.3562154647248
total_envstep_count: 3199375
total_train_sample_count: 2468548
total_episode_count: 12102
total_duration: 820.6530375798491
[2023-06-29 10:27:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2913
train_sample_count: 2913
avg_envstep_per_episode: 264.8181818181818
avg_sample_per_episode: 264.8181818181818
avg_envstep_per_sec: 2781.6115504129903
avg_train_sample_per_sec: 2781.6115504129903
avg_episode_per_sec: 10.503854121023993
collect_time: 1.0472346505634484
reward_mean: 1458.4415711646632
reward_std: 795.2712496459739
reward_max: 3218.3413810651014
reward_min: 690.3401006377981
total_envstep_count: 3203335
total_train_sample_count: 2471861
total_episode_count: 12113
total_duration: 821.7002722304126
[2023-06-29 10:27:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2883
train_sample_count: 2883
avg_envstep_per_episode: 288.3
avg_sample_per_episode: 288.3
avg_envstep_per_sec: 2524.832593788824
avg_train_sample_per_sec: 2524.832593788824
avg_episode_per_sec: 8.757657279877987
collect_time: 1.1418578828126191
reward_mean: 1354.3901019235523
reward_std: 760.2394924083494
reward_max: 3369.8967781487536
reward_min: 731.7257888375246
total_envstep_count: 3207639
total_train_sample_count: 2475144
total_episode_count: 12123
total_duration: 822.8421301132252
[2023-06-29 10:27:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2279
train_sample_count: 2279
avg_envstep_per_episode: 284.875
avg_sample_per_episode: 284.875
avg_envstep_per_sec: 2776.5676361362625
avg_train_sample_per_sec: 2776.5676361362625
avg_episode_per_sec: 9.746617415133874
collect_time: 0.8207975812796501
reward_mean: 1446.477347311595
reward_std: 597.6907094863234
reward_max: 2573.5261533926423
reward_min: 671.4617761185156
total_envstep_count: 3212055
total_train_sample_count: 2478623
total_episode_count: 12131
total_duration: 823.6629276945048
[2023-06-29 10:27:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2170
train_sample_count: 2170
avg_envstep_per_episode: 217.0
avg_sample_per_episode: 217.0
avg_envstep_per_sec: 2538.175340581196
avg_train_sample_per_sec: 2538.175340581196
avg_episode_per_sec: 11.696660555673715
collect_time: 0.8549448752831668
reward_mean: 1569.9446437904928
reward_std: 867.3131674034333
reward_max: 3358.3411891150536
reward_min: 611.0175727786725
total_envstep_count: 3216431
total_train_sample_count: 2481993
total_episode_count: 12141
total_duration: 824.517872569788
[2023-06-29 10:27:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2840
train_sample_count: 2840
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2580.182633327161
avg_train_sample_per_sec: 2580.182633327161
avg_episode_per_sec: 9.085150117349158
collect_time: 1.100697277517058
reward_mean: 1718.2592008959332
reward_std: 891.4857432232914
reward_max: 3418.883896858847
reward_min: 634.7145002774035
total_envstep_count: 3220487
total_train_sample_count: 2485233
total_episode_count: 12151
total_duration: 825.618569847305
[2023-06-29 10:27:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2509
train_sample_count: 2509
avg_envstep_per_episode: 313.625
avg_sample_per_episode: 313.625
avg_envstep_per_sec: 2700.73171052172
avg_train_sample_per_sec: 2700.73171052172
avg_episode_per_sec: 8.611340647339082
collect_time: 0.9290074946079403
reward_mean: 1399.6349679105556
reward_std: 836.6413770182246
reward_max: 3317.361776118691
reward_min: 647.6989472027616
total_envstep_count: 3225207
total_train_sample_count: 2488542
total_episode_count: 12159
total_duration: 826.547577341913
[2023-06-29 10:28:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2123
train_sample_count: 2123
avg_envstep_per_episode: 163.30769230769232
avg_sample_per_episode: 163.30769230769232
avg_envstep_per_sec: 2757.1083947220523
avg_train_sample_per_sec: 2757.1083947220523
avg_episode_per_sec: 16.882905855575448
collect_time: 0.7700096245994792
reward_mean: 1167.0977334979566
reward_std: 763.3842286955837
reward_max: 3112.3183746176405
reward_min: 572.2869727276387
total_envstep_count: 3229455
total_train_sample_count: 2491865
total_episode_count: 12172
total_duration: 827.3175869665124
[2023-06-29 10:28:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3088
train_sample_count: 3088
avg_envstep_per_episode: 280.72727272727275
avg_sample_per_episode: 280.72727272727275
avg_envstep_per_sec: 2536.744659835614
avg_train_sample_per_sec: 2536.744659835614
avg_episode_per_sec: 9.036331365994739
collect_time: 1.2173081701491029
reward_mean: 1593.8535928848287
reward_std: 641.1285121386966
reward_max: 2550.804132506949
reward_min: 617.4551711074301
total_envstep_count: 3234463
total_train_sample_count: 2495353
total_episode_count: 12183
total_duration: 828.5348951366615
[2023-06-29 10:28:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 232.6
avg_sample_per_episode: 232.6
avg_envstep_per_sec: 2577.6663775587635
avg_train_sample_per_sec: 2577.6663775587635
avg_episode_per_sec: 11.081970668782303
collect_time: 0.9023665825221688
reward_mean: 1175.3050029719982
reward_std: 681.5389615181192
reward_max: 2637.171924398151
reward_min: 266.71694609434996
total_envstep_count: 3239199
total_train_sample_count: 2498879
total_episode_count: 12193
total_duration: 829.4372617191837
[2023-06-29 10:28:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1616
train_sample_count: 1616
avg_envstep_per_episode: 230.85714285714286
avg_sample_per_episode: 230.85714285714286
avg_envstep_per_sec: 2770.941239829328
avg_train_sample_per_sec: 2770.941239829328
avg_episode_per_sec: 12.002839528963673
collect_time: 0.5831953333299609
reward_mean: 1854.3236889893178
reward_std: 1177.335367569984
reward_max: 3522.563859634785
reward_min: 296.73849951386194
total_envstep_count: 3243983
total_train_sample_count: 2502095
total_episode_count: 12200
total_duration: 830.0204570525136
[2023-06-29 10:28:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1643
train_sample_count: 1643
avg_envstep_per_episode: 234.71428571428572
avg_sample_per_episode: 234.71428571428572
avg_envstep_per_sec: 2748.7851724751995
avg_train_sample_per_sec: 2748.7851724751995
avg_episode_per_sec: 11.711196717788434
collect_time: 0.5977185909077526
reward_mean: 2537.927717153068
reward_std: 1005.2465798045225
reward_max: 3491.184992120985
reward_min: 912.0131649825144
total_envstep_count: 3248167
total_train_sample_count: 2505338
total_episode_count: 12207
total_duration: 830.6181756434214
[2023-06-29 10:28:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 225.77777777777777
avg_sample_per_episode: 225.77777777777777
avg_envstep_per_sec: 2729.1372187416205
avg_train_sample_per_sec: 2729.1372187416205
avg_episode_per_sec: 12.087714059387098
collect_time: 0.7445576521568
reward_mean: 1614.7753292435814
reward_std: 1114.5188786097567
reward_max: 3355.7472135131466
reward_min: 257.93895398062347
total_envstep_count: 3252871
total_train_sample_count: 2508570
total_episode_count: 12216
total_duration: 831.3627332955782
[2023-06-29 10:28:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2572
train_sample_count: 2572
avg_envstep_per_episode: 233.8181818181818
avg_sample_per_episode: 233.8181818181818
avg_envstep_per_sec: 2525.1742672956393
avg_train_sample_per_sec: 2525.1742672956393
avg_episode_per_sec: 10.799734424670309
collect_time: 1.0185435648187993
reward_mean: 1678.026298936129
reward_std: 957.3933909484581
reward_max: 3456.470032789996
reward_min: 276.27897273715746
total_envstep_count: 3257463
total_train_sample_count: 2511942
total_episode_count: 12227
total_duration: 832.3812768603971
[2023-06-29 10:28:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1860
train_sample_count: 1860
avg_envstep_per_episode: 232.5
avg_sample_per_episode: 232.5
avg_envstep_per_sec: 2761.2533427102508
avg_train_sample_per_sec: 2761.2533427102508
avg_episode_per_sec: 11.876358463269897
collect_time: 0.6736071519516408
reward_mean: 1515.998175903772
reward_std: 1044.374346969802
reward_max: 3315.4368306775173
reward_min: 661.4789315841552
total_envstep_count: 3262375
total_train_sample_count: 2515402
total_episode_count: 12235
total_duration: 833.0548840123487
[2023-06-29 10:28:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3345
train_sample_count: 3345
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2598.860270879193
avg_train_sample_per_sec: 2598.860270879193
avg_episode_per_sec: 11.65408193219369
collect_time: 1.287102672460489
reward_mean: 1464.3611416997446
reward_std: 996.2905569664701
reward_max: 3293.389354352701
reward_min: 186.47718298845746
total_envstep_count: 3266431
total_train_sample_count: 2518747
total_episode_count: 12250
total_duration: 834.3419866848092
[2023-06-29 10:28:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2180
train_sample_count: 2180
avg_envstep_per_episode: 311.42857142857144
avg_sample_per_episode: 311.42857142857144
avg_envstep_per_sec: 2743.0720349632047
avg_train_sample_per_sec: 2743.0720349632047
avg_episode_per_sec: 8.808029470065337
collect_time: 0.7947294027330355
reward_mean: 1287.9287491364157
reward_std: 317.4244875630325
reward_max: 1816.4954011315272
reward_min: 961.2556404527637
total_envstep_count: 3271263
total_train_sample_count: 2522127
total_episode_count: 12257
total_duration: 835.1367160875423
[2023-06-29 10:28:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1368
train_sample_count: 1368
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2648.0417879357665
avg_train_sample_per_sec: 2648.0417879357665
avg_episode_per_sec: 11.614218368139326
collect_time: 0.5166081616356968
reward_mean: 2036.3968813568226
reward_std: 1183.1113300299453
reward_max: 3402.1715961286795
reward_min: 779.1395465101513
total_envstep_count: 3275703
total_train_sample_count: 2525495
total_episode_count: 12263
total_duration: 835.6533242491779
[2023-06-29 10:28:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2267
train_sample_count: 2267
avg_envstep_per_episode: 323.85714285714283
avg_sample_per_episode: 323.85714285714283
avg_envstep_per_sec: 2755.280059169084
avg_train_sample_per_sec: 2755.280059169084
avg_episode_per_sec: 8.50770199125875
collect_time: 0.8227838736232368
reward_mean: 2402.4779274954662
reward_std: 921.0434459234517
reward_max: 3246.0320927895077
reward_min: 971.8541256156711
total_envstep_count: 3280119
total_train_sample_count: 2528962
total_episode_count: 12270
total_duration: 836.4761081228012
[2023-06-29 10:28:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2071
train_sample_count: 2071
avg_envstep_per_episode: 230.11111111111111
avg_sample_per_episode: 230.11111111111111
avg_envstep_per_sec: 2780.9257995606313
avg_train_sample_per_sec: 2780.9257995606313
avg_episode_per_sec: 12.085143503643497
collect_time: 0.7447160223862157
reward_mean: 1589.7243559577598
reward_std: 949.142894316896
reward_max: 3264.109597012378
reward_min: 677.2493124032286
total_envstep_count: 3284039
total_train_sample_count: 2532233
total_episode_count: 12279
total_duration: 837.2208241451874
[2023-06-29 10:28:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2828
train_sample_count: 2828
avg_envstep_per_episode: 353.5
avg_sample_per_episode: 353.5
avg_envstep_per_sec: 2767.086907096269
avg_train_sample_per_sec: 2767.086907096269
avg_episode_per_sec: 7.827685734360026
collect_time: 1.022013436855748
reward_mean: 2007.5440072895212
reward_std: 948.4570463819124
reward_max: 3266.17336369116
reward_min: 1009.3859449943008
total_envstep_count: 3288431
total_train_sample_count: 2535461
total_episode_count: 12287
total_duration: 838.2428375820432
[2023-06-29 10:28:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2941
train_sample_count: 2941
avg_envstep_per_episode: 326.77777777777777
avg_sample_per_episode: 326.77777777777777
avg_envstep_per_sec: 2598.41840086091
avg_train_sample_per_sec: 2598.41840086091
avg_episode_per_sec: 7.951637404878677
collect_time: 1.1318423541896045
reward_mean: 1625.4657749762457
reward_std: 760.7084463243735
reward_max: 3195.4973726083513
reward_min: 663.0544104352748
total_envstep_count: 3293055
total_train_sample_count: 2538802
total_episode_count: 12296
total_duration: 839.3746799362328
[2023-06-29 10:28:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 201.75
avg_sample_per_episode: 201.75
avg_envstep_per_sec: 2738.031378815203
avg_train_sample_per_sec: 2738.031378815203
avg_episode_per_sec: 13.571407082107575
collect_time: 0.29473730879928917
reward_mean: 1174.4510538550148
reward_std: 532.3834766953909
reward_max: 2088.8629204499007
reward_min: 792.6445148568927
total_envstep_count: 3296735
total_train_sample_count: 2542009
total_episode_count: 12300
total_duration: 839.6694172450322
[2023-06-29 10:28:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1355
train_sample_count: 1355
avg_envstep_per_episode: 193.57142857142858
avg_sample_per_episode: 193.57142857142858
avg_envstep_per_sec: 2765.3065380647545
avg_train_sample_per_sec: 2765.3065380647545
avg_episode_per_sec: 14.28571643280685
collect_time: 0.4899999263547361
reward_mean: 2238.4482107102517
reward_std: 1091.6657547095476
reward_max: 3332.3566138834094
reward_min: 654.663179925189
total_envstep_count: 3300791
total_train_sample_count: 2545364
total_episode_count: 12307
total_duration: 840.1594171713868
[2023-06-29 10:28:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 151.375
avg_sample_per_episode: 151.375
avg_envstep_per_sec: 2685.2354889479916
avg_train_sample_per_sec: 2685.2354889479916
avg_episode_per_sec: 17.73896276761679
collect_time: 0.45098465478513383
reward_mean: 1726.0619114428175
reward_std: 1083.2809896250274
reward_max: 3393.7210095814157
reward_min: 407.6152231296245
total_envstep_count: 3304935
total_train_sample_count: 2548575
total_episode_count: 12315
total_duration: 840.6104018261719
[2023-06-29 10:28:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2031
train_sample_count: 2031
avg_envstep_per_episode: 253.875
avg_sample_per_episode: 253.875
avg_envstep_per_sec: 2455.4111051639784
avg_train_sample_per_sec: 2455.4111051639784
avg_episode_per_sec: 9.671732565884701
collect_time: 0.8271527304444461
reward_mean: 1985.1359875754479
reward_std: 607.3462680466168
reward_max: 3076.837269375841
reward_min: 1263.2290396815151
total_envstep_count: 3308695
total_train_sample_count: 2551806
total_episode_count: 12323
total_duration: 841.4375545566164
[2023-06-29 10:29:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2714
train_sample_count: 2714
avg_envstep_per_episode: 226.16666666666666
avg_sample_per_episode: 226.16666666666666
avg_envstep_per_sec: 2719.5129968875717
avg_train_sample_per_sec: 2719.5129968875717
avg_episode_per_sec: 12.024375815272977
collect_time: 0.9979727999484168
reward_mean: 1281.8906459249574
reward_std: 738.7880223133507
reward_max: 3162.8224119308616
reward_min: 162.88140073058386
total_envstep_count: 3313415
total_train_sample_count: 2555320
total_episode_count: 12335
total_duration: 842.4355273565649
[2023-06-29 10:29:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1653
train_sample_count: 1653
avg_envstep_per_episode: 236.14285714285714
avg_sample_per_episode: 236.14285714285714
avg_envstep_per_sec: 2732.5109615627835
avg_train_sample_per_sec: 2732.5109615627835
avg_episode_per_sec: 11.571431779152743
collect_time: 0.6049381039096043
reward_mean: 1582.2764233893201
reward_std: 689.6752499227437
reward_max: 2828.585622137084
reward_min: 720.5235053097641
total_envstep_count: 3318039
total_train_sample_count: 2558573
total_episode_count: 12342
total_duration: 843.0404654604745
[2023-06-29 10:29:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2514
train_sample_count: 2514
avg_envstep_per_episode: 251.4
avg_sample_per_episode: 251.4
avg_envstep_per_sec: 2611.4053780266854
avg_train_sample_per_sec: 2611.4053780266854
avg_episode_per_sec: 10.387451782126831
collect_time: 0.9627000163029878
reward_mean: 1699.9693399563173
reward_std: 966.9690193255227
reward_max: 3231.34455773267
reward_min: 473.92462367669367
total_envstep_count: 3322431
total_train_sample_count: 2561887
total_episode_count: 12352
total_duration: 844.0031654767774
[2023-06-29 10:29:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 2867
train_sample_count: 2867
avg_envstep_per_episode: 159.27777777777777
avg_sample_per_episode: 159.27777777777777
avg_envstep_per_sec: 2556.7857700056466
avg_train_sample_per_sec: 2556.7857700056466
avg_episode_per_sec: 16.052369675654564
collect_time: 1.121329770226963
reward_mean: 929.1846609015914
reward_std: 930.94900340043
reward_max: 3387.473348438152
reward_min: 50.96375523041385
total_envstep_count: 3327119
total_train_sample_count: 2565154
total_episode_count: 12370
total_duration: 845.1244952470043
[2023-06-29 10:29:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2402
train_sample_count: 2402
avg_envstep_per_episode: 160.13333333333333
avg_sample_per_episode: 160.13333333333333
avg_envstep_per_sec: 2729.3483679602805
avg_train_sample_per_sec: 2729.3483679602805
avg_episode_per_sec: 17.04422377993514
collect_time: 0.8800635449094697
reward_mean: 853.456515720215
reward_std: 729.1449926107209
reward_max: 3093.248872836173
reward_min: 48.28177173920956
total_envstep_count: 3330903
total_train_sample_count: 2568356
total_episode_count: 12385
total_duration: 846.0045587919138
[2023-06-29 10:29:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3251
train_sample_count: 3251
avg_envstep_per_episode: 216.73333333333332
avg_sample_per_episode: 216.73333333333332
avg_envstep_per_sec: 2675.5858091488803
avg_train_sample_per_sec: 2675.5858091488803
avg_episode_per_sec: 12.345059100963768
collect_time: 1.2150610116422176
reward_mean: 1092.8323022103043
reward_std: 697.8136245728441
reward_max: 3372.8805685594034
reward_min: 559.092330095926
total_envstep_count: 3335311
total_train_sample_count: 2571607
total_episode_count: 12400
total_duration: 847.219619803556
[2023-06-29 10:29:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 182.125
avg_sample_per_episode: 182.125
avg_envstep_per_sec: 2581.7396479367844
avg_train_sample_per_sec: 2581.7396479367844
avg_episode_per_sec: 14.17564665991371
collect_time: 1.1286963045746088
reward_mean: 796.1278134866241
reward_std: 322.219180268155
reward_max: 1771.9465266472773
reward_min: 465.3020542706397
total_envstep_count: 3339199
total_train_sample_count: 2574921
total_episode_count: 12416
total_duration: 848.3483161081307
[2023-06-29 10:29:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2488
train_sample_count: 2488
avg_envstep_per_episode: 165.86666666666667
avg_sample_per_episode: 165.86666666666667
avg_envstep_per_sec: 2710.834630506863
avg_train_sample_per_sec: 2710.834630506863
avg_episode_per_sec: 16.343456373634623
collect_time: 0.917798515630886
reward_mean: 751.4190094586112
reward_std: 465.78093463593905
reward_max: 2430.2007291567
reward_min: 383.6875081796255
total_envstep_count: 3343551
total_train_sample_count: 2578209
total_episode_count: 12431
total_duration: 849.2661146237616
[2023-06-29 10:29:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 2967
train_sample_count: 2967
avg_envstep_per_episode: 174.52941176470588
avg_sample_per_episode: 174.52941176470588
avg_envstep_per_sec: 2764.8070477765623
avg_train_sample_per_sec: 2764.8070477765623
avg_episode_per_sec: 15.841496397776057
collect_time: 1.0731309450278057
reward_mean: 969.7158200750067
reward_std: 901.9797740676263
reward_max: 3461.0242718411787
reward_min: 51.544423424703965
total_envstep_count: 3347935
total_train_sample_count: 2581576
total_episode_count: 12448
total_duration: 850.3392455687895
[2023-06-29 10:29:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3288
train_sample_count: 3288
avg_envstep_per_episode: 182.66666666666666
avg_sample_per_episode: 182.66666666666666
avg_envstep_per_sec: 2587.454427052245
avg_train_sample_per_sec: 2587.454427052245
avg_episode_per_sec: 14.164896498461195
collect_time: 1.2707470190096646
reward_mean: 870.1716416407382
reward_std: 475.9331857740452
reward_max: 2688.119388163565
reward_min: 500.55879227920605
total_envstep_count: 3352119
total_train_sample_count: 2584864
total_episode_count: 12466
total_duration: 851.6099925877992
[2023-06-29 10:29:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2960
train_sample_count: 2960
avg_envstep_per_episode: 197.33333333333334
avg_sample_per_episode: 197.33333333333334
avg_envstep_per_sec: 2545.1598618467274
avg_train_sample_per_sec: 2545.1598618467274
avg_episode_per_sec: 12.897769570169226
collect_time: 1.1629917807411403
reward_mean: 776.1135547727403
reward_std: 159.01762883691512
reward_max: 1023.9844259836176
reward_min: 541.3470527493193
total_envstep_count: 3356271
total_train_sample_count: 2588224
total_episode_count: 12481
total_duration: 852.7729843685403
[2023-06-29 10:29:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2050
train_sample_count: 2050
avg_envstep_per_episode: 227.77777777777777
avg_sample_per_episode: 227.77777777777777
avg_envstep_per_sec: 2786.6201445728975
avg_train_sample_per_sec: 2786.6201445728975
avg_episode_per_sec: 12.233942098124915
collect_time: 0.7356582144834102
reward_mean: 1268.189292752119
reward_std: 843.30145076801
reward_max: 3352.8849717320973
reward_min: 651.5913594995812
total_envstep_count: 3361103
total_train_sample_count: 2591474
total_episode_count: 12490
total_duration: 853.5086425830237
[2023-06-29 10:29:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2813
train_sample_count: 2813
avg_envstep_per_episode: 187.53333333333333
avg_sample_per_episode: 187.53333333333333
avg_envstep_per_sec: 2576.500614458925
avg_train_sample_per_sec: 2576.500614458925
avg_episode_per_sec: 13.738894140378202
collect_time: 1.0917909292215482
reward_mean: 1282.826860238802
reward_std: 593.4386088799358
reward_max: 2661.6193513349226
reward_min: 553.1389447234451
total_envstep_count: 3365527
total_train_sample_count: 2594687
total_episode_count: 12505
total_duration: 854.6004335122453
[2023-06-29 10:29:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2166
train_sample_count: 2166
avg_envstep_per_episode: 270.75
avg_sample_per_episode: 270.75
avg_envstep_per_sec: 2310.2597311716513
avg_train_sample_per_sec: 2310.2597311716513
avg_episode_per_sec: 8.532815258251713
collect_time: 0.9375569208841771
reward_mean: 1459.915836590375
reward_std: 520.2787426569084
reward_max: 2497.6616007645134
reward_min: 955.4333665139073
total_envstep_count: 3370207
total_train_sample_count: 2598053
total_episode_count: 12513
total_duration: 855.5379904331295
[2023-06-29 10:29:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2623
train_sample_count: 2623
avg_envstep_per_episode: 262.3
avg_sample_per_episode: 262.3
avg_envstep_per_sec: 2541.4732682730555
avg_train_sample_per_sec: 2541.4732682730555
avg_episode_per_sec: 9.689185163069217
collect_time: 1.0320785320643338
reward_mean: 1716.1784441762113
reward_std: 930.7733038208837
reward_max: 3279.8232568720246
reward_min: 815.7993349131474
total_envstep_count: 3374247
total_train_sample_count: 2601476
total_episode_count: 12523
total_duration: 856.5700689651939
[2023-06-29 10:29:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1761
train_sample_count: 1761
avg_envstep_per_episode: 251.57142857142858
avg_sample_per_episode: 251.57142857142858
avg_envstep_per_sec: 2777.8349022994666
avg_train_sample_per_sec: 2777.8349022994666
avg_episode_per_sec: 11.041933172115995
collect_time: 0.6339469629898667
reward_mean: 1145.0439874413112
reward_std: 672.4158213627849
reward_max: 2763.720122716392
reward_min: 590.6013367523792
total_envstep_count: 3378743
total_train_sample_count: 2604837
total_episode_count: 12530
total_duration: 857.2040159281837
[2023-06-29 10:29:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 2760.3285239325164
avg_train_sample_per_sec: 2760.3285239325164
avg_episode_per_sec: 12.322895196127305
collect_time: 1.0549468930065629
reward_mean: 1605.041900976153
reward_std: 1101.3955274900932
reward_max: 3244.6665098697117
reward_min: 574.1974098797992
total_envstep_count: 3382903
total_train_sample_count: 2608149
total_episode_count: 12543
total_duration: 858.2589628211903
[2023-06-29 10:29:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2958
train_sample_count: 2958
avg_envstep_per_episode: 227.53846153846155
avg_sample_per_episode: 227.53846153846155
avg_envstep_per_sec: 2565.7837684580727
avg_train_sample_per_sec: 2565.7837684580727
avg_episode_per_sec: 11.276264026353937
collect_time: 1.1528641019416974
reward_mean: 1066.5961467643594
reward_std: 387.08257366383174
reward_max: 2270.820114829408
reward_min: 740.7100807530386
total_envstep_count: 3387407
total_train_sample_count: 2611507
total_episode_count: 12556
total_duration: 859.4118269231319
[2023-06-29 10:29:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1652
train_sample_count: 1652
avg_envstep_per_episode: 236.0
avg_sample_per_episode: 236.0
avg_envstep_per_sec: 2727.3297340226295
avg_train_sample_per_sec: 2727.3297340226295
avg_episode_per_sec: 11.556481923824702
collect_time: 0.6057206722721459
reward_mean: 1259.924721735287
reward_std: 709.088288981611
reward_max: 2757.919698019207
reward_min: 592.8860248220967
total_envstep_count: 3391735
total_train_sample_count: 2614759
total_episode_count: 12563
total_duration: 860.017547595404
[2023-06-29 10:29:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2919
train_sample_count: 2919
avg_envstep_per_episode: 208.5
avg_sample_per_episode: 208.5
avg_envstep_per_sec: 2696.1746215713197
avg_train_sample_per_sec: 2696.1746215713197
avg_episode_per_sec: 12.931293149023116
collect_time: 1.0826450099507348
reward_mean: 1416.119272510634
reward_std: 788.962182819602
reward_max: 3115.992583690142
reward_min: 629.3540316784141
total_envstep_count: 3395911
total_train_sample_count: 2618078
total_episode_count: 12577
total_duration: 861.1001926053548
[2023-06-29 10:30:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2579
train_sample_count: 2579
avg_envstep_per_episode: 234.45454545454547
avg_sample_per_episode: 234.45454545454547
avg_envstep_per_sec: 2622.705615335541
avg_train_sample_per_sec: 2622.705615335541
avg_episode_per_sec: 11.186414024308242
collect_time: 0.9833356763031333
reward_mean: 1184.5035523824913
reward_std: 433.249019718548
reward_max: 2029.643056910333
reward_min: 597.1364352883345
total_envstep_count: 3400599
total_train_sample_count: 2621457
total_episode_count: 12588
total_duration: 862.0835282816579
[2023-06-29 10:30:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3514
train_sample_count: 3514
avg_envstep_per_episode: 219.625
avg_sample_per_episode: 219.625
avg_envstep_per_sec: 2572.9050804999256
avg_train_sample_per_sec: 2572.9050804999256
avg_episode_per_sec: 11.714991829254073
collect_time: 1.3657713324259968
reward_mean: 1175.4266536736068
reward_std: 505.09532510848106
reward_max: 2332.196919365455
reward_min: 642.9208428948933
total_envstep_count: 3404911
total_train_sample_count: 2624971
total_episode_count: 12604
total_duration: 863.4492996140839
[2023-06-29 10:30:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 200.9
avg_sample_per_episode: 200.9
avg_envstep_per_sec: 2749.968438625733
avg_train_sample_per_sec: 2749.968438625733
avg_episode_per_sec: 13.688245090222663
collect_time: 0.7305538390120492
reward_mean: 916.0308995054002
reward_std: 227.28164408491864
reward_max: 1258.6248687083423
reward_min: 553.6474188053335
total_envstep_count: 3409087
total_train_sample_count: 2628180
total_episode_count: 12614
total_duration: 864.1798534530959
[2023-06-29 10:30:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 341.0
avg_sample_per_episode: 341.0
avg_envstep_per_sec: 2775.680273693696
avg_train_sample_per_sec: 2775.680273693696
avg_episode_per_sec: 8.13982484954163
collect_time: 0.6142638315223158
reward_mean: 2020.9560677970626
reward_std: 1105.7919179724802
reward_max: 3244.8645435568296
reward_min: 643.7534826364979
total_envstep_count: 3413311
total_train_sample_count: 2631485
total_episode_count: 12619
total_duration: 864.7941172846182
[2023-06-29 10:30:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 190.14285714285714
avg_sample_per_episode: 190.14285714285714
avg_envstep_per_sec: 2669.8231257966686
avg_train_sample_per_sec: 2669.8231257966686
avg_episode_per_sec: 14.041143411402466
collect_time: 0.4985348981134594
reward_mean: 2037.1875087743495
reward_std: 1026.2009298860587
reward_max: 3182.962480756599
reward_min: 732.3725918504442
total_envstep_count: 3417623
total_train_sample_count: 2634816
total_episode_count: 12626
total_duration: 865.2926521827317
[2023-06-29 10:30:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2108
train_sample_count: 2108
avg_envstep_per_episode: 234.22222222222223
avg_sample_per_episode: 234.22222222222223
avg_envstep_per_sec: 2534.8301772625387
avg_train_sample_per_sec: 2534.8301772625387
avg_episode_per_sec: 10.82232997882488
collect_time: 0.8316138962320982
reward_mean: 1977.5399437663982
reward_std: 869.9038004497625
reward_max: 3316.19688620461
reward_min: 900.8095342558241
total_envstep_count: 3422743
total_train_sample_count: 2638124
total_episode_count: 12635
total_duration: 866.1242660789637
[2023-06-29 10:30:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 280.1
avg_sample_per_episode: 280.1
avg_envstep_per_sec: 2774.7928689264254
avg_train_sample_per_sec: 2774.7928689264254
avg_episode_per_sec: 9.906436518837648
collect_time: 1.0094447161685673
reward_mean: 1900.18745599902
reward_std: 711.9136204827201
reward_max: 3141.106917724147
reward_min: 829.9201505923907
total_envstep_count: 3427447
total_train_sample_count: 2641325
total_episode_count: 12645
total_duration: 867.1337107951323
[2023-06-29 10:30:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3277
train_sample_count: 3277
avg_envstep_per_episode: 234.07142857142858
avg_sample_per_episode: 234.07142857142858
avg_envstep_per_sec: 2745.7154975309436
avg_train_sample_per_sec: 2745.7154975309436
avg_episode_per_sec: 11.730246251276537
collect_time: 1.1934958312129602
reward_mean: 1218.6005502737714
reward_std: 481.08956942266
reward_max: 2435.848391206027
reward_min: 642.8513104570341
total_envstep_count: 3432255
total_train_sample_count: 2644602
total_episode_count: 12659
total_duration: 868.3272066263453
[2023-06-29 10:30:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 272.6666666666667
avg_sample_per_episode: 272.6666666666667
avg_envstep_per_sec: 2497.052016741849
avg_train_sample_per_sec: 2497.052016741849
avg_episode_per_sec: 9.15789248193832
collect_time: 0.9827588626695798
reward_mean: 1452.9355773059756
reward_std: 482.15599222158215
reward_max: 2072.3877558627487
reward_min: 848.398118564804
total_envstep_count: 3437015
total_train_sample_count: 2647856
total_episode_count: 12668
total_duration: 869.3099654890149
[2023-06-29 10:30:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3319
train_sample_count: 3319
avg_envstep_per_episode: 301.72727272727275
avg_sample_per_episode: 301.72727272727275
avg_envstep_per_sec: 2629.919841928695
avg_train_sample_per_sec: 2629.919841928695
avg_episode_per_sec: 8.716215203740779
collect_time: 1.2620156504716724
reward_mean: 1716.6123643241067
reward_std: 706.7852112330113
reward_max: 2875.093394837583
reward_min: 647.392349231711
total_envstep_count: 3441519
total_train_sample_count: 2651175
total_episode_count: 12679
total_duration: 870.5719811394865
[2023-06-29 10:30:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 218.69230769230768
avg_sample_per_episode: 218.69230769230768
avg_envstep_per_sec: 2570.8495386166937
avg_train_sample_per_sec: 2570.8495386166937
avg_episode_per_sec: 11.755555399935638
collect_time: 1.1058601280609146
reward_mean: 1025.5717826054054
reward_std: 231.20797478833202
reward_max: 1280.010503066881
reward_min: 632.3035683422227
total_envstep_count: 3446135
total_train_sample_count: 2654418
total_episode_count: 12692
total_duration: 871.6778412675475
[2023-06-29 10:30:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 202.66666666666666
avg_sample_per_episode: 202.66666666666666
avg_envstep_per_sec: 2738.681976716315
avg_train_sample_per_sec: 2738.681976716315
avg_episode_per_sec: 13.513233437744976
collect_time: 0.44400920236017555
reward_mean: 1618.0923635661673
reward_std: 254.0441822011365
reward_max: 2033.1156819218284
reward_min: 1211.3536154822575
total_envstep_count: 3450879
total_train_sample_count: 2657634
total_episode_count: 12698
total_duration: 872.1218504699076
[2023-06-29 10:30:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 220.63636363636363
avg_sample_per_episode: 220.63636363636363
avg_envstep_per_sec: 2728.202451847716
avg_train_sample_per_sec: 2728.202451847716
avg_episode_per_sec: 12.365153263421869
collect_time: 0.8895967373521998
reward_mean: 1791.2165145253755
reward_std: 775.7985387690904
reward_max: 3118.3916807584046
reward_min: 896.715807447547
total_envstep_count: 3455375
total_train_sample_count: 2660861
total_episode_count: 12709
total_duration: 873.0114472072598
[2023-06-29 10:30:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3194
train_sample_count: 3194
avg_envstep_per_episode: 245.69230769230768
avg_sample_per_episode: 245.69230769230768
avg_envstep_per_sec: 2591.8019386887804
avg_train_sample_per_sec: 2591.8019386887804
avg_episode_per_sec: 10.548974703492219
collect_time: 1.2323472532071174
reward_mean: 1396.594944959106
reward_std: 789.8169782201622
reward_max: 3311.5154253573073
reward_min: 568.4041532119647
total_envstep_count: 3460031
total_train_sample_count: 2664455
total_episode_count: 12722
total_duration: 874.2437944604669
[2023-06-29 10:30:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 230.92857142857142
avg_sample_per_episode: 230.92857142857142
avg_envstep_per_sec: 2557.3899953029872
avg_train_sample_per_sec: 2557.3899953029872
avg_episode_per_sec: 11.074376719530411
collect_time: 1.2641794978231193
reward_mean: 1110.515208303416
reward_std: 284.26071523399764
reward_max: 1761.4548184565324
reward_min: 694.951151293798
total_envstep_count: 3464455
total_train_sample_count: 2667688
total_episode_count: 12736
total_duration: 875.50797395829
[2023-06-29 10:30:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2907
train_sample_count: 2907
avg_envstep_per_episode: 264.27272727272725
avg_sample_per_episode: 264.27272727272725
avg_envstep_per_sec: 2540.137886870086
avg_train_sample_per_sec: 2540.137886870086
avg_episode_per_sec: 9.611804869477448
collect_time: 1.1444260624693707
reward_mean: 1256.2371679925602
reward_std: 398.6367646922562
reward_max: 2089.848180924931
reward_min: 810.226995528471
total_envstep_count: 3469543
total_train_sample_count: 2670995
total_episode_count: 12747
total_duration: 876.6524000207594
[2023-06-29 10:30:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2659
train_sample_count: 2659
avg_envstep_per_episode: 204.53846153846155
avg_sample_per_episode: 204.53846153846155
avg_envstep_per_sec: 2690.137492326284
avg_train_sample_per_sec: 2690.137492326284
avg_episode_per_sec: 13.152232944806952
collect_time: 0.9884253156520422
reward_mean: 1254.9692498031268
reward_std: 453.42688349107175
reward_max: 2005.6944967456734
reward_min: 45.88440182444443
total_envstep_count: 3473983
total_train_sample_count: 2674454
total_episode_count: 12760
total_duration: 877.6408253364115
[2023-06-29 10:30:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2634
train_sample_count: 2634
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 2726.502151025541
avg_train_sample_per_sec: 2726.502151025541
avg_episode_per_sec: 12.42142210034415
collect_time: 0.9660729587208478
reward_mean: 1220.7712935573043
reward_std: 354.4588502824236
reward_max: 1803.6175433097226
reward_min: 800.2514485709956
total_envstep_count: 3478455
total_train_sample_count: 2677888
total_episode_count: 12772
total_duration: 878.6068982951323
[2023-06-29 10:30:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2996
train_sample_count: 2996
avg_envstep_per_episode: 214.0
avg_sample_per_episode: 214.0
avg_envstep_per_sec: 2532.1355797845035
avg_train_sample_per_sec: 2532.1355797845035
avg_episode_per_sec: 11.832409251329455
collect_time: 1.1831909886337815
reward_mean: 1171.770452961888
reward_std: 316.1975372034271
reward_max: 1779.6534390430875
reward_min: 681.0461558982213
total_envstep_count: 3482639
total_train_sample_count: 2681284
total_episode_count: 12786
total_duration: 879.7900892837661
[2023-06-29 10:30:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2194
train_sample_count: 2194
avg_envstep_per_episode: 274.25
avg_sample_per_episode: 274.25
avg_envstep_per_sec: 2748.598534594552
avg_train_sample_per_sec: 2748.598534594552
avg_episode_per_sec: 10.022237136169743
collect_time: 0.7982249762509019
reward_mean: 1372.8914362717082
reward_std: 426.86879411219826
reward_max: 2090.507918308745
reward_min: 689.897836025373
total_envstep_count: 3487095
total_train_sample_count: 2684678
total_episode_count: 12794
total_duration: 880.588314260017
[2023-06-29 10:31:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2235
train_sample_count: 2235
avg_envstep_per_episode: 248.33333333333334
avg_sample_per_episode: 248.33333333333334
avg_envstep_per_sec: 2728.963915175091
avg_train_sample_per_sec: 2728.963915175091
avg_episode_per_sec: 10.989116436946675
collect_time: 0.8189921411462129
reward_mean: 1701.1610915447511
reward_std: 559.0622858881896
reward_max: 2908.663892445744
reward_min: 909.2366159434077
total_envstep_count: 3491999
total_train_sample_count: 2688113
total_episode_count: 12803
total_duration: 881.4073064011632
[2023-06-29 10:31:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3236
train_sample_count: 3236
avg_envstep_per_episode: 269.6666666666667
avg_sample_per_episode: 269.6666666666667
avg_envstep_per_sec: 2762.593933034121
avg_train_sample_per_sec: 2762.593933034121
avg_episode_per_sec: 10.2444768839337
collect_time: 1.17136288518738
reward_mean: 1665.1030176133752
reward_std: 872.0357620256764
reward_max: 3295.008031050222
reward_min: 687.3287779562464
total_envstep_count: 3496911
total_train_sample_count: 2691349
total_episode_count: 12815
total_duration: 882.5786692863505
[2023-06-29 10:31:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1878
train_sample_count: 1878
avg_envstep_per_episode: 268.2857142857143
avg_sample_per_episode: 268.2857142857143
avg_envstep_per_sec: 2720.2159908924914
avg_train_sample_per_sec: 2720.2159908924914
avg_episode_per_sec: 10.13925023229363
collect_time: 0.6903863539835439
reward_mean: 1558.3324418169566
reward_std: 358.9207223393354
reward_max: 2065.1688361249503
reward_min: 1140.527603796058
total_envstep_count: 3501831
total_train_sample_count: 2694827
total_episode_count: 12822
total_duration: 883.269055640334
[2023-06-29 10:31:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2986
train_sample_count: 2986
avg_envstep_per_episode: 298.6
avg_sample_per_episode: 298.6
avg_envstep_per_sec: 2566.1424926366744
avg_train_sample_per_sec: 2566.1424926366744
avg_episode_per_sec: 8.593913237229318
collect_time: 1.1636142609259115
reward_mean: 2097.8473446307366
reward_std: 827.9964266445756
reward_max: 3313.8751941668456
reward_min: 1280.6925281507822
total_envstep_count: 3506247
total_train_sample_count: 2698213
total_episode_count: 12832
total_duration: 884.4326699012599
[2023-06-29 10:31:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3405
train_sample_count: 3405
avg_envstep_per_episode: 378.3333333333333
avg_sample_per_episode: 378.3333333333333
avg_envstep_per_sec: 2626.3561929423945
avg_train_sample_per_sec: 2626.3561929423945
avg_episode_per_sec: 6.941910642138488
collect_time: 1.2964730409188194
reward_mean: 1816.4283319571268
reward_std: 644.6232942764742
reward_max: 2877.7036108808006
reward_min: 939.9748854696867
total_envstep_count: 3511191
total_train_sample_count: 2701618
total_episode_count: 12841
total_duration: 885.7291429421788
[2023-06-29 10:31:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2650
train_sample_count: 2650
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 2678.7916993276717
avg_train_sample_per_sec: 2678.7916993276717
avg_episode_per_sec: 10.108647921991215
collect_time: 0.9892519827745853
reward_mean: 1347.4752067340628
reward_std: 454.75098586617634
reward_max: 2391.961215077023
reward_min: 846.0587286099264
total_envstep_count: 3515911
total_train_sample_count: 2705068
total_episode_count: 12851
total_duration: 886.7183949249534
[2023-06-29 10:31:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2259
train_sample_count: 2259
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2802.480341216653
avg_train_sample_per_sec: 2802.480341216653
avg_episode_per_sec: 11.165260323572323
collect_time: 0.8060716668646783
reward_mean: 1738.7918997136808
reward_std: 774.9635698874454
reward_max: 3276.038609967854
reward_min: 762.0403766969987
total_envstep_count: 3520655
total_train_sample_count: 2708527
total_episode_count: 12860
total_duration: 887.524466591818
[2023-06-29 10:31:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2111
train_sample_count: 2111
avg_envstep_per_episode: 211.1
avg_sample_per_episode: 211.1
avg_envstep_per_sec: 2574.4993979671
avg_train_sample_per_sec: 2574.4993979671
avg_episode_per_sec: 12.195639024003315
collect_time: 0.8199652335001156
reward_mean: 1558.2310284594398
reward_std: 647.553525436724
reward_max: 2661.0884299858017
reward_min: 638.2414440247999
total_envstep_count: 3525055
total_train_sample_count: 2711838
total_episode_count: 12870
total_duration: 888.3444318253182
[2023-06-29 10:31:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3125
train_sample_count: 3125
avg_envstep_per_episode: 260.4166666666667
avg_sample_per_episode: 260.4166666666667
avg_envstep_per_sec: 2596.3777111670543
avg_train_sample_per_sec: 2596.3777111670543
avg_episode_per_sec: 9.970090410881488
collect_time: 1.2035999179007486
reward_mean: 1539.9683099276472
reward_std: 427.96945998606935
reward_max: 2108.338836875769
reward_min: 691.9103289263461
total_envstep_count: 3529743
total_train_sample_count: 2715363
total_episode_count: 12882
total_duration: 889.548031743219
[2023-06-29 10:31:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2864
train_sample_count: 2864
avg_envstep_per_episode: 220.30769230769232
avg_sample_per_episode: 220.30769230769232
avg_envstep_per_sec: 2591.5987160465706
avg_train_sample_per_sec: 2591.5987160465706
avg_episode_per_sec: 11.763541658032617
collect_time: 1.1051093605915085
reward_mean: 1169.9467468879034
reward_std: 405.3214699629989
reward_max: 2077.5635127562578
reward_min: 685.963985749935
total_envstep_count: 3534191
total_train_sample_count: 2718627
total_episode_count: 12895
total_duration: 890.6531411038105
[2023-06-29 10:31:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3347
train_sample_count: 3347
avg_envstep_per_episode: 196.88235294117646
avg_sample_per_episode: 196.88235294117646
avg_envstep_per_sec: 2669.711350420504
avg_train_sample_per_sec: 2669.711350420504
avg_episode_per_sec: 13.559932165266975
collect_time: 1.2536935873134063
reward_mean: 972.7238715382705
reward_std: 257.4754840248573
reward_max: 1480.822774724057
reward_min: 573.9333482054448
total_envstep_count: 3538287
total_train_sample_count: 2721974
total_episode_count: 12912
total_duration: 891.9068346911239
[2023-06-29 10:31:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3502
train_sample_count: 3502
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 2568.065814368552
avg_train_sample_per_sec: 2568.065814368552
avg_episode_per_sec: 12.46633890470171
collect_time: 1.363672216033563
reward_mean: 830.5106465766441
reward_std: 176.1563553719518
reward_max: 1238.7432119104978
reward_min: 633.7754515403097
total_envstep_count: 3542311
total_train_sample_count: 2725476
total_episode_count: 12929
total_duration: 893.2705069071575
[2023-06-29 10:31:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3250
train_sample_count: 3250
avg_envstep_per_episode: 216.66666666666666
avg_sample_per_episode: 216.66666666666666
avg_envstep_per_sec: 2613.035528497095
avg_train_sample_per_sec: 2613.035528497095
avg_episode_per_sec: 12.0601639776789
collect_time: 1.2437641832865776
reward_mean: 848.8491995914563
reward_std: 157.4179122554627
reward_max: 1159.7424085969142
reward_min: 597.2558712781148
total_envstep_count: 3546423
total_train_sample_count: 2728726
total_episode_count: 12944
total_duration: 894.514271090444
[2023-06-29 10:31:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2803
train_sample_count: 2803
avg_envstep_per_episode: 233.58333333333334
avg_sample_per_episode: 233.58333333333334
avg_envstep_per_sec: 2633.4133806728223
avg_train_sample_per_sec: 2633.4133806728223
avg_episode_per_sec: 11.273978083508338
collect_time: 1.064398024469614
reward_mean: 1045.32791499678
reward_std: 282.2316950200689
reward_max: 1763.2983538642543
reward_min: 759.8951027805554
total_envstep_count: 3550583
total_train_sample_count: 2731929
total_episode_count: 12956
total_duration: 895.5786691149136
[2023-06-29 10:31:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 206.33333333333334
avg_sample_per_episode: 206.33333333333334
avg_envstep_per_sec: 2719.9878108405687
avg_train_sample_per_sec: 2719.9878108405687
avg_episode_per_sec: 13.182493428952675
collect_time: 0.9102981969742107
reward_mean: 1090.5456677079655
reward_std: 331.502404954485
reward_max: 1569.4254649195555
reward_min: 649.3320454612401
total_envstep_count: 3555095
total_train_sample_count: 2735205
total_episode_count: 12968
total_duration: 896.4889673118878
[2023-06-29 10:31:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2871
train_sample_count: 2871
avg_envstep_per_episode: 220.84615384615384
avg_sample_per_episode: 220.84615384615384
avg_envstep_per_sec: 2533.484209120717
avg_train_sample_per_sec: 2533.484209120717
avg_episode_per_sec: 11.471715332138391
collect_time: 1.1332219832530248
reward_mean: 1284.2486398575963
reward_std: 458.3371785674738
reward_max: 2081.6428670029904
reward_min: 661.9736818887195
total_envstep_count: 3559343
total_train_sample_count: 2738476
total_episode_count: 12981
total_duration: 897.6221892951409
[2023-06-29 10:31:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2928
train_sample_count: 2928
avg_envstep_per_episode: 225.23076923076923
avg_sample_per_episode: 225.23076923076923
avg_envstep_per_sec: 2633.1199223987055
avg_train_sample_per_sec: 2633.1199223987055
avg_episode_per_sec: 11.690764682781138
collect_time: 1.1119888521190733
reward_mean: 1126.32239701201
reward_std: 460.8511940144458
reward_max: 2194.0442641037125
reward_min: 632.0844250633056
total_envstep_count: 3563767
total_train_sample_count: 2741804
total_episode_count: 12994
total_duration: 898.73417814726
[2023-06-29 10:31:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3422
train_sample_count: 3422
avg_envstep_per_episode: 342.2
avg_sample_per_episode: 342.2
avg_envstep_per_sec: 2512.4247419180247
avg_train_sample_per_sec: 2512.4247419180247
avg_episode_per_sec: 7.341977621034555
collect_time: 1.3620308472951874
reward_mean: 1708.661882474417
reward_std: 504.5575318722584
reward_max: 2398.7643717069986
reward_min: 860.31737492859
total_envstep_count: 3568167
total_train_sample_count: 2745226
total_episode_count: 13004
total_duration: 900.0962089945551
[2023-06-29 10:31:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2884
train_sample_count: 2884
avg_envstep_per_episode: 288.4
avg_sample_per_episode: 288.4
avg_envstep_per_sec: 2722.223074353216
avg_train_sample_per_sec: 2722.223074353216
avg_episode_per_sec: 9.439053655871067
collect_time: 1.0594282397981736
reward_mean: 1315.422225304373
reward_std: 305.7181079059984
reward_max: 1775.9825669746815
reward_min: 785.5049758816685
total_envstep_count: 3572223
total_train_sample_count: 2748510
total_episode_count: 13014
total_duration: 901.1556372343533
[2023-06-29 10:31:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2591
train_sample_count: 2591
avg_envstep_per_episode: 259.1
avg_sample_per_episode: 259.1
avg_envstep_per_sec: 2546.7415073530333
avg_train_sample_per_sec: 2546.7415073530333
avg_episode_per_sec: 9.829183741231313
collect_time: 1.0173784785456954
reward_mean: 1293.3976117222633
reward_std: 679.9430082158036
reward_max: 3200.4804007277357
reward_min: 672.462902028577
total_envstep_count: 3576543
total_train_sample_count: 2751901
total_episode_count: 13024
total_duration: 902.173015712899
[2023-06-29 10:32:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1911
train_sample_count: 1911
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2488.621419027111
avg_train_sample_per_sec: 2488.621419027111
avg_episode_per_sec: 9.115829373725683
collect_time: 0.7678950222758576
reward_mean: 1771.0267455828903
reward_std: 707.7662196572581
reward_max: 3301.2850469774794
reward_min: 981.8375498012701
total_envstep_count: 3581111
total_train_sample_count: 2755412
total_episode_count: 13031
total_duration: 902.9409107351748
[2023-06-29 10:32:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 223.11111111111111
avg_sample_per_episode: 223.11111111111111
avg_envstep_per_sec: 2775.792972191572
avg_train_sample_per_sec: 2775.792972191572
avg_episode_per_sec: 12.441303162213222
collect_time: 0.7233968887869269
reward_mean: 1678.164989302696
reward_std: 752.2704654618607
reward_max: 3183.760576825906
reward_min: 914.1373700135682
total_envstep_count: 3585111
total_train_sample_count: 2758620
total_episode_count: 13040
total_duration: 903.6643076239618
[2023-06-29 10:32:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 231.07142857142858
avg_sample_per_episode: 231.07142857142858
avg_envstep_per_sec: 2766.215250745722
avg_train_sample_per_sec: 2766.215250745722
avg_episode_per_sec: 11.971256108327701
collect_time: 1.1694679216044022
reward_mean: 1365.560741947529
reward_std: 559.841720507294
reward_max: 2762.778980800298
reward_min: 813.9800686537634
total_envstep_count: 3589407
total_train_sample_count: 2761855
total_episode_count: 13054
total_duration: 904.8337755455663
[2023-06-29 10:32:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1766
train_sample_count: 1766
avg_envstep_per_episode: 220.75
avg_sample_per_episode: 220.75
avg_envstep_per_sec: 2529.4862245374957
avg_train_sample_per_sec: 2529.4862245374957
avg_episode_per_sec: 11.458601243657963
collect_time: 0.6981654941895976
reward_mean: 1152.1921248192798
reward_std: 211.16342629230635
reward_max: 1404.717696370761
reward_min: 842.5398234584231
total_envstep_count: 3593575
total_train_sample_count: 2765221
total_episode_count: 13062
total_duration: 905.5319410397559
[2023-06-29 10:32:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3518
train_sample_count: 3518
avg_envstep_per_episode: 293.1666666666667
avg_sample_per_episode: 293.1666666666667
avg_envstep_per_sec: 2640.681919516445
avg_train_sample_per_sec: 2640.681919516445
avg_episode_per_sec: 9.007442590732616
collect_time: 1.332231638350524
reward_mean: 1734.324086289307
reward_std: 970.0501409387467
reward_max: 3359.4914765745725
reward_min: 674.354717321007
total_envstep_count: 3598575
total_train_sample_count: 2768739
total_episode_count: 13074
total_duration: 906.8641726781065
[2023-06-29 10:32:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2080
train_sample_count: 2080
avg_envstep_per_episode: 346.6666666666667
avg_sample_per_episode: 346.6666666666667
avg_envstep_per_sec: 2461.0861282773712
avg_train_sample_per_sec: 2461.0861282773712
avg_episode_per_sec: 7.0992869084924175
collect_time: 0.8451553060663866
reward_mean: 1745.8638677952647
reward_std: 402.2083681351158
reward_max: 2267.800112821848
reward_min: 1229.4087079975204
total_envstep_count: 3603583
total_train_sample_count: 2772019
total_episode_count: 13080
total_duration: 907.7093279841729
[2023-06-29 10:32:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2082
train_sample_count: 2082
avg_envstep_per_episode: 297.42857142857144
avg_sample_per_episode: 297.42857142857144
avg_envstep_per_sec: 2805.671868460309
avg_train_sample_per_sec: 2805.671868460309
avg_episode_per_sec: 9.433094658608146
collect_time: 0.7420682451874018
reward_mean: 2430.793719949249
reward_std: 1111.204120334806
reward_max: 3347.6621368450424
reward_min: 784.9188016435668
total_envstep_count: 3608695
total_train_sample_count: 2775301
total_episode_count: 13087
total_duration: 908.4513962293603
[2023-06-29 10:32:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2369
train_sample_count: 2369
avg_envstep_per_episode: 263.22222222222223
avg_sample_per_episode: 263.22222222222223
avg_envstep_per_sec: 2602.0028720788314
avg_train_sample_per_sec: 2602.0028720788314
avg_episode_per_sec: 9.885194533013712
collect_time: 0.9104524923553688
reward_mean: 2132.4343349245355
reward_std: 814.1236950439891
reward_max: 3421.795817789059
reward_min: 800.7791205627219
total_envstep_count: 3612711
total_train_sample_count: 2778870
total_episode_count: 13096
total_duration: 909.3618487217157
[2023-06-29 10:32:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2196
train_sample_count: 2196
avg_envstep_per_episode: 313.7142857142857
avg_sample_per_episode: 313.7142857142857
avg_envstep_per_sec: 2477.805269035413
avg_train_sample_per_sec: 2477.805269035413
avg_episode_per_sec: 7.89828637670669
collect_time: 0.8862681936481969
reward_mean: 1746.6320082372856
reward_std: 758.8000375870198
reward_max: 3270.891063711144
reward_min: 1002.3319368641763
total_envstep_count: 3617415
total_train_sample_count: 2782266
total_episode_count: 13103
total_duration: 910.2481169153639
[2023-06-29 10:32:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 2767.244581307601
avg_train_sample_per_sec: 2767.244581307601
avg_episode_per_sec: 13.631746705948775
collect_time: 0.7335817056838423
reward_mean: 1710.8220121585284
reward_std: 910.6752570970114
reward_max: 3327.495572114799
reward_min: 787.7094072280505
total_envstep_count: 3621367
total_train_sample_count: 2785496
total_episode_count: 13113
total_duration: 910.9816986210477
[2023-06-29 10:32:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2596
train_sample_count: 2596
avg_envstep_per_episode: 259.6
avg_sample_per_episode: 259.6
avg_envstep_per_sec: 2732.265255377765
avg_train_sample_per_sec: 2732.265255377765
avg_episode_per_sec: 10.524904681732531
collect_time: 0.9501273695481939
reward_mean: 1492.252030985383
reward_std: 745.3828563276252
reward_max: 3288.770781798448
reward_min: 651.1755908884892
total_envstep_count: 3626663
total_train_sample_count: 2788892
total_episode_count: 13123
total_duration: 911.9318259905959
[2023-06-29 10:32:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2070
train_sample_count: 2070
avg_envstep_per_episode: 295.7142857142857
avg_sample_per_episode: 295.7142857142857
avg_envstep_per_sec: 2812.8489712789074
avg_train_sample_per_sec: 2812.8489712789074
avg_episode_per_sec: 9.51204966132964
collect_time: 0.7359086894234641
reward_mean: 2099.3494356550405
reward_std: 1028.188772892291
reward_max: 3470.6442330102263
reward_min: 937.5223000946957
total_envstep_count: 3630903
total_train_sample_count: 2792162
total_episode_count: 13130
total_duration: 912.6677346800194
[2023-06-29 10:32:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2398
train_sample_count: 2398
avg_envstep_per_episode: 299.75
avg_sample_per_episode: 299.75
avg_envstep_per_sec: 2480.6598294958826
avg_train_sample_per_sec: 2480.6598294958826
avg_episode_per_sec: 8.275762567125547
collect_time: 0.9666782891741023
reward_mean: 2079.90244887118
reward_std: 994.0999371065371
reward_max: 3408.4479267490956
reward_min: 1167.3687639787138
total_envstep_count: 3635463
total_train_sample_count: 2795760
total_episode_count: 13138
total_duration: 913.6344129691935
[2023-06-29 10:32:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2670
train_sample_count: 2670
avg_envstep_per_episode: 222.5
avg_sample_per_episode: 222.5
avg_envstep_per_sec: 2585.416387474122
avg_train_sample_per_sec: 2585.416387474122
avg_episode_per_sec: 11.619848932467965
collect_time: 1.032715663494542
reward_mean: 1499.5450928016596
reward_std: 759.3681788101204
reward_max: 3338.7023387546324
reward_min: 656.8092737530461
total_envstep_count: 3640567
total_train_sample_count: 2799230
total_episode_count: 13150
total_duration: 914.667128632688
[2023-06-29 10:32:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 292.09090909090907
avg_sample_per_episode: 292.09090909090907
avg_envstep_per_sec: 2621.298925357021
avg_train_sample_per_sec: 2621.298925357021
avg_episode_per_sec: 8.974257136298547
collect_time: 1.225728194872849
reward_mean: 1808.424970011381
reward_std: 647.4454298501208
reward_max: 2881.4258334135066
reward_min: 865.6517751118419
total_envstep_count: 3645207
total_train_sample_count: 2802443
total_episode_count: 13161
total_duration: 915.8928568275609
[2023-06-29 10:32:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2025
train_sample_count: 2025
avg_envstep_per_episode: 184.0909090909091
avg_sample_per_episode: 184.0909090909091
avg_envstep_per_sec: 2713.5200582254283
avg_train_sample_per_sec: 2713.5200582254283
avg_episode_per_sec: 14.740108958261585
collect_time: 0.7462631403300912
reward_mean: 1086.574761279252
reward_std: 413.55194616992696
reward_max: 2146.479077809492
reward_min: 661.7604246000008
total_envstep_count: 3649663
total_train_sample_count: 2805668
total_episode_count: 13172
total_duration: 916.639119967891
[2023-06-29 10:32:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 268.0833333333333
avg_sample_per_episode: 268.0833333333333
avg_envstep_per_sec: 2735.8792351102143
avg_train_sample_per_sec: 2735.8792351102143
avg_episode_per_sec: 10.205331309083796
collect_time: 1.1758559949267657
reward_mean: 1618.514176785785
reward_std: 902.4712371512684
reward_max: 3137.9684383582503
reward_min: 529.4702091705404
total_envstep_count: 3654031
total_train_sample_count: 2808885
total_episode_count: 13184
total_duration: 917.8149759628178
[2023-06-29 10:32:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 225.22222222222223
avg_sample_per_episode: 225.22222222222223
avg_envstep_per_sec: 2808.5242395322953
avg_train_sample_per_sec: 2808.5242395322953
avg_episode_per_sec: 12.470013890375263
collect_time: 0.7217313532382249
reward_mean: 1045.9335363544715
reward_std: 403.8597141068159
reward_max: 1777.7070786980485
reward_min: 638.332587981959
total_envstep_count: 3658551
total_train_sample_count: 2812112
total_episode_count: 13193
total_duration: 918.536707316056
[2023-06-29 10:32:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2742
train_sample_count: 2742
avg_envstep_per_episode: 274.2
avg_sample_per_episode: 274.2
avg_envstep_per_sec: 2621.7072841471772
avg_train_sample_per_sec: 2621.7072841471772
avg_episode_per_sec: 9.56129571169649
collect_time: 1.0458833511201664
reward_mean: 1973.552821109847
reward_std: 892.9365415553895
reward_max: 3396.9563730740583
reward_min: 930.5748037190554
total_envstep_count: 3662895
total_train_sample_count: 2815654
total_episode_count: 13203
total_duration: 919.5825906671762
[2023-06-29 10:33:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3111
train_sample_count: 3111
avg_envstep_per_episode: 311.1
avg_sample_per_episode: 311.1
avg_envstep_per_sec: 2788.4410084344763
avg_train_sample_per_sec: 2788.4410084344763
avg_episode_per_sec: 8.963166211618375
collect_time: 1.1156771796820686
reward_mean: 1503.365264084698
reward_std: 577.1496325378483
reward_max: 2921.2774119167816
reward_min: 647.71243731158
total_envstep_count: 3667775
total_train_sample_count: 2819165
total_episode_count: 13213
total_duration: 920.6982678468582
[2023-06-29 10:33:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2477
train_sample_count: 2477
avg_envstep_per_episode: 247.7
avg_sample_per_episode: 247.7
avg_envstep_per_sec: 2769.641100062599
avg_train_sample_per_sec: 2769.641100062599
avg_episode_per_sec: 11.181433589271697
collect_time: 0.8943397034164517
reward_mean: 1562.991079666896
reward_std: 701.8539684661552
reward_max: 3336.579149784607
reward_min: 663.5119101485294
total_envstep_count: 3672271
total_train_sample_count: 2822442
total_episode_count: 13223
total_duration: 921.5926075502747
[2023-06-29 10:33:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2169
train_sample_count: 2169
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2647.978531228823
avg_train_sample_per_sec: 2647.978531228823
avg_episode_per_sec: 10.987462785181838
collect_time: 0.8191154023418203
reward_mean: 1479.5109458968236
reward_std: 842.4516540977985
reward_max: 3372.3091107213254
reward_min: 784.2148162790714
total_envstep_count: 3677071
total_train_sample_count: 2825811
total_episode_count: 13232
total_duration: 922.4117229526165
[2023-06-29 10:33:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1341
train_sample_count: 1341
avg_envstep_per_episode: 191.57142857142858
avg_sample_per_episode: 191.57142857142858
avg_envstep_per_sec: 2375.2236585938986
avg_train_sample_per_sec: 2375.2236585938986
avg_episode_per_sec: 12.398632073197083
collect_time: 0.5645784114468844
reward_mean: 1967.2756305285677
reward_std: 1119.6980068679743
reward_max: 3466.6321663281656
reward_min: 642.2118605934297
total_envstep_count: 3681143
total_train_sample_count: 2829152
total_episode_count: 13239
total_duration: 922.9763013640634
[2023-06-29 10:33:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2295
train_sample_count: 2295
avg_envstep_per_episode: 286.875
avg_sample_per_episode: 286.875
avg_envstep_per_sec: 2530.160397725798
avg_train_sample_per_sec: 2530.160397725798
avg_episode_per_sec: 8.819731233902564
collect_time: 0.907057118616998
reward_mean: 1946.7608081580245
reward_std: 950.1746553654754
reward_max: 3356.080134983165
reward_min: 838.6543220130848
total_envstep_count: 3685295
total_train_sample_count: 2832647
total_episode_count: 13247
total_duration: 923.8833584826804
[2023-06-29 10:33:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 166.1
avg_sample_per_episode: 166.1
avg_envstep_per_sec: 2751.5687184944704
avg_train_sample_per_sec: 2751.5687184944704
avg_episode_per_sec: 16.565735812730104
collect_time: 0.6036556488070636
reward_mean: 1462.9721805470886
reward_std: 966.8713740461435
reward_max: 3386.5913782298644
reward_min: 643.8687147922229
total_envstep_count: 3689703
total_train_sample_count: 2835908
total_episode_count: 13257
total_duration: 924.4870141314874
[2023-06-29 10:33:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1462
train_sample_count: 1462
avg_envstep_per_episode: 292.4
avg_sample_per_episode: 292.4
avg_envstep_per_sec: 2696.108492338459
avg_train_sample_per_sec: 2696.108492338459
avg_episode_per_sec: 9.220617278859299
collect_time: 0.5422630447382109
reward_mean: 2680.3073266639885
reward_std: 549.6864251390648
reward_max: 3388.7906867320185
reward_min: 2068.234607752145
total_envstep_count: 3694031
total_train_sample_count: 2839370
total_episode_count: 13262
total_duration: 925.0292771762256
[2023-06-29 10:33:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1603
train_sample_count: 1603
avg_envstep_per_episode: 200.375
avg_sample_per_episode: 200.375
avg_envstep_per_sec: 2466.570680994534
avg_train_sample_per_sec: 2466.570680994534
avg_episode_per_sec: 12.309772581382578
collect_time: 0.6498901541121304
reward_mean: 1875.5510048035953
reward_std: 935.7786525715901
reward_max: 3281.0383337316175
reward_min: 732.429884950044
total_envstep_count: 3698031
total_train_sample_count: 2842573
total_episode_count: 13270
total_duration: 925.6791673303377
[2023-06-29 10:33:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2575
train_sample_count: 2575
avg_envstep_per_episode: 286.1111111111111
avg_sample_per_episode: 286.1111111111111
avg_envstep_per_sec: 2534.077308165955
avg_train_sample_per_sec: 2534.077308165955
avg_episode_per_sec: 8.856969232424698
collect_time: 1.016148951613344
reward_mean: 1996.0363917698835
reward_std: 1001.9061513489906
reward_max: 3403.1777695187975
reward_min: 674.5699600360655
total_envstep_count: 3701823
total_train_sample_count: 2845948
total_episode_count: 13279
total_duration: 926.695316281951
[2023-06-29 10:33:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 254.5
avg_sample_per_episode: 254.5
avg_envstep_per_sec: 2770.940225831881
avg_train_sample_per_sec: 2770.940225831881
avg_episode_per_sec: 10.8877808480624
collect_time: 0.7347686467645689
reward_mean: 1399.2893032713878
reward_std: 788.8550220796202
reward_max: 3321.371089871214
reward_min: 661.4233432016682
total_envstep_count: 3705863
total_train_sample_count: 2849184
total_episode_count: 13287
total_duration: 927.4300849287156
[2023-06-29 10:33:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2517
train_sample_count: 2517
avg_envstep_per_episode: 228.8181818181818
avg_sample_per_episode: 228.8181818181818
avg_envstep_per_sec: 2549.3061589448594
avg_train_sample_per_sec: 2549.3061589448594
avg_episode_per_sec: 11.141187027569904
collect_time: 0.9873274699347094
reward_mean: 1446.47316652301
reward_std: 784.5808644712532
reward_max: 3429.381044744559
reward_min: 781.0241089243196
total_envstep_count: 3710535
total_train_sample_count: 2852501
total_episode_count: 13298
total_duration: 928.4174123986503
[2023-06-29 10:33:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 592
train_sample_count: 592
avg_envstep_per_episode: 148.0
avg_sample_per_episode: 148.0
avg_envstep_per_sec: 2692.8653232814822
avg_train_sample_per_sec: 2692.8653232814822
avg_episode_per_sec: 18.195035968118123
collect_time: 0.21984018097072838
reward_mean: 1639.0345142945075
reward_std: 605.1203527469394
reward_max: 2621.3754153548807
reward_min: 1062.46314386158
total_envstep_count: 3714335
total_train_sample_count: 2855893
total_episode_count: 13302
total_duration: 928.6372525796211
[2023-06-29 10:33:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1597
train_sample_count: 1597
avg_envstep_per_episode: 177.44444444444446
avg_sample_per_episode: 177.44444444444446
avg_envstep_per_sec: 2392.453114419619
avg_train_sample_per_sec: 2392.453114419619
avg_episode_per_sec: 13.482829073122462
collect_time: 0.6675156935676934
reward_mean: 2214.7945802488916
reward_std: 792.8720175448954
reward_max: 3412.182856893393
reward_min: 937.9043014141398
total_envstep_count: 3719015
total_train_sample_count: 2859490
total_episode_count: 13311
total_duration: 929.3047682731888
[2023-06-29 10:33:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1620
train_sample_count: 1620
avg_envstep_per_episode: 324.0
avg_sample_per_episode: 324.0
avg_envstep_per_sec: 2751.525533671128
avg_train_sample_per_sec: 2751.525533671128
avg_episode_per_sec: 8.492362758244223
collect_time: 0.5887642982685939
reward_mean: 2603.1358414719607
reward_std: 693.471002827603
reward_max: 3372.5405662187522
reward_min: 1536.938717132511
total_envstep_count: 3723135
total_train_sample_count: 2862710
total_episode_count: 13316
total_duration: 929.8935325714574
[2023-06-29 10:33:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 800
train_sample_count: 800
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 2673.470555822977
avg_train_sample_per_sec: 2673.470555822977
avg_episode_per_sec: 16.70919097389361
collect_time: 0.29923651048168554
reward_mean: 2499.2308742145783
reward_std: 693.7237454354043
reward_max: 3279.9175237254867
reward_min: 1659.0286903953504
total_envstep_count: 3727119
total_train_sample_count: 2865910
total_episode_count: 13321
total_duration: 930.1927690819391
[2023-06-29 10:33:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1673
train_sample_count: 1673
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 2405.446172166632
avg_train_sample_per_sec: 2405.446172166632
avg_episode_per_sec: 10.064628335425239
collect_time: 0.6955050665270537
reward_mean: 2187.277659382555
reward_std: 1294.5820025834983
reward_max: 3367.550132562383
reward_min: 158.22893870897556
total_envstep_count: 3731727
total_train_sample_count: 2869183
total_episode_count: 13328
total_duration: 930.8882741484662
[2023-06-29 10:33:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2052
train_sample_count: 2052
avg_envstep_per_episode: 293.14285714285717
avg_sample_per_episode: 293.14285714285717
avg_envstep_per_sec: 2768.8869181675304
avg_train_sample_per_sec: 2768.8869181675304
avg_episode_per_sec: 9.445520676010094
collect_time: 0.7410920202396812
reward_mean: 2583.7458842650817
reward_std: 897.3738625513026
reward_max: 3393.7236162017525
reward_min: 654.965284276516
total_envstep_count: 3735791
total_train_sample_count: 2872435
total_episode_count: 13335
total_duration: 931.6293661687058
[2023-06-29 10:33:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2086
train_sample_count: 2086
avg_envstep_per_episode: 260.75
avg_sample_per_episode: 260.75
avg_envstep_per_sec: 2762.807785774875
avg_train_sample_per_sec: 2762.807785774875
avg_episode_per_sec: 10.595619504409875
collect_time: 0.7550290001137183
reward_mean: 1910.8634297515464
reward_std: 1073.0130857738345
reward_max: 3464.633131122246
reward_min: 446.47123294023913
total_envstep_count: 3740311
total_train_sample_count: 2875721
total_episode_count: 13343
total_duration: 932.3843951688195
[2023-06-29 10:33:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2407
train_sample_count: 2407
avg_envstep_per_episode: 300.875
avg_sample_per_episode: 300.875
avg_envstep_per_sec: 2574.671722106042
avg_train_sample_per_sec: 2574.671722106042
avg_episode_per_sec: 8.557280339363663
collect_time: 0.9348764657387508
reward_mean: 2097.4460352641613
reward_std: 1143.0778183991013
reward_max: 3534.9073435626883
reward_min: 646.8467745229563
total_envstep_count: 3744599
total_train_sample_count: 2878928
total_episode_count: 13351
total_duration: 933.3192716345583
[2023-06-29 10:33:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2838
train_sample_count: 2838
avg_envstep_per_episode: 283.8
avg_sample_per_episode: 283.8
avg_envstep_per_sec: 2501.955409147435
avg_train_sample_per_sec: 2501.955409147435
avg_episode_per_sec: 8.815910532584338
collect_time: 1.1343127817641943
reward_mean: 1577.5833852617957
reward_std: 1015.6085727509585
reward_max: 3456.7816606606707
reward_min: 409.1845134865109
total_envstep_count: 3749407
total_train_sample_count: 2882166
total_episode_count: 13361
total_duration: 934.4535844163224
[2023-06-29 10:34:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 266.8333333333333
avg_sample_per_episode: 266.8333333333333
avg_envstep_per_sec: 2577.859767417337
avg_train_sample_per_sec: 2577.859767417337
avg_episode_per_sec: 9.66093604278827
collect_time: 1.2421156652783973
reward_mean: 1499.5455890344708
reward_std: 591.790928728609
reward_max: 2860.4095406006727
reward_min: 661.4457979727147
total_envstep_count: 3753487
total_train_sample_count: 2885368
total_episode_count: 13373
total_duration: 935.6957000816009
[2023-06-29 10:34:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2815
train_sample_count: 2815
avg_envstep_per_episode: 351.875
avg_sample_per_episode: 351.875
avg_envstep_per_sec: 2748.418315310121
avg_train_sample_per_sec: 2748.418315310121
avg_episode_per_sec: 7.810780292177964
collect_time: 1.0242254551714287
reward_mean: 1551.3719401108103
reward_std: 632.3785442280922
reward_max: 2515.4459709389484
reward_min: 659.2996540697497
total_envstep_count: 3757559
total_train_sample_count: 2888583
total_episode_count: 13381
total_duration: 936.7199255367723
[2023-06-29 10:34:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2517
train_sample_count: 2517
avg_envstep_per_episode: 314.625
avg_sample_per_episode: 314.625
avg_envstep_per_sec: 2524.4928193307633
avg_train_sample_per_sec: 2524.4928193307633
avg_episode_per_sec: 8.023815079319073
collect_time: 0.9970319506265224
reward_mean: 1596.5191198643463
reward_std: 494.8856954394654
reward_max: 2426.5156336694167
reward_min: 836.743016172614
total_envstep_count: 3761863
total_train_sample_count: 2891900
total_episode_count: 13389
total_duration: 937.7169574873988
[2023-06-29 10:34:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3086
train_sample_count: 3086
avg_envstep_per_episode: 237.3846153846154
avg_sample_per_episode: 237.3846153846154
avg_envstep_per_sec: 2570.5440067446075
avg_train_sample_per_sec: 2570.5440067446075
avg_episode_per_sec: 10.828604046558619
collect_time: 1.2005240882486106
reward_mean: 1327.4477745006452
reward_std: 727.1154631655768
reward_max: 3425.0005920886215
reward_min: 625.1489661019943
total_envstep_count: 3766831
total_train_sample_count: 2895386
total_episode_count: 13402
total_duration: 938.9174815756473
[2023-06-29 10:34:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2966
train_sample_count: 2966
avg_envstep_per_episode: 228.15384615384616
avg_sample_per_episode: 228.15384615384616
avg_envstep_per_sec: 2688.5959378767047
avg_train_sample_per_sec: 2688.5959378767047
avg_episode_per_sec: 11.784135938097492
collect_time: 1.103178041079082
reward_mean: 1250.4491124853253
reward_std: 461.16398637136854
reward_max: 2311.288344974644
reward_min: 677.048123188531
total_envstep_count: 3771207
total_train_sample_count: 2898752
total_episode_count: 13415
total_duration: 940.0206596167264
[2023-06-29 10:34:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2573
train_sample_count: 2573
avg_envstep_per_episode: 257.3
avg_sample_per_episode: 257.3
avg_envstep_per_sec: 2724.0950840563287
avg_train_sample_per_sec: 2724.0950840563287
avg_episode_per_sec: 10.587233128862529
collect_time: 0.9445338435722517
reward_mean: 1308.652214095729
reward_std: 431.54111755417176
reward_max: 2161.325564438612
reward_min: 706.404040645883
total_envstep_count: 3775615
total_train_sample_count: 2902125
total_episode_count: 13425
total_duration: 940.9651934602987
[2023-06-29 10:34:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2005
train_sample_count: 2005
avg_envstep_per_episode: 334.1666666666667
avg_sample_per_episode: 334.1666666666667
avg_envstep_per_sec: 2685.2703257548246
avg_train_sample_per_sec: 2685.2703257548246
avg_episode_per_sec: 8.035721673081769
collect_time: 0.7466659802440554
reward_mean: 2183.1071544982174
reward_std: 835.2097588902074
reward_max: 3427.3424584646173
reward_min: 1481.0611761879397
total_envstep_count: 3780231
total_train_sample_count: 2905330
total_episode_count: 13431
total_duration: 941.7118594405428
[2023-06-29 10:34:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2098
train_sample_count: 2098
avg_envstep_per_episode: 262.25
avg_sample_per_episode: 262.25
avg_envstep_per_sec: 2768.402217793174
avg_train_sample_per_sec: 2768.402217793174
avg_episode_per_sec: 10.556347827619348
collect_time: 0.7578378555383533
reward_mean: 1996.4151073103694
reward_std: 819.7848643019064
reward_max: 3517.461059677266
reward_min: 1025.875006400422
total_envstep_count: 3784663
total_train_sample_count: 2908628
total_episode_count: 13439
total_duration: 942.4696972960811
[2023-06-29 10:34:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1386
train_sample_count: 1386
avg_envstep_per_episode: 277.2
avg_sample_per_episode: 277.2
avg_envstep_per_sec: 2653.919280161418
avg_train_sample_per_sec: 2653.919280161418
avg_episode_per_sec: 9.574023377205693
collect_time: 0.5222464791452511
reward_mean: 2533.6307709950925
reward_std: 827.6841659345324
reward_max: 3587.373409248292
reward_min: 1558.0482382477935
total_envstep_count: 3789511
total_train_sample_count: 2912014
total_episode_count: 13444
total_duration: 942.9919437752263
[2023-06-29 10:34:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2139
train_sample_count: 2139
avg_envstep_per_episode: 356.5
avg_sample_per_episode: 356.5
avg_envstep_per_sec: 2724.785484653284
avg_train_sample_per_sec: 2724.785484653284
avg_episode_per_sec: 7.6431570397006565
collect_time: 0.7850159258581699
reward_mean: 3182.536205250621
reward_std: 238.42374140545198
reward_max: 3387.3003385466673
reward_min: 2829.9455668098426
total_envstep_count: 3794023
total_train_sample_count: 2915353
total_episode_count: 13450
total_duration: 943.7769597010845
[2023-06-29 10:34:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 885
train_sample_count: 885
avg_envstep_per_episode: 221.25
avg_sample_per_episode: 221.25
avg_envstep_per_sec: 2539.218560711326
avg_train_sample_per_sec: 2539.218560711326
avg_episode_per_sec: 11.476694059712209
collect_time: 0.3485324239879846
reward_mean: 2393.4197157062727
reward_std: 642.7514972935898
reward_max: 3405.476938789014
reward_min: 1658.4953365592307
total_envstep_count: 3797823
total_train_sample_count: 2918638
total_episode_count: 13454
total_duration: 944.1254921250725
[2023-06-29 10:34:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 244.0
avg_sample_per_episode: 244.0
avg_envstep_per_sec: 2813.9495951907675
avg_train_sample_per_sec: 2813.9495951907675
avg_episode_per_sec: 11.532580308158883
collect_time: 0.433554318842478
reward_mean: 2747.0665507106014
reward_std: 800.7839824806329
reward_max: 3431.7606456032745
reward_min: 1205.5213409398457
total_envstep_count: 3801687
total_train_sample_count: 2921858
total_episode_count: 13459
total_duration: 944.5590464439149
[2023-06-29 10:34:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 741
train_sample_count: 741
avg_envstep_per_episode: 185.25
avg_sample_per_episode: 185.25
avg_envstep_per_sec: 2733.20847149541
avg_train_sample_per_sec: 2733.20847149541
avg_episode_per_sec: 14.754161789448906
collect_time: 0.2711099455924705
reward_mean: 3009.3310042731723
reward_std: 618.2605799804878
reward_max: 3468.462411733923
reward_min: 1944.2932808445996
total_envstep_count: 3806079
total_train_sample_count: 2925399
total_episode_count: 13463
total_duration: 944.8301563895074
[2023-06-29 10:34:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2296
train_sample_count: 2296
avg_envstep_per_episode: 328.0
avg_sample_per_episode: 328.0
avg_envstep_per_sec: 2754.3808670240664
avg_train_sample_per_sec: 2754.3808670240664
avg_episode_per_sec: 8.397502643366057
collect_time: 0.8335811606477945
reward_mean: 3161.155966893555
reward_std: 304.1601966805652
reward_max: 3387.571125088398
reward_min: 2658.130166795861
total_envstep_count: 3811815
total_train_sample_count: 2928895
total_episode_count: 13470
total_duration: 945.6637375501551
[2023-06-29 10:34:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1380
train_sample_count: 1380
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 2696.094234979259
avg_train_sample_per_sec: 2696.094234979259
avg_episode_per_sec: 11.722148847735909
collect_time: 0.5118515451336278
reward_mean: 2544.821853984408
reward_std: 623.3170692043548
reward_max: 3367.467721973946
reward_min: 1728.768568971184
total_envstep_count: 3816559
total_train_sample_count: 2932275
total_episode_count: 13476
total_duration: 946.1755890952887
[2023-06-29 10:34:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1686
train_sample_count: 1686
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2359.1040383631457
avg_train_sample_per_sec: 2359.1040383631457
avg_episode_per_sec: 8.395388036879522
collect_time: 0.7146781034590675
reward_mean: 2775.1260758144613
reward_std: 712.2332364784438
reward_max: 3425.2115632453892
reward_min: 1372.4664690739162
total_envstep_count: 3820831
total_train_sample_count: 2935561
total_episode_count: 13482
total_duration: 946.8902671987478
[2023-06-29 10:34:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2221
train_sample_count: 2221
avg_envstep_per_episode: 277.625
avg_sample_per_episode: 277.625
avg_envstep_per_sec: 2470.0441994206626
avg_train_sample_per_sec: 2470.0441994206626
avg_episode_per_sec: 8.897052496787618
collect_time: 0.8991741931261494
reward_mean: 2210.609819405981
reward_std: 754.1993987019223
reward_max: 3287.285171102742
reward_min: 1031.1555692456343
total_envstep_count: 3825647
total_train_sample_count: 2938982
total_episode_count: 13490
total_duration: 947.7894413918739
[2023-06-29 10:34:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 292.7
avg_sample_per_episode: 292.7
avg_envstep_per_sec: 2611.88641203877
avg_train_sample_per_sec: 2611.88641203877
avg_episode_per_sec: 8.923424708024495
collect_time: 1.1206459769876673
reward_mean: 1986.440853304448
reward_std: 637.6754745200046
reward_max: 3063.4452564338926
reward_min: 890.2964627634984
total_envstep_count: 3830447
total_train_sample_count: 2942309
total_episode_count: 13500
total_duration: 948.9100873688616
[2023-06-29 10:34:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2776.3223920415994
avg_train_sample_per_sec: 2776.3223920415994
avg_episode_per_sec: 10.320901085656503
collect_time: 0.872016883536242
reward_mean: 1667.6597855107234
reward_std: 405.3165708930552
reward_max: 2075.7261546552877
reward_min: 884.5116273560806
total_envstep_count: 3835167
total_train_sample_count: 2945530
total_episode_count: 13509
total_duration: 949.7821042523979
[2023-06-29 10:35:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 406.5
avg_sample_per_episode: 406.5
avg_envstep_per_sec: 2684.8345157920635
avg_train_sample_per_sec: 2684.8345157920635
avg_episode_per_sec: 6.60475895643804
collect_time: 0.6056239185081794
reward_mean: 2520.275282545666
reward_std: 502.4856075213819
reward_max: 3139.1752043792053
reward_min: 1819.4455416169187
total_envstep_count: 3838815
total_train_sample_count: 2948756
total_episode_count: 13513
total_duration: 950.387728170906
[2023-06-29 10:35:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1816
train_sample_count: 1816
avg_envstep_per_episode: 259.42857142857144
avg_sample_per_episode: 259.42857142857144
avg_envstep_per_sec: 2498.4957191532903
avg_train_sample_per_sec: 2498.4957191532903
avg_episode_per_sec: 9.630765437264886
collect_time: 0.7268373469999061
reward_mean: 2374.3417188408407
reward_std: 879.1928423290416
reward_max: 3405.696398102426
reward_min: 1084.6122450342953
total_envstep_count: 3842943
total_train_sample_count: 2952172
total_episode_count: 13520
total_duration: 951.1145655179059
[2023-06-29 10:35:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2050
train_sample_count: 2050
avg_envstep_per_episode: 341.6666666666667
avg_sample_per_episode: 341.6666666666667
avg_envstep_per_sec: 2748.796329456645
avg_train_sample_per_sec: 2748.796329456645
avg_episode_per_sec: 8.045257549629204
collect_time: 0.7457809725776314
reward_mean: 2402.4731179760115
reward_std: 684.245023189794
reward_max: 3376.9244140098276
reward_min: 1393.3044960459497
total_envstep_count: 3847151
total_train_sample_count: 2955422
total_episode_count: 13526
total_duration: 951.8603464904836
[2023-06-29 10:35:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2361
train_sample_count: 2361
avg_envstep_per_episode: 295.125
avg_sample_per_episode: 295.125
avg_envstep_per_sec: 2551.4730854944846
avg_train_sample_per_sec: 2551.4730854944846
avg_episode_per_sec: 8.645398002522608
collect_time: 0.9253477974832056
reward_mean: 2040.8288464898312
reward_std: 555.8585936960337
reward_max: 3450.4476924977366
reward_min: 1502.1082258576191
total_envstep_count: 3852543
total_train_sample_count: 2958983
total_episode_count: 13534
total_duration: 952.7856942879669
[2023-06-29 10:35:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2858
train_sample_count: 2858
avg_envstep_per_episode: 238.16666666666666
avg_sample_per_episode: 238.16666666666666
avg_envstep_per_sec: 2537.836023243376
avg_train_sample_per_sec: 2537.836023243376
avg_episode_per_sec: 10.655714583247205
collect_time: 1.1261562897777184
reward_mean: 1652.3710073048671
reward_std: 751.6477016577962
reward_max: 3431.2645138684725
reward_min: 954.6118922238556
total_envstep_count: 3857295
total_train_sample_count: 2962241
total_episode_count: 13546
total_duration: 953.9118505777445
[2023-06-29 10:35:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1881
train_sample_count: 1881
avg_envstep_per_episode: 235.125
avg_sample_per_episode: 235.125
avg_envstep_per_sec: 2450.6415526714204
avg_train_sample_per_sec: 2450.6415526714204
avg_episode_per_sec: 10.422717927363829
collect_time: 0.767554111677222
reward_mean: 1535.1685326835134
reward_std: 667.5949277649573
reward_max: 3232.42178140729
reward_min: 931.1951540769102
total_envstep_count: 3861991
total_train_sample_count: 2965722
total_episode_count: 13554
total_duration: 954.6794046894217
[2023-06-29 10:35:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2422
train_sample_count: 2422
avg_envstep_per_episode: 269.1111111111111
avg_sample_per_episode: 269.1111111111111
avg_envstep_per_sec: 2760.729377869838
avg_train_sample_per_sec: 2760.729377869838
avg_episode_per_sec: 10.25869711016868
collect_time: 0.8773043889831753
reward_mean: 2244.8879522523052
reward_std: 881.2175678067589
reward_max: 3519.3545526689436
reward_min: 1053.3867354000329
total_envstep_count: 3866207
total_train_sample_count: 2968944
total_episode_count: 13563
total_duration: 955.5567090784049
[2023-06-29 10:35:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2867
train_sample_count: 2867
avg_envstep_per_episode: 358.375
avg_sample_per_episode: 358.375
avg_envstep_per_sec: 2768.0448024177726
avg_train_sample_per_sec: 2768.0448024177726
avg_episode_per_sec: 7.723878067437105
collect_time: 1.0357491314793006
reward_mean: 2003.4037863492717
reward_std: 756.0351747390114
reward_max: 3150.3887677988578
reward_min: 1160.2211906882471
total_envstep_count: 3871311
total_train_sample_count: 2972211
total_episode_count: 13571
total_duration: 956.5924582098842
[2023-06-29 10:35:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2134
train_sample_count: 2134
avg_envstep_per_episode: 266.75
avg_sample_per_episode: 266.75
avg_envstep_per_sec: 2500.2201049550026
avg_train_sample_per_sec: 2500.2201049550026
avg_episode_per_sec: 9.372896363467676
collect_time: 0.8535248539801684
reward_mean: 1704.598536176687
reward_std: 835.3719028799189
reward_max: 3488.9714646932152
reward_min: 823.0553149058244
total_envstep_count: 3875703
total_train_sample_count: 2975545
total_episode_count: 13579
total_duration: 957.4459830638643
[2023-06-29 10:35:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1862
train_sample_count: 1862
avg_envstep_per_episode: 232.75
avg_sample_per_episode: 232.75
avg_envstep_per_sec: 2477.5495012741344
avg_train_sample_per_sec: 2477.5495012741344
avg_episode_per_sec: 10.644680993659009
collect_time: 0.7515490604899824
reward_mean: 1973.2399078531703
reward_std: 925.7946323195393
reward_max: 3419.926776982449
reward_min: 997.6270842893548
total_envstep_count: 3880335
total_train_sample_count: 2979007
total_episode_count: 13587
total_duration: 958.1975321243543
[2023-06-29 10:35:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2611
train_sample_count: 2611
avg_envstep_per_episode: 290.1111111111111
avg_sample_per_episode: 290.1111111111111
avg_envstep_per_sec: 2740.128258282456
avg_train_sample_per_sec: 2740.128258282456
avg_episode_per_sec: 9.445099320008467
collect_time: 0.9528751043342054
reward_mean: 2022.560018647701
reward_std: 835.6344149468324
reward_max: 3378.2947875314376
reward_min: 868.2774725556475
total_envstep_count: 3885575
total_train_sample_count: 2982418
total_episode_count: 13596
total_duration: 959.1504072286886
[2023-06-29 10:35:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 675
train_sample_count: 675
avg_envstep_per_episode: 168.75
avg_sample_per_episode: 168.75
avg_envstep_per_sec: 2670.4159842613717
avg_train_sample_per_sec: 2670.4159842613717
avg_episode_per_sec: 15.824687314141462
collect_time: 0.2527696074238047
reward_mean: 2055.676429670503
reward_std: 920.3079472773519
reward_max: 3478.0376700018996
reward_min: 1221.7213585924442
total_envstep_count: 3890071
total_train_sample_count: 2985893
total_episode_count: 13600
total_duration: 959.4031768361124
[2023-06-29 10:35:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1925
train_sample_count: 1925
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2600.239157457183
avg_train_sample_per_sec: 2600.239157457183
avg_episode_per_sec: 9.455415118026119
collect_time: 0.7403165183784439
reward_mean: 3180.518121368296
reward_std: 244.42495565453234
reward_max: 3406.4778229261224
reward_min: 2785.033535596074
total_envstep_count: 3894463
total_train_sample_count: 2989418
total_episode_count: 13607
total_duration: 960.1434933544908
[2023-06-29 10:35:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 2725.9724130702994
avg_train_sample_per_sec: 2725.9724130702994
avg_episode_per_sec: 15.75706597150462
collect_time: 0.3173179581174627
reward_mean: 1865.5640213344043
reward_std: 894.7249066368307
reward_max: 3349.4984908198953
reward_min: 934.8295556786319
total_envstep_count: 3898391
total_train_sample_count: 2992683
total_episode_count: 13612
total_duration: 960.4608113126083
[2023-06-29 10:35:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1795
train_sample_count: 1795
avg_envstep_per_episode: 224.375
avg_sample_per_episode: 224.375
avg_envstep_per_sec: 2747.391249990313
avg_train_sample_per_sec: 2747.391249990313
avg_episode_per_sec: 12.244640668480503
collect_time: 0.6533470615101977
reward_mean: 2509.5325192286036
reward_std: 1106.2741845018995
reward_max: 3454.5873132504
reward_min: 627.8074882295042
total_envstep_count: 3902775
total_train_sample_count: 2996078
total_episode_count: 13620
total_duration: 961.1141583741185
[2023-06-29 10:35:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1315
train_sample_count: 1315
avg_envstep_per_episode: 328.75
avg_sample_per_episode: 328.75
avg_envstep_per_sec: 2792.5223182796503
avg_train_sample_per_sec: 2792.5223182796503
avg_episode_per_sec: 8.494364466249888
collect_time: 0.47090044415835264
reward_mean: 2680.0149373605786
reward_std: 756.3231897531064
reward_max: 3461.99803106771
reward_min: 1805.3078525496576
total_envstep_count: 3906551
total_train_sample_count: 2999393
total_episode_count: 13624
total_duration: 961.5850588182768
[2023-06-29 10:35:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 248.3
avg_sample_per_episode: 248.3
avg_envstep_per_sec: 2661.0858657418257
avg_train_sample_per_sec: 2661.0858657418257
avg_episode_per_sec: 10.717220562794303
collect_time: 0.93307774542924
reward_mean: 2012.4965203233016
reward_std: 1080.425034678094
reward_max: 3477.8691111472467
reward_min: 658.5384786291098
total_envstep_count: 3911511
total_train_sample_count: 3002676
total_episode_count: 13634
total_duration: 962.5181365637061
[2023-06-29 10:35:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 999
train_sample_count: 999
avg_envstep_per_episode: 333.0
avg_sample_per_episode: 333.0
avg_envstep_per_sec: 2766.340708878885
avg_train_sample_per_sec: 2766.340708878885
avg_episode_per_sec: 8.307329456092747
collect_time: 0.3611268838988618
reward_mean: 2566.4632622585113
reward_std: 660.7012341997814
reward_max: 3350.486255560024
reward_min: 1734.2584662601002
total_envstep_count: 3916311
total_train_sample_count: 3006075
total_episode_count: 13637
total_duration: 962.8792634476049
[2023-06-29 10:35:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1707
train_sample_count: 1707
avg_envstep_per_episode: 213.375
avg_sample_per_episode: 213.375
avg_envstep_per_sec: 2717.0191220843035
avg_train_sample_per_sec: 2717.0191220843035
avg_episode_per_sec: 12.73354011521642
collect_time: 0.6282620487008245
reward_mean: 2852.582222437153
reward_std: 920.3456394576989
reward_max: 3433.575288450894
reward_min: 1046.158388321279
total_envstep_count: 3920975
total_train_sample_count: 3009382
total_episode_count: 13645
total_duration: 963.5075254963057
[2023-06-29 10:36:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1597
train_sample_count: 1597
avg_envstep_per_episode: 228.14285714285714
avg_sample_per_episode: 228.14285714285714
avg_envstep_per_sec: 2764.200980065263
avg_train_sample_per_sec: 2764.200980065263
avg_episode_per_sec: 12.116096969603534
collect_time: 0.5777438078913837
reward_mean: 2129.058003138615
reward_std: 693.1409680528486
reward_max: 3378.8107197971663
reward_min: 1166.871079846385
total_envstep_count: 3926023
total_train_sample_count: 3012979
total_episode_count: 13652
total_duration: 964.085269304197
[2023-06-29 10:36:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1421
train_sample_count: 1421
avg_envstep_per_episode: 236.83333333333334
avg_sample_per_episode: 236.83333333333334
avg_envstep_per_sec: 2686.938380700809
avg_train_sample_per_sec: 2686.938380700809
avg_episode_per_sec: 11.345271135964007
collect_time: 0.528854703258723
reward_mean: 2326.6961495378146
reward_std: 1032.3270050452477
reward_max: 3355.0756091040553
reward_min: 916.7383527727171
total_envstep_count: 3930295
total_train_sample_count: 3016400
total_episode_count: 13658
total_duration: 964.6141240074558
[2023-06-29 10:36:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 849
train_sample_count: 849
avg_envstep_per_episode: 169.8
avg_sample_per_episode: 169.8
avg_envstep_per_sec: 2740.777093355248
avg_train_sample_per_sec: 2740.777093355248
avg_episode_per_sec: 16.141207852504404
collect_time: 0.30976616159640247
reward_mean: 2771.5542553104283
reward_std: 914.2364953135066
reward_max: 3432.559762530445
reward_min: 1014.1315805048331
total_envstep_count: 3934263
total_train_sample_count: 3019649
total_episode_count: 13663
total_duration: 964.9238901690521
[2023-06-29 10:36:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2131
train_sample_count: 2131
avg_envstep_per_episode: 304.42857142857144
avg_sample_per_episode: 304.42857142857144
avg_envstep_per_sec: 2732.01128845157
avg_train_sample_per_sec: 2732.01128845157
avg_episode_per_sec: 8.974227601671043
collect_time: 0.7800114183304832
reward_mean: 2537.6497670753056
reward_std: 851.0701312207972
reward_max: 3419.0094157019907
reward_min: 1464.175107746087
total_envstep_count: 3938559
total_train_sample_count: 3022980
total_episode_count: 13670
total_duration: 965.7039015873826
[2023-06-29 10:36:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 974
train_sample_count: 974
avg_envstep_per_episode: 194.8
avg_sample_per_episode: 194.8
avg_envstep_per_sec: 2728.349819323239
avg_train_sample_per_sec: 2728.349819323239
avg_episode_per_sec: 14.005902563260982
collect_time: 0.3569923450071364
reward_mean: 2302.9226370726674
reward_std: 892.8921898175114
reward_max: 3348.906359454036
reward_min: 955.7849951621994
total_envstep_count: 3943071
total_train_sample_count: 3026354
total_episode_count: 13675
total_duration: 966.0608939323897
[2023-06-29 10:36:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2317
train_sample_count: 2317
avg_envstep_per_episode: 289.625
avg_sample_per_episode: 289.625
avg_envstep_per_sec: 2638.210055308081
avg_train_sample_per_sec: 2638.210055308081
avg_episode_per_sec: 9.109055003221686
collect_time: 0.8782469748146832
reward_mean: 2509.0056066659363
reward_std: 1040.933437294505
reward_max: 3429.049809339468
reward_min: 588.2945322132608
total_envstep_count: 3947631
total_train_sample_count: 3029871
total_episode_count: 13683
total_duration: 966.9391409072044
[2023-06-29 10:36:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2679
train_sample_count: 2679
avg_envstep_per_episode: 297.6666666666667
avg_sample_per_episode: 297.6666666666667
avg_envstep_per_sec: 2478.986350869005
avg_train_sample_per_sec: 2478.986350869005
avg_episode_per_sec: 8.328061649056007
collect_time: 1.0806836427561937
reward_mean: 1964.8664132557958
reward_std: 825.6632218959511
reward_max: 3428.090935891101
reward_min: 902.0160607776908
total_envstep_count: 3952127
total_train_sample_count: 3033350
total_episode_count: 13692
total_duration: 968.0198245499606
[2023-06-29 10:36:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2202
train_sample_count: 2202
avg_envstep_per_episode: 275.25
avg_sample_per_episode: 275.25
avg_envstep_per_sec: 2741.18713636677
avg_train_sample_per_sec: 2741.18713636677
avg_episode_per_sec: 9.958899677990082
collect_time: 0.8033015954243019
reward_mean: 1608.1590862987664
reward_std: 620.3924620932236
reward_max: 2490.2965906154063
reward_min: 875.7937742011027
total_envstep_count: 3957015
total_train_sample_count: 3036752
total_episode_count: 13700
total_duration: 968.8231261453849
[2023-06-29 10:36:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 2694.2295861999582
avg_train_sample_per_sec: 2694.2295861999582
avg_episode_per_sec: 11.868852802642989
collect_time: 0.33701656482834375
reward_mean: 2605.729693525066
reward_std: 815.0815836780306
reward_max: 3487.632707116567
reward_min: 1741.1425402718367
total_envstep_count: 3961279
total_train_sample_count: 3040060
total_episode_count: 13704
total_duration: 969.1601427102132
[2023-06-29 10:36:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2041
train_sample_count: 2041
avg_envstep_per_episode: 291.57142857142856
avg_sample_per_episode: 291.57142857142856
avg_envstep_per_sec: 2587.571686093291
avg_train_sample_per_sec: 2587.571686093291
avg_episode_per_sec: 8.874572171804527
collect_time: 0.788770417828113
reward_mean: 2420.886376683301
reward_std: 1085.421566647767
reward_max: 3444.586316191376
reward_min: 816.1538762693821
total_envstep_count: 3965207
total_train_sample_count: 3043301
total_episode_count: 13711
total_duration: 969.9489131280413
[2023-06-29 10:36:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 416
train_sample_count: 416
avg_envstep_per_episode: 138.66666666666666
avg_sample_per_episode: 138.66666666666666
avg_envstep_per_sec: 2688.4621456632476
avg_train_sample_per_sec: 2688.4621456632476
avg_episode_per_sec: 19.38794816584073
collect_time: 0.1547353012468666
reward_mean: 3341.185403457977
reward_std: 28.403711739460874
reward_max: 3368.703142022578
reward_min: 3302.084142633336
total_envstep_count: 3969279
total_train_sample_count: 3046517
total_episode_count: 13714
total_duration: 970.1036484292882
[2023-06-29 10:36:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2467
train_sample_count: 2467
avg_envstep_per_episode: 352.42857142857144
avg_sample_per_episode: 352.42857142857144
avg_envstep_per_sec: 2554.0273533274653
avg_train_sample_per_sec: 2554.0273533274653
avg_episode_per_sec: 7.246936146450043
collect_time: 0.9659254419440405
reward_mean: 2755.865512982208
reward_std: 925.4013303160064
reward_max: 3462.043159814532
reward_min: 905.5612740389214
total_envstep_count: 3973447
total_train_sample_count: 3049784
total_episode_count: 13721
total_duration: 971.0695738712323
[2023-06-29 10:36:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 542
train_sample_count: 542
avg_envstep_per_episode: 180.66666666666666
avg_sample_per_episode: 180.66666666666666
avg_envstep_per_sec: 2437.280824520923
avg_train_sample_per_sec: 2437.280824520923
avg_episode_per_sec: 13.490484268565993
collect_time: 0.22237897026352582
reward_mean: 2672.5523025881366
reward_std: 979.67615842574
reward_max: 3412.2248679265176
reward_min: 1288.1661516788347
total_envstep_count: 3978063
total_train_sample_count: 3053126
total_episode_count: 13724
total_duration: 971.2919528414958
[2023-06-29 10:36:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2139
train_sample_count: 2139
avg_envstep_per_episode: 237.66666666666666
avg_sample_per_episode: 237.66666666666666
avg_envstep_per_sec: 2398.2173409092343
avg_train_sample_per_sec: 2398.2173409092343
avg_episode_per_sec: 10.090676048706456
collect_time: 0.8919124899618325
reward_mean: 2387.817456254941
reward_std: 919.1102637818891
reward_max: 3467.656461821814
reward_min: 923.8640758268538
total_envstep_count: 3982015
total_train_sample_count: 3056465
total_episode_count: 13733
total_duration: 972.1838653314576
[2023-06-29 10:36:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1067
train_sample_count: 1067
avg_envstep_per_episode: 213.4
avg_sample_per_episode: 213.4
avg_envstep_per_sec: 2659.311497352843
avg_train_sample_per_sec: 2659.311497352843
avg_episode_per_sec: 12.46162838497115
collect_time: 0.40123167258221654
reward_mean: 1834.157221013845
reward_std: 893.474019663593
reward_max: 3378.282819699678
reward_min: 1101.7697895740532
total_envstep_count: 3986655
total_train_sample_count: 3059932
total_episode_count: 13738
total_duration: 972.5850970040398
[2023-06-29 10:36:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2406.8288232166474
avg_train_sample_per_sec: 2406.8288232166474
avg_episode_per_sec: 8.386163147096331
collect_time: 0.83470830190368
reward_mean: 2843.195667544747
reward_std: 978.8072148417153
reward_max: 3535.922057814163
reward_min: 749.3995651750466
total_envstep_count: 3991455
total_train_sample_count: 3063141
total_episode_count: 13745
total_duration: 973.4198053059434
[2023-06-29 10:36:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1684
train_sample_count: 1684
avg_envstep_per_episode: 240.57142857142858
avg_sample_per_episode: 240.57142857142858
avg_envstep_per_sec: 2650.739591871761
avg_train_sample_per_sec: 2650.739591871761
avg_episode_per_sec: 11.018513742934875
collect_time: 0.6352943929927423
reward_mean: 2422.459811075325
reward_std: 820.8936844911821
reward_max: 3430.7214829238023
reward_min: 1129.6578067875707
total_envstep_count: 3995367
total_train_sample_count: 3066425
total_episode_count: 13752
total_duration: 974.0550996989361
[2023-06-29 10:36:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 2576.4740892415502
avg_train_sample_per_sec: 2576.4740892415502
avg_episode_per_sec: 8.475243714610363
collect_time: 0.8259349507475272
reward_mean: 1781.7878398403166
reward_std: 871.7436933640391
reward_max: 2897.3808879378503
reward_min: 656.3461664461411
total_envstep_count: 3999743
total_train_sample_count: 3069753
total_episode_count: 13759
total_duration: 974.8810346496837
[2023-06-29 10:36:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1936
train_sample_count: 1936
avg_envstep_per_episode: 322.6666666666667
avg_sample_per_episode: 322.6666666666667
avg_envstep_per_sec: 2602.3348481924686
avg_train_sample_per_sec: 2602.3348481924686
avg_episode_per_sec: 8.065087339439469
collect_time: 0.7439473061449828
reward_mean: 2904.4184783033925
reward_std: 648.4350373005843
reward_max: 3471.2309814731834
reward_min: 1690.7481229120156
total_envstep_count: 4004815
total_train_sample_count: 3073289
total_episode_count: 13765
total_duration: 975.6249819558286
[2023-06-29 10:36:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3123
train_sample_count: 3123
avg_envstep_per_episode: 283.90909090909093
avg_sample_per_episode: 283.90909090909093
avg_envstep_per_sec: 2513.337819790284
avg_train_sample_per_sec: 2513.337819790284
avg_episode_per_sec: 8.852614799133246
collect_time: 1.2425707262307408
reward_mean: 2027.9483520720794
reward_std: 1062.4906956691216
reward_max: 3411.9836674563294
reward_min: 542.4378518296913
total_envstep_count: 4009271
total_train_sample_count: 3076812
total_episode_count: 13776
total_duration: 976.8675526820593
[2023-06-29 10:37:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2152
train_sample_count: 2152
avg_envstep_per_episode: 195.63636363636363
avg_sample_per_episode: 195.63636363636363
avg_envstep_per_sec: 2727.6916787354044
avg_train_sample_per_sec: 2727.6916787354044
avg_episode_per_sec: 13.94266192662149
collect_time: 0.7889454723848031
reward_mean: 987.0738300365443
reward_std: 413.7004861331356
reward_max: 1853.4768083889014
reward_min: 398.0231614634052
total_envstep_count: 4013895
total_train_sample_count: 3080164
total_episode_count: 13787
total_duration: 977.6564981544442
[2023-06-29 10:37:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3314
train_sample_count: 3314
avg_envstep_per_episode: 254.92307692307693
avg_sample_per_episode: 254.92307692307693
avg_envstep_per_sec: 2687.702661762763
avg_train_sample_per_sec: 2687.702661762763
avg_episode_per_sec: 10.543190888025322
collect_time: 1.2330232979813593
reward_mean: 1638.6907846492663
reward_std: 940.439993615756
reward_max: 3583.064837724367
reward_min: 650.1659660059452
total_envstep_count: 4018615
total_train_sample_count: 3083478
total_episode_count: 13800
total_duration: 978.8895214524256
[2023-06-29 10:37:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2323
train_sample_count: 2323
avg_envstep_per_episode: 258.1111111111111
avg_sample_per_episode: 258.1111111111111
avg_envstep_per_sec: 2583.5300857191696
avg_train_sample_per_sec: 2583.5300857191696
avg_episode_per_sec: 10.009371834469446
collect_time: 0.8991573246391491
reward_mean: 1400.3198097913762
reward_std: 451.67449535657045
reward_max: 2130.2669142631553
reward_min: 779.8175304746092
total_envstep_count: 4023567
total_train_sample_count: 3087001
total_episode_count: 13809
total_duration: 979.7886787770648
[2023-06-29 10:37:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 229.57142857142858
avg_sample_per_episode: 229.57142857142858
avg_envstep_per_sec: 2579.75605374641
avg_train_sample_per_sec: 2579.75605374641
avg_episode_per_sec: 11.237269680289279
collect_time: 1.24585423312895
reward_mean: 1543.7699255830646
reward_std: 780.3807668152816
reward_max: 3497.271132638702
reward_min: 803.5739247027219
total_envstep_count: 4028063
total_train_sample_count: 3090615
total_episode_count: 13823
total_duration: 981.0345330101937
[2023-06-29 10:37:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 254.58333333333334
avg_sample_per_episode: 254.58333333333334
avg_envstep_per_sec: 2556.2277861490124
avg_train_sample_per_sec: 2556.2277861490124
avg_episode_per_sec: 10.040829274562405
collect_time: 1.1951204100642352
reward_mean: 1270.7960287524118
reward_std: 485.22071871754406
reward_max: 2126.7605321121227
reward_min: 626.4608482353458
total_envstep_count: 4032583
total_train_sample_count: 3094070
total_episode_count: 13835
total_duration: 982.2296534202579
[2023-06-29 10:37:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1460
train_sample_count: 1460
avg_envstep_per_episode: 292.0
avg_sample_per_episode: 292.0
avg_envstep_per_sec: 2757.7813242246684
avg_train_sample_per_sec: 2757.7813242246684
avg_episode_per_sec: 9.444456589810509
collect_time: 0.5294110838938505
reward_mean: 1706.8464854265658
reward_std: 886.9905489534608
reward_max: 3384.224000572277
reward_min: 814.3900016051323
total_envstep_count: 4036479
total_train_sample_count: 3097530
total_episode_count: 13840
total_duration: 982.7590645041518
[2023-06-29 10:37:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2781.699292053163
avg_train_sample_per_sec: 2781.699292053163
avg_episode_per_sec: 11.060434560847565
collect_time: 0.7232988863131031
reward_mean: 2090.4507002890077
reward_std: 952.5562698914791
reward_max: 3424.4330565213772
reward_min: 643.5481533952875
total_envstep_count: 4040999
total_train_sample_count: 3100742
total_episode_count: 13848
total_duration: 983.4823633904649
[2023-06-29 10:37:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2121
train_sample_count: 2121
avg_envstep_per_episode: 353.5
avg_sample_per_episode: 353.5
avg_envstep_per_sec: 2771.071951065373
avg_train_sample_per_sec: 2771.071951065373
avg_episode_per_sec: 7.838958843183517
collect_time: 0.7654077690709384
reward_mean: 2509.628669426893
reward_std: 698.8587264548659
reward_max: 3481.4224101203527
reward_min: 1655.8813209907305
total_envstep_count: 4045215
total_train_sample_count: 3104063
total_episode_count: 13854
total_duration: 984.2477711595359
[2023-06-29 10:37:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1882
train_sample_count: 1882
avg_envstep_per_episode: 313.6666666666667
avg_sample_per_episode: 313.6666666666667
avg_envstep_per_sec: 2629.9335035862077
avg_train_sample_per_sec: 2629.9335035862077
avg_episode_per_sec: 8.384485133643595
collect_time: 0.7156074468931184
reward_mean: 2491.9511574885078
reward_std: 958.9436684406317
reward_max: 3434.939188356408
reward_min: 890.9706776748118
total_envstep_count: 4049559
total_train_sample_count: 3107545
total_episode_count: 13860
total_duration: 984.963378606429
[2023-06-29 10:37:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1457
train_sample_count: 1457
avg_envstep_per_episode: 208.14285714285714
avg_sample_per_episode: 208.14285714285714
avg_envstep_per_sec: 2705.7718241893986
avg_train_sample_per_sec: 2705.7718241893986
avg_episode_per_sec: 12.999590095625114
collect_time: 0.5384785172846167
reward_mean: 1907.3592113394031
reward_std: 1031.8445049335144
reward_max: 3489.4482388308124
reward_min: 604.1095465433804
total_envstep_count: 4054311
total_train_sample_count: 3111002
total_episode_count: 13867
total_duration: 985.5018571237136
[2023-06-29 10:37:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2579
train_sample_count: 2579
avg_envstep_per_episode: 322.375
avg_sample_per_episode: 322.375
avg_envstep_per_sec: 2804.1597705620475
avg_train_sample_per_sec: 2804.1597705620475
avg_episode_per_sec: 8.698440544589523
collect_time: 0.9197050849506632
reward_mean: 2562.2323715391985
reward_std: 837.0932954457888
reward_max: 3492.6796790366175
reward_min: 1385.4626236338825
total_envstep_count: 4058935
total_train_sample_count: 3114381
total_episode_count: 13875
total_duration: 986.4215622086643
[2023-06-29 10:37:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1796
train_sample_count: 1796
avg_envstep_per_episode: 299.3333333333333
avg_sample_per_episode: 299.3333333333333
avg_envstep_per_sec: 2662.614810774299
avg_train_sample_per_sec: 2662.614810774299
avg_episode_per_sec: 8.895149701918593
collect_time: 0.6745249041402711
reward_mean: 2113.591655019695
reward_std: 1027.9523854834508
reward_max: 3453.413210658128
reward_min: 997.1157899273273
total_envstep_count: 4063391
total_train_sample_count: 3117777
total_episode_count: 13881
total_duration: 987.0960871128046
[2023-06-29 10:37:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2626
train_sample_count: 2626
avg_envstep_per_episode: 262.6
avg_sample_per_episode: 262.6
avg_envstep_per_sec: 2351.1698670131614
avg_train_sample_per_sec: 2351.1698670131614
avg_episode_per_sec: 8.953426759379898
collect_time: 1.116890802677721
reward_mean: 2125.907807602043
reward_std: 800.9761075842523
reward_max: 3506.893649616404
reward_min: 1268.2171559401677
total_envstep_count: 4068079
total_train_sample_count: 3121203
total_episode_count: 13891
total_duration: 988.2129779154824
[2023-06-29 10:37:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2205
train_sample_count: 2205
avg_envstep_per_episode: 275.625
avg_sample_per_episode: 275.625
avg_envstep_per_sec: 2795.8942721021904
avg_train_sample_per_sec: 2795.8942721021904
avg_episode_per_sec: 10.143834093794796
collect_time: 0.788656431683339
reward_mean: 1771.2110795672293
reward_std: 835.9400734721313
reward_max: 3314.216617897055
reward_min: 938.9735662834386
total_envstep_count: 4072927
total_train_sample_count: 3124608
total_episode_count: 13899
total_duration: 989.0016343471657
[2023-06-29 10:37:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1257
train_sample_count: 1257
avg_envstep_per_episode: 251.4
avg_sample_per_episode: 251.4
avg_envstep_per_sec: 2747.7746765455336
avg_train_sample_per_sec: 2747.7746765455336
avg_episode_per_sec: 10.929891314819148
collect_time: 0.4574610905069858
reward_mean: 2467.773387062951
reward_std: 871.4251529916951
reward_max: 3485.3907505279712
reward_min: 1303.009323146979
total_envstep_count: 4077727
total_train_sample_count: 3127865
total_episode_count: 13904
total_duration: 989.4590954376727
[2023-06-29 10:37:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2021
train_sample_count: 2021
avg_envstep_per_episode: 224.55555555555554
avg_sample_per_episode: 224.55555555555554
avg_envstep_per_sec: 2601.1141527209315
avg_train_sample_per_sec: 2601.1141527209315
avg_episode_per_sec: 11.583388112067484
collect_time: 0.7769747428754347
reward_mean: 2489.410938471809
reward_std: 886.0079932819311
reward_max: 3541.0785782632224
reward_min: 1237.9993825998354
total_envstep_count: 4081983
total_train_sample_count: 3131086
total_episode_count: 13913
total_duration: 990.236070180548
[2023-06-29 10:37:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1743
train_sample_count: 1743
avg_envstep_per_episode: 193.66666666666666
avg_sample_per_episode: 193.66666666666666
avg_envstep_per_sec: 2622.706710299549
avg_train_sample_per_sec: 2622.706710299549
avg_episode_per_sec: 13.542375440445175
collect_time: 0.6645806003222242
reward_mean: 1406.7288536552392
reward_std: 489.8638415840064
reward_max: 2496.589895195859
reward_min: 703.7118382641411
total_envstep_count: 4086287
total_train_sample_count: 3134429
total_episode_count: 13922
total_duration: 990.9006507808703
[2023-06-29 10:37:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2904
train_sample_count: 2904
avg_envstep_per_episode: 290.4
avg_sample_per_episode: 290.4
avg_envstep_per_sec: 2638.231641587203
avg_train_sample_per_sec: 2638.231641587203
avg_episode_per_sec: 9.084819702435272
collect_time: 1.1007373098796231
reward_mean: 2025.9521531385356
reward_std: 1210.279835300677
reward_max: 3571.679340403334
reward_min: 296.66194971663447
total_envstep_count: 4091703
total_train_sample_count: 3137733
total_episode_count: 13932
total_duration: 992.0013880907499
[2023-06-29 10:37:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2726
train_sample_count: 2726
avg_envstep_per_episode: 227.16666666666666
avg_sample_per_episode: 227.16666666666666
avg_envstep_per_sec: 2730.6654945753153
avg_train_sample_per_sec: 2730.6654945753153
avg_episode_per_sec: 12.020537760419584
collect_time: 0.9982914441243046
reward_mean: 1482.8661501151284
reward_std: 862.8841410305201
reward_max: 3481.6540268048643
reward_min: 320.90872118730965
total_envstep_count: 4096503
total_train_sample_count: 3141259
total_episode_count: 13944
total_duration: 992.9996795348742
[2023-06-29 10:38:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2591
train_sample_count: 2591
avg_envstep_per_episode: 235.54545454545453
avg_sample_per_episode: 235.54545454545453
avg_envstep_per_sec: 2626.4893583171474
avg_train_sample_per_sec: 2626.4893583171474
avg_episode_per_sec: 11.150668831141884
collect_time: 0.9864879108667373
reward_mean: 1568.3625447595834
reward_std: 647.24575142304
reward_max: 3506.679805458145
reward_min: 953.6519263980791
total_envstep_count: 4100583
total_train_sample_count: 3144650
total_episode_count: 13955
total_duration: 993.9861674457409
[2023-06-29 10:38:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3269
train_sample_count: 3269
avg_envstep_per_episode: 297.1818181818182
avg_sample_per_episode: 297.1818181818182
avg_envstep_per_sec: 2558.779393999538
avg_train_sample_per_sec: 2558.779393999538
avg_episode_per_sec: 8.61014785377636
collect_time: 1.2775622656904162
reward_mean: 1531.2990429083654
reward_std: 452.94324416625534
reward_max: 2631.081274028178
reward_min: 961.0605028664135
total_envstep_count: 4105191
total_train_sample_count: 3147919
total_episode_count: 13966
total_duration: 995.2637297114313
[2023-06-29 10:38:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3331
train_sample_count: 3331
avg_envstep_per_episode: 302.8181818181818
avg_sample_per_episode: 302.8181818181818
avg_envstep_per_sec: 2592.615625268456
avg_train_sample_per_sec: 2592.615625268456
avg_episode_per_sec: 8.56162470067638
collect_time: 1.2848028714843092
reward_mean: 1513.0007071934015
reward_std: 584.1745602377124
reward_max: 2377.7667455635337
reward_min: 345.3817040059291
total_envstep_count: 4109783
total_train_sample_count: 3151250
total_episode_count: 13977
total_duration: 996.5485325829156
[2023-06-29 10:38:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2459
train_sample_count: 2459
avg_envstep_per_episode: 204.91666666666666
avg_sample_per_episode: 204.91666666666666
avg_envstep_per_sec: 2747.293803600539
avg_train_sample_per_sec: 2747.293803600539
avg_episode_per_sec: 13.406883140791567
collect_time: 0.8950626237271355
reward_mean: 1064.245049583723
reward_std: 377.71896082260025
reward_max: 1813.8476479171807
reward_min: 600.2280297749926
total_envstep_count: 4113871
total_train_sample_count: 3154509
total_episode_count: 13989
total_duration: 997.4435952066427
[2023-06-29 10:38:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3057
train_sample_count: 3057
avg_envstep_per_episode: 235.15384615384616
avg_sample_per_episode: 235.15384615384616
avg_envstep_per_sec: 2612.9484550573993
avg_train_sample_per_sec: 2612.9484550573993
avg_episode_per_sec: 11.111655189972584
collect_time: 1.1699427113011482
reward_mean: 1252.3952941444256
reward_std: 403.05563616124726
reward_max: 1992.1401505199497
reward_min: 615.5479129132261
total_envstep_count: 4118391
total_train_sample_count: 3157966
total_episode_count: 14002
total_duration: 998.6135379179439
[2023-06-29 10:38:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 292.54545454545456
avg_sample_per_episode: 292.54545454545456
avg_envstep_per_sec: 2575.7460038235804
avg_train_sample_per_sec: 2575.7460038235804
avg_episode_per_sec: 8.804601007476501
collect_time: 1.2493467893274501
reward_mean: 1506.7946470544832
reward_std: 461.3271530786368
reward_max: 2442.1207661225294
reward_min: 829.0137963515641
total_envstep_count: 4122423
total_train_sample_count: 3161184
total_episode_count: 14013
total_duration: 999.8628847072713
[2023-06-29 10:38:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3111
train_sample_count: 3111
avg_envstep_per_episode: 311.1
avg_sample_per_episode: 311.1
avg_envstep_per_sec: 2747.973674290622
avg_train_sample_per_sec: 2747.973674290622
avg_episode_per_sec: 8.833087991933855
collect_time: 1.132106915399432
reward_mean: 1408.2098948942523
reward_std: 344.6525534797588
reward_max: 2018.496932890839
reward_min: 942.0794639954985
total_envstep_count: 4126935
total_train_sample_count: 3164695
total_episode_count: 14023
total_duration: 1000.9949916226707
[2023-06-29 10:38:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2806.4547808266084
avg_train_sample_per_sec: 2806.4547808266084
avg_episode_per_sec: 10.752700309680492
collect_time: 0.9299989502169193
reward_mean: 1413.403955139799
reward_std: 488.94631549369353
reward_max: 2080.3304961302792
reward_min: 633.0149403111859
total_envstep_count: 4131663
total_train_sample_count: 3168105
total_episode_count: 14033
total_duration: 1001.9249905728876
[2023-06-29 10:38:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2270
train_sample_count: 2270
avg_envstep_per_episode: 206.36363636363637
avg_sample_per_episode: 206.36363636363637
avg_envstep_per_sec: 2634.578770866552
avg_train_sample_per_sec: 2634.578770866552
avg_episode_per_sec: 12.766681268516331
collect_time: 0.8616178134819493
reward_mean: 1413.9772888835598
reward_std: 259.8913995355098
reward_max: 1839.04978648238
reward_min: 977.4772740756031
total_envstep_count: 4136319
total_train_sample_count: 3171575
total_episode_count: 14044
total_duration: 1002.7866083863696
[2023-06-29 10:38:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3344
train_sample_count: 3344
avg_envstep_per_episode: 257.2307692307692
avg_sample_per_episode: 257.2307692307692
avg_envstep_per_sec: 2650.6497283775093
avg_train_sample_per_sec: 2650.6497283775093
avg_episode_per_sec: 10.304559350749887
collect_time: 1.2615774782309308
reward_mean: 1561.4800683322499
reward_std: 831.4703869026259
reward_max: 3592.612765575638
reward_min: 285.4754445103801
total_envstep_count: 4140791
total_train_sample_count: 3174919
total_episode_count: 14057
total_duration: 1004.0481858646006
[2023-06-29 10:38:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3477
train_sample_count: 3477
avg_envstep_per_episode: 289.75
avg_sample_per_episode: 289.75
avg_envstep_per_sec: 2618.1369824941435
avg_train_sample_per_sec: 2618.1369824941435
avg_episode_per_sec: 9.03584808453544
collect_time: 1.3280435757366937
reward_mean: 1360.0769430724072
reward_std: 310.9679450455858
reward_max: 2080.2230104063474
reward_min: 925.3086946953832
total_envstep_count: 4145487
total_train_sample_count: 3178396
total_episode_count: 14069
total_duration: 1005.3762294403373
[2023-06-29 10:38:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3070
train_sample_count: 3070
avg_envstep_per_episode: 279.09090909090907
avg_sample_per_episode: 279.09090909090907
avg_envstep_per_sec: 2609.153484274415
avg_train_sample_per_sec: 2609.153484274415
avg_episode_per_sec: 9.34875841270963
collect_time: 1.1766268326118587
reward_mean: 1355.4184301260004
reward_std: 403.27980179909054
reward_max: 2423.0688023166435
reward_min: 918.8114112979434
total_envstep_count: 4150375
total_train_sample_count: 3181866
total_episode_count: 14080
total_duration: 1006.5528562729492
[2023-06-29 10:38:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2907
train_sample_count: 2907
avg_envstep_per_episode: 223.6153846153846
avg_sample_per_episode: 223.6153846153846
avg_envstep_per_sec: 2631.753297366628
avg_train_sample_per_sec: 2631.753297366628
avg_episode_per_sec: 11.769106592970816
collect_time: 1.1045868178103122
reward_mean: 1278.7724149904486
reward_std: 416.21472117846247
reward_max: 2293.716082224565
reward_min: 614.5754650336236
total_envstep_count: 4154639
total_train_sample_count: 3185173
total_episode_count: 14093
total_duration: 1007.6574430907594
[2023-06-29 10:38:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3020
train_sample_count: 3020
avg_envstep_per_episode: 251.66666666666666
avg_sample_per_episode: 251.66666666666666
avg_envstep_per_sec: 2560.860735664476
avg_train_sample_per_sec: 2560.860735664476
avg_episode_per_sec: 10.175605572176726
collect_time: 1.1792909930404276
reward_mean: 1286.0452387518524
reward_std: 277.0304377058602
reward_max: 1755.350007477097
reward_min: 900.9480549844775
total_envstep_count: 4159559
total_train_sample_count: 3188593
total_episode_count: 14105
total_duration: 1008.8367340837999
[2023-06-29 10:38:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1667
train_sample_count: 1667
avg_envstep_per_episode: 185.22222222222223
avg_sample_per_episode: 185.22222222222223
avg_envstep_per_sec: 2705.537764545609
avg_train_sample_per_sec: 2705.537764545609
avg_episode_per_sec: 14.606982532039881
collect_time: 0.6161436819862576
reward_mean: 1404.2426857385565
reward_std: 302.1634525297256
reward_max: 1707.913092057109
reward_min: 902.4393268582822
total_envstep_count: 4163695
total_train_sample_count: 3191860
total_episode_count: 14114
total_duration: 1009.4528777657862
[2023-06-29 10:38:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1140
train_sample_count: 1140
avg_envstep_per_episode: 142.5
avg_sample_per_episode: 142.5
avg_envstep_per_sec: 2718.731675075507
avg_train_sample_per_sec: 2718.731675075507
avg_episode_per_sec: 19.078818772459698
collect_time: 0.41931317108310767
reward_mean: 1551.2287053226253
reward_std: 576.677483400994
reward_max: 2275.470231130149
reward_min: 289.89200950573814
total_envstep_count: 4168319
total_train_sample_count: 3195400
total_episode_count: 14122
total_duration: 1009.8721909368693
[2023-06-29 10:38:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 258.44444444444446
avg_sample_per_episode: 258.44444444444446
avg_envstep_per_sec: 2754.096867390041
avg_train_sample_per_sec: 2754.096867390041
avg_episode_per_sec: 10.656436718190184
collect_time: 0.8445599817279728
reward_mean: 2341.703916329686
reward_std: 759.9029998880824
reward_max: 3496.1858560294295
reward_min: 925.396400585051
total_envstep_count: 4172863
total_train_sample_count: 3198926
total_episode_count: 14131
total_duration: 1010.7167509185973
[2023-06-29 10:38:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1838
train_sample_count: 1838
avg_envstep_per_episode: 183.8
avg_sample_per_episode: 183.8
avg_envstep_per_sec: 2615.2832475060077
avg_train_sample_per_sec: 2615.2832475060077
avg_episode_per_sec: 14.2289621735909
collect_time: 0.702791944907978
reward_mean: 1453.53085962326
reward_std: 362.5698617403657
reward_max: 2049.914163596302
reward_min: 883.2549814700081
total_envstep_count: 4176999
total_train_sample_count: 3202364
total_episode_count: 14141
total_duration: 1011.4195428635053
[2023-06-29 10:38:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 312.25
avg_sample_per_episode: 312.25
avg_envstep_per_sec: 2572.34416675727
avg_train_sample_per_sec: 2572.34416675727
avg_episode_per_sec: 8.238091807068919
collect_time: 0.9710986703420059
reward_mean: 2050.176367114059
reward_std: 783.2467297852853
reward_max: 3421.030430269375
reward_min: 974.6354991920534
total_envstep_count: 4181247
total_train_sample_count: 3205662
total_episode_count: 14149
total_duration: 1012.3906415338473
[2023-06-29 10:39:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3441
train_sample_count: 3441
avg_envstep_per_episode: 344.1
avg_sample_per_episode: 344.1
avg_envstep_per_sec: 2748.4412448762405
avg_train_sample_per_sec: 2748.4412448762405
avg_episode_per_sec: 7.987332882523221
collect_time: 1.2519823759794235
reward_mean: 1879.180364376763
reward_std: 853.35397993403
reward_max: 3401.8545867582475
reward_min: 910.0356496639786
total_envstep_count: 4185599
total_train_sample_count: 3209103
total_episode_count: 14159
total_duration: 1013.6426239098267
[2023-06-29 10:39:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2044
train_sample_count: 2044
avg_envstep_per_episode: 255.5
avg_sample_per_episode: 255.5
avg_envstep_per_sec: 2686.494337010162
avg_train_sample_per_sec: 2686.494337010162
avg_episode_per_sec: 10.51465493937441
collect_time: 0.7608428470669315
reward_mean: 1291.6364616693777
reward_std: 265.6152347974236
reward_max: 1785.685894054504
reward_min: 944.4910054619347
total_envstep_count: 4190311
total_train_sample_count: 3212347
total_episode_count: 14167
total_duration: 1014.4034667568936
[2023-06-29 10:39:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2631
train_sample_count: 2631
avg_envstep_per_episode: 263.1
avg_sample_per_episode: 263.1
avg_envstep_per_sec: 2498.613493486645
avg_train_sample_per_sec: 2498.613493486645
avg_episode_per_sec: 9.496820575775923
collect_time: 1.0529839876629412
reward_mean: 1732.7102936477263
reward_std: 777.8883620247738
reward_max: 3335.136273396734
reward_min: 843.9578858715904
total_envstep_count: 4195143
total_train_sample_count: 3215778
total_episode_count: 14177
total_duration: 1015.4564507445566
[2023-06-29 10:39:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1228
train_sample_count: 1228
avg_envstep_per_episode: 204.66666666666666
avg_sample_per_episode: 204.66666666666666
avg_envstep_per_sec: 2737.2132964835187
avg_train_sample_per_sec: 2737.2132964835187
avg_episode_per_sec: 13.374006334610025
collect_time: 0.44863146090134964
reward_mean: 1924.983850630345
reward_std: 832.0766150797929
reward_max: 3427.28443404933
reward_min: 842.1615065960414
total_envstep_count: 4199591
total_train_sample_count: 3219006
total_episode_count: 14183
total_duration: 1015.9050822054579
[2023-06-29 10:39:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2388
train_sample_count: 2388
avg_envstep_per_episode: 298.5
avg_sample_per_episode: 298.5
avg_envstep_per_sec: 2768.4932372566677
avg_train_sample_per_sec: 2768.4932372566677
avg_episode_per_sec: 9.274684211915135
collect_time: 0.8625630606077612
reward_mean: 2715.2080544797054
reward_std: 804.3683448932233
reward_max: 3566.012723050761
reward_min: 1475.418751895363
total_envstep_count: 4204735
total_train_sample_count: 3222594
total_episode_count: 14191
total_duration: 1016.7676452660656
[2023-06-29 10:39:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1732
train_sample_count: 1732
avg_envstep_per_episode: 247.42857142857142
avg_sample_per_episode: 247.42857142857142
avg_envstep_per_sec: 2678.0606475728796
avg_train_sample_per_sec: 2678.0606475728796
avg_episode_per_sec: 10.82357074654166
collect_time: 0.6467366605643183
reward_mean: 2056.4422481244605
reward_std: 633.9318712958566
reward_max: 3476.9217617140553
reward_min: 1590.3478836844938
total_envstep_count: 4209287
total_train_sample_count: 3225926
total_episode_count: 14198
total_duration: 1017.41438192663
[2023-06-29 10:39:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2169
train_sample_count: 2169
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2495.494424225518
avg_train_sample_per_sec: 2495.494424225518
avg_episode_per_sec: 10.354748648238663
collect_time: 0.8691664380989967
reward_mean: 1963.8880832839438
reward_std: 729.7288153177662
reward_max: 3428.7285032001764
reward_min: 1271.1610085292111
total_envstep_count: 4213759
total_train_sample_count: 3229295
total_episode_count: 14207
total_duration: 1018.283548364729
[2023-06-29 10:39:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 226.22222222222223
avg_sample_per_episode: 226.22222222222223
avg_envstep_per_sec: 2740.741821047792
avg_train_sample_per_sec: 2740.741821047792
avg_episode_per_sec: 12.115263452568826
collect_time: 0.7428645720528438
reward_mean: 1746.343192346209
reward_std: 727.577699958418
reward_max: 3488.2236255370917
reward_min: 1046.3509982870808
total_envstep_count: 4217959
total_train_sample_count: 3232531
total_episode_count: 14216
total_duration: 1019.0264129367819
[2023-06-29 10:39:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 631
train_sample_count: 631
avg_envstep_per_episode: 157.75
avg_sample_per_episode: 157.75
avg_envstep_per_sec: 2729.453737887213
avg_train_sample_per_sec: 2729.453737887213
avg_episode_per_sec: 17.302400874086928
collect_time: 0.23118178968969738
reward_mean: 2424.16648709466
reward_std: 674.6254675753194
reward_max: 3532.3802955911838
reward_min: 1837.0854083558313
total_envstep_count: 4222839
total_train_sample_count: 3235962
total_episode_count: 14220
total_duration: 1019.2575947264716
[2023-06-29 10:39:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1670
train_sample_count: 1670
avg_envstep_per_episode: 238.57142857142858
avg_sample_per_episode: 238.57142857142858
avg_envstep_per_sec: 2689.4062906842164
avg_train_sample_per_sec: 2689.4062906842164
avg_episode_per_sec: 11.272960499873962
collect_time: 0.6209548946861176
reward_mean: 2835.3439114704047
reward_std: 734.6070753922057
reward_max: 3539.3123126688906
reward_min: 1768.961900301765
total_envstep_count: 4226863
total_train_sample_count: 3239232
total_episode_count: 14227
total_duration: 1019.8785496211576
[2023-06-29 10:39:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1109
train_sample_count: 1109
avg_envstep_per_episode: 184.83333333333334
avg_sample_per_episode: 184.83333333333334
avg_envstep_per_sec: 2604.7987122580544
avg_train_sample_per_sec: 2604.7987122580544
avg_episode_per_sec: 14.092689155589113
collect_time: 0.4257526674829424
reward_mean: 2036.2229960463344
reward_std: 864.0881883624045
reward_max: 3476.345759064701
reward_min: 1158.9945518522973
total_envstep_count: 4231007
total_train_sample_count: 3242741
total_episode_count: 14233
total_duration: 1020.3043022886405
[2023-06-29 10:39:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1552
train_sample_count: 1552
avg_envstep_per_episode: 258.6666666666667
avg_sample_per_episode: 258.6666666666667
avg_envstep_per_sec: 2458.211841880165
avg_train_sample_per_sec: 2458.211841880165
avg_episode_per_sec: 9.503396295928473
collect_time: 0.6313532355343923
reward_mean: 2786.3877856489485
reward_std: 743.3431338661892
reward_max: 3478.595088491033
reward_min: 1752.4650802714455
total_envstep_count: 4235423
total_train_sample_count: 3246293
total_episode_count: 14239
total_duration: 1020.935655524175
[2023-06-29 10:39:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 240.11111111111111
avg_sample_per_episode: 240.11111111111111
avg_envstep_per_sec: 2664.4327401774917
avg_train_sample_per_sec: 2664.4327401774917
avg_episode_per_sec: 11.096665738823427
collect_time: 0.8110544384978712
reward_mean: 2053.165514675503
reward_std: 780.4867188121125
reward_max: 3468.1568749359217
reward_min: 967.7563690843162
total_envstep_count: 4239847
total_train_sample_count: 3249654
total_episode_count: 14248
total_duration: 1021.7467099626729
[2023-06-29 10:39:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2242
train_sample_count: 2242
avg_envstep_per_episode: 249.11111111111111
avg_sample_per_episode: 249.11111111111111
avg_envstep_per_sec: 2686.306440707897
avg_train_sample_per_sec: 2686.306440707897
avg_episode_per_sec: 10.783567335580317
collect_time: 0.8346032180190087
reward_mean: 1873.009335994573
reward_std: 786.9451049416972
reward_max: 2848.4295128816257
reward_min: 42.12946634846177
total_envstep_count: 4244207
total_train_sample_count: 3253096
total_episode_count: 14257
total_duration: 1022.5813131806918
[2023-06-29 10:39:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2165
train_sample_count: 2165
avg_envstep_per_episode: 240.55555555555554
avg_sample_per_episode: 240.55555555555554
avg_envstep_per_sec: 2728.117091407488
avg_train_sample_per_sec: 2728.117091407488
avg_episode_per_sec: 11.340902458506877
collect_time: 0.793587638455443
reward_mean: 1603.301604394113
reward_std: 717.0583757239133
reward_max: 2908.5429946357676
reward_min: 612.275435118443
total_envstep_count: 4249431
total_train_sample_count: 3256461
total_episode_count: 14266
total_duration: 1023.3749008191472
[2023-06-29 10:39:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2562.37189830508
avg_train_sample_per_sec: 2562.37189830508
avg_episode_per_sec: 12.029915015516806
collect_time: 0.9975132812261582
reward_mean: 1707.6462458956737
reward_std: 700.2823627123977
reward_max: 3230.4143488033997
reward_min: 799.2634109515154
total_envstep_count: 4253423
total_train_sample_count: 3259817
total_episode_count: 14278
total_duration: 1024.3724141003734
[2023-06-29 10:39:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2664
train_sample_count: 2664
avg_envstep_per_episode: 333.0
avg_sample_per_episode: 333.0
avg_envstep_per_sec: 2577.781637592231
avg_train_sample_per_sec: 2577.781637592231
avg_episode_per_sec: 7.741085998775469
collect_time: 1.03344672843907
reward_mean: 1819.9658830389321
reward_std: 228.65185989569653
reward_max: 2140.8890963866265
reward_min: 1440.133161693443
total_envstep_count: 4257727
total_train_sample_count: 3263281
total_episode_count: 14286
total_duration: 1025.4058608288124
[2023-06-29 10:39:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 306.75
avg_sample_per_episode: 306.75
avg_envstep_per_sec: 2786.6030616359103
avg_train_sample_per_sec: 2786.6030616359103
avg_episode_per_sec: 9.08428055953027
collect_time: 0.8806421100245789
reward_mean: 1655.8022929149697
reward_std: 518.6705571514686
reward_max: 2624.3883562902515
reward_min: 881.1746069107959
total_envstep_count: 4261975
total_train_sample_count: 3266535
total_episode_count: 14294
total_duration: 1026.286502938837
[2023-06-29 10:39:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2404
train_sample_count: 2404
avg_envstep_per_episode: 200.33333333333334
avg_sample_per_episode: 200.33333333333334
avg_envstep_per_sec: 2720.4725157923554
avg_train_sample_per_sec: 2720.4725157923554
avg_episode_per_sec: 13.579729696134887
collect_time: 0.8836700191032142
reward_mean: 1351.3562874243632
reward_std: 819.9908903118272
reward_max: 3599.270230907641
reward_min: 40.62554959385424
total_envstep_count: 4266671
total_train_sample_count: 3269739
total_episode_count: 14306
total_duration: 1027.1701729579402
[2023-06-29 10:39:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2555.280600468963
avg_train_sample_per_sec: 2555.280600468963
avg_episode_per_sec: 10.873534470080692
collect_time: 1.1955634146165104
reward_mean: 1465.17593840857
reward_std: 376.37225985604744
reward_max: 2010.8999264427014
reward_min: 884.0395707080644
total_envstep_count: 4271639
total_train_sample_count: 3273194
total_episode_count: 14319
total_duration: 1028.3657363725567
[2023-06-29 10:40:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 223.11111111111111
avg_sample_per_episode: 223.11111111111111
avg_envstep_per_sec: 2460.662836991611
avg_train_sample_per_sec: 2460.662836991611
avg_episode_per_sec: 11.028867297273157
collect_time: 0.8160402838671578
reward_mean: 1463.7526380504962
reward_std: 277.72234994339925
reward_max: 1867.9809168032252
reward_min: 876.5167636260528
total_envstep_count: 4276567
total_train_sample_count: 3276402
total_episode_count: 14328
total_duration: 1029.1817766564238
[2023-06-29 10:40:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2625
train_sample_count: 2625
avg_envstep_per_episode: 238.63636363636363
avg_sample_per_episode: 238.63636363636363
avg_envstep_per_sec: 2554.2954054245465
avg_train_sample_per_sec: 2554.2954054245465
avg_episode_per_sec: 10.70371407987429
collect_time: 1.0276806646659968
reward_mean: 1873.2042106172191
reward_std: 691.3853178351633
reward_max: 3363.707082923771
reward_min: 1323.3188962646302
total_envstep_count: 4280703
total_train_sample_count: 3279827
total_episode_count: 14339
total_duration: 1030.2094573210898
[2023-06-29 10:40:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 296.8
avg_sample_per_episode: 296.8
avg_envstep_per_sec: 2467.68544246674
avg_train_sample_per_sec: 2467.68544246674
avg_episode_per_sec: 8.314304051437803
collect_time: 1.2027464882368222
reward_mean: 1604.5375049253075
reward_std: 365.65106845025394
reward_max: 2168.9707496681413
reward_min: 1192.453462892498
total_envstep_count: 4285383
total_train_sample_count: 3283195
total_episode_count: 14349
total_duration: 1031.4122038093267
[2023-06-29 10:40:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 315.8888888888889
avg_sample_per_episode: 315.8888888888889
avg_envstep_per_sec: 2731.5313788902586
avg_train_sample_per_sec: 2731.5313788902586
avg_episode_per_sec: 8.647127122761985
collect_time: 1.0408081056550147
reward_mean: 1810.7056212777854
reward_std: 572.0774250753487
reward_max: 2693.438877774915
reward_min: 1209.815588816505
total_envstep_count: 4289751
total_train_sample_count: 3286438
total_episode_count: 14358
total_duration: 1032.4530119149817
[2023-06-29 10:40:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3150
train_sample_count: 3150
avg_envstep_per_episode: 315.0
avg_sample_per_episode: 315.0
avg_envstep_per_sec: 2550.3132547398936
avg_train_sample_per_sec: 2550.3132547398936
avg_episode_per_sec: 8.09623255472982
collect_time: 1.235142386585474
reward_mean: 1691.3601624991322
reward_std: 513.4520643782663
reward_max: 2862.3736714883257
reward_min: 1071.0573400614692
total_envstep_count: 4294439
total_train_sample_count: 3289988
total_episode_count: 14368
total_duration: 1033.6881543015672
[2023-06-29 10:40:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2954
train_sample_count: 2954
avg_envstep_per_episode: 268.54545454545456
avg_sample_per_episode: 268.54545454545456
avg_envstep_per_sec: 2602.923840721915
avg_train_sample_per_sec: 2602.923840721915
avg_episode_per_sec: 9.69267510086021
collect_time: 1.1348776148520408
reward_mean: 1447.539482748209
reward_std: 461.5119880540913
reward_max: 2559.6482238259423
reward_min: 827.2454069084656
total_envstep_count: 4298975
total_train_sample_count: 3293342
total_episode_count: 14379
total_duration: 1034.8230319164193
[2023-06-29 10:40:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 246.91666666666666
avg_sample_per_episode: 246.91666666666666
avg_envstep_per_sec: 2745.0096035915444
avg_train_sample_per_sec: 2745.0096035915444
avg_episode_per_sec: 11.117149930171628
collect_time: 1.0794133456302808
reward_mean: 1273.6557772440385
reward_std: 306.9132359472873
reward_max: 1888.432459485336
reward_min: 942.8008971308935
total_envstep_count: 4303359
total_train_sample_count: 3296705
total_episode_count: 14391
total_duration: 1035.9024452620495
[2023-06-29 10:40:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3014
train_sample_count: 3014
avg_envstep_per_episode: 251.16666666666666
avg_sample_per_episode: 251.16666666666666
avg_envstep_per_sec: 2782.642888294975
avg_train_sample_per_sec: 2782.642888294975
avg_episode_per_sec: 11.078870159104081
collect_time: 1.0831429403601214
reward_mean: 1401.7724182739169
reward_std: 556.8266038200561
reward_max: 3052.334248197604
reward_min: 746.3736495641542
total_envstep_count: 4308447
total_train_sample_count: 3300119
total_episode_count: 14403
total_duration: 1036.9855882024096
[2023-06-29 10:40:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2588
train_sample_count: 2588
avg_envstep_per_episode: 258.8
avg_sample_per_episode: 258.8
avg_envstep_per_sec: 2574.7226469705274
avg_train_sample_per_sec: 2574.7226469705274
avg_episode_per_sec: 9.948696472065407
collect_time: 1.005156809043139
reward_mean: 1525.2833645071987
reward_std: 729.0145302828945
reward_max: 3578.167032598314
reward_min: 944.9547180011299
total_envstep_count: 4313111
total_train_sample_count: 3303507
total_episode_count: 14413
total_duration: 1037.9907450114529
[2023-06-29 10:40:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3004
train_sample_count: 3004
avg_envstep_per_episode: 300.4
avg_sample_per_episode: 300.4
avg_envstep_per_sec: 2518.7253125258035
avg_train_sample_per_sec: 2518.7253125258035
avg_episode_per_sec: 8.384571612935432
collect_time: 1.1926667767465116
reward_mean: 1944.3433396302785
reward_std: 898.595362188146
reward_max: 3635.497152539192
reward_min: 897.5091730679605
total_envstep_count: 4317663
total_train_sample_count: 3306911
total_episode_count: 14423
total_duration: 1039.1834117881995
[2023-06-29 10:40:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 248.77777777777777
avg_sample_per_episode: 248.77777777777777
avg_envstep_per_sec: 2531.8435758233263
avg_train_sample_per_sec: 2531.8435758233263
avg_episode_per_sec: 10.177129156949503
collect_time: 0.8843358339276165
reward_mean: 1277.9785534125851
reward_std: 429.3375594265378
reward_max: 2183.620355209922
reward_min: 928.6279362213775
total_envstep_count: 4322335
total_train_sample_count: 3310350
total_episode_count: 14432
total_duration: 1040.0677476221272
[2023-06-29 10:40:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 932
train_sample_count: 932
avg_envstep_per_episode: 186.4
avg_sample_per_episode: 186.4
avg_envstep_per_sec: 2733.218142234449
avg_train_sample_per_sec: 2733.218142234449
avg_episode_per_sec: 14.66318745833932
collect_time: 0.34098998012579973
reward_mean: 2347.426970312356
reward_std: 1081.1166729444672
reward_max: 3435.8766550693167
reward_min: 1038.2929223606106
total_envstep_count: 4326855
total_train_sample_count: 3313682
total_episode_count: 14437
total_duration: 1040.408737602253
[2023-06-29 10:40:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 250.375
avg_sample_per_episode: 250.375
avg_envstep_per_sec: 2669.634879240749
avg_train_sample_per_sec: 2669.634879240749
avg_episode_per_sec: 10.662545698415371
collect_time: 0.7502898675678296
reward_mean: 2566.3258852186204
reward_std: 1339.2383114091567
reward_max: 3642.756610278702
reward_min: 44.11969918143104
total_envstep_count: 4331367
total_train_sample_count: 3316885
total_episode_count: 14445
total_duration: 1041.1590274698208
[2023-06-29 10:40:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 346.0
avg_sample_per_episode: 346.0
avg_envstep_per_sec: 2591.789675862677
avg_train_sample_per_sec: 2591.789675862677
avg_episode_per_sec: 7.490721606539529
collect_time: 0.4004954605950044
reward_mean: 3187.0986367408364
reward_std: 286.72369159535214
reward_max: 3423.2226987933345
reward_min: 2783.554936472986
total_envstep_count: 4335407
total_train_sample_count: 3320323
total_episode_count: 14448
total_duration: 1041.5595229304158
[2023-06-29 10:40:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1899
train_sample_count: 1899
avg_envstep_per_episode: 237.375
avg_sample_per_episode: 237.375
avg_envstep_per_sec: 2421.3924717436453
avg_train_sample_per_sec: 2421.3924717436453
avg_episode_per_sec: 10.200705515507721
collect_time: 0.784259479683824
reward_mean: 2584.129095543964
reward_std: 1031.1348739880768
reward_max: 3522.0004277237417
reward_min: 933.8662944448461
total_envstep_count: 4339839
total_train_sample_count: 3323822
total_episode_count: 14456
total_duration: 1042.3437824100997
[2023-06-29 10:40:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1689
train_sample_count: 1689
avg_envstep_per_episode: 241.28571428571428
avg_sample_per_episode: 241.28571428571428
avg_envstep_per_sec: 2721.5398932764106
avg_train_sample_per_sec: 2721.5398932764106
avg_episode_per_sec: 11.279324602092881
collect_time: 0.620604535018094
reward_mean: 2046.5037454476296
reward_std: 980.5220278354338
reward_max: 3438.5729046408705
reward_min: 980.8987574387183
total_envstep_count: 4344639
total_train_sample_count: 3327111
total_episode_count: 14463
total_duration: 1042.964386945118
[2023-06-29 10:40:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1776
train_sample_count: 1776
avg_envstep_per_episode: 296.0
avg_sample_per_episode: 296.0
avg_envstep_per_sec: 2754.7405144374684
avg_train_sample_per_sec: 2754.7405144374684
avg_episode_per_sec: 9.306555792018473
collect_time: 0.6447068210933355
reward_mean: 2734.4461271069617
reward_std: 986.873093078047
reward_max: 3471.5179726408032
reward_min: 1306.8862624223905
total_envstep_count: 4349223
total_train_sample_count: 3330487
total_episode_count: 14469
total_duration: 1043.6090937662111
[2023-06-29 10:40:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1509
train_sample_count: 1509
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2725.9317259954105
avg_train_sample_per_sec: 2725.9317259954105
avg_episode_per_sec: 10.838694735568232
collect_time: 0.5535721917059271
reward_mean: 2347.99102620369
reward_std: 889.1065176945417
reward_max: 3475.8463156306143
reward_min: 1277.6223855320611
total_envstep_count: 4353815
total_train_sample_count: 3333996
total_episode_count: 14475
total_duration: 1044.162665957917
[2023-06-29 10:40:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1929
train_sample_count: 1929
avg_envstep_per_episode: 214.33333333333334
avg_sample_per_episode: 214.33333333333334
avg_envstep_per_sec: 2535.7105920197405
avg_train_sample_per_sec: 2535.7105920197405
avg_episode_per_sec: 11.83068705452445
collect_time: 0.7607335025025532
reward_mean: 1962.6457568777337
reward_std: 1262.6283281457304
reward_max: 3492.343584244794
reward_min: 268.7921742556374
total_envstep_count: 4358239
total_train_sample_count: 3337525
total_episode_count: 14484
total_duration: 1044.9233994604194
[2023-06-29 10:41:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 207.0
avg_sample_per_episode: 207.0
avg_envstep_per_sec: 2355.543244082456
avg_train_sample_per_sec: 2355.543244082456
avg_episode_per_sec: 11.379435961750994
collect_time: 0.5272669067401438
reward_mean: 2149.080285628356
reward_std: 1087.5241233341176
reward_max: 3499.59752029267
reward_min: 749.6766415277532
total_envstep_count: 4362327
total_train_sample_count: 3340767
total_episode_count: 14490
total_duration: 1045.4506663671596
[2023-06-29 10:41:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 291.27272727272725
avg_sample_per_episode: 291.27272727272725
avg_envstep_per_sec: 2552.7717205130825
avg_train_sample_per_sec: 2552.7717205130825
avg_episode_per_sec: 8.7641975423358
collect_time: 1.2551063513646363
reward_mean: 2101.882331699414
reward_std: 866.1017988651114
reward_max: 3474.014753974807
reward_min: 972.7480192643186
total_envstep_count: 4366567
total_train_sample_count: 3343971
total_episode_count: 14501
total_duration: 1046.7057727185243
[2023-06-29 10:41:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2099
train_sample_count: 2099
avg_envstep_per_episode: 419.8
avg_sample_per_episode: 419.8
avg_envstep_per_sec: 2788.8766683744757
avg_train_sample_per_sec: 2788.8766683744757
avg_episode_per_sec: 6.643346041863925
collect_time: 0.7526327800014989
reward_mean: 1803.527198540221
reward_std: 666.8612050045879
reward_max: 2661.841577378788
reward_min: 1032.4268493022107
total_envstep_count: 4371015
total_train_sample_count: 3347270
total_episode_count: 14506
total_duration: 1047.4584054985257
[2023-06-29 10:41:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2379
train_sample_count: 2379
avg_envstep_per_episode: 237.9
avg_sample_per_episode: 237.9
avg_envstep_per_sec: 2729.4172406304992
avg_train_sample_per_sec: 2729.4172406304992
avg_episode_per_sec: 11.472960238043294
collect_time: 0.8716146306199954
reward_mean: 1782.077902644761
reward_std: 1129.473876751237
reward_max: 3561.793735416
reward_min: 339.45747892103606
total_envstep_count: 4375711
total_train_sample_count: 3350849
total_episode_count: 14516
total_duration: 1048.3300201291456
[2023-06-29 10:41:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1689
train_sample_count: 1689
avg_envstep_per_episode: 211.125
avg_sample_per_episode: 211.125
avg_envstep_per_sec: 2610.7803761893983
avg_train_sample_per_sec: 2610.7803761893983
avg_episode_per_sec: 12.36604085820911
collect_time: 0.6469330072356388
reward_mean: 1795.51532624689
reward_std: 914.5488165326233
reward_max: 3460.388530149013
reward_min: 266.5674954220895
total_envstep_count: 4380055
total_train_sample_count: 3354138
total_episode_count: 14524
total_duration: 1048.9769531363813
[2023-06-29 10:41:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2839
train_sample_count: 2839
avg_envstep_per_episode: 258.09090909090907
avg_sample_per_episode: 258.09090909090907
avg_envstep_per_sec: 2621.8014831692894
avg_train_sample_per_sec: 2621.8014831692894
avg_episode_per_sec: 10.15844181573166
collect_time: 1.0828432351667436
reward_mean: 1808.4995164250743
reward_std: 948.122561747133
reward_max: 3501.073192643
reward_min: 268.6868816641881
total_envstep_count: 4384655
total_train_sample_count: 3357377
total_episode_count: 14535
total_duration: 1050.0597963715481
[2023-06-29 10:41:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1423
train_sample_count: 1423
avg_envstep_per_episode: 203.28571428571428
avg_sample_per_episode: 203.28571428571428
avg_envstep_per_sec: 2346.7621107926575
avg_train_sample_per_sec: 2346.7621107926575
avg_episode_per_sec: 11.544156553442447
collect_time: 0.606367383151315
reward_mean: 1411.5933135958492
reward_std: 353.92476391748676
reward_max: 2018.1059054259015
reward_min: 972.0928618742937
total_envstep_count: 4388615
total_train_sample_count: 3360800
total_episode_count: 14542
total_duration: 1050.6661637546995
[2023-06-29 10:41:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2585
train_sample_count: 2585
avg_envstep_per_episode: 323.125
avg_sample_per_episode: 323.125
avg_envstep_per_sec: 2808.868870185998
avg_train_sample_per_sec: 2808.868870185998
avg_episode_per_sec: 8.692824356475041
collect_time: 0.9202992804106325
reward_mean: 2260.431936894156
reward_std: 622.0642867843302
reward_max: 3379.4291602515295
reward_min: 1448.575185525364
total_envstep_count: 4393119
total_train_sample_count: 3364185
total_episode_count: 14550
total_duration: 1051.5864630351102
[2023-06-29 10:41:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1633
train_sample_count: 1633
avg_envstep_per_episode: 272.1666666666667
avg_sample_per_episode: 272.1666666666667
avg_envstep_per_sec: 2678.4508433965934
avg_train_sample_per_sec: 2678.4508433965934
avg_episode_per_sec: 9.841215591169357
collect_time: 0.6096807802263648
reward_mean: 2253.7059082110422
reward_std: 661.8103941342908
reward_max: 3477.7134213146746
reward_min: 1676.706223275533
total_envstep_count: 4397103
total_train_sample_count: 3367418
total_episode_count: 14556
total_duration: 1052.1961438153367
[2023-06-29 10:41:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3063
train_sample_count: 3063
avg_envstep_per_episode: 278.45454545454544
avg_sample_per_episode: 278.45454545454544
avg_envstep_per_sec: 2540.231391464841
avg_train_sample_per_sec: 2540.231391464841
avg_episode_per_sec: 9.122607021258
collect_time: 1.2057956650294368
reward_mean: 1771.0832157930463
reward_std: 603.4749374928026
reward_max: 3277.8347383677856
reward_min: 1241.8413310215406
total_envstep_count: 4401719
total_train_sample_count: 3370881
total_episode_count: 14567
total_duration: 1053.401939480366
[2023-06-29 10:41:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2769
train_sample_count: 2769
avg_envstep_per_episode: 307.6666666666667
avg_sample_per_episode: 307.6666666666667
avg_envstep_per_sec: 2582.0119828523357
avg_train_sample_per_sec: 2582.0119828523357
avg_episode_per_sec: 8.392238297461546
collect_time: 1.0724195001376793
reward_mean: 1660.0405219725487
reward_std: 596.8520747403509
reward_max: 3237.081792310813
reward_min: 1160.0057554943903
total_envstep_count: 4406071
total_train_sample_count: 3374450
total_episode_count: 14576
total_duration: 1054.4743589805037
[2023-06-29 10:41:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3091
train_sample_count: 3091
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2720.499968062801
avg_train_sample_per_sec: 2720.499968062801
avg_episode_per_sec: 9.681494548266198
collect_time: 1.1361882140366362
reward_mean: 1530.16539349128
reward_std: 532.716687692332
reward_max: 3027.3103500051284
reward_min: 1009.4675841460809
total_envstep_count: 4410967
total_train_sample_count: 3377941
total_episode_count: 14587
total_duration: 1055.6105471945402
[2023-06-29 10:41:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2739
train_sample_count: 2739
avg_envstep_per_episode: 273.9
avg_sample_per_episode: 273.9
avg_envstep_per_sec: 2784.188040798162
avg_train_sample_per_sec: 2784.188040798162
avg_episode_per_sec: 10.164980068631479
collect_time: 0.9837697597518565
reward_mean: 1546.7943024745666
reward_std: 619.300564458565
reward_max: 3033.2460171951775
reward_min: 602.7866788105604
total_envstep_count: 4415703
total_train_sample_count: 3381480
total_episode_count: 14597
total_duration: 1056.594316954292
[2023-06-29 10:41:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2233
train_sample_count: 2233
avg_envstep_per_episode: 248.11111111111111
avg_sample_per_episode: 248.11111111111111
avg_envstep_per_sec: 2771.5752750938304
avg_train_sample_per_sec: 2771.5752750938304
avg_episode_per_sec: 11.170701959625829
collect_time: 0.8056790014207363
reward_mean: 1611.6369102708938
reward_std: 696.3455475222336
reward_max: 3245.9382996917266
reward_min: 939.1587639903297
total_envstep_count: 4420247
total_train_sample_count: 3384913
total_episode_count: 14606
total_duration: 1057.3999959557127
[2023-06-29 10:41:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2167
train_sample_count: 2167
avg_envstep_per_episode: 240.77777777777777
avg_sample_per_episode: 240.77777777777777
avg_envstep_per_sec: 2564.3278416632425
avg_train_sample_per_sec: 2564.3278416632425
avg_episode_per_sec: 10.650184852316189
collect_time: 0.8450557548813522
reward_mean: 1870.0962917670286
reward_std: 679.9460472679691
reward_max: 3103.388187388145
reward_min: 757.2213767206705
total_envstep_count: 4425167
total_train_sample_count: 3388280
total_episode_count: 14615
total_duration: 1058.245051710594
[2023-06-29 10:41:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1315
train_sample_count: 1315
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2627.0464721484486
avg_train_sample_per_sec: 2627.0464721484486
avg_episode_per_sec: 9.988769856077752
collect_time: 0.5005621384857223
reward_mean: 2218.4616350468705
reward_std: 500.4979444162144
reward_max: 2971.5354384104494
reward_min: 1487.0990870332007
total_envstep_count: 4429183
total_train_sample_count: 3391595
total_episode_count: 14620
total_duration: 1058.7456138490797
[2023-06-29 10:41:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1544
train_sample_count: 1544
avg_envstep_per_episode: 220.57142857142858
avg_sample_per_episode: 220.57142857142858
avg_envstep_per_sec: 2638.692608728487
avg_train_sample_per_sec: 2638.692608728487
avg_episode_per_sec: 11.962984625064383
collect_time: 0.5851382593382148
reward_mean: 2463.730031526767
reward_std: 845.4082084032718
reward_max: 3466.4371832768525
reward_min: 1217.0569409943676
total_envstep_count: 4433343
total_train_sample_count: 3395139
total_episode_count: 14627
total_duration: 1059.330752108418
[2023-06-29 10:41:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 234.85714285714286
avg_sample_per_episode: 234.85714285714286
avg_envstep_per_sec: 2646.013409258537
avg_train_sample_per_sec: 2646.013409258537
avg_episode_per_sec: 11.266480453047299
collect_time: 0.6213120440915225
reward_mean: 2274.955048511893
reward_std: 725.0522511956145
reward_max: 3434.5225017271537
reward_min: 1103.920372512655
total_envstep_count: 4437831
total_train_sample_count: 3398383
total_episode_count: 14634
total_duration: 1059.9520641525096
[2023-06-29 10:41:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1527
train_sample_count: 1527
avg_envstep_per_episode: 218.14285714285714
avg_sample_per_episode: 218.14285714285714
avg_envstep_per_sec: 2303.669745635382
avg_train_sample_per_sec: 2303.669745635382
avg_episode_per_sec: 10.56037211489697
collect_time: 0.662855430077645
reward_mean: 2193.9183720887563
reward_std: 823.9065653849754
reward_max: 3467.2518424237765
reward_min: 1520.8395573563787
total_envstep_count: 4442847
total_train_sample_count: 3401910
total_episode_count: 14641
total_duration: 1060.6149195825872
[2023-06-29 10:42:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2193
train_sample_count: 2193
avg_envstep_per_episode: 313.2857142857143
avg_sample_per_episode: 313.2857142857143
avg_envstep_per_sec: 2342.339890519006
avg_train_sample_per_sec: 2342.339890519006
avg_episode_per_sec: 7.476689117023731
collect_time: 0.9362432876955719
reward_mean: 2822.4974206059055
reward_std: 741.4342816083503
reward_max: 3553.7630074556396
reward_min: 1586.078184737025
total_envstep_count: 4447095
total_train_sample_count: 3405303
total_episode_count: 14648
total_duration: 1061.5511628702827
[2023-06-29 10:42:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2683
train_sample_count: 2683
avg_envstep_per_episode: 268.3
avg_sample_per_episode: 268.3
avg_envstep_per_sec: 2671.1877686174143
avg_train_sample_per_sec: 2671.1877686174143
avg_episode_per_sec: 9.955973792834193
collect_time: 1.0044220894994214
reward_mean: 1796.886951221355
reward_std: 605.5623159236486
reward_max: 3267.6069828025993
reward_min: 1191.0659436172002
total_envstep_count: 4451719
total_train_sample_count: 3408786
total_episode_count: 14658
total_duration: 1062.5555849597822
[2023-06-29 10:42:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 304.5
avg_sample_per_episode: 304.5
avg_envstep_per_sec: 2606.2540751906076
avg_train_sample_per_sec: 2606.2540751906076
avg_episode_per_sec: 8.559126683712998
collect_time: 0.9346747975144533
reward_mean: 1798.8405809934106
reward_std: 472.1439524464767
reward_max: 2578.138221556177
reward_min: 1232.6983730138882
total_envstep_count: 4455663
total_train_sample_count: 3412022
total_episode_count: 14666
total_duration: 1063.4902597572966
[2023-06-29 10:42:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3033
train_sample_count: 3033
avg_envstep_per_episode: 303.3
avg_sample_per_episode: 303.3
avg_envstep_per_sec: 2115.8529459486044
avg_train_sample_per_sec: 2115.8529459486044
avg_episode_per_sec: 6.976105987301697
collect_time: 1.4334644597147128
reward_mean: 1732.7983710357184
reward_std: 701.1413166485312
reward_max: 3608.057146477057
reward_min: 895.9052125373681
total_envstep_count: 4460919
total_train_sample_count: 3415455
total_episode_count: 14676
total_duration: 1064.9237242170113
[2023-06-29 10:42:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1917
train_sample_count: 1917
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2149.59950331542
avg_train_sample_per_sec: 2149.59950331542
avg_episode_per_sec: 10.092016447490234
collect_time: 0.8917940281635386
reward_mean: 1480.3207131224672
reward_std: 471.90963265316424
reward_max: 1997.9646802833852
reward_min: 332.5545298923908
total_envstep_count: 4465751
total_train_sample_count: 3418972
total_episode_count: 14685
total_duration: 1065.8155182451749
[2023-06-29 10:42:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1853
train_sample_count: 1853
avg_envstep_per_episode: 231.625
avg_sample_per_episode: 231.625
avg_envstep_per_sec: 2053.3221636856288
avg_train_sample_per_sec: 2053.3221636856288
avg_episode_per_sec: 8.86485553668917
collect_time: 0.9024399739950896
reward_mean: 2068.026194271508
reward_std: 947.5786601040256
reward_max: 3477.992424799774
reward_min: 964.6392409875984
total_envstep_count: 4470343
total_train_sample_count: 3422425
total_episode_count: 14693
total_duration: 1066.71795821917
[2023-06-29 10:42:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1700
train_sample_count: 1700
avg_envstep_per_episode: 188.88888888888889
avg_sample_per_episode: 188.88888888888889
avg_envstep_per_sec: 2621.5205771477426
avg_train_sample_per_sec: 2621.5205771477426
avg_episode_per_sec: 13.878638349605696
collect_time: 0.6484786023879423
reward_mean: 1860.0885700447207
reward_std: 776.5336358593376
reward_max: 3599.946879833177
reward_min: 1087.4978927330037
total_envstep_count: 4475063
total_train_sample_count: 3425725
total_episode_count: 14702
total_duration: 1067.366436821558
[2023-06-29 10:42:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2655
train_sample_count: 2655
avg_envstep_per_episode: 204.23076923076923
avg_sample_per_episode: 204.23076923076923
avg_envstep_per_sec: 2595.022218676553
avg_train_sample_per_sec: 2595.022218676553
avg_episode_per_sec: 12.706323481278792
collect_time: 1.023112627279945
reward_mean: 1586.6048972099165
reward_std: 654.3307190894635
reward_max: 3117.921289735658
reward_min: 809.2734321834998
total_envstep_count: 4480119
total_train_sample_count: 3429180
total_episode_count: 14715
total_duration: 1068.389549448838
[2023-06-29 10:42:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 2541.258955685355
avg_train_sample_per_sec: 2541.258955685355
avg_episode_per_sec: 15.784217116058105
collect_time: 0.6335442503402009
reward_mean: 1387.9109366449884
reward_std: 502.5745359396514
reward_max: 2132.4514665398024
reward_min: 336.91318746345274
total_envstep_count: 4483951
total_train_sample_count: 3432390
total_episode_count: 14725
total_duration: 1069.0230936991782
[2023-06-29 10:42:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 240.4
avg_sample_per_episode: 240.4
avg_envstep_per_sec: 2519.057600412349
avg_train_sample_per_sec: 2519.057600412349
avg_episode_per_sec: 10.478608986740221
collect_time: 0.4771625705594197
reward_mean: 1661.1544655498722
reward_std: 692.4977878549275
reward_max: 3029.583915673569
reward_min: 1185.1234562045413
total_envstep_count: 4487759
total_train_sample_count: 3435592
total_episode_count: 14730
total_duration: 1069.5002562697375
[2023-06-29 10:42:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1420
train_sample_count: 1420
avg_envstep_per_episode: 236.66666666666666
avg_sample_per_episode: 236.66666666666666
avg_envstep_per_sec: 2439.5613406872685
avg_train_sample_per_sec: 2439.5613406872685
avg_episode_per_sec: 10.308005664875783
collect_time: 0.5820718570658938
reward_mean: 2871.0508736168645
reward_std: 858.8565948205296
reward_max: 3603.2886452520124
reward_min: 1617.8816148790538
total_envstep_count: 4491895
total_train_sample_count: 3439012
total_episode_count: 14736
total_duration: 1070.0823281268033
[2023-06-29 10:42:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2299
train_sample_count: 2299
avg_envstep_per_episode: 328.42857142857144
avg_sample_per_episode: 328.42857142857144
avg_envstep_per_sec: 2652.5302178562906
avg_train_sample_per_sec: 2652.5302178562906
avg_episode_per_sec: 8.076429545451951
collect_time: 0.8667196266129609
reward_mean: 2601.017445160841
reward_std: 937.3569525622158
reward_max: 3529.4334061023574
reward_min: 1200.0088951544067
total_envstep_count: 4496839
total_train_sample_count: 3442511
total_episode_count: 14743
total_duration: 1070.9490477534162
[2023-06-29 10:42:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2728
train_sample_count: 2728
avg_envstep_per_episode: 341.0
avg_sample_per_episode: 341.0
avg_envstep_per_sec: 2363.3307468009916
avg_train_sample_per_sec: 2363.3307468009916
avg_episode_per_sec: 6.9305887002961635
collect_time: 1.1543030968867245
reward_mean: 2311.596695883556
reward_std: 804.0652125863121
reward_max: 3513.4213060915313
reward_min: 1263.2001532622187
total_envstep_count: 4501423
total_train_sample_count: 3446039
total_episode_count: 14751
total_duration: 1072.1033508503028
[2023-06-29 10:42:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1833
train_sample_count: 1833
avg_envstep_per_episode: 305.5
avg_sample_per_episode: 305.5
avg_envstep_per_sec: 2334.2804890057632
avg_train_sample_per_sec: 2334.2804890057632
avg_episode_per_sec: 7.640852664503316
collect_time: 0.785252675774507
reward_mean: 2208.570484486843
reward_std: 850.8971996891127
reward_max: 3113.9797541851394
reward_min: 941.3731426190354
total_envstep_count: 4506511
total_train_sample_count: 3449472
total_episode_count: 14757
total_duration: 1072.8886035260773
[2023-06-29 10:42:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2215
train_sample_count: 2215
avg_envstep_per_episode: 246.11111111111111
avg_sample_per_episode: 246.11111111111111
avg_envstep_per_sec: 2304.6480641913427
avg_train_sample_per_sec: 2304.6480641913427
avg_episode_per_sec: 9.364258500100263
collect_time: 0.9611011912906544
reward_mean: 2228.696312509987
reward_std: 1134.1992341295393
reward_max: 3520.2017897882924
reward_min: 938.7027883964911
total_envstep_count: 4511335
total_train_sample_count: 3452887
total_episode_count: 14766
total_duration: 1073.849704717368
[2023-06-29 10:42:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2231
train_sample_count: 2231
avg_envstep_per_episode: 223.1
avg_sample_per_episode: 223.1
avg_envstep_per_sec: 2559.218789920798
avg_train_sample_per_sec: 2559.218789920798
avg_episode_per_sec: 11.471173419636028
collect_time: 0.8717503985147923
reward_mean: 1748.5031701643347
reward_std: 817.7720901896537
reward_max: 3443.3615138875225
reward_min: 963.5002395519241
total_envstep_count: 4515607
total_train_sample_count: 3456318
total_episode_count: 14776
total_duration: 1074.721455115883
[2023-06-29 10:42:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2459
train_sample_count: 2459
avg_envstep_per_episode: 307.375
avg_sample_per_episode: 307.375
avg_envstep_per_sec: 2575.384186761742
avg_train_sample_per_sec: 2575.384186761742
avg_episode_per_sec: 8.37863907852539
collect_time: 0.9548090000086231
reward_mean: 1898.8159179927902
reward_std: 942.1275234898928
reward_max: 3369.6591849997626
reward_min: 660.1299535958071
total_envstep_count: 4520247
total_train_sample_count: 3459577
total_episode_count: 14784
total_duration: 1075.6762641158916
[2023-06-29 10:42:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2492
train_sample_count: 2492
avg_envstep_per_episode: 249.2
avg_sample_per_episode: 249.2
avg_envstep_per_sec: 2440.345960848677
avg_train_sample_per_sec: 2440.345960848677
avg_episode_per_sec: 9.792720549151994
collect_time: 1.0211666870107874
reward_mean: 1719.93246434123
reward_std: 628.7136688538346
reward_max: 3125.9721668868274
reward_min: 995.607848377794
total_envstep_count: 4524327
total_train_sample_count: 3462869
total_episode_count: 14794
total_duration: 1076.6974308029023
[2023-06-29 10:43:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2198
train_sample_count: 2198
avg_envstep_per_episode: 366.3333333333333
avg_sample_per_episode: 366.3333333333333
avg_envstep_per_sec: 2549.34022652156
avg_train_sample_per_sec: 2549.34022652156
avg_episode_per_sec: 6.9590725018786905
collect_time: 0.8621838611941783
reward_mean: 2004.6811550669856
reward_std: 990.9201418537357
reward_max: 3513.9697335398496
reward_min: 947.7944564894403
total_envstep_count: 4529255
total_train_sample_count: 3466267
total_episode_count: 14800
total_duration: 1077.5596146640964
[2023-06-29 10:43:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2683
train_sample_count: 2683
avg_envstep_per_episode: 243.9090909090909
avg_sample_per_episode: 243.9090909090909
avg_envstep_per_sec: 2579.068073110205
avg_train_sample_per_sec: 2579.068073110205
avg_episode_per_sec: 10.573890720913997
collect_time: 1.0402982488028938
reward_mean: 1861.1476961698224
reward_std: 865.5452069697259
reward_max: 3541.12201612832
reward_min: 1102.7713313387442
total_envstep_count: 4534295
total_train_sample_count: 3469750
total_episode_count: 14811
total_duration: 1078.5999129128993
[2023-06-29 10:43:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2661
train_sample_count: 2661
avg_envstep_per_episode: 241.9090909090909
avg_sample_per_episode: 241.9090909090909
avg_envstep_per_sec: 2517.234026366912
avg_train_sample_per_sec: 2517.234026366912
avg_episode_per_sec: 10.405702476526132
collect_time: 1.0571126769013937
reward_mean: 1651.9190762003002
reward_std: 670.8739244794673
reward_max: 3566.6924181805516
reward_min: 1102.4859466289845
total_envstep_count: 4539167
total_train_sample_count: 3473211
total_episode_count: 14822
total_duration: 1079.6570255898007
[2023-06-29 10:43:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3100
train_sample_count: 3100
avg_envstep_per_episode: 258.3333333333333
avg_sample_per_episode: 258.3333333333333
avg_envstep_per_sec: 2391.7639597568796
avg_train_sample_per_sec: 2391.7639597568796
avg_episode_per_sec: 9.258441134542759
collect_time: 1.29611452139914
reward_mean: 1571.6893045443576
reward_std: 418.68642361584705
reward_max: 2472.0551204100425
reward_min: 835.2619924892755
total_envstep_count: 4544167
total_train_sample_count: 3476711
total_episode_count: 14834
total_duration: 1080.9531401112
[2023-06-29 10:43:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1787
train_sample_count: 1787
avg_envstep_per_episode: 223.375
avg_sample_per_episode: 223.375
avg_envstep_per_sec: 2280.373159967205
avg_train_sample_per_sec: 2280.373159967205
avg_episode_per_sec: 10.208721477189503
collect_time: 0.783643673487939
reward_mean: 1406.4779763022793
reward_std: 661.0061541109735
reward_max: 2683.823580061696
reward_min: 798.177976523749
total_envstep_count: 4548567
total_train_sample_count: 3480098
total_episode_count: 14842
total_duration: 1081.7367837846878
[2023-06-29 10:43:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 246.15384615384616
avg_sample_per_episode: 246.15384615384616
avg_envstep_per_sec: 2496.588726819954
avg_train_sample_per_sec: 2496.588726819954
avg_episode_per_sec: 10.142391702706064
collect_time: 1.2817489583380521
reward_mean: 1715.6692207276733
reward_std: 679.5239300932122
reward_max: 3212.281604301755
reward_min: 978.6550569856461
total_envstep_count: 4552871
total_train_sample_count: 3483298
total_episode_count: 14855
total_duration: 1083.0185327430258
[2023-06-29 10:43:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2986
train_sample_count: 2986
avg_envstep_per_episode: 298.6
avg_sample_per_episode: 298.6
avg_envstep_per_sec: 2517.5697596503787
avg_train_sample_per_sec: 2517.5697596503787
avg_episode_per_sec: 8.431245008876017
collect_time: 1.1860644530520073
reward_mean: 1435.8627283277315
reward_std: 264.98100367693365
reward_max: 1943.1447453973437
reward_min: 949.1212271522747
total_envstep_count: 4557007
total_train_sample_count: 3486684
total_episode_count: 14865
total_duration: 1084.2045971960779
[2023-06-29 10:43:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2548
train_sample_count: 2548
avg_envstep_per_episode: 231.63636363636363
avg_sample_per_episode: 231.63636363636363
avg_envstep_per_sec: 2296.9301594355447
avg_train_sample_per_sec: 2296.9301594355447
avg_episode_per_sec: 9.9161035140467
collect_time: 1.1093066933415834
reward_mean: 1157.75572390998
reward_std: 331.46419818834295
reward_max: 1889.8925448308826
reward_min: 560.9227041105247
total_envstep_count: 4561311
total_train_sample_count: 3490032
total_episode_count: 14876
total_duration: 1085.3139038894194
[2023-06-29 10:43:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1657
train_sample_count: 1657
avg_envstep_per_episode: 236.71428571428572
avg_sample_per_episode: 236.71428571428572
avg_envstep_per_sec: 2312.2505007780105
avg_train_sample_per_sec: 2312.2505007780105
avg_episode_per_sec: 9.768107124590268
collect_time: 0.716617857555859
reward_mean: 1731.3215629356384
reward_std: 559.8671725931833
reward_max: 2848.649645721627
reward_min: 1098.9376026651278
total_envstep_count: 4565823
total_train_sample_count: 3493289
total_episode_count: 14883
total_duration: 1086.0305217469752
[2023-06-29 10:43:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2776
train_sample_count: 2776
avg_envstep_per_episode: 252.36363636363637
avg_sample_per_episode: 252.36363636363637
avg_envstep_per_sec: 2351.1701750217812
avg_train_sample_per_sec: 2351.1701750217812
avg_episode_per_sec: 9.316596514855762
collect_time: 1.1806886755758899
reward_mean: 1705.2798762577843
reward_std: 375.7952186751447
reward_max: 2603.645974828821
reward_min: 996.1576992047835
total_envstep_count: 4570343
total_train_sample_count: 3496865
total_episode_count: 14894
total_duration: 1087.2112104225512
[2023-06-29 10:43:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2752
train_sample_count: 2752
avg_envstep_per_episode: 250.1818181818182
avg_sample_per_episode: 250.1818181818182
avg_envstep_per_sec: 2479.24376769914
avg_train_sample_per_sec: 2479.24376769914
avg_episode_per_sec: 9.90976796682069
collect_time: 1.1100158991441134
reward_mean: 1582.7046325337083
reward_std: 684.0817070835989
reward_max: 3559.6435152303306
reward_min: 939.6029122103278
total_envstep_count: 4574959
total_train_sample_count: 3500417
total_episode_count: 14905
total_duration: 1088.3212263216953
[2023-06-29 10:43:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2102
train_sample_count: 2102
avg_envstep_per_episode: 300.2857142857143
avg_sample_per_episode: 300.2857142857143
avg_envstep_per_sec: 2476.3880778747275
avg_train_sample_per_sec: 2476.3880778747275
avg_episode_per_sec: 8.246772856861604
collect_time: 0.8488168792203067
reward_mean: 2033.987564119776
reward_std: 543.4325919839599
reward_max: 2796.061161147397
reward_min: 1238.460718173324
total_envstep_count: 4579343
total_train_sample_count: 3503719
total_episode_count: 14912
total_duration: 1089.1700432009156
[2023-06-29 10:43:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2601
train_sample_count: 2601
avg_envstep_per_episode: 325.125
avg_sample_per_episode: 325.125
avg_envstep_per_sec: 2392.4425332205956
avg_train_sample_per_sec: 2392.4425332205956
avg_episode_per_sec: 7.358531436280186
collect_time: 1.0871734488429505
reward_mean: 2126.7680975156873
reward_std: 724.4973568523831
reward_max: 3510.1620382043902
reward_min: 1309.5684696532667
total_envstep_count: 4584111
total_train_sample_count: 3507120
total_episode_count: 14920
total_duration: 1090.2572166497587
[2023-06-29 10:43:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2218
train_sample_count: 2218
avg_envstep_per_episode: 221.8
avg_sample_per_episode: 221.8
avg_envstep_per_sec: 2248.7158268622966
avg_train_sample_per_sec: 2248.7158268622966
avg_episode_per_sec: 10.138484341128478
collect_time: 0.9863407254507764
reward_mean: 1572.039181826621
reward_std: 510.9969312287735
reward_max: 2915.751270229903
reward_min: 979.8355858602002
total_envstep_count: 4588775
total_train_sample_count: 3510538
total_episode_count: 14930
total_duration: 1091.2435573752095
[2023-06-29 10:43:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1278
train_sample_count: 1278
avg_envstep_per_episode: 159.75
avg_sample_per_episode: 159.75
avg_envstep_per_sec: 2382.5436861323105
avg_train_sample_per_sec: 2382.5436861323105
avg_episode_per_sec: 14.914201478136528
collect_time: 0.5364014970380814
reward_mean: 1730.3377069605517
reward_std: 760.2458615896682
reward_max: 3622.0215312441564
reward_min: 1007.2453068849577
total_envstep_count: 4592911
total_train_sample_count: 3513816
total_episode_count: 14938
total_duration: 1091.7799588722476
[2023-06-29 10:43:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 155
train_sample_count: 155
avg_envstep_per_episode: 31.0
avg_sample_per_episode: 31.0
avg_envstep_per_sec: 2389.1315060192146
avg_train_sample_per_sec: 2389.1315060192146
avg_episode_per_sec: 77.06875825868434
collect_time: 0.06487713196594269
reward_mean: 1808.8928063922526
reward_std: 262.77077012684504
reward_max: 2110.5026041710535
reward_min: 1518.9067711797763
total_envstep_count: 4596631
total_train_sample_count: 3517171
total_episode_count: 14943
total_duration: 1091.8448360042134
[2023-06-29 10:43:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2780
train_sample_count: 2780
avg_envstep_per_episode: 252.72727272727272
avg_sample_per_episode: 252.72727272727272
avg_envstep_per_sec: 2108.932916542853
avg_train_sample_per_sec: 2108.932916542853
avg_episode_per_sec: 8.344698590637188
collect_time: 1.3182021951448406
reward_mean: 2226.5514791440664
reward_std: 1048.511314995916
reward_max: 3652.9172023713672
reward_min: 979.3868498887515
total_envstep_count: 4601455
total_train_sample_count: 3520751
total_episode_count: 14954
total_duration: 1093.1630381993582
[2023-06-29 10:43:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 289.0
avg_sample_per_episode: 289.0
avg_envstep_per_sec: 2347.642273623579
avg_train_sample_per_sec: 2347.642273623579
avg_episode_per_sec: 8.123329666517575
collect_time: 0.8617156126080083
reward_mean: 2025.5537600291736
reward_std: 903.0327826995634
reward_max: 3516.246604686512
reward_min: 1254.526137019725
total_envstep_count: 4605615
total_train_sample_count: 3523974
total_episode_count: 14961
total_duration: 1094.024753811966
[2023-06-29 10:43:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 407.0
avg_sample_per_episode: 407.0
avg_envstep_per_sec: 2500.586157402235
avg_train_sample_per_sec: 2500.586157402235
avg_episode_per_sec: 6.143946332683625
collect_time: 0.6510473535098138
reward_mean: 2717.530261791322
reward_std: 810.0842065262497
reward_max: 3560.8091679647546
reward_min: 1900.1164240874732
total_envstep_count: 4610023
total_train_sample_count: 3527202
total_episode_count: 14965
total_duration: 1094.6758011654758
[2023-06-29 10:44:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2386
train_sample_count: 2386
avg_envstep_per_episode: 298.25
avg_sample_per_episode: 298.25
avg_envstep_per_sec: 2317.242914944309
avg_train_sample_per_sec: 2317.242914944309
avg_episode_per_sec: 7.7694649285643225
collect_time: 1.02967193668487
reward_mean: 2454.4562288424313
reward_std: 911.3336928164025
reward_max: 3552.038168494588
reward_min: 1100.0585993427642
total_envstep_count: 4614479
total_train_sample_count: 3530788
total_episode_count: 14973
total_duration: 1095.7054731021608
[2023-06-29 10:44:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 274.8888888888889
avg_sample_per_episode: 274.8888888888889
avg_envstep_per_sec: 2513.2420494508106
avg_train_sample_per_sec: 2513.2420494508106
avg_episode_per_sec: 9.142756040847734
collect_time: 0.9843858853708954
reward_mean: 1869.017909802562
reward_std: 872.8749999391621
reward_max: 3561.237401330049
reward_min: 902.5046550123902
total_envstep_count: 4619199
total_train_sample_count: 3534062
total_episode_count: 14982
total_duration: 1096.6898589875316
[2023-06-29 10:44:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3263
train_sample_count: 3263
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2480.572037613309
avg_train_sample_per_sec: 2480.572037613309
avg_episode_per_sec: 9.882757121965374
collect_time: 1.315422390691587
reward_mean: 1534.447440105465
reward_std: 651.2588861781046
reward_max: 2895.1009738171747
reward_min: 932.8810700200232
total_envstep_count: 4623623
total_train_sample_count: 3537325
total_episode_count: 14995
total_duration: 1098.0052813782231
[2023-06-29 10:44:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 229.55555555555554
avg_sample_per_episode: 229.55555555555554
avg_envstep_per_sec: 2650.6927787764057
avg_train_sample_per_sec: 2650.6927787764057
avg_episode_per_sec: 11.5470643799553
collect_time: 0.7794188811853529
reward_mean: 1131.0804741739507
reward_std: 352.6153732406355
reward_max: 1938.12621307374
reward_min: 670.0811574488902
total_envstep_count: 4628047
total_train_sample_count: 3540591
total_episode_count: 15004
total_duration: 1098.7847002594085
[2023-06-29 10:44:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2159
train_sample_count: 2159
avg_envstep_per_episode: 215.9
avg_sample_per_episode: 215.9
avg_envstep_per_sec: 2629.2656620357375
avg_train_sample_per_sec: 2629.2656620357375
avg_episode_per_sec: 12.178164252134032
collect_time: 0.8211418234277517
reward_mean: 1602.9052334064268
reward_std: 544.6897704115902
reward_max: 2987.9615227919485
reward_min: 1116.851102971544
total_envstep_count: 4632031
total_train_sample_count: 3543950
total_episode_count: 15014
total_duration: 1099.6058420828363
[2023-06-29 10:44:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3463
train_sample_count: 3463
avg_envstep_per_episode: 266.38461538461536
avg_sample_per_episode: 266.38461538461536
avg_envstep_per_sec: 2442.414757200148
avg_train_sample_per_sec: 2442.414757200148
avg_episode_per_sec: 9.168753059082277
collect_time: 1.417859104311094
reward_mean: 1500.5194077355359
reward_std: 516.3966800186748
reward_max: 2760.6739624140564
reward_min: 963.0769201815979
total_envstep_count: 4637079
total_train_sample_count: 3547413
total_episode_count: 15027
total_duration: 1101.0237011871473
[2023-06-29 10:44:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3006
train_sample_count: 3006
avg_envstep_per_episode: 231.23076923076923
avg_sample_per_episode: 231.23076923076923
avg_envstep_per_sec: 2410.6821012850874
avg_train_sample_per_sec: 2410.6821012850874
avg_episode_per_sec: 10.42543822911049
collect_time: 1.2469499808363618
reward_mean: 1213.501303055003
reward_std: 377.99425852201244
reward_max: 1939.8969032998393
reward_min: 603.1918113860586
total_envstep_count: 4641703
total_train_sample_count: 3550819
total_episode_count: 15040
total_duration: 1102.2706511679837
[2023-06-29 10:44:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2193
train_sample_count: 2193
avg_envstep_per_episode: 219.3
avg_sample_per_episode: 219.3
avg_envstep_per_sec: 2428.0301036995133
avg_train_sample_per_sec: 2428.0301036995133
avg_episode_per_sec: 11.071728699040188
collect_time: 0.9032013221988454
reward_mean: 1336.3717687375256
reward_std: 702.6845313928353
reward_max: 2822.7563141161636
reward_min: 622.7671053693011
total_envstep_count: 4645919
total_train_sample_count: 3554212
total_episode_count: 15050
total_duration: 1103.1738524901825
[2023-06-29 10:44:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1384
train_sample_count: 1384
avg_envstep_per_episode: 197.71428571428572
avg_sample_per_episode: 197.71428571428572
avg_envstep_per_sec: 2585.906478854614
avg_train_sample_per_sec: 2585.906478854614
avg_episode_per_sec: 13.079006757212642
collect_time: 0.5352088373331354
reward_mean: 1575.5665795388536
reward_std: 298.8968153954663
reward_max: 1876.4691327922594
reward_min: 1096.0544201374107
total_envstep_count: 4650591
total_train_sample_count: 3557596
total_episode_count: 15057
total_duration: 1103.7090613275157
[2023-06-29 10:44:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3018
train_sample_count: 3018
avg_envstep_per_episode: 274.3636363636364
avg_sample_per_episode: 274.3636363636364
avg_envstep_per_sec: 2510.431697792898
avg_train_sample_per_sec: 2510.431697792898
avg_episode_per_sec: 9.150016128469806
collect_time: 1.202183673291467
reward_mean: 2135.2655940353984
reward_std: 1120.9521844352562
reward_max: 3567.1500086495034
reward_min: 409.78200498355443
total_envstep_count: 4655695
total_train_sample_count: 3561014
total_episode_count: 15068
total_duration: 1104.9112450008072
[2023-06-29 10:44:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2158
train_sample_count: 2158
avg_envstep_per_episode: 269.75
avg_sample_per_episode: 269.75
avg_envstep_per_sec: 2470.015636623778
avg_train_sample_per_sec: 2470.015636623778
avg_episode_per_sec: 9.156684473118732
collect_time: 0.8736786796012892
reward_mean: 1680.9475992682947
reward_std: 532.0397397993125
reward_max: 2971.405270177822
reward_min: 1110.4345593974845
total_envstep_count: 4660087
total_train_sample_count: 3564372
total_episode_count: 15076
total_duration: 1105.7849236804084
[2023-06-29 10:44:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3307
train_sample_count: 3307
avg_envstep_per_episode: 275.5833333333333
avg_sample_per_episode: 275.5833333333333
avg_envstep_per_sec: 2492.864878975025
avg_train_sample_per_sec: 2492.864878975025
avg_episode_per_sec: 9.045775188297641
collect_time: 1.326586141066626
reward_mean: 1804.1284883076762
reward_std: 796.6411437618185
reward_max: 3421.0122747926152
reward_min: 919.986288369001
total_envstep_count: 4664919
total_train_sample_count: 3567679
total_episode_count: 15088
total_duration: 1107.111509821475
[2023-06-29 10:44:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3140
train_sample_count: 3140
avg_envstep_per_episode: 285.45454545454544
avg_sample_per_episode: 285.45454545454544
avg_envstep_per_sec: 2670.6108374857786
avg_train_sample_per_sec: 2670.6108374857786
avg_episode_per_sec: 9.355643061255911
collect_time: 1.1757609742032364
reward_mean: 1451.510697945998
reward_std: 267.7617171573395
reward_max: 2174.67711912694
reward_min: 1170.3554340195506
total_envstep_count: 4669159
total_train_sample_count: 3571219
total_episode_count: 15099
total_duration: 1108.2872707956783
[2023-06-29 10:44:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2830
train_sample_count: 2830
avg_envstep_per_episode: 314.44444444444446
avg_sample_per_episode: 314.44444444444446
avg_envstep_per_sec: 2669.866348508432
avg_train_sample_per_sec: 2669.866348508432
avg_episode_per_sec: 8.490741037659326
collect_time: 1.059978152682073
reward_mean: 1629.3704248763468
reward_std: 687.6975613134372
reward_max: 3297.9128798709153
reward_min: 790.4587137086907
total_envstep_count: 4673519
total_train_sample_count: 3574449
total_episode_count: 15108
total_duration: 1109.3472489483604
[2023-06-29 10:44:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2889
train_sample_count: 2889
avg_envstep_per_episode: 321.0
avg_sample_per_episode: 321.0
avg_envstep_per_sec: 2432.281168107106
avg_train_sample_per_sec: 2432.281168107106
avg_episode_per_sec: 7.5771999006451916
collect_time: 1.1877738634338602
reward_mean: 1766.86448921467
reward_std: 442.48469022590075
reward_max: 2876.952885186708
reward_min: 1242.374489518985
total_envstep_count: 4677455
total_train_sample_count: 3577738
total_episode_count: 15117
total_duration: 1110.5350228117943
[2023-06-29 10:44:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2846
train_sample_count: 2846
avg_envstep_per_episode: 284.6
avg_sample_per_episode: 284.6
avg_envstep_per_sec: 2519.751303536258
avg_train_sample_per_sec: 2519.751303536258
avg_episode_per_sec: 8.853658831821006
collect_time: 1.129476546358317
reward_mean: 1332.7174695752487
reward_std: 387.7783319279721
reward_max: 2150.3256215135693
reward_min: 679.6823736858469
total_envstep_count: 4682183
total_train_sample_count: 3580984
total_episode_count: 15127
total_duration: 1111.6644993581526
[2023-06-29 10:44:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2586
train_sample_count: 2586
avg_envstep_per_episode: 287.3333333333333
avg_sample_per_episode: 287.3333333333333
avg_envstep_per_sec: 2708.648705387471
avg_train_sample_per_sec: 2708.648705387471
avg_episode_per_sec: 9.42685164287983
collect_time: 0.9547195968441665
reward_mean: 1754.691561036405
reward_std: 637.734655920051
reward_max: 3207.3111080341955
reward_min: 999.6518311531225
total_envstep_count: 4686799
total_train_sample_count: 3584370
total_episode_count: 15136
total_duration: 1112.6192189549968
[2023-06-29 10:44:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2250
train_sample_count: 2250
avg_envstep_per_episode: 225.0
avg_sample_per_episode: 225.0
avg_envstep_per_sec: 2477.1633424777024
avg_train_sample_per_sec: 2477.1633424777024
avg_episode_per_sec: 11.009614855456455
collect_time: 0.9082969868872315
reward_mean: 1443.3026354126014
reward_std: 776.6510047012042
reward_max: 3353.733508246046
reward_min: 622.1071590582912
total_envstep_count: 4691783
total_train_sample_count: 3587820
total_episode_count: 15146
total_duration: 1113.527515941884
[2023-06-29 10:45:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2087
train_sample_count: 2087
avg_envstep_per_episode: 208.7
avg_sample_per_episode: 208.7
avg_envstep_per_sec: 2318.485172213693
avg_train_sample_per_sec: 2318.485172213693
avg_episode_per_sec: 11.109176675676537
collect_time: 0.9001567165544255
reward_mean: 1850.9468522413977
reward_std: 623.9985893795146
reward_max: 3471.305832990312
reward_min: 1196.296514992166
total_envstep_count: 4695967
total_train_sample_count: 3591107
total_episode_count: 15156
total_duration: 1114.4276726584385
[2023-06-29 10:45:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 279.875
avg_sample_per_episode: 279.875
avg_envstep_per_sec: 2371.5312465939346
avg_train_sample_per_sec: 2371.5312465939346
avg_episode_per_sec: 8.473537281264615
collect_time: 0.9441157493563368
reward_mean: 1855.3591448141738
reward_std: 828.6984350665792
reward_max: 3325.4997045687505
reward_min: 629.9474148507799
total_envstep_count: 4700647
total_train_sample_count: 3594546
total_episode_count: 15164
total_duration: 1115.3717884077948
[2023-06-29 10:45:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1648
train_sample_count: 1648
avg_envstep_per_episode: 235.42857142857142
avg_sample_per_episode: 235.42857142857142
avg_envstep_per_sec: 2683.2521405298207
avg_train_sample_per_sec: 2683.2521405298207
avg_episode_per_sec: 11.397308849337831
collect_time: 0.6141800746591763
reward_mean: 1911.4557906942443
reward_std: 691.2972674053983
reward_max: 3070.211179661502
reward_min: 982.0694291326452
total_envstep_count: 4705015
total_train_sample_count: 3597794
total_episode_count: 15171
total_duration: 1115.985968482454
[2023-06-29 10:45:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 804
train_sample_count: 804
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2469.236256636641
avg_train_sample_per_sec: 2469.236256636641
avg_episode_per_sec: 9.213568121778511
collect_time: 0.32560675303509934
reward_mean: 3269.148850068574
reward_std: 326.38892473255447
reward_max: 3517.165386800274
reward_min: 2808.0049362826358
total_envstep_count: 4709295
total_train_sample_count: 3600998
total_episode_count: 15174
total_duration: 1116.311575235489
[2023-06-29 10:45:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1917
train_sample_count: 1917
avg_envstep_per_episode: 239.625
avg_sample_per_episode: 239.625
avg_envstep_per_sec: 2391.406057955654
avg_train_sample_per_sec: 2391.406057955654
avg_episode_per_sec: 9.979785322715301
collect_time: 0.8016204498698936
reward_mean: 2840.773414682567
reward_std: 955.6200484777193
reward_max: 3587.890771113199
reward_min: 1133.644026675693
total_envstep_count: 4714263
total_train_sample_count: 3604515
total_episode_count: 15182
total_duration: 1117.113195685359
[2023-06-29 10:45:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2941
train_sample_count: 2941
avg_envstep_per_episode: 367.625
avg_sample_per_episode: 367.625
avg_envstep_per_sec: 2477.4232145580195
avg_train_sample_per_sec: 2477.4232145580195
avg_episode_per_sec: 6.738995483326813
collect_time: 1.1871205463474612
reward_mean: 2706.9223686854375
reward_std: 1075.2931228746759
reward_max: 3601.7072997860823
reward_min: 641.9273546544426
total_envstep_count: 4719263
total_train_sample_count: 3607856
total_episode_count: 15190
total_duration: 1118.3003162317063
[2023-06-29 10:45:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1700
train_sample_count: 1700
avg_envstep_per_episode: 340.0
avg_sample_per_episode: 340.0
avg_envstep_per_sec: 2349.190866799043
avg_train_sample_per_sec: 2349.190866799043
avg_episode_per_sec: 6.9093849023501255
collect_time: 0.7236534178750591
reward_mean: 2271.445252765552
reward_std: 816.9450990062302
reward_max: 3394.557964490591
reward_min: 1332.9354365875138
total_envstep_count: 4723695
total_train_sample_count: 3611156
total_episode_count: 15195
total_duration: 1119.0239696495814
[2023-06-29 10:45:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 2657.2890506882
avg_train_sample_per_sec: 2657.2890506882
avg_episode_per_sec: 12.446318738586417
collect_time: 0.8034504185561091
reward_mean: 1910.3615564232387
reward_std: 972.2235886127751
reward_max: 3556.982787391346
reward_min: 655.7107815031973
total_envstep_count: 4728815
total_train_sample_count: 3614491
total_episode_count: 15205
total_duration: 1119.8274200681376
[2023-06-29 10:45:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2432
train_sample_count: 2432
avg_envstep_per_episode: 347.42857142857144
avg_sample_per_episode: 347.42857142857144
avg_envstep_per_sec: 2505.350432868944
avg_train_sample_per_sec: 2505.350432868944
avg_episode_per_sec: 7.211123778816861
collect_time: 0.9707224858021365
reward_mean: 2559.9134040282347
reward_std: 882.0908811998047
reward_max: 3521.1448108382797
reward_min: 1337.6795625014556
total_envstep_count: 4733639
total_train_sample_count: 3617723
total_episode_count: 15212
total_duration: 1120.7981425539397
[2023-06-29 10:45:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2592
train_sample_count: 2592
avg_envstep_per_episode: 324.0
avg_sample_per_episode: 324.0
avg_envstep_per_sec: 2435.9657899712815
avg_train_sample_per_sec: 2435.9657899712815
avg_episode_per_sec: 7.518412932010127
collect_time: 1.0640543519416823
reward_mean: 2257.277674849899
reward_std: 1034.2407169273297
reward_max: 3601.0564480999983
reward_min: 930.8413177660968
total_envstep_count: 4738791
total_train_sample_count: 3621115
total_episode_count: 15220
total_duration: 1121.8621969058813
[2023-06-29 10:45:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1809
train_sample_count: 1809
avg_envstep_per_episode: 258.42857142857144
avg_sample_per_episode: 258.42857142857144
avg_envstep_per_sec: 2422.658853086811
avg_train_sample_per_sec: 2422.658853086811
avg_episode_per_sec: 9.374578204316018
collect_time: 0.746700261861086
reward_mean: 2090.5946065986623
reward_std: 804.852788799527
reward_max: 3604.2430181887776
reward_min: 1347.082607232513
total_envstep_count: 4742959
total_train_sample_count: 3624524
total_episode_count: 15227
total_duration: 1122.6088971677425
[2023-06-29 10:45:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1677
train_sample_count: 1677
avg_envstep_per_episode: 239.57142857142858
avg_sample_per_episode: 239.57142857142858
avg_envstep_per_sec: 2695.128256525233
avg_train_sample_per_sec: 2695.128256525233
avg_episode_per_sec: 11.249789979532876
collect_time: 0.6222338383859021
reward_mean: 1999.0970813348479
reward_std: 1276.5916742320642
reward_max: 3588.299533757755
reward_min: 392.60831584265435
total_envstep_count: 4747255
total_train_sample_count: 3627801
total_episode_count: 15234
total_duration: 1123.2311310061284
[2023-06-29 10:45:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1353
train_sample_count: 1353
avg_envstep_per_episode: 193.28571428571428
avg_sample_per_episode: 193.28571428571428
avg_envstep_per_sec: 2247.062702831726
avg_train_sample_per_sec: 2247.062702831726
avg_episode_per_sec: 11.625601566756895
collect_time: 0.6021193793546407
reward_mean: 2243.8786200499517
reward_std: 867.5322237069195
reward_max: 3547.367969879498
reward_min: 1208.368779723422
total_envstep_count: 4751543
total_train_sample_count: 3631154
total_episode_count: 15241
total_duration: 1123.833250385483
[2023-06-29 10:45:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2037
train_sample_count: 2037
avg_envstep_per_episode: 339.5
avg_sample_per_episode: 339.5
avg_envstep_per_sec: 2662.88532536647
avg_train_sample_per_sec: 2662.88532536647
avg_episode_per_sec: 7.8435502956302505
collect_time: 0.7649597151614725
reward_mean: 2657.691852317264
reward_std: 744.7232936068053
reward_max: 3554.3003031319363
reward_min: 1701.2203000623729
total_envstep_count: 4756175
total_train_sample_count: 3634391
total_episode_count: 15247
total_duration: 1124.5982101006446
[2023-06-29 10:45:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2516
train_sample_count: 2516
avg_envstep_per_episode: 279.55555555555554
avg_sample_per_episode: 279.55555555555554
avg_envstep_per_sec: 2362.7625173118154
avg_train_sample_per_sec: 2362.7625173118154
avg_episode_per_sec: 8.451853201830819
collect_time: 1.0648552199238912
reward_mean: 2284.284410331344
reward_std: 839.4511101761175
reward_max: 3539.75128499977
reward_min: 1137.8880476863144
total_envstep_count: 4760703
total_train_sample_count: 3637707
total_episode_count: 15256
total_duration: 1125.6630653205684
[2023-06-29 10:45:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2155
train_sample_count: 2155
avg_envstep_per_episode: 307.85714285714283
avg_sample_per_episode: 307.85714285714283
avg_envstep_per_sec: 2647.785438990705
avg_train_sample_per_sec: 2647.785438990705
avg_episode_per_sec: 8.600695161454727
collect_time: 0.8138876996096227
reward_mean: 2131.6911228921517
reward_std: 671.1526736193682
reward_max: 3518.219229830685
reward_min: 1515.9109914955977
total_envstep_count: 4765215
total_train_sample_count: 3641062
total_episode_count: 15263
total_duration: 1126.4769530201781
[2023-06-29 10:45:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2173
train_sample_count: 2173
avg_envstep_per_episode: 241.44444444444446
avg_sample_per_episode: 241.44444444444446
avg_envstep_per_sec: 2425.604766953808
avg_train_sample_per_sec: 2425.604766953808
avg_episode_per_sec: 10.04622314891131
collect_time: 0.8958590573389079
reward_mean: 1760.2260013019586
reward_std: 457.39020154614224
reward_max: 2321.463287749894
reward_min: 1028.9187048510316
total_envstep_count: 4769351
total_train_sample_count: 3644435
total_episode_count: 15272
total_duration: 1127.372812077517
[2023-06-29 10:45:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3152
train_sample_count: 3152
avg_envstep_per_episode: 315.2
avg_sample_per_episode: 315.2
avg_envstep_per_sec: 2539.8859202585104
avg_train_sample_per_sec: 2539.8859202585104
avg_episode_per_sec: 8.058013706403903
collect_time: 1.241000619303086
reward_mean: 1875.610623836284
reward_std: 817.1819820666539
reward_max: 3508.7473848276964
reward_min: 1305.7194536900704
total_envstep_count: 4774231
total_train_sample_count: 3647987
total_episode_count: 15282
total_duration: 1128.61381269682
[2023-06-29 10:45:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 341.1666666666667
avg_sample_per_episode: 341.1666666666667
avg_envstep_per_sec: 2668.1228975284935
avg_train_sample_per_sec: 2668.1228975284935
avg_episode_per_sec: 7.820584946346341
collect_time: 0.7672060390831902
reward_mean: 1944.4763918713245
reward_std: 931.1122655429374
reward_max: 3616.452293391446
reward_min: 1007.015816993174
total_envstep_count: 4778575
total_train_sample_count: 3651234
total_episode_count: 15288
total_duration: 1129.3810187359034
[2023-06-29 10:46:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2115
train_sample_count: 2115
avg_envstep_per_episode: 264.375
avg_sample_per_episode: 264.375
avg_envstep_per_sec: 2651.626288095377
avg_train_sample_per_sec: 2651.626288095377
avg_episode_per_sec: 10.029792106270929
collect_time: 0.7976237109638752
reward_mean: 2201.357221534465
reward_std: 657.9508129726499
reward_max: 3521.813590772515
reward_min: 1332.9798536020858
total_envstep_count: 4783351
total_train_sample_count: 3654549
total_episode_count: 15296
total_duration: 1130.1786424468671
[2023-06-29 10:46:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2999
train_sample_count: 2999
avg_envstep_per_episode: 333.22222222222223
avg_sample_per_episode: 333.22222222222223
avg_envstep_per_sec: 2627.3280641509587
avg_train_sample_per_sec: 2627.3280641509587
avg_episode_per_sec: 7.884612396585071
collect_time: 1.1414638472143561
reward_mean: 2120.309190294093
reward_std: 826.8800806331778
reward_max: 3503.4007416835343
reward_min: 1343.831667359425
total_envstep_count: 4788151
total_train_sample_count: 3657948
total_episode_count: 15305
total_duration: 1131.3201062940814
[2023-06-29 10:46:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2033
train_sample_count: 2033
avg_envstep_per_episode: 254.125
avg_sample_per_episode: 254.125
avg_envstep_per_sec: 2481.2313431318207
avg_train_sample_per_sec: 2481.2313431318207
avg_episode_per_sec: 9.763822304502984
collect_time: 0.8193512489786376
reward_mean: 1817.7899473685725
reward_std: 875.436081084768
reward_max: 3626.914248584526
reward_min: 635.9374256082373
total_envstep_count: 4792855
total_train_sample_count: 3661181
total_episode_count: 15313
total_duration: 1132.13945754306
[2023-06-29 10:46:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 217.6
avg_sample_per_episode: 217.6
avg_envstep_per_sec: 2647.9293323698694
avg_train_sample_per_sec: 2647.9293323698694
avg_episode_per_sec: 12.168792887729179
collect_time: 0.41088709834497406
reward_mean: 2262.3607932422774
reward_std: 848.1205187371502
reward_max: 3565.9545477340253
reward_min: 932.4141859359592
total_envstep_count: 4797311
total_train_sample_count: 3664669
total_episode_count: 15318
total_duration: 1132.550344641405
[2023-06-29 10:46:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2096
train_sample_count: 2096
avg_envstep_per_episode: 232.88888888888889
avg_sample_per_episode: 232.88888888888889
avg_envstep_per_sec: 2443.7602564661747
avg_train_sample_per_sec: 2443.7602564661747
avg_episode_per_sec: 10.493245376047506
collect_time: 0.8576946099577472
reward_mean: 2183.165325683648
reward_std: 1055.3910713497023
reward_max: 3542.9306403636638
reward_min: 552.4592648849414
total_envstep_count: 4801647
total_train_sample_count: 3667965
total_episode_count: 15327
total_duration: 1133.4080392513627
[2023-06-29 10:46:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2185
train_sample_count: 2185
avg_envstep_per_episode: 312.14285714285717
avg_sample_per_episode: 312.14285714285717
avg_envstep_per_sec: 2678.292901467953
avg_train_sample_per_sec: 2678.292901467953
avg_episode_per_sec: 8.580343391430512
collect_time: 0.8158181649222971
reward_mean: 2148.081769219694
reward_std: 1180.9098671299519
reward_max: 3559.0768303559444
reward_min: 653.7960485817143
total_envstep_count: 4806567
total_train_sample_count: 3671350
total_episode_count: 15334
total_duration: 1134.223857416285
[2023-06-29 10:46:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1643
train_sample_count: 1643
avg_envstep_per_episode: 273.8333333333333
avg_sample_per_episode: 273.8333333333333
avg_envstep_per_sec: 2627.66784054563
avg_train_sample_per_sec: 2627.66784054563
avg_episode_per_sec: 9.595865516295667
collect_time: 0.6252692880919204
reward_mean: 2336.2007308235247
reward_std: 579.6472621143848
reward_max: 3475.7657453823695
reward_min: 1686.8413858487127
total_envstep_count: 4810695
total_train_sample_count: 3674593
total_episode_count: 15340
total_duration: 1134.8491267043769
[2023-06-29 10:46:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 869
train_sample_count: 869
avg_envstep_per_episode: 217.25
avg_sample_per_episode: 217.25
avg_envstep_per_sec: 2612.1751194116055
avg_train_sample_per_sec: 2612.1751194116055
avg_episode_per_sec: 12.023821032964811
collect_time: 0.33267294889315957
reward_mean: 3133.639926647368
reward_std: 629.550290815884
reward_max: 3519.959003392182
reward_min: 2043.5035050466827
total_envstep_count: 4814767
total_train_sample_count: 3677862
total_episode_count: 15344
total_duration: 1135.18179965327
[2023-06-29 10:46:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2058
train_sample_count: 2058
avg_envstep_per_episode: 228.66666666666666
avg_sample_per_episode: 228.66666666666666
avg_envstep_per_sec: 2349.1976963647576
avg_train_sample_per_sec: 2349.1976963647576
avg_episode_per_sec: 10.273459313548504
collect_time: 0.87604376727622
reward_mean: 2061.857544134039
reward_std: 1112.422066660262
reward_max: 3472.845418692369
reward_min: 625.3342658162246
total_envstep_count: 4818839
total_train_sample_count: 3681120
total_episode_count: 15353
total_duration: 1136.0578434205463
[2023-06-29 10:46:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 278.4
avg_sample_per_episode: 278.4
avg_envstep_per_sec: 2666.038451712536
avg_train_sample_per_sec: 2666.038451712536
avg_episode_per_sec: 9.57628754207089
collect_time: 0.5221230020541698
reward_mean: 2364.9401727963223
reward_std: 681.8794396711883
reward_max: 3615.2433857246283
reward_min: 1657.3650023273062
total_envstep_count: 4823351
total_train_sample_count: 3684512
total_episode_count: 15358
total_duration: 1136.5799664226004
[2023-06-29 10:46:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1872
train_sample_count: 1872
avg_envstep_per_episode: 312.0
avg_sample_per_episode: 312.0
avg_envstep_per_sec: 2664.1721848314205
avg_train_sample_per_sec: 2664.1721848314205
avg_episode_per_sec: 8.53901341292122
collect_time: 0.7026572871897367
reward_mean: 2754.207219255146
reward_std: 1046.5876449540795
reward_max: 3579.101472409686
reward_min: 1233.1790462022675
total_envstep_count: 4827463
total_train_sample_count: 3687984
total_episode_count: 15364
total_duration: 1137.2826237097902
[2023-06-29 10:46:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 253.6
avg_sample_per_episode: 253.6
avg_envstep_per_sec: 2584.857912998932
avg_train_sample_per_sec: 2584.857912998932
avg_episode_per_sec: 10.192657385642477
collect_time: 0.49054920722078543
reward_mean: 2426.0262342488627
reward_std: 1050.917227908057
reward_max: 3391.464708102131
reward_min: 771.5046913542349
total_envstep_count: 4831351
total_train_sample_count: 3691252
total_episode_count: 15369
total_duration: 1137.773172917011
[2023-06-29 10:46:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1293
train_sample_count: 1293
avg_envstep_per_episode: 258.6
avg_sample_per_episode: 258.6
avg_envstep_per_sec: 2622.9583497428816
avg_train_sample_per_sec: 2622.9583497428816
avg_episode_per_sec: 10.142917052369999
collect_time: 0.49295483480580155
reward_mean: 3010.2347826141327
reward_std: 707.7484116255955
reward_max: 3533.300221676533
reward_min: 1674.2524333560393
total_envstep_count: 4835743
total_train_sample_count: 3694545
total_episode_count: 15374
total_duration: 1138.2661277518168
[2023-06-29 10:46:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2265
train_sample_count: 2265
avg_envstep_per_episode: 377.5
avg_sample_per_episode: 377.5
avg_envstep_per_sec: 2679.884448313544
avg_train_sample_per_sec: 2679.884448313544
avg_episode_per_sec: 7.099031651161706
collect_time: 0.8451856950120997
reward_mean: 3270.346159904167
reward_std: 593.1478858450071
reward_max: 3670.105756183298
reward_min: 1952.1102729186455
total_envstep_count: 4840239
total_train_sample_count: 3698010
total_episode_count: 15380
total_duration: 1139.111313446829
[2023-06-29 10:46:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 329.57142857142856
avg_sample_per_episode: 329.57142857142856
avg_envstep_per_sec: 2704.782882706888
avg_train_sample_per_sec: 2704.782882706888
avg_episode_per_sec: 8.206970168594804
collect_time: 0.8529335255520416
reward_mean: 2286.3233353734618
reward_std: 940.6515942812667
reward_max: 3552.667789849952
reward_min: 922.9148175090974
total_envstep_count: 4844799
total_train_sample_count: 3701517
total_episode_count: 15387
total_duration: 1139.964246972381
[2023-06-29 10:46:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2530
train_sample_count: 2530
avg_envstep_per_episode: 281.1111111111111
avg_sample_per_episode: 281.1111111111111
avg_envstep_per_sec: 2568.5525913616966
avg_train_sample_per_sec: 2568.5525913616966
avg_episode_per_sec: 9.137143605634494
collect_time: 0.9849905384490266
reward_mean: 1801.9577289373067
reward_std: 672.0869848273419
reward_max: 3454.9150485759114
reward_min: 995.3921768693626
total_envstep_count: 4849095
total_train_sample_count: 3704847
total_episode_count: 15396
total_duration: 1140.94923751083
[2023-06-29 10:46:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2551
train_sample_count: 2551
avg_envstep_per_episode: 283.44444444444446
avg_sample_per_episode: 283.44444444444446
avg_envstep_per_sec: 2590.4454866613496
avg_train_sample_per_sec: 2590.4454866613496
avg_episode_per_sec: 9.139164790259564
collect_time: 0.9847727015046404
reward_mean: 1778.2062906728527
reward_std: 716.380784108414
reward_max: 3586.63602520528
reward_min: 934.8107009194207
total_envstep_count: 4853975
total_train_sample_count: 3708198
total_episode_count: 15405
total_duration: 1141.9340102123347
[2023-06-29 10:46:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1737
train_sample_count: 1737
avg_envstep_per_episode: 217.125
avg_sample_per_episode: 217.125
avg_envstep_per_sec: 2580.139646586208
avg_train_sample_per_sec: 2580.139646586208
avg_episode_per_sec: 11.88319929343101
collect_time: 0.6732193748885766
reward_mean: 1648.9057089594878
reward_std: 463.7522142431601
reward_max: 2534.402742139652
reward_min: 1117.0901410261033
total_envstep_count: 4858255
total_train_sample_count: 3711535
total_episode_count: 15413
total_duration: 1142.6072295872232
[2023-06-29 10:46:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 245.3
avg_sample_per_episode: 245.3
avg_envstep_per_sec: 2636.5953086746567
avg_train_sample_per_sec: 2636.5953086746567
avg_episode_per_sec: 10.748452134833496
collect_time: 0.9303665192490443
reward_mean: 1875.669730460671
reward_std: 767.2068191454837
reward_max: 3275.964764394533
reward_min: 703.8913553894502
total_envstep_count: 4862855
total_train_sample_count: 3714788
total_episode_count: 15423
total_duration: 1143.5375961064722
[2023-06-29 10:47:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1433
train_sample_count: 1433
avg_envstep_per_episode: 286.6
avg_sample_per_episode: 286.6
avg_envstep_per_sec: 2599.237282920293
avg_train_sample_per_sec: 2599.237282920293
avg_episode_per_sec: 9.06921592086634
collect_time: 0.5513155760793016
reward_mean: 2298.5656487183655
reward_std: 906.20580807426
reward_max: 3539.903336385654
reward_min: 858.7764599638023
total_envstep_count: 4867847
total_train_sample_count: 3718221
total_episode_count: 15428
total_duration: 1144.0889116825515
[2023-06-29 10:47:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2819
train_sample_count: 2819
avg_envstep_per_episode: 234.91666666666666
avg_sample_per_episode: 234.91666666666666
avg_envstep_per_sec: 2489.8957608039254
avg_train_sample_per_sec: 2489.8957608039254
avg_episode_per_sec: 10.599059641591737
collect_time: 1.132175910484628
reward_mean: 1936.5814299678104
reward_std: 1113.4675498702895
reward_max: 3500.935856787377
reward_min: 221.79620400814224
total_envstep_count: 4872695
total_train_sample_count: 3721440
total_episode_count: 15440
total_duration: 1145.2210875930361
[2023-06-29 10:47:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2709
train_sample_count: 2709
avg_envstep_per_episode: 270.9
avg_sample_per_episode: 270.9
avg_envstep_per_sec: 2419.324426020856
avg_train_sample_per_sec: 2419.324426020856
avg_episode_per_sec: 8.930691864233504
collect_time: 1.1197340757045895
reward_mean: 1602.5367590409446
reward_std: 707.290281215863
reward_max: 3230.664910141163
reward_min: 825.7794941036478
total_envstep_count: 4876999
total_train_sample_count: 3724949
total_episode_count: 15450
total_duration: 1146.3408216687408
[2023-06-29 10:47:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2777
train_sample_count: 2777
avg_envstep_per_episode: 396.7142857142857
avg_sample_per_episode: 396.7142857142857
avg_envstep_per_sec: 2531.1149677675307
avg_train_sample_per_sec: 2531.1149677675307
avg_episode_per_sec: 6.3801961737028146
collect_time: 1.0971449481211604
reward_mean: 2200.0559018349236
reward_std: 962.6761359399294
reward_max: 3545.1661105869534
reward_min: 779.3348995228084
total_envstep_count: 4882039
total_train_sample_count: 3728526
total_episode_count: 15457
total_duration: 1147.437966616862
[2023-06-29 10:47:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1720
train_sample_count: 1720
avg_envstep_per_episode: 344.0
avg_sample_per_episode: 344.0
avg_envstep_per_sec: 2534.6766257570994
avg_train_sample_per_sec: 2534.6766257570994
avg_episode_per_sec: 7.368246005107847
collect_time: 0.6785875494023786
reward_mean: 2321.3829980405367
reward_std: 843.0135982324448
reward_max: 3423.609035112053
reward_min: 926.4343002712214
total_envstep_count: 4887263
total_train_sample_count: 3731846
total_episode_count: 15462
total_duration: 1148.1165541662645
[2023-06-29 10:47:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 198.8
avg_sample_per_episode: 198.8
avg_envstep_per_sec: 2572.4462512924997
avg_train_sample_per_sec: 2572.4462512924997
avg_episode_per_sec: 12.939870479338529
collect_time: 0.3864026311533525
reward_mean: 3274.769930063733
reward_std: 355.15024144648424
reward_max: 3486.1325104861135
reward_min: 2565.905278844341
total_envstep_count: 4892071
total_train_sample_count: 3735240
total_episode_count: 15467
total_duration: 1148.5029567974177
[2023-06-29 10:47:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2266
train_sample_count: 2266
avg_envstep_per_episode: 251.77777777777777
avg_sample_per_episode: 251.77777777777777
avg_envstep_per_sec: 2440.9590471509214
avg_train_sample_per_sec: 2440.9590471509214
avg_episode_per_sec: 9.694894715074268
collect_time: 0.928323645021766
reward_mean: 2587.036812823473
reward_std: 698.6882530889826
reward_max: 3532.468104847083
reward_min: 1434.619407123183
total_envstep_count: 4896639
total_train_sample_count: 3738706
total_episode_count: 15476
total_duration: 1149.4312804424394
[2023-06-29 10:47:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1417
train_sample_count: 1417
avg_envstep_per_episode: 202.42857142857142
avg_sample_per_episode: 202.42857142857142
avg_envstep_per_sec: 2648.227064721593
avg_train_sample_per_sec: 2648.227064721593
avg_episode_per_sec: 13.082279077664891
collect_time: 0.5350749635016545
reward_mean: 1491.5003591276025
reward_std: 667.6869465275097
reward_max: 2048.0591590102254
reward_min: 200.13776622659418
total_envstep_count: 4900871
total_train_sample_count: 3742123
total_episode_count: 15483
total_duration: 1149.9663554059412
[2023-06-29 10:47:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 290.2857142857143
avg_sample_per_episode: 290.2857142857143
avg_envstep_per_sec: 2672.734455832385
avg_train_sample_per_sec: 2672.734455832385
avg_episode_per_sec: 9.207254523044634
collect_time: 0.7602700655749067
reward_mean: 2713.748625053118
reward_std: 803.7894947644237
reward_max: 3694.8014203643343
reward_min: 1611.038255385172
total_envstep_count: 4905055
total_train_sample_count: 3745355
total_episode_count: 15490
total_duration: 1150.7266254715162
[2023-06-29 10:47:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2240
train_sample_count: 2240
avg_envstep_per_episode: 373.3333333333333
avg_sample_per_episode: 373.3333333333333
avg_envstep_per_sec: 2449.56923141564
avg_train_sample_per_sec: 2449.56923141564
avg_episode_per_sec: 6.561346155577606
collect_time: 0.9144464958459138
reward_mean: 2418.650561448781
reward_std: 824.4595649754751
reward_max: 3449.4411719213363
reward_min: 1300.1766219068145
total_envstep_count: 4910063
total_train_sample_count: 3748795
total_episode_count: 15496
total_duration: 1151.641071967362
[2023-06-29 10:47:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 813
train_sample_count: 813
avg_envstep_per_episode: 203.25
avg_sample_per_episode: 203.25
avg_envstep_per_sec: 2665.7365972489474
avg_train_sample_per_sec: 2665.7365972489474
avg_episode_per_sec: 13.115555214016961
collect_time: 0.30498137019202115
reward_mean: 2553.409467260755
reward_std: 685.100938717363
reward_max: 3509.658627777529
reward_min: 1902.6599106171686
total_envstep_count: 4913951
total_train_sample_count: 3752008
total_episode_count: 15500
total_duration: 1151.946053337554
[2023-06-29 10:47:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1763
train_sample_count: 1763
avg_envstep_per_episode: 220.375
avg_sample_per_episode: 220.375
avg_envstep_per_sec: 2489.5252145659133
avg_train_sample_per_sec: 2489.5252145659133
avg_episode_per_sec: 11.296767848285482
collect_time: 0.7081671596193919
reward_mean: 2624.6696214908266
reward_std: 821.9523771519868
reward_max: 3610.76893196132
reward_min: 955.2100543311362
total_envstep_count: 4918479
total_train_sample_count: 3755371
total_episode_count: 15508
total_duration: 1152.6542204971734
[2023-06-29 10:47:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2974
train_sample_count: 2974
avg_envstep_per_episode: 371.75
avg_sample_per_episode: 371.75
avg_envstep_per_sec: 2563.9520899728063
avg_train_sample_per_sec: 2563.9520899728063
avg_episode_per_sec: 6.896979394681389
collect_time: 1.159928070275113
reward_mean: 2572.416955928718
reward_std: 723.3907018588998
reward_max: 3549.678367249846
reward_min: 1579.1378695829737
total_envstep_count: 4923423
total_train_sample_count: 3758745
total_episode_count: 15516
total_duration: 1153.8141485674485
[2023-06-29 10:47:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 302.0
avg_sample_per_episode: 302.0
avg_envstep_per_sec: 2521.4361317254784
avg_train_sample_per_sec: 2521.4361317254784
avg_episode_per_sec: 8.34912626399165
collect_time: 0.8384110838267951
reward_mean: 1857.070695637464
reward_std: 950.1241659338322
reward_max: 3563.020237275204
reward_min: 110.70138568043298
total_envstep_count: 4928191
total_train_sample_count: 3762059
total_episode_count: 15523
total_duration: 1154.6525596512752
[2023-06-29 10:47:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2159
train_sample_count: 2159
avg_envstep_per_episode: 308.42857142857144
avg_sample_per_episode: 308.42857142857144
avg_envstep_per_sec: 2594.1605901130006
avg_train_sample_per_sec: 2594.1605901130006
avg_episode_per_sec: 8.410895845665125
collect_time: 0.8322537965569644
reward_mean: 2407.8700339495363
reward_std: 1024.1615072056118
reward_max: 3624.528399684144
reward_min: 1082.7205527406572
total_envstep_count: 4932807
total_train_sample_count: 3765418
total_episode_count: 15530
total_duration: 1155.484813447832
[2023-06-29 10:47:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 2279.2847647206722
avg_train_sample_per_sec: 2279.2847647206722
avg_episode_per_sec: 9.153754075183421
collect_time: 0.546223981869407
reward_mean: 2457.0938907371847
reward_std: 924.6455932354041
reward_max: 3555.0962798717105
reward_min: 1307.4235310882473
total_envstep_count: 4937047
total_train_sample_count: 3768663
total_episode_count: 15535
total_duration: 1156.0310374297014
[2023-06-29 10:47:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1666
train_sample_count: 1666
avg_envstep_per_episode: 277.6666666666667
avg_sample_per_episode: 277.6666666666667
avg_envstep_per_sec: 2439.256743228695
avg_train_sample_per_sec: 2439.256743228695
avg_episode_per_sec: 8.784838210907665
collect_time: 0.6829949346762152
reward_mean: 2765.082115725008
reward_std: 932.4284663345668
reward_max: 3517.4660832842696
reward_min: 901.0915803315442
total_envstep_count: 4941919
total_train_sample_count: 3771929
total_episode_count: 15541
total_duration: 1156.7140323643775
[2023-06-29 10:47:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1809
train_sample_count: 1809
avg_envstep_per_episode: 258.42857142857144
avg_sample_per_episode: 258.42857142857144
avg_envstep_per_sec: 2674.397217940747
avg_train_sample_per_sec: 2674.397217940747
avg_episode_per_sec: 10.348690174452862
collect_time: 0.6764141047801822
reward_mean: 2725.9953753481764
reward_std: 726.5684289277812
reward_max: 3514.5727637981418
reward_min: 1604.8280433598243
total_envstep_count: 4946711
total_train_sample_count: 3775338
total_episode_count: 15548
total_duration: 1157.3904464691577
[2023-06-29 10:48:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2305
train_sample_count: 2305
avg_envstep_per_episode: 384.1666666666667
avg_sample_per_episode: 384.1666666666667
avg_envstep_per_sec: 2549.0806868477744
avg_train_sample_per_sec: 2549.0806868477744
avg_episode_per_sec: 6.635351028670996
collect_time: 0.9042475634030998
reward_mean: 2861.256875756228
reward_std: 699.2352894802913
reward_max: 3636.868711143498
reward_min: 1987.3108244813232
total_envstep_count: 4951287
total_train_sample_count: 3778843
total_episode_count: 15554
total_duration: 1158.2946940325608
[2023-06-29 10:48:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1784
train_sample_count: 1784
avg_envstep_per_episode: 254.85714285714286
avg_sample_per_episode: 254.85714285714286
avg_envstep_per_sec: 2677.1666946836426
avg_train_sample_per_sec: 2677.1666946836426
avg_episode_per_sec: 10.504577837884248
collect_time: 0.6663761369595302
reward_mean: 2046.7133770006842
reward_std: 1052.6769964873197
reward_max: 3523.4843603439913
reward_min: 546.3208369203285
total_envstep_count: 4955983
total_train_sample_count: 3782227
total_episode_count: 15561
total_duration: 1158.9610701695203
[2023-06-29 10:48:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1662
train_sample_count: 1662
avg_envstep_per_episode: 237.42857142857142
avg_sample_per_episode: 237.42857142857142
avg_envstep_per_sec: 2081.2093207738403
avg_train_sample_per_sec: 2081.2093207738403
avg_episode_per_sec: 8.765622891345899
collect_time: 0.7985741671491414
reward_mean: 2299.0846829904995
reward_std: 1225.0387057183962
reward_max: 3499.112967236207
reward_min: 111.2928342095815
total_envstep_count: 4960879
total_train_sample_count: 3785489
total_episode_count: 15568
total_duration: 1159.7596443366695
[2023-06-29 10:48:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 924
train_sample_count: 924
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 2599.548671969486
avg_train_sample_per_sec: 2599.548671969486
avg_episode_per_sec: 11.253457454413358
collect_time: 0.35544631649460656
reward_mean: 3013.128602049802
reward_std: 720.6431760179445
reward_max: 3480.378755194508
reward_min: 1768.8248716713397
total_envstep_count: 4964855
total_train_sample_count: 3788813
total_episode_count: 15572
total_duration: 1160.115090653164
[2023-06-29 10:48:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2116
train_sample_count: 2116
avg_envstep_per_episode: 352.6666666666667
avg_sample_per_episode: 352.6666666666667
avg_envstep_per_sec: 2567.9636310403307
avg_train_sample_per_sec: 2567.9636310403307
avg_episode_per_sec: 7.281560390473527
collect_time: 0.8239992087204009
reward_mean: 3429.0028986985776
reward_std: 68.73523145448947
reward_max: 3534.538230526861
reward_min: 3316.6198122535984
total_envstep_count: 4969655
total_train_sample_count: 3792129
total_episode_count: 15578
total_duration: 1160.9390898618844
[2023-06-29 10:48:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2945
train_sample_count: 2945
avg_envstep_per_episode: 327.22222222222223
avg_sample_per_episode: 327.22222222222223
avg_envstep_per_sec: 2360.200404664232
avg_train_sample_per_sec: 2360.200404664232
avg_episode_per_sec: 7.212836550756566
collect_time: 1.2477753983009605
reward_mean: 2326.227239649413
reward_std: 766.8981444901143
reward_max: 3529.7340310972286
reward_min: 1014.1551303067045
total_envstep_count: 4974751
total_train_sample_count: 3795474
total_episode_count: 15587
total_duration: 1162.1868652601854
[2023-06-29 10:48:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2490
train_sample_count: 2490
avg_envstep_per_episode: 415.0
avg_sample_per_episode: 415.0
avg_envstep_per_sec: 2526.593257256612
avg_train_sample_per_sec: 2526.593257256612
avg_episode_per_sec: 6.088176523509909
collect_time: 0.9855167597113176
reward_mean: 2710.8511497722243
reward_std: 654.1511883015041
reward_max: 3436.745185972551
reward_min: 1774.6521897157563
total_envstep_count: 4979199
total_train_sample_count: 3798764
total_episode_count: 15593
total_duration: 1163.1723820198968
[2023-06-29 10:48:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2132
train_sample_count: 2132
avg_envstep_per_episode: 304.57142857142856
avg_sample_per_episode: 304.57142857142856
avg_envstep_per_sec: 2615.1255115257
avg_train_sample_per_sec: 2615.1255115257
avg_episode_per_sec: 8.586246989061866
collect_time: 0.8152572374073787
reward_mean: 1854.3619030117886
reward_std: 910.6398554730162
reward_max: 3395.2127432376838
reward_min: 830.6652916950794
total_envstep_count: 4983559
total_train_sample_count: 3802096
total_episode_count: 15600
total_duration: 1163.9876392573042
[2023-06-29 10:48:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1689
train_sample_count: 1689
avg_envstep_per_episode: 337.8
avg_sample_per_episode: 337.8
avg_envstep_per_sec: 2320.9870068777786
avg_train_sample_per_sec: 2320.9870068777786
avg_episode_per_sec: 6.870891080159203
collect_time: 0.7277076498037205
reward_mean: 2701.4236160539867
reward_std: 970.3655435880236
reward_max: 3554.228820141324
reward_min: 1237.4258489179053
total_envstep_count: 4988223
total_train_sample_count: 3805385
total_episode_count: 15605
total_duration: 1164.715346907108
[2023-06-29 10:48:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2367
train_sample_count: 2367
avg_envstep_per_episode: 394.5
avg_sample_per_episode: 394.5
avg_envstep_per_sec: 2460.371060062354
avg_train_sample_per_sec: 2460.371060062354
avg_episode_per_sec: 6.2366820280414546
collect_time: 0.9620500088064003
reward_mean: 3038.6934968237747
reward_std: 607.2263540134311
reward_max: 3456.690262569483
reward_min: 1832.975587217205
total_envstep_count: 4993127
total_train_sample_count: 3808952
total_episode_count: 15611
total_duration: 1165.6773969159144
[2023-06-29 10:48:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 452
train_sample_count: 452
avg_envstep_per_episode: 150.66666666666666
avg_sample_per_episode: 150.66666666666666
avg_envstep_per_sec: 2679.6332426045205
avg_train_sample_per_sec: 2679.6332426045205
avg_episode_per_sec: 17.785176388968058
collect_time: 0.1686798002105206
reward_mean: 2605.331083815024
reward_std: 1178.0297959488648
reward_max: 3459.6519569090296
reward_min: 939.5289781151109
total_envstep_count: 4997087
total_train_sample_count: 3812204
total_episode_count: 15614
total_duration: 1165.846076716125
[2023-06-29 10:48:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2493
train_sample_count: 2493
avg_envstep_per_episode: 249.3
avg_sample_per_episode: 249.3
avg_envstep_per_sec: 2634.613336483273
avg_train_sample_per_sec: 2634.613336483273
avg_episode_per_sec: 10.568043868765637
collect_time: 0.9462489107899602
reward_mean: 2443.127502915209
reward_std: 1056.0980684532192
reward_max: 3482.7015939616335
reward_min: 114.79086371306552
total_envstep_count: 5001623
total_train_sample_count: 3815497
total_episode_count: 15624
total_duration: 1166.792325626915
[2023-06-29 10:48:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2508
train_sample_count: 2508
avg_envstep_per_episode: 278.6666666666667
avg_sample_per_episode: 278.6666666666667
avg_envstep_per_sec: 2514.8907168883106
avg_train_sample_per_sec: 2514.8907168883106
avg_episode_per_sec: 9.024727452948483
collect_time: 0.9972600332722066
reward_mean: 1713.9406211218322
reward_std: 845.7999145228933
reward_max: 3171.321932551967
reward_min: 304.25383195080286
total_envstep_count: 5006391
total_train_sample_count: 3818805
total_episode_count: 15633
total_duration: 1167.7895856601872
[2023-06-29 10:48:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3125
train_sample_count: 3125
avg_envstep_per_episode: 260.4166666666667
avg_sample_per_episode: 260.4166666666667
avg_envstep_per_sec: 2498.11515723838
avg_train_sample_per_sec: 2498.11515723838
avg_episode_per_sec: 9.59276220379538
collect_time: 1.2509431324433535
reward_mean: 1566.04480449728
reward_std: 962.0684060343274
reward_max: 3306.1372548577715
reward_min: 263.57344913977977
total_envstep_count: 5011439
total_train_sample_count: 3822330
total_episode_count: 15645
total_duration: 1169.0405287926305
[2023-06-29 10:48:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1326
train_sample_count: 1326
avg_envstep_per_episode: 221.0
avg_sample_per_episode: 221.0
avg_envstep_per_sec: 2519.527988637337
avg_train_sample_per_sec: 2519.527988637337
avg_episode_per_sec: 11.400579134105596
collect_time: 0.5262890533385798
reward_mean: 1211.2646268323633
reward_std: 558.679619881934
reward_max: 2140.4856524599395
reward_min: 499.30844286925617
total_envstep_count: 5016111
total_train_sample_count: 3825656
total_episode_count: 15651
total_duration: 1169.5668178459691
[2023-06-29 10:48:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2580
train_sample_count: 2580
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 2363.630931243209
avg_train_sample_per_sec: 2363.630931243209
avg_episode_per_sec: 10.993632238340506
collect_time: 1.0915409702491017
reward_mean: 1976.3978501207494
reward_std: 1264.0461193344302
reward_max: 3435.008488324461
reward_min: 109.5971546624985
total_envstep_count: 5020687
total_train_sample_count: 3829036
total_episode_count: 15663
total_duration: 1170.6583588162182
[2023-06-29 10:48:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3486
train_sample_count: 3486
avg_envstep_per_episode: 290.5
avg_sample_per_episode: 290.5
avg_envstep_per_sec: 2646.858492561808
avg_train_sample_per_sec: 2646.858492561808
avg_episode_per_sec: 9.111388958904675
collect_time: 1.3170330071654168
reward_mean: 1590.8833646183457
reward_std: 544.1695595104753
reward_max: 2859.8441841094536
reward_min: 877.2454050441733
total_envstep_count: 5025863
total_train_sample_count: 3832522
total_episode_count: 15675
total_duration: 1171.9753918233837
[2023-06-29 10:48:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1768
train_sample_count: 1768
avg_envstep_per_episode: 252.57142857142858
avg_sample_per_episode: 252.57142857142858
avg_envstep_per_sec: 2544.789543739688
avg_train_sample_per_sec: 2544.789543739688
avg_episode_per_sec: 10.075524211639035
collect_time: 0.6947529332432894
reward_mean: 1619.2107258865124
reward_std: 871.3399075291255
reward_max: 3454.59682228932
reward_min: 600.1382576317188
total_envstep_count: 5031031
total_train_sample_count: 3835890
total_episode_count: 15682
total_duration: 1172.670144756627
[2023-06-29 10:49:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1828
train_sample_count: 1828
avg_envstep_per_episode: 304.6666666666667
avg_sample_per_episode: 304.6666666666667
avg_envstep_per_sec: 2566.243265443457
avg_train_sample_per_sec: 2566.243265443457
avg_episode_per_sec: 8.42311793909231
collect_time: 0.7123252984685824
reward_mean: 2973.8334026370917
reward_std: 683.6668560356137
reward_max: 3503.500527895072
reward_min: 1569.77573189343
total_envstep_count: 5035471
total_train_sample_count: 3839318
total_episode_count: 15688
total_duration: 1173.3824700550956
[2023-06-29 10:49:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2575
train_sample_count: 2575
avg_envstep_per_episode: 214.58333333333334
avg_sample_per_episode: 214.58333333333334
avg_envstep_per_sec: 2517.4655315998048
avg_train_sample_per_sec: 2517.4655315998048
avg_episode_per_sec: 11.731878205513652
collect_time: 1.0228541235929587
reward_mean: 1590.596180192412
reward_std: 923.7213146903781
reward_max: 3474.4339801638466
reward_min: 542.8416845455084
total_envstep_count: 5039975
total_train_sample_count: 3842693
total_episode_count: 15700
total_duration: 1174.4053241786885
[2023-06-29 10:49:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2835
train_sample_count: 2835
avg_envstep_per_episode: 218.07692307692307
avg_sample_per_episode: 218.07692307692307
avg_envstep_per_sec: 2592.0015588225883
avg_train_sample_per_sec: 2592.0015588225883
avg_episode_per_sec: 11.885721433754373
collect_time: 1.0937493422217668
reward_mean: 1252.9005997006427
reward_std: 855.0143983393651
reward_max: 3262.880328624593
reward_min: 257.01375589326574
total_envstep_count: 5043759
total_train_sample_count: 3845928
total_episode_count: 15713
total_duration: 1175.4990735209103
[2023-06-29 10:49:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2186
train_sample_count: 2186
avg_envstep_per_episode: 218.6
avg_sample_per_episode: 218.6
avg_envstep_per_sec: 2333.056818826247
avg_train_sample_per_sec: 2333.056818826247
avg_episode_per_sec: 10.672721037631504
collect_time: 0.9369681794118367
reward_mean: 1039.8331575178177
reward_std: 472.714856303405
reward_max: 1710.3634922589486
reward_min: 372.0678650106729
total_envstep_count: 5048127
total_train_sample_count: 3849314
total_episode_count: 15723
total_duration: 1176.4360417003222
[2023-06-29 10:49:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2120
train_sample_count: 2120
avg_envstep_per_episode: 235.55555555555554
avg_sample_per_episode: 235.55555555555554
avg_envstep_per_sec: 2284.663601065714
avg_train_sample_per_sec: 2284.663601065714
avg_episode_per_sec: 9.699043589429918
collect_time: 0.9279265442015603
reward_mean: 1597.9304201484774
reward_std: 719.4103892114084
reward_max: 2970.6023171325646
reward_min: 455.035784978319
total_envstep_count: 5053247
total_train_sample_count: 3852634
total_episode_count: 15732
total_duration: 1177.3639682445237
[2023-06-29 10:49:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 1934
train_sample_count: 1934
avg_envstep_per_episode: 161.16666666666666
avg_sample_per_episode: 161.16666666666666
avg_envstep_per_sec: 2318.5536308343267
avg_train_sample_per_sec: 2318.5536308343267
avg_episode_per_sec: 14.386061825238842
collect_time: 0.8341407221639527
reward_mean: 1384.8544553757854
reward_std: 735.0939909923762
reward_max: 3127.611711907894
reward_min: 250.6650283691046
total_envstep_count: 5057903
total_train_sample_count: 3856168
total_episode_count: 15744
total_duration: 1178.1981089666876
[2023-06-29 10:49:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2134
train_sample_count: 2134
avg_envstep_per_episode: 213.4
avg_sample_per_episode: 213.4
avg_envstep_per_sec: 2646.1618222459533
avg_train_sample_per_sec: 2646.1618222459533
avg_episode_per_sec: 12.400008539109434
collect_time: 0.8064510575504973
reward_mean: 1838.8924781793019
reward_std: 872.4577150513873
reward_max: 3465.5185516652514
reward_min: 616.3547102343795
total_envstep_count: 5062183
total_train_sample_count: 3859502
total_episode_count: 15754
total_duration: 1179.0045600242381
[2023-06-29 10:49:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 203.2
avg_sample_per_episode: 203.2
avg_envstep_per_sec: 2627.20554073197
avg_train_sample_per_sec: 2627.20554073197
avg_episode_per_sec: 12.929161125649458
collect_time: 0.7734453846476973
reward_mean: 1460.4010336218416
reward_std: 717.9323284653624
reward_max: 2905.477974546355
reward_min: 472.869242162541
total_envstep_count: 5066895
total_train_sample_count: 3862734
total_episode_count: 15764
total_duration: 1179.7780054088857
[2023-06-29 10:49:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1830
train_sample_count: 1830
avg_envstep_per_episode: 203.33333333333334
avg_sample_per_episode: 203.33333333333334
avg_envstep_per_sec: 2404.2165377150645
avg_train_sample_per_sec: 2404.2165377150645
avg_episode_per_sec: 11.824015759254415
collect_time: 0.7611627202844249
reward_mean: 1759.3448412864507
reward_std: 777.6481709945806
reward_max: 2935.8150499306175
reward_min: 755.3782257515414
total_envstep_count: 5071047
total_train_sample_count: 3866164
total_episode_count: 15773
total_duration: 1180.53916812917
[2023-06-29 10:49:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2867
train_sample_count: 2867
avg_envstep_per_episode: 238.91666666666666
avg_sample_per_episode: 238.91666666666666
avg_envstep_per_sec: 2425.204147584573
avg_train_sample_per_sec: 2425.204147584573
avg_episode_per_sec: 10.150837032094481
collect_time: 1.1821685208873824
reward_mean: 1538.4327918428478
reward_std: 606.080596947353
reward_max: 3264.9607375889213
reward_min: 1025.126917586174
total_envstep_count: 5075583
total_train_sample_count: 3869431
total_episode_count: 15785
total_duration: 1181.7213366500575
[2023-06-29 10:49:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2217
train_sample_count: 2217
avg_envstep_per_episode: 246.33333333333334
avg_sample_per_episode: 246.33333333333334
avg_envstep_per_sec: 2401.859660321214
avg_train_sample_per_sec: 2401.859660321214
avg_episode_per_sec: 9.750445170451478
collect_time: 0.9230347786862403
reward_mean: 1464.6739554379544
reward_std: 324.2709338375241
reward_max: 1902.2259272706378
reward_min: 908.4013530447139
total_envstep_count: 5080055
total_train_sample_count: 3872848
total_episode_count: 15794
total_duration: 1182.6443714287439
[2023-06-29 10:49:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2720
train_sample_count: 2720
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 2585.06865030487
avg_train_sample_per_sec: 2585.06865030487
avg_episode_per_sec: 9.503928861414964
collect_time: 1.0521964280055838
reward_mean: 1832.6727166877026
reward_std: 385.9666358675962
reward_max: 2581.566688898794
reward_min: 1380.3511631444517
total_envstep_count: 5085015
total_train_sample_count: 3876368
total_episode_count: 15804
total_duration: 1183.6965678567494
[2023-06-29 10:49:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1137
train_sample_count: 1137
avg_envstep_per_episode: 227.4
avg_sample_per_episode: 227.4
avg_envstep_per_sec: 2405.7710551460464
avg_train_sample_per_sec: 2405.7710551460464
avg_episode_per_sec: 10.579468140483932
collect_time: 0.47261355047393594
reward_mean: 1937.0988791783261
reward_std: 569.6765601907235
reward_max: 2868.38808712666
reward_min: 1290.3571331928188
total_envstep_count: 5089695
total_train_sample_count: 3879905
total_episode_count: 15809
total_duration: 1184.1691814072233
[2023-06-29 10:49:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 263.1818181818182
avg_sample_per_episode: 263.1818181818182
avg_envstep_per_sec: 2528.438134242727
avg_train_sample_per_sec: 2528.438134242727
avg_episode_per_sec: 9.607191529074264
collect_time: 1.1449756119372323
reward_mean: 2316.8212511230236
reward_std: 1022.526564483456
reward_max: 3674.3125740772725
reward_min: 960.59503393152
total_envstep_count: 5093943
total_train_sample_count: 3883200
total_episode_count: 15820
total_duration: 1185.3141570191606
[2023-06-29 10:49:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1372
train_sample_count: 1372
avg_envstep_per_episode: 274.4
avg_sample_per_episode: 274.4
avg_envstep_per_sec: 2682.8093071945673
avg_train_sample_per_sec: 2682.8093071945673
avg_episode_per_sec: 9.777001848376702
collect_time: 0.5114042195696384
reward_mean: 1644.8507139285528
reward_std: 222.33736695794548
reward_max: 1961.655674180727
reward_min: 1271.1938932344112
total_envstep_count: 5098543
total_train_sample_count: 3886572
total_episode_count: 15825
total_duration: 1185.8255612387302
[2023-06-29 10:49:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1839
train_sample_count: 1839
avg_envstep_per_episode: 306.5
avg_sample_per_episode: 306.5
avg_envstep_per_sec: 2661.2532214892653
avg_train_sample_per_sec: 2661.2532214892653
avg_episode_per_sec: 8.68271850404328
collect_time: 0.6910278154481204
reward_mean: 3050.147756844411
reward_std: 687.3924361521284
reward_max: 3665.982742910554
reward_min: 1687.6226642210947
total_envstep_count: 5103135
total_train_sample_count: 3890011
total_episode_count: 15831
total_duration: 1186.5165890541782
[2023-06-29 10:49:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2945
train_sample_count: 2945
avg_envstep_per_episode: 327.22222222222223
avg_sample_per_episode: 327.22222222222223
avg_envstep_per_sec: 2658.387184738748
avg_train_sample_per_sec: 2658.387184738748
avg_episode_per_sec: 8.124103450814511
collect_time: 1.1078145489515736
reward_mean: 2345.7188274293458
reward_std: 1078.8489749729727
reward_max: 3599.634134841793
reward_min: 468.6148514167517
total_envstep_count: 5107671
total_train_sample_count: 3893356
total_episode_count: 15840
total_duration: 1187.6244036031298
[2023-06-29 10:49:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1716
train_sample_count: 1716
avg_envstep_per_episode: 343.2
avg_sample_per_episode: 343.2
avg_envstep_per_sec: 2099.733116818582
avg_train_sample_per_sec: 2099.733116818582
avg_episode_per_sec: 6.11810348723363
collect_time: 0.8172467187639558
reward_mean: 2279.9205633536358
reward_std: 716.5222376049702
reward_max: 3522.4354445250115
reward_min: 1629.7108807318896
total_envstep_count: 5113255
total_train_sample_count: 3896672
total_episode_count: 15845
total_duration: 1188.4416503218938
[2023-06-29 10:49:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2667
train_sample_count: 2667
avg_envstep_per_episode: 266.7
avg_sample_per_episode: 266.7
avg_envstep_per_sec: 2594.8215663927344
avg_train_sample_per_sec: 2594.8215663927344
avg_episode_per_sec: 9.729364703384832
collect_time: 1.0278163379486653
reward_mean: 2429.8813335005825
reward_std: 928.1579749889881
reward_max: 3581.893940651631
reward_min: 1028.6416928426045
total_envstep_count: 5117623
total_train_sample_count: 3900139
total_episode_count: 15855
total_duration: 1189.4694666598425
[2023-06-29 10:50:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 662
train_sample_count: 662
avg_envstep_per_episode: 132.4
avg_sample_per_episode: 132.4
avg_envstep_per_sec: 2533.612222896419
avg_train_sample_per_sec: 2533.612222896419
avg_episode_per_sec: 19.136043979580204
collect_time: 0.2612870249114931
reward_mean: 1565.979223987223
reward_std: 188.15111486136885
reward_max: 1818.305471648343
reward_min: 1272.0453277757392
total_envstep_count: 5121647
total_train_sample_count: 3903601
total_episode_count: 15860
total_duration: 1189.730753684754
[2023-06-29 10:50:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1640
train_sample_count: 1640
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2512.5100297902995
avg_train_sample_per_sec: 2512.5100297902995
avg_episode_per_sec: 9.192109865086461
collect_time: 0.6527337127234786
reward_mean: 2566.255149240686
reward_std: 992.0332735366791
reward_max: 3551.318755728796
reward_min: 616.8160851834338
total_envstep_count: 5125647
total_train_sample_count: 3906841
total_episode_count: 15866
total_duration: 1190.3834873974774
[2023-06-29 10:50:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2272
train_sample_count: 2272
avg_envstep_per_episode: 252.44444444444446
avg_sample_per_episode: 252.44444444444446
avg_envstep_per_sec: 2395.438949294968
avg_train_sample_per_sec: 2395.438949294968
avg_episode_per_sec: 9.488974711115631
collect_time: 0.9484691733298822
reward_mean: 2130.7055003064243
reward_std: 1290.7557601627132
reward_max: 3575.076589421249
reward_min: 264.65381319458936
total_envstep_count: 5130383
total_train_sample_count: 3910313
total_episode_count: 15875
total_duration: 1191.3319565708073
[2023-06-29 10:50:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2465
train_sample_count: 2465
avg_envstep_per_episode: 308.125
avg_sample_per_episode: 308.125
avg_envstep_per_sec: 2603.854368328771
avg_train_sample_per_sec: 2603.854368328771
avg_episode_per_sec: 8.450642980377351
collect_time: 0.9466735275145621
reward_mean: 1936.4948266103233
reward_std: 1158.3551301332218
reward_max: 3514.574243605042
reward_min: 247.63384152363372
total_envstep_count: 5134799
total_train_sample_count: 3913578
total_episode_count: 15883
total_duration: 1192.2786300983219
[2023-06-29 10:50:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 145.5
avg_sample_per_episode: 145.5
avg_envstep_per_sec: 2694.9360414894336
avg_train_sample_per_sec: 2694.9360414894336
avg_episode_per_sec: 18.52189719236724
collect_time: 0.4319211966739968
reward_mean: 1511.723106739522
reward_std: 1086.1516641597652
reward_max: 3527.359281680411
reward_min: 263.3349691102863
total_envstep_count: 5139863
total_train_sample_count: 3917142
total_episode_count: 15891
total_duration: 1192.7105512949959
[2023-06-29 10:50:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2657
train_sample_count: 2657
avg_envstep_per_episode: 332.125
avg_sample_per_episode: 332.125
avg_envstep_per_sec: 2556.8276902024686
avg_train_sample_per_sec: 2556.8276902024686
avg_episode_per_sec: 7.698389733390948
collect_time: 1.0391783576896412
reward_mean: 2808.7489050223458
reward_std: 1048.4688819685744
reward_max: 3533.2633862723674
reward_min: 543.9573487845608
total_envstep_count: 5144631
total_train_sample_count: 3920599
total_episode_count: 15899
total_duration: 1193.7497296526856
[2023-06-29 10:50:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1870
train_sample_count: 1870
avg_envstep_per_episode: 267.14285714285717
avg_sample_per_episode: 267.14285714285717
avg_envstep_per_sec: 2502.5587985844763
avg_train_sample_per_sec: 2502.5587985844763
avg_episode_per_sec: 9.367867160476651
collect_time: 0.7472351902611555
reward_mean: 1916.9913678313017
reward_std: 893.27146307421
reward_max: 3534.5359918134145
reward_min: 765.5753644522009
total_envstep_count: 5149423
total_train_sample_count: 3924469
total_episode_count: 15906
total_duration: 1194.4969648429467
[2023-06-29 10:50:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1647
train_sample_count: 1647
avg_envstep_per_episode: 274.5
avg_sample_per_episode: 274.5
avg_envstep_per_sec: 2653.519584227485
avg_train_sample_per_sec: 2653.519584227485
avg_episode_per_sec: 9.666738011757689
collect_time: 0.6206850741896779
reward_mean: 2717.4737315146554
reward_std: 850.844726657281
reward_max: 3535.7167375781605
reward_min: 1632.0588659114933
total_envstep_count: 5153935
total_train_sample_count: 3927716
total_episode_count: 15912
total_duration: 1195.1176499171363
[2023-06-29 10:50:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1769
train_sample_count: 1769
avg_envstep_per_episode: 252.71428571428572
avg_sample_per_episode: 252.71428571428572
avg_envstep_per_sec: 2459.6074432554033
avg_train_sample_per_sec: 2459.6074432554033
avg_episode_per_sec: 9.73275980937695
collect_time: 0.7192204613182693
reward_mean: 2515.6904124735183
reward_std: 934.0558227388768
reward_max: 3659.937301756278
reward_min: 1372.8206468766941
total_envstep_count: 5157951
total_train_sample_count: 3931085
total_episode_count: 15919
total_duration: 1195.8368703784545
[2023-06-29 10:50:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2240
train_sample_count: 2240
avg_envstep_per_episode: 320.0
avg_sample_per_episode: 320.0
avg_envstep_per_sec: 2594.0188221764724
avg_train_sample_per_sec: 2594.0188221764724
avg_episode_per_sec: 8.106308819301477
collect_time: 0.8635249601313848
reward_mean: 2332.6562270864656
reward_std: 514.2203543913739
reward_max: 2927.2216358096775
reward_min: 1235.3506985968052
total_envstep_count: 5163031
total_train_sample_count: 3934525
total_episode_count: 15926
total_duration: 1196.7003953385858
[2023-06-29 10:50:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2719
train_sample_count: 2719
avg_envstep_per_episode: 302.1111111111111
avg_sample_per_episode: 302.1111111111111
avg_envstep_per_sec: 2599.228645341291
avg_train_sample_per_sec: 2599.228645341291
avg_episode_per_sec: 8.603551970603759
collect_time: 1.0460795762902122
reward_mean: 1939.000488568553
reward_std: 461.14994475843827
reward_max: 2533.8718995959216
reward_min: 1209.5167375466008
total_envstep_count: 5167919
total_train_sample_count: 3938044
total_episode_count: 15935
total_duration: 1197.746474914876
[2023-06-29 10:50:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2824
train_sample_count: 2824
avg_envstep_per_episode: 235.33333333333334
avg_sample_per_episode: 235.33333333333334
avg_envstep_per_sec: 2387.0640473662665
avg_train_sample_per_sec: 2387.0640473662665
avg_episode_per_sec: 10.143331646032294
collect_time: 1.1830432464163751
reward_mean: 1685.1720092861215
reward_std: 926.5757119011546
reward_max: 3633.9378517106447
reward_min: 654.1777886158542
total_envstep_count: 5172287
total_train_sample_count: 3941268
total_episode_count: 15947
total_duration: 1198.9295181612924
[2023-06-29 10:50:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2842
train_sample_count: 2842
avg_envstep_per_episode: 258.3636363636364
avg_sample_per_episode: 258.3636363636364
avg_envstep_per_sec: 2565.737256056901
avg_train_sample_per_sec: 2565.737256056901
avg_episode_per_sec: 9.930721258489061
collect_time: 1.1076738248590845
reward_mean: 1419.9840946616846
reward_std: 637.0203804199217
reward_max: 3225.9767221759016
reward_min: 801.8994428037178
total_envstep_count: 5176343
total_train_sample_count: 3944510
total_episode_count: 15958
total_duration: 1200.0371919861516
[2023-06-29 10:50:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3187
train_sample_count: 3187
avg_envstep_per_episode: 289.72727272727275
avg_sample_per_episode: 289.72727272727275
avg_envstep_per_sec: 2615.821741261388
avg_train_sample_per_sec: 2615.821741261388
avg_episode_per_sec: 9.028565784083863
collect_time: 1.2183551920717584
reward_mean: 1436.1818071352557
reward_std: 571.9039102339076
reward_max: 2260.6159347727885
reward_min: 112.80140864233731
total_envstep_count: 5181927
total_train_sample_count: 3948097
total_episode_count: 15969
total_duration: 1201.2555471782234
[2023-06-29 10:50:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3006
train_sample_count: 3006
avg_envstep_per_episode: 250.5
avg_sample_per_episode: 250.5
avg_envstep_per_sec: 2616.332741692575
avg_train_sample_per_sec: 2616.332741692575
avg_episode_per_sec: 10.444442082605091
collect_time: 1.1489364300258456
reward_mean: 1618.925119568709
reward_std: 508.65671959816217
reward_max: 2665.312420615216
reward_min: 990.8508729710054
total_envstep_count: 5186151
total_train_sample_count: 3951503
total_episode_count: 15981
total_duration: 1202.4044836082492
[2023-06-29 10:50:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2001
train_sample_count: 2001
avg_envstep_per_episode: 250.125
avg_sample_per_episode: 250.125
avg_envstep_per_sec: 2375.9712472576066
avg_train_sample_per_sec: 2375.9712472576066
avg_episode_per_sec: 9.499135421319767
collect_time: 0.8421819086866451
reward_mean: 1407.2882735505214
reward_std: 491.6230891309063
reward_max: 2208.4352308029647
reward_min: 356.5268823271867
total_envstep_count: 5190639
total_train_sample_count: 3954704
total_episode_count: 15989
total_duration: 1203.2466655169358
[2023-06-29 10:50:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2892
train_sample_count: 2892
avg_envstep_per_episode: 262.90909090909093
avg_sample_per_episode: 262.90909090909093
avg_envstep_per_sec: 2528.0743943419857
avg_train_sample_per_sec: 2528.0743943419857
avg_episode_per_sec: 9.615773975712946
collect_time: 1.143953677341342
reward_mean: 1789.3801845183118
reward_std: 736.9217430412488
reward_max: 3375.7796936953896
reward_min: 1089.9624678363755
total_envstep_count: 5195263
total_train_sample_count: 3957996
total_episode_count: 16000
total_duration: 1204.3906191942772
[2023-06-29 10:50:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2705
train_sample_count: 2705
avg_envstep_per_episode: 300.55555555555554
avg_sample_per_episode: 300.55555555555554
avg_envstep_per_sec: 2697.5738657206853
avg_train_sample_per_sec: 2697.5738657206853
avg_episode_per_sec: 8.975291974671412
collect_time: 1.0027528937663883
reward_mean: 1752.7010078757385
reward_std: 540.827927645194
reward_max: 3031.602418746178
reward_min: 1292.23743562575
total_envstep_count: 5200199
total_train_sample_count: 3961501
total_episode_count: 16009
total_duration: 1205.3933720880436
[2023-06-29 10:50:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3460
train_sample_count: 3460
avg_envstep_per_episode: 288.3333333333333
avg_sample_per_episode: 288.3333333333333
avg_envstep_per_sec: 2659.1185595179136
avg_train_sample_per_sec: 2659.1185595179136
avg_episode_per_sec: 9.222376506998543
collect_time: 1.3011830509081486
reward_mean: 1752.9843042586892
reward_std: 695.3393953834054
reward_max: 3460.3330572523273
reward_min: 962.9853871684364
total_envstep_count: 5204823
total_train_sample_count: 3964961
total_episode_count: 16021
total_duration: 1206.6945551389517
[2023-06-29 10:51:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3281
train_sample_count: 3281
avg_envstep_per_episode: 273.4166666666667
avg_sample_per_episode: 273.4166666666667
avg_envstep_per_sec: 2519.419800965165
avg_train_sample_per_sec: 2519.419800965165
avg_episode_per_sec: 9.214580192496793
collect_time: 1.3022839618641884
reward_mean: 1331.6777963054512
reward_std: 315.34983113444986
reward_max: 2148.32872901562
reward_min: 843.7344720842865
total_envstep_count: 5209263
total_train_sample_count: 3968242
total_episode_count: 16033
total_duration: 1207.9968391008158
[2023-06-29 10:51:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2505
train_sample_count: 2505
avg_envstep_per_episode: 278.3333333333333
avg_sample_per_episode: 278.3333333333333
avg_envstep_per_sec: 2394.449377027258
avg_train_sample_per_sec: 2394.449377027258
avg_episode_per_sec: 8.602812133032064
collect_time: 1.04616953861434
reward_mean: 1476.6744999255527
reward_std: 401.61663188281733
reward_max: 2435.270886908051
reward_min: 1017.2702396774732
total_envstep_count: 5213943
total_train_sample_count: 3971547
total_episode_count: 16042
total_duration: 1209.0430086394301
[2023-06-29 10:51:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2495
train_sample_count: 2495
avg_envstep_per_episode: 249.5
avg_sample_per_episode: 249.5
avg_envstep_per_sec: 2645.5926447641114
avg_train_sample_per_sec: 2645.5926447641114
avg_episode_per_sec: 10.603577734525496
collect_time: 0.9430779167525473
reward_mean: 1700.9143027848713
reward_std: 524.152753993472
reward_max: 2574.4615157497337
reward_min: 1114.4161994693018
total_envstep_count: 5218295
total_train_sample_count: 3974842
total_episode_count: 16052
total_duration: 1209.9860865561827
[2023-06-29 10:51:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2984
train_sample_count: 2984
avg_envstep_per_episode: 271.27272727272725
avg_sample_per_episode: 271.27272727272725
avg_envstep_per_sec: 2652.4090460173147
avg_train_sample_per_sec: 2652.4090460173147
avg_episode_per_sec: 9.77764728759734
collect_time: 1.1250150139853357
reward_mean: 1591.4425899440605
reward_std: 328.2971104993049
reward_max: 2305.0661017940656
reward_min: 1174.9010290269632
total_envstep_count: 5222911
total_train_sample_count: 3978226
total_episode_count: 16063
total_duration: 1211.111101570168
[2023-06-29 10:51:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1961
train_sample_count: 1961
avg_envstep_per_episode: 245.125
avg_sample_per_episode: 245.125
avg_envstep_per_sec: 2380.8780938955147
avg_train_sample_per_sec: 2380.8780938955147
avg_episode_per_sec: 9.712914202531422
collect_time: 0.8236456982102246
reward_mean: 1497.8762493049803
reward_std: 302.4842472653093
reward_max: 2149.3433329083846
reward_min: 1151.5744999393053
total_envstep_count: 5227455
total_train_sample_count: 3981787
total_episode_count: 16071
total_duration: 1211.9347472683783
[2023-06-29 10:51:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2566
train_sample_count: 2566
avg_envstep_per_episode: 256.6
avg_sample_per_episode: 256.6
avg_envstep_per_sec: 2415.143441603624
avg_train_sample_per_sec: 2415.143441603624
avg_episode_per_sec: 9.412094472344599
collect_time: 1.0624627737622943
reward_mean: 1960.688035848401
reward_std: 907.257945143257
reward_max: 3682.109019269291
reward_min: 1142.79116733246
total_envstep_count: 5231775
total_train_sample_count: 3985153
total_episode_count: 16081
total_duration: 1212.9972100421405
[2023-06-29 10:51:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2480
train_sample_count: 2480
avg_envstep_per_episode: 354.2857142857143
avg_sample_per_episode: 354.2857142857143
avg_envstep_per_sec: 2347.439840330934
avg_train_sample_per_sec: 2347.439840330934
avg_episode_per_sec: 6.625838258998605
collect_time: 1.0564700987823303
reward_mean: 2018.2326115710425
reward_std: 554.9338688959288
reward_max: 2979.9976881119323
reward_min: 1259.2655597149137
total_envstep_count: 5236263
total_train_sample_count: 3988433
total_episode_count: 16088
total_duration: 1214.0536801409228
[2023-06-29 10:51:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2108
train_sample_count: 2108
avg_envstep_per_episode: 234.22222222222223
avg_sample_per_episode: 234.22222222222223
avg_envstep_per_sec: 2367.3302109777082
avg_train_sample_per_sec: 2367.3302109777082
avg_episode_per_sec: 10.107197295445623
collect_time: 0.890454567860812
reward_mean: 1763.6808787855114
reward_std: 827.0582983588579
reward_max: 3608.654243176644
reward_min: 1165.4054944707011
total_envstep_count: 5240951
total_train_sample_count: 3991741
total_episode_count: 16097
total_duration: 1214.9441347087836
[2023-06-29 10:51:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2073
train_sample_count: 2073
avg_envstep_per_episode: 259.125
avg_sample_per_episode: 259.125
avg_envstep_per_sec: 2631.3403397824654
avg_train_sample_per_sec: 2631.3403397824654
avg_episode_per_sec: 10.154714287631318
collect_time: 0.7878114315578715
reward_mean: 2201.137100414511
reward_std: 716.1812882201259
reward_max: 3403.8529870809816
reward_min: 1348.3062845373565
total_envstep_count: 5245303
total_train_sample_count: 3995014
total_episode_count: 16105
total_duration: 1215.7319461403415
[2023-06-29 10:51:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2441.31962784369
avg_train_sample_per_sec: 2441.31962784369
avg_episode_per_sec: 9.611494597809802
collect_time: 0.8323367316694931
reward_mean: 1921.2693503343921
reward_std: 674.2942445977952
reward_max: 3177.4023629374196
reward_min: 1367.0610312603715
total_envstep_count: 5248935
total_train_sample_count: 3998246
total_episode_count: 16113
total_duration: 1216.564282872011
[2023-06-29 10:51:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2201
train_sample_count: 2201
avg_envstep_per_episode: 314.42857142857144
avg_sample_per_episode: 314.42857142857144
avg_envstep_per_sec: 2493.3411043726346
avg_train_sample_per_sec: 2493.3411043726346
avg_episode_per_sec: 7.929753625901155
collect_time: 0.8827512594005094
reward_mean: 1907.4943440426111
reward_std: 434.272575270365
reward_max: 2679.6567881972423
reward_min: 1393.0357168176743
total_envstep_count: 5252999
total_train_sample_count: 4001647
total_episode_count: 16120
total_duration: 1217.4470341314116
[2023-06-29 10:51:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 378.3333333333333
avg_sample_per_episode: 378.3333333333333
avg_envstep_per_sec: 2566.761962344884
avg_train_sample_per_sec: 2566.761962344884
avg_episode_per_sec: 6.7843928520129095
collect_time: 0.44219137444405343
reward_mean: 3517.8451726681874
reward_std: 84.25477569858931
reward_max: 3609.643386395416
reward_min: 3406.157641219416
total_envstep_count: 5257799
total_train_sample_count: 4005182
total_episode_count: 16123
total_duration: 1217.8892255058556
[2023-06-29 10:51:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2241
train_sample_count: 2241
avg_envstep_per_episode: 320.14285714285717
avg_sample_per_episode: 320.14285714285717
avg_envstep_per_sec: 2567.9124225942837
avg_train_sample_per_sec: 2567.9124225942837
avg_episode_per_sec: 8.021145452101734
collect_time: 0.8726933131683619
reward_mean: 3097.3268389378572
reward_std: 775.6449728165918
reward_max: 3633.4930762105296
reward_min: 1394.9647045017261
total_envstep_count: 5262887
total_train_sample_count: 4008623
total_episode_count: 16130
total_duration: 1218.761918819024
[2023-06-29 10:51:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1369
train_sample_count: 1369
avg_envstep_per_episode: 195.57142857142858
avg_sample_per_episode: 195.57142857142858
avg_envstep_per_sec: 2487.3190514337775
avg_train_sample_per_sec: 2487.3190514337775
avg_episode_per_sec: 12.718212826907555
collect_time: 0.5503917960226536
reward_mean: 2257.24634185938
reward_std: 876.7254701268982
reward_max: 3543.7675027838127
reward_min: 1470.57271826956
total_envstep_count: 5267367
total_train_sample_count: 4011992
total_episode_count: 16137
total_duration: 1219.3123106150467
[2023-06-29 10:51:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 351.42857142857144
avg_sample_per_episode: 351.42857142857144
avg_envstep_per_sec: 2364.5743621926845
avg_train_sample_per_sec: 2364.5743621926845
avg_episode_per_sec: 6.728463632255607
collect_time: 1.040356369980611
reward_mean: 2826.9588866116983
reward_std: 574.0792207288307
reward_max: 3619.7706030921927
reward_min: 2014.7740578012135
total_envstep_count: 5272167
total_train_sample_count: 4015252
total_episode_count: 16144
total_duration: 1220.3526669850273
[2023-06-29 10:51:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1834
train_sample_count: 1834
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 2245.4827378656796
avg_train_sample_per_sec: 2245.4827378656796
avg_episode_per_sec: 8.570544801014044
collect_time: 0.8167508790306748
reward_mean: 1877.9035864170044
reward_std: 824.073032460126
reward_max: 3203.869285284606
reward_min: 690.5049603687165
total_envstep_count: 5277119
total_train_sample_count: 4018686
total_episode_count: 16151
total_duration: 1221.169417864058
[2023-06-29 10:51:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2248
train_sample_count: 2248
avg_envstep_per_episode: 224.8
avg_sample_per_episode: 224.8
avg_envstep_per_sec: 2654.091518384741
avg_train_sample_per_sec: 2654.091518384741
avg_episode_per_sec: 11.806456932316463
collect_time: 0.8469941539047285
reward_mean: 1907.8305031482687
reward_std: 1281.2775174747085
reward_max: 3747.8841100908585
reward_min: 117.5461689360517
total_envstep_count: 5281663
total_train_sample_count: 4022134
total_episode_count: 16161
total_duration: 1222.0164120179627
[2023-06-29 10:51:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 172.71428571428572
avg_sample_per_episode: 172.71428571428572
avg_envstep_per_sec: 2451.122568372938
avg_train_sample_per_sec: 2451.122568372938
avg_episode_per_sec: 14.191776657246127
collect_time: 0.49324338798876854
reward_mean: 1894.69934202295
reward_std: 1265.9011290866572
reward_max: 3575.130315972147
reward_min: 254.49828145938505
total_envstep_count: 5285567
total_train_sample_count: 4025343
total_episode_count: 16168
total_duration: 1222.5096554059514
[2023-06-29 10:52:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 326.8888888888889
avg_sample_per_episode: 326.8888888888889
avg_envstep_per_sec: 2442.4161245710025
avg_train_sample_per_sec: 2442.4161245710025
avg_episode_per_sec: 7.471701264833114
collect_time: 1.2045449464581908
reward_mean: 2493.1012469866187
reward_std: 871.5138123078849
reward_max: 3699.1025393329496
reward_min: 1233.744781270577
total_envstep_count: 5289951
total_train_sample_count: 4028685
total_episode_count: 16177
total_duration: 1223.7142003524095
[2023-06-29 10:52:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3107
train_sample_count: 3107
avg_envstep_per_episode: 310.7
avg_sample_per_episode: 310.7
avg_envstep_per_sec: 2335.2460301148594
avg_train_sample_per_sec: 2335.2460301148594
avg_episode_per_sec: 7.516079916687671
collect_time: 1.3304807972833517
reward_mean: 1592.3226132875438
reward_std: 308.5140007136566
reward_max: 2162.9363711951128
reward_min: 1217.8205545173207
total_envstep_count: 5294687
total_train_sample_count: 4032192
total_episode_count: 16187
total_duration: 1225.044681149693
[2023-06-29 10:52:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2976
train_sample_count: 2976
avg_envstep_per_episode: 270.54545454545456
avg_sample_per_episode: 270.54545454545456
avg_envstep_per_sec: 2283.566143051621
avg_train_sample_per_sec: 2283.566143051621
avg_episode_per_sec: 8.440600663161234
collect_time: 1.3032247868340927
reward_mean: 1522.434827406131
reward_std: 812.4723163995185
reward_max: 3623.1023643792823
reward_min: 333.8588445967047
total_envstep_count: 5299055
total_train_sample_count: 4035568
total_episode_count: 16198
total_duration: 1226.347905936527
[2023-06-29 10:52:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3247
train_sample_count: 3247
avg_envstep_per_episode: 360.77777777777777
avg_sample_per_episode: 360.77777777777777
avg_envstep_per_sec: 2454.3285499358276
avg_train_sample_per_sec: 2454.3285499358276
avg_episode_per_sec: 6.802881721411287
collect_time: 1.322968760675867
reward_mean: 1843.095905105583
reward_std: 451.642241068703
reward_max: 2593.6480086482757
reward_min: 1345.7191127662754
total_envstep_count: 5303831
total_train_sample_count: 4038815
total_episode_count: 16207
total_duration: 1227.6708746972029
[2023-06-29 10:52:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 268.5833333333333
avg_sample_per_episode: 268.5833333333333
avg_envstep_per_sec: 2418.5469890786235
avg_train_sample_per_sec: 2418.5469890786235
avg_episode_per_sec: 9.004829000603003
collect_time: 1.3326183094866573
reward_mean: 1369.7240191578242
reward_std: 578.6277626975846
reward_max: 2677.0964957656465
reward_min: 274.03280243999734
total_envstep_count: 5308215
total_train_sample_count: 4042038
total_episode_count: 16219
total_duration: 1229.0034930066895
[2023-06-29 10:52:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 404
train_sample_count: 404
avg_envstep_per_episode: 202.0
avg_sample_per_episode: 202.0
avg_envstep_per_sec: 2157.37030966999
avg_train_sample_per_sec: 2157.37030966999
avg_episode_per_sec: 10.680051037970246
collect_time: 0.18726502269413328
reward_mean: 1425.8664874082847
reward_std: 137.04407583021225
reward_max: 1562.910563238497
reward_min: 1288.8224115780724
total_envstep_count: 5311647
total_train_sample_count: 4045242
total_episode_count: 16221
total_duration: 1229.1907580293837
[2023-06-29 10:52:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2941
train_sample_count: 2941
avg_envstep_per_episode: 267.3636363636364
avg_sample_per_episode: 267.3636363636364
avg_envstep_per_sec: 2674.4827996704576
avg_train_sample_per_sec: 2674.4827996704576
avg_episode_per_sec: 10.003165860719154
collect_time: 1.0996518655354157
reward_mean: 2182.7044447507265
reward_std: 890.1562059362445
reward_max: 3520.9984649962257
reward_min: 409.7459172469916
total_envstep_count: 5316359
total_train_sample_count: 4048583
total_episode_count: 16232
total_duration: 1230.290409894919
[2023-06-29 10:52:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1753
train_sample_count: 1753
avg_envstep_per_episode: 292.1666666666667
avg_sample_per_episode: 292.1666666666667
avg_envstep_per_sec: 2377.114995422798
avg_train_sample_per_sec: 2377.114995422798
avg_episode_per_sec: 8.13616085141859
collect_time: 0.7374485472412782
reward_mean: 1737.8904514541416
reward_std: 638.8756543165593
reward_max: 2414.9273404141463
reward_min: 624.8041711848891
total_envstep_count: 5321095
total_train_sample_count: 4051936
total_episode_count: 16238
total_duration: 1231.0278584421603
[2023-06-29 10:52:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1238
train_sample_count: 1238
avg_envstep_per_episode: 247.6
avg_sample_per_episode: 247.6
avg_envstep_per_sec: 2214.996188485397
avg_train_sample_per_sec: 2214.996188485397
avg_episode_per_sec: 8.945865058503218
collect_time: 0.5589174403259529
reward_mean: 3104.3829611401006
reward_std: 439.7445543015871
reward_max: 3533.330934852042
reward_min: 2559.865289312024
total_envstep_count: 5325527
total_train_sample_count: 4055174
total_episode_count: 16243
total_duration: 1231.5867758824863
[2023-06-29 10:52:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2362
train_sample_count: 2362
avg_envstep_per_episode: 236.2
avg_sample_per_episode: 236.2
avg_envstep_per_sec: 2486.737283336858
avg_train_sample_per_sec: 2486.737283336858
avg_episode_per_sec: 10.528100268149274
collect_time: 0.9498389780968426
reward_mean: 2203.2784189339854
reward_std: 754.549496021322
reward_max: 3556.1601157693626
reward_min: 1278.177779531599
total_envstep_count: 5330015
total_train_sample_count: 4058736
total_episode_count: 16253
total_duration: 1232.536614860583
[2023-06-29 10:52:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2150
train_sample_count: 2150
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 2672.679224590714
avg_train_sample_per_sec: 2672.679224590714
avg_episode_per_sec: 12.431066160887044
collect_time: 0.8044362302136143
reward_mean: 1380.1366079054835
reward_std: 336.2540218292237
reward_max: 1954.9985434184418
reward_min: 779.9859024818135
total_envstep_count: 5334167
total_train_sample_count: 4062086
total_episode_count: 16263
total_duration: 1233.3410510907968
[2023-06-29 10:52:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2529
train_sample_count: 2529
avg_envstep_per_episode: 229.9090909090909
avg_sample_per_episode: 229.9090909090909
avg_envstep_per_sec: 2675.984583206194
avg_train_sample_per_sec: 2675.984583206194
avg_episode_per_sec: 11.639316099354739
collect_time: 0.945072709264234
reward_mean: 1572.9156748106843
reward_std: 836.9172174053735
reward_max: 3592.9638372024738
reward_min: 260.9904741925932
total_envstep_count: 5339175
total_train_sample_count: 4065415
total_episode_count: 16274
total_duration: 1234.286123800061
[2023-06-29 10:52:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2105
train_sample_count: 2105
avg_envstep_per_episode: 263.125
avg_sample_per_episode: 263.125
avg_envstep_per_sec: 2364.6568724238923
avg_train_sample_per_sec: 2364.6568724238923
avg_episode_per_sec: 8.986819467644247
collect_time: 0.8901925791213289
reward_mean: 2027.2064308395738
reward_std: 737.2343273032488
reward_max: 3664.320451969058
reward_min: 1225.7460287668962
total_envstep_count: 5344007
total_train_sample_count: 4068720
total_episode_count: 16282
total_duration: 1235.1763163791823
[2023-06-29 10:52:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1629
train_sample_count: 1629
avg_envstep_per_episode: 203.625
avg_sample_per_episode: 203.625
avg_envstep_per_sec: 2550.281486362764
avg_train_sample_per_sec: 2550.281486362764
avg_episode_per_sec: 12.524402634071278
collect_time: 0.6387530195042491
reward_mean: 1548.677036995788
reward_std: 1011.3463257620573
reward_max: 3251.430026553289
reward_min: 111.59494297403907
total_envstep_count: 5348239
total_train_sample_count: 4071949
total_episode_count: 16290
total_duration: 1235.8150693986865
[2023-06-29 10:52:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1493
train_sample_count: 1493
avg_envstep_per_episode: 213.28571428571428
avg_sample_per_episode: 213.28571428571428
avg_envstep_per_sec: 2607.1720656303264
avg_train_sample_per_sec: 2607.1720656303264
avg_episode_per_sec: 12.223847595051765
collect_time: 0.5726511186897988
reward_mean: 2616.3744743283096
reward_std: 985.4565703956417
reward_max: 3630.786861242754
reward_min: 920.7657152735292
total_envstep_count: 5353103
total_train_sample_count: 4075442
total_episode_count: 16297
total_duration: 1236.3877205173762
[2023-06-29 10:52:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2540
train_sample_count: 2540
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2522.328155782891
avg_train_sample_per_sec: 2522.328155782891
avg_episode_per_sec: 9.930425810168861
collect_time: 1.0070061638001357
reward_mean: 2074.5082469069575
reward_std: 765.7242664905764
reward_max: 3532.2501365073217
reward_min: 453.45234295778715
total_envstep_count: 5357599
total_train_sample_count: 4078782
total_episode_count: 16307
total_duration: 1237.3947266811763
[2023-06-29 10:52:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2283
train_sample_count: 2283
avg_envstep_per_episode: 285.375
avg_sample_per_episode: 285.375
avg_envstep_per_sec: 2323.3521762662863
avg_train_sample_per_sec: 2323.3521762662863
avg_episode_per_sec: 8.14140053006145
collect_time: 0.9826319157816472
reward_mean: 1957.19779754996
reward_std: 1059.3437150593013
reward_max: 3589.0046115722957
reward_min: 442.3930285347831
total_envstep_count: 5362463
total_train_sample_count: 4082265
total_episode_count: 16315
total_duration: 1238.377358596958
[2023-06-29 10:52:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2706
train_sample_count: 2706
avg_envstep_per_episode: 193.28571428571428
avg_sample_per_episode: 193.28571428571428
avg_envstep_per_sec: 2141.737056431839
avg_train_sample_per_sec: 2141.737056431839
avg_episode_per_sec: 11.080679523298501
collect_time: 1.2634604196036232
reward_mean: 1304.0492435567962
reward_std: 874.8827201173444
reward_max: 3011.6537035070733
reward_min: 254.04950575196966
total_envstep_count: 5367247
total_train_sample_count: 4085771
total_episode_count: 16329
total_duration: 1239.6408190165616
[2023-06-29 10:52:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1822
train_sample_count: 1822
avg_envstep_per_episode: 227.75
avg_sample_per_episode: 227.75
avg_envstep_per_sec: 2249.788297845562
avg_train_sample_per_sec: 2249.788297845562
avg_episode_per_sec: 9.878324030057351
collect_time: 0.8098539768140763
reward_mean: 1433.5452135223545
reward_std: 709.8913193939483
reward_max: 2360.5613988064306
reward_min: 116.30342726573105
total_envstep_count: 5371503
total_train_sample_count: 4089193
total_episode_count: 16337
total_duration: 1240.4506729933757
[2023-06-29 10:53:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1883
train_sample_count: 1883
avg_envstep_per_episode: 209.22222222222223
avg_sample_per_episode: 209.22222222222223
avg_envstep_per_sec: 2494.0331729877275
avg_train_sample_per_sec: 2494.0331729877275
avg_episode_per_sec: 11.92049843700985
collect_time: 0.7550019864989445
reward_mean: 1986.0778620580932
reward_std: 962.2324311290455
reward_max: 3651.4841006030433
reward_min: 968.3096820342379
total_envstep_count: 5376567
total_train_sample_count: 4092676
total_episode_count: 16346
total_duration: 1241.2056749798746
[2023-06-29 10:53:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2226
train_sample_count: 2226
avg_envstep_per_episode: 222.6
avg_sample_per_episode: 222.6
avg_envstep_per_sec: 2675.619751813358
avg_train_sample_per_sec: 2675.619751813358
avg_episode_per_sec: 12.019855129440064
collect_time: 0.831956782532856
reward_mean: 1952.2547198076495
reward_std: 648.0387699788716
reward_max: 3547.666787055299
reward_min: 1252.2981368965445
total_envstep_count: 5380927
total_train_sample_count: 4096102
total_episode_count: 16356
total_duration: 1242.0376317624075
[2023-06-29 10:53:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2092
train_sample_count: 2092
avg_envstep_per_episode: 232.44444444444446
avg_sample_per_episode: 232.44444444444446
avg_envstep_per_sec: 2642.7614548291303
avg_train_sample_per_sec: 2642.7614548291303
avg_episode_per_sec: 11.369432645058401
collect_time: 0.7915962283229455
reward_mean: 1529.9347590129555
reward_std: 479.0319759978576
reward_max: 2175.9254673257724
reward_min: 744.163505177936
total_envstep_count: 5385087
total_train_sample_count: 4099394
total_episode_count: 16365
total_duration: 1242.8292279907305
[2023-06-29 10:53:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2423
train_sample_count: 2423
avg_envstep_per_episode: 242.3
avg_sample_per_episode: 242.3
avg_envstep_per_sec: 2498.2964986306006
avg_train_sample_per_sec: 2498.2964986306006
avg_episode_per_sec: 10.310757319977716
collect_time: 0.9698608637237921
reward_mean: 1728.4237492907894
reward_std: 1208.3263284323361
reward_max: 3700.200079921099
reward_min: 105.08858417347322
total_envstep_count: 5389247
total_train_sample_count: 4102617
total_episode_count: 16375
total_duration: 1243.7990888544543
[2023-06-29 10:53:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2583
train_sample_count: 2583
avg_envstep_per_episode: 215.25
avg_sample_per_episode: 215.25
avg_envstep_per_sec: 2389.3052242931394
avg_train_sample_per_sec: 2389.3052242931394
avg_episode_per_sec: 11.100140414834563
collect_time: 1.0810674055945129
reward_mean: 1299.3954005272085
reward_std: 613.7121088532969
reward_max: 2230.8224200067557
reward_min: 105.1864504669301
total_envstep_count: 5393431
total_train_sample_count: 4106000
total_episode_count: 16387
total_duration: 1244.8801562600488
[2023-06-29 10:53:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2855
train_sample_count: 2855
avg_envstep_per_episode: 317.22222222222223
avg_sample_per_episode: 317.22222222222223
avg_envstep_per_sec: 2666.2222088482335
avg_train_sample_per_sec: 2666.2222088482335
avg_episode_per_sec: 8.404903635598636
collect_time: 1.0708034726157785
reward_mean: 1797.0492664791018
reward_std: 437.1684384273353
reward_max: 2467.784191569007
reward_min: 1199.3298997148133
total_envstep_count: 5398095
total_train_sample_count: 4109255
total_episode_count: 16396
total_duration: 1245.9509597326646
[2023-06-29 10:53:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2478
train_sample_count: 2478
avg_envstep_per_episode: 275.3333333333333
avg_sample_per_episode: 275.3333333333333
avg_envstep_per_sec: 2477.623709325211
avg_train_sample_per_sec: 2477.623709325211
avg_episode_per_sec: 8.998633326847015
collect_time: 1.0001518756352599
reward_mean: 1565.644183755477
reward_std: 340.62417279762985
reward_max: 2327.64513418155
reward_min: 1181.4216846176266
total_envstep_count: 5402543
total_train_sample_count: 4112533
total_episode_count: 16405
total_duration: 1246.9511116083
[2023-06-29 10:53:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3115
train_sample_count: 3115
avg_envstep_per_episode: 239.6153846153846
avg_sample_per_episode: 239.6153846153846
avg_envstep_per_sec: 2586.158931298095
avg_train_sample_per_sec: 2586.158931298095
avg_episode_per_sec: 10.792958621789802
collect_time: 1.2044890057999873
reward_mean: 1506.574317684161
reward_std: 728.7575318583588
reward_max: 3648.8211676293427
reward_min: 114.3176864628872
total_envstep_count: 5407127
total_train_sample_count: 4116048
total_episode_count: 16418
total_duration: 1248.1556006141
[2023-06-29 10:53:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2865
train_sample_count: 2865
avg_envstep_per_episode: 286.5
avg_sample_per_episode: 286.5
avg_envstep_per_sec: 2533.5723623941535
avg_train_sample_per_sec: 2533.5723623941535
avg_episode_per_sec: 8.843184510974357
collect_time: 1.1308143562525512
reward_mean: 1563.5818312842446
reward_std: 560.9448327089384
reward_max: 2452.8821775902707
reward_min: 340.1615825700149
total_envstep_count: 5411855
total_train_sample_count: 4119313
total_episode_count: 16428
total_duration: 1249.2864149703526
[2023-06-29 10:53:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 2667.597726185387
avg_train_sample_per_sec: 2667.597726185387
avg_episode_per_sec: 10.713243880262597
collect_time: 0.46671204873919503
reward_mean: 1900.3588661087338
reward_std: 539.2052046540567
reward_max: 2704.3633973722303
reward_min: 1354.2931553679712
total_envstep_count: 5416279
total_train_sample_count: 4122558
total_episode_count: 16433
total_duration: 1249.7531270190918
[2023-06-29 10:53:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2706
train_sample_count: 2706
avg_envstep_per_episode: 246.0
avg_sample_per_episode: 246.0
avg_envstep_per_sec: 2713.4409868149423
avg_train_sample_per_sec: 2713.4409868149423
avg_episode_per_sec: 11.03024791388188
collect_time: 0.9972577303685249
reward_mean: 2090.214242005321
reward_std: 972.4516092043106
reward_max: 3679.063936837712
reward_min: 649.3834897892172
total_envstep_count: 5420711
total_train_sample_count: 4126064
total_episode_count: 16444
total_duration: 1250.7503847494604
[2023-06-29 10:53:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2188
train_sample_count: 2188
avg_envstep_per_episode: 243.11111111111111
avg_sample_per_episode: 243.11111111111111
avg_envstep_per_sec: 2567.484149389103
avg_train_sample_per_sec: 2567.484149389103
avg_episode_per_sec: 10.56094942618918
collect_time: 0.8521961082099003
reward_mean: 1495.6262940663814
reward_std: 479.74698733491186
reward_max: 2165.1141997975105
reward_min: 484.9218119918681
total_envstep_count: 5425207
total_train_sample_count: 4129452
total_episode_count: 16453
total_duration: 1251.6025808576703
[2023-06-29 10:53:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 247.6
avg_sample_per_episode: 247.6
avg_envstep_per_sec: 2537.338891787425
avg_train_sample_per_sec: 2537.338891787425
avg_episode_per_sec: 10.247733811742428
collect_time: 0.975825502858148
reward_mean: 1775.6863510374303
reward_std: 655.5187978555167
reward_max: 3611.8519379685285
reward_min: 1096.4107316310772
total_envstep_count: 5429303
total_train_sample_count: 4132728
total_episode_count: 16463
total_duration: 1252.5784063605286
[2023-06-29 10:53:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2330
train_sample_count: 2330
avg_envstep_per_episode: 233.0
avg_sample_per_episode: 233.0
avg_envstep_per_sec: 2709.105410393934
avg_train_sample_per_sec: 2709.105410393934
avg_episode_per_sec: 11.627061847184267
collect_time: 0.8600625103255735
reward_mean: 1413.894793635019
reward_std: 632.057793431808
reward_max: 2347.4496027127248
reward_min: 111.22531239219516
total_envstep_count: 5434207
total_train_sample_count: 4136258
total_episode_count: 16473
total_duration: 1253.4384688708542
[2023-06-29 10:53:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1514
train_sample_count: 1514
avg_envstep_per_episode: 189.25
avg_sample_per_episode: 189.25
avg_envstep_per_sec: 2704.5327703631874
avg_train_sample_per_sec: 2704.5327703631874
avg_episode_per_sec: 14.290794030981175
collect_time: 0.5598009447660297
reward_mean: 1868.7760993688794
reward_std: 643.1278617492044
reward_max: 3060.982342078738
reward_min: 781.7932441665514
total_envstep_count: 5438711
total_train_sample_count: 4139772
total_episode_count: 16481
total_duration: 1253.9982698156202
[2023-06-29 10:53:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3010
train_sample_count: 3010
avg_envstep_per_episode: 250.83333333333334
avg_sample_per_episode: 250.83333333333334
avg_envstep_per_sec: 2654.266481800273
avg_train_sample_per_sec: 2654.266481800273
avg_episode_per_sec: 10.581793282924677
collect_time: 1.1340232869001339
reward_mean: 1799.6659698529186
reward_std: 590.8665758431387
reward_max: 3173.162762498872
reward_min: 775.3110870514041
total_envstep_count: 5442671
total_train_sample_count: 4143182
total_episode_count: 16493
total_duration: 1255.1322931025204
[2023-06-29 10:53:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2570
train_sample_count: 2570
avg_envstep_per_episode: 321.25
avg_sample_per_episode: 321.25
avg_envstep_per_sec: 2492.8562906806696
avg_train_sample_per_sec: 2492.8562906806696
avg_episode_per_sec: 7.759863939862006
collect_time: 1.030945911165327
reward_mean: 1591.2011627565057
reward_std: 332.88966109512074
reward_max: 2143.586268338481
reward_min: 1155.6507981330788
total_envstep_count: 5447183
total_train_sample_count: 4146552
total_episode_count: 16501
total_duration: 1256.1632390136858
[2023-06-29 10:53:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1682
train_sample_count: 1682
avg_envstep_per_episode: 280.3333333333333
avg_sample_per_episode: 280.3333333333333
avg_envstep_per_sec: 2367.9402612355566
avg_train_sample_per_sec: 2367.9402612355566
avg_episode_per_sec: 8.446873702386052
collect_time: 0.7103219737149775
reward_mean: 1870.40007995062
reward_std: 709.9983752881003
reward_max: 2719.4859598932085
reward_min: 692.3851585503064
total_envstep_count: 5451671
total_train_sample_count: 4149834
total_episode_count: 16507
total_duration: 1256.8735609874009
[2023-06-29 10:53:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2327
train_sample_count: 2327
avg_envstep_per_episode: 232.7
avg_sample_per_episode: 232.7
avg_envstep_per_sec: 2660.94431914015
avg_train_sample_per_sec: 2660.94431914015
avg_episode_per_sec: 11.435085170348733
collect_time: 0.8745015757232906
reward_mean: 2020.164506121328
reward_std: 1219.8819130454042
reward_max: 3640.776196083086
reward_min: 108.05778935795416
total_envstep_count: 5456431
total_train_sample_count: 4153361
total_episode_count: 16517
total_duration: 1257.7480625631242
[2023-06-29 10:54:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 913
train_sample_count: 913
avg_envstep_per_episode: 152.16666666666666
avg_sample_per_episode: 152.16666666666666
avg_envstep_per_sec: 2671.7155468253973
avg_train_sample_per_sec: 2671.7155468253973
avg_episode_per_sec: 17.55782396599385
collect_time: 0.34172799611277876
reward_mean: 1878.0950901111294
reward_std: 462.24154773458116
reward_max: 2680.858733276528
reward_min: 1365.973451158324
total_envstep_count: 5460671
total_train_sample_count: 4156674
total_episode_count: 16523
total_duration: 1258.089790559237
[2023-06-29 10:54:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1845
train_sample_count: 1845
avg_envstep_per_episode: 263.57142857142856
avg_sample_per_episode: 263.57142857142856
avg_envstep_per_sec: 2672.7298807355314
avg_train_sample_per_sec: 2672.7298807355314
avg_episode_per_sec: 10.140438571896325
collect_time: 0.690305448858999
reward_mean: 2585.8794826155367
reward_std: 892.7695954923163
reward_max: 3610.8918455500575
reward_min: 1225.1136766072384
total_envstep_count: 5465391
total_train_sample_count: 4160119
total_episode_count: 16530
total_duration: 1258.7800960080958
[2023-06-29 10:54:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2815
train_sample_count: 2815
avg_envstep_per_episode: 234.58333333333334
avg_sample_per_episode: 234.58333333333334
avg_envstep_per_sec: 2542.9645295643577
avg_train_sample_per_sec: 2542.9645295643577
avg_episode_per_sec: 10.840346129581631
collect_time: 1.106975723519921
reward_mean: 1789.9928080827212
reward_std: 1028.3430804676266
reward_max: 3595.881724868564
reward_min: 401.9887949853045
total_envstep_count: 5469711
total_train_sample_count: 4163334
total_episode_count: 16542
total_duration: 1259.8870717316158
[2023-06-29 10:54:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1526
train_sample_count: 1526
avg_envstep_per_episode: 305.2
avg_sample_per_episode: 305.2
avg_envstep_per_sec: 2674.912514473445
avg_train_sample_per_sec: 2674.912514473445
avg_episode_per_sec: 8.764457780057159
collect_time: 0.5704859473882241
reward_mean: 1987.8135040729462
reward_std: 872.324526560086
reward_max: 3602.6770683663217
reward_min: 1250.4751527962326
total_envstep_count: 5474935
total_train_sample_count: 4166860
total_episode_count: 16547
total_duration: 1260.4575576790041
[2023-06-29 10:54:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3034
train_sample_count: 3034
avg_envstep_per_episode: 275.8181818181818
avg_sample_per_episode: 275.8181818181818
avg_envstep_per_sec: 2647.780966791639
avg_train_sample_per_sec: 2647.780966791639
avg_episode_per_sec: 9.599733234907063
collect_time: 1.1458651746697723
reward_mean: 2246.4241983422685
reward_std: 1043.8826905096307
reward_max: 3631.1595948198824
reward_min: 1007.3268684657054
total_envstep_count: 5479815
total_train_sample_count: 4170294
total_episode_count: 16558
total_duration: 1261.603422853674
[2023-06-29 10:54:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2157
train_sample_count: 2157
avg_envstep_per_episode: 239.66666666666666
avg_sample_per_episode: 239.66666666666666
avg_envstep_per_sec: 2599.1395693228405
avg_train_sample_per_sec: 2599.1395693228405
avg_episode_per_sec: 10.844810442237165
collect_time: 0.8298900241674855
reward_mean: 1451.001590984305
reward_std: 782.9756766185418
reward_max: 2771.1054375715944
reward_min: 476.85497476835104
total_envstep_count: 5484207
total_train_sample_count: 4173651
total_episode_count: 16567
total_duration: 1262.4333128778414
[2023-06-29 10:54:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 244.14285714285714
avg_sample_per_episode: 244.14285714285714
avg_envstep_per_sec: 2681.4997827721386
avg_train_sample_per_sec: 2681.4997827721386
avg_episode_per_sec: 10.983322691284359
collect_time: 0.6373299043243752
reward_mean: 1889.5906864240928
reward_std: 1282.8244254118224
reward_max: 3607.4907773326177
reward_min: 270.7091243700215
total_envstep_count: 5488583
total_train_sample_count: 4176960
total_episode_count: 16574
total_duration: 1263.0706427821658
[2023-06-29 10:54:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 264.25
avg_sample_per_episode: 264.25
avg_envstep_per_sec: 2477.3482462491647
avg_train_sample_per_sec: 2477.3482462491647
avg_episode_per_sec: 9.37501701513402
collect_time: 0.8533317845808344
reward_mean: 2154.1278314693936
reward_std: 1249.2594285071232
reward_max: 3567.9875063576283
reward_min: 245.5128271249985
total_envstep_count: 5492999
total_train_sample_count: 4180274
total_episode_count: 16582
total_duration: 1263.9239745667467
[2023-06-29 10:54:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1620
train_sample_count: 1620
avg_envstep_per_episode: 324.0
avg_sample_per_episode: 324.0
avg_envstep_per_sec: 2338.7984314388623
avg_train_sample_per_sec: 2338.7984314388623
avg_episode_per_sec: 7.218513677280439
collect_time: 0.6926633686013518
reward_mean: 2625.125034068007
reward_std: 613.2340531664669
reward_max: 3541.8884029053283
reward_min: 1610.0372557656824
total_envstep_count: 5497815
total_train_sample_count: 4183494
total_episode_count: 16587
total_duration: 1264.616637935348
[2023-06-29 10:54:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2071
train_sample_count: 2071
avg_envstep_per_episode: 258.875
avg_sample_per_episode: 258.875
avg_envstep_per_sec: 2423.7411287593354
avg_train_sample_per_sec: 2423.7411287593354
avg_episode_per_sec: 9.362592481928868
collect_time: 0.8544641898535192
reward_mean: 2267.157776012012
reward_std: 823.0932070063449
reward_max: 3597.539316339263
reward_min: 1345.0161707080554
total_envstep_count: 5501959
total_train_sample_count: 4186765
total_episode_count: 16595
total_duration: 1265.4711021252017
[2023-06-29 10:54:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1872
train_sample_count: 1872
avg_envstep_per_episode: 208.0
avg_sample_per_episode: 208.0
avg_envstep_per_sec: 2613.9030942629593
avg_train_sample_per_sec: 2613.9030942629593
avg_episode_per_sec: 12.56684179934115
collect_time: 0.7161703905966135
reward_mean: 1784.8335950278097
reward_std: 1327.9196626886107
reward_max: 3553.534554188765
reward_min: 111.5208094704459
total_envstep_count: 5506223
total_train_sample_count: 4190237
total_episode_count: 16604
total_duration: 1266.1872725157982
[2023-06-29 10:54:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2383
train_sample_count: 2383
avg_envstep_per_episode: 238.3
avg_sample_per_episode: 238.3
avg_envstep_per_sec: 2423.243385531742
avg_train_sample_per_sec: 2423.243385531742
avg_episode_per_sec: 10.168876985026195
collect_time: 0.9833927595667773
reward_mean: 1544.468871835188
reward_std: 1023.7020529470249
reward_max: 3576.5055009467105
reward_min: 248.1501871130706
total_envstep_count: 5511023
total_train_sample_count: 4193820
total_episode_count: 16614
total_duration: 1267.170665275365
[2023-06-29 10:54:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1526
train_sample_count: 1526
avg_envstep_per_episode: 152.6
avg_sample_per_episode: 152.6
avg_envstep_per_sec: 2648.3390481564716
avg_train_sample_per_sec: 2648.3390481564716
avg_episode_per_sec: 17.35477751085499
collect_time: 0.5762102103438228
reward_mean: 1307.5865155356228
reward_std: 1045.696739374246
reward_max: 3590.2847805802394
reward_min: 246.94688635525748
total_envstep_count: 5515311
total_train_sample_count: 4197346
total_episode_count: 16624
total_duration: 1267.7468754857089
[2023-06-29 10:54:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2108
train_sample_count: 2108
avg_envstep_per_episode: 301.14285714285717
avg_sample_per_episode: 301.14285714285717
avg_envstep_per_sec: 2577.3402697796455
avg_train_sample_per_sec: 2577.3402697796455
avg_episode_per_sec: 8.558530307617419
collect_time: 0.8178974366392946
reward_mean: 2561.558621235468
reward_std: 833.0712840654943
reward_max: 3576.6451768465736
reward_min: 1471.923834601263
total_envstep_count: 5519935
total_train_sample_count: 4200654
total_episode_count: 16631
total_duration: 1268.564772922348
[2023-06-29 10:54:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2090
train_sample_count: 2090
avg_envstep_per_episode: 232.22222222222223
avg_sample_per_episode: 232.22222222222223
avg_envstep_per_sec: 2637.4223876530446
avg_train_sample_per_sec: 2637.4223876530446
avg_episode_per_sec: 11.357321286544211
collect_time: 0.7924403803441671
reward_mean: 1917.8915996075893
reward_std: 1210.5671366772954
reward_max: 3577.361146574369
reward_min: 410.94761212584416
total_envstep_count: 5524239
total_train_sample_count: 4203944
total_episode_count: 16640
total_duration: 1269.3572133026923
[2023-06-29 10:54:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 326.25
avg_sample_per_episode: 326.25
avg_envstep_per_sec: 2376.806019236014
avg_train_sample_per_sec: 2376.806019236014
avg_episode_per_sec: 7.28522917773491
collect_time: 1.098112331791781
reward_mean: 2101.786092431488
reward_std: 970.2755231532693
reward_max: 3555.224357263208
reward_min: 257.21603411458125
total_envstep_count: 5528343
total_train_sample_count: 4207354
total_episode_count: 16648
total_duration: 1270.455325634484
[2023-06-29 10:54:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2375
train_sample_count: 2375
avg_envstep_per_episode: 339.2857142857143
avg_sample_per_episode: 339.2857142857143
avg_envstep_per_sec: 2461.1771475727455
avg_train_sample_per_sec: 2461.1771475727455
avg_episode_per_sec: 7.253995803372302
collect_time: 0.9649853942217306
reward_mean: 1891.3581612586654
reward_std: 850.5981955010736
reward_max: 3515.074196451514
reward_min: 520.3260091945629
total_envstep_count: 5533087
total_train_sample_count: 4210929
total_episode_count: 16655
total_duration: 1271.4203110287058
[2023-06-29 10:54:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2515
train_sample_count: 2515
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2575.1977734395564
avg_train_sample_per_sec: 2575.1977734395564
avg_episode_per_sec: 10.23935496397438
collect_time: 0.9766240193042908
reward_mean: 1844.4282258799226
reward_std: 907.0314196198232
reward_max: 3593.4399671442093
reward_min: 245.36236491763685
total_envstep_count: 5537439
total_train_sample_count: 4214244
total_episode_count: 16665
total_duration: 1272.3969350480102
[2023-06-29 10:55:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1680
train_sample_count: 1680
avg_envstep_per_episode: 420.0
avg_sample_per_episode: 420.0
avg_envstep_per_sec: 2521.439357665163
avg_train_sample_per_sec: 2521.439357665163
avg_episode_per_sec: 6.003427042059911
collect_time: 0.6662861015843227
reward_mean: 2860.808491632852
reward_std: 847.474067454901
reward_max: 3650.172757886877
reward_min: 1503.8475240244736
total_envstep_count: 5542199
total_train_sample_count: 4217524
total_episode_count: 16669
total_duration: 1273.0632211495945
[2023-06-29 10:55:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2040
train_sample_count: 2040
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2655.307555912302
avg_train_sample_per_sec: 2655.307555912302
avg_episode_per_sec: 10.412970807499224
collect_time: 0.7682725850185378
reward_mean: 2423.9385837226246
reward_std: 711.8621603329815
reward_max: 3622.5843312525303
reward_min: 1560.4547587121203
total_envstep_count: 5546503
total_train_sample_count: 4220764
total_episode_count: 16677
total_duration: 1273.831493734613
[2023-06-29 10:55:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2853
train_sample_count: 2853
avg_envstep_per_episode: 285.3
avg_sample_per_episode: 285.3
avg_envstep_per_sec: 2504.6684378659347
avg_train_sample_per_sec: 2504.6684378659347
avg_episode_per_sec: 8.779069182845898
collect_time: 1.1390729235326875
reward_mean: 1932.249752853056
reward_std: 943.3820906279394
reward_max: 3601.789911066447
reward_min: 518.2431780630258
total_envstep_count: 5551247
total_train_sample_count: 4224017
total_episode_count: 16687
total_duration: 1274.9705666581458
[2023-06-29 10:55:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2493
train_sample_count: 2493
avg_envstep_per_episode: 249.3
avg_sample_per_episode: 249.3
avg_envstep_per_sec: 2628.8011860346714
avg_train_sample_per_sec: 2628.8011860346714
avg_episode_per_sec: 10.54472998810538
collect_time: 0.9483410207070408
reward_mean: 1402.5760753375396
reward_std: 380.97637006949867
reward_max: 2137.500803913933
reward_min: 698.7206617106568
total_envstep_count: 5556055
total_train_sample_count: 4227310
total_episode_count: 16697
total_duration: 1275.9189076788527
[2023-06-29 10:55:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1943
train_sample_count: 1943
avg_envstep_per_episode: 215.88888888888889
avg_sample_per_episode: 215.88888888888889
avg_envstep_per_sec: 2619.224366591229
avg_train_sample_per_sec: 2619.224366591229
avg_episode_per_sec: 12.132279618796224
collect_time: 0.741822665054351
reward_mean: 1731.2932955360536
reward_std: 797.6776328391801
reward_max: 3508.62016893205
reward_min: 737.9306343877826
total_envstep_count: 5560775
total_train_sample_count: 4230853
total_episode_count: 16706
total_duration: 1276.660730343907
[2023-06-29 10:55:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2709
train_sample_count: 2709
avg_envstep_per_episode: 246.27272727272728
avg_sample_per_episode: 246.27272727272728
avg_envstep_per_sec: 2680.6685104655708
avg_train_sample_per_sec: 2680.6685104655708
avg_episode_per_sec: 10.884958883396559
collect_time: 1.0105688149891792
reward_mean: 1790.9389974551457
reward_std: 771.8818730990918
reward_max: 3269.85278931276
reward_min: 881.0505414344509
total_envstep_count: 5565719
total_train_sample_count: 4234362
total_episode_count: 16717
total_duration: 1277.6712991588963
[2023-06-29 10:55:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2269
train_sample_count: 2269
avg_envstep_per_episode: 283.625
avg_sample_per_episode: 283.625
avg_envstep_per_sec: 2448.755981536067
avg_train_sample_per_sec: 2448.755981536067
avg_episode_per_sec: 8.63378045495308
collect_time: 0.9265929382545872
reward_mean: 1866.5216252539258
reward_std: 439.18302432401794
reward_max: 2678.793276408467
reward_min: 1133.220379208895
total_envstep_count: 5570423
total_train_sample_count: 4237831
total_episode_count: 16725
total_duration: 1278.5978920971509
[2023-06-29 10:55:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2848
train_sample_count: 2848
avg_envstep_per_episode: 316.44444444444446
avg_sample_per_episode: 316.44444444444446
avg_envstep_per_sec: 2587.1823483203107
avg_train_sample_per_sec: 2587.1823483203107
avg_episode_per_sec: 8.17578691533806
collect_time: 1.1008114684490722
reward_mean: 2250.4499885752675
reward_std: 929.3771612872146
reward_max: 3617.536484037341
reward_min: 729.5445394107987
total_envstep_count: 5575071
total_train_sample_count: 4241079
total_episode_count: 16734
total_duration: 1279.6987035656
[2023-06-29 10:55:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2393
train_sample_count: 2393
avg_envstep_per_episode: 299.125
avg_sample_per_episode: 299.125
avg_envstep_per_sec: 2207.0915280902277
avg_train_sample_per_sec: 2207.0915280902277
avg_episode_per_sec: 7.378492363026252
collect_time: 1.0842323345197364
reward_mean: 1875.8234287965574
reward_std: 807.9921867925548
reward_max: 3441.821217432732
reward_min: 743.6386805089655
total_envstep_count: 5579327
total_train_sample_count: 4244672
total_episode_count: 16742
total_duration: 1280.7829359001198
[2023-06-29 10:55:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1426
train_sample_count: 1426
avg_envstep_per_episode: 203.71428571428572
avg_sample_per_episode: 203.71428571428572
avg_envstep_per_sec: 2549.0175486291214
avg_train_sample_per_sec: 2549.0175486291214
avg_episode_per_sec: 12.512708864238324
collect_time: 0.559431221164763
reward_mean: 1396.781535359268
reward_std: 749.352083372339
reward_max: 2675.5336735363962
reward_min: 605.6178592468304
total_envstep_count: 5583783
total_train_sample_count: 4248098
total_episode_count: 16749
total_duration: 1281.3423671212845
[2023-06-29 10:55:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1708
train_sample_count: 1708
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 2560.882139083355
avg_train_sample_per_sec: 2560.882139083355
avg_episode_per_sec: 11.99476411748644
collect_time: 0.6669576760027556
reward_mean: 2037.2501468588748
reward_std: 1242.0668265077434
reward_max: 3591.052733318632
reward_min: 465.61268955525804
total_envstep_count: 5588367
total_train_sample_count: 4251406
total_episode_count: 16757
total_duration: 1282.0093247972873
[2023-06-29 10:55:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 222.75
avg_sample_per_episode: 222.75
avg_envstep_per_sec: 2405.6480159211314
avg_train_sample_per_sec: 2405.6480159211314
avg_episode_per_sec: 10.799766625908559
collect_time: 0.37037837377004335
reward_mean: 3333.0811744301354
reward_std: 479.0620804614263
reward_max: 3656.668281637464
reward_min: 2506.335134922178
total_envstep_count: 5592927
total_train_sample_count: 4254697
total_episode_count: 16761
total_duration: 1282.3797031710574
[2023-06-29 10:55:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 170.58333333333334
avg_sample_per_episode: 170.58333333333334
avg_envstep_per_sec: 2282.1766361976406
avg_train_sample_per_sec: 2282.1766361976406
avg_episode_per_sec: 13.378661277172293
collect_time: 0.8969507300760599
reward_mean: 1858.0642951769614
reward_std: 1270.276903093562
reward_max: 3640.572558348626
reward_min: 460.06936169642375
total_envstep_count: 5597495
total_train_sample_count: 4257944
total_episode_count: 16773
total_duration: 1283.2766539011334
[2023-06-29 10:55:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1953
train_sample_count: 1953
avg_envstep_per_episode: 390.6
avg_sample_per_episode: 390.6
avg_envstep_per_sec: 2243.5575787453818
avg_train_sample_per_sec: 2243.5575787453818
avg_episode_per_sec: 5.743875009588791
collect_time: 0.8704924796679993
reward_mean: 2807.9685466067212
reward_std: 438.92129423744774
reward_max: 3510.0437431917594
reward_min: 2246.814386897052
total_envstep_count: 5601839
total_train_sample_count: 4261497
total_episode_count: 16778
total_duration: 1284.1471463808014
[2023-06-29 10:55:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2332
train_sample_count: 2332
avg_envstep_per_episode: 233.2
avg_sample_per_episode: 233.2
avg_envstep_per_sec: 2614.6578301173117
avg_train_sample_per_sec: 2614.6578301173117
avg_episode_per_sec: 11.212083319542502
collect_time: 0.8918949061473831
reward_mean: 1814.3505335383265
reward_std: 981.1912731265262
reward_max: 3430.9845758769416
reward_min: 563.0362834939526
total_envstep_count: 5606055
total_train_sample_count: 4265029
total_episode_count: 16788
total_duration: 1285.0390412869488
[2023-06-29 10:55:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 322.85714285714283
avg_sample_per_episode: 322.85714285714283
avg_envstep_per_sec: 2365.623314078926
avg_train_sample_per_sec: 2365.623314078926
avg_episode_per_sec: 7.327151857766585
collect_time: 0.9553507469044998
reward_mean: 2195.17417047552
reward_std: 979.0409052463816
reward_max: 3561.9806933841346
reward_min: 491.76913851927776
total_envstep_count: 5610535
total_train_sample_count: 4268489
total_episode_count: 16795
total_duration: 1285.9943920338533
[2023-06-29 10:55:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 240.4
avg_sample_per_episode: 240.4
avg_envstep_per_sec: 2349.4299847501284
avg_train_sample_per_sec: 2349.4299847501284
avg_episode_per_sec: 9.773003264351615
collect_time: 0.5116134584993124
reward_mean: 1819.1165865515984
reward_std: 584.590850094986
reward_max: 2634.9207842568285
reward_min: 951.8439348465835
total_envstep_count: 5613903
total_train_sample_count: 4271691
total_episode_count: 16800
total_duration: 1286.5060054923526
[2023-06-29 10:55:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2886
train_sample_count: 2886
avg_envstep_per_episode: 262.3636363636364
avg_sample_per_episode: 262.3636363636364
avg_envstep_per_sec: 2260.0807246578993
avg_train_sample_per_sec: 2260.0807246578993
avg_episode_per_sec: 8.61430629633988
collect_time: 1.2769455393841491
reward_mean: 1911.6069848913423
reward_std: 816.3192523897474
reward_max: 3515.5197380509535
reward_min: 699.4227875382425
total_envstep_count: 5618343
total_train_sample_count: 4274977
total_episode_count: 16811
total_duration: 1287.7829510317367
[2023-06-29 10:55:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2455
train_sample_count: 2455
avg_envstep_per_episode: 272.77777777777777
avg_sample_per_episode: 272.77777777777777
avg_envstep_per_sec: 2599.442794193196
avg_train_sample_per_sec: 2599.442794193196
avg_episode_per_sec: 9.529525518427194
collect_time: 0.9444331706333906
reward_mean: 1430.445520727826
reward_std: 929.0005117577847
reward_max: 3545.5821760870886
reward_min: 397.30510339345
total_envstep_count: 5622431
total_train_sample_count: 4278232
total_episode_count: 16820
total_duration: 1288.72738420237
[2023-06-29 10:56:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 242.5
avg_sample_per_episode: 242.5
avg_envstep_per_sec: 2465.9346737826827
avg_train_sample_per_sec: 2465.9346737826827
avg_episode_per_sec: 10.168802778485288
collect_time: 1.180079923016019
reward_mean: 1396.167035160405
reward_std: 681.0521701615997
reward_max: 2887.0898887143044
reward_min: 185.688493321242
total_envstep_count: 5626895
total_train_sample_count: 4281542
total_episode_count: 16832
total_duration: 1289.907464125386
[2023-06-29 10:56:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2126
train_sample_count: 2126
avg_envstep_per_episode: 265.75
avg_sample_per_episode: 265.75
avg_envstep_per_sec: 2531.3002161265895
avg_train_sample_per_sec: 2531.3002161265895
avg_episode_per_sec: 9.52511840499187
collect_time: 0.8398845725432038
reward_mean: 1616.362643140546
reward_std: 500.23196446782964
reward_max: 2385.1195726053575
reward_min: 1059.7620720454702
total_envstep_count: 5631527
total_train_sample_count: 4284868
total_episode_count: 16840
total_duration: 1290.7473486979293
[2023-06-29 10:56:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2768
train_sample_count: 2768
avg_envstep_per_episode: 251.63636363636363
avg_sample_per_episode: 251.63636363636363
avg_envstep_per_sec: 2583.3387209106986
avg_train_sample_per_sec: 2583.3387209106986
avg_episode_per_sec: 10.266158211711591
collect_time: 1.0714816363779827
reward_mean: 1726.2136551412232
reward_std: 628.7975370067599
reward_max: 3053.0378258948917
reward_min: 1141.1466377537
total_envstep_count: 5636215
total_train_sample_count: 4288436
total_episode_count: 16851
total_duration: 1291.8188303343072
[2023-06-29 10:56:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 214.46666666666667
avg_sample_per_episode: 214.46666666666667
avg_envstep_per_sec: 2701.479201821172
avg_train_sample_per_sec: 2701.479201821172
avg_episode_per_sec: 12.596266094907547
collect_time: 1.1908290827600285
reward_mean: 1200.5022052818836
reward_std: 350.54576603117926
reward_max: 1660.7292517039623
reward_min: 241.54039271548086
total_envstep_count: 5641015
total_train_sample_count: 4291653
total_episode_count: 16866
total_duration: 1293.0096594170673
[2023-06-29 10:56:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1654
train_sample_count: 1654
avg_envstep_per_episode: 236.28571428571428
avg_sample_per_episode: 236.28571428571428
avg_envstep_per_sec: 2699.8158308710513
avg_train_sample_per_sec: 2699.8158308710513
avg_episode_per_sec: 11.426064580469987
collect_time: 0.6126343808667735
reward_mean: 1436.7977597072968
reward_std: 592.82317597332
reward_max: 2438.526155858448
reward_min: 243.5119964913228
total_envstep_count: 5644727
total_train_sample_count: 4294907
total_episode_count: 16873
total_duration: 1293.622293797934
[2023-06-29 10:56:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 306.57142857142856
avg_sample_per_episode: 306.57142857142856
avg_envstep_per_sec: 2439.5635775102082
avg_train_sample_per_sec: 2439.5635775102082
avg_episode_per_sec: 7.957569917321275
collect_time: 0.8796655351733789
reward_mean: 2336.5861456560065
reward_std: 879.2930059129277
reward_max: 3536.8746453084555
reward_min: 1098.5564104933546
total_envstep_count: 5649623
total_train_sample_count: 4298253
total_episode_count: 16880
total_duration: 1294.5019593331074
[2023-06-29 10:56:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2271
train_sample_count: 2271
avg_envstep_per_episode: 206.45454545454547
avg_sample_per_episode: 206.45454545454547
avg_envstep_per_sec: 2580.521084753021
avg_train_sample_per_sec: 2580.521084753021
avg_episode_per_sec: 12.499221458513093
collect_time: 0.8800548127345973
reward_mean: 1619.4750136526197
reward_std: 902.0409477196056
reward_max: 2951.4134544849558
reward_min: 387.69082084013746
total_envstep_count: 5654511
total_train_sample_count: 4301724
total_episode_count: 16891
total_duration: 1295.382014145842
[2023-06-29 10:56:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2184
train_sample_count: 2184
avg_envstep_per_episode: 198.54545454545453
avg_sample_per_episode: 198.54545454545453
avg_envstep_per_sec: 2631.375827149925
avg_train_sample_per_sec: 2631.375827149925
avg_episode_per_sec: 13.253266528685518
collect_time: 0.8299840628867967
reward_mean: 1498.4868864373364
reward_std: 631.3622442723723
reward_max: 2702.4090111328755
reward_min: 501.1557586548419
total_envstep_count: 5658719
total_train_sample_count: 4305108
total_episode_count: 16902
total_duration: 1296.2119982087288
[2023-06-29 10:56:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2909
train_sample_count: 2909
avg_envstep_per_episode: 415.57142857142856
avg_sample_per_episode: 415.57142857142856
avg_envstep_per_sec: 2640.795062917016
avg_train_sample_per_sec: 2640.795062917016
avg_episode_per_sec: 6.354611701759749
collect_time: 1.1015621927082542
reward_mean: 2400.5403118262757
reward_std: 975.1114651202145
reward_max: 3518.445168838321
reward_min: 1300.896395764009
total_envstep_count: 5663519
total_train_sample_count: 4308417
total_episode_count: 16909
total_duration: 1297.3135604014371
[2023-06-29 10:56:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2715
train_sample_count: 2715
avg_envstep_per_episode: 271.5
avg_sample_per_episode: 271.5
avg_envstep_per_sec: 2529.4299068848545
avg_train_sample_per_sec: 2529.4299068848545
avg_episode_per_sec: 9.316500577844769
collect_time: 1.073364394328557
reward_mean: 1663.611663985103
reward_std: 645.2991667471106
reward_max: 3209.6125881952707
reward_min: 1157.9126083717474
total_envstep_count: 5667719
total_train_sample_count: 4311932
total_episode_count: 16919
total_duration: 1298.3869247957657
[2023-06-29 10:56:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2230
train_sample_count: 2230
avg_envstep_per_episode: 278.75
avg_sample_per_episode: 278.75
avg_envstep_per_sec: 2557.2359546165935
avg_train_sample_per_sec: 2557.2359546165935
avg_episode_per_sec: 9.17394064436446
collect_time: 0.8720352910626678
reward_mean: 1631.4764449385616
reward_std: 873.306750240852
reward_max: 3401.511040747838
reward_min: 553.1075100794421
total_envstep_count: 5672727
total_train_sample_count: 4315362
total_episode_count: 16927
total_duration: 1299.2589600868284
[2023-06-29 10:56:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3107
train_sample_count: 3107
avg_envstep_per_episode: 282.45454545454544
avg_sample_per_episode: 282.45454545454544
avg_envstep_per_sec: 2576.5436581276967
avg_train_sample_per_sec: 2576.5436581276967
avg_episode_per_sec: 9.121976259866322
collect_time: 1.2058790427241475
reward_mean: 1814.8077080667135
reward_std: 916.9461000215908
reward_max: 3521.4003443970646
reward_min: 505.59739316718077
total_envstep_count: 5677439
total_train_sample_count: 4318869
total_episode_count: 16938
total_duration: 1300.4648391295525
[2023-06-29 10:56:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 286.7142857142857
avg_sample_per_episode: 286.7142857142857
avg_envstep_per_sec: 2691.7876675550388
avg_train_sample_per_sec: 2691.7876675550388
avg_episode_per_sec: 9.388397445383792
collect_time: 0.745601157249883
reward_mean: 1825.769343288235
reward_std: 785.9168623091417
reward_max: 3617.0645739313204
reward_min: 1074.6973232302648
total_envstep_count: 5681839
total_train_sample_count: 4322076
total_episode_count: 16945
total_duration: 1301.2104402868024
[2023-06-29 10:56:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 175.28571428571428
avg_sample_per_episode: 175.28571428571428
avg_envstep_per_sec: 2626.7286345410134
avg_train_sample_per_sec: 2626.7286345410134
avg_episode_per_sec: 14.985411932996817
collect_time: 0.46712095945701
reward_mean: 1912.9990126023345
reward_std: 990.5402177134165
reward_max: 3689.337652886054
reward_min: 838.1213657045854
total_envstep_count: 5685839
total_train_sample_count: 4325303
total_episode_count: 16952
total_duration: 1301.6775612462593
[2023-06-29 10:56:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2331
train_sample_count: 2331
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2482.502096327577
avg_train_sample_per_sec: 2482.502096327577
avg_episode_per_sec: 9.584950178870953
collect_time: 0.938972016760148
reward_mean: 2004.9612944274086
reward_std: 1013.4508452245157
reward_max: 3334.912208477167
reward_min: 524.9762761439714
total_envstep_count: 5691071
total_train_sample_count: 4328834
total_episode_count: 16961
total_duration: 1302.6165332630194
[2023-06-29 10:56:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 406.5
avg_sample_per_episode: 406.5
avg_envstep_per_sec: 2421.7592536191573
avg_train_sample_per_sec: 2421.7592536191573
avg_episode_per_sec: 5.957587339776524
collect_time: 1.0071191000323743
reward_mean: 2849.658054732356
reward_std: 435.43875812320755
reward_max: 3580.5384397158195
reward_min: 2139.490174904006
total_envstep_count: 5695871
total_train_sample_count: 4332073
total_episode_count: 16967
total_duration: 1303.6236523630519
[2023-06-29 10:56:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1815
train_sample_count: 1815
avg_envstep_per_episode: 181.5
avg_sample_per_episode: 181.5
avg_envstep_per_sec: 2657.930066459602
avg_train_sample_per_sec: 2657.930066459602
avg_episode_per_sec: 14.644242790411031
collect_time: 0.6828622102979571
reward_mean: 1533.1512764692154
reward_std: 1159.925651691821
reward_max: 3440.503411139316
reward_min: 110.78708473760608
total_envstep_count: 5700743
total_train_sample_count: 4335488
total_episode_count: 16977
total_duration: 1304.30651457335
[2023-06-29 10:56:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2236
train_sample_count: 2236
avg_envstep_per_episode: 223.6
avg_sample_per_episode: 223.6
avg_envstep_per_sec: 2598.845962023747
avg_train_sample_per_sec: 2598.845962023747
avg_episode_per_sec: 11.622745805115146
collect_time: 0.8603818897595628
reward_mean: 1784.5639071464927
reward_std: 1207.1712484194445
reward_max: 3468.714274741948
reward_min: 249.2408999628037
total_envstep_count: 5705103
total_train_sample_count: 4338924
total_episode_count: 16987
total_duration: 1305.1668964631094
[2023-06-29 10:56:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2157
train_sample_count: 2157
avg_envstep_per_episode: 239.66666666666666
avg_sample_per_episode: 239.66666666666666
avg_envstep_per_sec: 2564.178094816427
avg_train_sample_per_sec: 2564.178094816427
avg_episode_per_sec: 10.698935027050458
collect_time: 0.8412052206359804
reward_mean: 1811.024141223678
reward_std: 1024.5048182087153
reward_max: 3566.3517831149456
reward_min: 242.45472623844714
total_envstep_count: 5709799
total_train_sample_count: 4342281
total_episode_count: 16996
total_duration: 1306.0081016837455
[2023-06-29 10:57:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2234
train_sample_count: 2234
avg_envstep_per_episode: 279.25
avg_sample_per_episode: 279.25
avg_envstep_per_sec: 2368.9486089205484
avg_train_sample_per_sec: 2368.9486089205484
avg_episode_per_sec: 8.48325374725353
collect_time: 0.943034387317486
reward_mean: 2054.885687356382
reward_std: 885.7503884539999
reward_max: 3499.888129041527
reward_min: 903.3582503147234
total_envstep_count: 5714359
total_train_sample_count: 4345715
total_episode_count: 17004
total_duration: 1306.951136071063
[2023-06-29 10:57:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1885
train_sample_count: 1885
avg_envstep_per_episode: 314.1666666666667
avg_sample_per_episode: 314.1666666666667
avg_envstep_per_sec: 2726.14664403378
avg_train_sample_per_sec: 2726.14664403378
avg_episode_per_sec: 8.677389848383383
collect_time: 0.6914521653210974
reward_mean: 2355.8637675477617
reward_std: 762.9205056007686
reward_max: 3535.7555244724513
reward_min: 1333.9625860698875
total_envstep_count: 5718847
total_train_sample_count: 4349200
total_episode_count: 17010
total_duration: 1307.6425882363842
[2023-06-29 10:57:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1902
train_sample_count: 1902
avg_envstep_per_episode: 237.75
avg_sample_per_episode: 237.75
avg_envstep_per_sec: 2627.330147680259
avg_train_sample_per_sec: 2627.330147680259
avg_episode_per_sec: 11.050810295185105
collect_time: 0.7239288148386405
reward_mean: 2212.3375500466323
reward_std: 881.0642364535868
reward_max: 3564.4719494089572
reward_min: 1118.444582431963
total_envstep_count: 5723943
total_train_sample_count: 4352702
total_episode_count: 17018
total_duration: 1308.366517051223
[2023-06-29 10:57:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2731
train_sample_count: 2731
avg_envstep_per_episode: 273.1
avg_sample_per_episode: 273.1
avg_envstep_per_sec: 2676.480382212911
avg_train_sample_per_sec: 2676.480382212911
avg_episode_per_sec: 9.800367565774117
collect_time: 1.0203698925459757
reward_mean: 2151.1501590517983
reward_std: 783.1393937131953
reward_max: 3380.7035513492456
reward_min: 1150.9678039466232
total_envstep_count: 5728599
total_train_sample_count: 4356233
total_episode_count: 17028
total_duration: 1309.3868869437688
[2023-06-29 10:57:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 223.63636363636363
avg_sample_per_episode: 223.63636363636363
avg_envstep_per_sec: 2530.2937048552158
avg_train_sample_per_sec: 2530.2937048552158
avg_episode_per_sec: 11.314321444474542
collect_time: 0.9722191519821063
reward_mean: 1393.8343483743984
reward_std: 549.644016510738
reward_max: 2634.771652147073
reward_min: 404.9426644395713
total_envstep_count: 5733071
total_train_sample_count: 4359493
total_episode_count: 17039
total_duration: 1310.3591060957508
[2023-06-29 10:57:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 219.7
avg_sample_per_episode: 219.7
avg_envstep_per_sec: 2601.934214504228
avg_train_sample_per_sec: 2601.934214504228
avg_episode_per_sec: 11.843123416041092
collect_time: 0.8443718475867062
reward_mean: 1453.037328761305
reward_std: 478.51566950438115
reward_max: 2404.4610729017686
reward_min: 964.7479516854304
total_envstep_count: 5737415
total_train_sample_count: 4362890
total_episode_count: 17049
total_duration: 1311.2034779433375
[2023-06-29 10:57:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2952
train_sample_count: 2952
avg_envstep_per_episode: 246.0
avg_sample_per_episode: 246.0
avg_envstep_per_sec: 2671.3591383025037
avg_train_sample_per_sec: 2671.3591383025037
avg_episode_per_sec: 10.859183489034569
collect_time: 1.1050554594751447
reward_mean: 1514.0544901397996
reward_std: 446.1653750553086
reward_max: 2307.748038437744
reward_min: 633.7730193157629
total_envstep_count: 5742343
total_train_sample_count: 4366242
total_episode_count: 17061
total_duration: 1312.3085334028126
[2023-06-29 10:57:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2911
train_sample_count: 2911
avg_envstep_per_episode: 291.1
avg_sample_per_episode: 291.1
avg_envstep_per_sec: 2591.3877145326337
avg_train_sample_per_sec: 2591.3877145326337
avg_episode_per_sec: 8.902053296230278
collect_time: 1.1233363435640928
reward_mean: 1732.2562832097221
reward_std: 793.071881959738
reward_max: 2665.22910616225
reward_min: 241.90078682529753
total_envstep_count: 5746743
total_train_sample_count: 4369553
total_episode_count: 17071
total_duration: 1313.4318697463766
[2023-06-29 10:57:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3557
train_sample_count: 3557
avg_envstep_per_episode: 296.4166666666667
avg_sample_per_episode: 296.4166666666667
avg_envstep_per_sec: 2438.412983270665
avg_train_sample_per_sec: 2438.412983270665
avg_episode_per_sec: 8.226301883398364
collect_time: 1.4587356712762267
reward_mean: 1482.1204001804183
reward_std: 405.0048176090447
reward_max: 1965.0568432031416
reward_min: 540.6867324838223
total_envstep_count: 5751783
total_train_sample_count: 4373110
total_episode_count: 17083
total_duration: 1314.8906054176528
[2023-06-29 10:57:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1278
train_sample_count: 1278
avg_envstep_per_episode: 182.57142857142858
avg_sample_per_episode: 182.57142857142858
avg_envstep_per_sec: 2675.025047474864
avg_train_sample_per_sec: 2675.025047474864
avg_episode_per_sec: 14.651936879752776
collect_time: 0.4777525358898565
reward_mean: 1328.5870027260041
reward_std: 191.89325406815266
reward_max: 1700.8671875308662
reward_min: 1089.2004843134177
total_envstep_count: 5756103
total_train_sample_count: 4376388
total_episode_count: 17090
total_duration: 1315.3683579535425
[2023-06-29 10:57:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2862
train_sample_count: 2862
avg_envstep_per_episode: 238.5
avg_sample_per_episode: 238.5
avg_envstep_per_sec: 2649.5753011526526
avg_train_sample_per_sec: 2649.5753011526526
avg_episode_per_sec: 11.109330403155775
collect_time: 1.0801731125569203
reward_mean: 1755.235543557217
reward_std: 1023.3930274216432
reward_max: 3546.7991915516113
reward_min: 234.58854028730673
total_envstep_count: 5760439
total_train_sample_count: 4379650
total_episode_count: 17102
total_duration: 1316.4485310660993
[2023-06-29 10:57:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3082
train_sample_count: 3082
avg_envstep_per_episode: 237.07692307692307
avg_sample_per_episode: 237.07692307692307
avg_envstep_per_sec: 2691.884586009065
avg_train_sample_per_sec: 2691.884586009065
avg_episode_per_sec: 11.354477488033046
collect_time: 1.144922786072828
reward_mean: 1186.3316393479242
reward_std: 594.5712307498886
reward_max: 2326.870786849335
reward_min: 240.113169125441
total_envstep_count: 5765127
total_train_sample_count: 4383132
total_episode_count: 17115
total_duration: 1317.5934538521722
[2023-06-29 10:57:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2882
train_sample_count: 2882
avg_envstep_per_episode: 240.16666666666666
avg_sample_per_episode: 240.16666666666666
avg_envstep_per_sec: 2478.550672949425
avg_train_sample_per_sec: 2478.550672949425
avg_episode_per_sec: 10.320127715264782
collect_time: 1.1627763077244164
reward_mean: 1316.5864128424753
reward_std: 366.4229025669897
reward_max: 1920.182107208447
reward_min: 602.4862011736424
total_envstep_count: 5769615
total_train_sample_count: 4386414
total_episode_count: 17127
total_duration: 1318.7562301598966
[2023-06-29 10:57:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1936
train_sample_count: 1936
avg_envstep_per_episode: 215.11111111111111
avg_sample_per_episode: 215.11111111111111
avg_envstep_per_sec: 2643.556782578482
avg_train_sample_per_sec: 2643.556782578482
avg_episode_per_sec: 12.289261902482611
collect_time: 0.7323466674741359
reward_mean: 1370.3590903234929
reward_std: 668.4251405884988
reward_max: 2531.3361401041416
reward_min: 415.17265595728753
total_envstep_count: 5774007
total_train_sample_count: 4389950
total_episode_count: 17136
total_duration: 1319.4885768273707
[2023-06-29 10:57:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2853
train_sample_count: 2853
avg_envstep_per_episode: 285.3
avg_sample_per_episode: 285.3
avg_envstep_per_sec: 2656.009600425684
avg_train_sample_per_sec: 2656.009600425684
avg_episode_per_sec: 9.309532423503974
collect_time: 1.0741678040405969
reward_mean: 1892.5031628247111
reward_std: 861.9090241510906
reward_max: 3532.369847660467
reward_min: 243.77526199883033
total_envstep_count: 5778359
total_train_sample_count: 4393203
total_episode_count: 17146
total_duration: 1320.5627446314113
[2023-06-29 10:57:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 293.09090909090907
avg_sample_per_episode: 293.09090909090907
avg_envstep_per_sec: 2665.3698590518256
avg_train_sample_per_sec: 2665.3698590518256
avg_episode_per_sec: 9.094003861529183
collect_time: 1.2095882262084634
reward_mean: 1530.1067705345731
reward_std: 600.6717951251935
reward_max: 3057.1527893174903
reward_min: 884.3910543133106
total_envstep_count: 5783223
total_train_sample_count: 4396427
total_episode_count: 17157
total_duration: 1321.7723328576199
[2023-06-29 10:57:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3443
train_sample_count: 3443
avg_envstep_per_episode: 245.92857142857142
avg_sample_per_episode: 245.92857142857142
avg_envstep_per_sec: 2454.96698239401
avg_train_sample_per_sec: 2454.96698239401
avg_episode_per_sec: 9.982439080312558
collect_time: 1.4024628537539394
reward_mean: 1279.8518493690474
reward_std: 298.47560008970237
reward_max: 1964.0365736870554
reward_min: 967.7552666627288
total_envstep_count: 5787791
total_train_sample_count: 4399870
total_episode_count: 17171
total_duration: 1323.1747957113737
[2023-06-29 10:57:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2407
train_sample_count: 2407
avg_envstep_per_episode: 218.8181818181818
avg_sample_per_episode: 218.8181818181818
avg_envstep_per_sec: 2442.7100148985733
avg_train_sample_per_sec: 2442.7100148985733
avg_episode_per_sec: 11.163194916445494
collect_time: 0.9853809847747909
reward_mean: 1119.1782097501439
reward_std: 106.47735931291497
reward_max: 1336.4543016236996
reward_min: 1000.3725749135123
total_envstep_count: 5792015
total_train_sample_count: 4403077
total_episode_count: 17182
total_duration: 1324.1601766961485
[2023-06-29 10:57:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2832
train_sample_count: 2832
avg_envstep_per_episode: 217.84615384615384
avg_sample_per_episode: 217.84615384615384
avg_envstep_per_sec: 2560.8137054972635
avg_train_sample_per_sec: 2560.8137054972635
avg_episode_per_sec: 11.755147659415405
collect_time: 1.1058984860634666
reward_mean: 1231.126326246794
reward_std: 471.96483739633607
reward_max: 2103.7034243906846
reward_min: 258.3820881235573
total_envstep_count: 5796383
total_train_sample_count: 4406309
total_episode_count: 17195
total_duration: 1325.266075182212
[2023-06-29 10:58:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2214
train_sample_count: 2214
avg_envstep_per_episode: 221.4
avg_sample_per_episode: 221.4
avg_envstep_per_sec: 2596.254315673351
avg_train_sample_per_sec: 2596.254315673351
avg_episode_per_sec: 11.726532591117213
collect_time: 0.8527669984539972
reward_mean: 1273.109836165388
reward_std: 383.05200157420427
reward_max: 1759.7167054900535
reward_min: 250.72799879764082
total_envstep_count: 5800631
total_train_sample_count: 4409723
total_episode_count: 17205
total_duration: 1326.118842180666
[2023-06-29 10:58:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 222.0909090909091
avg_sample_per_episode: 222.0909090909091
avg_envstep_per_sec: 2582.5874749892164
avg_train_sample_per_sec: 2582.5874749892164
avg_episode_per_sec: 11.628515032698067
collect_time: 0.9459505335865539
reward_mean: 1427.8706288583992
reward_std: 701.7405668699081
reward_max: 2715.9923989210033
reward_min: 525.2883242196101
total_envstep_count: 5805143
total_train_sample_count: 4412966
total_episode_count: 17216
total_duration: 1327.0647927142525
[2023-06-29 10:58:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1823
train_sample_count: 1823
avg_envstep_per_episode: 227.875
avg_sample_per_episode: 227.875
avg_envstep_per_sec: 2267.470399372391
avg_train_sample_per_sec: 2267.470399372391
avg_episode_per_sec: 9.950500929774618
collect_time: 0.8039796243887394
reward_mean: 1678.019413739219
reward_std: 515.8681359277085
reward_max: 2670.7350927004836
reward_min: 1257.6263836840826
total_envstep_count: 5809431
total_train_sample_count: 4416389
total_episode_count: 17224
total_duration: 1327.8687723386413
[2023-06-29 10:58:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2827
train_sample_count: 2827
avg_envstep_per_episode: 235.58333333333334
avg_sample_per_episode: 235.58333333333334
avg_envstep_per_sec: 2453.9025658936444
avg_train_sample_per_sec: 2453.9025658936444
avg_episode_per_sec: 10.416282557737436
collect_time: 1.1520424809411631
reward_mean: 1630.2885692893276
reward_std: 918.1460929014057
reward_max: 3536.6930451855264
reward_min: 625.1542152387527
total_envstep_count: 5814015
total_train_sample_count: 4419616
total_episode_count: 17236
total_duration: 1329.0208148195825
[2023-06-29 10:58:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2951
train_sample_count: 2951
avg_envstep_per_episode: 268.27272727272725
avg_sample_per_episode: 268.27272727272725
avg_envstep_per_sec: 2204.1667035442915
avg_train_sample_per_sec: 2204.1667035442915
avg_episode_per_sec: 8.216141558450426
collect_time: 1.338827954915934
reward_mean: 1523.3268007415807
reward_std: 594.4595317767535
reward_max: 2920.8034238215178
reward_min: 619.1135340876879
total_envstep_count: 5818527
total_train_sample_count: 4422967
total_episode_count: 17247
total_duration: 1330.3596427744985
[2023-06-29 10:58:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2523
train_sample_count: 2523
avg_envstep_per_episode: 252.3
avg_sample_per_episode: 252.3
avg_envstep_per_sec: 2481.898232814971
avg_train_sample_per_sec: 2481.898232814971
avg_episode_per_sec: 9.837091687732741
collect_time: 1.0165606174506243
reward_mean: 1360.2126398301127
reward_std: 447.46897493605235
reward_max: 2401.162812215304
reward_min: 726.2940743072911
total_envstep_count: 5822311
total_train_sample_count: 4426290
total_episode_count: 17257
total_duration: 1331.376203391949
[2023-06-29 10:58:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3068
train_sample_count: 3068
avg_envstep_per_episode: 306.8
avg_sample_per_episode: 306.8
avg_envstep_per_sec: 2335.5888665834227
avg_train_sample_per_sec: 2335.5888665834227
avg_episode_per_sec: 7.612740764613504
collect_time: 1.3135873543052003
reward_mean: 1599.2878508451374
reward_std: 523.5900830782304
reward_max: 2594.023037356008
reward_min: 631.6652524491822
total_envstep_count: 5827183
total_train_sample_count: 4429758
total_episode_count: 17267
total_duration: 1332.6897907462542
[2023-06-29 10:58:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2509
train_sample_count: 2509
avg_envstep_per_episode: 313.625
avg_sample_per_episode: 313.625
avg_envstep_per_sec: 2491.23153286133
avg_train_sample_per_sec: 2491.23153286133
avg_episode_per_sec: 7.943344863647126
collect_time: 1.0071324029518292
reward_mean: 1908.8800138887668
reward_std: 765.185877912635
reward_max: 3576.080486234205
reward_min: 1138.425258703077
total_envstep_count: 5831511
total_train_sample_count: 4433067
total_episode_count: 17275
total_duration: 1333.696923149206
[2023-06-29 10:58:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2590
train_sample_count: 2590
avg_envstep_per_episode: 235.45454545454547
avg_sample_per_episode: 235.45454545454547
avg_envstep_per_sec: 2570.5092055126443
avg_train_sample_per_sec: 2570.5092055126443
avg_episode_per_sec: 10.917220563953315
collect_time: 1.0075824643792586
reward_mean: 1337.0714747114207
reward_std: 749.1572940419741
reward_max: 2619.8347483619996
reward_min: 507.2882810736827
total_envstep_count: 5836263
total_train_sample_count: 4436457
total_episode_count: 17286
total_duration: 1334.7045056135853
[2023-06-29 10:58:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1684
train_sample_count: 1684
avg_envstep_per_episode: 240.57142857142858
avg_sample_per_episode: 240.57142857142858
avg_envstep_per_sec: 2620.353222774839
avg_train_sample_per_sec: 2620.353222774839
avg_episode_per_sec: 10.892204607733891
collect_time: 0.6426614493662491
reward_mean: 1724.200608400366
reward_std: 873.1111231302086
reward_max: 3563.98428890802
reward_min: 802.8062760845904
total_envstep_count: 5840759
total_train_sample_count: 4439741
total_episode_count: 17293
total_duration: 1335.3471670629515
[2023-06-29 10:58:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2417
train_sample_count: 2417
avg_envstep_per_episode: 219.72727272727272
avg_sample_per_episode: 219.72727272727272
avg_envstep_per_sec: 2469.1346095739286
avg_train_sample_per_sec: 2469.1346095739286
avg_episode_per_sec: 11.237269633973195
collect_time: 0.9788854729216546
reward_mean: 1746.8765392588955
reward_std: 995.5782500037658
reward_max: 3439.090367021699
reward_min: 459.04788654489465
total_envstep_count: 5844703
total_train_sample_count: 4442958
total_episode_count: 17304
total_duration: 1336.326052535873
[2023-06-29 10:58:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3446
train_sample_count: 3446
avg_envstep_per_episode: 287.1666666666667
avg_sample_per_episode: 287.1666666666667
avg_envstep_per_sec: 2546.914041323374
avg_train_sample_per_sec: 2546.914041323374
avg_episode_per_sec: 8.86911447936172
collect_time: 1.353009934410453
reward_mean: 1466.2718297415743
reward_std: 504.47988890797154
reward_max: 2300.712731258568
reward_min: 468.0467617162386
total_envstep_count: 5849207
total_train_sample_count: 4446404
total_episode_count: 17316
total_duration: 1337.6790624702835
[2023-06-29 10:58:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3054
train_sample_count: 3054
avg_envstep_per_episode: 277.6363636363636
avg_sample_per_episode: 277.6363636363636
avg_envstep_per_sec: 2711.8640019704026
avg_train_sample_per_sec: 2711.8640019704026
avg_episode_per_sec: 9.767683045734914
collect_time: 1.1261626681061463
reward_mean: 1274.1577674709988
reward_std: 467.76217638416506
reward_max: 2166.812448068008
reward_min: 533.1487205787553
total_envstep_count: 5854255
total_train_sample_count: 4449858
total_episode_count: 17327
total_duration: 1338.8052251383897
[2023-06-29 10:58:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2880
train_sample_count: 2880
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 2628.5652980414443
avg_train_sample_per_sec: 2628.5652980414443
avg_episode_per_sec: 9.126962840421681
collect_time: 1.0956547292722387
reward_mean: 1721.331445843764
reward_std: 545.1066079512675
reward_max: 2585.5385619767953
reward_min: 1139.0247100963945
total_envstep_count: 5859071
total_train_sample_count: 4453138
total_episode_count: 17337
total_duration: 1339.9008798676618
[2023-06-29 10:58:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2905
train_sample_count: 2905
avg_envstep_per_episode: 290.5
avg_sample_per_episode: 290.5
avg_envstep_per_sec: 2577.828769928384
avg_train_sample_per_sec: 2577.828769928384
avg_episode_per_sec: 8.873765128841253
collect_time: 1.1269173631267624
reward_mean: 1722.7716333855708
reward_std: 502.9256942920107
reward_max: 2696.2942646458537
reward_min: 1304.0146010700403
total_envstep_count: 5863863
total_train_sample_count: 4456843
total_episode_count: 17347
total_duration: 1341.0277972307886
[2023-06-29 10:58:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2079
train_sample_count: 2079
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 2468.4967520685805
avg_train_sample_per_sec: 2468.4967520685805
avg_episode_per_sec: 10.686133125838012
collect_time: 0.8422129776990043
reward_mean: 1541.624378463736
reward_std: 517.7242628483693
reward_max: 2304.5290193290793
reward_min: 635.3206130974951
total_envstep_count: 5868063
total_train_sample_count: 4460122
total_episode_count: 17356
total_duration: 1341.8700102084877
[2023-06-29 10:58:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2370
train_sample_count: 2370
avg_envstep_per_episode: 296.25
avg_sample_per_episode: 296.25
avg_envstep_per_sec: 2431.0986547205457
avg_train_sample_per_sec: 2431.0986547205457
avg_episode_per_sec: 8.206240184710703
collect_time: 0.9748678834559394
reward_mean: 1991.6483297465425
reward_std: 527.30501937533
reward_max: 2885.525916180148
reward_min: 1396.228158477213
total_envstep_count: 5872751
total_train_sample_count: 4463692
total_episode_count: 17364
total_duration: 1342.8448780919437
[2023-06-29 10:58:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2459
train_sample_count: 2459
avg_envstep_per_episode: 245.9
avg_sample_per_episode: 245.9
avg_envstep_per_sec: 2550.9188086491185
avg_train_sample_per_sec: 2550.9188086491185
avg_episode_per_sec: 10.37380564721073
collect_time: 0.9639663918986917
reward_mean: 1702.0485917409721
reward_std: 651.9001030478396
reward_max: 2595.6680379258833
reward_min: 602.3532553090408
total_envstep_count: 5876983
total_train_sample_count: 4466951
total_episode_count: 17374
total_duration: 1343.8088444838424
[2023-06-29 10:58:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 356.1111111111111
avg_sample_per_episode: 356.1111111111111
avg_envstep_per_sec: 2687.2511746810287
avg_train_sample_per_sec: 2687.2511746810287
avg_episode_per_sec: 7.546103142630034
collect_time: 1.1926685641435908
reward_mean: 1993.3925390534305
reward_std: 821.6560781701069
reward_max: 3567.755066899725
reward_min: 1340.5527059125698
total_envstep_count: 5881783
total_train_sample_count: 4470156
total_episode_count: 17383
total_duration: 1345.001513047986
[2023-06-29 10:59:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2948
train_sample_count: 2948
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2555.0451567817868
avg_train_sample_per_sec: 2555.0451567817868
avg_episode_per_sec: 9.533750585006667
collect_time: 1.1537956549124793
reward_mean: 1467.3596165373087
reward_std: 616.2353363259239
reward_max: 2435.44120358951
reward_min: 414.49999387161915
total_envstep_count: 5886823
total_train_sample_count: 4473504
total_episode_count: 17394
total_duration: 1346.1553087028985
[2023-06-29 10:59:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2288
train_sample_count: 2288
avg_envstep_per_episode: 254.22222222222223
avg_sample_per_episode: 254.22222222222223
avg_envstep_per_sec: 2696.2573512578524
avg_train_sample_per_sec: 2696.2573512578524
avg_episode_per_sec: 10.60590741316463
collect_time: 0.8485836854306978
reward_mean: 1754.5632567710174
reward_std: 703.6642435192363
reward_max: 3316.345259688332
reward_min: 925.081120539806
total_envstep_count: 5891167
total_train_sample_count: 4476992
total_episode_count: 17403
total_duration: 1347.0038923883292
[2023-06-29 10:59:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 275.77777777777777
avg_sample_per_episode: 275.77777777777777
avg_envstep_per_sec: 2691.3351916964652
avg_train_sample_per_sec: 2691.3351916964652
avg_episode_per_sec: 9.759072008568971
collect_time: 0.9222188331121579
reward_mean: 1803.2228513719901
reward_std: 804.2613466177689
reward_max: 3688.4421939607287
reward_min: 570.537064244345
total_envstep_count: 5895735
total_train_sample_count: 4480274
total_episode_count: 17412
total_duration: 1347.9261112214413
[2023-06-29 10:59:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2331
train_sample_count: 2331
avg_envstep_per_episode: 291.375
avg_sample_per_episode: 291.375
avg_envstep_per_sec: 2679.8835002483816
avg_train_sample_per_sec: 2679.8835002483816
avg_episode_per_sec: 9.197369370221816
collect_time: 0.8698139302637425
reward_mean: 1860.7172562367377
reward_std: 734.9433594312527
reward_max: 3439.171269894323
reward_min: 1284.514924845772
total_envstep_count: 5900135
total_train_sample_count: 4483805
total_episode_count: 17420
total_duration: 1348.795925151705
[2023-06-29 10:59:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2772
train_sample_count: 2772
avg_envstep_per_episode: 308.0
avg_sample_per_episode: 308.0
avg_envstep_per_sec: 2538.94344468985
avg_train_sample_per_sec: 2538.94344468985
avg_episode_per_sec: 8.243322872369642
collect_time: 1.0917927320506422
reward_mean: 2087.285009668658
reward_std: 847.4360154362678
reward_max: 3714.0672571086247
reward_min: 1150.204915707023
total_envstep_count: 5905015
total_train_sample_count: 4487377
total_episode_count: 17429
total_duration: 1349.8877178837556
[2023-06-29 10:59:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1664
train_sample_count: 1664
avg_envstep_per_episode: 208.0
avg_sample_per_episode: 208.0
avg_envstep_per_sec: 2707.996624932917
avg_train_sample_per_sec: 2707.996624932917
avg_episode_per_sec: 13.019214542946715
collect_time: 0.6144763936111705
reward_mean: 1619.9837630748789
reward_std: 456.30715602822926
reward_max: 2480.2118378781593
reward_min: 992.3509738561356
total_envstep_count: 5909063
total_train_sample_count: 4490641
total_episode_count: 17437
total_duration: 1350.5021942773667
[2023-06-29 10:59:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1791
train_sample_count: 1791
avg_envstep_per_episode: 223.875
avg_sample_per_episode: 223.875
avg_envstep_per_sec: 2703.637953666019
avg_train_sample_per_sec: 2703.637953666019
avg_episode_per_sec: 12.076551440160888
collect_time: 0.6624407671047374
reward_mean: 1934.0727412431906
reward_std: 771.4632451616355
reward_max: 3672.094867594864
reward_min: 1250.5864350008462
total_envstep_count: 5914039
total_train_sample_count: 4494032
total_episode_count: 17445
total_duration: 1351.1646350444714
[2023-06-29 10:59:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 214.6
avg_sample_per_episode: 214.6
avg_envstep_per_sec: 2623.6978296418206
avg_train_sample_per_sec: 2623.6978296418206
avg_episode_per_sec: 12.22599175042787
collect_time: 0.8179295556657016
reward_mean: 1792.7312182167734
reward_std: 828.6398163748003
reward_max: 3511.639653226699
reward_min: 685.5630066187723
total_envstep_count: 5918063
total_train_sample_count: 4497378
total_episode_count: 17455
total_duration: 1351.982564600137
[2023-06-29 10:59:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1654
train_sample_count: 1654
avg_envstep_per_episode: 236.28571428571428
avg_sample_per_episode: 236.28571428571428
avg_envstep_per_sec: 2518.530410529565
avg_train_sample_per_sec: 2518.530410529565
avg_episode_per_sec: 10.658834869230324
collect_time: 0.6567321931412444
reward_mean: 1773.9631538428116
reward_std: 741.2477507146585
reward_max: 3492.6260431661453
reward_min: 1046.3504020968342
total_envstep_count: 5922135
total_train_sample_count: 4500632
total_episode_count: 17462
total_duration: 1352.6392967932784
[2023-06-29 10:59:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3155
train_sample_count: 3155
avg_envstep_per_episode: 262.9166666666667
avg_sample_per_episode: 262.9166666666667
avg_envstep_per_sec: 2533.5574123101233
avg_train_sample_per_sec: 2533.5574123101233
avg_episode_per_sec: 9.636351488976697
collect_time: 1.2452845886461437
reward_mean: 1745.1160739621146
reward_std: 728.872903888455
reward_max: 3290.8892817826845
reward_min: 879.6752284166653
total_envstep_count: 5927319
total_train_sample_count: 4504187
total_episode_count: 17474
total_duration: 1353.8845813819246
[2023-06-29 10:59:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2976
train_sample_count: 2976
avg_envstep_per_episode: 248.0
avg_sample_per_episode: 248.0
avg_envstep_per_sec: 2647.0694985024707
avg_train_sample_per_sec: 2647.0694985024707
avg_episode_per_sec: 10.673667332671252
collect_time: 1.1242621327787636
reward_mean: 1488.591692275073
reward_std: 287.00361224653875
reward_max: 1953.266105930464
reward_min: 1155.6957600591993
total_envstep_count: 5931895
total_train_sample_count: 4507563
total_episode_count: 17486
total_duration: 1355.0088435147034
[2023-06-29 10:59:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2868
train_sample_count: 2868
avg_envstep_per_episode: 286.8
avg_sample_per_episode: 286.8
avg_envstep_per_sec: 2702.9605841323782
avg_train_sample_per_sec: 2702.9605841323782
avg_episode_per_sec: 9.424548759178446
collect_time: 1.0610587578807027
reward_mean: 1584.9803585286966
reward_std: 373.2897822401381
reward_max: 2492.846243859993
reward_min: 1076.4140389069082
total_envstep_count: 5936319
total_train_sample_count: 4510831
total_episode_count: 17496
total_duration: 1356.0699022725842
[2023-06-29 10:59:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3480
train_sample_count: 3480
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 2494.446030548196
avg_train_sample_per_sec: 2494.446030548196
avg_episode_per_sec: 8.60153803637309
collect_time: 1.3950993356369439
reward_mean: 1470.539329647682
reward_std: 270.1503391797045
reward_max: 1996.40187980275
reward_min: 1090.4545821302293
total_envstep_count: 5940927
total_train_sample_count: 4514311
total_episode_count: 17508
total_duration: 1357.4650016082212
[2023-06-29 10:59:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2607
train_sample_count: 2607
avg_envstep_per_episode: 325.875
avg_sample_per_episode: 325.875
avg_envstep_per_sec: 2549.683925225653
avg_train_sample_per_sec: 2549.683925225653
avg_episode_per_sec: 7.824116379672123
collect_time: 1.0224796784445642
reward_mean: 1631.5393719127535
reward_std: 451.1769455805121
reward_max: 2331.296423341551
reward_min: 901.4007262316028
total_envstep_count: 5945831
total_train_sample_count: 4517718
total_episode_count: 17516
total_duration: 1358.4874812866658
[2023-06-29 10:59:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1357
train_sample_count: 1357
avg_envstep_per_episode: 150.77777777777777
avg_sample_per_episode: 150.77777777777777
avg_envstep_per_sec: 2624.536895604342
avg_train_sample_per_sec: 2624.536895604342
avg_episode_per_sec: 17.40665590305017
collect_time: 0.5170435981573537
reward_mean: 1440.1494653513773
reward_std: 256.42107610207984
reward_max: 1937.9881294303068
reward_min: 1018.3359422918935
total_envstep_count: 5950103
total_train_sample_count: 4521075
total_episode_count: 17525
total_duration: 1359.0045248848232
[2023-06-29 10:59:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2341
train_sample_count: 2341
avg_envstep_per_episode: 212.8181818181818
avg_sample_per_episode: 212.8181818181818
avg_envstep_per_sec: 2659.770512950495
avg_train_sample_per_sec: 2659.770512950495
avg_episode_per_sec: 12.497853755854523
collect_time: 0.8801511215353384
reward_mean: 1661.3701699051633
reward_std: 725.4549102973431
reward_max: 3623.30478781962
reward_min: 611.2729451981724
total_envstep_count: 5954351
total_train_sample_count: 4524616
total_episode_count: 17536
total_duration: 1359.8846760063586
[2023-06-29 10:59:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 457
train_sample_count: 457
avg_envstep_per_episode: 114.25
avg_sample_per_episode: 114.25
avg_envstep_per_sec: 2528.194693914172
avg_train_sample_per_sec: 2528.194693914172
avg_episode_per_sec: 22.128618765113103
collect_time: 0.18076139511726796
reward_mean: 1979.2942928169682
reward_std: 248.24983362681562
reward_max: 2374.0179307179956
reward_min: 1710.6405957692125
total_envstep_count: 5958263
total_train_sample_count: 4527873
total_episode_count: 17540
total_duration: 1360.065437401476
[2023-06-29 10:59:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 2499.0295638441235
avg_train_sample_per_sec: 2499.0295638441235
avg_episode_per_sec: 11.057652937363377
collect_time: 0.90435104598105
reward_mean: 1878.0301581633794
reward_std: 1152.9575624888412
reward_max: 3594.1361742294453
reward_min: 423.7150937832971
total_envstep_count: 5962463
total_train_sample_count: 4531333
total_episode_count: 17550
total_duration: 1360.969788447457
[2023-06-29 10:59:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 177.57142857142858
avg_sample_per_episode: 177.57142857142858
avg_envstep_per_sec: 2742.9728038186036
avg_train_sample_per_sec: 2742.9728038186036
avg_episode_per_sec: 15.447151751190848
collect_time: 0.45315797454118734
reward_mean: 1462.2729955639097
reward_std: 939.143088260505
reward_max: 3503.838312188039
reward_min: 562.9046428234288
total_envstep_count: 5966399
total_train_sample_count: 4534576
total_episode_count: 17557
total_duration: 1361.4229464219982
[2023-06-29 10:59:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2608
train_sample_count: 2608
avg_envstep_per_episode: 289.77777777777777
avg_sample_per_episode: 289.77777777777777
avg_envstep_per_sec: 2704.22080707626
avg_train_sample_per_sec: 2704.22080707626
avg_episode_per_sec: 9.332050331168075
collect_time: 0.9644182875804836
reward_mean: 2112.4182440079035
reward_std: 980.2600057823904
reward_max: 3307.8601294352725
reward_min: 557.4396955232303
total_envstep_count: 5971055
total_train_sample_count: 4537984
total_episode_count: 17566
total_duration: 1362.3873647095786
[2023-06-29 11:00:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2535
train_sample_count: 2535
avg_envstep_per_episode: 253.5
avg_sample_per_episode: 253.5
avg_envstep_per_sec: 2564.2889891167133
avg_train_sample_per_sec: 2564.2889891167133
avg_episode_per_sec: 10.115538418606365
collect_time: 0.9885781246805563
reward_mean: 1699.134629817951
reward_std: 855.182010617482
reward_max: 3459.3643558407302
reward_min: 541.5407577463502
total_envstep_count: 5975719
total_train_sample_count: 4541319
total_episode_count: 17576
total_duration: 1363.3759428342591
[2023-06-29 11:00:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 251.75
avg_sample_per_episode: 251.75
avg_envstep_per_sec: 2476.299302379256
avg_train_sample_per_sec: 2476.299302379256
avg_episode_per_sec: 9.836342809848087
collect_time: 0.8133104096362368
reward_mean: 1703.9986113840655
reward_std: 918.1674933814212
reward_max: 3422.0975495809794
reward_min: 260.1417153509589
total_envstep_count: 5980287
total_train_sample_count: 4544533
total_episode_count: 17584
total_duration: 1364.1892532438953
[2023-06-29 11:00:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1057
train_sample_count: 1057
avg_envstep_per_episode: 176.16666666666666
avg_sample_per_episode: 176.16666666666666
avg_envstep_per_sec: 2626.29545071433
avg_train_sample_per_sec: 2626.29545071433
avg_episode_per_sec: 14.90801580348721
collect_time: 0.40246804665960373
reward_mean: 1837.9628063546281
reward_std: 877.9598493906723
reward_max: 3496.554177566133
reward_min: 741.114634796208
total_envstep_count: 5984231
total_train_sample_count: 4547990
total_episode_count: 17590
total_duration: 1364.591721290555
[2023-06-29 11:00:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 242.7
avg_sample_per_episode: 242.7
avg_envstep_per_sec: 2637.926079143169
avg_train_sample_per_sec: 2637.926079143169
avg_episode_per_sec: 10.86908149626357
collect_time: 0.9200409439783543
reward_mean: 2135.176374324444
reward_std: 867.5463087014143
reward_max: 3399.668293459911
reward_min: 588.4748887752514
total_envstep_count: 5988735
total_train_sample_count: 4551217
total_episode_count: 17600
total_duration: 1365.5117622345333
[2023-06-29 11:00:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1380
train_sample_count: 1380
avg_envstep_per_episode: 153.33333333333334
avg_sample_per_episode: 153.33333333333334
avg_envstep_per_sec: 2545.613343392565
avg_train_sample_per_sec: 2545.613343392565
avg_episode_per_sec: 16.60182615256021
collect_time: 0.5421090377224609
reward_mean: 1205.8842909743444
reward_std: 833.3261589428204
reward_max: 2511.2344655430584
reward_min: 250.74802247890267
total_envstep_count: 5992999
total_train_sample_count: 4554597
total_episode_count: 17609
total_duration: 1366.0538712722557
[2023-06-29 11:00:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 234.88888888888889
avg_sample_per_episode: 234.88888888888889
avg_envstep_per_sec: 2431.263951065442
avg_train_sample_per_sec: 2431.263951065442
avg_episode_per_sec: 10.35069799412913
collect_time: 0.8695065786968919
reward_mean: 1778.8329603433438
reward_std: 829.0630159848898
reward_max: 3535.1725076116404
reward_min: 695.8863764405083
total_envstep_count: 5997247
total_train_sample_count: 4557911
total_episode_count: 17618
total_duration: 1366.9233778509526
[2023-06-29 11:00:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1993
train_sample_count: 1993
avg_envstep_per_episode: 284.7142857142857
avg_sample_per_episode: 284.7142857142857
avg_envstep_per_sec: 2731.0796189994408
avg_train_sample_per_sec: 2731.0796189994408
avg_episode_per_sec: 9.592351898141539
collect_time: 0.7297480403482913
reward_mean: 2256.6787502338875
reward_std: 785.0114799261329
reward_max: 3433.5817824939018
reward_min: 1409.4730492730166
total_envstep_count: 6002727
total_train_sample_count: 4561504
total_episode_count: 17625
total_duration: 1367.653125891301
[2023-06-29 11:00:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2045
train_sample_count: 2045
avg_envstep_per_episode: 227.22222222222223
avg_sample_per_episode: 227.22222222222223
avg_envstep_per_sec: 2610.329613149022
avg_train_sample_per_sec: 2610.329613149022
avg_episode_per_sec: 11.48800318745291
collect_time: 0.7834259664751588
reward_mean: 2124.1622264705256
reward_std: 825.4213609997348
reward_max: 3499.3994720447754
reward_min: 891.745508547283
total_envstep_count: 6007391
total_train_sample_count: 4564749
total_episode_count: 17634
total_duration: 1368.436551857776
[2023-06-29 11:00:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2393
train_sample_count: 2393
avg_envstep_per_episode: 265.8888888888889
avg_sample_per_episode: 265.8888888888889
avg_envstep_per_sec: 2543.1325327645513
avg_train_sample_per_sec: 2543.1325327645513
avg_episode_per_sec: 9.564643875838263
collect_time: 0.9409655097285285
reward_mean: 2040.2390365205856
reward_std: 834.0981442778431
reward_max: 3508.3042426520706
reward_min: 647.781690038632
total_envstep_count: 6012287
total_train_sample_count: 4568342
total_episode_count: 17643
total_duration: 1369.3775173675047
[2023-06-29 11:00:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1463
train_sample_count: 1463
avg_envstep_per_episode: 209.0
avg_sample_per_episode: 209.0
avg_envstep_per_sec: 2692.9140516864472
avg_train_sample_per_sec: 2692.9140516864472
avg_episode_per_sec: 12.88475622816482
collect_time: 0.543277643444948
reward_mean: 1790.7857192333843
reward_std: 574.4755971733756
reward_max: 2898.542862301407
reward_min: 1271.3378836933855
total_envstep_count: 6016663
total_train_sample_count: 4571805
total_episode_count: 17650
total_duration: 1369.9207950109496
[2023-06-29 11:00:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2206
train_sample_count: 2206
avg_envstep_per_episode: 245.11111111111111
avg_sample_per_episode: 245.11111111111111
avg_envstep_per_sec: 2699.1621744317445
avg_train_sample_per_sec: 2699.1621744317445
avg_episode_per_sec: 11.011994365315369
collect_time: 0.8172906470373273
reward_mean: 2157.607261635895
reward_std: 860.1457120297388
reward_max: 3445.3154404704487
reward_min: 1085.285189849625
total_envstep_count: 6021319
total_train_sample_count: 4575211
total_episode_count: 17659
total_duration: 1370.7380856579869
[2023-06-29 11:00:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3195
train_sample_count: 3195
avg_envstep_per_episode: 266.25
avg_sample_per_episode: 266.25
avg_envstep_per_sec: 2699.5362392907764
avg_train_sample_per_sec: 2699.5362392907764
avg_episode_per_sec: 10.139103246162541
collect_time: 1.1835366214010863
reward_mean: 1657.9204863479745
reward_std: 775.2030508542977
reward_max: 3163.825070971154
reward_min: 649.0822269760563
total_envstep_count: 6026943
total_train_sample_count: 4578806
total_episode_count: 17671
total_duration: 1371.921622279388
[2023-06-29 11:00:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2523
train_sample_count: 2523
avg_envstep_per_episode: 210.25
avg_sample_per_episode: 210.25
avg_envstep_per_sec: 2643.9564414430733
avg_train_sample_per_sec: 2643.9564414430733
avg_episode_per_sec: 12.575298175710218
collect_time: 0.9542517268639058
reward_mean: 1425.4226094861515
reward_std: 375.5239195110361
reward_max: 2304.3944828452095
reward_min: 1033.2477907902273
total_envstep_count: 6031007
total_train_sample_count: 4582129
total_episode_count: 17683
total_duration: 1372.875874006252
[2023-06-29 11:00:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3554
train_sample_count: 3554
avg_envstep_per_episode: 273.38461538461536
avg_sample_per_episode: 273.38461538461536
avg_envstep_per_sec: 2552.880680382471
avg_train_sample_per_sec: 2552.880680382471
avg_episode_per_sec: 9.33805538688017
collect_time: 1.3921528049902991
reward_mean: 1378.9539108321578
reward_std: 390.80641193548416
reward_max: 2582.092944913706
reward_min: 946.9397241575223
total_envstep_count: 6035999
total_train_sample_count: 4585683
total_episode_count: 17696
total_duration: 1374.2680268112422
[2023-06-29 11:00:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2780
train_sample_count: 2780
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2568.8175813119597
avg_train_sample_per_sec: 2568.8175813119597
avg_episode_per_sec: 9.240351011913525
collect_time: 1.0822099709315225
reward_mean: 1480.6438273741526
reward_std: 270.95845148775743
reward_max: 1972.9833279971986
reward_min: 1196.0258654728489
total_envstep_count: 6041223
total_train_sample_count: 4589263
total_episode_count: 17706
total_duration: 1375.3502367821736
[2023-06-29 11:00:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2537
train_sample_count: 2537
avg_envstep_per_episode: 211.41666666666666
avg_sample_per_episode: 211.41666666666666
avg_envstep_per_sec: 2518.246986103748
avg_train_sample_per_sec: 2518.246986103748
avg_episode_per_sec: 11.911298318188795
collect_time: 1.007446852512774
reward_mean: 1464.8466697420208
reward_std: 427.33751770705805
reward_max: 2500.1770955582497
reward_min: 609.0351141057466
total_envstep_count: 6045727
total_train_sample_count: 4592600
total_episode_count: 17718
total_duration: 1376.3576836346865
[2023-06-29 11:00:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3263
train_sample_count: 3263
avg_envstep_per_episode: 271.9166666666667
avg_sample_per_episode: 271.9166666666667
avg_envstep_per_sec: 2606.5424733994
avg_train_sample_per_sec: 2606.5424733994
avg_episode_per_sec: 9.585813570577015
collect_time: 1.2518499250635504
reward_mean: 1522.0442402982244
reward_std: 431.0073607570891
reward_max: 2588.849649256689
reward_min: 875.8150400015376
total_envstep_count: 6050567
total_train_sample_count: 4595863
total_episode_count: 17730
total_duration: 1377.6095335597502
[2023-06-29 11:00:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2265
train_sample_count: 2265
avg_envstep_per_episode: 251.66666666666666
avg_sample_per_episode: 251.66666666666666
avg_envstep_per_sec: 2389.7089515914354
avg_train_sample_per_sec: 2389.7089515914354
avg_episode_per_sec: 9.495532257979214
collect_time: 0.9478141672824278
reward_mean: 1506.0249184128302
reward_std: 261.9316356041945
reward_max: 1962.4681101978742
reward_min: 1246.898647637186
total_envstep_count: 6055111
total_train_sample_count: 4599328
total_episode_count: 17739
total_duration: 1378.5573477270325
[2023-06-29 11:00:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2578
train_sample_count: 2578
avg_envstep_per_episode: 257.8
avg_sample_per_episode: 257.8
avg_envstep_per_sec: 2494.8125013118565
avg_train_sample_per_sec: 2494.8125013118565
avg_episode_per_sec: 9.677317693218994
collect_time: 1.0333441886492074
reward_mean: 1639.3584514770723
reward_std: 736.324681921986
reward_max: 2925.5999664804376
reward_min: 250.90495004145734
total_envstep_count: 6060175
total_train_sample_count: 4602706
total_episode_count: 17749
total_duration: 1379.5906919156816
[2023-06-29 11:01:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 230.7
avg_sample_per_episode: 230.7
avg_envstep_per_sec: 2621.5572575640967
avg_train_sample_per_sec: 2621.5572575640967
avg_episode_per_sec: 11.363490496593398
collect_time: 0.8800112960888072
reward_mean: 1771.054620496987
reward_std: 896.8232503888551
reward_max: 3516.239643959447
reward_min: 251.48206486629596
total_envstep_count: 6065191
total_train_sample_count: 4606213
total_episode_count: 17759
total_duration: 1380.4707032117703
[2023-06-29 11:01:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 293.45454545454544
avg_sample_per_episode: 293.45454545454544
avg_envstep_per_sec: 2609.2874082898393
avg_train_sample_per_sec: 2609.2874082898393
avg_episode_per_sec: 8.891623758112836
collect_time: 1.237119372034096
reward_mean: 1904.2514344951646
reward_std: 682.939205400086
reward_max: 2821.4832507334827
reward_min: 571.7305353088846
total_envstep_count: 6069879
total_train_sample_count: 4609441
total_episode_count: 17770
total_duration: 1381.7078225838045
[2023-06-29 11:01:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3035
train_sample_count: 3035
avg_envstep_per_episode: 303.5
avg_sample_per_episode: 303.5
avg_envstep_per_sec: 2486.313540921159
avg_train_sample_per_sec: 2486.313540921159
avg_episode_per_sec: 8.19213687288685
collect_time: 1.220682729691267
reward_mean: 1560.118701671177
reward_std: 416.49243388606266
reward_max: 2334.6019434668833
reward_min: 879.2131612999319
total_envstep_count: 6074703
total_train_sample_count: 4612876
total_episode_count: 17780
total_duration: 1382.9285053134959
[2023-06-29 11:01:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2288
train_sample_count: 2288
avg_envstep_per_episode: 254.22222222222223
avg_sample_per_episode: 254.22222222222223
avg_envstep_per_sec: 2464.116606648601
avg_train_sample_per_sec: 2464.116606648601
avg_episode_per_sec: 9.692766372306561
collect_time: 0.9285274868188425
reward_mean: 1537.278577857338
reward_std: 364.03261812369993
reward_max: 1982.2370566427662
reward_min: 702.8415394530928
total_envstep_count: 6079479
total_train_sample_count: 4616364
total_episode_count: 17789
total_duration: 1383.8570328003148
[2023-06-29 11:01:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2991
train_sample_count: 2991
avg_envstep_per_episode: 249.25
avg_sample_per_episode: 249.25
avg_envstep_per_sec: 2348.170077270766
avg_train_sample_per_sec: 2348.170077270766
avg_episode_per_sec: 9.42094313849856
collect_time: 1.2737578205903992
reward_mean: 1663.8098064124354
reward_std: 456.3939511842235
reward_max: 2742.8680897641057
reward_min: 1177.335212457186
total_envstep_count: 6084719
total_train_sample_count: 4619755
total_episode_count: 17801
total_duration: 1385.1307906209051
[2023-06-29 11:01:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2612
train_sample_count: 2612
avg_envstep_per_episode: 217.66666666666666
avg_sample_per_episode: 217.66666666666666
avg_envstep_per_sec: 2385.440182883859
avg_train_sample_per_sec: 2385.440182883859
avg_episode_per_sec: 10.959143259803334
collect_time: 1.0949761049309747
reward_mean: 1415.9899839943776
reward_std: 420.0822183093289
reward_max: 2670.508210876308
reward_min: 881.7311424462587
total_envstep_count: 6088959
total_train_sample_count: 4623167
total_episode_count: 17813
total_duration: 1386.2257667258361
[2023-06-29 11:01:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3054
train_sample_count: 3054
avg_envstep_per_episode: 277.6363636363636
avg_sample_per_episode: 277.6363636363636
avg_envstep_per_sec: 2677.812715717339
avg_train_sample_per_sec: 2677.812715717339
avg_episode_per_sec: 9.645035976716022
collect_time: 1.1404830450145529
reward_mean: 1472.4101706223034
reward_std: 438.1642727802522
reward_max: 2471.2952736041025
reward_min: 896.5954676324715
total_envstep_count: 6093447
total_train_sample_count: 4626621
total_episode_count: 17824
total_duration: 1387.3662497708508
[2023-06-29 11:01:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3266
train_sample_count: 3266
avg_envstep_per_episode: 272.1666666666667
avg_sample_per_episode: 272.1666666666667
avg_envstep_per_sec: 2477.433248132287
avg_train_sample_per_sec: 2477.433248132287
avg_episode_per_sec: 9.102632877399708
collect_time: 1.3182998986802996
reward_mean: 1281.2947754523582
reward_std: 580.8402973489297
reward_max: 2812.669532245719
reward_min: 582.8439105503558
total_envstep_count: 6098151
total_train_sample_count: 4629887
total_episode_count: 17836
total_duration: 1388.6845496695312
[2023-06-29 11:01:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2192
train_sample_count: 2192
avg_envstep_per_episode: 219.2
avg_sample_per_episode: 219.2
avg_envstep_per_sec: 2276.876917822331
avg_train_sample_per_sec: 2276.876917822331
avg_episode_per_sec: 10.38721221634275
collect_time: 0.9627222195640204
reward_mean: 1223.220705190424
reward_std: 387.1472347424609
reward_max: 1937.844853445161
reward_min: 508.0611849675871
total_envstep_count: 6103015
total_train_sample_count: 4633279
total_episode_count: 17846
total_duration: 1389.6472718890952
[2023-06-29 11:01:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2026
train_sample_count: 2026
avg_envstep_per_episode: 253.25
avg_sample_per_episode: 253.25
avg_envstep_per_sec: 2355.7967287067863
avg_train_sample_per_sec: 2355.7967287067863
avg_episode_per_sec: 9.302257566463126
collect_time: 0.8600062880264596
reward_mean: 1665.0595379606775
reward_std: 614.1966302246198
reward_max: 2607.5969771882365
reward_min: 797.2247665758396
total_envstep_count: 6107151
total_train_sample_count: 4636505
total_episode_count: 17854
total_duration: 1390.5072781771216
[2023-06-29 11:01:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2600
train_sample_count: 2600
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 2684.1310914426385
avg_train_sample_per_sec: 2684.1310914426385
avg_episode_per_sec: 10.323581120933225
collect_time: 0.9686561167929317
reward_mean: 1927.680862399776
reward_std: 826.6031970656744
reward_max: 3519.8661180979248
reward_min: 1209.6491538006687
total_envstep_count: 6111799
total_train_sample_count: 4639905
total_episode_count: 17864
total_duration: 1391.4759342939146
[2023-06-29 11:01:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 269.25
avg_sample_per_episode: 269.25
avg_envstep_per_sec: 2660.2306605682115
avg_train_sample_per_sec: 2660.2306605682115
avg_episode_per_sec: 9.880151014180916
collect_time: 1.2145563344908878
reward_mean: 1530.2905877026376
reward_std: 356.21562840764506
reward_max: 2450.2005418624476
reward_min: 995.5563147456119
total_envstep_count: 6115919
total_train_sample_count: 4643136
total_episode_count: 17876
total_duration: 1392.6904906284055
[2023-06-29 11:01:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2975
train_sample_count: 2975
avg_envstep_per_episode: 330.55555555555554
avg_sample_per_episode: 330.55555555555554
avg_envstep_per_sec: 2455.0749239422403
avg_train_sample_per_sec: 2455.0749239422403
avg_episode_per_sec: 7.427117416968122
collect_time: 1.2117756452104074
reward_mean: 1470.4484675642675
reward_std: 425.34294302480976
reward_max: 2071.8944753546166
reward_min: 495.4107026169211
total_envstep_count: 6120567
total_train_sample_count: 4646511
total_episode_count: 17885
total_duration: 1393.9022662736159
[2023-06-29 11:01:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1649
train_sample_count: 1649
avg_envstep_per_episode: 329.8
avg_sample_per_episode: 329.8
avg_envstep_per_sec: 2640.124623008991
avg_train_sample_per_sec: 2640.124623008991
avg_episode_per_sec: 8.005229299602762
collect_time: 0.6245917278407143
reward_mean: 1877.9964705085786
reward_std: 941.4439318426367
reward_max: 3407.847166295981
reward_min: 895.313491450819
total_envstep_count: 6125095
total_train_sample_count: 4649760
total_episode_count: 17890
total_duration: 1394.5268580014565
[2023-06-29 11:01:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 557
train_sample_count: 557
avg_envstep_per_episode: 111.4
avg_sample_per_episode: 111.4
avg_envstep_per_sec: 2681.380073072056
avg_train_sample_per_sec: 2681.380073072056
avg_episode_per_sec: 24.069839076050773
collect_time: 0.20772885037586086
reward_mean: 2405.6449759505404
reward_std: 877.8853360684949
reward_max: 3437.1687147599373
reward_min: 1281.196614587505
total_envstep_count: 6129663
total_train_sample_count: 4653117
total_episode_count: 17895
total_duration: 1394.7345868518323
[2023-06-29 11:01:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1868
train_sample_count: 1868
avg_envstep_per_episode: 186.8
avg_sample_per_episode: 186.8
avg_envstep_per_sec: 2689.5647178598756
avg_train_sample_per_sec: 2689.5647178598756
avg_episode_per_sec: 14.398098061348371
collect_time: 0.6945361781390387
reward_mean: 2227.8465344214633
reward_std: 1007.9827766825459
reward_max: 3483.2461900494695
reward_min: 247.65632933303428
total_envstep_count: 6133879
total_train_sample_count: 4656585
total_episode_count: 17905
total_duration: 1395.4291230299714
[2023-06-29 11:01:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 366.1666666666667
avg_sample_per_episode: 366.1666666666667
avg_envstep_per_sec: 2369.818428323088
avg_train_sample_per_sec: 2369.818428323088
avg_episode_per_sec: 6.4719665771226795
collect_time: 0.9270752449817954
reward_mean: 2239.467351865988
reward_std: 902.2903892444879
reward_max: 3523.4948947821545
reward_min: 730.1478925413905
total_envstep_count: 6138575
total_train_sample_count: 4659982
total_episode_count: 17911
total_duration: 1396.3561982749532
[2023-06-29 11:01:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2477
train_sample_count: 2477
avg_envstep_per_episode: 225.1818181818182
avg_sample_per_episode: 225.1818181818182
avg_envstep_per_sec: 2413.5287711760034
avg_train_sample_per_sec: 2413.5287711760034
avg_episode_per_sec: 10.718133420644344
collect_time: 1.0262981032511453
reward_mean: 1589.8442579691487
reward_std: 896.9029428195865
reward_max: 3433.258665781083
reward_min: 620.8614172016402
total_envstep_count: 6142463
total_train_sample_count: 4663259
total_episode_count: 17922
total_duration: 1397.3824963782042
[2023-06-29 11:02:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2455
train_sample_count: 2455
avg_envstep_per_episode: 306.875
avg_sample_per_episode: 306.875
avg_envstep_per_sec: 2507.3814748504733
avg_train_sample_per_sec: 2507.3814748504733
avg_episode_per_sec: 8.170693197068752
collect_time: 0.9791090923435984
reward_mean: 1917.8643369124009
reward_std: 937.3115201886501
reward_max: 3408.179787822688
reward_min: 468.16881109709976
total_envstep_count: 6146575
total_train_sample_count: 4666514
total_episode_count: 17930
total_duration: 1398.3616054705478
[2023-06-29 11:02:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2074
train_sample_count: 2074
avg_envstep_per_episode: 345.6666666666667
avg_sample_per_episode: 345.6666666666667
avg_envstep_per_sec: 2428.5786511492684
avg_train_sample_per_sec: 2428.5786511492684
avg_episode_per_sec: 7.025782018753911
collect_time: 0.8539974602092988
reward_mean: 2075.5906447626835
reward_std: 478.33822252040795
reward_max: 2654.9707314103043
reward_min: 1199.3074028002693
total_envstep_count: 6150975
total_train_sample_count: 4669788
total_episode_count: 17936
total_duration: 1399.215602930757
[2023-06-29 11:02:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1668
train_sample_count: 1668
avg_envstep_per_episode: 238.28571428571428
avg_sample_per_episode: 238.28571428571428
avg_envstep_per_sec: 2502.1940417445753
avg_train_sample_per_sec: 2502.1940417445753
avg_episode_per_sec: 10.500814323868122
collect_time: 0.6666149675734341
reward_mean: 2057.3065544545816
reward_std: 646.2140300731235
reward_max: 3481.5907524725967
reward_min: 1545.3959392752884
total_envstep_count: 6155575
total_train_sample_count: 4673056
total_episode_count: 17943
total_duration: 1399.8822178983305
[2023-06-29 11:02:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2566
train_sample_count: 2566
avg_envstep_per_episode: 285.1111111111111
avg_sample_per_episode: 285.1111111111111
avg_envstep_per_sec: 2453.493708759502
avg_train_sample_per_sec: 2453.493708759502
avg_episode_per_sec: 8.605394925500983
collect_time: 1.045855545029044
reward_mean: 1998.1274453761314
reward_std: 937.7994136298468
reward_max: 3571.24582210136
reward_min: 798.5045363181066
total_envstep_count: 6159839
total_train_sample_count: 4676422
total_episode_count: 17952
total_duration: 1400.9280734433596
[2023-06-29 11:02:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2769
train_sample_count: 2769
avg_envstep_per_episode: 276.9
avg_sample_per_episode: 276.9
avg_envstep_per_sec: 2580.0907318910176
avg_train_sample_per_sec: 2580.0907318910176
avg_episode_per_sec: 9.317770790505662
collect_time: 1.0732180716646835
reward_mean: 1633.659489113868
reward_std: 732.1323132326296
reward_max: 3669.9619958409435
reward_min: 878.5033201965703
total_envstep_count: 6164871
total_train_sample_count: 4679991
total_episode_count: 17962
total_duration: 1402.0012915150244
[2023-06-29 11:02:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2462
train_sample_count: 2462
avg_envstep_per_episode: 246.2
avg_sample_per_episode: 246.2
avg_envstep_per_sec: 2594.8096864668
avg_train_sample_per_sec: 2594.8096864668
avg_episode_per_sec: 10.539438206607636
collect_time: 0.9488171763966092
reward_mean: 1673.3174190297552
reward_std: 675.4002113172656
reward_max: 3202.9972546916865
reward_min: 907.146986855796
total_envstep_count: 6169215
total_train_sample_count: 4683253
total_episode_count: 17972
total_duration: 1402.950108691421
[2023-06-29 11:02:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1791
train_sample_count: 1791
avg_envstep_per_episode: 223.875
avg_sample_per_episode: 223.875
avg_envstep_per_sec: 2323.9619560290553
avg_train_sample_per_sec: 2323.9619560290553
avg_episode_per_sec: 10.380622919169426
collect_time: 0.7706666605938226
reward_mean: 1577.9620517374547
reward_std: 545.919838707138
reward_max: 2567.6163738700143
reward_min: 886.3321152690676
total_envstep_count: 6173519
total_train_sample_count: 4686644
total_episode_count: 17980
total_duration: 1403.720775352015
[2023-06-29 11:02:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2222
train_sample_count: 2222
avg_envstep_per_episode: 246.88888888888889
avg_sample_per_episode: 246.88888888888889
avg_envstep_per_sec: 2432.88652855994
avg_train_sample_per_sec: 2432.88652855994
avg_episode_per_sec: 9.854175858253582
collect_time: 0.9133183869924395
reward_mean: 1748.9061432054002
reward_std: 695.5289901865029
reward_max: 2906.053135837301
reward_min: 876.7239887827607
total_envstep_count: 6178191
total_train_sample_count: 4690066
total_episode_count: 17989
total_duration: 1404.6340937390073
[2023-06-29 11:02:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 256.3333333333333
avg_sample_per_episode: 256.3333333333333
avg_envstep_per_sec: 2348.341179316619
avg_train_sample_per_sec: 2348.341179316619
avg_episode_per_sec: 9.161278983029723
collect_time: 0.9823955821748824
reward_mean: 1782.5075364468355
reward_std: 515.4552600649911
reward_max: 2500.734944227615
reward_min: 857.2878451288328
total_envstep_count: 6183183
total_train_sample_count: 4693573
total_episode_count: 17998
total_duration: 1405.6164893211821
[2023-06-29 11:02:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1603
train_sample_count: 1603
avg_envstep_per_episode: 267.1666666666667
avg_sample_per_episode: 267.1666666666667
avg_envstep_per_sec: 2310.330939607457
avg_train_sample_per_sec: 2310.330939607457
avg_episode_per_sec: 8.647526910570644
collect_time: 0.6938399917166681
reward_mean: 2388.3766672527267
reward_std: 1013.4768832545021
reward_max: 3464.655732132367
reward_min: 851.3258406111775
total_envstep_count: 6187255
total_train_sample_count: 4696776
total_episode_count: 18004
total_duration: 1406.3103293128988
[2023-06-29 11:02:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2909
train_sample_count: 2909
avg_envstep_per_episode: 264.45454545454544
avg_sample_per_episode: 264.45454545454544
avg_envstep_per_sec: 2432.9760846555496
avg_train_sample_per_sec: 2432.9760846555496
avg_episode_per_sec: 9.199978319426279
collect_time: 1.1956549915745858
reward_mean: 1808.4060001264659
reward_std: 992.8577537776512
reward_max: 3352.718346152404
reward_min: 338.3259695755367
total_envstep_count: 6191727
total_train_sample_count: 4700085
total_episode_count: 18015
total_duration: 1407.5059843044735
[2023-06-29 11:02:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1515
train_sample_count: 1515
avg_envstep_per_episode: 252.5
avg_sample_per_episode: 252.5
avg_envstep_per_sec: 2600.300379580004
avg_train_sample_per_sec: 2600.300379580004
avg_episode_per_sec: 10.298219325069324
collect_time: 0.5826249966723844
reward_mean: 1649.0667853797856
reward_std: 268.8299530667487
reward_max: 2018.9811443111066
reward_min: 1315.1859356425236
total_envstep_count: 6196303
total_train_sample_count: 4703600
total_episode_count: 18021
total_duration: 1408.0886093011459
[2023-06-29 11:02:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2882
train_sample_count: 2882
avg_envstep_per_episode: 360.25
avg_sample_per_episode: 360.25
avg_envstep_per_sec: 2392.9586913039757
avg_train_sample_per_sec: 2392.9586913039757
avg_episode_per_sec: 6.642494632349689
collect_time: 1.2043667993405833
reward_mean: 2586.423412799096
reward_std: 1145.3126694569387
reward_max: 3552.6478127659366
reward_min: 242.82976809510066
total_envstep_count: 6201103
total_train_sample_count: 4706882
total_episode_count: 18029
total_duration: 1409.2929761004864
[2023-06-29 11:02:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 695
train_sample_count: 695
avg_envstep_per_episode: 173.75
avg_sample_per_episode: 173.75
avg_envstep_per_sec: 2133.2586243871815
avg_train_sample_per_sec: 2133.2586243871815
avg_episode_per_sec: 12.277747478487376
collect_time: 0.3257926591997966
reward_mean: 1507.1036199959228
reward_std: 1212.56795602455
reward_max: 3379.3733328559224
reward_min: 241.28501855402249
total_envstep_count: 6205431
total_train_sample_count: 4710377
total_episode_count: 18033
total_duration: 1409.6187687596862
[2023-06-29 11:02:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2143
train_sample_count: 2143
avg_envstep_per_episode: 267.875
avg_sample_per_episode: 267.875
avg_envstep_per_sec: 2561.661996164461
avg_train_sample_per_sec: 2561.661996164461
avg_episode_per_sec: 9.562900592307834
collect_time: 0.8365662617506456
reward_mean: 2682.7604880743456
reward_std: 1039.3728498293349
reward_max: 3425.3935181880174
reward_min: 242.90565207207493
total_envstep_count: 6209943
total_train_sample_count: 4713720
total_episode_count: 18041
total_duration: 1410.455335021437
[2023-06-29 11:02:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1803
train_sample_count: 1803
avg_envstep_per_episode: 300.5
avg_sample_per_episode: 300.5
avg_envstep_per_sec: 2407.0919382993925
avg_train_sample_per_sec: 2407.0919382993925
avg_episode_per_sec: 8.010289312144401
collect_time: 0.7490366160562264
reward_mean: 2634.843581527494
reward_std: 764.7651601929914
reward_max: 3391.5689319479625
reward_min: 1495.110033277646
total_envstep_count: 6214607
total_train_sample_count: 4717123
total_episode_count: 18047
total_duration: 1411.204371637493
[2023-06-29 11:02:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1354
train_sample_count: 1354
avg_envstep_per_episode: 270.8
avg_sample_per_episode: 270.8
avg_envstep_per_sec: 2617.61740890943
avg_train_sample_per_sec: 2617.61740890943
avg_episode_per_sec: 9.666238585337629
collect_time: 0.5172642859844491
reward_mean: 2539.9886585933527
reward_std: 723.2329640899445
reward_max: 3378.816434645875
reward_min: 1510.902916369674
total_envstep_count: 6219407
total_train_sample_count: 4720477
total_episode_count: 18052
total_duration: 1411.7216359234776
[2023-06-29 11:02:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2209
train_sample_count: 2209
avg_envstep_per_episode: 276.125
avg_sample_per_episode: 276.125
avg_envstep_per_sec: 2703.2661068164402
avg_train_sample_per_sec: 2703.2661068164402
avg_episode_per_sec: 9.790008535324365
collect_time: 0.8171596552887931
reward_mean: 2568.4624931940734
reward_std: 1280.2338585964176
reward_max: 3535.202518623937
reward_min: 256.42640564755607
total_envstep_count: 6223559
total_train_sample_count: 4723886
total_episode_count: 18060
total_duration: 1412.5387955787664
[2023-06-29 11:02:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 558
train_sample_count: 558
avg_envstep_per_episode: 111.6
avg_sample_per_episode: 111.6
avg_envstep_per_sec: 2535.451288928556
avg_train_sample_per_sec: 2535.451288928556
avg_episode_per_sec: 22.71909757104441
collect_time: 0.2200791639881208
reward_mean: 970.7898677676433
reward_std: 824.2062353208709
reward_max: 2594.262857805556
reward_min: 322.21954170568284
total_envstep_count: 6227383
total_train_sample_count: 4727244
total_episode_count: 18065
total_duration: 1412.7588747427546
[2023-06-29 11:03:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 203.6
avg_sample_per_episode: 203.6
avg_envstep_per_sec: 2580.388369365457
avg_train_sample_per_sec: 2580.388369365457
avg_episode_per_sec: 12.673813209064132
collect_time: 0.7890285137584434
reward_mean: 1994.7344536174332
reward_std: 1207.1355903246508
reward_max: 3447.151713627285
reward_min: 241.3718785598823
total_envstep_count: 6231839
total_train_sample_count: 4730480
total_episode_count: 18075
total_duration: 1413.547903256513
[2023-06-29 11:03:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1624
train_sample_count: 1624
avg_envstep_per_episode: 147.63636363636363
avg_sample_per_episode: 147.63636363636363
avg_envstep_per_sec: 2598.2389715784825
avg_train_sample_per_sec: 2598.2389715784825
avg_episode_per_sec: 17.598909290248343
collect_time: 0.6250387349911033
reward_mean: 1038.246143149243
reward_std: 1054.214398446868
reward_max: 3553.7612743380528
reward_min: 235.50502822199894
total_envstep_count: 6236023
total_train_sample_count: 4733704
total_episode_count: 18086
total_duration: 1414.172941991504
[2023-06-29 11:03:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2069
train_sample_count: 2069
avg_envstep_per_episode: 258.625
avg_sample_per_episode: 258.625
avg_envstep_per_sec: 2652.828939145637
avg_train_sample_per_sec: 2652.828939145637
avg_episode_per_sec: 10.257434274125227
collect_time: 0.7799221312273292
reward_mean: 2279.439102656548
reward_std: 1036.6965401398606
reward_max: 3438.11203001299
reward_min: 370.17178909919807
total_envstep_count: 6240759
total_train_sample_count: 4736973
total_episode_count: 18094
total_duration: 1414.9528641227314
[2023-06-29 11:03:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2611
train_sample_count: 2611
avg_envstep_per_episode: 290.1111111111111
avg_sample_per_episode: 290.1111111111111
avg_envstep_per_sec: 2570.34597894647
avg_train_sample_per_sec: 2570.34597894647
avg_episode_per_sec: 8.859867411152138
collect_time: 1.0158165559759365
reward_mean: 2091.488289241735
reward_std: 1052.6167279534463
reward_max: 3442.950561995826
reward_min: 242.23587479510155
total_envstep_count: 6245311
total_train_sample_count: 4740384
total_episode_count: 18103
total_duration: 1415.9686806787074
[2023-06-29 11:03:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1773
train_sample_count: 1773
avg_envstep_per_episode: 253.28571428571428
avg_sample_per_episode: 253.28571428571428
avg_envstep_per_sec: 2662.211602231684
avg_train_sample_per_sec: 2662.211602231684
avg_episode_per_sec: 10.51070570537044
collect_time: 0.6659876316795126
reward_mean: 1675.2244416383066
reward_std: 1273.1272089617144
reward_max: 3402.0618152789407
reward_min: 231.24329891015014
total_envstep_count: 6249919
total_train_sample_count: 4743757
total_episode_count: 18110
total_duration: 1416.6346683103868
[2023-06-29 11:03:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1579
train_sample_count: 1579
avg_envstep_per_episode: 225.57142857142858
avg_sample_per_episode: 225.57142857142858
avg_envstep_per_sec: 2592.378085497683
avg_train_sample_per_sec: 2592.378085497683
avg_episode_per_sec: 11.49249309593653
collect_time: 0.609093252575025
reward_mean: 2398.5968637395677
reward_std: 1266.8910106034762
reward_max: 3525.1016338005948
reward_min: 329.56926125583794
total_envstep_count: 6254879
total_train_sample_count: 4747336
total_episode_count: 18117
total_duration: 1417.243761562962
[2023-06-29 11:03:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2261
train_sample_count: 2261
avg_envstep_per_episode: 226.1
avg_sample_per_episode: 226.1
avg_envstep_per_sec: 2732.5812130441973
avg_train_sample_per_sec: 2732.5812130441973
avg_episode_per_sec: 12.085719650792559
collect_time: 0.8274228005399926
reward_mean: 1842.2017864663135
reward_std: 1287.9441247535979
reward_max: 3582.3509268556236
reward_min: 248.2969508825398
total_envstep_count: 6259431
total_train_sample_count: 4750797
total_episode_count: 18127
total_duration: 1418.071184363502
[2023-06-29 11:03:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 128.25
avg_sample_per_episode: 128.25
avg_envstep_per_sec: 2678.1212057274442
avg_train_sample_per_sec: 2678.1212057274442
avg_episode_per_sec: 20.882036691831924
collect_time: 0.38310439341049646
reward_mean: 1355.351430227971
reward_std: 1107.2320288615479
reward_max: 3354.9468421758284
reward_min: 232.15826571150063
total_envstep_count: 6263743
total_train_sample_count: 4754223
total_episode_count: 18135
total_duration: 1418.4542887569125
[2023-06-29 11:03:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 304.875
avg_sample_per_episode: 304.875
avg_envstep_per_sec: 2521.395528102753
avg_train_sample_per_sec: 2521.395528102753
avg_episode_per_sec: 8.270260034777376
collect_time: 0.9673214586190878
reward_mean: 2466.0879401081957
reward_std: 1104.4701890520175
reward_max: 3478.4919398789034
reward_min: 810.4134865364628
total_envstep_count: 6268271
total_train_sample_count: 4757462
total_episode_count: 18143
total_duration: 1419.4216102155317
[2023-06-29 11:03:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2243
train_sample_count: 2243
avg_envstep_per_episode: 203.9090909090909
avg_sample_per_episode: 203.9090909090909
avg_envstep_per_sec: 2419.7998355048694
avg_train_sample_per_sec: 2419.7998355048694
avg_episode_per_sec: 11.867052247237433
collect_time: 0.9269361734343693
reward_mean: 1452.412519811793
reward_std: 754.2669706089728
reward_max: 3434.66577545216
reward_min: 454.5395603953365
total_envstep_count: 6272591
total_train_sample_count: 4760905
total_episode_count: 18154
total_duration: 1420.348546388966
[2023-06-29 11:03:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2697
train_sample_count: 2697
avg_envstep_per_episode: 269.7
avg_sample_per_episode: 269.7
avg_envstep_per_sec: 2488.785664824446
avg_train_sample_per_sec: 2488.785664824446
avg_episode_per_sec: 9.227977993416559
collect_time: 1.0836610151361672
reward_mean: 1700.8446781230855
reward_std: 984.912404131966
reward_max: 3411.762920472309
reward_min: 245.20224697697955
total_envstep_count: 6277151
total_train_sample_count: 4764402
total_episode_count: 18164
total_duration: 1421.4322074041022
[2023-06-29 11:03:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2018
train_sample_count: 2018
avg_envstep_per_episode: 224.22222222222223
avg_sample_per_episode: 224.22222222222223
avg_envstep_per_sec: 2430.1966933501326
avg_train_sample_per_sec: 2430.1966933501326
avg_episode_per_sec: 10.838340059539739
collect_time: 0.8303854603711516
reward_mean: 1436.6275754930805
reward_std: 753.0990601061291
reward_max: 2994.401644011794
reward_min: 243.342376357349
total_envstep_count: 6280999
total_train_sample_count: 4767620
total_episode_count: 18173
total_duration: 1422.2625928644734
[2023-06-29 11:03:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 326.3333333333333
avg_sample_per_episode: 326.3333333333333
avg_envstep_per_sec: 2695.9748454915625
avg_train_sample_per_sec: 2695.9748454915625
avg_episode_per_sec: 8.261414235418476
collect_time: 1.0894018558487295
reward_mean: 1960.2798205841452
reward_std: 696.6243625460716
reward_max: 3136.102676612659
reward_min: 1203.8373939978342
total_envstep_count: 6285695
total_train_sample_count: 4770957
total_episode_count: 18182
total_duration: 1423.3519947203222
[2023-06-29 11:03:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 156.33333333333334
avg_sample_per_episode: 156.33333333333334
avg_envstep_per_sec: 2423.803885701006
avg_train_sample_per_sec: 2423.803885701006
avg_episode_per_sec: 15.504076027938206
collect_time: 0.3869950062930583
reward_mean: 1418.995010378743
reward_std: 570.0029839099241
reward_max: 2224.7938027181
reward_min: 567.4035079371926
total_envstep_count: 6290335
total_train_sample_count: 4774295
total_episode_count: 18188
total_duration: 1423.7389897266153
[2023-06-29 11:03:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1736
train_sample_count: 1736
avg_envstep_per_episode: 289.3333333333333
avg_sample_per_episode: 289.3333333333333
avg_envstep_per_sec: 2443.4698999498805
avg_train_sample_per_sec: 2443.4698999498805
avg_episode_per_sec: 8.445172465264564
collect_time: 0.7104650644706563
reward_mean: 2687.2851201102676
reward_std: 872.4943877333956
reward_max: 3430.92169567037
reward_min: 1063.1653973815864
total_envstep_count: 6294719
total_train_sample_count: 4777631
total_episode_count: 18194
total_duration: 1424.4494547910858
[2023-06-29 11:03:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 780
train_sample_count: 780
avg_envstep_per_episode: 156.0
avg_sample_per_episode: 156.0
avg_envstep_per_sec: 2666.582142988698
avg_train_sample_per_sec: 2666.582142988698
avg_episode_per_sec: 17.093475275568576
collect_time: 0.2925092714847997
reward_mean: 2758.327321829519
reward_std: 539.7091641187155
reward_max: 3415.224402704393
reward_min: 2166.7617571552437
total_envstep_count: 6299015
total_train_sample_count: 4781211
total_episode_count: 18199
total_duration: 1424.7419640625706
[2023-06-29 11:03:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2232
train_sample_count: 2232
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2459.789935888603
avg_train_sample_per_sec: 2459.789935888603
avg_episode_per_sec: 8.816451383113272
collect_time: 0.9073945573298261
reward_mean: 2672.0647220033616
reward_std: 855.6113945655725
reward_max: 3422.8170255766004
reward_min: 582.457479128083
total_envstep_count: 6303831
total_train_sample_count: 4784643
total_episode_count: 18207
total_duration: 1425.6493586199003
[2023-06-29 11:03:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2915
train_sample_count: 2915
avg_envstep_per_episode: 364.375
avg_sample_per_episode: 364.375
avg_envstep_per_sec: 2652.512890116356
avg_train_sample_per_sec: 2652.512890116356
avg_episode_per_sec: 7.279623712154665
collect_time: 1.0989579017171636
reward_mean: 2243.4138226473333
reward_std: 973.4611332635751
reward_max: 3468.922029120155
reward_min: 664.6727033885026
total_envstep_count: 6308047
total_train_sample_count: 4787958
total_episode_count: 18215
total_duration: 1426.7483165216174
[2023-06-29 11:03:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1497
train_sample_count: 1497
avg_envstep_per_episode: 249.5
avg_sample_per_episode: 249.5
avg_envstep_per_sec: 2278.7056387995367
avg_train_sample_per_sec: 2278.7056387995367
avg_episode_per_sec: 9.133088732663474
collect_time: 0.6569519004607575
reward_mean: 1705.8513423488184
reward_std: 1106.610496965665
reward_max: 3255.3623153457543
reward_min: 260.9179116537537
total_envstep_count: 6312015
total_train_sample_count: 4791455
total_episode_count: 18221
total_duration: 1427.4052684220783
[2023-06-29 11:04:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2016
train_sample_count: 2016
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 2374.2454086850094
avg_train_sample_per_sec: 2374.2454086850094
avg_episode_per_sec: 8.243907669045171
collect_time: 0.8491118873497472
reward_mean: 2097.964958217722
reward_std: 978.4807387325843
reward_max: 3546.6588121712716
reward_min: 507.5445367194361
total_envstep_count: 6316199
total_train_sample_count: 4794671
total_episode_count: 18228
total_duration: 1428.254380309428
[2023-06-29 11:04:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1942
train_sample_count: 1942
avg_envstep_per_episode: 323.6666666666667
avg_sample_per_episode: 323.6666666666667
avg_envstep_per_sec: 2427.171243712737
avg_train_sample_per_sec: 2427.171243712737
avg_episode_per_sec: 7.498984275116593
collect_time: 0.8001083586625755
reward_mean: 2531.1735738276006
reward_std: 890.6107721023518
reward_max: 3430.835705340344
reward_min: 1233.5592852925422
total_envstep_count: 6321135
total_train_sample_count: 4798213
total_episode_count: 18234
total_duration: 1429.0544886680905
[2023-06-29 11:04:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2109
train_sample_count: 2109
avg_envstep_per_episode: 301.2857142857143
avg_sample_per_episode: 301.2857142857143
avg_envstep_per_sec: 2654.651651640217
avg_train_sample_per_sec: 2654.651651640217
avg_episode_per_sec: 8.811077079886923
collect_time: 0.7944545186171308
reward_mean: 2420.7760403502534
reward_std: 1073.957506922358
reward_max: 3419.9330319238506
reward_min: 759.7210603830972
total_envstep_count: 6325991
total_train_sample_count: 4801522
total_episode_count: 18241
total_duration: 1429.8489431867076
[2023-06-29 11:04:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1630
train_sample_count: 1630
avg_envstep_per_episode: 232.85714285714286
avg_sample_per_episode: 232.85714285714286
avg_envstep_per_sec: 2307.8942490741397
avg_train_sample_per_sec: 2307.8942490741397
avg_episode_per_sec: 9.91120229663741
collect_time: 0.7062715289723127
reward_mean: 1997.1666815409542
reward_std: 895.1848657221866
reward_max: 3383.432392452112
reward_min: 1020.5183126649514
total_envstep_count: 6330367
total_train_sample_count: 4804752
total_episode_count: 18248
total_duration: 1430.55521471568
[2023-06-29 11:04:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2366
train_sample_count: 2366
avg_envstep_per_episode: 295.75
avg_sample_per_episode: 295.75
avg_envstep_per_sec: 2602.570211284868
avg_train_sample_per_sec: 2602.570211284868
avg_episode_per_sec: 8.799899277379097
collect_time: 0.9091013144394382
reward_mean: 2576.938756289408
reward_std: 804.799074223885
reward_max: 3409.3132995566198
reward_min: 1307.5433195797684
total_envstep_count: 6335399
total_train_sample_count: 4808318
total_episode_count: 18256
total_duration: 1431.4643160301193
[2023-06-29 11:04:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1329
train_sample_count: 1329
avg_envstep_per_episode: 221.5
avg_sample_per_episode: 221.5
avg_envstep_per_sec: 2569.106823442659
avg_train_sample_per_sec: 2569.106823442659
avg_episode_per_sec: 11.59867640380433
collect_time: 0.517300404900685
reward_mean: 2093.622164648103
reward_std: 721.8557152681334
reward_max: 3342.0649601616096
reward_min: 1209.767964487891
total_envstep_count: 6339895
total_train_sample_count: 4811647
total_episode_count: 18262
total_duration: 1431.98161643502
[2023-06-29 11:04:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2459
train_sample_count: 2459
avg_envstep_per_episode: 307.375
avg_sample_per_episode: 307.375
avg_envstep_per_sec: 2698.2027653432674
avg_train_sample_per_sec: 2698.2027653432674
avg_episode_per_sec: 8.778211517993551
collect_time: 0.9113473722524942
reward_mean: 2392.4632937584142
reward_std: 818.3982444644173
reward_max: 3417.914719492262
reward_min: 1321.4248452272905
total_envstep_count: 6344503
total_train_sample_count: 4814906
total_episode_count: 18270
total_duration: 1432.8929638072725
[2023-06-29 11:04:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3030
train_sample_count: 3030
avg_envstep_per_episode: 275.45454545454544
avg_sample_per_episode: 275.45454545454544
avg_envstep_per_sec: 2481.2492156157937
avg_train_sample_per_sec: 2481.2492156157937
avg_episode_per_sec: 9.007835436228953
collect_time: 1.221159076214768
reward_mean: 1786.5155183552304
reward_std: 1007.0831379002306
reward_max: 3551.174159839322
reward_min: 514.9680098170656
total_envstep_count: 6349247
total_train_sample_count: 4818336
total_episode_count: 18281
total_duration: 1434.1141228834872
[2023-06-29 11:04:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2360
train_sample_count: 2360
avg_envstep_per_episode: 236.0
avg_sample_per_episode: 236.0
avg_envstep_per_sec: 2559.8295851075254
avg_train_sample_per_sec: 2559.8295851075254
avg_episode_per_sec: 10.846735530116632
collect_time: 0.9219363717529925
reward_mean: 1403.9198994856188
reward_std: 582.702639385529
reward_max: 2724.0240158679067
reward_min: 511.8791050180523
total_envstep_count: 6353447
total_train_sample_count: 4821896
total_episode_count: 18291
total_duration: 1435.0360592552402
[2023-06-29 11:04:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2310
train_sample_count: 2310
avg_envstep_per_episode: 288.75
avg_sample_per_episode: 288.75
avg_envstep_per_sec: 2443.8389520734013
avg_train_sample_per_sec: 2443.8389520734013
avg_episode_per_sec: 8.463511522332126
collect_time: 0.9452341358419507
reward_mean: 1644.8283717897277
reward_std: 788.5124474625379
reward_max: 3437.1107199612115
reward_min: 775.1219980130248
total_envstep_count: 6358095
total_train_sample_count: 4825406
total_episode_count: 18299
total_duration: 1435.981293391082
[2023-06-29 11:04:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 291.2
avg_sample_per_episode: 291.2
avg_envstep_per_sec: 2616.292901299993
avg_train_sample_per_sec: 2616.292901299993
avg_episode_per_sec: 8.984522325892833
collect_time: 1.113025226859376
reward_mean: 1934.9964163986085
reward_std: 987.3881424826014
reward_max: 3398.6318040183533
reward_min: 480.30962832631076
total_envstep_count: 6362599
total_train_sample_count: 4828718
total_episode_count: 18309
total_duration: 1437.0943186179416
[2023-06-29 11:04:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2747
train_sample_count: 2747
avg_envstep_per_episode: 274.7
avg_sample_per_episode: 274.7
avg_envstep_per_sec: 2663.0836590462
avg_train_sample_per_sec: 2663.0836590462
avg_episode_per_sec: 9.694516414438295
collect_time: 1.0315109668705846
reward_mean: 1584.7194422151292
reward_std: 706.8952573502671
reward_max: 2880.03869076182
reward_min: 614.9740097214258
total_envstep_count: 6367503
total_train_sample_count: 4832265
total_episode_count: 18319
total_duration: 1438.1258295848122
[2023-06-29 11:04:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3320
train_sample_count: 3320
avg_envstep_per_episode: 301.8181818181818
avg_sample_per_episode: 301.8181818181818
avg_envstep_per_sec: 2603.5207413043213
avg_train_sample_per_sec: 2603.5207413043213
avg_episode_per_sec: 8.626122938056486
collect_time: 1.27519629374519
reward_mean: 1761.1598859927178
reward_std: 758.1764698683916
reward_max: 3130.0920962072028
reward_min: 766.6676192265679
total_envstep_count: 6372255
total_train_sample_count: 4835585
total_episode_count: 18330
total_duration: 1439.4010258785574
[2023-06-29 11:04:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2180
train_sample_count: 2180
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2199.6369502307657
avg_train_sample_per_sec: 2199.6369502307657
avg_episode_per_sec: 10.090077753352137
collect_time: 0.991072640315164
reward_mean: 1253.5515694905996
reward_std: 310.7030524549459
reward_max: 1625.1937798864276
reward_min: 613.3743326895626
total_envstep_count: 6377335
total_train_sample_count: 4838965
total_episode_count: 18340
total_duration: 1440.3920985188727
[2023-06-29 11:04:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2699
train_sample_count: 2699
avg_envstep_per_episode: 299.8888888888889
avg_sample_per_episode: 299.8888888888889
avg_envstep_per_sec: 2441.079953960366
avg_train_sample_per_sec: 2441.079953960366
avg_episode_per_sec: 8.139947975414337
collect_time: 1.1056581721631809
reward_mean: 2198.5267943993244
reward_std: 440.2017651252649
reward_max: 3132.738461844402
reward_min: 1722.516113122759
total_envstep_count: 6382295
total_train_sample_count: 4842464
total_episode_count: 18349
total_duration: 1441.4977566910359
[2023-06-29 11:04:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1918
train_sample_count: 1918
avg_envstep_per_episode: 174.36363636363637
avg_sample_per_episode: 174.36363636363637
avg_envstep_per_sec: 2622.291919549394
avg_train_sample_per_sec: 2622.291919549394
avg_episode_per_sec: 15.039213302942303
collect_time: 0.7314212371632456
reward_mean: 1334.138681992526
reward_std: 548.8579435153881
reward_max: 2232.8865432991547
reward_min: 323.3051104209232
total_envstep_count: 6386903
total_train_sample_count: 4845982
total_episode_count: 18360
total_duration: 1442.229177928199
[2023-06-29 11:04:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3242
train_sample_count: 3242
avg_envstep_per_episode: 249.3846153846154
avg_sample_per_episode: 249.3846153846154
avg_envstep_per_sec: 2649.4002509071215
avg_train_sample_per_sec: 2649.4002509071215
avg_episode_per_sec: 10.623751777233986
collect_time: 1.2236731686312703
reward_mean: 1601.4351883663176
reward_std: 800.6361079494043
reward_max: 3096.49329668524
reward_min: 431.95591385041547
total_envstep_count: 6391679
total_train_sample_count: 4849224
total_episode_count: 18373
total_duration: 1443.4528510968303
[2023-06-29 11:04:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 247.30769230769232
avg_sample_per_episode: 247.30769230769232
avg_envstep_per_sec: 2613.1863258295684
avg_train_sample_per_sec: 2613.1863258295684
avg_episode_per_sec: 10.566538798066684
collect_time: 1.2302987996768209
reward_mean: 1277.5064986526584
reward_std: 253.26418861014773
reward_max: 1768.2114194123262
reward_min: 771.7288098797906
total_envstep_count: 6396231
total_train_sample_count: 4852439
total_episode_count: 18386
total_duration: 1444.683149896507
[2023-06-29 11:04:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2312
train_sample_count: 2312
avg_envstep_per_episode: 330.2857142857143
avg_sample_per_episode: 330.2857142857143
avg_envstep_per_sec: 2521.692618771507
avg_train_sample_per_sec: 2521.692618771507
avg_episode_per_sec: 7.634882496280514
collect_time: 0.9168444967437535
reward_mean: 1647.359842258067
reward_std: 295.96762726827376
reward_max: 1910.7714079341633
reward_min: 1216.8281465561145
total_envstep_count: 6400815
total_train_sample_count: 4855951
total_episode_count: 18393
total_duration: 1445.5999943932509
[2023-06-29 11:05:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3170
train_sample_count: 3170
avg_envstep_per_episode: 264.1666666666667
avg_sample_per_episode: 264.1666666666667
avg_envstep_per_sec: 2465.1448544345176
avg_train_sample_per_sec: 2465.1448544345176
avg_episode_per_sec: 9.331778628774199
collect_time: 1.2859284898806362
reward_mean: 1714.7663569393305
reward_std: 790.3953657418833
reward_max: 3619.716937542051
reward_min: 588.8853432355359
total_envstep_count: 6405519
total_train_sample_count: 4859521
total_episode_count: 18405
total_duration: 1446.8859228831316
[2023-06-29 11:05:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2668
train_sample_count: 2668
avg_envstep_per_episode: 266.8
avg_sample_per_episode: 266.8
avg_envstep_per_sec: 2511.6421326868117
avg_train_sample_per_sec: 2511.6421326868117
avg_episode_per_sec: 9.413951022064513
collect_time: 1.0622532427205007
reward_mean: 1442.007240987875
reward_std: 626.666278335859
reward_max: 2618.658332390811
reward_min: 399.0630585609053
total_envstep_count: 6410279
total_train_sample_count: 4862989
total_episode_count: 18415
total_duration: 1447.9481761258521
[2023-06-29 11:05:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 307.25
avg_sample_per_episode: 307.25
avg_envstep_per_sec: 2482.0056751046823
avg_train_sample_per_sec: 2482.0056751046823
avg_episode_per_sec: 8.078130757053483
collect_time: 0.9903281143369385
reward_mean: 2014.668569971045
reward_std: 846.9496678640552
reward_max: 3357.870784086683
reward_min: 575.410386441492
total_envstep_count: 6414327
total_train_sample_count: 4866247
total_episode_count: 18423
total_duration: 1448.938504240189
[2023-06-29 11:05:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3396
train_sample_count: 3396
avg_envstep_per_episode: 261.2307692307692
avg_sample_per_episode: 261.2307692307692
avg_envstep_per_sec: 2491.460534146317
avg_train_sample_per_sec: 2491.460534146317
avg_episode_per_sec: 9.537393093021825
collect_time: 1.363055907752365
reward_mean: 1362.724484555483
reward_std: 416.2553548156184
reward_max: 2162.823101959251
reward_min: 810.7378851607
total_envstep_count: 6419111
total_train_sample_count: 4869643
total_episode_count: 18436
total_duration: 1450.3015601479415
[2023-06-29 11:05:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2429
train_sample_count: 2429
avg_envstep_per_episode: 269.8888888888889
avg_sample_per_episode: 269.8888888888889
avg_envstep_per_sec: 2607.1941381014535
avg_train_sample_per_sec: 2607.1941381014535
avg_episode_per_sec: 9.660249997082373
collect_time: 0.9316529078148305
reward_mean: 1396.7697751790884
reward_std: 417.8621521851242
reward_max: 2122.909300618091
reward_min: 851.3375302319179
total_envstep_count: 6423247
total_train_sample_count: 4872872
total_episode_count: 18445
total_duration: 1451.2332130557563
[2023-06-29 11:05:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2864
train_sample_count: 2864
avg_envstep_per_episode: 260.3636363636364
avg_sample_per_episode: 260.3636363636364
avg_envstep_per_sec: 2429.2523357784344
avg_train_sample_per_sec: 2429.2523357784344
avg_episode_per_sec: 9.330228943283094
collect_time: 1.1789635674394665
reward_mean: 1441.3152812206072
reward_std: 647.1084601378133
reward_max: 2809.031093535519
reward_min: 479.36946838839145
total_envstep_count: 6427767
total_train_sample_count: 4876136
total_episode_count: 18456
total_duration: 1452.4121766231958
[2023-06-29 11:05:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2833
train_sample_count: 2833
avg_envstep_per_episode: 236.08333333333334
avg_sample_per_episode: 236.08333333333334
avg_envstep_per_sec: 2630.7281252673015
avg_train_sample_per_sec: 2630.7281252673015
avg_episode_per_sec: 11.143218320934562
collect_time: 1.0768881712974983
reward_mean: 1422.629515974819
reward_std: 702.4482984494365
reward_max: 3280.7097327894544
reward_min: 563.8732446470366
total_envstep_count: 6431791
total_train_sample_count: 4879369
total_episode_count: 18468
total_duration: 1453.4890647944933
[2023-06-29 11:05:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2847
train_sample_count: 2847
avg_envstep_per_episode: 258.8181818181818
avg_sample_per_episode: 258.8181818181818
avg_envstep_per_sec: 2531.2019357209347
avg_train_sample_per_sec: 2531.2019357209347
avg_episode_per_sec: 9.779845905490088
collect_time: 1.1247620981251818
reward_mean: 1310.7631760045738
reward_std: 374.9265755612197
reward_max: 1968.4092757006717
reward_min: 869.6440556111061
total_envstep_count: 6436455
total_train_sample_count: 4882616
total_episode_count: 18479
total_duration: 1454.6138268926184
[2023-06-29 11:05:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2062
train_sample_count: 2062
avg_envstep_per_episode: 294.57142857142856
avg_sample_per_episode: 294.57142857142856
avg_envstep_per_sec: 2689.7265593280663
avg_train_sample_per_sec: 2689.7265593280663
avg_episode_per_sec: 9.130982500143775
collect_time: 0.7666206785403191
reward_mean: 1893.2890226261327
reward_std: 821.6384010018559
reward_max: 3355.0764374771584
reward_min: 846.1933714981637
total_envstep_count: 6440255
total_train_sample_count: 4885878
total_episode_count: 18486
total_duration: 1455.3804475711586
[2023-06-29 11:05:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3045
train_sample_count: 3045
avg_envstep_per_episode: 338.3333333333333
avg_sample_per_episode: 338.3333333333333
avg_envstep_per_sec: 2658.4594780376124
avg_train_sample_per_sec: 2658.4594780376124
avg_episode_per_sec: 7.857515698633337
collect_time: 1.1454001932907847
reward_mean: 1925.310621948563
reward_std: 800.4238287953995
reward_max: 3448.3516020291113
reward_min: 884.7356166877845
total_envstep_count: 6445247
total_train_sample_count: 4889323
total_episode_count: 18495
total_duration: 1456.5258477644493
[2023-06-29 11:05:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2422
train_sample_count: 2422
avg_envstep_per_episode: 269.1111111111111
avg_sample_per_episode: 269.1111111111111
avg_envstep_per_sec: 2574.5058526026723
avg_train_sample_per_sec: 2574.5058526026723
avg_episode_per_sec: 9.566702177301424
collect_time: 0.9407630584919828
reward_mean: 1549.3354188218173
reward_std: 587.2495781512841
reward_max: 2767.411209822593
reward_min: 894.1288043516914
total_envstep_count: 6449007
total_train_sample_count: 4892545
total_episode_count: 18504
total_duration: 1457.4666108229412
[2023-06-29 11:05:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2134
train_sample_count: 2134
avg_envstep_per_episode: 237.11111111111111
avg_sample_per_episode: 237.11111111111111
avg_envstep_per_sec: 2652.8921077137234
avg_train_sample_per_sec: 2652.8921077137234
avg_episode_per_sec: 11.18839220685263
collect_time: 0.8044051221664995
reward_mean: 1432.6877308853966
reward_std: 781.4861465827422
reward_max: 3473.962578752254
reward_min: 717.4529811332806
total_envstep_count: 6453375
total_train_sample_count: 4895879
total_episode_count: 18513
total_duration: 1458.2710159451078
[2023-06-29 11:05:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2989
train_sample_count: 2989
avg_envstep_per_episode: 271.72727272727275
avg_sample_per_episode: 271.72727272727275
avg_envstep_per_sec: 2595.507852686121
avg_train_sample_per_sec: 2595.507852686121
avg_episode_per_sec: 9.551885707443068
collect_time: 1.1516050690837438
reward_mean: 1743.563644507594
reward_std: 678.7457048833977
reward_max: 2822.2029909073635
reward_min: 425.9863796301014
total_envstep_count: 6457687
total_train_sample_count: 4899268
total_episode_count: 18524
total_duration: 1459.4226210141915
[2023-06-29 11:05:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3306
train_sample_count: 3306
avg_envstep_per_episode: 300.54545454545456
avg_sample_per_episode: 300.54545454545456
avg_envstep_per_sec: 2722.3605171156573
avg_train_sample_per_sec: 2722.3605171156573
avg_episode_per_sec: 9.058065846422332
collect_time: 1.2143872860390692
reward_mean: 1505.109737635973
reward_std: 564.4512587015153
reward_max: 2810.37105099668
reward_min: 961.9588986399572
total_envstep_count: 6462279
total_train_sample_count: 4902574
total_episode_count: 18535
total_duration: 1460.6370083002305
[2023-06-29 11:05:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 271.44444444444446
avg_sample_per_episode: 271.44444444444446
avg_envstep_per_sec: 2520.5512085868377
avg_train_sample_per_sec: 2520.5512085868377
avg_episode_per_sec: 9.28569827150288
collect_time: 0.9692324407761915
reward_mean: 1446.320131740991
reward_std: 447.3571725216278
reward_max: 2557.8450997700384
reward_min: 1013.7110861180065
total_envstep_count: 6466663
total_train_sample_count: 4905817
total_episode_count: 18544
total_duration: 1461.6062407410068
[2023-06-29 11:05:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3001
train_sample_count: 3001
avg_envstep_per_episode: 230.84615384615384
avg_sample_per_episode: 230.84615384615384
avg_envstep_per_sec: 2446.5578334390057
avg_train_sample_per_sec: 2446.5578334390057
avg_episode_per_sec: 10.598217872278266
collect_time: 1.2266213203640652
reward_mean: 1348.0903111965565
reward_std: 691.5962696790162
reward_max: 3476.936429114341
reward_min: 842.2076800211594
total_envstep_count: 6471311
total_train_sample_count: 4909218
total_episode_count: 18557
total_duration: 1462.8328620613709
[2023-06-29 11:05:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2598
train_sample_count: 2598
avg_envstep_per_episode: 259.8
avg_sample_per_episode: 259.8
avg_envstep_per_sec: 2506.178693192708
avg_train_sample_per_sec: 2506.178693192708
avg_episode_per_sec: 9.646569257862618
collect_time: 1.0366379728056492
reward_mean: 1388.6034788816655
reward_std: 569.8534132488941
reward_max: 2644.372542495381
reward_min: 806.0484082719693
total_envstep_count: 6476135
total_train_sample_count: 4912616
total_episode_count: 18567
total_duration: 1463.8695000341766
[2023-06-29 11:05:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2462
train_sample_count: 2462
avg_envstep_per_episode: 246.2
avg_sample_per_episode: 246.2
avg_envstep_per_sec: 2544.8996999230726
avg_train_sample_per_sec: 2544.8996999230726
avg_episode_per_sec: 10.336716896519386
collect_time: 0.9674251602428267
reward_mean: 1769.5813859382429
reward_std: 973.270413793645
reward_max: 3457.53011527196
reward_min: 342.9497832095125
total_envstep_count: 6480775
total_train_sample_count: 4915878
total_episode_count: 18577
total_duration: 1464.8369251944193
[2023-06-29 11:05:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2816
train_sample_count: 2816
avg_envstep_per_episode: 216.6153846153846
avg_sample_per_episode: 216.6153846153846
avg_envstep_per_sec: 2478.5159643191773
avg_train_sample_per_sec: 2478.5159643191773
avg_episode_per_sec: 11.442012619371203
collect_time: 1.1361637530438606
reward_mean: 1363.5062929710607
reward_std: 343.43723629760535
reward_max: 2167.7545855534263
reward_min: 1010.1573489659834
total_envstep_count: 6484943
total_train_sample_count: 4919094
total_episode_count: 18590
total_duration: 1465.973088947463
[2023-06-29 11:06:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2485
train_sample_count: 2485
avg_envstep_per_episode: 276.1111111111111
avg_sample_per_episode: 276.1111111111111
avg_envstep_per_sec: 2339.389718730468
avg_train_sample_per_sec: 2339.389718730468
avg_episode_per_sec: 8.472638820351795
collect_time: 1.062242849108763
reward_mean: 1496.4976186770696
reward_std: 555.4939140859105
reward_max: 2737.2640069454696
reward_min: 899.4305204636106
total_envstep_count: 6489583
total_train_sample_count: 4922379
total_episode_count: 18599
total_duration: 1467.0353317965719
[2023-06-29 11:06:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2190
train_sample_count: 2190
avg_envstep_per_episode: 243.33333333333334
avg_sample_per_episode: 243.33333333333334
avg_envstep_per_sec: 2637.005474048545
avg_train_sample_per_sec: 2637.005474048545
avg_episode_per_sec: 10.837008797459774
collect_time: 0.8304874682864174
reward_mean: 1637.5061373721264
reward_std: 764.0982863671459
reward_max: 3494.2418611899025
reward_min: 1002.0833462212038
total_envstep_count: 6494383
total_train_sample_count: 4925769
total_episode_count: 18608
total_duration: 1467.8658192648584
[2023-06-29 11:06:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 239.33333333333334
avg_sample_per_episode: 239.33333333333334
avg_envstep_per_sec: 2703.751777766804
avg_train_sample_per_sec: 2703.751777766804
avg_episode_per_sec: 11.297012999025643
collect_time: 0.7966707660490646
reward_mean: 1930.4033837261143
reward_std: 718.5074003003266
reward_max: 2944.2793122804533
reward_min: 597.2397936585525
total_envstep_count: 6498943
total_train_sample_count: 4929123
total_episode_count: 18617
total_duration: 1468.6624900309075
[2023-06-29 11:06:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 182.36363636363637
avg_sample_per_episode: 182.36363636363637
avg_envstep_per_sec: 2580.309304306468
avg_train_sample_per_sec: 2580.309304306468
avg_episode_per_sec: 14.14925341344524
collect_time: 0.7774261778043581
reward_mean: 1346.7388319245163
reward_std: 595.6287516933268
reward_max: 2191.2593714666136
reward_min: 374.2514919680567
total_envstep_count: 6503087
total_train_sample_count: 4932329
total_episode_count: 18628
total_duration: 1469.4399162087118
[2023-06-29 11:06:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3277
train_sample_count: 3277
avg_envstep_per_episode: 327.7
avg_sample_per_episode: 327.7
avg_envstep_per_sec: 2640.63244013703
avg_train_sample_per_sec: 2640.63244013703
avg_episode_per_sec: 8.05807885302725
collect_time: 1.2409905862665034
reward_mean: 1968.0490191348795
reward_std: 374.9113027221901
reward_max: 2459.183109563521
reward_min: 1247.8787278692944
total_envstep_count: 6507551
total_train_sample_count: 4935606
total_episode_count: 18638
total_duration: 1470.6809067949782
[2023-06-29 11:06:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2246
train_sample_count: 2246
avg_envstep_per_episode: 280.75
avg_sample_per_episode: 280.75
avg_envstep_per_sec: 2556.474306830232
avg_train_sample_per_sec: 2556.474306830232
avg_episode_per_sec: 9.10587464587794
collect_time: 0.8785537151690805
reward_mean: 1541.5552830071938
reward_std: 220.805218463226
reward_max: 2020.5237731486868
reward_min: 1235.6906675919297
total_envstep_count: 6512415
total_train_sample_count: 4939052
total_episode_count: 18646
total_duration: 1471.5594605101473
[2023-06-29 11:06:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 240.11111111111111
avg_sample_per_episode: 240.11111111111111
avg_envstep_per_sec: 2413.80300293534
avg_train_sample_per_sec: 2413.80300293534
avg_episode_per_sec: 10.052858411114327
collect_time: 0.8952677568849176
reward_mean: 1578.657232772025
reward_std: 755.2768753985212
reward_max: 2870.931131944631
reward_min: 247.1252938333731
total_envstep_count: 6516471
total_train_sample_count: 4942413
total_episode_count: 18655
total_duration: 1472.4547282670324
[2023-06-29 11:06:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2936
train_sample_count: 2936
avg_envstep_per_episode: 209.71428571428572
avg_sample_per_episode: 209.71428571428572
avg_envstep_per_sec: 2493.08087957072
avg_train_sample_per_sec: 2493.08087957072
avg_episode_per_sec: 11.887987845364467
collect_time: 1.1776593467378988
reward_mean: 1372.9388567797198
reward_std: 796.1617341962974
reward_max: 3612.911342859816
reward_min: 423.29120123444943
total_envstep_count: 6521407
total_train_sample_count: 4945749
total_episode_count: 18669
total_duration: 1473.6323876137703
[2023-06-29 11:06:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 261.3076923076923
avg_sample_per_episode: 261.3076923076923
avg_envstep_per_sec: 2264.337646211022
avg_train_sample_per_sec: 2264.337646211022
avg_episode_per_sec: 8.665407536280036
collect_time: 1.5002179580789523
reward_mean: 1469.7141544664437
reward_std: 596.5358905355147
reward_max: 2605.173322397627
reward_min: 223.62233455297186
total_envstep_count: 6525679
total_train_sample_count: 4949146
total_episode_count: 18682
total_duration: 1475.1326055718494
[2023-06-29 11:06:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2830
train_sample_count: 2830
avg_envstep_per_episode: 314.44444444444446
avg_sample_per_episode: 314.44444444444446
avg_envstep_per_sec: 2559.5689930811977
avg_train_sample_per_sec: 2559.5689930811977
avg_episode_per_sec: 8.139972062802396
collect_time: 1.1056549003561957
reward_mean: 1457.8369783530432
reward_std: 364.08424808335235
reward_max: 2433.474624726736
reward_min: 1190.499000588242
total_envstep_count: 6530655
total_train_sample_count: 4952376
total_episode_count: 18691
total_duration: 1476.2382604722056
[2023-06-29 11:06:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3330
train_sample_count: 3330
avg_envstep_per_episode: 237.85714285714286
avg_sample_per_episode: 237.85714285714286
avg_envstep_per_sec: 2496.0796356279143
avg_train_sample_per_sec: 2496.0796356279143
avg_episode_per_sec: 10.494028498135377
collect_time: 1.334092050777981
reward_mean: 1396.136607687918
reward_std: 398.9187767084586
reward_max: 2496.2728787702376
reward_min: 989.1753752964414
total_envstep_count: 6534967
total_train_sample_count: 4955706
total_episode_count: 18705
total_duration: 1477.5723525229837
[2023-06-29 11:06:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 242.6
avg_sample_per_episode: 242.6
avg_envstep_per_sec: 2558.332549422529
avg_train_sample_per_sec: 2558.332549422529
avg_episode_per_sec: 10.545476296053293
collect_time: 0.948273906200193
reward_mean: 1194.992723509905
reward_std: 364.44895756798815
reward_max: 1934.0019055080081
reward_min: 561.2213069013516
total_envstep_count: 6539479
total_train_sample_count: 4958932
total_episode_count: 18715
total_duration: 1478.520626429184
[2023-06-29 11:06:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2863
train_sample_count: 2863
avg_envstep_per_episode: 220.23076923076923
avg_sample_per_episode: 220.23076923076923
avg_envstep_per_sec: 2597.4323590279346
avg_train_sample_per_sec: 2597.4323590279346
avg_episode_per_sec: 11.79413924811846
collect_time: 1.102242370258085
reward_mean: 1350.2319753125537
reward_std: 336.07218766348086
reward_max: 1991.6513288421063
reward_min: 938.5174148948846
total_envstep_count: 6543919
total_train_sample_count: 4962195
total_episode_count: 18728
total_duration: 1479.6228687994421
[2023-06-29 11:06:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3059
train_sample_count: 3059
avg_envstep_per_episode: 278.09090909090907
avg_sample_per_episode: 278.09090909090907
avg_envstep_per_sec: 2518.462780951784
avg_train_sample_per_sec: 2518.462780951784
avg_episode_per_sec: 9.056257139741623
collect_time: 1.2146298222616316
reward_mean: 1466.2874575271105
reward_std: 485.74710266410483
reward_max: 2597.4862279638137
reward_min: 456.8736531916375
total_envstep_count: 6548351
total_train_sample_count: 4965654
total_episode_count: 18739
total_duration: 1480.8374986217038
[2023-06-29 11:06:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2555
train_sample_count: 2555
avg_envstep_per_episode: 255.5
avg_sample_per_episode: 255.5
avg_envstep_per_sec: 2330.8726528453317
avg_train_sample_per_sec: 2330.8726528453317
avg_episode_per_sec: 9.122789247926933
collect_time: 1.0961559812721098
reward_mean: 1414.5922187777878
reward_std: 463.71249475615014
reward_max: 2586.753576857231
reward_min: 974.2795935216269
total_envstep_count: 6553159
total_train_sample_count: 4969009
total_episode_count: 18749
total_duration: 1481.933654602976
[2023-06-29 11:06:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3122
train_sample_count: 3122
avg_envstep_per_episode: 260.1666666666667
avg_sample_per_episode: 260.1666666666667
avg_envstep_per_sec: 2450.3569945796694
avg_train_sample_per_sec: 2450.3569945796694
avg_episode_per_sec: 9.41841253521974
collect_time: 1.2741000625239685
reward_mean: 1609.8019432676374
reward_std: 541.6988106198465
reward_max: 2633.1243451701653
reward_min: 1055.54534139928
total_envstep_count: 6557935
total_train_sample_count: 4972531
total_episode_count: 18761
total_duration: 1483.2077546655
[2023-06-29 11:06:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2594
train_sample_count: 2594
avg_envstep_per_episode: 288.22222222222223
avg_sample_per_episode: 288.22222222222223
avg_envstep_per_sec: 2376.2943021735064
avg_train_sample_per_sec: 2376.2943021735064
avg_episode_per_sec: 8.244660261974385
collect_time: 1.0916156292709058
reward_mean: 1698.068343376453
reward_std: 423.8763423732568
reward_max: 2497.3573922403825
reward_min: 1100.6773017220157
total_envstep_count: 6562375
total_train_sample_count: 4975925
total_episode_count: 18770
total_duration: 1484.299370294771
[2023-06-29 11:06:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 273.1111111111111
avg_sample_per_episode: 273.1111111111111
avg_envstep_per_sec: 2621.970221366546
avg_train_sample_per_sec: 2621.970221366546
avg_episode_per_sec: 9.600379166923886
collect_time: 0.9374629734425106
reward_mean: 1719.4711386154795
reward_std: 470.2081884906684
reward_max: 2506.5225346858465
reward_min: 1077.1745737923973
total_envstep_count: 6566639
total_train_sample_count: 4979183
total_episode_count: 18779
total_duration: 1485.2368332682136
[2023-06-29 11:06:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3019
train_sample_count: 3019
avg_envstep_per_episode: 251.58333333333334
avg_sample_per_episode: 251.58333333333334
avg_envstep_per_sec: 2664.037275515736
avg_train_sample_per_sec: 2664.037275515736
avg_episode_per_sec: 10.589084897710777
collect_time: 1.1332424015784637
reward_mean: 1440.41494448562
reward_std: 283.6576360235369
reward_max: 2153.1588019830524
reward_min: 1078.631351278208
total_envstep_count: 6570791
total_train_sample_count: 4982602
total_episode_count: 18791
total_duration: 1486.370075669792
[2023-06-29 11:07:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2212
train_sample_count: 2212
avg_envstep_per_episode: 316.0
avg_sample_per_episode: 316.0
avg_envstep_per_sec: 2394.2882022282665
avg_train_sample_per_sec: 2394.2882022282665
avg_episode_per_sec: 7.57686139945654
collect_time: 0.9238653884446248
reward_mean: 1676.4524202077914
reward_std: 344.97654396571977
reward_max: 2177.54661958445
reward_min: 1142.1974567495047
total_envstep_count: 6575519
total_train_sample_count: 4986014
total_episode_count: 18798
total_duration: 1487.2939410582367
[2023-06-29 11:07:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1811
train_sample_count: 1811
avg_envstep_per_episode: 258.7142857142857
avg_sample_per_episode: 258.7142857142857
avg_envstep_per_sec: 2588.821995633881
avg_train_sample_per_sec: 2588.821995633881
avg_episode_per_sec: 10.006490319954262
collect_time: 0.6995459722817177
reward_mean: 2206.3373778744235
reward_std: 847.7771285087631
reward_max: 3229.8844833082303
reward_min: 1254.1279902037613
total_envstep_count: 6580071
total_train_sample_count: 4989425
total_episode_count: 18805
total_duration: 1487.9934870305183
[2023-06-29 11:07:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2284
train_sample_count: 2284
avg_envstep_per_episode: 253.77777777777777
avg_sample_per_episode: 253.77777777777777
avg_envstep_per_sec: 2558.708096102948
avg_train_sample_per_sec: 2558.708096102948
avg_episode_per_sec: 10.08247498464384
collect_time: 0.8926379697155205
reward_mean: 2035.869240444532
reward_std: 903.973710133528
reward_max: 3570.0532540343147
reward_min: 401.08975131642603
total_envstep_count: 6585223
total_train_sample_count: 4992909
total_episode_count: 18814
total_duration: 1488.8861250002337
[2023-06-29 11:07:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2438
train_sample_count: 2438
avg_envstep_per_episode: 243.8
avg_sample_per_episode: 243.8
avg_envstep_per_sec: 2631.364298969282
avg_train_sample_per_sec: 2631.364298969282
avg_episode_per_sec: 10.793126739004437
collect_time: 0.9265155725320802
reward_mean: 1908.4685824570195
reward_std: 658.0733787344797
reward_max: 3433.7533681373593
reward_min: 1321.9676136226478
total_envstep_count: 6589231
total_train_sample_count: 4996147
total_episode_count: 18824
total_duration: 1489.8126405727658
[2023-06-29 11:07:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1807
train_sample_count: 1807
avg_envstep_per_episode: 200.77777777777777
avg_sample_per_episode: 200.77777777777777
avg_envstep_per_sec: 2584.535963334493
avg_train_sample_per_sec: 2584.535963334493
avg_episode_per_sec: 12.872619629225476
collect_time: 0.6991583888307212
reward_mean: 1327.2757590599128
reward_std: 469.21229439134817
reward_max: 1976.0658467195576
reward_min: 260.75256741555796
total_envstep_count: 6593959
total_train_sample_count: 4999554
total_episode_count: 18833
total_duration: 1490.5117989615965
[2023-06-29 11:07:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2553
train_sample_count: 2553
avg_envstep_per_episode: 364.7142857142857
avg_sample_per_episode: 364.7142857142857
avg_envstep_per_sec: 2412.579279721636
avg_train_sample_per_sec: 2412.579279721636
avg_episode_per_sec: 6.614984315727165
collect_time: 1.0582035672189665
reward_mean: 2597.449539929598
reward_std: 913.0939264666451
reward_max: 3536.2519190914104
reward_min: 1092.7466670829276
total_envstep_count: 6598727
total_train_sample_count: 5002907
total_episode_count: 18840
total_duration: 1491.5700025288154
[2023-06-29 11:07:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 300.25
avg_sample_per_episode: 300.25
avg_envstep_per_sec: 2730.9213341843433
avg_train_sample_per_sec: 2730.9213341843433
avg_episode_per_sec: 9.095491537666422
collect_time: 0.43977832131832834
reward_mean: 2546.2923125138714
reward_std: 925.7658694366979
reward_max: 3466.9289434561038
reward_min: 1323.0780982729293
total_envstep_count: 6602863
total_train_sample_count: 5006108
total_episode_count: 18844
total_duration: 1492.0097808501337
[2023-06-29 11:07:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2412
train_sample_count: 2412
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2629.852729376386
avg_train_sample_per_sec: 2629.852729376386
avg_episode_per_sec: 9.812883318568604
collect_time: 0.9171616239408034
reward_mean: 2441.069802639023
reward_std: 959.4834739477305
reward_max: 3617.582703624947
reward_min: 1372.8525289076351
total_envstep_count: 6607255
total_train_sample_count: 5009320
total_episode_count: 18853
total_duration: 1492.9269424740744
[2023-06-29 11:07:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2126
train_sample_count: 2126
avg_envstep_per_episode: 303.7142857142857
avg_sample_per_episode: 303.7142857142857
avg_envstep_per_sec: 2538.3300046914505
avg_train_sample_per_sec: 2538.3300046914505
avg_episode_per_sec: 8.357624662671757
collect_time: 0.8375585507284851
reward_mean: 1819.9697939198236
reward_std: 699.5490854946296
reward_max: 2853.105935930112
reward_min: 493.405549915332
total_envstep_count: 6611367
total_train_sample_count: 5012646
total_episode_count: 18860
total_duration: 1493.764501024803
[2023-06-29 11:07:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2584
train_sample_count: 2584
avg_envstep_per_episode: 258.4
avg_sample_per_episode: 258.4
avg_envstep_per_sec: 2675.9418025852638
avg_train_sample_per_sec: 2675.9418025852638
avg_episode_per_sec: 10.355811929509535
collect_time: 0.9656413295324893
reward_mean: 1724.5962911254815
reward_std: 809.0204601004789
reward_max: 3482.6418566942534
reward_min: 519.26846937975
total_envstep_count: 6616359
total_train_sample_count: 5016030
total_episode_count: 18870
total_duration: 1494.7301423543354
[2023-06-29 11:07:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2976
train_sample_count: 2976
avg_envstep_per_episode: 372.0
avg_sample_per_episode: 372.0
avg_envstep_per_sec: 2509.6635082038297
avg_train_sample_per_sec: 2509.6635082038297
avg_episode_per_sec: 6.746407280117821
collect_time: 1.185816341621801
reward_mean: 2411.7831393535707
reward_std: 607.0080468366963
reward_max: 3420.134435987439
reward_min: 1904.4657902372674
total_envstep_count: 6621183
total_train_sample_count: 5019406
total_episode_count: 18878
total_duration: 1495.9159586959572
[2023-06-29 11:07:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 267.5
avg_sample_per_episode: 267.5
avg_envstep_per_sec: 2705.217007566835
avg_train_sample_per_sec: 2705.217007566835
avg_episode_per_sec: 10.112960775950784
collect_time: 1.1865961181750755
reward_mean: 1483.7761886538522
reward_std: 207.1723030135649
reward_max: 1998.8367145925113
reward_min: 1279.8078138381036
total_envstep_count: 6625871
total_train_sample_count: 5022616
total_episode_count: 18890
total_duration: 1497.1025548141322
[2023-06-29 11:07:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2044
train_sample_count: 2044
avg_envstep_per_episode: 255.5
avg_sample_per_episode: 255.5
avg_envstep_per_sec: 2444.7870463453555
avg_train_sample_per_sec: 2444.7870463453555
avg_episode_per_sec: 9.568638146165776
collect_time: 0.8360646392721685
reward_mean: 1369.2987258763037
reward_std: 472.33523730981847
reward_max: 1847.5591715024427
reward_min: 570.94428094126
total_envstep_count: 6630047
total_train_sample_count: 5025860
total_episode_count: 18898
total_duration: 1497.9386194534043
[2023-06-29 11:07:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2883
train_sample_count: 2883
avg_envstep_per_episode: 262.09090909090907
avg_sample_per_episode: 262.09090909090907
avg_envstep_per_sec: 2428.9102674380247
avg_train_sample_per_sec: 2428.9102674380247
avg_episode_per_sec: 9.26743424967682
collect_time: 1.1869520412711425
reward_mean: 1716.97517233478
reward_std: 627.6065518905426
reward_max: 3467.8690568186807
reward_min: 1154.8222613089167
total_envstep_count: 6634431
total_train_sample_count: 5029143
total_episode_count: 18909
total_duration: 1499.1255714946753
[2023-06-29 11:07:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2567
train_sample_count: 2567
avg_envstep_per_episode: 285.22222222222223
avg_sample_per_episode: 285.22222222222223
avg_envstep_per_sec: 2727.9415707442395
avg_train_sample_per_sec: 2727.9415707442395
avg_episode_per_sec: 9.564267291273142
collect_time: 0.9410025594132021
reward_mean: 1536.279039906649
reward_std: 444.82355540261165
reward_max: 2468.8354915428354
reward_min: 833.3386366535005
total_envstep_count: 6639039
total_train_sample_count: 5032510
total_episode_count: 18918
total_duration: 1500.0665740540885
[2023-06-29 11:07:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1827
train_sample_count: 1827
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 2582.02371945442
avg_train_sample_per_sec: 2582.02371945442
avg_episode_per_sec: 12.719328667263154
collect_time: 0.7075845145164057
reward_mean: 1438.0752540712529
reward_std: 639.173226947323
reward_max: 2691.433723421248
reward_min: 677.7967359908462
total_envstep_count: 6643695
total_train_sample_count: 5035937
total_episode_count: 18927
total_duration: 1500.774158568605
[2023-06-29 11:07:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1651
train_sample_count: 1651
avg_envstep_per_episode: 235.85714285714286
avg_sample_per_episode: 235.85714285714286
avg_envstep_per_sec: 2628.7652389003656
avg_train_sample_per_sec: 2628.7652389003656
avg_episode_per_sec: 11.145582478681138
collect_time: 0.6280515184728428
reward_mean: 2306.2092650591253
reward_std: 673.3949155510788
reward_max: 3496.8884068918605
reward_min: 1446.1471140065182
total_envstep_count: 6648023
total_train_sample_count: 5039188
total_episode_count: 18934
total_duration: 1501.4022100870777
[2023-06-29 11:07:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 2373.768875406208
avg_train_sample_per_sec: 2373.768875406208
avg_episode_per_sec: 7.808450248046737
collect_time: 0.8964646988371389
reward_mean: 2551.923805579349
reward_std: 769.0226505643357
reward_max: 3486.0403197617693
reward_min: 1572.7732700658096
total_envstep_count: 6652447
total_train_sample_count: 5042516
total_episode_count: 18941
total_duration: 1502.298674785915
[2023-06-29 11:07:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2816
train_sample_count: 2816
avg_envstep_per_episode: 352.0
avg_sample_per_episode: 352.0
avg_envstep_per_sec: 2470.4956240830516
avg_train_sample_per_sec: 2470.4956240830516
avg_episode_per_sec: 7.01845347750867
collect_time: 1.1398522517299279
reward_mean: 2255.1228921940915
reward_std: 1033.8883578339064
reward_max: 3562.72480210309
reward_min: 687.2175602599697
total_envstep_count: 6657159
total_train_sample_count: 5045732
total_episode_count: 18949
total_duration: 1503.438527037645
[2023-06-29 11:08:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 286.7142857142857
avg_sample_per_episode: 286.7142857142857
avg_envstep_per_sec: 2413.986369909495
avg_train_sample_per_sec: 2413.986369909495
avg_episode_per_sec: 8.41948410033207
collect_time: 0.8314048600345851
reward_mean: 1781.788832030448
reward_std: 594.7097950347722
reward_max: 2663.0787975505805
reward_min: 1016.236390973627
total_envstep_count: 6661767
total_train_sample_count: 5048939
total_episode_count: 18956
total_duration: 1504.2699318976795
[2023-06-29 11:08:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1804
train_sample_count: 1804
avg_envstep_per_episode: 225.5
avg_sample_per_episode: 225.5
avg_envstep_per_sec: 2512.1497285341147
avg_train_sample_per_sec: 2512.1497285341147
avg_episode_per_sec: 11.140353563344188
collect_time: 0.7181100630704313
reward_mean: 2082.9683616949624
reward_std: 852.2077167425936
reward_max: 3527.0609850593096
reward_min: 960.1646933648566
total_envstep_count: 6665951
total_train_sample_count: 5052343
total_episode_count: 18964
total_duration: 1504.98804196075
[2023-06-29 11:08:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3080
train_sample_count: 3080
avg_envstep_per_episode: 308.0
avg_sample_per_episode: 308.0
avg_envstep_per_sec: 2527.6562630049684
avg_train_sample_per_sec: 2527.6562630049684
avg_episode_per_sec: 8.20667617858756
collect_time: 1.2185201148902998
reward_mean: 1877.9866988725196
reward_std: 938.8423446081051
reward_max: 3493.9499685208457
reward_min: 253.95210023623204
total_envstep_count: 6671567
total_train_sample_count: 5055823
total_episode_count: 18974
total_duration: 1506.2065620756402
[2023-06-29 11:08:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1600
train_sample_count: 1600
avg_envstep_per_episode: 228.57142857142858
avg_sample_per_episode: 228.57142857142858
avg_envstep_per_sec: 2605.359385820857
avg_train_sample_per_sec: 2605.359385820857
avg_episode_per_sec: 11.39844731296625
collect_time: 0.6141187310693785
reward_mean: 2239.667214597526
reward_std: 749.3075488568601
reward_max: 3534.784143369069
reward_min: 1588.9967375442297
total_envstep_count: 6675991
total_train_sample_count: 5059023
total_episode_count: 18981
total_duration: 1506.8206808067096
[2023-06-29 11:08:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 886
train_sample_count: 886
avg_envstep_per_episode: 177.2
avg_sample_per_episode: 177.2
avg_envstep_per_sec: 2502.4157789868955
avg_train_sample_per_sec: 2502.4157789868955
avg_episode_per_sec: 14.12198520872966
collect_time: 0.3540578697752208
reward_mean: 2075.63466900239
reward_std: 877.0375076108205
reward_max: 3557.2666684535784
reward_min: 1314.192618820555
total_envstep_count: 6680079
total_train_sample_count: 5062309
total_episode_count: 18986
total_duration: 1507.1747386764848
[2023-06-29 11:08:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1393
train_sample_count: 1393
avg_envstep_per_episode: 174.125
avg_sample_per_episode: 174.125
avg_envstep_per_sec: 2602.0307886393557
avg_train_sample_per_sec: 2602.0307886393557
avg_episode_per_sec: 14.943464687088907
collect_time: 0.5353510827319696
reward_mean: 1969.908521150936
reward_std: 1059.1402452935254
reward_max: 3511.6184570327537
reward_min: 265.54437497742634
total_envstep_count: 6684223
total_train_sample_count: 5065702
total_episode_count: 18994
total_duration: 1507.7100897592168
[2023-06-29 11:08:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2958
train_sample_count: 2958
avg_envstep_per_episode: 295.8
avg_sample_per_episode: 295.8
avg_envstep_per_sec: 2517.499628844358
avg_train_sample_per_sec: 2517.499628844358
avg_episode_per_sec: 8.510816865599589
collect_time: 1.1749753470104187
reward_mean: 2335.32845075567
reward_std: 916.1013334540211
reward_max: 3541.160089856503
reward_min: 862.8056878646819
total_envstep_count: 6688967
total_train_sample_count: 5069060
total_episode_count: 19004
total_duration: 1508.885065106227
[2023-06-29 11:08:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1772
train_sample_count: 1772
avg_envstep_per_episode: 253.14285714285714
avg_sample_per_episode: 253.14285714285714
avg_envstep_per_sec: 2734.8883500618663
avg_train_sample_per_sec: 2734.8883500618663
avg_episode_per_sec: 10.803735017174414
collect_time: 0.6479240733757615
reward_mean: 1694.7329795837675
reward_std: 465.5912478738258
reward_max: 2565.1232098127607
reward_min: 1290.5132971126277
total_envstep_count: 6693007
total_train_sample_count: 5072432
total_episode_count: 19011
total_duration: 1509.532989179603
[2023-06-29 11:08:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2741
train_sample_count: 2741
avg_envstep_per_episode: 304.55555555555554
avg_sample_per_episode: 304.55555555555554
avg_envstep_per_sec: 2622.3642818865324
avg_train_sample_per_sec: 2622.3642818865324
avg_episode_per_sec: 8.61046280079489
collect_time: 1.0452399839842696
reward_mean: 2057.4289266602536
reward_std: 786.7979107913111
reward_max: 3432.9722039800945
reward_min: 637.086183869019
total_envstep_count: 6697231
total_train_sample_count: 5075973
total_episode_count: 19020
total_duration: 1510.5782291635871
[2023-06-29 11:08:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3107
train_sample_count: 3107
avg_envstep_per_episode: 388.375
avg_sample_per_episode: 388.375
avg_envstep_per_sec: 2447.6481614632266
avg_train_sample_per_sec: 2447.6481614632266
avg_episode_per_sec: 6.30228042861468
collect_time: 1.26938178816624
reward_mean: 2104.1250416148137
reward_std: 558.763598150959
reward_max: 3249.372233612523
reward_min: 1535.016376728822
total_envstep_count: 6702047
total_train_sample_count: 5079480
total_episode_count: 19028
total_duration: 1511.8476109517533
[2023-06-29 11:08:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2711
train_sample_count: 2711
avg_envstep_per_episode: 338.875
avg_sample_per_episode: 338.875
avg_envstep_per_sec: 2540.23217888224
avg_train_sample_per_sec: 2540.23217888224
avg_episode_per_sec: 7.496074301386176
collect_time: 1.0672252806406466
reward_mean: 1846.4468780437728
reward_std: 408.4135837912836
reward_max: 2526.315841373361
reward_min: 1275.7509785717566
total_envstep_count: 6706671
total_train_sample_count: 5082991
total_episode_count: 19036
total_duration: 1512.914836232394
[2023-06-29 11:08:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1301
train_sample_count: 1301
avg_envstep_per_episode: 260.2
avg_sample_per_episode: 260.2
avg_envstep_per_sec: 2663.426078636884
avg_train_sample_per_sec: 2663.426078636884
avg_episode_per_sec: 10.236072554330837
collect_time: 0.48846859705820683
reward_mean: 1934.063940987436
reward_std: 1112.743088820104
reward_max: 3502.9961785350533
reward_min: 698.9525524387051
total_envstep_count: 6711311
total_train_sample_count: 5086292
total_episode_count: 19041
total_duration: 1513.4033048294523
[2023-06-29 11:08:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 305.875
avg_sample_per_episode: 305.875
avg_envstep_per_sec: 2348.73567154299
avg_train_sample_per_sec: 2348.73567154299
avg_episode_per_sec: 7.678743511378799
collect_time: 1.0418371167294682
reward_mean: 2706.13122473617
reward_std: 857.7401633951634
reward_max: 3577.487623759724
reward_min: 1315.2080803376539
total_envstep_count: 6715639
total_train_sample_count: 5089539
total_episode_count: 19049
total_duration: 1514.4451419461818
[2023-06-29 11:08:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3503
train_sample_count: 3503
avg_envstep_per_episode: 291.9166666666667
avg_sample_per_episode: 291.9166666666667
avg_envstep_per_sec: 2542.2682865763927
avg_train_sample_per_sec: 2542.2682865763927
avg_episode_per_sec: 8.708883653701603
collect_time: 1.377903354455717
reward_mean: 1707.858030276105
reward_std: 621.7735212270653
reward_max: 3454.228275207332
reward_min: 1220.1859828048937
total_envstep_count: 6720191
total_train_sample_count: 5093042
total_episode_count: 19061
total_duration: 1515.8230453006374
[2023-06-29 11:08:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1394
train_sample_count: 1394
avg_envstep_per_episode: 232.33333333333334
avg_sample_per_episode: 232.33333333333334
avg_envstep_per_sec: 2422.138741084482
avg_train_sample_per_sec: 2422.138741084482
avg_episode_per_sec: 10.42527435187008
collect_time: 0.575524422426708
reward_mean: 1324.0136201729308
reward_std: 316.69920889916705
reward_max: 1894.163246796112
reward_min: 891.4700923018647
total_envstep_count: 6724839
total_train_sample_count: 5096436
total_episode_count: 19067
total_duration: 1516.3985697230642
[2023-06-29 11:08:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1623
train_sample_count: 1623
avg_envstep_per_episode: 270.5
avg_sample_per_episode: 270.5
avg_envstep_per_sec: 2387.7024707122605
avg_train_sample_per_sec: 2387.7024707122605
avg_episode_per_sec: 8.826996194869725
collect_time: 0.679732931513805
reward_mean: 2702.575961528292
reward_std: 975.4066238791481
reward_max: 3489.2061679365247
reward_min: 785.9057313195151
total_envstep_count: 6729319
total_train_sample_count: 5099659
total_episode_count: 19073
total_duration: 1517.078302654578
[2023-06-29 11:08:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2243
train_sample_count: 2243
avg_envstep_per_episode: 280.375
avg_sample_per_episode: 280.375
avg_envstep_per_sec: 2655.158141038212
avg_train_sample_per_sec: 2655.158141038212
avg_episode_per_sec: 9.47002457793388
collect_time: 0.8447707747919485
reward_mean: 2471.886383848382
reward_std: 881.6626577596907
reward_max: 3625.7353666000736
reward_min: 1409.6082534183795
total_envstep_count: 6734087
total_train_sample_count: 5103102
total_episode_count: 19081
total_duration: 1517.9230734293699
[2023-06-29 11:08:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 200.3
avg_sample_per_episode: 200.3
avg_envstep_per_sec: 2631.680593376628
avg_train_sample_per_sec: 2631.680593376628
avg_episode_per_sec: 13.138694924496397
collect_time: 0.7611106017353012
reward_mean: 1599.302770866832
reward_std: 497.32099889261553
reward_max: 2753.2319235001287
reward_min: 1030.533992841723
total_envstep_count: 6738383
total_train_sample_count: 5106305
total_episode_count: 19091
total_duration: 1518.6841840311051
[2023-06-29 11:08:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 138.85714285714286
avg_sample_per_episode: 138.85714285714286
avg_envstep_per_sec: 2133.896240861175
avg_train_sample_per_sec: 2133.896240861175
avg_episode_per_sec: 15.36756552060517
collect_time: 0.4555048091784119
reward_mean: 1626.0489488377737
reward_std: 670.1620917667609
reward_max: 2891.6354643995655
reward_min: 648.9834460286854
total_envstep_count: 6742631
total_train_sample_count: 5109677
total_episode_count: 19098
total_duration: 1519.1396888402835
[2023-06-29 11:09:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2898
train_sample_count: 2898
avg_envstep_per_episode: 241.5
avg_sample_per_episode: 241.5
avg_envstep_per_sec: 2460.8334635897563
avg_train_sample_per_sec: 2460.8334635897563
avg_episode_per_sec: 10.189786598715347
collect_time: 1.1776497852774337
reward_mean: 1825.393748670178
reward_std: 619.6200658564414
reward_max: 3477.1573583722998
reward_min: 1099.7660038019003
total_envstep_count: 6747071
total_train_sample_count: 5112975
total_episode_count: 19110
total_duration: 1520.317338625561
[2023-06-29 11:09:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2669
train_sample_count: 2669
avg_envstep_per_episode: 242.63636363636363
avg_sample_per_episode: 242.63636363636363
avg_envstep_per_sec: 2652.5441617854826
avg_train_sample_per_sec: 2652.5441617854826
avg_episode_per_sec: 10.932179010730726
collect_time: 1.0062037942484021
reward_mean: 1341.1738563349384
reward_std: 329.9402999583861
reward_max: 1695.3076277982038
reward_min: 461.80875858917454
total_envstep_count: 6751479
total_train_sample_count: 5116444
total_episode_count: 19121
total_duration: 1521.3235424198094
[2023-06-29 11:09:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2667
train_sample_count: 2667
avg_envstep_per_episode: 266.7
avg_sample_per_episode: 266.7
avg_envstep_per_sec: 2523.728423611629
avg_train_sample_per_sec: 2523.728423611629
avg_episode_per_sec: 9.46279873870127
collect_time: 1.0567698073405773
reward_mean: 1478.833940811554
reward_std: 472.9189001019493
reward_max: 2452.2490897864272
reward_min: 666.9752878435414
total_envstep_count: 6756791
total_train_sample_count: 5119911
total_episode_count: 19131
total_duration: 1522.38031222715
[2023-06-29 11:09:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1704
train_sample_count: 1704
avg_envstep_per_episode: 189.33333333333334
avg_sample_per_episode: 189.33333333333334
avg_envstep_per_sec: 2540.058193064667
avg_train_sample_per_sec: 2540.058193064667
avg_episode_per_sec: 13.415800315482397
collect_time: 0.670850772101432
reward_mean: 1798.1477478586842
reward_std: 728.9348966204326
reward_max: 3129.4532371502023
reward_min: 636.6025753031944
total_envstep_count: 6760935
total_train_sample_count: 5123215
total_episode_count: 19140
total_duration: 1523.0511629992513
[2023-06-29 11:09:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1949
train_sample_count: 1949
avg_envstep_per_episode: 243.625
avg_sample_per_episode: 243.625
avg_envstep_per_sec: 2539.5705244833894
avg_train_sample_per_sec: 2539.5705244833894
avg_episode_per_sec: 10.424096560219146
collect_time: 0.767452599252574
reward_mean: 1882.8401477628886
reward_std: 432.94741400031137
reward_max: 2702.0111705904756
reward_min: 1321.5188954342245
total_envstep_count: 6765871
total_train_sample_count: 5126764
total_episode_count: 19148
total_duration: 1523.8186155985038
[2023-06-29 11:09:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1545
train_sample_count: 1545
avg_envstep_per_episode: 171.66666666666666
avg_sample_per_episode: 171.66666666666666
avg_envstep_per_sec: 2510.1798974489857
avg_train_sample_per_sec: 2510.1798974489857
avg_episode_per_sec: 14.622407169605742
collect_time: 0.6154937347598606
reward_mean: 1739.0879848369157
reward_std: 832.0313932842251
reward_max: 3337.2931658777266
reward_min: 579.543280658441
total_envstep_count: 6770423
total_train_sample_count: 5130309
total_episode_count: 19157
total_duration: 1524.4341093332637
[2023-06-29 11:09:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1013
train_sample_count: 1013
avg_envstep_per_episode: 168.83333333333334
avg_sample_per_episode: 168.83333333333334
avg_envstep_per_sec: 2508.835614105349
avg_train_sample_per_sec: 2508.835614105349
avg_episode_per_sec: 14.859835818985287
collect_time: 0.40377296715043476
reward_mean: 2062.1360341069944
reward_std: 760.8087024814988
reward_max: 3276.1673187016872
reward_min: 1323.6714394465143
total_envstep_count: 6774087
total_train_sample_count: 5133722
total_episode_count: 19163
total_duration: 1524.837882300414
[2023-06-29 11:09:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1908
train_sample_count: 1908
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2380.564556333396
avg_train_sample_per_sec: 2380.564556333396
avg_episode_per_sec: 11.229078095912245
collect_time: 0.8014905518625164
reward_mean: 2128.493176293272
reward_std: 751.9064433371008
reward_max: 3453.8929099556267
reward_min: 1427.6686009442271
total_envstep_count: 6778343
total_train_sample_count: 5137230
total_episode_count: 19172
total_duration: 1525.6393728522767
[2023-06-29 11:09:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 204.5
avg_sample_per_episode: 204.5
avg_envstep_per_sec: 2198.096825157556
avg_train_sample_per_sec: 2198.096825157556
avg_episode_per_sec: 10.74863973182179
collect_time: 0.7442802251819522
reward_mean: 1720.8094233289662
reward_std: 510.15159340740246
reward_max: 2417.033454670211
reward_min: 753.2559142394862
total_envstep_count: 6782959
total_train_sample_count: 5140466
total_episode_count: 19180
total_duration: 1526.3836530774586
[2023-06-29 11:09:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 2457.208022610698
avg_train_sample_per_sec: 2457.208022610698
avg_episode_per_sec: 8.473131112450684
collect_time: 1.0621811324004085
reward_mean: 2251.8442755202304
reward_std: 854.1464045700026
reward_max: 3611.2558970203154
reward_min: 1292.924455679799
total_envstep_count: 6787775
total_train_sample_count: 5143876
total_episode_count: 19189
total_duration: 1527.445834209859
[2023-06-29 11:09:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 256.25
avg_sample_per_episode: 256.25
avg_envstep_per_sec: 2485.179873904178
avg_train_sample_per_sec: 2485.179873904178
avg_episode_per_sec: 9.69826292255289
collect_time: 0.4124449947318064
reward_mean: 2263.961254955376
reward_std: 773.2553564513053
reward_max: 3567.291466718229
reward_min: 1572.6203294145205
total_envstep_count: 6792167
total_train_sample_count: 5147301
total_episode_count: 19193
total_duration: 1527.8582792045909
[2023-06-29 11:09:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1832
train_sample_count: 1832
avg_envstep_per_episode: 261.7142857142857
avg_sample_per_episode: 261.7142857142857
avg_envstep_per_sec: 2523.4617156622126
avg_train_sample_per_sec: 2523.4617156622126
avg_episode_per_sec: 9.642048040194043
collect_time: 0.7259868412623183
reward_mean: 2464.003120345911
reward_std: 1044.0831716753005
reward_max: 3503.9978469314706
reward_min: 1134.5401891925492
total_envstep_count: 6796247
total_train_sample_count: 5150733
total_episode_count: 19200
total_duration: 1528.5842660458532
[2023-06-29 11:09:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 310.375
avg_sample_per_episode: 310.375
avg_envstep_per_sec: 2415.3032826163258
avg_train_sample_per_sec: 2415.3032826163258
avg_episode_per_sec: 7.781887338272496
collect_time: 1.0280282471650282
reward_mean: 2515.0023470914625
reward_std: 925.1069702661712
reward_max: 3464.786243501427
reward_min: 1190.8474368396908
total_envstep_count: 6800719
total_train_sample_count: 5154016
total_episode_count: 19208
total_duration: 1529.6122942930183
[2023-06-29 11:09:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2958
train_sample_count: 2958
avg_envstep_per_episode: 422.57142857142856
avg_sample_per_episode: 422.57142857142856
avg_envstep_per_sec: 2093.244979158002
avg_train_sample_per_sec: 2093.244979158002
avg_episode_per_sec: 4.953588524038544
collect_time: 1.413116968846065
reward_mean: 2515.663361654952
reward_std: 675.9403485450836
reward_max: 3533.0060315108663
reward_min: 1645.5687808440978
total_envstep_count: 6805783
total_train_sample_count: 5157374
total_episode_count: 19215
total_duration: 1531.0254112618643
[2023-06-29 11:09:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1518
train_sample_count: 1518
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2441.8221061694103
avg_train_sample_per_sec: 2441.8221061694103
avg_episode_per_sec: 9.651470775373163
collect_time: 0.6216669085617178
reward_mean: 1956.9125829492084
reward_std: 718.2558371094798
reward_max: 3467.089146580369
reward_min: 1178.7413151210767
total_envstep_count: 6810479
total_train_sample_count: 5160892
total_episode_count: 19221
total_duration: 1531.647078170426
[2023-06-29 11:09:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2120
train_sample_count: 2120
avg_envstep_per_episode: 235.55555555555554
avg_sample_per_episode: 235.55555555555554
avg_envstep_per_sec: 2545.6470353822015
avg_train_sample_per_sec: 2545.6470353822015
avg_episode_per_sec: 10.806992131339534
collect_time: 0.8327941660936922
reward_mean: 2317.4147161228993
reward_std: 815.0729556840055
reward_max: 3510.396685469588
reward_min: 1176.13510177608
total_envstep_count: 6815199
total_train_sample_count: 5164212
total_episode_count: 19230
total_duration: 1532.4798723365197
[2023-06-29 11:09:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3385
train_sample_count: 3385
avg_envstep_per_episode: 282.0833333333333
avg_sample_per_episode: 282.0833333333333
avg_envstep_per_sec: 2239.4456982855827
avg_train_sample_per_sec: 2239.4456982855827
avg_episode_per_sec: 7.938950776787886
collect_time: 1.5115347528146814
reward_mean: 1776.4087462138848
reward_std: 642.3142600955881
reward_max: 3496.4049404459356
reward_min: 999.3523651041406
total_envstep_count: 6819999
total_train_sample_count: 5167597
total_episode_count: 19242
total_duration: 1533.9914070893344
[2023-06-29 11:10:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1523
train_sample_count: 1523
avg_envstep_per_episode: 253.83333333333334
avg_sample_per_episode: 253.83333333333334
avg_envstep_per_sec: 2219.0653843254468
avg_train_sample_per_sec: 2219.0653843254468
avg_episode_per_sec: 8.742214252102878
collect_time: 0.6863249775143343
reward_mean: 1557.1465903485378
reward_std: 311.9621052585837
reward_max: 2082.746314036514
reward_min: 1090.4462210329048
total_envstep_count: 6824559
total_train_sample_count: 5171120
total_episode_count: 19248
total_duration: 1534.6777320668486
[2023-06-29 11:10:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2352
train_sample_count: 2352
avg_envstep_per_episode: 235.2
avg_sample_per_episode: 235.2
avg_envstep_per_sec: 2341.661059298878
avg_train_sample_per_sec: 2341.661059298878
avg_episode_per_sec: 9.956041918787747
collect_time: 1.0044152165660634
reward_mean: 1992.6488965207113
reward_std: 992.1347528918218
reward_max: 3560.9175910663403
reward_min: 503.43158440358286
total_envstep_count: 6829255
total_train_sample_count: 5174672
total_episode_count: 19258
total_duration: 1535.6821472834147
[2023-06-29 11:10:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 243.6
avg_sample_per_episode: 243.6
avg_envstep_per_sec: 2335.2962466347926
avg_train_sample_per_sec: 2335.2962466347926
avg_episode_per_sec: 9.586601997679772
collect_time: 1.043122474722564
reward_mean: 1725.6089557466853
reward_std: 554.8161300405823
reward_max: 2645.817162995658
reward_min: 915.928972563662
total_envstep_count: 6833399
total_train_sample_count: 5177908
total_episode_count: 19268
total_duration: 1536.7252697581373
[2023-06-29 11:10:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 351.14285714285717
avg_sample_per_episode: 351.14285714285717
avg_envstep_per_sec: 2318.7272094484574
avg_train_sample_per_sec: 2318.7272094484574
avg_episode_per_sec: 6.603372850341417
collect_time: 1.060064327525906
reward_mean: 2156.1563883666017
reward_std: 664.6694131410597
reward_max: 3174.3074280245933
reward_min: 1269.6679749054615
total_envstep_count: 6838327
total_train_sample_count: 5181166
total_episode_count: 19275
total_duration: 1537.7853340856632
[2023-06-29 11:10:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2678
train_sample_count: 2678
avg_envstep_per_episode: 267.8
avg_sample_per_episode: 267.8
avg_envstep_per_sec: 2461.8667456095573
avg_train_sample_per_sec: 2461.8667456095573
avg_episode_per_sec: 9.192930342081992
collect_time: 1.0877924261237495
reward_mean: 1799.003025393216
reward_std: 897.2808462168222
reward_max: 3526.4478448457216
reward_min: 413.76997179228994
total_envstep_count: 6842791
total_train_sample_count: 5184644
total_episode_count: 19285
total_duration: 1538.873126511787
[2023-06-29 11:10:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2992
train_sample_count: 2992
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 2375.948419074737
avg_train_sample_per_sec: 2375.948419074737
avg_episode_per_sec: 8.735104481892416
collect_time: 1.2592865972928702
reward_mean: 1545.8090049246036
reward_std: 565.2809754635128
reward_max: 2433.1254581595417
reward_min: 566.8391973412356
total_envstep_count: 6847703
total_train_sample_count: 5188036
total_episode_count: 19296
total_duration: 1540.1324131090798
[2023-06-29 11:10:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3073
train_sample_count: 3073
avg_envstep_per_episode: 256.0833333333333
avg_sample_per_episode: 256.0833333333333
avg_envstep_per_sec: 2404.3377098801775
avg_train_sample_per_sec: 2404.3377098801775
avg_episode_per_sec: 9.388887900605964
collect_time: 1.2781066434103994
reward_mean: 1443.8264330685106
reward_std: 388.91027933861295
reward_max: 2044.428592836551
reward_min: 800.2877530017286
total_envstep_count: 6852407
total_train_sample_count: 5191509
total_episode_count: 19308
total_duration: 1541.4105197524902
[2023-06-29 11:10:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2286
train_sample_count: 2286
avg_envstep_per_episode: 285.75
avg_sample_per_episode: 285.75
avg_envstep_per_sec: 2529.4284172232365
avg_train_sample_per_sec: 2529.4284172232365
avg_episode_per_sec: 8.85189297365962
collect_time: 0.9037614918984471
reward_mean: 1774.2853327620328
reward_std: 331.3600534810107
reward_max: 2220.1783535089307
reward_min: 1255.5753447432458
total_envstep_count: 6857679
total_train_sample_count: 5194995
total_episode_count: 19316
total_duration: 1542.3142812443887
[2023-06-29 11:10:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2052
train_sample_count: 2052
avg_envstep_per_episode: 256.5
avg_sample_per_episode: 256.5
avg_envstep_per_sec: 2516.3369384019593
avg_train_sample_per_sec: 2516.3369384019593
avg_episode_per_sec: 9.810280461606078
collect_time: 0.8154710796810685
reward_mean: 2141.0811139608686
reward_std: 717.2365210642912
reward_max: 3371.7476937047254
reward_min: 1287.422535357043
total_envstep_count: 6862519
total_train_sample_count: 5198247
total_episode_count: 19324
total_duration: 1543.1297523240698
[2023-06-29 11:10:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 201.0
avg_sample_per_episode: 201.0
avg_envstep_per_sec: 2378.3525782817924
avg_train_sample_per_sec: 2378.3525782817924
avg_episode_per_sec: 11.832599891949217
collect_time: 0.5070736824357883
reward_mean: 2149.215830154451
reward_std: 635.9024636085805
reward_max: 3530.266024963628
reward_min: 1556.3491584304375
total_envstep_count: 6866951
total_train_sample_count: 5201453
total_episode_count: 19330
total_duration: 1543.6368260065055
[2023-06-29 11:10:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3010
train_sample_count: 3010
avg_envstep_per_episode: 273.6363636363636
avg_sample_per_episode: 273.6363636363636
avg_envstep_per_sec: 2420.8669908379375
avg_train_sample_per_sec: 2420.8669908379375
avg_episode_per_sec: 8.847022225653593
collect_time: 1.243356207256205
reward_mean: 2240.551519126779
reward_std: 797.5593074162283
reward_max: 3491.430624703127
reward_min: 1230.555116157605
total_envstep_count: 6871199
total_train_sample_count: 5204863
total_episode_count: 19341
total_duration: 1544.8801822137618
[2023-06-29 11:10:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3157
train_sample_count: 3157
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2404.9769776690014
avg_train_sample_per_sec: 2404.9769776690014
avg_episode_per_sec: 8.37971072358537
collect_time: 1.3126944787055255
reward_mean: 1436.2658895582115
reward_std: 486.97002724729066
reward_max: 2811.826858522193
reward_min: 996.9370726369548
total_envstep_count: 6876447
total_train_sample_count: 5208420
total_episode_count: 19352
total_duration: 1546.1928766924673
[2023-06-29 11:10:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2188
train_sample_count: 2188
avg_envstep_per_episode: 218.8
avg_sample_per_episode: 218.8
avg_envstep_per_sec: 2434.4128498350397
avg_train_sample_per_sec: 2434.4128498350397
avg_episode_per_sec: 11.126201324657401
collect_time: 0.8987793504903094
reward_mean: 1535.2309331303773
reward_std: 265.9019302382658
reward_max: 1885.8153064324747
reward_min: 1188.508715025609
total_envstep_count: 6880919
total_train_sample_count: 5211808
total_episode_count: 19362
total_duration: 1547.0916560429575
[2023-06-29 11:10:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2571
train_sample_count: 2571
avg_envstep_per_episode: 257.1
avg_sample_per_episode: 257.1
avg_envstep_per_sec: 2547.397870098538
avg_train_sample_per_sec: 2547.397870098538
avg_episode_per_sec: 9.908198639045267
collect_time: 1.0092651918173068
reward_mean: 1743.525132973881
reward_std: 390.81267037869816
reward_max: 2601.0530636451376
reward_min: 1181.0274139458481
total_envstep_count: 6885343
total_train_sample_count: 5215179
total_episode_count: 19372
total_duration: 1548.100921234775
[2023-06-29 11:10:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2532
train_sample_count: 2532
avg_envstep_per_episode: 281.3333333333333
avg_sample_per_episode: 281.3333333333333
avg_envstep_per_sec: 2411.1739822107656
avg_train_sample_per_sec: 2411.1739822107656
avg_episode_per_sec: 8.57052363345059
collect_time: 1.0501108666071666
reward_mean: 1686.1097290604982
reward_std: 404.1961075129408
reward_max: 2596.751753698145
reward_min: 1266.175631041442
total_envstep_count: 6890119
total_train_sample_count: 5218511
total_episode_count: 19381
total_duration: 1549.151032101382
[2023-06-29 11:10:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2924
train_sample_count: 2924
avg_envstep_per_episode: 208.85714285714286
avg_sample_per_episode: 208.85714285714286
avg_envstep_per_sec: 2341.6707628807544
avg_train_sample_per_sec: 2341.6707628807544
avg_episode_per_sec: 11.211829918033708
collect_time: 1.2486810897373364
reward_mean: 1335.8454799211036
reward_std: 539.0978666865914
reward_max: 2757.2360595677847
reward_min: 595.4376717270867
total_envstep_count: 6895079
total_train_sample_count: 5221835
total_episode_count: 19395
total_duration: 1550.3997131911194
[2023-06-29 11:10:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3029
train_sample_count: 3029
avg_envstep_per_episode: 252.41666666666666
avg_sample_per_episode: 252.41666666666666
avg_envstep_per_sec: 2264.2642388493655
avg_train_sample_per_sec: 2264.2642388493655
avg_episode_per_sec: 8.970343633605937
collect_time: 1.3377413943256249
reward_mean: 1509.4887657057816
reward_std: 482.0067962887958
reward_max: 2467.516112288462
reward_min: 940.6805618140045
total_envstep_count: 6899396
total_train_sample_count: 5225264
total_episode_count: 19407
total_duration: 1551.737454585445
[2023-06-29 11:10:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 323.77777777777777
avg_sample_per_episode: 323.77777777777777
avg_envstep_per_sec: 2587.2119500957124
avg_train_sample_per_sec: 2587.2119500957124
avg_episode_per_sec: 7.990702659870079
collect_time: 1.1263089596861975
reward_mean: 1679.205343769786
reward_std: 477.59018236502277
reward_max: 2500.8299523550913
reward_min: 1067.7150774979768
total_envstep_count: 6904436
total_train_sample_count: 5228578
total_episode_count: 19416
total_duration: 1552.8637635451312
[2023-06-29 11:11:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 2351.2700277630483
avg_train_sample_per_sec: 2351.2700277630483
avg_episode_per_sec: 11.582610974202208
collect_time: 1.0360358322253451
reward_mean: 1294.482351821647
reward_std: 468.097365098399
reward_max: 2492.2550410154963
reward_min: 559.771927955276
total_envstep_count: 6908980
total_train_sample_count: 5231814
total_episode_count: 19428
total_duration: 1553.8997993773564
[2023-06-29 11:11:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2956
train_sample_count: 2956
avg_envstep_per_episode: 268.72727272727275
avg_sample_per_episode: 268.72727272727275
avg_envstep_per_sec: 2587.233822491727
avg_train_sample_per_sec: 2587.233822491727
avg_episode_per_sec: 9.627730733223611
collect_time: 1.1425329919168727
reward_mean: 1689.3660353116395
reward_std: 755.940359553995
reward_max: 3258.922222395276
reward_min: 628.695046339368
total_envstep_count: 6913404
total_train_sample_count: 5235170
total_episode_count: 19439
total_duration: 1555.0423323692733
[2023-06-29 11:11:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2661
train_sample_count: 2661
avg_envstep_per_episode: 241.9090909090909
avg_sample_per_episode: 241.9090909090909
avg_envstep_per_sec: 2549.5351347678734
avg_train_sample_per_sec: 2549.5351347678734
avg_episode_per_sec: 10.53922829103593
collect_time: 1.0437196819577366
reward_mean: 1276.1892351987276
reward_std: 300.02241182228096
reward_max: 1613.100939724218
reward_min: 782.0618323348657
total_envstep_count: 6918500
total_train_sample_count: 5238631
total_episode_count: 19450
total_duration: 1556.086052051231
[2023-06-29 11:11:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2890
train_sample_count: 2890
avg_envstep_per_episode: 240.83333333333334
avg_sample_per_episode: 240.83333333333334
avg_envstep_per_sec: 2661.917332317187
avg_train_sample_per_sec: 2661.917332317187
avg_episode_per_sec: 11.052943940417386
collect_time: 1.0856836029104886
reward_mean: 1598.9083956943443
reward_std: 582.6667090442646
reward_max: 2819.4307150801455
reward_min: 682.5345098585444
total_envstep_count: 6922812
total_train_sample_count: 5241921
total_episode_count: 19462
total_duration: 1557.1717356541415
[2023-06-29 11:11:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2637
train_sample_count: 2637
avg_envstep_per_episode: 263.7
avg_sample_per_episode: 263.7
avg_envstep_per_sec: 2555.7933508844026
avg_train_sample_per_sec: 2555.7933508844026
avg_episode_per_sec: 9.69204911218962
collect_time: 1.0317735583307222
reward_mean: 1444.3962711575105
reward_std: 654.2683362542457
reward_max: 3004.4440952913305
reward_min: 543.9130841160189
total_envstep_count: 6927388
total_train_sample_count: 5245358
total_episode_count: 19472
total_duration: 1558.2035092124722
[2023-06-29 11:11:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2820
train_sample_count: 2820
avg_envstep_per_episode: 256.3636363636364
avg_sample_per_episode: 256.3636363636364
avg_envstep_per_sec: 2428.042118456673
avg_train_sample_per_sec: 2428.042118456673
avg_episode_per_sec: 9.471086277667872
collect_time: 1.1614296055920421
reward_mean: 1523.5200492764839
reward_std: 727.6962405212358
reward_max: 3407.101575076354
reward_min: 622.8457371329455
total_envstep_count: 6931908
total_train_sample_count: 5248578
total_episode_count: 19483
total_duration: 1559.3649388180643
[2023-06-29 11:11:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1430
train_sample_count: 1430
avg_envstep_per_episode: 178.75
avg_sample_per_episode: 178.75
avg_envstep_per_sec: 2618.6505075339387
avg_train_sample_per_sec: 2618.6505075339387
avg_episode_per_sec: 14.649793049140914
collect_time: 0.5460827994747087
reward_mean: 1225.5720889401775
reward_std: 369.4547096944944
reward_max: 1684.853284513509
reward_min: 654.4924407680822
total_envstep_count: 6936372
total_train_sample_count: 5252008
total_episode_count: 19491
total_duration: 1559.911021617539
[2023-06-29 11:11:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2774
train_sample_count: 2774
avg_envstep_per_episode: 231.16666666666666
avg_sample_per_episode: 231.16666666666666
avg_envstep_per_sec: 2604.6947182304993
avg_train_sample_per_sec: 2604.6947182304993
avg_episode_per_sec: 11.267605125726746
collect_time: 1.0650000480227173
reward_mean: 1768.9417762625408
reward_std: 898.4751440912415
reward_max: 3218.1795303447766
reward_min: 532.3588037740101
total_envstep_count: 6941452
total_train_sample_count: 5255582
total_episode_count: 19503
total_duration: 1560.9760216655618
[2023-06-29 11:11:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2438
train_sample_count: 2438
avg_envstep_per_episode: 243.8
avg_sample_per_episode: 243.8
avg_envstep_per_sec: 2452.0131329954725
avg_train_sample_per_sec: 2452.0131329954725
avg_episode_per_sec: 10.057477986035572
collect_time: 0.9942850497793405
reward_mean: 1583.421904073109
reward_std: 281.7067041917681
reward_max: 1980.4413512978374
reward_min: 1093.8796875955518
total_envstep_count: 6945372
total_train_sample_count: 5258820
total_episode_count: 19513
total_duration: 1561.9703067153412
[2023-06-29 11:11:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2383
train_sample_count: 2383
avg_envstep_per_episode: 264.77777777777777
avg_sample_per_episode: 264.77777777777777
avg_envstep_per_sec: 2439.752180707929
avg_train_sample_per_sec: 2439.752180707929
avg_episode_per_sec: 9.214338911611984
collect_time: 0.9767385469898581
reward_mean: 1652.475232127329
reward_std: 783.8720080459542
reward_max: 3569.5587810522607
reward_min: 985.8453717877034
total_envstep_count: 6949940
total_train_sample_count: 5262403
total_episode_count: 19522
total_duration: 1562.9470452623311
[2023-06-29 11:11:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1733
train_sample_count: 1733
avg_envstep_per_episode: 247.57142857142858
avg_sample_per_episode: 247.57142857142858
avg_envstep_per_sec: 2334.165336846458
avg_train_sample_per_sec: 2334.165336846458
avg_episode_per_sec: 9.428250062276518
collect_time: 0.7424495483003555
reward_mean: 1880.9371447438327
reward_std: 708.7972653449604
reward_max: 3034.217143111179
reward_min: 941.4447466894869
total_envstep_count: 6954868
total_train_sample_count: 5265736
total_episode_count: 19529
total_duration: 1563.6894948106315
[2023-06-29 11:11:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2623
train_sample_count: 2623
avg_envstep_per_episode: 218.58333333333334
avg_sample_per_episode: 218.58333333333334
avg_envstep_per_sec: 2389.0982690633323
avg_train_sample_per_sec: 2389.0982690633323
avg_episode_per_sec: 10.9299196449714
collect_time: 1.0979037714628503
reward_mean: 1725.5185632312744
reward_std: 844.8967448974055
reward_max: 3355.7009116619547
reward_min: 622.3397951773643
total_envstep_count: 6959564
total_train_sample_count: 5269159
total_episode_count: 19541
total_duration: 1564.7873985820943
[2023-06-29 11:11:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2869
train_sample_count: 2869
avg_envstep_per_episode: 239.08333333333334
avg_sample_per_episode: 239.08333333333334
avg_envstep_per_sec: 2611.8586454987426
avg_train_sample_per_sec: 2611.8586454987426
avg_episode_per_sec: 10.924469761584145
collect_time: 1.0984514820296316
reward_mean: 1565.744279702306
reward_std: 827.028896325828
reward_max: 3577.6078555312924
reward_min: 721.441799142924
total_envstep_count: 6963972
total_train_sample_count: 5272428
total_episode_count: 19553
total_duration: 1565.8858500641238
[2023-06-29 11:11:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2229
train_sample_count: 2229
avg_envstep_per_episode: 202.63636363636363
avg_sample_per_episode: 202.63636363636363
avg_envstep_per_sec: 2385.9971845206346
avg_train_sample_per_sec: 2385.9971845206346
avg_episode_per_sec: 11.774773005709728
collect_time: 0.9342005994226784
reward_mean: 1199.3123217403756
reward_std: 284.56098788881354
reward_max: 1758.8875557192587
reward_min: 668.6192557431083
total_envstep_count: 6968428
total_train_sample_count: 5275857
total_episode_count: 19564
total_duration: 1566.8200506635465
[2023-06-29 11:11:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2313
train_sample_count: 2313
avg_envstep_per_episode: 192.75
avg_sample_per_episode: 192.75
avg_envstep_per_sec: 2459.750080889039
avg_train_sample_per_sec: 2459.750080889039
avg_episode_per_sec: 12.76134931719346
collect_time: 0.9403394344697008
reward_mean: 1332.6108425319796
reward_std: 432.27653848004303
reward_max: 2100.1607737697555
reward_min: 602.6402809193752
total_envstep_count: 6972740
total_train_sample_count: 5279370
total_episode_count: 19576
total_duration: 1567.7603900980162
[2023-06-29 11:11:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2525.8786042666575
avg_train_sample_per_sec: 2525.8786042666575
avg_episode_per_sec: 10.748419592624076
collect_time: 1.2094801368678456
reward_mean: 1367.163388591159
reward_std: 822.348529821442
reward_max: 3418.816182909203
reward_min: 335.0054412040026
total_envstep_count: 6977468
total_train_sample_count: 5282825
total_episode_count: 19589
total_duration: 1568.969870234884
[2023-06-29 11:11:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2445
train_sample_count: 2445
avg_envstep_per_episode: 222.27272727272728
avg_sample_per_episode: 222.27272727272728
avg_envstep_per_sec: 2632.4588842721228
avg_train_sample_per_sec: 2632.4588842721228
avg_episode_per_sec: 11.843373303473761
collect_time: 0.9287894350821152
reward_mean: 1268.878678139488
reward_std: 421.8005220258327
reward_max: 2214.6135171600813
reward_min: 533.3994602094186
total_envstep_count: 6981956
total_train_sample_count: 5286070
total_episode_count: 19600
total_duration: 1569.898659669966
[2023-06-29 11:11:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2979
train_sample_count: 2979
avg_envstep_per_episode: 229.15384615384616
avg_sample_per_episode: 229.15384615384616
avg_envstep_per_sec: 2457.5205595052626
avg_train_sample_per_sec: 2457.5205595052626
avg_episode_per_sec: 10.724326040137097
collect_time: 1.2121973867025224
reward_mean: 1358.9994930501744
reward_std: 854.71565709319
reward_max: 3384.4444316431677
reward_min: 588.6809954775405
total_envstep_count: 6986860
total_train_sample_count: 5289449
total_episode_count: 19613
total_duration: 1571.1108570566685
[2023-06-29 11:12:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1380
train_sample_count: 1380
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 2606.958419404225
avg_train_sample_per_sec: 2606.958419404225
avg_episode_per_sec: 15.112802431328841
collect_time: 0.5293525166064501
reward_mean: 1443.4587466084258
reward_std: 803.7420081094748
reward_max: 3164.8513243761117
reward_min: 611.9658743866602
total_envstep_count: 6991372
total_train_sample_count: 5292829
total_episode_count: 19621
total_duration: 1571.640209573275
[2023-06-29 11:12:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2916
train_sample_count: 2916
avg_envstep_per_episode: 194.4
avg_sample_per_episode: 194.4
avg_envstep_per_sec: 2337.97539312481
avg_train_sample_per_sec: 2337.97539312481
avg_episode_per_sec: 12.026622392617337
collect_time: 1.2472329728426412
reward_mean: 1485.2639546159671
reward_std: 745.5780411756023
reward_max: 2972.978488855381
reward_min: 603.7384406305716
total_envstep_count: 6996004
total_train_sample_count: 5296145
total_episode_count: 19636
total_duration: 1572.8874425461174
[2023-06-29 11:12:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 205.83333333333334
avg_sample_per_episode: 205.83333333333334
avg_envstep_per_sec: 2455.083110510944
avg_train_sample_per_sec: 2455.083110510944
avg_episode_per_sec: 11.927529281834547
collect_time: 1.0060759203732013
reward_mean: 1186.8529807502944
reward_std: 411.60411417082196
reward_max: 1631.9904866847405
reward_min: 330.4709043959061
total_envstep_count: 6999980
total_train_sample_count: 5299415
total_episode_count: 19648
total_duration: 1573.8935184664906
[2023-06-29 11:12:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3107
train_sample_count: 3107
avg_envstep_per_episode: 221.92857142857142
avg_sample_per_episode: 221.92857142857142
avg_envstep_per_sec: 2448.330029739762
avg_train_sample_per_sec: 2448.330029739762
avg_episode_per_sec: 11.032063217366161
collect_time: 1.2690282610021533
reward_mean: 1178.190363809677
reward_std: 630.2040563697864
reward_max: 2895.0335338716145
reward_min: 581.4936642995434
total_envstep_count: 7004452
total_train_sample_count: 5302922
total_episode_count: 19662
total_duration: 1575.1625467274928
[2023-06-29 11:12:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2809
train_sample_count: 2809
avg_envstep_per_episode: 280.9
avg_sample_per_episode: 280.9
avg_envstep_per_sec: 2396.450235009325
avg_train_sample_per_sec: 2396.450235009325
avg_episode_per_sec: 8.53132871131835
collect_time: 1.172150357626379
reward_mean: 1482.5246360866645
reward_std: 446.40574486175586
reward_max: 2229.4909770618374
reward_min: 672.5509710909953
total_envstep_count: 7008388
total_train_sample_count: 5306131
total_episode_count: 19672
total_duration: 1576.3346970851192
[2023-06-29 11:12:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3282
train_sample_count: 3282
avg_envstep_per_episode: 252.46153846153845
avg_sample_per_episode: 252.46153846153845
avg_envstep_per_sec: 2499.154035143178
avg_train_sample_per_sec: 2499.154035143178
avg_episode_per_sec: 9.899147610256342
collect_time: 1.313244383438723
reward_mean: 1187.7864714938328
reward_std: 482.8017059397879
reward_max: 2327.45791206384
reward_min: 513.9169412079618
total_envstep_count: 7012780
total_train_sample_count: 5309413
total_episode_count: 19685
total_duration: 1577.647941468558
[2023-06-29 11:12:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3084
train_sample_count: 3084
avg_envstep_per_episode: 220.28571428571428
avg_sample_per_episode: 220.28571428571428
avg_envstep_per_sec: 2626.2628727982897
avg_train_sample_per_sec: 2626.2628727982897
avg_episode_per_sec: 11.92207529804671
collect_time: 1.1742921974577474
reward_mean: 1042.1726598746632
reward_std: 383.7925804614005
reward_max: 1562.7520038360117
reward_min: 464.6605333899279
total_envstep_count: 7017516
total_train_sample_count: 5312897
total_episode_count: 19699
total_duration: 1578.8222336660158
[2023-06-29 11:12:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2825
train_sample_count: 2825
avg_envstep_per_episode: 256.8181818181818
avg_sample_per_episode: 256.8181818181818
avg_envstep_per_sec: 2510.9962459385315
avg_train_sample_per_sec: 2510.9962459385315
avg_episode_per_sec: 9.777330515158884
collect_time: 1.1250514629678803
reward_mean: 1428.2479516840804
reward_std: 753.6676663113121
reward_max: 3359.1871183170115
reward_min: 537.3513516472742
total_envstep_count: 7021860
total_train_sample_count: 5316122
total_episode_count: 19710
total_duration: 1579.9472851289836
[2023-06-29 11:12:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2874
train_sample_count: 2874
avg_envstep_per_episode: 239.5
avg_sample_per_episode: 239.5
avg_envstep_per_sec: 2448.7875995937234
avg_train_sample_per_sec: 2448.7875995937234
avg_episode_per_sec: 10.224582879305734
collect_time: 1.1736420098161324
reward_mean: 1274.9326912041781
reward_std: 524.2632043847899
reward_max: 2450.746757436187
reward_min: 491.97928113256427
total_envstep_count: 7025620
total_train_sample_count: 5319396
total_episode_count: 19722
total_duration: 1581.1209271387997
[2023-06-29 11:12:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3300
train_sample_count: 3300
avg_envstep_per_episode: 300.0
avg_sample_per_episode: 300.0
avg_envstep_per_sec: 2589.3001446692747
avg_train_sample_per_sec: 2589.3001446692747
avg_episode_per_sec: 8.631000482230917
collect_time: 1.2744756558230144
reward_mean: 1356.2646996232124
reward_std: 274.7922111620434
reward_max: 1814.0569034489747
reward_min: 926.6862073893408
total_envstep_count: 7030556
total_train_sample_count: 5322696
total_episode_count: 19733
total_duration: 1582.3954027946227
[2023-06-29 11:12:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3492
train_sample_count: 3492
avg_envstep_per_episode: 249.42857142857142
avg_sample_per_episode: 249.42857142857142
avg_envstep_per_sec: 2413.8395420485153
avg_train_sample_per_sec: 2413.8395420485153
avg_episode_per_sec: 9.67747811817847
collect_time: 1.4466578822536393
reward_mean: 1293.9202401088585
reward_std: 285.42322466749425
reward_max: 1778.7960040867551
reward_min: 911.5462948613335
total_envstep_count: 7035116
total_train_sample_count: 5326188
total_episode_count: 19747
total_duration: 1583.8420606768764
[2023-06-29 11:12:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2651
train_sample_count: 2651
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2354.7375192339678
avg_train_sample_per_sec: 2354.7375192339678
avg_episode_per_sec: 9.770695100555884
collect_time: 1.1258155010255286
reward_mean: 1199.6870555673775
reward_std: 170.6884031863476
reward_max: 1483.5266269566766
reward_min: 906.4266467997188
total_envstep_count: 7039748
total_train_sample_count: 5329639
total_episode_count: 19758
total_duration: 1584.9678761779019
[2023-06-29 11:12:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2909
train_sample_count: 2909
avg_envstep_per_episode: 223.76923076923077
avg_sample_per_episode: 223.76923076923077
avg_envstep_per_sec: 2501.797961258095
avg_train_sample_per_sec: 2501.797961258095
avg_episode_per_sec: 11.180259022466563
collect_time: 1.1627637583240866
reward_mean: 1342.0857262773336
reward_std: 325.3099811365317
reward_max: 2181.523818121626
reward_min: 918.3893273565456
total_envstep_count: 7045012
total_train_sample_count: 5332948
total_episode_count: 19771
total_duration: 1586.1306399362259
[2023-06-29 11:12:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3386
train_sample_count: 3386
avg_envstep_per_episode: 199.1764705882353
avg_sample_per_episode: 199.1764705882353
avg_envstep_per_sec: 2498.118914151013
avg_train_sample_per_sec: 2498.118914151013
avg_episode_per_sec: 12.542239084632966
collect_time: 1.3554198644505815
reward_mean: 1190.1778941008877
reward_std: 496.08552780831997
reward_max: 2905.8874777382534
reward_min: 415.1946768716751
total_envstep_count: 7049484
total_train_sample_count: 5336334
total_episode_count: 19788
total_duration: 1587.4860598006765
[2023-06-29 11:12:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3239
train_sample_count: 3239
avg_envstep_per_episode: 231.35714285714286
avg_sample_per_episode: 231.35714285714286
avg_envstep_per_sec: 2395.3778027696067
avg_train_sample_per_sec: 2395.3778027696067
avg_episode_per_sec: 10.35359346674112
collect_time: 1.3521875322777779
reward_mean: 1070.779471309634
reward_std: 344.33947936460936
reward_max: 1624.656467385487
reward_min: 565.3584737420167
total_envstep_count: 7054204
total_train_sample_count: 5339573
total_episode_count: 19802
total_duration: 1588.8382473329543
[2023-06-29 11:12:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3359
train_sample_count: 3359
avg_envstep_per_episode: 258.38461538461536
avg_sample_per_episode: 258.38461538461536
avg_envstep_per_sec: 2463.448076645181
avg_train_sample_per_sec: 2463.448076645181
avg_episode_per_sec: 9.534035426134967
collect_time: 1.3635359445344657
reward_mean: 1307.1328888206335
reward_std: 325.71385148995495
reward_max: 1878.0830868216758
reward_min: 678.1301747640134
total_envstep_count: 7058364
total_train_sample_count: 5342932
total_episode_count: 19815
total_duration: 1590.2017832774889
[2023-06-29 11:12:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 269.1666666666667
avg_sample_per_episode: 269.1666666666667
avg_envstep_per_sec: 2380.1869618350966
avg_train_sample_per_sec: 2380.1869618350966
avg_episode_per_sec: 8.842799858210885
collect_time: 1.3570362546266985
reward_mean: 1185.521293598502
reward_std: 229.2068334348233
reward_max: 1590.2674365055816
reward_min: 936.3538735730183
total_envstep_count: 7063084
total_train_sample_count: 5346162
total_episode_count: 19827
total_duration: 1591.5588195321156
[2023-06-29 11:12:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 214.93333333333334
avg_sample_per_episode: 214.93333333333334
avg_envstep_per_sec: 2550.4032025135107
avg_train_sample_per_sec: 2550.4032025135107
avg_episode_per_sec: 11.866019862811
collect_time: 1.2641138455373002
reward_mean: 1094.3570151866124
reward_std: 261.5012101360076
reward_max: 1417.7736326273239
reward_min: 366.47448827761514
total_envstep_count: 7067684
total_train_sample_count: 5349386
total_episode_count: 19842
total_duration: 1592.822933377653
[2023-06-29 11:12:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 202.07142857142858
avg_sample_per_episode: 202.07142857142858
avg_envstep_per_sec: 2508.9110647679254
avg_train_sample_per_sec: 2508.9110647679254
avg_episode_per_sec: 12.41596143752243
collect_time: 1.1275808217066805
reward_mean: 1050.3018141499617
reward_std: 159.5703582717238
reward_max: 1234.7180511929644
reward_min: 591.433469941425
total_envstep_count: 7071732
total_train_sample_count: 5352615
total_episode_count: 19856
total_duration: 1593.9505141993598
[2023-06-29 11:13:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3378
train_sample_count: 3378
avg_envstep_per_episode: 241.28571428571428
avg_sample_per_episode: 241.28571428571428
avg_envstep_per_sec: 2434.598294224534
avg_train_sample_per_sec: 2434.598294224534
avg_episode_per_sec: 10.090105423073854
collect_time: 1.3874978915468095
reward_mean: 1152.323878647611
reward_std: 286.57663079644834
reward_max: 1826.8170188212277
reward_min: 577.2446060180306
total_envstep_count: 7076364
total_train_sample_count: 5355993
total_episode_count: 19870
total_duration: 1595.3380120909067
[2023-06-29 11:13:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3297
train_sample_count: 3297
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 2486.5488195352696
avg_train_sample_per_sec: 2486.5488195352696
avg_episode_per_sec: 10.55859371352556
collect_time: 1.3259341518242147
reward_mean: 1159.366954906376
reward_std: 151.92760282840726
reward_max: 1503.2394593424706
reward_min: 968.8507848510103
total_envstep_count: 7080532
total_train_sample_count: 5359290
total_episode_count: 19884
total_duration: 1596.6639462427308
[2023-06-29 11:13:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 243.85714285714286
avg_sample_per_episode: 243.85714285714286
avg_envstep_per_sec: 2464.436869868893
avg_train_sample_per_sec: 2464.436869868893
avg_episode_per_sec: 10.106068007663886
collect_time: 1.3853063317388297
reward_mean: 1084.065993315244
reward_std: 200.9710673385606
reward_max: 1303.4541600602627
reward_min: 439.82116632645244
total_envstep_count: 7085076
total_train_sample_count: 5362704
total_episode_count: 19898
total_duration: 1598.0492525744696
[2023-06-29 11:13:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 228.64285714285714
avg_sample_per_episode: 228.64285714285714
avg_envstep_per_sec: 2394.0904931230107
avg_train_sample_per_sec: 2394.0904931230107
avg_episode_per_sec: 10.47087375936337
collect_time: 1.3370421916777269
reward_mean: 1101.7408634043118
reward_std: 164.30368632375252
reward_max: 1431.3011585085387
reward_min: 931.4426121151351
total_envstep_count: 7089548
total_train_sample_count: 5365905
total_episode_count: 19912
total_duration: 1599.3862947661473
[2023-06-29 11:13:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3333
train_sample_count: 3333
avg_envstep_per_episode: 256.38461538461536
avg_sample_per_episode: 256.38461538461536
avg_envstep_per_sec: 2534.8824494852033
avg_train_sample_per_sec: 2534.8824494852033
avg_episode_per_sec: 9.887030256017894
collect_time: 1.3148538705125685
reward_mean: 1272.3812143993907
reward_std: 294.7095692673283
reward_max: 2154.2530942452127
reward_min: 962.9936731501526
total_envstep_count: 7094324
total_train_sample_count: 5369238
total_episode_count: 19925
total_duration: 1600.7011486366598
[2023-06-29 11:13:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3115
train_sample_count: 3115
avg_envstep_per_episode: 259.5833333333333
avg_sample_per_episode: 259.5833333333333
avg_envstep_per_sec: 2439.659280199722
avg_train_sample_per_sec: 2439.659280199722
avg_episode_per_sec: 9.39836640847405
collect_time: 1.276817638135515
reward_mean: 1375.8867214608426
reward_std: 235.67859340847843
reward_max: 1833.2732280897462
reward_min: 1056.325774070096
total_envstep_count: 7098468
total_train_sample_count: 5372753
total_episode_count: 19937
total_duration: 1601.9779662747953
[2023-06-29 11:13:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2203
train_sample_count: 2203
avg_envstep_per_episode: 275.375
avg_sample_per_episode: 275.375
avg_envstep_per_sec: 2350.2419186460056
avg_train_sample_per_sec: 2350.2419186460056
avg_episode_per_sec: 8.534696027765794
collect_time: 0.9373503138218074
reward_mean: 1442.6800629582312
reward_std: 358.9702950560262
reward_max: 2118.227841332369
reward_min: 997.4050566195344
total_envstep_count: 7103180
total_train_sample_count: 5376156
total_episode_count: 19945
total_duration: 1602.915316588617
[2023-06-29 11:13:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3163
train_sample_count: 3163
avg_envstep_per_episode: 243.30769230769232
avg_sample_per_episode: 243.30769230769232
avg_envstep_per_sec: 2414.1099527641345
avg_train_sample_per_sec: 2414.1099527641345
avg_episode_per_sec: 9.922045332258536
collect_time: 1.3102137275803833
reward_mean: 1575.4387473211095
reward_std: 570.2340909392302
reward_max: 3018.6913691603268
reward_min: 1052.9173717755093
total_envstep_count: 7108036
total_train_sample_count: 5379719
total_episode_count: 19958
total_duration: 1604.2255303161974
[2023-06-29 11:13:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2926
train_sample_count: 2926
avg_envstep_per_episode: 243.83333333333334
avg_sample_per_episode: 243.83333333333334
avg_envstep_per_sec: 2481.74064160161
avg_train_sample_per_sec: 2481.74064160161
avg_episode_per_sec: 10.178020403014122
collect_time: 1.1790111951874567
reward_mean: 1385.872229980785
reward_std: 357.89704411417136
reward_max: 2487.573717326137
reward_min: 1091.693884901373
total_envstep_count: 7112476
total_train_sample_count: 5383045
total_episode_count: 19970
total_duration: 1605.4045415113849
[2023-06-29 11:13:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3009
train_sample_count: 3009
avg_envstep_per_episode: 250.75
avg_sample_per_episode: 250.75
avg_envstep_per_sec: 2437.676097148161
avg_train_sample_per_sec: 2437.676097148161
avg_episode_per_sec: 9.721539769284789
collect_time: 1.2343723612502218
reward_mean: 1306.6190125701648
reward_std: 373.2277341439904
reward_max: 2457.573444819858
reward_min: 950.8054227947018
total_envstep_count: 7116508
total_train_sample_count: 5386454
total_episode_count: 19982
total_duration: 1606.6389138726352
[2023-06-29 11:13:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3490
train_sample_count: 3490
avg_envstep_per_episode: 290.8333333333333
avg_sample_per_episode: 290.8333333333333
avg_envstep_per_sec: 2372.181128941411
avg_train_sample_per_sec: 2372.181128941411
avg_episode_per_sec: 8.156496718423188
collect_time: 1.4712198648833437
reward_mean: 1411.7736171798178
reward_std: 392.75000242141715
reward_max: 2449.0132177514683
reward_min: 970.3615295804727
total_envstep_count: 7121316
total_train_sample_count: 5389944
total_episode_count: 19994
total_duration: 1608.1101337375185
[2023-06-29 11:13:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2814
train_sample_count: 2814
avg_envstep_per_episode: 216.46153846153845
avg_sample_per_episode: 216.46153846153845
avg_envstep_per_sec: 2244.0451764186455
avg_train_sample_per_sec: 2244.0451764186455
avg_episode_per_sec: 10.366946444009379
collect_time: 1.2539854498343774
reward_mean: 1133.8686278487671
reward_std: 257.95543103338724
reward_max: 1852.304607235197
reward_min: 717.6449255323766
total_envstep_count: 7125676
total_train_sample_count: 5393158
total_episode_count: 20007
total_duration: 1609.3641191873528
[2023-06-29 11:13:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2210
train_sample_count: 2210
avg_envstep_per_episode: 245.55555555555554
avg_sample_per_episode: 245.55555555555554
avg_envstep_per_sec: 2376.926508786742
avg_train_sample_per_sec: 2376.926508786742
avg_episode_per_sec: 9.6797912122537
collect_time: 0.9297721203538822
reward_mean: 1388.9206027038067
reward_std: 582.6554450298286
reward_max: 2308.9574880231885
reward_min: 626.2767846730593
total_envstep_count: 7129868
total_train_sample_count: 5396568
total_episode_count: 20016
total_duration: 1610.2938913077066
[2023-06-29 11:13:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3349
train_sample_count: 3349
avg_envstep_per_episode: 304.45454545454544
avg_sample_per_episode: 304.45454545454544
avg_envstep_per_sec: 2601.084965866972
avg_train_sample_per_sec: 2601.084965866972
avg_episode_per_sec: 8.54342628382702
collect_time: 1.2875396397840233
reward_mean: 1787.1268288640715
reward_std: 1035.6366519595126
reward_max: 3438.055586218359
reward_min: 792.170925224877
total_envstep_count: 7134668
total_train_sample_count: 5399917
total_episode_count: 20027
total_duration: 1611.5814309474906
[2023-06-29 11:13:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1291
train_sample_count: 1291
avg_envstep_per_episode: 258.2
avg_sample_per_episode: 258.2
avg_envstep_per_sec: 2542.0681186458473
avg_train_sample_per_sec: 2542.0681186458473
avg_episode_per_sec: 9.845345153547045
collect_time: 0.507854211510159
reward_mean: 1579.4506068102855
reward_std: 427.00976072345304
reward_max: 2207.8942742513814
reward_min: 1044.9548214669892
total_envstep_count: 7138916
total_train_sample_count: 5403208
total_episode_count: 20032
total_duration: 1612.0892851590008
[2023-06-29 11:13:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2538
train_sample_count: 2538
avg_envstep_per_episode: 253.8
avg_sample_per_episode: 253.8
avg_envstep_per_sec: 2466.5629465369275
avg_train_sample_per_sec: 2466.5629465369275
avg_episode_per_sec: 9.718530128199085
collect_time: 1.0289621854424476
reward_mean: 2161.2321189551308
reward_std: 1016.6777942526683
reward_max: 3540.440000830624
reward_min: 646.715517286148
total_envstep_count: 7143412
total_train_sample_count: 5406546
total_episode_count: 20042
total_duration: 1613.1182473444433
[2023-06-29 11:13:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1879
train_sample_count: 1879
avg_envstep_per_episode: 208.77777777777777
avg_sample_per_episode: 208.77777777777777
avg_envstep_per_sec: 2536.9885267540158
avg_train_sample_per_sec: 2536.9885267540158
avg_episode_per_sec: 12.151621469284802
collect_time: 0.7406418989226222
reward_mean: 1299.0453506860965
reward_std: 592.2312037575045
reward_max: 2423.323486218513
reward_min: 493.2119379502761
total_envstep_count: 7147780
total_train_sample_count: 5410025
total_episode_count: 20051
total_duration: 1613.8588892433659
[2023-06-29 11:13:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 222.22222222222223
avg_sample_per_episode: 222.22222222222223
avg_envstep_per_sec: 2606.0590599660654
avg_train_sample_per_sec: 2606.0590599660654
avg_episode_per_sec: 11.727265769847294
collect_time: 0.7674423157647252
reward_mean: 1798.1684693808618
reward_std: 881.0977350221376
reward_max: 3448.0533210054045
reward_min: 661.077817982127
total_envstep_count: 7151996
total_train_sample_count: 5413225
total_episode_count: 20060
total_duration: 1614.6263315591307
[2023-06-29 11:14:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2970
train_sample_count: 2970
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 2496.8156410055594
avg_train_sample_per_sec: 2496.8156410055594
avg_episode_per_sec: 8.406786670052387
collect_time: 1.189515137290582
reward_mean: 1978.133287913574
reward_std: 919.6463600825901
reward_max: 3438.5295687350977
reward_min: 740.6114108153781
total_envstep_count: 7156572
total_train_sample_count: 5416595
total_episode_count: 20070
total_duration: 1615.8158466964212
[2023-06-29 11:14:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2516
train_sample_count: 2516
avg_envstep_per_episode: 228.72727272727272
avg_sample_per_episode: 228.72727272727272
avg_envstep_per_sec: 2502.5040024906557
avg_train_sample_per_sec: 2502.5040024906557
avg_episode_per_sec: 10.940995241413836
collect_time: 1.005392997372197
reward_mean: 1236.3188115514056
reward_std: 274.0638424095648
reward_max: 1753.9328675615973
reward_min: 621.9350411071597
total_envstep_count: 7161452
total_train_sample_count: 5419911
total_episode_count: 20081
total_duration: 1616.8212396937934
[2023-06-29 11:14:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2341
train_sample_count: 2341
avg_envstep_per_episode: 195.08333333333334
avg_sample_per_episode: 195.08333333333334
avg_envstep_per_sec: 2478.182390600161
avg_train_sample_per_sec: 2478.182390600161
avg_episode_per_sec: 12.703198926613384
collect_time: 0.94464394908119
reward_mean: 1424.8062955891417
reward_std: 646.5056725135764
reward_max: 3420.9545237000093
reward_min: 952.6758688271152
total_envstep_count: 7166052
total_train_sample_count: 5423452
total_episode_count: 20093
total_duration: 1617.7658836428745
[2023-06-29 11:14:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2365.5868936569022
avg_train_sample_per_sec: 2365.5868936569022
avg_episode_per_sec: 8.65458619630574
collect_time: 1.0399110709466042
reward_mean: 1954.9576028793203
reward_std: 841.9941242105721
reward_max: 3426.95881722124
reward_min: 981.8413859737161
total_envstep_count: 7170820
total_train_sample_count: 5426712
total_episode_count: 20102
total_duration: 1618.8057947138211
[2023-06-29 11:14:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2547
train_sample_count: 2547
avg_envstep_per_episode: 254.7
avg_sample_per_episode: 254.7
avg_envstep_per_sec: 2499.70316364818
avg_train_sample_per_sec: 2499.70316364818
avg_episode_per_sec: 9.814303744201728
collect_time: 1.0189209811147306
reward_mean: 1590.569816483351
reward_std: 742.0660622040322
reward_max: 3427.313411164024
reward_min: 952.2813894158252
total_envstep_count: 7175620
total_train_sample_count: 5430059
total_episode_count: 20112
total_duration: 1619.8247156949358
[2023-06-29 11:14:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2574
train_sample_count: 2574
avg_envstep_per_episode: 257.4
avg_sample_per_episode: 257.4
avg_envstep_per_sec: 2663.458270119356
avg_train_sample_per_sec: 2663.458270119356
avg_episode_per_sec: 10.347545726959424
collect_time: 0.9664127382347361
reward_mean: 1712.3581381473475
reward_std: 1003.9783392403501
reward_max: 3568.862395071544
reward_min: 718.9448254035032
total_envstep_count: 7180412
total_train_sample_count: 5433433
total_episode_count: 20122
total_duration: 1620.7911284331706
[2023-06-29 11:14:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2533
train_sample_count: 2533
avg_envstep_per_episode: 253.3
avg_sample_per_episode: 253.3
avg_envstep_per_sec: 2517.8971777354272
avg_train_sample_per_sec: 2517.8971777354272
avg_episode_per_sec: 9.940375751028139
collect_time: 1.0059981886465101
reward_mean: 1814.080029618166
reward_std: 1050.6523733823071
reward_max: 3475.059913287744
reward_min: 608.1059686875936
total_envstep_count: 7185204
total_train_sample_count: 5436766
total_episode_count: 20132
total_duration: 1621.7971266218171
[2023-06-29 11:14:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2248
train_sample_count: 2248
avg_envstep_per_episode: 224.8
avg_sample_per_episode: 224.8
avg_envstep_per_sec: 2482.316406471877
avg_train_sample_per_sec: 2482.316406471877
avg_episode_per_sec: 11.042332769003012
collect_time: 0.9056057455604898
reward_mean: 1491.3851926182995
reward_std: 831.5604670118595
reward_max: 3498.820227968091
reward_min: 596.6060846198317
total_envstep_count: 7189564
total_train_sample_count: 5440214
total_episode_count: 20142
total_duration: 1622.7027323673776
[2023-06-29 11:14:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2565
train_sample_count: 2565
avg_envstep_per_episode: 256.5
avg_sample_per_episode: 256.5
avg_envstep_per_sec: 2592.230480082134
avg_train_sample_per_sec: 2592.230480082134
avg_episode_per_sec: 10.106161715719821
collect_time: 0.9894953476199881
reward_mean: 1742.064019842097
reward_std: 1036.1021202978866
reward_max: 3526.597504264953
reward_min: 752.9116697054206
total_envstep_count: 7194284
total_train_sample_count: 5443579
total_episode_count: 20152
total_duration: 1623.6922277149977
[2023-06-29 11:14:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 2621.6797804716475
avg_train_sample_per_sec: 2621.6797804716475
avg_episode_per_sec: 9.638528604675175
collect_time: 0.5187513784598561
reward_mean: 1929.1306464600948
reward_std: 1016.8400769507701
reward_max: 3439.5750942629843
reward_min: 974.0253236206307
total_envstep_count: 7198804
total_train_sample_count: 5446939
total_episode_count: 20157
total_duration: 1624.2109790934576
[2023-06-29 11:14:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1349
train_sample_count: 1349
avg_envstep_per_episode: 168.625
avg_sample_per_episode: 168.625
avg_envstep_per_sec: 2449.208436101475
avg_train_sample_per_sec: 2449.208436101475
avg_episode_per_sec: 14.524586722618086
collect_time: 0.5507901982190089
reward_mean: 2254.1776634269927
reward_std: 1067.876860780614
reward_max: 3493.723931297218
reward_min: 600.0028866940479
total_envstep_count: 7203468
total_train_sample_count: 5450288
total_episode_count: 20165
total_duration: 1624.7617692916765
[2023-06-29 11:14:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 250.3
avg_sample_per_episode: 250.3
avg_envstep_per_sec: 2555.239416608241
avg_train_sample_per_sec: 2555.239416608241
avg_episode_per_sec: 10.208707217771638
collect_time: 0.9795559600917624
reward_mean: 1984.5505278580713
reward_std: 1084.3655785511066
reward_max: 3493.616709076101
reward_min: 638.3491626559049
total_envstep_count: 7207260
total_train_sample_count: 5453591
total_episode_count: 20175
total_duration: 1625.7413252517683
[2023-06-29 11:14:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2524
train_sample_count: 2524
avg_envstep_per_episode: 315.5
avg_sample_per_episode: 315.5
avg_envstep_per_sec: 2616.0097196568504
avg_train_sample_per_sec: 2616.0097196568504
avg_episode_per_sec: 8.29163144106767
collect_time: 0.9648282194957137
reward_mean: 1746.1226715079247
reward_std: 1052.2028956284926
reward_max: 3473.924847532019
reward_min: 614.5236780712651
total_envstep_count: 7211572
total_train_sample_count: 5456915
total_episode_count: 20183
total_duration: 1626.706153471264
[2023-06-29 11:14:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 266.6666666666667
avg_sample_per_episode: 266.6666666666667
avg_envstep_per_sec: 2698.480803152755
avg_train_sample_per_sec: 2698.480803152755
avg_episode_per_sec: 10.119303011822831
collect_time: 0.8893893175730483
reward_mean: 1609.7216802018906
reward_std: 988.0103240015989
reward_max: 3464.7378596050416
reward_min: 897.2541667623952
total_envstep_count: 7216244
total_train_sample_count: 5460115
total_episode_count: 20192
total_duration: 1627.595542788837
[2023-06-29 11:14:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2338
train_sample_count: 2338
avg_envstep_per_episode: 259.77777777777777
avg_sample_per_episode: 259.77777777777777
avg_envstep_per_sec: 2709.9709771602697
avg_train_sample_per_sec: 2709.9709771602697
avg_episode_per_sec: 10.431881434748686
collect_time: 0.8627398668490349
reward_mean: 1780.246278347512
reward_std: 807.565440785693
reward_max: 3379.4568309783645
reward_min: 961.3929357633461
total_envstep_count: 7220668
total_train_sample_count: 5463653
total_episode_count: 20201
total_duration: 1628.4582826556862
[2023-06-29 11:14:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2410
train_sample_count: 2410
avg_envstep_per_episode: 267.77777777777777
avg_sample_per_episode: 267.77777777777777
avg_envstep_per_sec: 2477.549656612867
avg_train_sample_per_sec: 2477.549656612867
avg_episode_per_sec: 9.252260128429793
collect_time: 0.9727352965731408
reward_mean: 1812.8623736906832
reward_std: 583.870659937348
reward_max: 3274.8704538009315
reward_min: 1192.6113302522413
total_envstep_count: 7224628
total_train_sample_count: 5466863
total_episode_count: 20210
total_duration: 1629.4310179522593
[2023-06-29 11:14:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2706
train_sample_count: 2706
avg_envstep_per_episode: 300.6666666666667
avg_sample_per_episode: 300.6666666666667
avg_envstep_per_sec: 2570.9951580362595
avg_train_sample_per_sec: 2570.9951580362595
avg_episode_per_sec: 8.550981678612837
collect_time: 1.052510733651812
reward_mean: 1778.649529761529
reward_std: 1104.75899492028
reward_max: 3616.9795346848036
reward_min: 461.93301881486286
total_envstep_count: 7229692
total_train_sample_count: 5470369
total_episode_count: 20219
total_duration: 1630.483528685911
[2023-06-29 11:14:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3124
train_sample_count: 3124
avg_envstep_per_episode: 223.14285714285714
avg_sample_per_episode: 223.14285714285714
avg_envstep_per_sec: 2626.871692302957
avg_train_sample_per_sec: 2626.871692302957
avg_episode_per_sec: 11.772152270243724
collect_time: 1.1892472742972897
reward_mean: 1376.9675572784388
reward_std: 750.535441497935
reward_max: 3397.5107976972986
reward_min: 344.9047026356703
total_envstep_count: 7234748
total_train_sample_count: 5473893
total_episode_count: 20233
total_duration: 1631.6727759602084
[2023-06-29 11:15:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3394
train_sample_count: 3394
avg_envstep_per_episode: 226.26666666666668
avg_sample_per_episode: 226.26666666666668
avg_envstep_per_sec: 2674.600211517907
avg_train_sample_per_sec: 2674.600211517907
avg_episode_per_sec: 11.820566639000768
collect_time: 1.2689746996145694
reward_mean: 1260.49042944833
reward_std: 639.7011328525103
reward_max: 3332.5682369334604
reward_min: 632.7270780345566
total_envstep_count: 7239772
total_train_sample_count: 5477287
total_episode_count: 20248
total_duration: 1632.941750659823
[2023-06-29 11:15:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2594
train_sample_count: 2594
avg_envstep_per_episode: 216.16666666666666
avg_sample_per_episode: 216.16666666666666
avg_envstep_per_sec: 2503.31426561864
avg_train_sample_per_sec: 2503.31426561864
avg_episode_per_sec: 11.580482339022236
collect_time: 1.036226268362254
reward_mean: 1201.7338036348558
reward_std: 610.2839729849143
reward_max: 3029.879252539452
reward_min: 840.5627555805906
total_envstep_count: 7244188
total_train_sample_count: 5480681
total_episode_count: 20260
total_duration: 1633.9779769281852
[2023-06-29 11:15:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 2650.7945790373847
avg_train_sample_per_sec: 2650.7945790373847
avg_episode_per_sec: 12.049066268351748
collect_time: 0.9129338120492174
reward_mean: 1423.5445491456717
reward_std: 706.1996309195722
reward_max: 2810.300130079329
reward_min: 466.775858726897
total_envstep_count: 7248396
total_train_sample_count: 5483901
total_episode_count: 20271
total_duration: 1634.8909107402344
[2023-06-29 11:15:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2411
train_sample_count: 2411
avg_envstep_per_episode: 401.8333333333333
avg_sample_per_episode: 401.8333333333333
avg_envstep_per_sec: 2618.19326793146
avg_train_sample_per_sec: 2618.19326793146
avg_episode_per_sec: 6.515619911899112
collect_time: 0.920864028462209
reward_mean: 2068.166240533469
reward_std: 689.6217641716916
reward_max: 3458.2081621103384
reward_min: 1517.9238032140504
total_envstep_count: 7252932
total_train_sample_count: 5487112
total_episode_count: 20277
total_duration: 1635.8117747686965
[2023-06-29 11:15:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 187.6153846153846
avg_sample_per_episode: 187.6153846153846
avg_envstep_per_sec: 2606.3182216555506
avg_train_sample_per_sec: 2606.3182216555506
avg_episode_per_sec: 13.89181503957448
collect_time: 0.9358028423907235
reward_mean: 1445.9176842123898
reward_std: 944.9066070098918
reward_max: 3580.535880018745
reward_min: 586.2972625521217
total_envstep_count: 7257308
total_train_sample_count: 5490351
total_episode_count: 20290
total_duration: 1636.7475776110873
[2023-06-29 11:15:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2857
train_sample_count: 2857
avg_envstep_per_episode: 219.76923076923077
avg_sample_per_episode: 219.76923076923077
avg_envstep_per_sec: 2497.933905092032
avg_train_sample_per_sec: 2497.933905092032
avg_episode_per_sec: 11.366167576547573
collect_time: 1.1437452344819903
reward_mean: 1312.082423050186
reward_std: 549.4106485633997
reward_max: 2476.4651357262073
reward_min: 857.617150988072
total_envstep_count: 7261788
total_train_sample_count: 5493608
total_episode_count: 20303
total_duration: 1637.8913228455692
[2023-06-29 11:15:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 204.75
avg_sample_per_episode: 204.75
avg_envstep_per_sec: 2421.1660234054307
avg_train_sample_per_sec: 2421.1660234054307
avg_episode_per_sec: 11.824986683298807
collect_time: 1.014800297149457
reward_mean: 1213.8815302337653
reward_std: 438.94848915248315
reward_max: 2262.303050362335
reward_min: 887.7018692486446
total_envstep_count: 7265812
total_train_sample_count: 5496865
total_episode_count: 20315
total_duration: 1638.9061231427186
[2023-06-29 11:15:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2999
train_sample_count: 2999
avg_envstep_per_episode: 272.6363636363636
avg_sample_per_episode: 272.6363636363636
avg_envstep_per_sec: 2631.491017510042
avg_train_sample_per_sec: 2631.491017510042
avg_episode_per_sec: 9.652017736782415
collect_time: 1.1396580797899514
reward_mean: 1499.8082612723376
reward_std: 623.8737903573375
reward_max: 3043.6654446457205
reward_min: 458.081498557449
total_envstep_count: 7270468
total_train_sample_count: 5500264
total_episode_count: 20326
total_duration: 1640.0457812225086
[2023-06-29 11:15:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1367
train_sample_count: 1367
avg_envstep_per_episode: 195.28571428571428
avg_sample_per_episode: 195.28571428571428
avg_envstep_per_sec: 2652.7975351103078
avg_train_sample_per_sec: 2652.7975351103078
avg_episode_per_sec: 13.58418635389331
collect_time: 0.515305062639527
reward_mean: 1414.1567052447226
reward_std: 303.52596230309155
reward_max: 1890.1338654509657
reward_min: 1055.911136655626
total_envstep_count: 7275172
total_train_sample_count: 5503631
total_episode_count: 20333
total_duration: 1640.5610862851481
[2023-06-29 11:15:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1772
train_sample_count: 1772
avg_envstep_per_episode: 253.14285714285714
avg_sample_per_episode: 253.14285714285714
avg_envstep_per_sec: 2421.139847985766
avg_train_sample_per_sec: 2421.139847985766
avg_episode_per_sec: 9.56432219858937
collect_time: 0.7318866778695956
reward_mean: 2039.6345964319407
reward_std: 1159.3902936065244
reward_max: 3528.5773710090043
reward_min: 624.3672401091846
total_envstep_count: 7279500
total_train_sample_count: 5507003
total_episode_count: 20340
total_duration: 1641.2929729630177
[2023-06-29 11:15:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 648
train_sample_count: 648
avg_envstep_per_episode: 129.6
avg_sample_per_episode: 129.6
avg_envstep_per_sec: 1992.4604323501117
avg_train_sample_per_sec: 1992.4604323501117
avg_episode_per_sec: 15.37392308912123
collect_time: 0.3252260318342596
reward_mean: 2880.0688553391674
reward_std: 1146.7728461693844
reward_max: 3466.2795575989117
reward_min: 586.5797008916071
total_envstep_count: 7284124
total_train_sample_count: 5510451
total_episode_count: 20345
total_duration: 1641.618198994852
[2023-06-29 11:15:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3250
train_sample_count: 3250
avg_envstep_per_episode: 361.1111111111111
avg_sample_per_episode: 361.1111111111111
avg_envstep_per_sec: 2505.746426593639
avg_train_sample_per_sec: 2505.746426593639
avg_episode_per_sec: 6.938990104413155
collect_time: 1.2970187108749522
reward_mean: 2924.1932800498344
reward_std: 993.751051780617
reward_max: 3508.9705993077246
reward_min: 976.829382371542
total_envstep_count: 7288924
total_train_sample_count: 5513701
total_episode_count: 20354
total_duration: 1642.915217705727
[2023-06-29 11:15:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1942
train_sample_count: 1942
avg_envstep_per_episode: 388.4
avg_sample_per_episode: 388.4
avg_envstep_per_sec: 2537.982451976362
avg_train_sample_per_sec: 2537.982451976362
avg_episode_per_sec: 6.534455334645629
collect_time: 0.7651747152497992
reward_mean: 2036.7999206415395
reward_std: 889.2619817616709
reward_max: 3508.813234876224
reward_min: 1253.4617288102882
total_envstep_count: 7293820
total_train_sample_count: 5517243
total_episode_count: 20359
total_duration: 1643.6803924209767
[2023-06-29 11:15:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1264
train_sample_count: 1264
avg_envstep_per_episode: 210.66666666666666
avg_sample_per_episode: 210.66666666666666
avg_envstep_per_sec: 2685.034514083055
avg_train_sample_per_sec: 2685.034514083055
avg_episode_per_sec: 12.745416997229691
collect_time: 0.4707574496231974
reward_mean: 2500.1738781639947
reward_std: 975.9083321197406
reward_max: 3470.48516597099
reward_min: 1283.8286283878942
total_envstep_count: 7298124
total_train_sample_count: 5520507
total_episode_count: 20365
total_duration: 1644.1511498706
[2023-06-29 11:15:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2331
train_sample_count: 2331
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2390.906716291514
avg_train_sample_per_sec: 2390.906716291514
avg_episode_per_sec: 9.231300062901598
collect_time: 0.9749439340801911
reward_mean: 2266.9674237680692
reward_std: 905.1170194240837
reward_max: 3454.101677477122
reward_min: 1207.5332322628917
total_envstep_count: 7303188
total_train_sample_count: 5524038
total_episode_count: 20374
total_duration: 1645.12609380468
[2023-06-29 11:15:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1489
train_sample_count: 1489
avg_envstep_per_episode: 248.16666666666666
avg_sample_per_episode: 248.16666666666666
avg_envstep_per_sec: 2431.5444066821187
avg_train_sample_per_sec: 2431.5444066821187
avg_episode_per_sec: 9.79802984559618
collect_time: 0.6123680060738699
reward_mean: 2375.855385479666
reward_std: 1015.3930987906951
reward_max: 3477.795900874992
reward_min: 829.4598387441831
total_envstep_count: 7307980
total_train_sample_count: 5527527
total_episode_count: 20380
total_duration: 1645.738461810754
[2023-06-29 11:15:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 337.8333333333333
avg_sample_per_episode: 337.8333333333333
avg_envstep_per_sec: 2538.0777192768533
avg_train_sample_per_sec: 2538.0777192768533
avg_episode_per_sec: 7.512810219862418
collect_time: 0.7986359064597639
reward_mean: 3121.0667759725934
reward_std: 743.7895723015013
reward_max: 3480.767497238472
reward_min: 1458.3148212471922
total_envstep_count: 7312324
total_train_sample_count: 5530754
total_episode_count: 20386
total_duration: 1646.5370977172138
[2023-06-29 11:15:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1309
train_sample_count: 1309
avg_envstep_per_episode: 327.25
avg_sample_per_episode: 327.25
avg_envstep_per_sec: 2612.407419417498
avg_train_sample_per_sec: 2612.407419417498
avg_episode_per_sec: 7.9829103725515616
collect_time: 0.5010703882826494
reward_mean: 2903.9573604155103
reward_std: 931.5099827195634
reward_max: 3445.533168925885
reward_min: 1290.5429957085432
total_envstep_count: 7317260
total_train_sample_count: 5534063
total_episode_count: 20390
total_duration: 1647.0381681054964
[2023-06-29 11:15:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 869
train_sample_count: 869
avg_envstep_per_episode: 217.25
avg_sample_per_episode: 217.25
avg_envstep_per_sec: 2749.6645366379503
avg_train_sample_per_sec: 2749.6645366379503
avg_episode_per_sec: 12.656683712947988
collect_time: 0.31603855249285695
reward_mean: 3400.1396210493995
reward_std: 72.2619179019314
reward_max: 3488.1427383056593
reward_min: 3295.189973562928
total_envstep_count: 7321108
total_train_sample_count: 5537332
total_episode_count: 20394
total_duration: 1647.3542066579894
[2023-06-29 11:16:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 181.66666666666666
avg_sample_per_episode: 181.66666666666666
avg_envstep_per_sec: 2564.322005631252
avg_train_sample_per_sec: 2564.322005631252
avg_episode_per_sec: 14.115533975951847
collect_time: 0.42506362212169907
reward_mean: 2520.0192819500658
reward_std: 860.9067557074621
reward_max: 3462.305834553201
reward_min: 1281.4258065786469
total_envstep_count: 7325316
total_train_sample_count: 5540822
total_episode_count: 20400
total_duration: 1647.7792702801112
[2023-06-29 11:16:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 982
train_sample_count: 982
avg_envstep_per_episode: 140.28571428571428
avg_sample_per_episode: 140.28571428571428
avg_envstep_per_sec: 2563.5422294831974
avg_train_sample_per_sec: 2563.5422294831974
avg_episode_per_sec: 18.273722613424013
collect_time: 0.38306371110491455
reward_mean: 2339.2840070251573
reward_std: 831.4384456758755
reward_max: 3455.940405446547
reward_min: 1326.5852214719387
total_envstep_count: 7329332
total_train_sample_count: 5544204
total_episode_count: 20407
total_duration: 1648.1623339912162
[2023-06-29 11:16:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1697
train_sample_count: 1697
avg_envstep_per_episode: 282.8333333333333
avg_sample_per_episode: 282.8333333333333
avg_envstep_per_sec: 2628.4878528589875
avg_train_sample_per_sec: 2628.4878528589875
avg_episode_per_sec: 9.29341609732111
collect_time: 0.6456183535922319
reward_mean: 2299.0309892098435
reward_std: 1241.9126100504297
reward_max: 3445.2578915147114
reward_min: 590.5310000518909
total_envstep_count: 7333740
total_train_sample_count: 5547501
total_episode_count: 20413
total_duration: 1648.8079523448084
[2023-06-29 11:16:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1319
train_sample_count: 1319
avg_envstep_per_episode: 219.83333333333334
avg_sample_per_episode: 219.83333333333334
avg_envstep_per_sec: 2644.7363151129257
avg_train_sample_per_sec: 2644.7363151129257
avg_episode_per_sec: 12.030642828413612
collect_time: 0.49872646753583105
reward_mean: 2692.3443720274404
reward_std: 881.3929079104729
reward_max: 3438.715100089263
reward_min: 1350.3691549340085
total_envstep_count: 7337332
total_train_sample_count: 5550820
total_episode_count: 20419
total_duration: 1649.3066788123442
[2023-06-29 11:16:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 338.1666666666667
avg_sample_per_episode: 338.1666666666667
avg_envstep_per_sec: 2643.288814777298
avg_train_sample_per_sec: 2643.288814777298
avg_episode_per_sec: 7.816526805649969
collect_time: 0.7676043528262526
reward_mean: 2298.8133276697954
reward_std: 1008.9562543406676
reward_max: 3429.1917939697405
reward_min: 1264.1821264579617
total_envstep_count: 7341740
total_train_sample_count: 5554049
total_episode_count: 20425
total_duration: 1650.0742831651705
[2023-06-29 11:16:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1981
train_sample_count: 1981
avg_envstep_per_episode: 247.625
avg_sample_per_episode: 247.625
avg_envstep_per_sec: 2505.308765599952
avg_train_sample_per_sec: 2505.308765599952
avg_episode_per_sec: 10.117349886319847
collect_time: 0.7907208992363883
reward_mean: 2177.703198853341
reward_std: 912.211374521231
reward_max: 3469.7199236714773
reward_min: 1211.0799533491463
total_envstep_count: 7346580
total_train_sample_count: 5557630
total_episode_count: 20433
total_duration: 1650.865004064407
[2023-06-29 11:16:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1510
train_sample_count: 1510
avg_envstep_per_episode: 302.0
avg_sample_per_episode: 302.0
avg_envstep_per_sec: 2649.9790872240455
avg_train_sample_per_sec: 2649.9790872240455
avg_episode_per_sec: 8.774765189483594
collect_time: 0.5698158175209537
reward_mean: 2744.1509013289806
reward_std: 859.3376776078304
reward_max: 3535.730892227726
reward_min: 1308.046959284281
total_envstep_count: 7351148
total_train_sample_count: 5561140
total_episode_count: 20438
total_duration: 1651.434819881928
[2023-06-29 11:16:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2298.284197036272
avg_train_sample_per_sec: 2298.284197036272
avg_episode_per_sec: 9.497042136513521
collect_time: 0.6317756532775238
reward_mean: 2802.3581244399084
reward_std: 929.3110945796942
reward_max: 3481.82225121734
reward_min: 1314.0260254542977
total_envstep_count: 7355764
total_train_sample_count: 5564592
total_episode_count: 20444
total_duration: 1652.0665955352056
[2023-06-29 11:16:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2182
train_sample_count: 2182
avg_envstep_per_episode: 272.75
avg_sample_per_episode: 272.75
avg_envstep_per_sec: 2620.7709469790802
avg_train_sample_per_sec: 2620.7709469790802
avg_episode_per_sec: 9.608692747860973
collect_time: 0.8325794371748342
reward_mean: 2495.323932291247
reward_std: 935.3634128735089
reward_max: 3478.773932593505
reward_min: 1266.5044339330552
total_envstep_count: 7361076
total_train_sample_count: 5567974
total_episode_count: 20452
total_duration: 1652.8991749723805
[2023-06-29 11:16:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1693
train_sample_count: 1693
avg_envstep_per_episode: 188.11111111111111
avg_sample_per_episode: 188.11111111111111
avg_envstep_per_sec: 2598.7016289390526
avg_train_sample_per_sec: 2598.7016289390526
avg_episode_per_sec: 13.81471627906171
collect_time: 0.6514791775811466
reward_mean: 1925.798817851554
reward_std: 791.4330129948005
reward_max: 3440.807781338174
reward_min: 1021.7339419348148
total_envstep_count: 7365044
total_train_sample_count: 5571267
total_episode_count: 20461
total_duration: 1653.5506541499617
[2023-06-29 11:16:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 950
train_sample_count: 950
avg_envstep_per_episode: 158.33333333333334
avg_sample_per_episode: 158.33333333333334
avg_envstep_per_sec: 2434.01912052709
avg_train_sample_per_sec: 2434.01912052709
avg_episode_per_sec: 15.372752340171093
collect_time: 0.3903009602464735
reward_mean: 1318.6253888710078
reward_std: 272.16522594359185
reward_max: 1698.123055197181
reward_min: 996.7673654209509
total_envstep_count: 7368724
total_train_sample_count: 5574617
total_episode_count: 20467
total_duration: 1653.9409551102083
[2023-06-29 11:16:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 2529.7601926926777
avg_train_sample_per_sec: 2529.7601926926777
avg_episode_per_sec: 21.80827752321274
collect_time: 0.3209790407586843
reward_mean: 2007.204852599892
reward_std: 987.5774301058311
reward_max: 3489.524176447457
reward_min: 962.5308770891626
total_envstep_count: 7372556
total_train_sample_count: 5577829
total_episode_count: 20474
total_duration: 1654.261934150967
[2023-06-29 11:16:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1650
train_sample_count: 1650
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2455.527274889452
avg_train_sample_per_sec: 2455.527274889452
avg_episode_per_sec: 8.929190090507099
collect_time: 0.6719534402542049
reward_mean: 2585.7342521703868
reward_std: 882.783408335595
reward_max: 3462.893554627275
reward_min: 1512.7463094396678
total_envstep_count: 7376724
total_train_sample_count: 5581079
total_episode_count: 20480
total_duration: 1654.933887591221
[2023-06-29 11:16:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2040
train_sample_count: 2040
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2338.8031705119292
avg_train_sample_per_sec: 2338.8031705119292
avg_episode_per_sec: 9.171777139262469
collect_time: 0.8722409930517899
reward_mean: 2281.516172516123
reward_std: 1183.6127818413834
reward_max: 3471.7158762809936
reward_min: 927.421688449659
total_envstep_count: 7380772
total_train_sample_count: 5584319
total_episode_count: 20488
total_duration: 1655.8061285842728
[2023-06-29 11:16:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1657
train_sample_count: 1657
avg_envstep_per_episode: 331.4
avg_sample_per_episode: 331.4
avg_envstep_per_sec: 2671.351224763669
avg_train_sample_per_sec: 2671.351224763669
avg_episode_per_sec: 8.060806351127548
collect_time: 0.6202853389848025
reward_mean: 2339.0772721145886
reward_std: 884.7664770979414
reward_max: 3446.4113275935006
reward_min: 1377.0750741041047
total_envstep_count: 7385044
total_train_sample_count: 5587576
total_episode_count: 20493
total_duration: 1656.4264139232575
[2023-06-29 11:16:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2633
train_sample_count: 2633
avg_envstep_per_episode: 292.55555555555554
avg_sample_per_episode: 292.55555555555554
avg_envstep_per_sec: 2499.6558407896237
avg_train_sample_per_sec: 2499.6558407896237
avg_episode_per_sec: 8.544209102585118
collect_time: 1.053345007354394
reward_mean: 2202.543867013061
reward_std: 1084.0358425660404
reward_max: 3482.5150025984476
reward_min: 999.164342499348
total_envstep_count: 7389964
total_train_sample_count: 5591009
total_episode_count: 20502
total_duration: 1657.479758930612
[2023-06-29 11:16:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1214
train_sample_count: 1214
avg_envstep_per_episode: 303.5
avg_sample_per_episode: 303.5
avg_envstep_per_sec: 2558.2274038125356
avg_train_sample_per_sec: 2558.2274038125356
avg_episode_per_sec: 8.42908535028842
collect_time: 0.4745473362496123
reward_mean: 1933.3273935331717
reward_std: 1025.8356073701937
reward_max: 3431.447090856271
reward_min: 932.5217130199968
total_envstep_count: 7393356
total_train_sample_count: 5594223
total_episode_count: 20506
total_duration: 1657.9543062668615
[2023-06-29 11:16:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 242.6
avg_sample_per_episode: 242.6
avg_envstep_per_sec: 2091.5991820870936
avg_train_sample_per_sec: 2091.5991820870936
avg_episode_per_sec: 8.621595969031713
collect_time: 0.5799390296135098
reward_mean: 3159.6773033650616
reward_std: 558.545683669096
reward_max: 3453.2483637077594
reward_min: 2042.7388216680658
total_envstep_count: 7397964
total_train_sample_count: 5597436
total_episode_count: 20511
total_duration: 1658.534245296475
[2023-06-29 11:16:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1455
train_sample_count: 1455
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 2537.9285596631335
avg_train_sample_per_sec: 2537.9285596631335
avg_episode_per_sec: 8.721403985096678
collect_time: 0.5733021894805134
reward_mean: 2587.0731158836447
reward_std: 858.5405675371125
reward_max: 3392.0433352644163
reward_min: 1011.7906664025135
total_envstep_count: 7402428
total_train_sample_count: 5600891
total_episode_count: 20516
total_duration: 1659.1075474859556
[2023-06-29 11:17:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 284.8333333333333
avg_sample_per_episode: 284.8333333333333
avg_envstep_per_sec: 2517.9240275111933
avg_train_sample_per_sec: 2517.9240275111933
avg_episode_per_sec: 8.83999073438687
collect_time: 0.6787337430864573
reward_mean: 3120.7685059454184
reward_std: 678.3295742382254
reward_max: 3513.651850694428
reward_min: 1608.0234644322854
total_envstep_count: 7407228
total_train_sample_count: 5604200
total_episode_count: 20522
total_duration: 1659.786281229042
[2023-06-29 11:17:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1828
train_sample_count: 1828
avg_envstep_per_episode: 228.5
avg_sample_per_episode: 228.5
avg_envstep_per_sec: 2617.9808551808605
avg_train_sample_per_sec: 2617.9808551808605
avg_episode_per_sec: 11.457246630988449
collect_time: 0.6982480396609755
reward_mean: 2082.1295171825495
reward_std: 1330.6047119434095
reward_max: 3388.8942784451247
reward_min: 41.55756157756356
total_envstep_count: 7411900
total_train_sample_count: 5607628
total_episode_count: 20530
total_duration: 1660.484529268703
[2023-06-29 11:17:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1640
train_sample_count: 1640
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2296.8142810966337
avg_train_sample_per_sec: 2296.8142810966337
avg_episode_per_sec: 8.402979077182808
collect_time: 0.7140324812056497
reward_mean: 2369.2391652793217
reward_std: 1106.9686917794295
reward_max: 3390.794476884605
reward_min: 632.183026801032
total_envstep_count: 7415564
total_train_sample_count: 5610868
total_episode_count: 20536
total_duration: 1661.1985617499085
[2023-06-29 11:17:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1604
train_sample_count: 1604
avg_envstep_per_episode: 229.14285714285714
avg_sample_per_episode: 229.14285714285714
avg_envstep_per_sec: 2605.6350167952696
avg_train_sample_per_sec: 2605.6350167952696
avg_episode_per_sec: 11.371225135640204
collect_time: 0.6155889023831114
reward_mean: 1869.9073397998075
reward_std: 1384.0573249321853
reward_max: 3538.8808784784305
reward_min: 166.79107795315693
total_envstep_count: 7419636
total_train_sample_count: 5614072
total_episode_count: 20543
total_duration: 1661.8141506522916
[2023-06-29 11:17:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1614
train_sample_count: 1614
avg_envstep_per_episode: 322.8
avg_sample_per_episode: 322.8
avg_envstep_per_sec: 2690.418115072435
avg_train_sample_per_sec: 2690.418115072435
avg_episode_per_sec: 8.334628609270245
collect_time: 0.5999067546259611
reward_mean: 2602.3266463541013
reward_std: 840.6709276553034
reward_max: 3477.1396047772787
reward_min: 1558.1122256754663
total_envstep_count: 7423412
total_train_sample_count: 5617286
total_episode_count: 20548
total_duration: 1662.4140574069174
[2023-06-29 11:17:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 203.66666666666666
avg_sample_per_episode: 203.66666666666666
avg_envstep_per_sec: 2515.553586344866
avg_train_sample_per_sec: 2515.553586344866
avg_episode_per_sec: 12.351326937863499
collect_time: 0.4857777654323726
reward_mean: 1950.7572204984654
reward_std: 1510.394587428246
reward_max: 3436.008203804597
reward_min: 165.305386221302
total_envstep_count: 7427636
total_train_sample_count: 5620508
total_episode_count: 20554
total_duration: 1662.8998351723499
[2023-06-29 11:17:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 271.1666666666667
avg_sample_per_episode: 271.1666666666667
avg_envstep_per_sec: 2468.4194487158798
avg_train_sample_per_sec: 2468.4194487158798
avg_episode_per_sec: 9.102960474674418
collect_time: 0.6591262278566138
reward_mean: 2633.0499507263557
reward_std: 1160.225570568865
reward_max: 3544.678501273179
reward_min: 977.416682399815
total_envstep_count: 7431516
total_train_sample_count: 5623735
total_episode_count: 20560
total_duration: 1663.5589614002065
[2023-06-29 11:17:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2591
train_sample_count: 2591
avg_envstep_per_episode: 259.1
avg_sample_per_episode: 259.1
avg_envstep_per_sec: 2682.7254584325924
avg_train_sample_per_sec: 2682.7254584325924
avg_episode_per_sec: 10.354015663576197
collect_time: 0.9658088537743315
reward_mean: 1820.054579496847
reward_std: 1065.1674723652252
reward_max: 3414.382696837822
reward_min: 840.9449162705973
total_envstep_count: 7435908
total_train_sample_count: 5627126
total_episode_count: 20570
total_duration: 1664.524770253981
[2023-06-29 11:17:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2397
train_sample_count: 2397
avg_envstep_per_episode: 217.9090909090909
avg_sample_per_episode: 217.9090909090909
avg_envstep_per_sec: 2585.465027577744
avg_train_sample_per_sec: 2585.465027577744
avg_episode_per_sec: 11.86487914199215
collect_time: 0.9271059459062527
reward_mean: 1237.5100036167532
reward_std: 731.7693734672116
reward_max: 3401.4847213691564
reward_min: 631.1076977653723
total_envstep_count: 7440188
total_train_sample_count: 5630723
total_episode_count: 20581
total_duration: 1665.4518761998872
[2023-06-29 11:17:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1682
train_sample_count: 1682
avg_envstep_per_episode: 240.28571428571428
avg_sample_per_episode: 240.28571428571428
avg_envstep_per_sec: 2366.864383033554
avg_train_sample_per_sec: 2366.864383033554
avg_episode_per_sec: 9.850208490627157
collect_time: 0.7106448565693572
reward_mean: 1770.6945560687564
reward_std: 1057.439089390041
reward_max: 3443.4510220668267
reward_min: 819.0325581987207
total_envstep_count: 7444716
total_train_sample_count: 5634005
total_episode_count: 20588
total_duration: 1666.1625210564566
[2023-06-29 11:17:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1474
train_sample_count: 1474
avg_envstep_per_episode: 210.57142857142858
avg_sample_per_episode: 210.57142857142858
avg_envstep_per_sec: 2248.5963639156157
avg_train_sample_per_sec: 2248.5963639156157
avg_episode_per_sec: 10.678544469070088
collect_time: 0.6555200495980681
reward_mean: 2264.1006215785396
reward_std: 1104.003367945455
reward_max: 3432.0693677275494
reward_min: 988.1401312453269
total_envstep_count: 7449356
total_train_sample_count: 5637479
total_episode_count: 20595
total_duration: 1666.8180411060548
[2023-06-29 11:17:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1204
train_sample_count: 1204
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 2566.1275589107986
avg_train_sample_per_sec: 2566.1275589107986
avg_episode_per_sec: 14.9193462727372
collect_time: 0.46918945857509975
reward_mean: 2175.4226533736296
reward_std: 958.9473821125118
reward_max: 3454.982844652696
reward_min: 871.9944875666166
total_envstep_count: 7453428
total_train_sample_count: 5640683
total_episode_count: 20602
total_duration: 1667.28723056463
[2023-06-29 11:17:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3304
train_sample_count: 3304
avg_envstep_per_episode: 300.3636363636364
avg_sample_per_episode: 300.3636363636364
avg_envstep_per_sec: 2581.1755533496153
avg_train_sample_per_sec: 2581.1755533496153
avg_episode_per_sec: 8.593502144929108
collect_time: 1.2800369179509579
reward_mean: 2177.0622870457855
reward_std: 1118.8718346668736
reward_max: 3528.175530972952
reward_min: 795.0552022045517
total_envstep_count: 7457948
total_train_sample_count: 5643987
total_episode_count: 20613
total_duration: 1668.567267482581
[2023-06-29 11:17:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2550
train_sample_count: 2550
avg_envstep_per_episode: 231.8181818181818
avg_sample_per_episode: 231.8181818181818
avg_envstep_per_sec: 2660.1477359072774
avg_train_sample_per_sec: 2660.1477359072774
avg_episode_per_sec: 11.475147096070607
collect_time: 0.95859337644279
reward_mean: 1115.0336460042768
reward_std: 208.21435794049577
reward_max: 1457.9059709380645
reward_min: 833.1743016474175
total_envstep_count: 7462620
total_train_sample_count: 5647337
total_episode_count: 20624
total_duration: 1669.5258608590239
[2023-06-29 11:17:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2526
train_sample_count: 2526
avg_envstep_per_episode: 180.42857142857142
avg_sample_per_episode: 180.42857142857142
avg_envstep_per_sec: 2586.7565350777245
avg_train_sample_per_sec: 2586.7565350777245
avg_episode_per_sec: 14.336734557042021
collect_time: 0.9765124648362398
reward_mean: 1254.325158253231
reward_std: 758.6801557637967
reward_max: 3487.71495684102
reward_min: 634.8103040765947
total_envstep_count: 7466580
total_train_sample_count: 5650663
total_episode_count: 20638
total_duration: 1670.5023733238602
[2023-06-29 11:17:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2433
train_sample_count: 2433
avg_envstep_per_episode: 243.3
avg_sample_per_episode: 243.3
avg_envstep_per_sec: 2474.668053385717
avg_train_sample_per_sec: 2474.668053385717
avg_episode_per_sec: 10.171262036110633
collect_time: 0.9831621645865962
reward_mean: 1344.6500605619683
reward_std: 603.91388817854
reward_max: 2639.8541894126042
reward_min: 823.0115141803553
total_envstep_count: 7471300
total_train_sample_count: 5653896
total_episode_count: 20648
total_duration: 1671.4855354884469
[2023-06-29 11:17:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3441
train_sample_count: 3441
avg_envstep_per_episode: 202.41176470588235
avg_sample_per_episode: 202.41176470588235
avg_envstep_per_sec: 2481.48228791557
avg_train_sample_per_sec: 2481.48228791557
avg_episode_per_sec: 12.25957538348291
collect_time: 1.3866711911493912
reward_mean: 1228.347097848264
reward_std: 491.83050111185776
reward_max: 2641.28302110571
reward_min: 502.53892562967286
total_envstep_count: 7475940
total_train_sample_count: 5657337
total_episode_count: 20665
total_duration: 1672.8722066795963
[2023-06-29 11:17:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3302
train_sample_count: 3302
avg_envstep_per_episode: 220.13333333333333
avg_sample_per_episode: 220.13333333333333
avg_envstep_per_sec: 2579.4959928362587
avg_train_sample_per_sec: 2579.4959928362587
avg_episode_per_sec: 11.717880040140486
collect_time: 1.2800950298702807
reward_mean: 1066.2370811710346
reward_std: 178.5385702465061
reward_max: 1534.3550749951282
reward_min: 840.7148556038458
total_envstep_count: 7480348
total_train_sample_count: 5660639
total_episode_count: 20680
total_duration: 1674.1523017094667
[2023-06-29 11:18:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2687
train_sample_count: 2687
avg_envstep_per_episode: 244.27272727272728
avg_sample_per_episode: 244.27272727272728
avg_envstep_per_sec: 2418.914162593984
avg_train_sample_per_sec: 2418.914162593984
avg_episode_per_sec: 9.902514249547385
collect_time: 1.1108289998676626
reward_mean: 1232.203010127957
reward_std: 259.4347647780953
reward_max: 1806.9325631676315
reward_min: 976.590476405566
total_envstep_count: 7485164
total_train_sample_count: 5664126
total_episode_count: 20691
total_duration: 1675.2631307093343
[2023-06-29 11:18:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2504
train_sample_count: 2504
avg_envstep_per_episode: 250.4
avg_sample_per_episode: 250.4
avg_envstep_per_sec: 2426.336991111735
avg_train_sample_per_sec: 2426.336991111735
avg_episode_per_sec: 9.689844213705012
collect_time: 1.0320083356816319
reward_mean: 1655.9652593392166
reward_std: 704.5301099008717
reward_max: 3114.185866794854
reward_min: 1012.304896063078
total_envstep_count: 7489668
total_train_sample_count: 5667430
total_episode_count: 20701
total_duration: 1676.295139045016
[2023-06-29 11:18:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 222.55555555555554
avg_sample_per_episode: 222.55555555555554
avg_envstep_per_sec: 2665.0722477278337
avg_train_sample_per_sec: 2665.0722477278337
avg_episode_per_sec: 11.974862820544434
collect_time: 0.7515743716545403
reward_mean: 1478.2168123464066
reward_std: 710.120095482292
reward_max: 2948.2921072663557
reward_min: 667.1609669599668
total_envstep_count: 7493412
total_train_sample_count: 5670633
total_episode_count: 20710
total_duration: 1677.0467134166704
[2023-06-29 11:18:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 302.5
avg_sample_per_episode: 302.5
avg_envstep_per_sec: 2695.0857302130403
avg_train_sample_per_sec: 2695.0857302130403
avg_episode_per_sec: 8.909374314753853
collect_time: 0.8979306197464466
reward_mean: 1546.9274330381018
reward_std: 783.8619120073532
reward_max: 3516.522769760809
reward_min: 947.0300256806264
total_envstep_count: 7497652
total_train_sample_count: 5673853
total_episode_count: 20718
total_duration: 1677.9446440364168
[2023-06-29 11:18:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 207.0
avg_sample_per_episode: 207.0
avg_envstep_per_sec: 2354.205516245124
avg_train_sample_per_sec: 2354.205516245124
avg_episode_per_sec: 11.372973508430551
collect_time: 1.0551330301705748
reward_mean: 1463.3787189843385
reward_std: 943.2948109693631
reward_max: 3512.432917069336
reward_min: 648.0532526204588
total_envstep_count: 7501884
total_train_sample_count: 5677137
total_episode_count: 20730
total_duration: 1678.9997770665873
[2023-06-29 11:18:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2911
train_sample_count: 2911
avg_envstep_per_episode: 264.6363636363636
avg_sample_per_episode: 264.6363636363636
avg_envstep_per_sec: 2407.595494797
avg_train_sample_per_sec: 2407.595494797
avg_episode_per_sec: 9.097750066220199
collect_time: 1.2090901508542014
reward_mean: 1448.833155952977
reward_std: 916.6111195878528
reward_max: 3390.896921308364
reward_min: 766.7348219258831
total_envstep_count: 7506844
total_train_sample_count: 5680448
total_episode_count: 20741
total_duration: 1680.2088672174416
[2023-06-29 11:18:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 536
train_sample_count: 536
avg_envstep_per_episode: 134.0
avg_sample_per_episode: 134.0
avg_envstep_per_sec: 2445.7816660005374
avg_train_sample_per_sec: 2445.7816660005374
avg_episode_per_sec: 18.252101985078635
collect_time: 0.2191528407670557
reward_mean: 1727.8487801517413
reward_std: 979.2201259618835
reward_max: 3396.541000850769
reward_min: 885.5633335745243
total_envstep_count: 7511308
total_train_sample_count: 5683784
total_episode_count: 20745
total_duration: 1680.4280200582086
[2023-06-29 11:18:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1329
train_sample_count: 1329
avg_envstep_per_episode: 189.85714285714286
avg_sample_per_episode: 189.85714285714286
avg_envstep_per_sec: 2635.848571453748
avg_train_sample_per_sec: 2635.848571453748
avg_episode_per_sec: 13.883325809011463
collect_time: 0.5042019539335743
reward_mean: 2330.763582704559
reward_std: 1114.5909397864068
reward_max: 3439.281226427325
reward_min: 889.4458190725368
total_envstep_count: 7515308
total_train_sample_count: 5687113
total_episode_count: 20752
total_duration: 1680.9322220121421
[2023-06-29 11:18:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2441
train_sample_count: 2441
avg_envstep_per_episode: 221.9090909090909
avg_sample_per_episode: 221.9090909090909
avg_envstep_per_sec: 2363.013225738182
avg_train_sample_per_sec: 2363.013225738182
avg_episode_per_sec: 10.648564310987302
collect_time: 1.0330031052777775
reward_mean: 1908.9028198659062
reward_std: 1167.6287147522478
reward_max: 3474.553512053947
reward_min: 893.9676365329584
total_envstep_count: 7519844
total_train_sample_count: 5690354
total_episode_count: 20763
total_duration: 1681.96522511742
[2023-06-29 11:18:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2812
train_sample_count: 2812
avg_envstep_per_episode: 234.33333333333334
avg_sample_per_episode: 234.33333333333334
avg_envstep_per_sec: 2511.4091477112274
avg_train_sample_per_sec: 2511.4091477112274
avg_episode_per_sec: 10.717250985965409
collect_time: 1.1196901160301642
reward_mean: 1423.5484200030287
reward_std: 888.03861602477
reward_max: 3464.5182243608715
reward_min: 302.56878302009125
total_envstep_count: 7524308
total_train_sample_count: 5693566
total_episode_count: 20775
total_duration: 1683.0849152334501
[2023-06-29 11:18:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2695
train_sample_count: 2695
avg_envstep_per_episode: 224.58333333333334
avg_sample_per_episode: 224.58333333333334
avg_envstep_per_sec: 2452.193856774218
avg_train_sample_per_sec: 2452.193856774218
avg_episode_per_sec: 10.918859473577223
collect_time: 1.0990158843090756
reward_mean: 1359.3902631562482
reward_std: 772.4346872037978
reward_max: 3507.1477679549293
reward_min: 854.820101422337
total_envstep_count: 7529116
total_train_sample_count: 5697061
total_episode_count: 20787
total_duration: 1684.1839311177591
[2023-06-29 11:18:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3408
train_sample_count: 3408
avg_envstep_per_episode: 227.2
avg_sample_per_episode: 227.2
avg_envstep_per_sec: 2569.4607740314386
avg_train_sample_per_sec: 2569.4607740314386
avg_episode_per_sec: 11.309246364574994
collect_time: 1.3263483274169265
reward_mean: 1348.3900441899452
reward_std: 755.9482718201112
reward_max: 3489.021277355568
reward_min: 880.7157572155619
total_envstep_count: 7533860
total_train_sample_count: 5700469
total_episode_count: 20802
total_duration: 1685.5102794451761
[2023-06-29 11:18:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2976
train_sample_count: 2976
avg_envstep_per_episode: 248.0
avg_sample_per_episode: 248.0
avg_envstep_per_sec: 2426.5949469884126
avg_train_sample_per_sec: 2426.5949469884126
avg_episode_per_sec: 9.784657044308116
collect_time: 1.2264098726874217
reward_mean: 1147.6437175164451
reward_std: 366.9072746193113
reward_max: 1985.845684761832
reward_min: 872.2118302411834
total_envstep_count: 7538788
total_train_sample_count: 5703845
total_episode_count: 20814
total_duration: 1686.7366893178635
[2023-06-29 11:18:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1945
train_sample_count: 1945
avg_envstep_per_episode: 216.11111111111111
avg_sample_per_episode: 216.11111111111111
avg_envstep_per_sec: 2189.8963721247333
avg_train_sample_per_sec: 2189.8963721247333
avg_episode_per_sec: 10.133196580525759
collect_time: 0.8881698808938963
reward_mean: 1554.1226276213756
reward_std: 805.615295313724
reward_max: 3512.5384097384313
reward_min: 776.0243132302671
total_envstep_count: 7544484
total_train_sample_count: 5707390
total_episode_count: 20823
total_duration: 1687.6248591987573
[2023-06-29 11:18:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3234
train_sample_count: 3234
avg_envstep_per_episode: 248.76923076923077
avg_sample_per_episode: 248.76923076923077
avg_envstep_per_sec: 2381.4219701670804
avg_train_sample_per_sec: 2381.4219701670804
avg_episode_per_sec: 9.572815588179358
collect_time: 1.3580121626966861
reward_mean: 1940.3618753012086
reward_std: 1113.9481714906133
reward_max: 3471.37788736435
reward_min: 796.8400497651844
total_envstep_count: 7549092
total_train_sample_count: 5710624
total_episode_count: 20836
total_duration: 1688.982871361454
[2023-06-29 11:18:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2657
train_sample_count: 2657
avg_envstep_per_episode: 241.54545454545453
avg_sample_per_episode: 241.54545454545453
avg_envstep_per_sec: 2357.563913911078
avg_train_sample_per_sec: 2357.563913911078
avg_episode_per_sec: 9.760332349650682
collect_time: 1.1270108031099664
reward_mean: 1151.4732957148742
reward_std: 431.6712881223684
reward_max: 2158.312948299748
reward_min: 300.7466771059891
total_envstep_count: 7553636
total_train_sample_count: 5714081
total_episode_count: 20847
total_duration: 1690.109882164564
[2023-06-29 11:18:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 225.8181818181818
avg_sample_per_episode: 225.8181818181818
avg_envstep_per_sec: 2399.830595357073
avg_train_sample_per_sec: 2399.830595357073
avg_episode_per_sec: 10.627269142080435
collect_time: 1.0350730609092862
reward_mean: 1486.1579187859968
reward_std: 936.9671808893532
reward_max: 3458.487202193142
reward_min: 802.0245840409827
total_envstep_count: 7558804
total_train_sample_count: 5717365
total_episode_count: 20858
total_duration: 1691.1449552254733
[2023-06-29 11:18:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 317.25
avg_sample_per_episode: 317.25
avg_envstep_per_sec: 2231.5733388748904
avg_train_sample_per_sec: 2231.5733388748904
avg_episode_per_sec: 7.034116119384997
collect_time: 0.5686570895491168
reward_mean: 2848.3789797514505
reward_std: 872.3733470095917
reward_max: 3447.9952114031685
reward_min: 1348.9922524841268
total_envstep_count: 7563812
total_train_sample_count: 5720634
total_episode_count: 20862
total_duration: 1691.7136123150224
[2023-06-29 11:19:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2019
train_sample_count: 2019
avg_envstep_per_episode: 224.33333333333334
avg_sample_per_episode: 224.33333333333334
avg_envstep_per_sec: 2411.612970945006
avg_train_sample_per_sec: 2411.612970945006
avg_episode_per_sec: 10.750132114167933
collect_time: 0.8371990134092047
reward_mean: 2374.2181884116735
reward_std: 1289.615792137777
reward_max: 3531.6400266906326
reward_min: 162.50648976269187
total_envstep_count: 7568508
total_train_sample_count: 5723853
total_episode_count: 20871
total_duration: 1692.5508113284316
[2023-06-29 11:19:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 221.45454545454547
avg_sample_per_episode: 221.45454545454547
avg_envstep_per_sec: 2489.010191101038
avg_train_sample_per_sec: 2489.010191101038
avg_episode_per_sec: 11.239372784117988
collect_time: 0.9787023005005904
reward_mean: 1668.4119486267234
reward_std: 1003.80488294401
reward_max: 3481.9051285653427
reward_min: 671.1293376326576
total_envstep_count: 7573012
total_train_sample_count: 5727089
total_episode_count: 20882
total_duration: 1693.5295136289321
[2023-06-29 11:19:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1635
train_sample_count: 1635
avg_envstep_per_episode: 272.5
avg_sample_per_episode: 272.5
avg_envstep_per_sec: 2381.904879611635
avg_train_sample_per_sec: 2381.904879611635
avg_episode_per_sec: 8.740935338024348
collect_time: 0.6864253959069028
reward_mean: 2226.070160841556
reward_std: 846.3295858414778
reward_max: 3443.3334756140875
reward_min: 1147.2296504357
total_envstep_count: 7577172
total_train_sample_count: 5730324
total_episode_count: 20888
total_duration: 1694.2159390248391
[2023-06-29 11:19:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3360
train_sample_count: 3360
avg_envstep_per_episode: 305.45454545454544
avg_sample_per_episode: 305.45454545454544
avg_envstep_per_sec: 2474.836364064192
avg_train_sample_per_sec: 2474.836364064192
avg_episode_per_sec: 8.102142858543486
collect_time: 1.3576655203506816
reward_mean: 1947.844019726655
reward_std: 809.1381451952808
reward_max: 3479.092483949357
reward_min: 1101.896199870551
total_envstep_count: 7582420
total_train_sample_count: 5734084
total_episode_count: 20899
total_duration: 1695.57360454519
[2023-06-29 11:19:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1942
train_sample_count: 1942
avg_envstep_per_episode: 388.4
avg_sample_per_episode: 388.4
avg_envstep_per_sec: 2298.1467772652527
avg_train_sample_per_sec: 2298.1467772652527
avg_episode_per_sec: 5.916958746820939
collect_time: 0.8450287071354685
reward_mean: 2059.42253545698
reward_std: 877.5096285561739
reward_max: 3424.5938400461855
reward_min: 1032.9377596941351
total_envstep_count: 7587268
total_train_sample_count: 5737626
total_episode_count: 20904
total_duration: 1696.4186332523254
[2023-06-29 11:19:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2136
train_sample_count: 2136
avg_envstep_per_episode: 237.33333333333334
avg_sample_per_episode: 237.33333333333334
avg_envstep_per_sec: 2489.3947993802676
avg_train_sample_per_sec: 2489.3947993802676
avg_episode_per_sec: 10.489023031096634
collect_time: 0.8580398740014059
reward_mean: 2124.1313916367744
reward_std: 1266.65224516491
reward_max: 3583.1347073520064
reward_min: 330.59445064437557
total_envstep_count: 7592068
total_train_sample_count: 5740962
total_episode_count: 20913
total_duration: 1697.2766731263268
[2023-06-29 11:19:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 230.22222222222223
avg_sample_per_episode: 230.22222222222223
avg_envstep_per_sec: 2639.054058215361
avg_train_sample_per_sec: 2639.054058215361
avg_episode_per_sec: 11.463072646688342
collect_time: 0.7851298057157546
reward_mean: 2032.792767816442
reward_std: 969.4532320317632
reward_max: 3594.0484248443645
reward_min: 1001.4660421227326
total_envstep_count: 7596172
total_train_sample_count: 5744234
total_episode_count: 20922
total_duration: 1698.0618029320426
[2023-06-29 11:19:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1324
train_sample_count: 1324
avg_envstep_per_episode: 264.8
avg_sample_per_episode: 264.8
avg_envstep_per_sec: 2457.0908594472608
avg_train_sample_per_sec: 2457.0908594472608
avg_episode_per_sec: 9.279044031145245
collect_time: 0.5388486123373731
reward_mean: 1922.479591526915
reward_std: 1177.6786880500495
reward_max: 3483.204853877773
reward_min: 826.0457522587258
total_envstep_count: 7600396
total_train_sample_count: 5747558
total_episode_count: 20927
total_duration: 1698.60065154438
[2023-06-29 11:19:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2207
train_sample_count: 2207
avg_envstep_per_episode: 275.875
avg_sample_per_episode: 275.875
avg_envstep_per_sec: 2444.1264267439556
avg_train_sample_per_sec: 2444.1264267439556
avg_episode_per_sec: 8.859543005868439
collect_time: 0.9029811125360429
reward_mean: 2497.3726645858887
reward_std: 1013.799422417822
reward_max: 3508.2671816218945
reward_min: 1054.2233648949784
total_envstep_count: 7604972
total_train_sample_count: 5750965
total_episode_count: 20935
total_duration: 1699.5036326569161
[2023-06-29 11:19:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2158
train_sample_count: 2158
avg_envstep_per_episode: 269.75
avg_sample_per_episode: 269.75
avg_envstep_per_sec: 2409.582598790822
avg_train_sample_per_sec: 2409.582598790822
avg_episode_per_sec: 8.932650968640674
collect_time: 0.8955907969633117
reward_mean: 1925.5021371606388
reward_std: 916.4687231502488
reward_max: 3479.295575955516
reward_min: 988.8865471120034
total_envstep_count: 7609668
total_train_sample_count: 5754323
total_episode_count: 20943
total_duration: 1700.3992234538794
[2023-06-29 11:19:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2658
train_sample_count: 2658
avg_envstep_per_episode: 295.3333333333333
avg_sample_per_episode: 295.3333333333333
avg_envstep_per_sec: 2561.9824966732604
avg_train_sample_per_sec: 2561.9824966732604
avg_episode_per_sec: 8.67488430024806
collect_time: 1.0374778139395637
reward_mean: 2104.8426312658785
reward_std: 955.2222926710294
reward_max: 3477.9253911185765
reward_min: 1055.2260335168698
total_envstep_count: 7613708
total_train_sample_count: 5757781
total_episode_count: 20952
total_duration: 1701.436701267819
[2023-06-29 11:19:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2497
train_sample_count: 2497
avg_envstep_per_episode: 277.44444444444446
avg_sample_per_episode: 277.44444444444446
avg_envstep_per_sec: 2122.6443186218985
avg_train_sample_per_sec: 2122.6443186218985
avg_episode_per_sec: 7.650700387503839
collect_time: 1.1763628875991563
reward_mean: 1609.5812997049422
reward_std: 675.8459991197518
reward_max: 3039.287579008037
reward_min: 943.2431243969238
total_envstep_count: 7618468
total_train_sample_count: 5761078
total_episode_count: 20961
total_duration: 1702.6130641554182
[2023-06-29 11:19:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 856
train_sample_count: 856
avg_envstep_per_episode: 171.2
avg_sample_per_episode: 171.2
avg_envstep_per_sec: 2485.6110774216563
avg_train_sample_per_sec: 2485.6110774216563
avg_episode_per_sec: 14.518756293350798
collect_time: 0.3443821150362491
reward_mean: 1688.3402359323804
reward_std: 749.0227194420545
reward_max: 2794.852028935286
reward_min: 637.8900929358
total_envstep_count: 7622652
total_train_sample_count: 5764334
total_episode_count: 20966
total_duration: 1702.9574462704545
[2023-06-29 11:19:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 897
train_sample_count: 897
avg_envstep_per_episode: 179.4
avg_sample_per_episode: 179.4
avg_envstep_per_sec: 2552.140981036628
avg_train_sample_per_sec: 2552.140981036628
avg_episode_per_sec: 14.225980942233157
collect_time: 0.3514696118533611
reward_mean: 2672.4112718663205
reward_std: 837.2486658885236
reward_max: 3505.7966102234923
reward_min: 1437.9324915485502
total_envstep_count: 7627060
total_train_sample_count: 5767631
total_episode_count: 20971
total_duration: 1703.308915882308
[2023-06-29 11:19:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 826
train_sample_count: 826
avg_envstep_per_episode: 137.66666666666666
avg_sample_per_episode: 137.66666666666666
avg_envstep_per_sec: 2588.937799271308
avg_train_sample_per_sec: 2588.937799271308
avg_episode_per_sec: 18.805843578241944
collect_time: 0.3190497663684655
reward_mean: 2850.780436052619
reward_std: 786.2056036802398
reward_max: 3462.209740858963
reward_min: 1370.1120304841183
total_envstep_count: 7631460
total_train_sample_count: 5770857
total_episode_count: 20977
total_duration: 1703.6279656486763
[2023-06-29 11:19:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1566
train_sample_count: 1566
avg_envstep_per_episode: 195.75
avg_sample_per_episode: 195.75
avg_envstep_per_sec: 2444.1780217201576
avg_train_sample_per_sec: 2444.1780217201576
avg_episode_per_sec: 12.486222333180882
collect_time: 0.6407061949186027
reward_mean: 2292.857079893514
reward_std: 925.0537051560561
reward_max: 3513.542770404066
reward_min: 1193.2838663348482
total_envstep_count: 7635844
total_train_sample_count: 5774423
total_episode_count: 20985
total_duration: 1704.2686718435948
[2023-06-29 11:19:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 947
train_sample_count: 947
avg_envstep_per_episode: 189.4
avg_sample_per_episode: 189.4
avg_envstep_per_sec: 2456.896568529136
avg_train_sample_per_sec: 2456.896568529136
avg_episode_per_sec: 12.971998777872948
collect_time: 0.38544561139866707
reward_mean: 2247.512175338618
reward_std: 1116.33712810462
reward_max: 3422.696804635988
reward_min: 656.6318685897596
total_envstep_count: 7639604
total_train_sample_count: 5777770
total_episode_count: 20990
total_duration: 1704.6541174549934
[2023-06-29 11:19:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 145.16666666666666
avg_sample_per_episode: 145.16666666666666
avg_envstep_per_sec: 2295.86209297811
avg_train_sample_per_sec: 2295.86209297811
avg_episode_per_sec: 15.815353108919242
collect_time: 0.37937818768119913
reward_mean: 2513.9991945848246
reward_std: 878.8700681328401
reward_max: 3432.0558758892007
reward_min: 1255.9563414970971
total_envstep_count: 7643332
total_train_sample_count: 5781041
total_episode_count: 20996
total_duration: 1705.0334956426746
[2023-06-29 11:20:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1912
train_sample_count: 1912
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 2556.6341977559555
avg_train_sample_per_sec: 2556.6341977559555
avg_episode_per_sec: 10.697214216552116
collect_time: 0.7478582589868458
reward_mean: 2100.664677457915
reward_std: 872.2005071053555
reward_max: 3423.578335271651
reward_min: 776.8560330167629
total_envstep_count: 7647700
total_train_sample_count: 5784553
total_episode_count: 21004
total_duration: 1705.7813539016613
[2023-06-29 11:20:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 303.375
avg_sample_per_episode: 303.375
avg_envstep_per_sec: 2639.236413632555
avg_train_sample_per_sec: 2639.236413632555
avg_episode_per_sec: 8.69958438774637
collect_time: 0.919584159821272
reward_mean: 2202.583031673818
reward_std: 966.1015396883666
reward_max: 3447.7571420206145
reward_min: 1109.0844861868484
total_envstep_count: 7652500
total_train_sample_count: 5787780
total_episode_count: 21012
total_duration: 1706.7009380614825
[2023-06-29 11:20:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1498
train_sample_count: 1498
avg_envstep_per_episode: 374.5
avg_sample_per_episode: 374.5
avg_envstep_per_sec: 2490.936106295863
avg_train_sample_per_sec: 2490.936106295863
avg_episode_per_sec: 6.651364769815388
collect_time: 0.6013803389873357
reward_mean: 2945.2168092653515
reward_std: 479.18593177317484
reward_max: 3412.746546892708
reward_min: 2323.589993935365
total_envstep_count: 7656764
total_train_sample_count: 5791278
total_episode_count: 21016
total_duration: 1707.3023184004699
[2023-06-29 11:20:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 253.375
avg_sample_per_episode: 253.375
avg_envstep_per_sec: 2578.3760848310053
avg_train_sample_per_sec: 2578.3760848310053
avg_episode_per_sec: 10.17612662982143
collect_time: 0.786153739140369
reward_mean: 2422.1511783031065
reward_std: 1044.734493633191
reward_max: 3462.165731505467
reward_min: 984.3745424811655
total_envstep_count: 7661316
total_train_sample_count: 5794505
total_episode_count: 21024
total_duration: 1708.0884721396103
[2023-06-29 11:20:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2584
train_sample_count: 2584
avg_envstep_per_episode: 234.9090909090909
avg_sample_per_episode: 234.9090909090909
avg_envstep_per_sec: 2385.211319513285
avg_train_sample_per_sec: 2385.211319513285
avg_episode_per_sec: 10.153763357061198
collect_time: 1.0833421671532562
reward_mean: 1608.054882862248
reward_std: 650.6835197208202
reward_max: 2817.3841617850544
reward_min: 977.359012808194
total_envstep_count: 7665932
total_train_sample_count: 5797889
total_episode_count: 21035
total_duration: 1709.1718143067635
[2023-06-29 11:20:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2575
train_sample_count: 2575
avg_envstep_per_episode: 321.875
avg_sample_per_episode: 321.875
avg_envstep_per_sec: 2335.1362701237945
avg_train_sample_per_sec: 2335.1362701237945
avg_episode_per_sec: 7.254792295530236
collect_time: 1.1027193714324386
reward_mean: 2002.126549216497
reward_std: 912.2003779969589
reward_max: 3536.0463174198467
reward_min: 1026.3110741999615
total_envstep_count: 7670652
total_train_sample_count: 5801264
total_episode_count: 21043
total_duration: 1710.274533678196
[2023-06-29 11:20:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2521
train_sample_count: 2521
avg_envstep_per_episode: 315.125
avg_sample_per_episode: 315.125
avg_envstep_per_sec: 2514.978873661456
avg_train_sample_per_sec: 2514.978873661456
avg_episode_per_sec: 7.980892895395338
collect_time: 1.0023941061301156
reward_mean: 2023.3426605910379
reward_std: 919.7904881460304
reward_max: 3446.0170965792363
reward_min: 1013.9064008631369
total_envstep_count: 7675092
total_train_sample_count: 5804585
total_episode_count: 21051
total_duration: 1711.276927784326
[2023-06-29 11:20:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3274
train_sample_count: 3274
avg_envstep_per_episode: 251.84615384615384
avg_sample_per_episode: 251.84615384615384
avg_envstep_per_sec: 2624.959496776731
avg_train_sample_per_sec: 2624.959496776731
avg_episode_per_sec: 10.422869107543526
collect_time: 1.24725734016858
reward_mean: 1539.0902538366915
reward_std: 732.8642520316143
reward_max: 3612.6901079084805
reward_min: 965.8448465288519
total_envstep_count: 7679404
total_train_sample_count: 5807859
total_episode_count: 21064
total_duration: 1712.5241851244946
[2023-06-29 11:20:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2327
train_sample_count: 2327
avg_envstep_per_episode: 193.91666666666666
avg_sample_per_episode: 193.91666666666666
avg_envstep_per_sec: 2419.5223251598163
avg_train_sample_per_sec: 2419.5223251598163
avg_episode_per_sec: 12.477124152091877
collect_time: 0.9617600861964747
reward_mean: 942.2549063275792
reward_std: 211.40355498848447
reward_max: 1182.9724524681114
reward_min: 284.1028355862492
total_envstep_count: 7684572
total_train_sample_count: 5811386
total_episode_count: 21076
total_duration: 1713.485945210691
[2023-06-29 11:20:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2781
train_sample_count: 2781
avg_envstep_per_episode: 231.75
avg_sample_per_episode: 231.75
avg_envstep_per_sec: 2406.854331539034
avg_train_sample_per_sec: 2406.854331539034
avg_episode_per_sec: 10.385563458636607
collect_time: 1.1554500675667079
reward_mean: 1590.6803703563376
reward_std: 659.5480080413538
reward_max: 3383.0336881504686
reward_min: 941.0118381349416
total_envstep_count: 7688932
total_train_sample_count: 5814967
total_episode_count: 21088
total_duration: 1714.6413952782577
[2023-06-29 11:20:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 2391.1187183266434
avg_train_sample_per_sec: 2391.1187183266434
avg_episode_per_sec: 8.790877640906777
collect_time: 1.02378856442275
reward_mean: 1660.343862310226
reward_std: 797.260688178013
reward_max: 2994.482842606067
reward_min: 254.94476296152467
total_envstep_count: 7693692
total_train_sample_count: 5818215
total_episode_count: 21097
total_duration: 1715.6651838426806
[2023-06-29 11:20:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1909
train_sample_count: 1909
avg_envstep_per_episode: 272.7142857142857
avg_sample_per_episode: 272.7142857142857
avg_envstep_per_sec: 2613.336922497496
avg_train_sample_per_sec: 2613.336922497496
avg_episode_per_sec: 9.582691701143252
collect_time: 0.7304836906278507
reward_mean: 2024.2281035480557
reward_std: 464.74907449445226
reward_max: 2609.190129960766
reward_min: 1221.337880815761
total_envstep_count: 7698380
total_train_sample_count: 5821724
total_episode_count: 21104
total_duration: 1716.3956675333084
[2023-06-29 11:20:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2354
train_sample_count: 2354
avg_envstep_per_episode: 294.25
avg_sample_per_episode: 294.25
avg_envstep_per_sec: 2594.772264657271
avg_train_sample_per_sec: 2594.772264657271
avg_episode_per_sec: 8.818257483966937
collect_time: 0.9072087103994564
reward_mean: 2193.3766125135717
reward_std: 998.4968666636204
reward_max: 3513.5722621451564
reward_min: 1188.6654265723648
total_envstep_count: 7703236
total_train_sample_count: 5825278
total_episode_count: 21112
total_duration: 1717.3028762437077
[2023-06-29 11:20:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2888
train_sample_count: 2888
avg_envstep_per_episode: 288.8
avg_sample_per_episode: 288.8
avg_envstep_per_sec: 2445.608746935596
avg_train_sample_per_sec: 2445.608746935596
avg_episode_per_sec: 8.468174331494447
collect_time: 1.180892079985701
reward_mean: 2022.152712449983
reward_std: 1018.3458245119516
reward_max: 3629.0039396025436
reward_min: 987.5069140426971
total_envstep_count: 7707436
total_train_sample_count: 5828566
total_episode_count: 21122
total_duration: 1718.4837683236933
[2023-06-29 11:20:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1778
train_sample_count: 1778
avg_envstep_per_episode: 296.3333333333333
avg_sample_per_episode: 296.3333333333333
avg_envstep_per_sec: 2583.90098376615
avg_train_sample_per_sec: 2583.90098376615
avg_episode_per_sec: 8.719575873226603
collect_time: 0.6881068629063666
reward_mean: 1633.701041500641
reward_std: 818.788381296674
reward_max: 3389.7545319323945
reward_min: 1109.1146121012712
total_envstep_count: 7712076
total_train_sample_count: 5831944
total_episode_count: 21128
total_duration: 1719.1718751865997
[2023-06-29 11:20:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1638
train_sample_count: 1638
avg_envstep_per_episode: 204.75
avg_sample_per_episode: 204.75
avg_envstep_per_sec: 2576.4217178472563
avg_train_sample_per_sec: 2576.4217178472563
avg_episode_per_sec: 12.583256253222252
collect_time: 0.6357654838310555
reward_mean: 1960.6921938253631
reward_std: 1171.396354745317
reward_max: 3519.5727282910207
reward_min: 507.905779184343
total_envstep_count: 7716404
total_train_sample_count: 5835182
total_episode_count: 21136
total_duration: 1719.8076406704308
[2023-06-29 11:20:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2879
train_sample_count: 2879
avg_envstep_per_episode: 287.9
avg_sample_per_episode: 287.9
avg_envstep_per_sec: 2564.58692580503
avg_train_sample_per_sec: 2564.58692580503
avg_episode_per_sec: 8.907908738468324
collect_time: 1.1225979400547224
reward_mean: 1918.7493313879881
reward_std: 1042.5069722830344
reward_max: 3466.137373133174
reward_min: 805.3796065525964
total_envstep_count: 7720556
total_train_sample_count: 5838461
total_episode_count: 21146
total_duration: 1720.9302386104855
[2023-06-29 11:20:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 183.6
avg_sample_per_episode: 183.6
avg_envstep_per_sec: 2540.68261209484
avg_train_sample_per_sec: 2540.68261209484
avg_episode_per_sec: 13.83814058875185
collect_time: 0.3613202198613435
reward_mean: 1525.9115864359578
reward_std: 1014.6755189932503
reward_max: 3420.540194367428
reward_min: 417.78899137579833
total_envstep_count: 7725060
total_train_sample_count: 5841779
total_episode_count: 21151
total_duration: 1721.291558830347
[2023-06-29 11:21:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2021
train_sample_count: 2021
avg_envstep_per_episode: 336.8333333333333
avg_sample_per_episode: 336.8333333333333
avg_envstep_per_sec: 2496.3643348760543
avg_train_sample_per_sec: 2496.3643348760543
avg_episode_per_sec: 7.411274621106544
collect_time: 0.8095773408412934
reward_mean: 3006.331835138469
reward_std: 962.1350994065449
reward_max: 3470.148940713837
reward_min: 855.3892090995595
total_envstep_count: 7729476
total_train_sample_count: 5845000
total_episode_count: 21157
total_duration: 1722.1011361711883
[2023-06-29 11:21:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 121
train_sample_count: 121
avg_envstep_per_episode: 60.5
avg_sample_per_episode: 60.5
avg_envstep_per_sec: 2506.2426050056556
avg_train_sample_per_sec: 2506.2426050056556
avg_episode_per_sec: 41.42549760339927
collect_time: 0.048279444199986754
reward_mean: 3410.5002373621564
reward_std: 10.21958768565446
reward_max: 3420.719825047811
reward_min: 3400.280649676502
total_envstep_count: 7733260
total_train_sample_count: 5848321
total_episode_count: 21159
total_duration: 1722.1494156153883
[2023-06-29 11:21:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2546
train_sample_count: 2546
avg_envstep_per_episode: 254.6
avg_sample_per_episode: 254.6
avg_envstep_per_sec: 2367.2708050898464
avg_train_sample_per_sec: 2367.2708050898464
avg_episode_per_sec: 9.298000019991541
collect_time: 1.0755001052375883
reward_mean: 2240.2503163413517
reward_std: 1462.8823313727385
reward_max: 3482.3504050618544
reward_min: 360.39312198444964
total_envstep_count: 7737444
total_train_sample_count: 5851667
total_episode_count: 21169
total_duration: 1723.2249157206259
[2023-06-29 11:21:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 190.55555555555554
avg_sample_per_episode: 190.55555555555554
avg_envstep_per_sec: 2640.0209523342705
avg_train_sample_per_sec: 2640.0209523342705
avg_episode_per_sec: 13.854337359188591
collect_time: 0.6496160564497113
reward_mean: 1379.37059524199
reward_std: 1184.9618454340412
reward_max: 3478.169886064073
reward_min: 261.07297569021534
total_envstep_count: 7741596
total_train_sample_count: 5854982
total_episode_count: 21178
total_duration: 1723.8745317770756
[2023-06-29 11:21:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3006
train_sample_count: 3006
avg_envstep_per_episode: 273.27272727272725
avg_sample_per_episode: 273.27272727272725
avg_envstep_per_sec: 2440.404430965988
avg_train_sample_per_sec: 2440.404430965988
avg_episode_per_sec: 8.930289002204214
collect_time: 1.2317630479019135
reward_mean: 1823.8131612793795
reward_std: 1243.9676374158867
reward_max: 3460.0510516787967
reward_min: 442.24680639196174
total_envstep_count: 7746156
total_train_sample_count: 5858388
total_episode_count: 21189
total_duration: 1725.1062948249776
[2023-06-29 11:21:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2472
train_sample_count: 2472
avg_envstep_per_episode: 247.2
avg_sample_per_episode: 247.2
avg_envstep_per_sec: 2558.949034245734
avg_train_sample_per_sec: 2558.949034245734
avg_episode_per_sec: 10.351735575427726
collect_time: 0.9660215842198816
reward_mean: 1445.0287228140626
reward_std: 881.2663089943569
reward_max: 3476.287933313369
reward_min: 559.3748796325747
total_envstep_count: 7750396
total_train_sample_count: 5861660
total_episode_count: 21199
total_duration: 1726.0723164091974
[2023-06-29 11:21:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3341
train_sample_count: 3341
avg_envstep_per_episode: 222.73333333333332
avg_sample_per_episode: 222.73333333333332
avg_envstep_per_sec: 2506.2455324253156
avg_train_sample_per_sec: 2506.2455324253156
avg_episode_per_sec: 11.252224778922399
collect_time: 1.3330697079654783
reward_mean: 1190.353847998461
reward_std: 691.9010864210857
reward_max: 3335.6652281555043
reward_min: 571.7482328226176
total_envstep_count: 7754676
total_train_sample_count: 5865001
total_episode_count: 21214
total_duration: 1727.4053861171628
[2023-06-29 11:21:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 2465.6275477445433
avg_train_sample_per_sec: 2465.6275477445433
avg_episode_per_sec: 10.359779612372032
collect_time: 1.3513800991751488
reward_mean: 1064.2421095196592
reward_std: 461.2619607906063
reward_max: 2195.971712082056
reward_min: 324.9807888294502
total_envstep_count: 7758964
total_train_sample_count: 5868333
total_episode_count: 21228
total_duration: 1728.756766216338
[2023-06-29 11:21:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 246.91666666666666
avg_sample_per_episode: 246.91666666666666
avg_envstep_per_sec: 2343.880942490117
avg_train_sample_per_sec: 2343.880942490117
avg_episode_per_sec: 9.492599159595478
collect_time: 1.2641427072025837
reward_mean: 1160.5990033183461
reward_std: 268.7417912328661
reward_max: 1711.0293537216826
reward_min: 807.7597591207783
total_envstep_count: 7763484
total_train_sample_count: 5871696
total_episode_count: 21240
total_duration: 1730.0209089235407
[2023-06-29 11:21:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2682
train_sample_count: 2682
avg_envstep_per_episode: 223.5
avg_sample_per_episode: 223.5
avg_envstep_per_sec: 2572.8784887333295
avg_train_sample_per_sec: 2572.8784887333295
avg_episode_per_sec: 11.51176057598805
collect_time: 1.0424122288497164
reward_mean: 1260.0902702529836
reward_std: 457.4574823095885
reward_max: 2696.8496171181305
reward_min: 957.9424236060412
total_envstep_count: 7767884
total_train_sample_count: 5875178
total_episode_count: 21252
total_duration: 1731.0633211523905
[2023-06-29 11:21:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2231
train_sample_count: 2231
avg_envstep_per_episode: 247.88888888888889
avg_sample_per_episode: 247.88888888888889
avg_envstep_per_sec: 2460.718349677889
avg_train_sample_per_sec: 2460.718349677889
avg_episode_per_sec: 9.926698855715374
collect_time: 0.9066458175890145
reward_mean: 1392.074390252439
reward_std: 534.5229510584461
reward_max: 2165.5626542388336
reward_min: 654.7286273709085
total_envstep_count: 7772636
total_train_sample_count: 5878609
total_episode_count: 21261
total_duration: 1731.9699669699794
[2023-06-29 11:21:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2472
train_sample_count: 2472
avg_envstep_per_episode: 247.2
avg_sample_per_episode: 247.2
avg_envstep_per_sec: 2391.900053596157
avg_train_sample_per_sec: 2391.900053596157
avg_episode_per_sec: 9.67597109059934
collect_time: 1.0334879989167671
reward_mean: 1796.9225459393033
reward_std: 1120.0684954095238
reward_max: 3498.295160783515
reward_min: 782.7335507598287
total_envstep_count: 7777436
total_train_sample_count: 5881881
total_episode_count: 21271
total_duration: 1733.0034549688962
[2023-06-29 11:21:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1809
train_sample_count: 1809
avg_envstep_per_episode: 226.125
avg_sample_per_episode: 226.125
avg_envstep_per_sec: 2525.9924136659424
avg_train_sample_per_sec: 2525.9924136659424
avg_episode_per_sec: 11.170779054354638
collect_time: 0.7161541698276995
reward_mean: 1740.4865209690115
reward_std: 857.1660594909943
reward_max: 3504.9708066588537
reward_min: 1042.47854640273
total_envstep_count: 7781700
total_train_sample_count: 5885290
total_episode_count: 21279
total_duration: 1733.7196091387239
[2023-06-29 11:21:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2478
train_sample_count: 2478
avg_envstep_per_episode: 225.27272727272728
avg_sample_per_episode: 225.27272727272728
avg_envstep_per_sec: 2480.8343438344555
avg_train_sample_per_sec: 2480.8343438344555
avg_episode_per_sec: 11.01258183300202
collect_time: 0.9988575037904085
reward_mean: 1703.277512619817
reward_std: 1000.4132565416385
reward_max: 3576.160492147288
reward_min: 749.6417902793337
total_envstep_count: 7785900
total_train_sample_count: 5888568
total_episode_count: 21290
total_duration: 1734.7184666425142
[2023-06-29 11:21:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2404
train_sample_count: 2404
avg_envstep_per_episode: 300.5
avg_sample_per_episode: 300.5
avg_envstep_per_sec: 2415.963873874805
avg_train_sample_per_sec: 2415.963873874805
avg_episode_per_sec: 8.039813224209002
collect_time: 0.9950479914024472
reward_mean: 1933.7505823148294
reward_std: 585.2737755331813
reward_max: 2813.368783968318
reward_min: 950.9611246781417
total_envstep_count: 7790452
total_train_sample_count: 5891772
total_episode_count: 21298
total_duration: 1735.7135146339167
[2023-06-29 11:21:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 333.2
avg_sample_per_episode: 333.2
avg_envstep_per_sec: 2506.212340949781
avg_train_sample_per_sec: 2506.212340949781
avg_episode_per_sec: 7.521645681121791
collect_time: 1.329496286311187
reward_mean: 1985.2043583374968
reward_std: 928.1544976324237
reward_max: 3631.7629897959714
reward_min: 1020.3225013407762
total_envstep_count: 7794724
total_train_sample_count: 5895104
total_episode_count: 21308
total_duration: 1737.043010920228
[2023-06-29 11:21:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2591
train_sample_count: 2591
avg_envstep_per_episode: 287.8888888888889
avg_sample_per_episode: 287.8888888888889
avg_envstep_per_sec: 2379.2776434081816
avg_train_sample_per_sec: 2379.2776434081816
avg_episode_per_sec: 8.26456919748114
collect_time: 1.088985981597565
reward_mean: 1375.0387300157888
reward_std: 428.17154634648153
reward_max: 2162.3739247285903
reward_min: 703.7472898026507
total_envstep_count: 7799244
total_train_sample_count: 5898495
total_episode_count: 21317
total_duration: 1738.1319969018255
[2023-06-29 11:21:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2938
train_sample_count: 2938
avg_envstep_per_episode: 293.8
avg_sample_per_episode: 293.8
avg_envstep_per_sec: 2477.8245112884574
avg_train_sample_per_sec: 2477.8245112884574
avg_episode_per_sec: 8.433711747067589
collect_time: 1.185717546426342
reward_mean: 1793.36630675528
reward_std: 725.8952565377257
reward_max: 3503.697558813636
reward_min: 944.0533295081563
total_envstep_count: 7803804
total_train_sample_count: 5901833
total_episode_count: 21327
total_duration: 1739.3177144482518
[2023-06-29 11:22:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2933
train_sample_count: 2933
avg_envstep_per_episode: 293.3
avg_sample_per_episode: 293.3
avg_envstep_per_sec: 2478.0024950320108
avg_train_sample_per_sec: 2478.0024950320108
avg_episode_per_sec: 8.448695857592945
collect_time: 1.1836146274590864
reward_mean: 1610.3211483688513
reward_std: 663.0677815573359
reward_max: 2775.2290805641705
reward_min: 871.8265062623489
total_envstep_count: 7808772
total_train_sample_count: 5905166
total_episode_count: 21337
total_duration: 1740.5013290757108
[2023-06-29 11:22:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2656
train_sample_count: 2656
avg_envstep_per_episode: 265.6
avg_sample_per_episode: 265.6
avg_envstep_per_sec: 2462.0172186192312
avg_train_sample_per_sec: 2462.0172186192312
avg_episode_per_sec: 9.269643142391683
collect_time: 1.0787901806347073
reward_mean: 1725.3181835333176
reward_std: 464.9025519310473
reward_max: 2532.5924582673683
reward_min: 1199.3880095615582
total_envstep_count: 7813916
total_train_sample_count: 5908622
total_episode_count: 21347
total_duration: 1741.5801192563456
[2023-06-29 11:22:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1205
train_sample_count: 1205
avg_envstep_per_episode: 200.83333333333334
avg_sample_per_episode: 200.83333333333334
avg_envstep_per_sec: 2548.142493008277
avg_train_sample_per_sec: 2548.142493008277
avg_episode_per_sec: 12.687846438215487
collect_time: 0.4728934913594276
reward_mean: 1686.928496147865
reward_std: 831.2155782841683
reward_max: 3534.412980118022
reward_min: 1151.2860276811339
total_envstep_count: 7817820
total_train_sample_count: 5911827
total_episode_count: 21353
total_duration: 1742.053012747705
[2023-06-29 11:22:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2930
train_sample_count: 2930
avg_envstep_per_episode: 325.55555555555554
avg_sample_per_episode: 325.55555555555554
avg_envstep_per_sec: 2539.385808518069
avg_train_sample_per_sec: 2539.385808518069
avg_episode_per_sec: 7.800161186574274
collect_time: 1.15382231017109
reward_mean: 2565.0385938599434
reward_std: 964.7590859296953
reward_max: 3531.526682686487
reward_min: 880.637957789401
total_envstep_count: 7822196
total_train_sample_count: 5915157
total_episode_count: 21362
total_duration: 1743.206835057876
[2023-06-29 11:22:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2093
train_sample_count: 2093
avg_envstep_per_episode: 299.0
avg_sample_per_episode: 299.0
avg_envstep_per_sec: 2580.8481909194497
avg_train_sample_per_sec: 2580.8481909194497
avg_episode_per_sec: 8.631599300733946
collect_time: 0.8109736974705011
reward_mean: 1741.6378090157702
reward_std: 725.927660584261
reward_max: 3215.461754358021
reward_min: 917.2897222690004
total_envstep_count: 7826620
total_train_sample_count: 5918450
total_episode_count: 21369
total_duration: 1744.0178087553466
[2023-06-29 11:22:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2866
train_sample_count: 2866
avg_envstep_per_episode: 318.44444444444446
avg_sample_per_episode: 318.44444444444446
avg_envstep_per_sec: 2469.128112715979
avg_train_sample_per_sec: 2469.128112715979
avg_episode_per_sec: 7.753717032255342
collect_time: 1.1607336149307668
reward_mean: 2109.3352730443976
reward_std: 1069.2536492895736
reward_max: 3490.4266225372153
reward_min: 930.173104903348
total_envstep_count: 7830780
total_train_sample_count: 5921716
total_episode_count: 21378
total_duration: 1745.1785423702772
[2023-06-29 11:22:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2233
train_sample_count: 2233
avg_envstep_per_episode: 279.125
avg_sample_per_episode: 279.125
avg_envstep_per_sec: 2344.1002654001504
avg_train_sample_per_sec: 2344.1002654001504
avg_episode_per_sec: 8.398030507479268
collect_time: 0.9526043032202869
reward_mean: 1493.0771392227466
reward_std: 532.0859536154812
reward_max: 2282.763874959429
reward_min: 865.3289269589695
total_envstep_count: 7835380
total_train_sample_count: 5925149
total_episode_count: 21386
total_duration: 1746.1311466734976
[2023-06-29 11:22:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2281
train_sample_count: 2281
avg_envstep_per_episode: 285.125
avg_sample_per_episode: 285.125
avg_envstep_per_sec: 2592.4700452326165
avg_train_sample_per_sec: 2592.4700452326165
avg_episode_per_sec: 9.092398229662837
collect_time: 0.8798558749770746
reward_mean: 2140.7230038759035
reward_std: 836.8167907296038
reward_max: 3500.2286050788657
reward_min: 1258.3976120158898
total_envstep_count: 7840364
total_train_sample_count: 5928630
total_episode_count: 21394
total_duration: 1747.0110025484746
[2023-06-29 11:22:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2527
train_sample_count: 2527
avg_envstep_per_episode: 280.77777777777777
avg_sample_per_episode: 280.77777777777777
avg_envstep_per_sec: 2387.4002081839812
avg_train_sample_per_sec: 2387.4002081839812
avg_episode_per_sec: 8.502810397172865
collect_time: 1.058473561046645
reward_mean: 1965.5678833905472
reward_std: 937.0929822591037
reward_max: 3586.085145640504
reward_min: 1107.0449169415901
total_envstep_count: 7844884
total_train_sample_count: 5931957
total_episode_count: 21403
total_duration: 1748.0694761095212
[2023-06-29 11:22:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1617
train_sample_count: 1617
avg_envstep_per_episode: 202.125
avg_sample_per_episode: 202.125
avg_envstep_per_sec: 2599.9871278480755
avg_train_sample_per_sec: 2599.9871278480755
avg_episode_per_sec: 12.863263464925545
collect_time: 0.6219261559722944
reward_mean: 1587.920903045158
reward_std: 975.8637108849927
reward_max: 3551.4126622581202
reward_min: 685.0853183898492
total_envstep_count: 7849108
total_train_sample_count: 5935174
total_episode_count: 21411
total_duration: 1748.6914022654935
[2023-06-29 11:22:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3292
train_sample_count: 3292
avg_envstep_per_episode: 219.46666666666667
avg_sample_per_episode: 219.46666666666667
avg_envstep_per_sec: 2420.513724917842
avg_train_sample_per_sec: 2420.513724917842
avg_episode_per_sec: 11.029072258131116
collect_time: 1.3600418647127226
reward_mean: 1463.7215689754134
reward_std: 792.4191657782054
reward_max: 3472.667771063213
reward_min: 813.0447549996436
total_envstep_count: 7854044
total_train_sample_count: 5938466
total_episode_count: 21426
total_duration: 1750.0514441302062
[2023-06-29 11:22:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2837
train_sample_count: 2837
avg_envstep_per_episode: 218.23076923076923
avg_sample_per_episode: 218.23076923076923
avg_envstep_per_sec: 2516.4635863223975
avg_train_sample_per_sec: 2516.4635863223975
avg_episode_per_sec: 11.531204308139293
collect_time: 1.1273757408689706
reward_mean: 1140.574163013624
reward_std: 291.8783947087482
reward_max: 1896.0675509806724
reward_min: 892.0595585240688
total_envstep_count: 7858580
total_train_sample_count: 5941703
total_episode_count: 21439
total_duration: 1751.1788198710751
[2023-06-29 11:22:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2987
train_sample_count: 2987
avg_envstep_per_episode: 248.91666666666666
avg_sample_per_episode: 248.91666666666666
avg_envstep_per_sec: 2552.2459911579567
avg_train_sample_per_sec: 2552.2459911579567
avg_episode_per_sec: 10.253415431501667
collect_time: 1.1703417344363405
reward_mean: 1469.253561916473
reward_std: 722.1846405440331
reward_max: 3493.6350014423797
reward_min: 826.5901137846577
total_envstep_count: 7862852
total_train_sample_count: 5945090
total_episode_count: 21451
total_duration: 1752.3491616055114
[2023-06-29 11:22:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3290
train_sample_count: 3290
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2441.544189636101
avg_train_sample_per_sec: 2441.544189636101
avg_episode_per_sec: 10.389549743132344
collect_time: 1.3475078657045962
reward_mean: 1147.4453850990665
reward_std: 658.8208702267293
reward_max: 3428.0545960134414
reward_min: 668.9066287606181
total_envstep_count: 7866852
total_train_sample_count: 5948380
total_episode_count: 21465
total_duration: 1753.696669471216
[2023-06-29 11:22:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2918
train_sample_count: 2918
avg_envstep_per_episode: 243.16666666666666
avg_sample_per_episode: 243.16666666666666
avg_envstep_per_sec: 2486.6752659089775
avg_train_sample_per_sec: 2486.6752659089775
avg_episode_per_sec: 10.226217680228832
collect_time: 1.173454387070262
reward_mean: 1038.4307468542122
reward_std: 281.7311589161442
reward_max: 1571.1801164416627
reward_min: 312.712896093409
total_envstep_count: 7871500
total_train_sample_count: 5951698
total_episode_count: 21477
total_duration: 1754.8701238582862
[2023-06-29 11:22:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3035
train_sample_count: 3035
avg_envstep_per_episode: 252.91666666666666
avg_sample_per_episode: 252.91666666666666
avg_envstep_per_sec: 2537.625460259348
avg_train_sample_per_sec: 2537.625460259348
avg_episode_per_sec: 10.033444982903518
collect_time: 1.195999980111257
reward_mean: 1436.7651559671742
reward_std: 423.5580469728914
reward_max: 2574.617981539297
reward_min: 965.7880414229047
total_envstep_count: 7876164
total_train_sample_count: 5955133
total_episode_count: 21489
total_duration: 1756.0661238383975
[2023-06-29 11:22:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 244.75
avg_sample_per_episode: 244.75
avg_envstep_per_sec: 2338.5250708342664
avg_train_sample_per_sec: 2338.5250708342664
avg_episode_per_sec: 9.55475003405216
collect_time: 1.2559198259748519
reward_mean: 1345.2567209601089
reward_std: 509.37413607648887
reward_max: 2809.31379663104
reward_min: 934.4459091373747
total_envstep_count: 7880412
total_train_sample_count: 5958470
total_episode_count: 21501
total_duration: 1757.3220436643724
[2023-06-29 11:22:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3246
train_sample_count: 3246
avg_envstep_per_episode: 231.85714285714286
avg_sample_per_episode: 231.85714285714286
avg_envstep_per_sec: 2579.6939874734708
avg_train_sample_per_sec: 2579.6939874734708
avg_episode_per_sec: 11.126221757433331
collect_time: 1.2582887798948212
reward_mean: 1158.1422001467374
reward_std: 272.00085294527673
reward_max: 1896.6254531936781
reward_min: 852.7779090147756
total_envstep_count: 7884828
total_train_sample_count: 5961716
total_episode_count: 21515
total_duration: 1758.5803324442672
[2023-06-29 11:23:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2960
train_sample_count: 2960
avg_envstep_per_episode: 269.09090909090907
avg_sample_per_episode: 269.09090909090907
avg_envstep_per_sec: 2463.53089092403
avg_train_sample_per_sec: 2463.53089092403
avg_episode_per_sec: 9.155013446001462
collect_time: 1.2015274543156846
reward_mean: 1331.7989572146653
reward_std: 359.7275158409726
reward_max: 2004.6816175994115
reward_min: 635.5551672456832
total_envstep_count: 7889252
total_train_sample_count: 5965076
total_episode_count: 21526
total_duration: 1759.781859898583
[2023-06-29 11:23:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3380
train_sample_count: 3380
avg_envstep_per_episode: 307.27272727272725
avg_sample_per_episode: 307.27272727272725
avg_envstep_per_sec: 2557.9468797393833
avg_train_sample_per_sec: 2557.9468797393833
avg_episode_per_sec: 8.324679194418112
collect_time: 1.3213722406715387
reward_mean: 1587.1547055733033
reward_std: 576.374217670128
reward_max: 2792.0356859824296
reward_min: 949.2752227166673
total_envstep_count: 7894076
total_train_sample_count: 5968456
total_episode_count: 21537
total_duration: 1761.1032321392545
[2023-06-29 11:23:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1834
train_sample_count: 1834
avg_envstep_per_episode: 229.25
avg_sample_per_episode: 229.25
avg_envstep_per_sec: 2608.1707158801833
avg_train_sample_per_sec: 2608.1707158801833
avg_episode_per_sec: 11.376971497841584
collect_time: 0.7031748300958426
reward_mean: 1412.4529616811783
reward_std: 257.8718983869298
reward_max: 1856.377678562399
reward_min: 1035.2977099725197
total_envstep_count: 7898412
total_train_sample_count: 5971890
total_episode_count: 21545
total_duration: 1761.8064069693503
[2023-06-29 11:23:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 222.88888888888889
avg_sample_per_episode: 222.88888888888889
avg_envstep_per_sec: 1945.3977400316492
avg_train_sample_per_sec: 1945.3977400316492
avg_episode_per_sec: 8.728105513601616
collect_time: 1.0311516039734707
reward_mean: 1860.5150288718085
reward_std: 445.28319116755375
reward_max: 2518.3204080157725
reward_min: 1153.7280263002474
total_envstep_count: 7902308
total_train_sample_count: 5975096
total_episode_count: 21554
total_duration: 1762.8375585733238
[2023-06-29 11:23:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 308.8181818181818
avg_sample_per_episode: 308.8181818181818
avg_envstep_per_sec: 2316.6592782362964
avg_train_sample_per_sec: 2316.6592782362964
avg_episode_per_sec: 7.501693276596779
collect_time: 1.4663356117634103
reward_mean: 1687.7994250154798
reward_std: 890.0404795036911
reward_max: 3591.419302002542
reward_min: 747.1802520483387
total_envstep_count: 7907212
total_train_sample_count: 5978493
total_episode_count: 21565
total_duration: 1764.3038941850873
[2023-06-29 11:23:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 309.5
avg_sample_per_episode: 309.5
avg_envstep_per_sec: 2210.353543272406
avg_train_sample_per_sec: 2210.353543272406
avg_episode_per_sec: 7.141691577616821
collect_time: 1.120182790457271
reward_mean: 1731.4989172352548
reward_std: 421.06242407693685
reward_max: 2351.715104921117
reward_min: 1057.4159947822552
total_envstep_count: 7911788
total_train_sample_count: 5981769
total_episode_count: 21573
total_duration: 1765.4240769755445
[2023-06-29 11:23:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2536
train_sample_count: 2536
avg_envstep_per_episode: 253.6
avg_sample_per_episode: 253.6
avg_envstep_per_sec: 2325.3461139632295
avg_train_sample_per_sec: 2325.3461139632295
avg_episode_per_sec: 9.169345875249329
collect_time: 1.0905903361103264
reward_mean: 1674.658265356184
reward_std: 644.3656900259566
reward_max: 2969.265531135778
reward_min: 659.3558103098665
total_envstep_count: 7916476
total_train_sample_count: 5985105
total_episode_count: 21583
total_duration: 1766.5146673116549
[2023-06-29 11:23:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 986
train_sample_count: 986
avg_envstep_per_episode: 197.2
avg_sample_per_episode: 197.2
avg_envstep_per_sec: 1880.4152503410157
avg_train_sample_per_sec: 1880.4152503410157
avg_episode_per_sec: 9.535574291790141
collect_time: 0.5243522673096741
reward_mean: 1827.7264556685961
reward_std: 337.5527835828152
reward_max: 2259.573346859173
reward_min: 1299.080673595743
total_envstep_count: 7920660
total_train_sample_count: 5988491
total_episode_count: 21588
total_duration: 1767.0390195789646
[2023-06-29 11:23:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 272.55555555555554
avg_sample_per_episode: 272.55555555555554
avg_envstep_per_sec: 2094.349774048189
avg_train_sample_per_sec: 2094.349774048189
avg_episode_per_sec: 7.684120654885325
collect_time: 1.1712465751403942
reward_mean: 2500.1208864424043
reward_std: 801.6546185601254
reward_max: 3554.3641899285135
reward_min: 1229.18362736411
total_envstep_count: 7924852
total_train_sample_count: 5991744
total_episode_count: 21597
total_duration: 1768.210266154105
[2023-06-29 11:23:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2432
train_sample_count: 2432
avg_envstep_per_episode: 270.22222222222223
avg_sample_per_episode: 270.22222222222223
avg_envstep_per_sec: 1927.4427140879473
avg_train_sample_per_sec: 1927.4427140879473
avg_episode_per_sec: 7.132806096542568
collect_time: 1.2617755029626423
reward_mean: 1644.770862834236
reward_std: 694.8083132408157
reward_max: 2948.019039765327
reward_min: 595.9280076706067
total_envstep_count: 7929292
total_train_sample_count: 5994976
total_episode_count: 21606
total_duration: 1769.4720416570676
[2023-06-29 11:23:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1805
train_sample_count: 1805
avg_envstep_per_episode: 200.55555555555554
avg_sample_per_episode: 200.55555555555554
avg_envstep_per_sec: 2277.297864214283
avg_train_sample_per_sec: 2277.297864214283
avg_episode_per_sec: 11.354947799406398
collect_time: 0.7926060215327888
reward_mean: 1500.3838114114271
reward_std: 592.2817161195578
reward_max: 2557.4827940770083
reward_min: 578.0014435613489
total_envstep_count: 7933612
total_train_sample_count: 5998381
total_episode_count: 21615
total_duration: 1770.2646476786003
[2023-06-29 11:23:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2189
train_sample_count: 2189
avg_envstep_per_episode: 218.9
avg_sample_per_episode: 218.9
avg_envstep_per_sec: 1394.8632706375365
avg_train_sample_per_sec: 1394.8632706375365
avg_episode_per_sec: 6.372148335484406
collect_time: 1.5693294433077267
reward_mean: 1492.4722383212559
reward_std: 583.8349272236266
reward_max: 2775.480024520449
reward_min: 665.9127807212442
total_envstep_count: 7937771
total_train_sample_count: 6001770
total_episode_count: 21625
total_duration: 1771.833977121908
[2023-06-29 11:23:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 300.5
avg_sample_per_episode: 300.5
avg_envstep_per_sec: 1828.066463110588
avg_train_sample_per_sec: 1828.066463110588
avg_episode_per_sec: 6.083415850617597
collect_time: 0.6575253275828438
reward_mean: 2478.331631375406
reward_std: 808.8509033494593
reward_max: 3528.8140014125
reward_min: 1579.713502952122
total_envstep_count: 7941347
total_train_sample_count: 6004972
total_episode_count: 21629
total_duration: 1772.4915024494908
[2023-06-29 11:23:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 274.3333333333333
avg_sample_per_episode: 274.3333333333333
avg_envstep_per_sec: 2493.408959821079
avg_train_sample_per_sec: 2493.408959821079
avg_episode_per_sec: 9.088975552203204
collect_time: 0.9902106071589514
reward_mean: 2232.9211130472218
reward_std: 1280.4850995789643
reward_max: 3552.0557032619618
reward_min: 305.7026800261654
total_envstep_count: 7946219
total_train_sample_count: 6008241
total_episode_count: 21638
total_duration: 1773.4817130566498
[2023-06-29 11:23:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 320.1
avg_sample_per_episode: 320.1
avg_envstep_per_sec: 2572.7428646817334
avg_train_sample_per_sec: 2572.7428646817334
avg_episode_per_sec: 8.03730979282016
collect_time: 1.2441974065667019
reward_mean: 2018.326918939835
reward_std: 836.8135726641416
reward_max: 3467.5624242268964
reward_min: 1028.6256399737144
total_envstep_count: 7951107
total_train_sample_count: 6011442
total_episode_count: 21648
total_duration: 1774.7259104632165
[2023-06-29 11:23:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2627
train_sample_count: 2627
avg_envstep_per_episode: 238.8181818181818
avg_sample_per_episode: 238.8181818181818
avg_envstep_per_sec: 2634.566915603663
avg_train_sample_per_sec: 2634.566915603663
avg_episode_per_sec: 11.031684838842898
collect_time: 0.9971278332090004
reward_mean: 1401.679030026042
reward_std: 345.73405086463504
reward_max: 2237.5254504068507
reward_min: 981.8831235361896
total_envstep_count: 7955651
total_train_sample_count: 6014869
total_episode_count: 21659
total_duration: 1775.7230382964256
[2023-06-29 11:23:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 291.8181818181818
avg_sample_per_episode: 291.8181818181818
avg_envstep_per_sec: 2439.5754836020064
avg_train_sample_per_sec: 2439.5754836020064
avg_episode_per_sec: 8.359915987421205
collect_time: 1.3158026966480538
reward_mean: 1686.5947912802703
reward_std: 709.095939269601
reward_max: 3099.738416144894
reward_min: 917.4371937913003
total_envstep_count: 7960171
total_train_sample_count: 6018079
total_episode_count: 21670
total_duration: 1777.0388409930736
[2023-06-29 11:24:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1762
train_sample_count: 1762
avg_envstep_per_episode: 293.6666666666667
avg_sample_per_episode: 293.6666666666667
avg_envstep_per_sec: 2335.1529788595976
avg_train_sample_per_sec: 2335.1529788595976
avg_episode_per_sec: 7.951712754345963
collect_time: 0.7545544193256647
reward_mean: 1601.3945234749328
reward_std: 379.3461471923016
reward_max: 2407.16809691603
reward_min: 1302.9683159993376
total_envstep_count: 7964787
total_train_sample_count: 6021441
total_episode_count: 21676
total_duration: 1777.7933954123991
[2023-06-29 11:24:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1701
train_sample_count: 1701
avg_envstep_per_episode: 243.0
avg_sample_per_episode: 243.0
avg_envstep_per_sec: 2369.1410315312596
avg_train_sample_per_sec: 2369.1410315312596
avg_episode_per_sec: 9.749551570087489
collect_time: 0.7179817399475723
reward_mean: 2344.4711940512266
reward_std: 988.7932516235315
reward_max: 3566.3559572408476
reward_min: 769.9814785567238
total_envstep_count: 7969459
total_train_sample_count: 6024742
total_episode_count: 21683
total_duration: 1778.5113771523468
[2023-06-29 11:24:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 274.625
avg_sample_per_episode: 274.625
avg_envstep_per_sec: 2659.773587988121
avg_train_sample_per_sec: 2659.773587988121
avg_episode_per_sec: 9.685110925764665
collect_time: 0.8260101573765278
reward_mean: 2055.06689774443
reward_std: 1086.8433874727868
reward_max: 3526.191493401985
reward_min: 751.2152995023288
total_envstep_count: 7974171
total_train_sample_count: 6028139
total_episode_count: 21691
total_duration: 1779.3373873097232
[2023-06-29 11:24:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1230
train_sample_count: 1230
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2582.784655516071
avg_train_sample_per_sec: 2582.784655516071
avg_episode_per_sec: 12.598949539102785
collect_time: 0.47623017945885676
reward_mean: 2366.44463318478
reward_std: 1203.0658598065395
reward_max: 3568.960948373787
reward_min: 722.4544972848711
total_envstep_count: 7978211
total_train_sample_count: 6031369
total_episode_count: 21697
total_duration: 1779.813617489182
[2023-06-29 11:24:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2725
train_sample_count: 2725
avg_envstep_per_episode: 340.625
avg_sample_per_episode: 340.625
avg_envstep_per_sec: 2512.827445875443
avg_train_sample_per_sec: 2512.827445875443
avg_episode_per_sec: 7.377108097982952
collect_time: 1.0844357834728433
reward_mean: 2737.2337189619384
reward_std: 814.8978874431763
reward_max: 3530.519346012008
reward_min: 1614.9780343938166
total_envstep_count: 7982691
total_train_sample_count: 6034894
total_episode_count: 21705
total_duration: 1780.8980532726548
[2023-06-29 11:24:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2173
train_sample_count: 2173
avg_envstep_per_episode: 310.42857142857144
avg_sample_per_episode: 310.42857142857144
avg_envstep_per_sec: 2627.450537014543
avg_train_sample_per_sec: 2627.450537014543
avg_episode_per_sec: 8.463945586333088
collect_time: 0.8270374529939143
reward_mean: 1632.6577395268882
reward_std: 527.3344589166546
reward_max: 2494.86725764979
reward_min: 952.7380759314351
total_envstep_count: 7987139
total_train_sample_count: 6038267
total_episode_count: 21712
total_duration: 1781.7250907256487
[2023-06-29 11:24:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2138
train_sample_count: 2138
avg_envstep_per_episode: 213.8
avg_sample_per_episode: 213.8
avg_envstep_per_sec: 2642.531740956606
avg_train_sample_per_sec: 2642.531740956606
avg_episode_per_sec: 12.359830406719393
collect_time: 0.8090725900707767
reward_mean: 1794.066311675301
reward_std: 936.0884220888591
reward_max: 3520.8821292840657
reward_min: 858.8573700174777
total_envstep_count: 7991739
total_train_sample_count: 6041605
total_episode_count: 21722
total_duration: 1782.5341633157195
[2023-06-29 11:24:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2525
train_sample_count: 2525
avg_envstep_per_episode: 229.54545454545453
avg_sample_per_episode: 229.54545454545453
avg_envstep_per_sec: 2507.6066591558306
avg_train_sample_per_sec: 2507.6066591558306
avg_episode_per_sec: 10.924227029985797
collect_time: 1.0069362317174675
reward_mean: 1500.8458814074918
reward_std: 690.8619494628397
reward_max: 2563.740467222981
reward_min: 460.6113437087902
total_envstep_count: 7995987
total_train_sample_count: 6044930
total_episode_count: 21733
total_duration: 1783.541099547437
[2023-06-29 11:24:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2844
train_sample_count: 2844
avg_envstep_per_episode: 284.4
avg_sample_per_episode: 284.4
avg_envstep_per_sec: 2420.55909881535
avg_train_sample_per_sec: 2420.55909881535
avg_episode_per_sec: 8.511107942388714
collect_time: 1.1749351632818579
reward_mean: 1713.3864228910838
reward_std: 917.9271101238573
reward_max: 3290.649362186315
reward_min: 852.7312438117722
total_envstep_count: 8000051
total_train_sample_count: 6048174
total_episode_count: 21743
total_duration: 1784.7160347107188
[2023-06-29 11:24:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1622
train_sample_count: 1622
avg_envstep_per_episode: 270.3333333333333
avg_sample_per_episode: 270.3333333333333
avg_envstep_per_sec: 2606.994454021213
avg_train_sample_per_sec: 2606.994454021213
avg_episode_per_sec: 9.643629299708557
collect_time: 0.6221724014403299
reward_mean: 1556.1026005464707
reward_std: 571.8884875195265
reward_max: 2474.9933614820616
reward_min: 847.5092505880857
total_envstep_count: 8003995
total_train_sample_count: 6051396
total_episode_count: 21749
total_duration: 1785.3382071121591
[2023-06-29 11:24:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1733
train_sample_count: 1733
avg_envstep_per_episode: 346.6
avg_sample_per_episode: 346.6
avg_envstep_per_sec: 2540.8164644323197
avg_train_sample_per_sec: 2540.8164644323197
avg_episode_per_sec: 7.330688010479861
collect_time: 0.6820642200093718
reward_mean: 2885.631997012136
reward_std: 778.047710904148
reward_max: 3552.694773264636
reward_min: 1771.3685477875365
total_envstep_count: 8008707
total_train_sample_count: 6054729
total_episode_count: 21754
total_duration: 1786.0202713321685
[2023-06-29 11:24:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2677
train_sample_count: 2677
avg_envstep_per_episode: 223.08333333333334
avg_sample_per_episode: 223.08333333333334
avg_envstep_per_sec: 2537.3295612053294
avg_train_sample_per_sec: 2537.3295612053294
avg_episode_per_sec: 11.373909127554708
collect_time: 1.0550462348014114
reward_mean: 1744.6513457415338
reward_std: 917.101704501626
reward_max: 3564.9389627716278
reward_min: 773.1365222482834
total_envstep_count: 8013483
total_train_sample_count: 6058206
total_episode_count: 21766
total_duration: 1787.07531756697
[2023-06-29 11:24:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2466
train_sample_count: 2466
avg_envstep_per_episode: 274.0
avg_sample_per_episode: 274.0
avg_envstep_per_sec: 2413.9789692949753
avg_train_sample_per_sec: 2413.9789692949753
avg_episode_per_sec: 8.81014222370429
collect_time: 1.0215499104866759
reward_mean: 1821.5230046326521
reward_std: 756.9359497979108
reward_max: 3181.2682906448813
reward_min: 982.8679359656201
total_envstep_count: 8017779
total_train_sample_count: 6061472
total_episode_count: 21775
total_duration: 1788.0968674774567
[2023-06-29 11:24:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1914
train_sample_count: 1914
avg_envstep_per_episode: 273.42857142857144
avg_sample_per_episode: 273.42857142857144
avg_envstep_per_sec: 2636.487994565339
avg_train_sample_per_sec: 2636.487994565339
avg_episode_per_sec: 9.642328088796955
collect_time: 0.7259657559394839
reward_mean: 1740.3791412017429
reward_std: 739.5025788839736
reward_max: 3473.053759750038
reward_min: 945.6630822223574
total_envstep_count: 8022483
total_train_sample_count: 6064986
total_episode_count: 21782
total_duration: 1788.8228332333963
[2023-06-29 11:24:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1998
train_sample_count: 1998
avg_envstep_per_episode: 285.42857142857144
avg_sample_per_episode: 285.42857142857144
avg_envstep_per_sec: 2341.020191307041
avg_train_sample_per_sec: 2341.020191307041
avg_episode_per_sec: 8.20177244201666
collect_time: 0.8534740569172428
reward_mean: 2513.9993129652257
reward_std: 879.9200660008869
reward_max: 3529.7968283017626
reward_min: 1576.0745554308528
total_envstep_count: 8027715
total_train_sample_count: 6068584
total_episode_count: 21789
total_duration: 1789.6763072903136
[2023-06-29 11:24:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 284.1666666666667
avg_sample_per_episode: 284.1666666666667
avg_envstep_per_sec: 2620.0166195582015
avg_train_sample_per_sec: 2620.0166195582015
avg_episode_per_sec: 9.21999983422241
collect_time: 0.6507592307897285
reward_mean: 2883.690988844115
reward_std: 656.4644644413174
reward_max: 3569.1325552266553
reward_min: 1759.8885954314226
total_envstep_count: 8032363
total_train_sample_count: 6071889
total_episode_count: 21795
total_duration: 1790.3270665211032
[2023-06-29 11:24:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2081
train_sample_count: 2081
avg_envstep_per_episode: 297.2857142857143
avg_sample_per_episode: 297.2857142857143
avg_envstep_per_sec: 2477.6372842143173
avg_train_sample_per_sec: 2477.6372842143173
avg_episode_per_sec: 8.33419557400299
collect_time: 0.8399130951324479
reward_mean: 2441.335909794977
reward_std: 1045.8389630024417
reward_max: 3509.1320090133404
reward_min: 873.4604041649652
total_envstep_count: 8036851
total_train_sample_count: 6075170
total_episode_count: 21802
total_duration: 1791.1669796162357
[2023-06-29 11:24:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1818
train_sample_count: 1818
avg_envstep_per_episode: 303.0
avg_sample_per_episode: 303.0
avg_envstep_per_sec: 2552.9176683273295
avg_train_sample_per_sec: 2552.9176683273295
avg_episode_per_sec: 8.425470852565445
collect_time: 0.7121263731122017
reward_mean: 2605.6456963073338
reward_std: 888.7558158074826
reward_max: 3508.5214543322877
reward_min: 1304.284597181806
total_envstep_count: 8041523
total_train_sample_count: 6078588
total_episode_count: 21808
total_duration: 1791.8791059893479
[2023-06-29 11:25:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 260.6
avg_sample_per_episode: 260.6
avg_envstep_per_sec: 2353.151505855949
avg_train_sample_per_sec: 2353.151505855949
avg_episode_per_sec: 9.029744842117992
collect_time: 1.1074510049670936
reward_mean: 1978.9295551293642
reward_std: 1011.5877251102622
reward_max: 3540.958516147371
reward_min: 726.4693438068917
total_envstep_count: 8045731
total_train_sample_count: 6081994
total_episode_count: 21818
total_duration: 1792.986556994315
[2023-06-29 11:25:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2946
train_sample_count: 2946
avg_envstep_per_episode: 294.6
avg_sample_per_episode: 294.6
avg_envstep_per_sec: 2411.415530957843
avg_train_sample_per_sec: 2411.415530957843
avg_episode_per_sec: 8.185388767677676
collect_time: 1.2216890710784356
reward_mean: 1715.2707002454285
reward_std: 591.8027146288482
reward_max: 2884.6787719006634
reward_min: 747.3447584870839
total_envstep_count: 8049523
total_train_sample_count: 6085340
total_episode_count: 21828
total_duration: 1794.2082460653933
[2023-06-29 11:25:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 251.75
avg_sample_per_episode: 251.75
avg_envstep_per_sec: 1680.5349249904061
avg_train_sample_per_sec: 1680.5349249904061
avg_episode_per_sec: 6.675411817240938
collect_time: 1.198427935088286
reward_mean: 1252.964952222561
reward_std: 287.8247940249915
reward_max: 1703.54708629284
reward_min: 662.466188493527
total_envstep_count: 8054323
total_train_sample_count: 6088554
total_episode_count: 21836
total_duration: 1795.4066740004816
[2023-06-29 11:25:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1602
train_sample_count: 1602
avg_envstep_per_episode: 200.25
avg_sample_per_episode: 200.25
avg_envstep_per_sec: 2275.3423918250223
avg_train_sample_per_sec: 2275.3423918250223
avg_episode_per_sec: 11.362508823096242
collect_time: 0.7040698603233322
reward_mean: 1876.716670792621
reward_std: 457.45830069687406
reward_max: 2720.11983821245
reward_min: 1246.849410070014
total_envstep_count: 8058875
total_train_sample_count: 6091756
total_episode_count: 21844
total_duration: 1796.110743860805
[2023-06-29 11:25:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1156
train_sample_count: 1156
avg_envstep_per_episode: 165.14285714285714
avg_sample_per_episode: 165.14285714285714
avg_envstep_per_sec: 2594.944418344289
avg_train_sample_per_sec: 2594.944418344289
avg_episode_per_sec: 15.713331252949844
collect_time: 0.4454816033160313
reward_mean: 2055.8050020597316
reward_std: 810.6802690732619
reward_max: 3523.3334633139166
reward_min: 1004.4296716563598
total_envstep_count: 8063371
total_train_sample_count: 6095312
total_episode_count: 21851
total_duration: 1796.556225464121
[2023-06-29 11:25:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2889
train_sample_count: 2889
avg_envstep_per_episode: 240.75
avg_sample_per_episode: 240.75
avg_envstep_per_sec: 2606.9534987395746
avg_train_sample_per_sec: 2606.9534987395746
avg_episode_per_sec: 10.828467284484214
collect_time: 1.1081900775739923
reward_mean: 1785.69728379615
reward_std: 1162.6246187573813
reward_max: 3499.2081284950773
reward_min: 348.9526131553845
total_envstep_count: 8067611
total_train_sample_count: 6098601
total_episode_count: 21863
total_duration: 1797.664415541695
[2023-06-29 11:25:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1646
train_sample_count: 1646
avg_envstep_per_episode: 235.14285714285714
avg_sample_per_episode: 235.14285714285714
avg_envstep_per_sec: 2525.263048135662
avg_train_sample_per_sec: 2525.263048135662
avg_episode_per_sec: 10.73927177214437
collect_time: 0.6518132838538149
reward_mean: 1592.8008170180462
reward_std: 922.2538592131635
reward_max: 3592.5861565211794
reward_min: 554.3508441515968
total_envstep_count: 8071563
total_train_sample_count: 6101847
total_episode_count: 21870
total_duration: 1798.316228825549
[2023-06-29 11:25:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1638
train_sample_count: 1638
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2359.4900335525545
avg_train_sample_per_sec: 2359.4900335525545
avg_episode_per_sec: 8.642820635723643
collect_time: 0.6942178083853795
reward_mean: 1923.1647515572158
reward_std: 1059.1522185670544
reward_max: 3490.4388123576973
reward_min: 507.5767866256897
total_envstep_count: 8076059
total_train_sample_count: 6105085
total_episode_count: 21876
total_duration: 1799.0104466339344
[2023-06-29 11:25:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 307.5
avg_sample_per_episode: 307.5
avg_envstep_per_sec: 2407.769659094966
avg_train_sample_per_sec: 2407.769659094966
avg_episode_per_sec: 7.830145232829158
collect_time: 1.0216924159284682
reward_mean: 2730.9215171870446
reward_std: 828.3297555000537
reward_max: 3500.620366723503
reward_min: 1220.1291661028995
total_envstep_count: 8079811
total_train_sample_count: 6108345
total_episode_count: 21884
total_duration: 1800.032139049863
[2023-06-29 11:25:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2033
train_sample_count: 2033
avg_envstep_per_episode: 338.8333333333333
avg_sample_per_episode: 338.8333333333333
avg_envstep_per_sec: 2532.119436227464
avg_train_sample_per_sec: 2532.119436227464
avg_episode_per_sec: 7.473052935250755
collect_time: 0.8028847181983293
reward_mean: 1843.2162521395392
reward_std: 1149.3701706620757
reward_max: 3476.8040382387494
reward_min: 676.5301984228807
total_envstep_count: 8084467
total_train_sample_count: 6111578
total_episode_count: 21890
total_duration: 1800.8350237680613
[2023-06-29 11:25:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1199
train_sample_count: 1199
avg_envstep_per_episode: 239.8
avg_sample_per_episode: 239.8
avg_envstep_per_sec: 2532.8632048129507
avg_train_sample_per_sec: 2532.8632048129507
avg_episode_per_sec: 10.562398685625316
collect_time: 0.47337732164992496
reward_mean: 2192.4064963086116
reward_std: 872.4376929697446
reward_max: 3551.1238966411815
reward_min: 1031.4920615177302
total_envstep_count: 8088768
total_train_sample_count: 6115177
total_episode_count: 21895
total_duration: 1801.3084010897112
[2023-06-29 11:25:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2045
train_sample_count: 2045
avg_envstep_per_episode: 227.22222222222223
avg_sample_per_episode: 227.22222222222223
avg_envstep_per_sec: 1929.7963648762245
avg_train_sample_per_sec: 1929.7963648762245
avg_episode_per_sec: 8.492991336863579
collect_time: 1.059697301342551
reward_mean: 2255.6330149170303
reward_std: 1022.4110058231271
reward_max: 3539.263703381299
reward_min: 863.9155372687687
total_envstep_count: 8092542
total_train_sample_count: 6118422
total_episode_count: 21904
total_duration: 1802.3680983910538
[2023-06-29 11:25:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 266.6666666666667
avg_sample_per_episode: 266.6666666666667
avg_envstep_per_sec: 2497.6979560872514
avg_train_sample_per_sec: 2497.6979560872514
avg_episode_per_sec: 9.366367335327192
collect_time: 0.9608847996015102
reward_mean: 1510.948426422462
reward_std: 831.8587698113083
reward_max: 3555.6609240449125
reward_min: 835.7647017341312
total_envstep_count: 8096918
total_train_sample_count: 6121622
total_episode_count: 21913
total_duration: 1803.3289831906552
[2023-06-29 11:25:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2338
train_sample_count: 2338
avg_envstep_per_episode: 233.8
avg_sample_per_episode: 233.8
avg_envstep_per_sec: 1361.1280422862344
avg_train_sample_per_sec: 1361.1280422862344
avg_episode_per_sec: 5.821762370770892
collect_time: 1.7176929189357903
reward_mean: 1613.7177265254606
reward_std: 690.3615860875035
reward_max: 3505.8551125038293
reward_min: 965.744971281914
total_envstep_count: 8101582
total_train_sample_count: 6125160
total_episode_count: 21923
total_duration: 1805.046676109591
[2023-06-29 11:25:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1837
train_sample_count: 1837
avg_envstep_per_episode: 262.42857142857144
avg_sample_per_episode: 262.42857142857144
avg_envstep_per_sec: 1951.4976711003956
avg_train_sample_per_sec: 1951.4976711003956
avg_episode_per_sec: 7.436300325368954
collect_time: 0.9413283075885848
reward_mean: 1937.2860532967736
reward_std: 1068.790383689812
reward_max: 3543.183154202743
reward_min: 754.1158426331743
total_envstep_count: 8106358
total_train_sample_count: 6128597
total_episode_count: 21930
total_duration: 1805.9880044171796
[2023-06-29 11:26:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2409
train_sample_count: 2409
avg_envstep_per_episode: 267.6666666666667
avg_sample_per_episode: 267.6666666666667
avg_envstep_per_sec: 1741.6356707331138
avg_train_sample_per_sec: 1741.6356707331138
avg_episode_per_sec: 6.50673351456954
collect_time: 1.3831825108324578
reward_mean: 2161.3965246515545
reward_std: 1027.2590700687244
reward_max: 3604.9737882374898
reward_min: 1222.3896052763173
total_envstep_count: 8110596
total_train_sample_count: 6131806
total_episode_count: 21939
total_duration: 1807.371186928012
[2023-06-29 11:27:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2898
train_sample_count: 2898
avg_envstep_per_episode: 222.92307692307693
avg_sample_per_episode: 222.92307692307693
avg_envstep_per_sec: 776.4064161801815
avg_train_sample_per_sec: 776.4064161801815
avg_episode_per_sec: 3.482844517026349
collect_time: 3.7325812095394353
reward_mean: 1338.3359011127213
reward_std: 792.5992606074682
reward_max: 2930.2416695376223
reward_min: 42.234710067833234
total_envstep_count: 8114974
total_train_sample_count: 6135104
total_episode_count: 21952
total_duration: 1811.1037681375515
[2023-06-29 11:27:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2810
train_sample_count: 2810
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2201.1893045621255
avg_train_sample_per_sec: 2201.1893045621255
avg_episode_per_sec: 7.8334138952388805
collect_time: 1.2765826156687523
reward_mean: 1454.4833760976303
reward_std: 710.4236610411606
reward_max: 3497.5419752699577
reward_min: 882.7135561846715
total_envstep_count: 8120059
total_train_sample_count: 6138314
total_episode_count: 21962
total_duration: 1812.3803507532202
[2023-06-29 11:27:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2642
train_sample_count: 2642
avg_envstep_per_episode: 264.2
avg_sample_per_episode: 264.2
avg_envstep_per_sec: 1850.2422855943364
avg_train_sample_per_sec: 1850.2422855943364
avg_episode_per_sec: 7.003188060538745
collect_time: 1.4279211001554504
reward_mean: 1877.9060529907642
reward_std: 811.8910159366693
reward_max: 3543.913377727877
reward_min: 920.3648856439452
total_envstep_count: 8125283
total_train_sample_count: 6141756
total_episode_count: 21972
total_duration: 1813.8082718533756
[2023-06-29 11:27:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2357
train_sample_count: 2357
avg_envstep_per_episode: 214.27272727272728
avg_sample_per_episode: 214.27272727272728
avg_envstep_per_sec: 2215.9089345200177
avg_train_sample_per_sec: 2215.9089345200177
avg_episode_per_sec: 10.341535120797706
collect_time: 1.063671869941056
reward_mean: 1505.42628295623
reward_std: 608.3770399018042
reward_max: 3154.085170924512
reward_min: 959.4915706978614
total_envstep_count: 8129835
total_train_sample_count: 6145313
total_episode_count: 21983
total_duration: 1814.8719437233167
[2023-06-29 11:27:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 907
train_sample_count: 907
avg_envstep_per_episode: 181.4
avg_sample_per_episode: 181.4
avg_envstep_per_sec: 2581.1382978732177
avg_train_sample_per_sec: 2581.1382978732177
avg_episode_per_sec: 14.22898730911366
collect_time: 0.35139535171259184
reward_mean: 2230.6733929177253
reward_std: 978.480925410027
reward_max: 3507.4825600621034
reward_min: 1156.498731302146
total_envstep_count: 8133955
total_train_sample_count: 6148620
total_episode_count: 21988
total_duration: 1815.2233390750293
[2023-06-29 11:27:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2625
train_sample_count: 2625
avg_envstep_per_episode: 291.6666666666667
avg_sample_per_episode: 291.6666666666667
avg_envstep_per_sec: 2490.2368150807774
avg_train_sample_per_sec: 2490.2368150807774
avg_episode_per_sec: 8.537954794562665
collect_time: 1.0541166141722353
reward_mean: 2442.720672218138
reward_std: 861.9257201298935
reward_max: 3638.332704951166
reward_min: 1322.15865238579
total_envstep_count: 8138235
total_train_sample_count: 6152045
total_episode_count: 21997
total_duration: 1816.2774556892016
[2023-06-29 11:27:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1680
train_sample_count: 1680
avg_envstep_per_episode: 336.0
avg_sample_per_episode: 336.0
avg_envstep_per_sec: 2601.912611300078
avg_train_sample_per_sec: 2601.912611300078
avg_episode_per_sec: 7.743787533631185
collect_time: 0.6456788720358164
reward_mean: 2135.7202954327076
reward_std: 1171.7814973480174
reward_max: 3569.007861280129
reward_min: 1042.7657014171582
total_envstep_count: 8142699
total_train_sample_count: 6155325
total_episode_count: 22002
total_duration: 1816.9231345612375
[2023-06-29 11:27:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 246.9
avg_sample_per_episode: 246.9
avg_envstep_per_sec: 2404.5037951048357
avg_train_sample_per_sec: 2404.5037951048357
avg_episode_per_sec: 9.738776002854742
collect_time: 1.026823083010502
reward_mean: 1958.2171171831837
reward_std: 1128.7423501013495
reward_max: 3631.9134635165283
reward_min: 568.4824716008302
total_envstep_count: 8147379
total_train_sample_count: 6158594
total_episode_count: 22012
total_duration: 1817.949957644248
[2023-06-29 11:27:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2925
train_sample_count: 2925
avg_envstep_per_episode: 265.90909090909093
avg_sample_per_episode: 265.90909090909093
avg_envstep_per_sec: 2303.8083606021846
avg_train_sample_per_sec: 2303.8083606021846
avg_episode_per_sec: 8.663894689444113
collect_time: 1.2696368543585996
reward_mean: 1665.1285098047024
reward_std: 924.3579440236024
reward_max: 3623.359359994189
reward_min: 880.3494611260562
total_envstep_count: 8151779
total_train_sample_count: 6161919
total_episode_count: 22023
total_duration: 1819.2195944986065
[2023-06-29 11:27:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1695
train_sample_count: 1695
avg_envstep_per_episode: 282.5
avg_sample_per_episode: 282.5
avg_envstep_per_sec: 2601.8279819929485
avg_train_sample_per_sec: 2601.8279819929485
avg_episode_per_sec: 9.210010555727251
collect_time: 0.6514650513911622
reward_mean: 1766.9912645546476
reward_std: 362.1894996359739
reward_max: 2166.818578820898
reward_min: 1255.2317375802531
total_envstep_count: 8156619
total_train_sample_count: 6165214
total_episode_count: 22029
total_duration: 1819.8710595499977
[2023-06-29 11:27:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1749
train_sample_count: 1749
avg_envstep_per_episode: 291.5
avg_sample_per_episode: 291.5
avg_envstep_per_sec: 2511.2783865663337
avg_train_sample_per_sec: 2511.2783865663337
avg_episode_per_sec: 8.615020194052603
collect_time: 0.6964580308403818
reward_mean: 2694.5937072921406
reward_std: 752.2453352854942
reward_max: 3512.7142263699716
reward_min: 1503.879322020012
total_envstep_count: 8161107
total_train_sample_count: 6168563
total_episode_count: 22035
total_duration: 1820.567517580838
[2023-06-29 11:27:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1270
train_sample_count: 1270
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2652.4045335094456
avg_train_sample_per_sec: 2652.4045335094456
avg_episode_per_sec: 10.442537533501755
collect_time: 0.4788108238978311
reward_mean: 2969.3114907058434
reward_std: 424.0553797868405
reward_max: 3475.3695447840696
reward_min: 2483.0688109256607
total_envstep_count: 8165371
total_train_sample_count: 6171833
total_episode_count: 22040
total_duration: 1821.046328404736
[2023-06-29 11:27:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1758
train_sample_count: 1758
avg_envstep_per_episode: 293.0
avg_sample_per_episode: 293.0
avg_envstep_per_sec: 2427.2277372159133
avg_train_sample_per_sec: 2427.2277372159133
avg_episode_per_sec: 8.284053710634517
collect_time: 0.7242830876745282
reward_mean: 2383.7127579501907
reward_std: 1150.6188892704722
reward_max: 3518.1854679223948
reward_min: 603.7091923366228
total_envstep_count: 8169571
total_train_sample_count: 6175191
total_episode_count: 22046
total_duration: 1821.7706114924106
[2023-06-29 11:27:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1344
train_sample_count: 1344
avg_envstep_per_episode: 192.0
avg_sample_per_episode: 192.0
avg_envstep_per_sec: 2495.1437264424535
avg_train_sample_per_sec: 2495.1437264424535
avg_episode_per_sec: 12.995540241887777
collect_time: 0.5386463255630807
reward_mean: 2167.834505728241
reward_std: 1236.465194620284
reward_max: 3547.2328475156864
reward_min: 498.535496075097
total_envstep_count: 8174275
total_train_sample_count: 6178535
total_episode_count: 22053
total_duration: 1822.3092578179737
[2023-06-29 11:28:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 236.44444444444446
avg_sample_per_episode: 236.44444444444446
avg_envstep_per_sec: 2337.7967408298778
avg_train_sample_per_sec: 2337.7967408298778
avg_episode_per_sec: 9.887298245991024
collect_time: 0.9102587760664755
reward_mean: 2241.639202318953
reward_std: 1204.3013170838904
reward_max: 3556.7250720160664
reward_min: 379.36908357252594
total_envstep_count: 8179075
total_train_sample_count: 6181863
total_episode_count: 22062
total_duration: 1823.2195165940402
[2023-06-29 11:28:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2642
train_sample_count: 2642
avg_envstep_per_episode: 188.71428571428572
avg_sample_per_episode: 188.71428571428572
avg_envstep_per_sec: 2702.646085369713
avg_train_sample_per_sec: 2702.646085369713
avg_episode_per_sec: 14.321364570467821
collect_time: 0.9775604783408343
reward_mean: 1396.1334991574572
reward_std: 868.5665226051291
reward_max: 3508.6179805710744
reward_min: 383.49160703332007
total_envstep_count: 8183907
total_train_sample_count: 6185305
total_episode_count: 22076
total_duration: 1824.197077072381
[2023-06-29 11:28:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 225.22222222222223
avg_sample_per_episode: 225.22222222222223
avg_envstep_per_sec: 2494.934598810588
avg_train_sample_per_sec: 2494.934598810588
avg_episode_per_sec: 11.077657320816622
collect_time: 0.8124461462702602
reward_mean: 1360.4285538534887
reward_std: 840.4864024795298
reward_max: 3456.966577925419
reward_min: 314.1095688899638
total_envstep_count: 8187627
total_train_sample_count: 6188532
total_episode_count: 22085
total_duration: 1825.0095232186513
[2023-06-29 11:28:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1462
train_sample_count: 1462
avg_envstep_per_episode: 208.85714285714286
avg_sample_per_episode: 208.85714285714286
avg_envstep_per_sec: 2113.06341173648
avg_train_sample_per_sec: 2113.06341173648
avg_episode_per_sec: 10.117266677260847
collect_time: 0.6918864771779627
reward_mean: 1796.790285921328
reward_std: 1064.895509149306
reward_max: 3510.0717732772914
reward_min: 672.5699186127541
total_envstep_count: 8192203
total_train_sample_count: 6191994
total_episode_count: 22092
total_duration: 1825.7014096958294
[2023-06-29 11:28:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2738
train_sample_count: 2738
avg_envstep_per_episode: 391.14285714285717
avg_sample_per_episode: 391.14285714285717
avg_envstep_per_sec: 2702.939364543048
avg_train_sample_per_sec: 2702.939364543048
avg_episode_per_sec: 6.91036360547894
collect_time: 1.0129712992887945
reward_mean: 3008.5061833313894
reward_std: 531.3698212018128
reward_max: 3613.2004454326157
reward_min: 2228.1378848665063
total_envstep_count: 8197691
total_train_sample_count: 6195532
total_episode_count: 22099
total_duration: 1826.7143809951183
[2023-06-29 11:28:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2185
train_sample_count: 2185
avg_envstep_per_episode: 198.63636363636363
avg_sample_per_episode: 198.63636363636363
avg_envstep_per_sec: 2469.947456335287
avg_train_sample_per_sec: 2469.947456335287
avg_episode_per_sec: 12.434518086813801
collect_time: 0.884634203207679
reward_mean: 1386.3629029305066
reward_std: 988.137534709002
reward_max: 3507.80922385058
reward_min: 169.6581801237655
total_envstep_count: 8202259
total_train_sample_count: 6198917
total_episode_count: 22110
total_duration: 1827.599015198326
[2023-06-29 11:28:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1160
train_sample_count: 1160
avg_envstep_per_episode: 165.71428571428572
avg_sample_per_episode: 165.71428571428572
avg_envstep_per_sec: 2678.782863248198
avg_train_sample_per_sec: 2678.782863248198
avg_episode_per_sec: 16.165069002359814
collect_time: 0.4330324849821627
reward_mean: 1937.3193904059156
reward_std: 1434.2945782055579
reward_max: 3525.6842578466767
reward_min: 41.47435714310873
total_envstep_count: 8206955
total_train_sample_count: 6202477
total_episode_count: 22117
total_duration: 1828.032047683308
[2023-06-29 11:28:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1126
train_sample_count: 1126
avg_envstep_per_episode: 160.85714285714286
avg_sample_per_episode: 160.85714285714286
avg_envstep_per_sec: 2238.036621466408
avg_train_sample_per_sec: 2238.036621466408
avg_episode_per_sec: 13.913193916753869
collect_time: 0.5031195598855847
reward_mean: 2247.3593981887184
reward_std: 868.3520335244259
reward_max: 3494.6003571950023
reward_min: 1087.746919986669
total_envstep_count: 8211403
total_train_sample_count: 6206003
total_episode_count: 22124
total_duration: 1828.5351672431937
[2023-06-29 11:28:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1312
train_sample_count: 1312
avg_envstep_per_episode: 145.77777777777777
avg_sample_per_episode: 145.77777777777777
avg_envstep_per_sec: 2346.504989401958
avg_train_sample_per_sec: 2346.504989401958
avg_episode_per_sec: 16.09645190900733
collect_time: 0.5591294311862439
reward_mean: 1951.6980228469542
reward_std: 1004.2347847027718
reward_max: 3495.4751770086696
reward_min: 156.46856568375185
total_envstep_count: 8215627
total_train_sample_count: 6209315
total_episode_count: 22133
total_duration: 1829.0942966743798
[2023-06-29 11:28:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2432
train_sample_count: 2432
avg_envstep_per_episode: 243.2
avg_sample_per_episode: 243.2
avg_envstep_per_sec: 2662.154347032851
avg_train_sample_per_sec: 2662.154347032851
avg_episode_per_sec: 10.946358334839028
collect_time: 0.9135458290427925
reward_mean: 1923.8718211717592
reward_std: 706.5820150194824
reward_max: 3473.9485193463806
reward_min: 950.0673663065403
total_envstep_count: 8220179
total_train_sample_count: 6212547
total_episode_count: 22143
total_duration: 1830.0078425034226
[2023-06-29 11:28:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 203.33333333333334
avg_sample_per_episode: 203.33333333333334
avg_envstep_per_sec: 2702.5569955991173
avg_train_sample_per_sec: 2702.5569955991173
avg_episode_per_sec: 13.291263912782545
collect_time: 0.45142433702107504
reward_mean: 1742.0274502121463
reward_std: 1173.1417769553934
reward_max: 3446.9040495594895
reward_min: 520.4976417218721
total_envstep_count: 8224187
total_train_sample_count: 6215767
total_episode_count: 22149
total_duration: 1830.4592668404437
[2023-06-29 11:28:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 351.0
avg_sample_per_episode: 351.0
avg_envstep_per_sec: 2693.899721558935
avg_train_sample_per_sec: 2693.899721558935
avg_episode_per_sec: 7.674927981649389
collect_time: 0.9120606755837802
reward_mean: 2708.537299674466
reward_std: 1187.5078637006827
reward_max: 3512.755104710074
reward_min: 729.6689686960827
total_envstep_count: 8228443
total_train_sample_count: 6219024
total_episode_count: 22156
total_duration: 1831.3713275160273
[2023-06-29 11:28:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 214.33333333333334
avg_sample_per_episode: 214.33333333333334
avg_envstep_per_sec: 2641.3122050268353
avg_train_sample_per_sec: 2641.3122050268353
avg_episode_per_sec: 12.3233850934378
collect_time: 0.48687921009585255
reward_mean: 1512.4629038857438
reward_std: 1442.0631503553075
reward_max: 3516.781587092466
reward_min: 154.4686978464018
total_envstep_count: 8233139
total_train_sample_count: 6222310
total_episode_count: 22162
total_duration: 1831.8582067261232
[2023-06-29 11:28:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1902
train_sample_count: 1902
avg_envstep_per_episode: 211.33333333333334
avg_sample_per_episode: 211.33333333333334
avg_envstep_per_sec: 2620.751524120146
avg_train_sample_per_sec: 2620.751524120146
avg_episode_per_sec: 12.401032448518041
collect_time: 0.7257460245639085
reward_mean: 2024.676646754547
reward_std: 1393.0524245428699
reward_max: 3552.681939496983
reward_min: 156.63486884378943
total_envstep_count: 8237923
total_train_sample_count: 6225812
total_episode_count: 22171
total_duration: 1832.583952750687
[2023-06-29 11:28:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2213.655142582361
avg_train_sample_per_sec: 2213.655142582361
avg_episode_per_sec: 8.749625069495497
collect_time: 0.571453057735227
reward_mean: 2798.1665756044677
reward_std: 1010.8074237957263
reward_max: 3593.8540099292672
reward_min: 975.9277542000643
total_envstep_count: 8242603
total_train_sample_count: 6229077
total_episode_count: 22176
total_duration: 1833.1554058084223
[2023-06-29 11:28:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1575
train_sample_count: 1575
avg_envstep_per_episode: 196.875
avg_sample_per_episode: 196.875
avg_envstep_per_sec: 2702.372369776132
avg_train_sample_per_sec: 2702.372369776132
avg_episode_per_sec: 13.72633584648194
collect_time: 0.5828212342662736
reward_mean: 2425.134788171221
reward_std: 1037.4230964457784
reward_max: 3501.3272406982783
reward_min: 776.5954731051021
total_envstep_count: 8247515
total_train_sample_count: 6232652
total_episode_count: 22184
total_duration: 1833.7382270426885
[2023-06-29 11:28:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1667
train_sample_count: 1667
avg_envstep_per_episode: 277.8333333333333
avg_sample_per_episode: 277.8333333333333
avg_envstep_per_sec: 2318.8348099265577
avg_train_sample_per_sec: 2318.8348099265577
avg_episode_per_sec: 8.346136088517904
collect_time: 0.7188955387696623
reward_mean: 2843.437378100385
reward_std: 842.9701798654813
reward_max: 3492.3927160770695
reward_min: 1595.7727700157527
total_envstep_count: 8251667
total_train_sample_count: 6235919
total_episode_count: 22190
total_duration: 1834.4571225814582
[2023-06-29 11:28:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1244
train_sample_count: 1244
avg_envstep_per_episode: 311.0
avg_sample_per_episode: 311.0
avg_envstep_per_sec: 2523.774186414221
avg_train_sample_per_sec: 2523.774186414221
avg_episode_per_sec: 8.115029538309392
collect_time: 0.49291256194654864
reward_mean: 2539.660989911761
reward_std: 920.5482757479263
reward_max: 3440.3301222948917
reward_min: 1241.3695405118926
total_envstep_count: 8255515
total_train_sample_count: 6239163
total_episode_count: 22194
total_duration: 1834.9500351434046
[2023-06-29 11:28:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2330
train_sample_count: 2330
avg_envstep_per_episode: 258.8888888888889
avg_sample_per_episode: 258.8888888888889
avg_envstep_per_sec: 2646.5679089381674
avg_train_sample_per_sec: 2646.5679089381674
avg_episode_per_sec: 10.222794498044424
collect_time: 0.8803854955434799
reward_mean: 2357.318420735219
reward_std: 1184.286940978958
reward_max: 3553.788866844619
reward_min: 171.53214770968762
total_envstep_count: 8259947
total_train_sample_count: 6242693
total_episode_count: 22203
total_duration: 1835.8304206389482
[2023-06-29 11:29:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2282
train_sample_count: 2282
avg_envstep_per_episode: 175.53846153846155
avg_sample_per_episode: 175.53846153846155
avg_envstep_per_sec: 2690.8607288142584
avg_train_sample_per_sec: 2690.8607288142584
avg_episode_per_sec: 15.329180313139949
collect_time: 0.8480557821383699
reward_mean: 1165.3409383237017
reward_std: 1054.868395510568
reward_max: 3500.383455464251
reward_min: 150.0240544574896
total_envstep_count: 8265067
total_train_sample_count: 6246175
total_episode_count: 22216
total_duration: 1836.6784764210865
[2023-06-29 11:29:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 314.14285714285717
avg_sample_per_episode: 314.14285714285717
avg_envstep_per_sec: 2543.174570642608
avg_train_sample_per_sec: 2543.174570642608
avg_episode_per_sec: 8.095598906092885
collect_time: 0.8646673434786499
reward_mean: 2221.166466120491
reward_std: 838.9274850980484
reward_max: 3535.2381277831814
reward_min: 1245.5321867753057
total_envstep_count: 8269851
total_train_sample_count: 6249574
total_episode_count: 22223
total_duration: 1837.5431437645652
[2023-06-29 11:29:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 244.83333333333334
avg_sample_per_episode: 244.83333333333334
avg_envstep_per_sec: 2279.71655579071
avg_train_sample_per_sec: 2279.71655579071
avg_episode_per_sec: 9.311299751357563
collect_time: 0.6443783532073721
reward_mean: 2505.1997747393657
reward_std: 902.1873465301954
reward_max: 3541.6634256789134
reward_min: 1161.619825210299
total_envstep_count: 8273995
total_train_sample_count: 6253043
total_episode_count: 22229
total_duration: 1838.1875221177727
[2023-06-29 11:29:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 311.125
avg_sample_per_episode: 311.125
avg_envstep_per_sec: 2622.024569695531
avg_train_sample_per_sec: 2622.024569695531
avg_episode_per_sec: 8.427559886526417
collect_time: 0.9492664671288804
reward_mean: 2471.893202858696
reward_std: 1018.7503822602063
reward_max: 3568.682759514022
reward_min: 1291.7454657303797
total_envstep_count: 8278131
total_train_sample_count: 6256332
total_episode_count: 22237
total_duration: 1839.1367885849015
[2023-06-29 11:29:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3062
train_sample_count: 3062
avg_envstep_per_episode: 382.75
avg_sample_per_episode: 382.75
avg_envstep_per_sec: 2760.0549892823824
avg_train_sample_per_sec: 2760.0549892823824
avg_episode_per_sec: 7.2111168890460675
collect_time: 1.109398186590523
reward_mean: 2043.4884070539892
reward_std: 600.0541051064903
reward_max: 2994.566604755499
reward_min: 1275.894540344135
total_envstep_count: 8283435
total_train_sample_count: 6259794
total_episode_count: 22245
total_duration: 1840.2461867714921
[2023-06-29 11:29:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1445
train_sample_count: 1445
avg_envstep_per_episode: 240.83333333333334
avg_sample_per_episode: 240.83333333333334
avg_envstep_per_sec: 2402.2387243369317
avg_train_sample_per_sec: 2402.2387243369317
avg_episode_per_sec: 9.974693665066845
collect_time: 0.6015222323080527
reward_mean: 1743.9458681196868
reward_std: 1115.6148626068164
reward_max: 3461.9000564064527
reward_min: 430.77728408456454
total_envstep_count: 8288203
total_train_sample_count: 6263239
total_episode_count: 22251
total_duration: 1840.8477090038002
[2023-06-29 11:29:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1796
train_sample_count: 1796
avg_envstep_per_episode: 224.5
avg_sample_per_episode: 224.5
avg_envstep_per_sec: 2335.9335645132455
avg_train_sample_per_sec: 2335.9335645132455
avg_episode_per_sec: 10.40504928513695
collect_time: 0.768857482628897
reward_mean: 2535.9658892549733
reward_std: 1297.8370341631128
reward_max: 3580.515343799391
reward_min: 167.42691786152804
total_envstep_count: 8292747
total_train_sample_count: 6266635
total_episode_count: 22259
total_duration: 1841.616566486429
[2023-06-29 11:29:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2411
train_sample_count: 2411
avg_envstep_per_episode: 344.42857142857144
avg_sample_per_episode: 344.42857142857144
avg_envstep_per_sec: 2720.3654578279056
avg_train_sample_per_sec: 2720.3654578279056
avg_episode_per_sec: 7.898199172457627
collect_time: 0.886277978961356
reward_mean: 2432.4780103973385
reward_std: 763.7679866552105
reward_max: 3490.7797186547728
reward_min: 1280.7868224195454
total_envstep_count: 8297651
total_train_sample_count: 6269846
total_episode_count: 22266
total_duration: 1842.5028444653904
[2023-06-29 11:29:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 547
train_sample_count: 547
avg_envstep_per_episode: 136.75
avg_sample_per_episode: 136.75
avg_envstep_per_sec: 2761.2548552005046
avg_train_sample_per_sec: 2761.2548552005046
avg_episode_per_sec: 20.19199162852289
collect_time: 0.19809833886567502
reward_mean: 2187.722981036139
reward_std: 1032.4297245110836
reward_max: 3428.2994299024876
reward_min: 1077.3857783297449
total_envstep_count: 8301627
total_train_sample_count: 6273193
total_episode_count: 22270
total_duration: 1842.700942804256
[2023-06-29 11:29:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 306.57142857142856
avg_sample_per_episode: 306.57142857142856
avg_envstep_per_sec: 2471.0253074687184
avg_train_sample_per_sec: 2471.0253074687184
avg_episode_per_sec: 8.060194385965064
collect_time: 0.8684654072597624
reward_mean: 3252.981139221631
reward_std: 371.4542806429526
reward_max: 3551.7106322352734
reward_min: 2641.366868355497
total_envstep_count: 8306387
total_train_sample_count: 6276539
total_episode_count: 22277
total_duration: 1843.5694082115158
[2023-06-29 11:29:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1725
train_sample_count: 1725
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 2541.8971916906494
avg_train_sample_per_sec: 2541.8971916906494
avg_episode_per_sec: 8.841381536315303
collect_time: 0.6786269742297011
reward_mean: 2423.2412521068086
reward_std: 950.9738578830426
reward_max: 3491.736785778904
reward_min: 1276.452627885371
total_envstep_count: 8310667
total_train_sample_count: 6279864
total_episode_count: 22283
total_duration: 1844.2480351857455
[2023-06-29 11:29:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 949
train_sample_count: 949
avg_envstep_per_episode: 189.8
avg_sample_per_episode: 189.8
avg_envstep_per_sec: 2583.71444028412
avg_train_sample_per_sec: 2583.71444028412
avg_episode_per_sec: 13.612826345016439
collect_time: 0.3673006525812669
reward_mean: 2406.5011274377566
reward_std: 886.4414020535963
reward_max: 3487.4336915960334
reward_min: 1556.6457470987916
total_envstep_count: 8314827
total_train_sample_count: 6283213
total_episode_count: 22288
total_duration: 1844.6153358383267
[2023-06-29 11:29:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2952
train_sample_count: 2952
avg_envstep_per_episode: 328.0
avg_sample_per_episode: 328.0
avg_envstep_per_sec: 2488.206110663409
avg_train_sample_per_sec: 2488.206110663409
avg_episode_per_sec: 7.585994239827468
collect_time: 1.1863968934683362
reward_mean: 2626.6176530860043
reward_std: 862.4012231385638
reward_max: 3503.076009697139
reward_min: 1156.2639372515714
total_envstep_count: 8319739
total_train_sample_count: 6286565
total_episode_count: 22297
total_duration: 1845.801732731795
[2023-06-29 11:29:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1843
train_sample_count: 1843
avg_envstep_per_episode: 204.77777777777777
avg_sample_per_episode: 204.77777777777777
avg_envstep_per_sec: 2699.910441138485
avg_train_sample_per_sec: 2699.910441138485
avg_episode_per_sec: 13.184587070128252
collect_time: 0.6826152349049225
reward_mean: 1311.3740382763415
reward_std: 388.2777030734887
reward_max: 2017.922862641324
reward_min: 449.9325803604582
total_envstep_count: 8324099
total_train_sample_count: 6290008
total_episode_count: 22306
total_duration: 1846.4843479667
[2023-06-29 11:29:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2444
train_sample_count: 2444
avg_envstep_per_episode: 271.55555555555554
avg_sample_per_episode: 271.55555555555554
avg_envstep_per_sec: 2395.3140758104437
avg_train_sample_per_sec: 2395.3140758104437
avg_episode_per_sec: 8.820714681789685
collect_time: 1.0203254866162317
reward_mean: 2096.216840753198
reward_std: 884.8059281020988
reward_max: 3489.203488547439
reward_min: 1039.656596238532
total_envstep_count: 8329083
total_train_sample_count: 6293252
total_episode_count: 22315
total_duration: 1847.5046734533162
[2023-06-29 11:29:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2060
train_sample_count: 2060
avg_envstep_per_episode: 228.88888888888889
avg_sample_per_episode: 228.88888888888889
avg_envstep_per_sec: 2391.2367314132903
avg_train_sample_per_sec: 2391.2367314132903
avg_episode_per_sec: 10.447150768310491
collect_time: 0.8614789045928046
reward_mean: 1729.4801791772782
reward_std: 340.7070308888558
reward_max: 2200.0870454666074
reward_min: 1219.5417414130113
total_envstep_count: 8333779
total_train_sample_count: 6296512
total_episode_count: 22324
total_duration: 1848.366152357909
[2023-06-29 11:29:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2931
train_sample_count: 2931
avg_envstep_per_episode: 244.25
avg_sample_per_episode: 244.25
avg_envstep_per_sec: 2702.215345111342
avg_train_sample_per_sec: 2702.215345111342
avg_episode_per_sec: 11.063317687252166
collect_time: 1.084665589403361
reward_mean: 1708.0063066147889
reward_std: 877.1167745158718
reward_max: 3454.703889604924
reward_min: 325.0822710911689
total_envstep_count: 8338371
total_train_sample_count: 6299843
total_episode_count: 22336
total_duration: 1849.4508179473123
[2023-06-29 11:29:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2091
train_sample_count: 2091
avg_envstep_per_episode: 298.7142857142857
avg_sample_per_episode: 298.7142857142857
avg_envstep_per_sec: 2372.0637645820934
avg_train_sample_per_sec: 2372.0637645820934
avg_episode_per_sec: 7.940911693962054
collect_time: 0.881510873030173
reward_mean: 1876.2498573850476
reward_std: 369.59734039199094
reward_max: 2441.5113130558234
reward_min: 1347.5644012874518
total_envstep_count: 8343059
total_train_sample_count: 6303134
total_episode_count: 22343
total_duration: 1850.3323288203426
[2023-06-29 11:29:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 306.25
avg_sample_per_episode: 306.25
avg_envstep_per_sec: 2557.3175509507164
avg_train_sample_per_sec: 2557.3175509507164
avg_episode_per_sec: 8.350424656165604
collect_time: 0.9580351095190273
reward_mean: 2286.435012122818
reward_std: 802.816273275635
reward_max: 3629.792881574982
reward_min: 1209.9530224875748
total_envstep_count: 8347595
total_train_sample_count: 6306384
total_episode_count: 22351
total_duration: 1851.2903639298615
[2023-06-29 11:30:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2582
train_sample_count: 2582
avg_envstep_per_episode: 322.75
avg_sample_per_episode: 322.75
avg_envstep_per_sec: 2534.2232193320556
avg_train_sample_per_sec: 2534.2232193320556
avg_episode_per_sec: 7.851969695839057
collect_time: 1.0188526331475003
reward_mean: 2124.4007406255387
reward_std: 771.2595974151188
reward_max: 3552.5956368073935
reward_min: 986.9248306346553
total_envstep_count: 8353059
total_train_sample_count: 6310166
total_episode_count: 22359
total_duration: 1852.309216563009
[2023-06-29 11:30:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2583
train_sample_count: 2583
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2735.4890362691517
avg_train_sample_per_sec: 2735.4890362691517
avg_episode_per_sec: 9.53132068386464
collect_time: 0.9442552924733609
reward_mean: 2018.129662471102
reward_std: 678.555804608228
reward_max: 3499.4795594925413
reward_min: 1294.6415066093507
total_envstep_count: 8357355
total_train_sample_count: 6313549
total_episode_count: 22368
total_duration: 1853.2534718554823
[2023-06-29 11:30:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 605
train_sample_count: 605
avg_envstep_per_episode: 151.25
avg_sample_per_episode: 151.25
avg_envstep_per_sec: 2653.4531154962883
avg_train_sample_per_sec: 2653.4531154962883
avg_episode_per_sec: 17.543491672702732
collect_time: 0.22800478232186286
reward_mean: 1974.3091545579994
reward_std: 925.2979353783738
reward_max: 3540.2604078236363
reward_min: 1240.6622298064121
total_envstep_count: 8361811
total_train_sample_count: 6316954
total_episode_count: 22372
total_duration: 1853.4814766378042
[2023-06-29 11:30:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 325.22222222222223
avg_sample_per_episode: 325.22222222222223
avg_envstep_per_sec: 2678.39738874928
avg_train_sample_per_sec: 2678.39738874928
avg_episode_per_sec: 8.235591560896315
collect_time: 1.0928176723495124
reward_mean: 2821.6179393802367
reward_std: 939.6518226369354
reward_max: 3526.9895252938713
reward_min: 1227.9970560188497
total_envstep_count: 8366307
total_train_sample_count: 6320281
total_episode_count: 22381
total_duration: 1854.5742943101538
[2023-06-29 11:30:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3091
train_sample_count: 3091
avg_envstep_per_episode: 386.375
avg_sample_per_episode: 386.375
avg_envstep_per_sec: 2590.179282198069
avg_train_sample_per_sec: 2590.179282198069
avg_episode_per_sec: 6.703796265798949
collect_time: 1.1933536883890625
reward_mean: 2090.3668065205848
reward_std: 721.6450181965816
reward_max: 3239.1183060606854
reward_min: 1283.3044958513706
total_envstep_count: 8371355
total_train_sample_count: 6323772
total_episode_count: 22389
total_duration: 1855.767647998543
[2023-06-29 11:30:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 290.90909090909093
avg_sample_per_episode: 290.90909090909093
avg_envstep_per_sec: 2637.7602482633065
avg_train_sample_per_sec: 2637.7602482633065
avg_episode_per_sec: 9.067300853405115
collect_time: 1.2131504378030076
reward_mean: 1656.9891547213106
reward_std: 409.4359060198405
reward_max: 2461.25995475716
reward_min: 1253.38622248826
total_envstep_count: 8375939
total_train_sample_count: 6326972
total_episode_count: 22400
total_duration: 1856.980798436346
[2023-06-29 11:30:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2403
train_sample_count: 2403
avg_envstep_per_episode: 343.2857142857143
avg_sample_per_episode: 343.2857142857143
avg_envstep_per_sec: 2422.3577521666653
avg_train_sample_per_sec: 2422.3577521666653
avg_episode_per_sec: 7.056389623456786
collect_time: 0.9920087145883589
reward_mean: 1560.452970498219
reward_std: 440.8654904999547
reward_max: 2538.5191746096584
reward_min: 1025.127208235713
total_envstep_count: 8379691
total_train_sample_count: 6330175
total_episode_count: 22407
total_duration: 1857.9728071509344
[2023-06-29 11:30:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 266.0
avg_sample_per_episode: 266.0
avg_envstep_per_sec: 2714.8960347985544
avg_train_sample_per_sec: 2714.8960347985544
avg_episode_per_sec: 10.206376070671258
collect_time: 0.7838237533681093
reward_mean: 1830.2770124115264
reward_std: 1000.4427012987463
reward_max: 3513.3169318799164
reward_min: 627.1177875628362
total_envstep_count: 8384491
total_train_sample_count: 6333503
total_episode_count: 22415
total_duration: 1858.7566309043025
[2023-06-29 11:30:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2110
train_sample_count: 2110
avg_envstep_per_episode: 301.42857142857144
avg_sample_per_episode: 301.42857142857144
avg_envstep_per_sec: 2577.7864113439628
avg_train_sample_per_sec: 2577.7864113439628
avg_episode_per_sec: 8.551898047112674
collect_time: 0.8185317413089798
reward_mean: 2116.987114324119
reward_std: 810.7541164801152
reward_max: 3465.0778505291973
reward_min: 1422.265556145434
total_envstep_count: 8388915
total_train_sample_count: 6336813
total_episode_count: 22422
total_duration: 1859.5751626456115
[2023-06-29 11:30:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2461
train_sample_count: 2461
avg_envstep_per_episode: 246.1
avg_sample_per_episode: 246.1
avg_envstep_per_sec: 2567.980523367369
avg_train_sample_per_sec: 2567.980523367369
avg_episode_per_sec: 10.434703467563466
collect_time: 0.9583406017320231
reward_mean: 1894.0844929455584
reward_std: 1114.8134415508162
reward_max: 3508.0317374088568
reward_min: 267.89260135194354
total_envstep_count: 8393451
total_train_sample_count: 6340074
total_episode_count: 22432
total_duration: 1860.5335032473436
[2023-06-29 11:30:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 348.0
avg_sample_per_episode: 348.0
avg_envstep_per_sec: 2468.5786051925543
avg_train_sample_per_sec: 2468.5786051925543
avg_episode_per_sec: 7.0936166815877995
collect_time: 0.9868026867266748
reward_mean: 2120.4336172571193
reward_std: 892.6114924195904
reward_max: 3490.054893173894
reward_min: 1260.6962643762943
total_envstep_count: 8397619
total_train_sample_count: 6343310
total_episode_count: 22439
total_duration: 1861.5203059340702
[2023-06-29 11:30:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3441
train_sample_count: 3441
avg_envstep_per_episode: 312.8181818181818
avg_sample_per_episode: 312.8181818181818
avg_envstep_per_sec: 2567.478935328146
avg_train_sample_per_sec: 2567.478935328146
avg_episode_per_sec: 8.207575788610754
collect_time: 1.3402252118419857
reward_mean: 1817.379671258843
reward_std: 729.0180255173675
reward_max: 3496.2152048339135
reward_min: 1184.7472530198652
total_envstep_count: 8402147
total_train_sample_count: 6346751
total_episode_count: 22450
total_duration: 1862.860531145912
[2023-06-29 11:30:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2316
train_sample_count: 2316
avg_envstep_per_episode: 289.5
avg_sample_per_episode: 289.5
avg_envstep_per_sec: 2764.0394152924955
avg_train_sample_per_sec: 2764.0394152924955
avg_episode_per_sec: 9.547631831753007
collect_time: 0.8379041149653493
reward_mean: 1498.847320473143
reward_std: 283.8708839653266
reward_max: 1893.7736760469897
reward_min: 953.5202394364194
total_envstep_count: 8406771
total_train_sample_count: 6350267
total_episode_count: 22458
total_duration: 1863.6984352608774
[2023-06-29 11:30:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 333.0
avg_sample_per_episode: 333.0
avg_envstep_per_sec: 2611.2271061359365
avg_train_sample_per_sec: 2611.2271061359365
avg_episode_per_sec: 7.841522841249058
collect_time: 0.5101049988605082
reward_mean: 2276.478811899397
reward_std: 808.8238053227839
reward_max: 3510.786539639322
reward_min: 1531.3100533613394
total_envstep_count: 8411043
total_train_sample_count: 6353599
total_episode_count: 22462
total_duration: 1864.208540259738
[2023-06-29 11:30:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2142
train_sample_count: 2142
avg_envstep_per_episode: 178.5
avg_sample_per_episode: 178.5
avg_envstep_per_sec: 2463.9121434217373
avg_train_sample_per_sec: 2463.9121434217373
avg_episode_per_sec: 13.803429374911694
collect_time: 0.8693491794010624
reward_mean: 1810.8988615524793
reward_std: 923.1484040323818
reward_max: 3487.7796802206053
reward_min: 290.6137350007896
total_envstep_count: 8415211
total_train_sample_count: 6356941
total_episode_count: 22474
total_duration: 1865.077889439139
[2023-06-29 11:30:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2413
train_sample_count: 2413
avg_envstep_per_episode: 344.7142857142857
avg_sample_per_episode: 344.7142857142857
avg_envstep_per_sec: 2684.9686054546487
avg_train_sample_per_sec: 2684.9686054546487
avg_episode_per_sec: 7.7889681882231825
collect_time: 0.8987069700174033
reward_mean: 2164.781270313681
reward_std: 1010.3044402270464
reward_max: 3475.7238609214833
reward_min: 1165.3346185166865
total_envstep_count: 8419795
total_train_sample_count: 6360154
total_episode_count: 22481
total_duration: 1865.9765964091564
[2023-06-29 11:30:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 2681.9602706160795
avg_train_sample_per_sec: 2681.9602706160795
avg_episode_per_sec: 9.248138864193377
collect_time: 0.7569090497875586
reward_mean: 2008.1162220779534
reward_std: 1001.5586168349996
reward_max: 3510.1738965361033
reward_min: 293.05480400008497
total_envstep_count: 8423963
total_train_sample_count: 6363384
total_episode_count: 22488
total_duration: 1866.733505458944
[2023-06-29 11:30:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 942
train_sample_count: 942
avg_envstep_per_episode: 188.4
avg_sample_per_episode: 188.4
avg_envstep_per_sec: 2600.9704152232734
avg_train_sample_per_sec: 2600.9704152232734
avg_episode_per_sec: 13.805575452352832
collect_time: 0.36217251626029606
reward_mean: 2265.679434607732
reward_std: 737.6349625087186
reward_max: 3489.8110810784037
reward_min: 1315.4434310746594
total_envstep_count: 8428403
total_train_sample_count: 6366726
total_episode_count: 22493
total_duration: 1867.0956779752041
[2023-06-29 11:30:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2836
train_sample_count: 2836
avg_envstep_per_episode: 283.6
avg_sample_per_episode: 283.6
avg_envstep_per_sec: 2547.288906721774
avg_train_sample_per_sec: 2547.288906721774
avg_episode_per_sec: 8.98197780931514
collect_time: 1.113340537273325
reward_mean: 2323.8478146762914
reward_std: 805.006153107865
reward_max: 3282.1286141667883
reward_min: 1145.1510430953774
total_envstep_count: 8432755
total_train_sample_count: 6369962
total_episode_count: 22503
total_duration: 1868.2090185124775
[2023-06-29 11:31:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2347
train_sample_count: 2347
avg_envstep_per_episode: 293.375
avg_sample_per_episode: 293.375
avg_envstep_per_sec: 2768.638514007185
avg_train_sample_per_sec: 2768.638514007185
avg_episode_per_sec: 9.437199877314649
collect_time: 0.8477090772688388
reward_mean: 1832.5083283153558
reward_std: 797.6747835322709
reward_max: 3487.283068981831
reward_min: 840.8317496980867
total_envstep_count: 8437339
total_train_sample_count: 6373509
total_episode_count: 22511
total_duration: 1869.0567275897463
[2023-06-29 11:31:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1784
train_sample_count: 1784
avg_envstep_per_episode: 297.3333333333333
avg_sample_per_episode: 297.3333333333333
avg_envstep_per_sec: 2651.375465871196
avg_train_sample_per_sec: 2651.375465871196
avg_episode_per_sec: 8.917182060104919
collect_time: 0.6728583042891696
reward_mean: 2010.2641366815158
reward_std: 514.481305873462
reward_max: 2695.8355696031044
reward_min: 1440.3288870264594
total_envstep_count: 8442051
total_train_sample_count: 6376893
total_episode_count: 22517
total_duration: 1869.7295858940354
[2023-06-29 11:31:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 2597.357677998747
avg_train_sample_per_sec: 2597.357677998747
avg_episode_per_sec: 11.806171263630668
collect_time: 0.9317161130709575
reward_mean: 1973.7952570555972
reward_std: 849.8783610380816
reward_max: 3517.2152953527484
reward_min: 1131.4468140409879
total_envstep_count: 8446443
total_train_sample_count: 6380113
total_episode_count: 22528
total_duration: 1870.6613020071063
[2023-06-29 11:31:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3378
train_sample_count: 3378
avg_envstep_per_episode: 337.8
avg_sample_per_episode: 337.8
avg_envstep_per_sec: 2604.564509806947
avg_train_sample_per_sec: 2604.564509806947
avg_episode_per_sec: 7.710374510973793
collect_time: 1.2969538620682428
reward_mean: 1919.1555374179632
reward_std: 927.6985248276717
reward_max: 3517.501272124127
reward_min: 281.10598489214243
total_envstep_count: 8451155
total_train_sample_count: 6383891
total_episode_count: 22538
total_duration: 1871.9582558691745
[2023-06-29 11:31:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2742.386103983774
avg_train_sample_per_sec: 2742.386103983774
avg_episode_per_sec: 11.332173983404024
collect_time: 0.5294659267310053
reward_mean: 1392.4901558563597
reward_std: 268.46514716035216
reward_max: 1853.5250962028215
reward_min: 1121.1457965770126
total_envstep_count: 8455291
total_train_sample_count: 6387343
total_episode_count: 22544
total_duration: 1872.4877217959056
[2023-06-29 11:31:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1637
train_sample_count: 1637
avg_envstep_per_episode: 204.625
avg_sample_per_episode: 204.625
avg_envstep_per_sec: 2755.160924782738
avg_train_sample_per_sec: 2755.160924782738
avg_episode_per_sec: 13.46443946136952
collect_time: 0.594157671617344
reward_mean: 2103.7209875286567
reward_std: 942.5031391695222
reward_max: 3542.2023626133887
reward_min: 1004.2006603611372
total_envstep_count: 8459659
total_train_sample_count: 6390580
total_episode_count: 22552
total_duration: 1873.0818794675229
[2023-06-29 11:31:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2215
train_sample_count: 2215
avg_envstep_per_episode: 221.5
avg_sample_per_episode: 221.5
avg_envstep_per_sec: 2643.5434209012146
avg_train_sample_per_sec: 2643.5434209012146
avg_episode_per_sec: 11.934733277206385
collect_time: 0.8378905307501554
reward_mean: 1800.001735320047
reward_std: 426.1391125393804
reward_max: 2504.241731417678
reward_min: 1148.7660914187359
total_envstep_count: 8464139
total_train_sample_count: 6393995
total_episode_count: 22562
total_duration: 1873.919769998273
[2023-06-29 11:31:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2574
train_sample_count: 2574
avg_envstep_per_episode: 257.4
avg_sample_per_episode: 257.4
avg_envstep_per_sec: 2576.047113301507
avg_train_sample_per_sec: 2576.047113301507
avg_episode_per_sec: 10.007953043129397
collect_time: 0.999205327693373
reward_mean: 1723.5764631325274
reward_std: 527.1787092766565
reward_max: 2673.0766058985987
reward_min: 1153.7259490952724
total_envstep_count: 8468683
total_train_sample_count: 6397369
total_episode_count: 22572
total_duration: 1874.9189753259664
[2023-06-29 11:31:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1858
train_sample_count: 1858
avg_envstep_per_episode: 206.44444444444446
avg_sample_per_episode: 206.44444444444446
avg_envstep_per_sec: 2700.8715806722566
avg_train_sample_per_sec: 2700.8715806722566
avg_episode_per_sec: 13.082800982804256
collect_time: 0.6879260803423823
reward_mean: 1509.1307997577665
reward_std: 613.3752109833034
reward_max: 2454.1743342520945
reward_min: 264.5465875028033
total_envstep_count: 8473179
total_train_sample_count: 6400827
total_episode_count: 22581
total_duration: 1875.6069014063087
[2023-06-29 11:31:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2057
train_sample_count: 2057
avg_envstep_per_episode: 205.7
avg_sample_per_episode: 205.7
avg_envstep_per_sec: 2516.1063151580183
avg_train_sample_per_sec: 2516.1063151580183
avg_episode_per_sec: 12.231921804365669
collect_time: 0.8175330221969634
reward_mean: 1684.3030345014747
reward_std: 555.3053014405045
reward_max: 3103.8805946138746
reward_min: 1090.5185720667662
total_envstep_count: 8477499
total_train_sample_count: 6404084
total_episode_count: 22591
total_duration: 1876.4244344285057
[2023-06-29 11:31:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 225.4
avg_sample_per_episode: 225.4
avg_envstep_per_sec: 2730.256654851468
avg_train_sample_per_sec: 2730.256654851468
avg_episode_per_sec: 12.112939906173326
collect_time: 0.41278170607052744
reward_mean: 2259.1463052927043
reward_std: 638.5365986708704
reward_max: 3289.625551245684
reward_min: 1576.8682466259222
total_envstep_count: 8482163
total_train_sample_count: 6407611
total_episode_count: 22596
total_duration: 1876.8372161345762
[2023-06-29 11:31:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 272.44444444444446
avg_sample_per_episode: 272.44444444444446
avg_envstep_per_sec: 2501.765169179019
avg_train_sample_per_sec: 2501.765169179019
avg_episode_per_sec: 9.182661713952353
collect_time: 0.9801079774424433
reward_mean: 2519.886050568221
reward_std: 665.137087060594
reward_max: 3472.6623157065956
reward_min: 1693.4501771846562
total_envstep_count: 8486355
total_train_sample_count: 6410863
total_episode_count: 22605
total_duration: 1877.8173241120187
[2023-06-29 11:31:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2368
train_sample_count: 2368
avg_envstep_per_episode: 296.0
avg_sample_per_episode: 296.0
avg_envstep_per_sec: 2516.5374165358385
avg_train_sample_per_sec: 2516.5374165358385
avg_episode_per_sec: 8.50181559640486
collect_time: 0.940975478623994
reward_mean: 1767.9598018973325
reward_std: 452.813988262802
reward_max: 2583.7982347748075
reward_min: 1346.1399653968947
total_envstep_count: 8491395
total_train_sample_count: 6414431
total_episode_count: 22613
total_duration: 1878.7582995906428
[2023-06-29 11:31:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 244.14285714285714
avg_sample_per_episode: 244.14285714285714
avg_envstep_per_sec: 2738.9283777582928
avg_train_sample_per_sec: 2738.9283777582928
avg_episode_per_sec: 11.218548065715652
collect_time: 0.6239666629759595
reward_mean: 2001.4564283761072
reward_std: 699.6044890113646
reward_max: 2831.971164705006
reward_min: 916.9616500429298
total_envstep_count: 8495923
total_train_sample_count: 6417740
total_episode_count: 22620
total_duration: 1879.3822662536188
[2023-06-29 11:31:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1624
train_sample_count: 1624
avg_envstep_per_episode: 270.6666666666667
avg_sample_per_episode: 270.6666666666667
avg_envstep_per_sec: 2732.55539896546
avg_train_sample_per_sec: 2732.55539896546
avg_episode_per_sec: 10.095648025734457
collect_time: 0.5943154896749187
reward_mean: 2738.2311811457034
reward_std: 851.9668226195915
reward_max: 3524.0930563891297
reward_min: 1586.3094712253971
total_envstep_count: 8499731
total_train_sample_count: 6420964
total_episode_count: 22626
total_duration: 1879.9765817432938
[2023-06-29 11:31:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 303.25
avg_sample_per_episode: 303.25
avg_envstep_per_sec: 2300.7880969228054
avg_train_sample_per_sec: 2300.7880969228054
avg_episode_per_sec: 7.587100072292845
collect_time: 0.5272106551760807
reward_mean: 3116.6514504544157
reward_std: 550.7980883021532
reward_max: 3528.5628270109833
reward_min: 2183.988561701167
total_envstep_count: 8503915
total_train_sample_count: 6424177
total_episode_count: 22630
total_duration: 1880.5037923984698
[2023-06-29 11:31:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1603
train_sample_count: 1603
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 2489.589105569844
avg_train_sample_per_sec: 2489.589105569844
avg_episode_per_sec: 10.871568146593203
collect_time: 0.6438813523137941
reward_mean: 2353.9893512325702
reward_std: 750.307844975481
reward_max: 3459.661483978859
reward_min: 817.2685319859183
total_envstep_count: 8508963
total_train_sample_count: 6427380
total_episode_count: 22637
total_duration: 1881.1476737507837
[2023-06-29 11:31:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2054
train_sample_count: 2054
avg_envstep_per_episode: 256.75
avg_sample_per_episode: 256.75
avg_envstep_per_sec: 2696.3674235195795
avg_train_sample_per_sec: 2696.3674235195795
avg_episode_per_sec: 10.501917910494955
collect_time: 0.7617656192118303
reward_mean: 2402.3580702945546
reward_std: 915.0007716593157
reward_max: 3506.400322386962
reward_min: 1324.1914017229944
total_envstep_count: 8513571
total_train_sample_count: 6430634
total_episode_count: 22645
total_duration: 1881.9094393699957
[2023-06-29 11:31:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1724
train_sample_count: 1724
avg_envstep_per_episode: 246.28571428571428
avg_sample_per_episode: 246.28571428571428
avg_envstep_per_sec: 2747.431143368789
avg_train_sample_per_sec: 2747.431143368789
avg_episode_per_sec: 11.155462879107612
collect_time: 0.6274952528513966
reward_mean: 1994.9717495957923
reward_std: 678.7618343911605
reward_max: 3480.080623180119
reward_min: 1317.7371253318647
total_envstep_count: 8517875
total_train_sample_count: 6433958
total_episode_count: 22652
total_duration: 1882.536934622847
[2023-06-29 11:31:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2502
train_sample_count: 2502
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2560.466477486234
avg_train_sample_per_sec: 2560.466477486234
avg_episode_per_sec: 9.210311070094367
collect_time: 0.9771656930483879
reward_mean: 2347.6216597212297
reward_std: 765.4362599350916
reward_max: 3658.8910288068405
reward_min: 1376.574100569266
total_envstep_count: 8522579
total_train_sample_count: 6437260
total_episode_count: 22661
total_duration: 1883.5141003158953
[2023-06-29 11:32:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1590
train_sample_count: 1590
avg_envstep_per_episode: 227.14285714285714
avg_sample_per_episode: 227.14285714285714
avg_envstep_per_sec: 2592.2305636864453
avg_train_sample_per_sec: 2592.2305636864453
avg_episode_per_sec: 11.412335814971772
collect_time: 0.6133713652919978
reward_mean: 1909.1083614382128
reward_std: 601.6367019803412
reward_max: 3190.22748776827
reward_min: 1316.7803216648588
total_envstep_count: 8527195
total_train_sample_count: 6440850
total_episode_count: 22668
total_duration: 1884.1274716811874
[2023-06-29 11:32:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2913
train_sample_count: 2913
avg_envstep_per_episode: 323.6666666666667
avg_sample_per_episode: 323.6666666666667
avg_envstep_per_sec: 2569.5585587972337
avg_train_sample_per_sec: 2569.5585587972337
avg_episode_per_sec: 7.938903889177859
collect_time: 1.1336577600175515
reward_mean: 2358.295430985699
reward_std: 826.961187389286
reward_max: 3504.598948418662
reward_min: 1329.9048245229449
total_envstep_count: 8531835
total_train_sample_count: 6444163
total_episode_count: 22677
total_duration: 1885.261129441205
[2023-06-29 11:32:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1641
train_sample_count: 1641
avg_envstep_per_episode: 273.5
avg_sample_per_episode: 273.5
avg_envstep_per_sec: 2778.8096821069294
avg_train_sample_per_sec: 2778.8096821069294
avg_episode_per_sec: 10.16018165304179
collect_time: 0.5905406226869674
reward_mean: 1773.0123357210025
reward_std: 253.78487699774365
reward_max: 2053.4086737646307
reward_min: 1306.7771645447501
total_envstep_count: 8536411
total_train_sample_count: 6447404
total_episode_count: 22683
total_duration: 1885.851670063892
[2023-06-29 11:32:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 286.14285714285717
avg_sample_per_episode: 286.14285714285717
avg_envstep_per_sec: 2728.7121948042122
avg_train_sample_per_sec: 2728.7121948042122
avg_episode_per_sec: 9.536188399215918
collect_time: 0.7340459004119038
reward_mean: 2620.5436752725363
reward_std: 964.8294764559985
reward_max: 3524.674562822056
reward_min: 1340.1312463072436
total_envstep_count: 8541027
total_train_sample_count: 6450607
total_episode_count: 22690
total_duration: 1886.585715964304
[2023-06-29 11:32:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1310
train_sample_count: 1310
avg_envstep_per_episode: 163.75
avg_sample_per_episode: 163.75
avg_envstep_per_sec: 2346.364169625016
avg_train_sample_per_sec: 2346.364169625016
avg_episode_per_sec: 14.328941493893227
collect_time: 0.558310605386272
reward_mean: 1624.0272068009458
reward_std: 524.7632251615393
reward_max: 2947.7336757603243
reward_min: 1199.7044733671164
total_envstep_count: 8544963
total_train_sample_count: 6453917
total_episode_count: 22698
total_duration: 1887.1440265696901
[2023-06-29 11:32:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2598
train_sample_count: 2598
avg_envstep_per_episode: 216.5
avg_sample_per_episode: 216.5
avg_envstep_per_sec: 2525.6142935385374
avg_train_sample_per_sec: 2525.6142935385374
avg_episode_per_sec: 11.665654935512874
collect_time: 1.0286606338294222
reward_mean: 1668.1242411960045
reward_std: 567.6165642988843
reward_max: 3311.793935632792
reward_min: 927.9361005154143
total_envstep_count: 8549779
total_train_sample_count: 6457315
total_episode_count: 22710
total_duration: 1888.1726872035197
[2023-06-29 11:32:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2844
train_sample_count: 2844
avg_envstep_per_episode: 316.0
avg_sample_per_episode: 316.0
avg_envstep_per_sec: 2557.8648635083287
avg_train_sample_per_sec: 2557.8648635083287
avg_episode_per_sec: 8.094509061735216
collect_time: 1.1118648371826856
reward_mean: 2014.6584385516576
reward_std: 358.7555553599615
reward_max: 2511.7586330545296
reward_min: 1560.5813733747725
total_envstep_count: 8554411
total_train_sample_count: 6460959
total_episode_count: 22719
total_duration: 1889.2845520407025
[2023-06-29 11:32:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 300.0
avg_sample_per_episode: 300.0
avg_envstep_per_sec: 2777.0322761851958
avg_train_sample_per_sec: 2777.0322761851958
avg_episode_per_sec: 9.256774253950653
collect_time: 0.8642319430643692
reward_mean: 1814.599339144273
reward_std: 505.7529410084766
reward_max: 2511.7993184132642
reward_min: 1044.9964765620214
total_envstep_count: 8558923
total_train_sample_count: 6464159
total_episode_count: 22727
total_duration: 1890.1487839837669
[2023-06-29 11:32:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2929
train_sample_count: 2929
avg_envstep_per_episode: 292.9
avg_sample_per_episode: 292.9
avg_envstep_per_sec: 2687.45545104919
avg_train_sample_per_sec: 2687.45545104919
avg_episode_per_sec: 9.175334418058005
collect_time: 1.0898785313284023
reward_mean: 1831.4695826534382
reward_std: 716.7671221907975
reward_max: 3415.8226408910896
reward_min: 989.5848068951493
total_envstep_count: 8563563
total_train_sample_count: 6467488
total_episode_count: 22737
total_duration: 1891.2386625150953
[2023-06-29 11:32:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2925
train_sample_count: 2925
avg_envstep_per_episode: 265.90909090909093
avg_sample_per_episode: 265.90909090909093
avg_envstep_per_sec: 2560.831180378541
avg_train_sample_per_sec: 2560.831180378541
avg_episode_per_sec: 9.630476233902204
collect_time: 1.1422072733305395
reward_mean: 1503.9666081993962
reward_std: 260.0791680909564
reward_max: 2166.8122994194728
reward_min: 1251.26764938189
total_envstep_count: 8567971
total_train_sample_count: 6470813
total_episode_count: 22748
total_duration: 1892.3808697884258
[2023-06-29 11:32:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2385
train_sample_count: 2385
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 2718.5528377180826
avg_train_sample_per_sec: 2718.5528377180826
avg_episode_per_sec: 10.258689953653143
collect_time: 0.877305000995286
reward_mean: 1501.5695457895797
reward_std: 354.8096039045302
reward_max: 2221.7945065359568
reward_min: 948.0736599670759
total_envstep_count: 8573011
total_train_sample_count: 6474398
total_episode_count: 22757
total_duration: 1893.258174789421
[2023-06-29 11:32:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2956
train_sample_count: 2956
avg_envstep_per_episode: 295.6
avg_sample_per_episode: 295.6
avg_envstep_per_sec: 2715.7988397555646
avg_train_sample_per_sec: 2715.7988397555646
avg_episode_per_sec: 9.187411501202858
collect_time: 1.088445858628489
reward_mean: 2009.652470223312
reward_std: 613.593591672778
reward_max: 3344.045049925662
reward_min: 1321.33198948573
total_envstep_count: 8577627
total_train_sample_count: 6477754
total_episode_count: 22767
total_duration: 1894.3466206480496
[2023-06-29 11:32:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2750.895403722491
avg_train_sample_per_sec: 2750.895403722491
avg_episode_per_sec: 9.686251421558067
collect_time: 0.929152012301609
reward_mean: 1641.9138992464273
reward_std: 667.0553062715636
reward_max: 3463.152396255616
reward_min: 1257.2890855378662
total_envstep_count: 8582379
total_train_sample_count: 6481110
total_episode_count: 22776
total_duration: 1895.275772660351
[2023-06-29 11:32:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2122
train_sample_count: 2122
avg_envstep_per_episode: 235.77777777777777
avg_sample_per_episode: 235.77777777777777
avg_envstep_per_sec: 2511.197160976511
avg_train_sample_per_sec: 2511.197160976511
avg_episode_per_sec: 10.65069483920292
collect_time: 0.8450152911031619
reward_mean: 1712.2569829796435
reward_std: 408.02946036358105
reward_max: 2723.4120734510657
reward_min: 1264.6171242594912
total_envstep_count: 8587371
total_train_sample_count: 6484432
total_episode_count: 22785
total_duration: 1896.1207879514543
[2023-06-29 11:32:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 244.33333333333334
avg_sample_per_episode: 244.33333333333334
avg_envstep_per_sec: 2530.358785546448
avg_train_sample_per_sec: 2530.358785546448
avg_episode_per_sec: 10.356175111377004
collect_time: 0.869046718813479
reward_mean: 1915.452767921313
reward_std: 654.9977589182536
reward_max: 3460.565666117786
reward_min: 1303.7469742651294
total_envstep_count: 8591891
total_train_sample_count: 6487831
total_episode_count: 22794
total_duration: 1896.9898346702678
[2023-06-29 11:32:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2425
train_sample_count: 2425
avg_envstep_per_episode: 303.125
avg_sample_per_episode: 303.125
avg_envstep_per_sec: 2742.4255426173063
avg_train_sample_per_sec: 2742.4255426173063
avg_episode_per_sec: 9.04717704780967
collect_time: 0.8842537244185806
reward_mean: 2206.7800277341516
reward_std: 575.1157154663036
reward_max: 3487.3996022240112
reward_min: 1407.93837319616
total_envstep_count: 8596915
total_train_sample_count: 6491456
total_episode_count: 22802
total_duration: 1897.8740883946864
[2023-06-29 11:32:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 278.1111111111111
avg_sample_per_episode: 278.1111111111111
avg_envstep_per_sec: 2515.0246492774945
avg_train_sample_per_sec: 2515.0246492774945
avg_episode_per_sec: 9.04323685317517
collect_time: 0.9952188741844145
reward_mean: 2058.2089225949308
reward_std: 829.7765139441556
reward_max: 3615.667475074562
reward_min: 1379.0823757975295
total_envstep_count: 8601427
total_train_sample_count: 6494759
total_episode_count: 22811
total_duration: 1898.869307268871
[2023-06-29 11:32:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2262
train_sample_count: 2262
avg_envstep_per_episode: 226.2
avg_sample_per_episode: 226.2
avg_envstep_per_sec: 2702.8366782239523
avg_train_sample_per_sec: 2702.8366782239523
avg_episode_per_sec: 11.948880098249125
collect_time: 0.8368985141515735
reward_mean: 1504.885521357789
reward_std: 318.5848725424421
reward_max: 2019.872770774312
reward_min: 941.7097081080653
total_envstep_count: 8606211
total_train_sample_count: 6498221
total_episode_count: 22821
total_duration: 1899.7062057830224
[2023-06-29 11:32:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3452
train_sample_count: 3452
avg_envstep_per_episode: 287.6666666666667
avg_sample_per_episode: 287.6666666666667
avg_envstep_per_sec: 2629.032145805993
avg_train_sample_per_sec: 2629.032145805993
avg_episode_per_sec: 9.139161572906117
collect_time: 1.3130307309124616
reward_mean: 1771.0232801883237
reward_std: 534.3565058315501
reward_max: 2881.303960475104
reward_min: 1127.9084697095348
total_envstep_count: 8610947
total_train_sample_count: 6501673
total_episode_count: 22833
total_duration: 1901.0192365139349
[2023-06-29 11:33:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2088
train_sample_count: 2088
avg_envstep_per_episode: 298.2857142857143
avg_sample_per_episode: 298.2857142857143
avg_envstep_per_sec: 2707.6854543314366
avg_train_sample_per_sec: 2707.6854543314366
avg_episode_per_sec: 9.077489549961713
collect_time: 0.7711383154420183
reward_mean: 1705.5208401270284
reward_std: 506.8530021779683
reward_max: 2906.08973064992
reward_min: 1284.2176856868734
total_envstep_count: 8615123
total_train_sample_count: 6504961
total_episode_count: 22840
total_duration: 1901.7903748293768
[2023-06-29 11:33:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2095
train_sample_count: 2095
avg_envstep_per_episode: 232.77777777777777
avg_sample_per_episode: 232.77777777777777
avg_envstep_per_sec: 2805.2414240015887
avg_train_sample_per_sec: 2805.2414240015887
avg_episode_per_sec: 12.051156475424486
collect_time: 0.7468162925569338
reward_mean: 1601.5170660740832
reward_std: 730.4108305380604
reward_max: 2724.9597221011863
reward_min: 38.02396245424497
total_envstep_count: 8618987
total_train_sample_count: 6508256
total_episode_count: 22849
total_duration: 1902.5371911219338
[2023-06-29 11:33:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2112
train_sample_count: 2112
avg_envstep_per_episode: 301.7142857142857
avg_sample_per_episode: 301.7142857142857
avg_envstep_per_sec: 2693.835814916362
avg_train_sample_per_sec: 2693.835814916362
avg_episode_per_sec: 8.928433098681124
collect_time: 0.7840121466591955
reward_mean: 2016.4548132474504
reward_std: 978.7637040141814
reward_max: 3500.3040265165464
reward_min: 162.29350014740683
total_envstep_count: 8623339
total_train_sample_count: 6511568
total_episode_count: 22856
total_duration: 1903.321203268593
[2023-06-29 11:33:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1815
train_sample_count: 1815
avg_envstep_per_episode: 363.0
avg_sample_per_episode: 363.0
avg_envstep_per_sec: 2628.4517908177513
avg_train_sample_per_sec: 2628.4517908177513
avg_episode_per_sec: 7.240914024291326
collect_time: 0.6905205590380358
reward_mean: 2555.6327286297937
reward_std: 744.0079627963555
reward_max: 3461.490919028084
reward_min: 1666.68083477264
total_envstep_count: 8627987
total_train_sample_count: 6514983
total_episode_count: 22861
total_duration: 1904.0117238276312
[2023-06-29 11:33:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1675
train_sample_count: 1675
avg_envstep_per_episode: 335.0
avg_sample_per_episode: 335.0
avg_envstep_per_sec: 2778.5514604677633
avg_train_sample_per_sec: 2778.5514604677633
avg_episode_per_sec: 8.294183464082876
collect_time: 0.6028320957273245
reward_mean: 3260.2204392599656
reward_std: 498.5502960009013
reward_max: 3538.8569403679994
reward_min: 2263.9466760799783
total_envstep_count: 8632659
total_train_sample_count: 6518258
total_episode_count: 22866
total_duration: 1904.6145559233585
[2023-06-29 11:33:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2336
train_sample_count: 2336
avg_envstep_per_episode: 292.0
avg_sample_per_episode: 292.0
avg_envstep_per_sec: 2663.688601388129
avg_train_sample_per_sec: 2663.688601388129
avg_episode_per_sec: 9.122221237630578
collect_time: 0.8769793881997466
reward_mean: 2465.065566004495
reward_std: 1156.3038561356104
reward_max: 3535.754419524132
reward_min: 43.5352070072603
total_envstep_count: 8637587
total_train_sample_count: 6521794
total_episode_count: 22874
total_duration: 1905.4915353115582
[2023-06-29 11:33:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1593
train_sample_count: 1593
avg_envstep_per_episode: 265.5
avg_sample_per_episode: 265.5
avg_envstep_per_sec: 2783.6005537324772
avg_train_sample_per_sec: 2783.6005537324772
avg_episode_per_sec: 10.484371200498973
collect_time: 0.572280386229977
reward_mean: 2161.1961761990524
reward_std: 868.7848134767057
reward_max: 3086.6566461497537
reward_min: 522.6697818836308
total_envstep_count: 8642435
total_train_sample_count: 6525387
total_episode_count: 22880
total_duration: 1906.0638156977882
[2023-06-29 11:33:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2679
train_sample_count: 2679
avg_envstep_per_episode: 267.9
avg_sample_per_episode: 267.9
avg_envstep_per_sec: 2790.633349417646
avg_train_sample_per_sec: 2790.633349417646
avg_episode_per_sec: 10.416697832839292
collect_time: 0.9599971277341246
reward_mean: 2329.8890402887155
reward_std: 897.2904360960302
reward_max: 3681.9796464624355
reward_min: 1247.3059305410256
total_envstep_count: 8647187
total_train_sample_count: 6528866
total_episode_count: 22890
total_duration: 1907.0238128255223
[2023-06-29 11:33:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2918
train_sample_count: 2918
avg_envstep_per_episode: 364.75
avg_sample_per_episode: 364.75
avg_envstep_per_sec: 2608.2218757867454
avg_train_sample_per_sec: 2608.2218757867454
avg_episode_per_sec: 7.150711105652489
collect_time: 1.1187698512496422
reward_mean: 2210.33695142286
reward_std: 907.5682707297011
reward_max: 3548.8855007756956
reward_min: 944.9425138755146
total_envstep_count: 8651731
total_train_sample_count: 6532184
total_episode_count: 22898
total_duration: 1908.142582676772
[2023-06-29 11:33:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1336
train_sample_count: 1336
avg_envstep_per_episode: 445.3333333333333
avg_sample_per_episode: 445.3333333333333
avg_envstep_per_sec: 2871.7935645040475
avg_train_sample_per_sec: 2871.7935645040475
avg_episode_per_sec: 6.448638243646813
collect_time: 0.4652144974879921
reward_mean: 2748.7111126469026
reward_std: 778.3353421135718
reward_max: 3468.8650292371767
reward_min: 1667.7023895575219
total_envstep_count: 8656563
total_train_sample_count: 6535520
total_episode_count: 22901
total_duration: 1908.60779717426
[2023-06-29 11:33:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2768
train_sample_count: 2768
avg_envstep_per_episode: 251.63636363636363
avg_sample_per_episode: 251.63636363636363
avg_envstep_per_sec: 2695.331891411865
avg_train_sample_per_sec: 2695.331891411865
avg_episode_per_sec: 10.711217776564492
collect_time: 1.0269607274783774
reward_mean: 2230.161197334967
reward_std: 839.5571579404352
reward_max: 3527.8699647256544
reward_min: 1166.5447274319147
total_envstep_count: 8661475
total_train_sample_count: 6539088
total_episode_count: 22912
total_duration: 1909.6347579017383
[2023-06-29 11:33:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 230.4
avg_sample_per_episode: 230.4
avg_envstep_per_sec: 2763.0376878508423
avg_train_sample_per_sec: 2763.0376878508423
avg_episode_per_sec: 11.992351075741503
collect_time: 0.41693242371082295
reward_mean: 1643.8401286088756
reward_std: 1030.104235519854
reward_max: 3183.4826796127145
reward_min: 153.21896841496678
total_envstep_count: 8665971
total_train_sample_count: 6542640
total_episode_count: 22917
total_duration: 1910.0516903254493
[2023-06-29 11:33:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 250.875
avg_sample_per_episode: 250.875
avg_envstep_per_sec: 2525.7587709184227
avg_train_sample_per_sec: 2525.7587709184227
avg_episode_per_sec: 10.067797791403777
collect_time: 0.7946127013824879
reward_mean: 2582.147103975506
reward_std: 1030.1724025666679
reward_max: 3634.4835661140355
reward_min: 1242.0053121987303
total_envstep_count: 8669963
total_train_sample_count: 6545847
total_episode_count: 22925
total_duration: 1910.8463030268317
[2023-06-29 11:33:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 2339.256407436939
avg_train_sample_per_sec: 2339.256407436939
avg_episode_per_sec: 9.282763521575154
collect_time: 0.5386327022528277
reward_mean: 2307.66590222316
reward_std: 694.9966366834096
reward_max: 3483.896504612553
reward_min: 1561.0932072511655
total_envstep_count: 8673971
total_train_sample_count: 6549107
total_episode_count: 22930
total_duration: 1911.3849357290846
[2023-06-29 11:33:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1156
train_sample_count: 1156
avg_envstep_per_episode: 192.66666666666666
avg_sample_per_episode: 192.66666666666666
avg_envstep_per_sec: 2765.317191355201
avg_train_sample_per_sec: 2765.317191355201
avg_episode_per_sec: 14.352857394577168
collect_time: 0.4180352270668372
reward_mean: 2532.9613178887516
reward_std: 789.049165347877
reward_max: 3563.9440323842973
reward_min: 1322.8651953395072
total_envstep_count: 8678627
total_train_sample_count: 6552663
total_episode_count: 22936
total_duration: 1911.8029709561515
[2023-06-29 11:33:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1681
train_sample_count: 1681
avg_envstep_per_episode: 210.125
avg_sample_per_episode: 210.125
avg_envstep_per_sec: 2765.4221817398243
avg_train_sample_per_sec: 2765.4221817398243
avg_episode_per_sec: 13.160843220653536
collect_time: 0.6078637869833039
reward_mean: 2184.367285682968
reward_std: 958.2326745114391
reward_max: 3509.597126477998
reward_min: 115.8785408638538
total_envstep_count: 8682923
total_train_sample_count: 6555944
total_episode_count: 22944
total_duration: 1912.4108347431347
[2023-06-29 11:33:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2097
train_sample_count: 2097
avg_envstep_per_episode: 299.57142857142856
avg_sample_per_episode: 299.57142857142856
avg_envstep_per_sec: 2594.8184408249244
avg_train_sample_per_sec: 2594.8184408249244
avg_episode_per_sec: 8.66176875811849
collect_time: 0.8081490276958793
reward_mean: 2160.364042802176
reward_std: 809.8781721214513
reward_max: 3576.0755700332697
reward_min: 1016.4033022495944
total_envstep_count: 8687171
total_train_sample_count: 6559241
total_episode_count: 22951
total_duration: 1913.2189837708306
[2023-06-29 11:33:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1434
train_sample_count: 1434
avg_envstep_per_episode: 204.85714285714286
avg_sample_per_episode: 204.85714285714286
avg_envstep_per_sec: 2367.520313676372
avg_train_sample_per_sec: 2367.520313676372
avg_episode_per_sec: 11.556933190888847
collect_time: 0.6056970205139369
reward_mean: 2075.2006830788655
reward_std: 1006.1491216912808
reward_max: 3510.0272933796114
reward_min: 560.4202890797565
total_envstep_count: 8692003
total_train_sample_count: 6562675
total_episode_count: 22958
total_duration: 1913.8246807913445
[2023-06-29 11:33:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1652
train_sample_count: 1652
avg_envstep_per_episode: 206.5
avg_sample_per_episode: 206.5
avg_envstep_per_sec: 2740.684209768606
avg_train_sample_per_sec: 2740.684209768606
avg_episode_per_sec: 13.272078497668794
collect_time: 0.6027691895738244
reward_mean: 2334.715764401125
reward_std: 749.4388765996152
reward_max: 3591.496120266065
reward_min: 1364.1399266427009
total_envstep_count: 8696955
total_train_sample_count: 6565927
total_episode_count: 22966
total_duration: 1914.4274499809183
[2023-06-29 11:34:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3187
train_sample_count: 3187
avg_envstep_per_episode: 354.1111111111111
avg_sample_per_episode: 354.1111111111111
avg_envstep_per_sec: 2738.9693404342347
avg_train_sample_per_sec: 2738.9693404342347
avg_episode_per_sec: 7.734773788487014
collect_time: 1.1635763690201566
reward_mean: 2662.5386399602994
reward_std: 784.4835259823727
reward_max: 3605.7002499564214
reward_min: 1613.8377669041072
total_envstep_count: 8701779
total_train_sample_count: 6569514
total_episode_count: 22975
total_duration: 1915.5910263499384
[2023-06-29 11:34:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2699
train_sample_count: 2699
avg_envstep_per_episode: 337.375
avg_sample_per_episode: 337.375
avg_envstep_per_sec: 2727.2786447675135
avg_train_sample_per_sec: 2727.2786447675135
avg_episode_per_sec: 8.083819621393149
collect_time: 0.9896311860829592
reward_mean: 1801.3332533208325
reward_std: 320.48993555481417
reward_max: 2457.1592400473864
reward_min: 1321.1547321811338
total_envstep_count: 8706387
total_train_sample_count: 6573013
total_episode_count: 22983
total_duration: 1916.5806575360214
[2023-06-29 11:34:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3076
train_sample_count: 3076
avg_envstep_per_episode: 279.6363636363636
avg_sample_per_episode: 279.6363636363636
avg_envstep_per_sec: 2675.255263324997
avg_train_sample_per_sec: 2675.255263324997
avg_episode_per_sec: 9.566907638678469
collect_time: 1.1497968220710755
reward_mean: 1679.181721897389
reward_std: 562.1821111447126
reward_max: 3188.527679414893
reward_min: 1219.1296177091128
total_envstep_count: 8711067
total_train_sample_count: 6576489
total_episode_count: 22994
total_duration: 1917.7304543580924
[2023-06-29 11:34:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3139
train_sample_count: 3139
avg_envstep_per_episode: 313.9
avg_sample_per_episode: 313.9
avg_envstep_per_sec: 2555.88513925647
avg_train_sample_per_sec: 2555.88513925647
avg_episode_per_sec: 8.142354696580027
collect_time: 1.2281459568692368
reward_mean: 1681.7057600280314
reward_std: 539.5331647823285
reward_max: 2800.877546308849
reward_min: 1291.6826059234827
total_envstep_count: 8715843
total_train_sample_count: 6580028
total_episode_count: 23004
total_duration: 1918.9586003149616
[2023-06-29 11:34:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1962
train_sample_count: 1962
avg_envstep_per_episode: 245.25
avg_sample_per_episode: 245.25
avg_envstep_per_sec: 2605.252244670544
avg_train_sample_per_sec: 2605.252244670544
avg_episode_per_sec: 10.622842995598548
collect_time: 0.7530940637374296
reward_mean: 1581.581542670737
reward_std: 542.2313685222978
reward_max: 2229.5806120866578
reward_min: 389.9747953652444
total_envstep_count: 8720307
total_train_sample_count: 6583590
total_episode_count: 23012
total_duration: 1919.7116943786991
[2023-06-29 11:34:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1561
train_sample_count: 1561
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2635.4708017175135
avg_train_sample_per_sec: 2635.4708017175135
avg_episode_per_sec: 11.818254716222034
collect_time: 0.5923040388012304
reward_mean: 1842.324491094927
reward_std: 615.7961696026883
reward_max: 2992.971540389575
reward_min: 908.1316832993708
total_envstep_count: 8724803
total_train_sample_count: 6587151
total_episode_count: 23019
total_duration: 1920.3039984175005
[2023-06-29 11:34:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2001
train_sample_count: 2001
avg_envstep_per_episode: 285.85714285714283
avg_sample_per_episode: 285.85714285714283
avg_envstep_per_sec: 2748.9287415761282
avg_train_sample_per_sec: 2748.9287415761282
avg_episode_per_sec: 9.616442374329285
collect_time: 0.7279199237637222
reward_mean: 2662.297560824932
reward_std: 917.5514077329779
reward_max: 3519.252734759589
reward_min: 1129.4343392322137
total_envstep_count: 8728507
total_train_sample_count: 6590352
total_episode_count: 23026
total_duration: 1921.0319183412641
[2023-06-29 11:34:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2074
train_sample_count: 2074
avg_envstep_per_episode: 296.2857142857143
avg_sample_per_episode: 296.2857142857143
avg_envstep_per_sec: 2673.575853899138
avg_train_sample_per_sec: 2673.575853899138
avg_episode_per_sec: 9.023640779794585
collect_time: 0.7757400999022647
reward_mean: 1994.6474083711253
reward_std: 524.156133499888
reward_max: 2931.801749060613
reward_min: 1275.7362625234778
total_envstep_count: 8733355
total_train_sample_count: 6593626
total_episode_count: 23033
total_duration: 1921.8076584411665
[2023-06-29 11:34:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 223.11111111111111
avg_sample_per_episode: 223.11111111111111
avg_envstep_per_sec: 2765.819951811123
avg_train_sample_per_sec: 2765.819951811123
avg_episode_per_sec: 12.396603369671366
collect_time: 0.7260053202975542
reward_mean: 1785.3958392723046
reward_std: 404.67779523047284
reward_max: 2800.9459400081305
reward_min: 1423.7248671024126
total_envstep_count: 8737323
total_train_sample_count: 6596834
total_episode_count: 23042
total_duration: 1922.5336637614641
[2023-06-29 11:34:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2779
train_sample_count: 2779
avg_envstep_per_episode: 308.77777777777777
avg_sample_per_episode: 308.77777777777777
avg_envstep_per_sec: 2786.438046255004
avg_train_sample_per_sec: 2786.438046255004
avg_episode_per_sec: 9.024088670851038
collect_time: 0.9973306256476793
reward_mean: 2018.8362348783262
reward_std: 695.2793747584204
reward_max: 3477.8140196946565
reward_min: 1166.9952369170242
total_envstep_count: 8742019
total_train_sample_count: 6600413
total_episode_count: 23051
total_duration: 1923.5309943871118
[2023-06-29 11:34:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3123
train_sample_count: 3123
avg_envstep_per_episode: 312.3
avg_sample_per_episode: 312.3
avg_envstep_per_sec: 2733.7953826640532
avg_train_sample_per_sec: 2733.7953826640532
avg_episode_per_sec: 8.753747623003692
collect_time: 1.1423678669603543
reward_mean: 1812.1879584111132
reward_std: 679.852564364097
reward_max: 3293.839534567541
reward_min: 657.9434071603099
total_envstep_count: 8746955
total_train_sample_count: 6603936
total_episode_count: 23061
total_duration: 1924.6733622540721
[2023-06-29 11:34:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 270.6666666666667
avg_sample_per_episode: 270.6666666666667
avg_envstep_per_sec: 2609.8869421789063
avg_train_sample_per_sec: 2609.8869421789063
avg_episode_per_sec: 9.642439441547685
collect_time: 0.9333737644460054
reward_mean: 1662.860856861606
reward_std: 356.8128740040275
reward_max: 2228.709846200056
reward_min: 1115.740138085568
total_envstep_count: 8751843
total_train_sample_count: 6607172
total_episode_count: 23070
total_duration: 1925.6067360185182
[2023-06-29 11:34:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2521
train_sample_count: 2521
avg_envstep_per_episode: 280.1111111111111
avg_sample_per_episode: 280.1111111111111
avg_envstep_per_sec: 2653.8864954690466
avg_train_sample_per_sec: 2653.8864954690466
avg_episode_per_sec: 9.474406370179064
collect_time: 0.9499275889545682
reward_mean: 2019.38516586846
reward_std: 604.3502294860546
reward_max: 3005.0214287293898
reward_min: 1117.2491270241844
total_envstep_count: 8756235
total_train_sample_count: 6610493
total_episode_count: 23079
total_duration: 1926.5566636074727
[2023-06-29 11:34:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1664
train_sample_count: 1664
avg_envstep_per_episode: 332.8
avg_sample_per_episode: 332.8
avg_envstep_per_sec: 2777.5245273233763
avg_train_sample_per_sec: 2777.5245273233763
avg_episode_per_sec: 8.345927065274568
collect_time: 0.5990946195544674
reward_mean: 2118.439748745931
reward_std: 441.7195845975976
reward_max: 2949.910720822276
reward_min: 1630.9228874987496
total_envstep_count: 8759963
total_train_sample_count: 6613757
total_episode_count: 23084
total_duration: 1927.1557582270273
[2023-06-29 11:34:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2203
train_sample_count: 2203
avg_envstep_per_episode: 244.77777777777777
avg_sample_per_episode: 244.77777777777777
avg_envstep_per_sec: 2739.8886055930025
avg_train_sample_per_sec: 2739.8886055930025
avg_episode_per_sec: 11.193371516267373
collect_time: 0.8040472869966179
reward_mean: 1711.9117324081394
reward_std: 983.3814672033918
reward_max: 3494.056855488366
reward_min: 544.8733193518908
total_envstep_count: 8764323
total_train_sample_count: 6617160
total_episode_count: 23093
total_duration: 1927.9598055140239
[2023-06-29 11:34:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1827
train_sample_count: 1827
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2576.0567681349576
avg_train_sample_per_sec: 2576.0567681349576
avg_episode_per_sec: 9.869949303199071
collect_time: 0.7092235010499135
reward_mean: 2045.1153522385482
reward_std: 701.5397668562988
reward_max: 3572.552685989266
reward_min: 1268.902761285861
total_envstep_count: 8768651
total_train_sample_count: 6620587
total_episode_count: 23100
total_duration: 1928.6690290150739
[2023-06-29 11:34:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2211
train_sample_count: 2211
avg_envstep_per_episode: 245.66666666666666
avg_sample_per_episode: 245.66666666666666
avg_envstep_per_sec: 2506.734830059173
avg_train_sample_per_sec: 2506.734830059173
avg_episode_per_sec: 10.20380527839555
collect_time: 0.8820238876035436
reward_mean: 1980.9846103382188
reward_std: 1017.8343651206898
reward_max: 3582.8967084147594
reward_min: 381.977189120243
total_envstep_count: 8773291
total_train_sample_count: 6623998
total_episode_count: 23109
total_duration: 1929.5510529026774
[2023-06-29 11:34:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2331
train_sample_count: 2331
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2529.2100603537765
avg_train_sample_per_sec: 2529.2100603537765
avg_episode_per_sec: 9.765289808315739
collect_time: 0.9216316337417811
reward_mean: 1884.6180340932779
reward_std: 625.7831829205694
reward_max: 3402.072296228889
reward_min: 1273.1524124059463
total_envstep_count: 8777971
total_train_sample_count: 6627529
total_episode_count: 23118
total_duration: 1930.4726845364191
[2023-06-29 11:34:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 277.55555555555554
avg_sample_per_episode: 277.55555555555554
avg_envstep_per_sec: 2638.5893869509305
avg_train_sample_per_sec: 2638.5893869509305
avg_episode_per_sec: 9.506527014635058
collect_time: 0.9467179745184259
reward_mean: 1956.966975095757
reward_std: 677.5770047013134
reward_max: 3494.254981028778
reward_min: 1026.4799242931886
total_envstep_count: 8782171
total_train_sample_count: 6630827
total_episode_count: 23127
total_duration: 1931.4194025109375
[2023-06-29 11:34:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1701
train_sample_count: 1701
avg_envstep_per_episode: 283.5
avg_sample_per_episode: 283.5
avg_envstep_per_sec: 2775.3805851886796
avg_train_sample_per_sec: 2775.3805851886796
avg_episode_per_sec: 9.789702240524443
collect_time: 0.6128889165967703
reward_mean: 1911.5605510609305
reward_std: 748.0110030105386
reward_max: 3467.061736154697
reward_min: 1160.791958959545
total_envstep_count: 8786635
total_train_sample_count: 6634128
total_episode_count: 23133
total_duration: 1932.0322914275343
[2023-06-29 11:35:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2961
train_sample_count: 2961
avg_envstep_per_episode: 246.75
avg_sample_per_episode: 246.75
avg_envstep_per_sec: 2551.4554926568444
avg_train_sample_per_sec: 2551.4554926568444
avg_episode_per_sec: 10.340245157677181
collect_time: 1.1605140707027166
reward_mean: 1810.8117985616957
reward_std: 682.434586013193
reward_max: 3312.595808990869
reward_min: 1124.1011796645287
total_envstep_count: 8791067
total_train_sample_count: 6637489
total_episode_count: 23145
total_duration: 1933.192805498237
[2023-06-29 11:35:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2522
train_sample_count: 2522
avg_envstep_per_episode: 315.25
avg_sample_per_episode: 315.25
avg_envstep_per_sec: 2573.360128744257
avg_train_sample_per_sec: 2573.360128744257
avg_episode_per_sec: 8.162918727182417
collect_time: 0.9800416085682808
reward_mean: 1802.050710538349
reward_std: 481.8389753418299
reward_max: 2601.036615341328
reward_min: 1163.8456258724295
total_envstep_count: 8795571
total_train_sample_count: 6640811
total_episode_count: 23153
total_duration: 1934.1728471068052
[2023-06-29 11:35:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2628
train_sample_count: 2628
avg_envstep_per_episode: 262.8
avg_sample_per_episode: 262.8
avg_envstep_per_sec: 2554.1962029390847
avg_train_sample_per_sec: 2554.1962029390847
avg_episode_per_sec: 9.719163633710368
collect_time: 1.0288951165834441
reward_mean: 1648.4591678264612
reward_std: 455.67626787622805
reward_max: 2551.410035117289
reward_min: 1168.5251208416612
total_envstep_count: 8800019
total_train_sample_count: 6644239
total_episode_count: 23163
total_duration: 1935.2017422233887
[2023-06-29 11:35:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2755.9312205466563
avg_train_sample_per_sec: 2755.9312205466563
avg_episode_per_sec: 10.082675197121914
collect_time: 0.8926202445328238
reward_mean: 1715.6703838194055
reward_std: 444.30703971318025
reward_max: 2511.2926949025923
reward_min: 1096.3944159668895
total_envstep_count: 8804355
total_train_sample_count: 6647499
total_episode_count: 23172
total_duration: 1936.0943624679214
[2023-06-29 11:35:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 811
train_sample_count: 811
avg_envstep_per_episode: 202.75
avg_sample_per_episode: 202.75
avg_envstep_per_sec: 2217.9924631902722
avg_train_sample_per_sec: 2217.9924631902722
avg_episode_per_sec: 10.939543591567311
collect_time: 0.36564596744999295
reward_mean: 2167.7110824906435
reward_std: 221.76580794098044
reward_max: 2497.028264198158
reward_min: 1910.2426044743909
total_envstep_count: 8808467
total_train_sample_count: 6650710
total_episode_count: 23176
total_duration: 1936.4600084353715
[2023-06-29 11:35:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2785.846056357642
avg_train_sample_per_sec: 2785.846056357642
avg_episode_per_sec: 10.192119718381617
collect_time: 0.8830351534988728
reward_mean: 2276.6946946988423
reward_std: 888.3959532760286
reward_max: 3559.430053814721
reward_min: 992.8854547158221
total_envstep_count: 8813043
total_train_sample_count: 6653970
total_episode_count: 23185
total_duration: 1937.3430435888704
[2023-06-29 11:35:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2864
train_sample_count: 2864
avg_envstep_per_episode: 318.22222222222223
avg_sample_per_episode: 318.22222222222223
avg_envstep_per_sec: 2791.741462857097
avg_train_sample_per_sec: 2791.741462857097
avg_episode_per_sec: 8.772930574620766
collect_time: 1.0258829616224394
reward_mean: 2113.511006919156
reward_std: 783.9584230839623
reward_max: 3495.733074335676
reward_min: 1234.5272813225984
total_envstep_count: 8817315
total_train_sample_count: 6657234
total_episode_count: 23194
total_duration: 1938.368926550493
[2023-06-29 11:35:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 306.625
avg_sample_per_episode: 306.625
avg_envstep_per_sec: 2681.107195013889
avg_train_sample_per_sec: 2681.107195013889
avg_episode_per_sec: 8.743928887122346
collect_time: 0.9149205240886658
reward_mean: 1730.6679859503386
reward_std: 815.2843503964839
reward_max: 3664.6311951196917
reward_min: 921.7359226125104
total_envstep_count: 8821371
total_train_sample_count: 6660487
total_episode_count: 23202
total_duration: 1939.2838470745817
[2023-06-29 11:35:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 282.9
avg_sample_per_episode: 282.9
avg_envstep_per_sec: 2537.4142903655593
avg_train_sample_per_sec: 2537.4142903655593
avg_episode_per_sec: 8.969297597615975
collect_time: 1.1149145059762522
reward_mean: 1617.3904664505737
reward_std: 448.28063069727875
reward_max: 2211.8358455681305
reward_min: 561.57563271788
total_envstep_count: 8825539
total_train_sample_count: 6663716
total_episode_count: 23212
total_duration: 1940.398761580558
[2023-06-29 11:35:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3301
train_sample_count: 3301
avg_envstep_per_episode: 366.77777777777777
avg_sample_per_episode: 366.77777777777777
avg_envstep_per_sec: 2613.1323403228967
avg_train_sample_per_sec: 2613.1323403228967
avg_episode_per_sec: 7.124565605242674
collect_time: 1.2632349112452934
reward_mean: 1853.9235166501303
reward_std: 439.369189639355
reward_max: 2548.0972536208997
reward_min: 1213.270958959066
total_envstep_count: 8830691
total_train_sample_count: 6667017
total_episode_count: 23221
total_duration: 1941.6619964918032
[2023-06-29 11:35:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1417
train_sample_count: 1417
avg_envstep_per_episode: 236.16666666666666
avg_sample_per_episode: 236.16666666666666
avg_envstep_per_sec: 2770.254081920792
avg_train_sample_per_sec: 2770.254081920792
avg_episode_per_sec: 11.730080798535463
collect_time: 0.5115054280571638
reward_mean: 1805.253720637769
reward_std: 400.68981569823643
reward_max: 2565.2148958592097
reward_min: 1304.3741899374525
total_envstep_count: 8835675
total_train_sample_count: 6670434
total_episode_count: 23227
total_duration: 1942.1735019198604
[2023-06-29 11:35:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2767
train_sample_count: 2767
avg_envstep_per_episode: 276.7
avg_sample_per_episode: 276.7
avg_envstep_per_sec: 2777.2201301686864
avg_train_sample_per_sec: 2777.2201301686864
avg_episode_per_sec: 10.036935779431467
collect_time: 0.9963200143706052
reward_mean: 2360.7713308214884
reward_std: 832.6824374319243
reward_max: 3504.7152462052904
reward_min: 1416.0292414219207
total_envstep_count: 8841107
total_train_sample_count: 6674001
total_episode_count: 23237
total_duration: 1943.169821934231
[2023-06-29 11:35:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3072
train_sample_count: 3072
avg_envstep_per_episode: 256.0
avg_sample_per_episode: 256.0
avg_envstep_per_sec: 2602.897053478328
avg_train_sample_per_sec: 2602.897053478328
avg_episode_per_sec: 10.167566615149719
collect_time: 1.1802233960404989
reward_mean: 1704.4174989827345
reward_std: 685.6019753457857
reward_max: 2862.1069772180335
reward_min: 559.6887643445164
total_envstep_count: 8846323
total_train_sample_count: 6677473
total_episode_count: 23249
total_duration: 1944.3500453302715
[2023-06-29 11:35:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3080
train_sample_count: 3080
avg_envstep_per_episode: 256.6666666666667
avg_sample_per_episode: 256.6666666666667
avg_envstep_per_sec: 2599.6885623773355
avg_train_sample_per_sec: 2599.6885623773355
avg_episode_per_sec: 10.128656736535072
collect_time: 1.1847572992295026
reward_mean: 1553.3702065994803
reward_std: 350.29769605559375
reward_max: 2248.147677051259
reward_min: 1187.5115742732005
total_envstep_count: 8850859
total_train_sample_count: 6680953
total_episode_count: 23261
total_duration: 1945.534802629501
[2023-06-29 11:35:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2979
train_sample_count: 2979
avg_envstep_per_episode: 270.8181818181818
avg_sample_per_episode: 270.8181818181818
avg_envstep_per_sec: 2697.5456386784394
avg_train_sample_per_sec: 2697.5456386784394
avg_episode_per_sec: 9.960725755442374
collect_time: 1.1043372009303423
reward_mean: 1428.8564799600547
reward_std: 304.76680761207666
reward_max: 1760.6829332866985
reward_min: 586.8705199889498
total_envstep_count: 8855483
total_train_sample_count: 6684332
total_episode_count: 23272
total_duration: 1946.6391398304313
[2023-06-29 11:35:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 753
train_sample_count: 753
avg_envstep_per_episode: 188.25
avg_sample_per_episode: 188.25
avg_envstep_per_sec: 2522.5553997560155
avg_train_sample_per_sec: 2522.5553997560155
avg_episode_per_sec: 13.400028683962898
collect_time: 0.29850682370457793
reward_mean: 1475.2896451189833
reward_std: 132.46610698520524
reward_max: 1599.4269253984885
reward_min: 1256.5633136445651
total_envstep_count: 8859963
total_train_sample_count: 6687885
total_episode_count: 23276
total_duration: 1946.937646654136
[2023-06-29 11:35:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2172
train_sample_count: 2172
avg_envstep_per_episode: 217.2
avg_sample_per_episode: 217.2
avg_envstep_per_sec: 2693.8216218727307
avg_train_sample_per_sec: 2693.8216218727307
avg_episode_per_sec: 12.402493655030987
collect_time: 0.806289467114024
reward_mean: 2326.3636530870913
reward_std: 754.0908104271168
reward_max: 3438.667379317623
reward_min: 1352.7267767708424
total_envstep_count: 8864763
total_train_sample_count: 6691257
total_episode_count: 23286
total_duration: 1947.74393612125
[2023-06-29 11:35:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 247.4
avg_sample_per_episode: 247.4
avg_envstep_per_sec: 2690.693547031185
avg_train_sample_per_sec: 2690.693547031185
avg_episode_per_sec: 10.875883375227101
collect_time: 0.4597327708927914
reward_mean: 2335.053406307037
reward_std: 594.0391633146564
reward_max: 3483.490618205898
reward_min: 1852.5152673856114
total_envstep_count: 8869219
total_train_sample_count: 6694494
total_episode_count: 23291
total_duration: 1948.2036688921428
[2023-06-29 11:35:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2345
train_sample_count: 2345
avg_envstep_per_episode: 260.55555555555554
avg_sample_per_episode: 260.55555555555554
avg_envstep_per_sec: 2603.303589841158
avg_train_sample_per_sec: 2603.303589841158
avg_episode_per_sec: 9.991357061224061
collect_time: 0.9007785373749211
reward_mean: 2406.219656355248
reward_std: 1112.0585719154833
reward_max: 3538.6179827352075
reward_min: 258.1535060333009
total_envstep_count: 8874475
total_train_sample_count: 6698039
total_episode_count: 23300
total_duration: 1949.1044474295177
[2023-06-29 11:36:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1756
train_sample_count: 1756
avg_envstep_per_episode: 250.85714285714286
avg_sample_per_episode: 250.85714285714286
avg_envstep_per_sec: 2496.146674571306
avg_train_sample_per_sec: 2496.146674571306
avg_episode_per_sec: 9.950470798404979
collect_time: 0.7034843015791848
reward_mean: 2119.9101825571843
reward_std: 801.638334890675
reward_max: 3483.389162014895
reward_min: 991.9246316843869
total_envstep_count: 8879043
total_train_sample_count: 6701395
total_episode_count: 23307
total_duration: 1949.807931731097
[2023-06-29 11:36:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1647
train_sample_count: 1647
avg_envstep_per_episode: 274.5
avg_sample_per_episode: 274.5
avg_envstep_per_sec: 2691.693278936657
avg_train_sample_per_sec: 2691.693278936657
avg_episode_per_sec: 9.805804294851209
collect_time: 0.6118824952635915
reward_mean: 2579.606872151709
reward_std: 756.1695476872679
reward_max: 3473.50461921985
reward_min: 1278.36106676896
total_envstep_count: 8883395
total_train_sample_count: 6704642
total_episode_count: 23313
total_duration: 1950.4198142263606
[2023-06-29 11:36:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1928
train_sample_count: 1928
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2686.6131211734005
avg_train_sample_per_sec: 2686.6131211734005
avg_episode_per_sec: 11.147772287026557
collect_time: 0.7176321684746072
reward_mean: 2054.5381362772027
reward_std: 1165.852089910126
reward_max: 3533.546434711638
reward_min: 553.8282754754647
total_envstep_count: 8887915
total_train_sample_count: 6708170
total_episode_count: 23321
total_duration: 1951.1374463948353
[2023-06-29 11:36:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 244.4
avg_sample_per_episode: 244.4
avg_envstep_per_sec: 2409.377239555396
avg_train_sample_per_sec: 2409.377239555396
avg_episode_per_sec: 9.858335677395237
collect_time: 0.5071850019739941
reward_mean: 2649.7682040073787
reward_std: 875.2493841411883
reward_max: 3558.8258120377723
reward_min: 1483.5094776492197
total_envstep_count: 8891819
total_train_sample_count: 6711392
total_episode_count: 23326
total_duration: 1951.6446313968092
[2023-06-29 11:36:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1246
train_sample_count: 1246
avg_envstep_per_episode: 207.66666666666666
avg_sample_per_episode: 207.66666666666666
avg_envstep_per_sec: 2649.850171566863
avg_train_sample_per_sec: 2649.850171566863
avg_episode_per_sec: 12.760113185715232
collect_time: 0.4702152647608891
reward_mean: 2296.7301623704607
reward_std: 946.669832195143
reward_max: 3437.0090476121327
reward_min: 801.3685254469336
total_envstep_count: 8896763
total_train_sample_count: 6714638
total_episode_count: 23332
total_duration: 1952.11484666157
[2023-06-29 11:36:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2132
train_sample_count: 2132
avg_envstep_per_episode: 266.5
avg_sample_per_episode: 266.5
avg_envstep_per_sec: 2467.7916086052455
avg_train_sample_per_sec: 2467.7916086052455
avg_episode_per_sec: 9.260006036042197
collect_time: 0.8639303223844621
reward_mean: 2647.867001313119
reward_std: 969.5968982328102
reward_max: 3615.8764567615844
reward_min: 988.3555877668822
total_envstep_count: 8901563
total_train_sample_count: 6717970
total_episode_count: 23340
total_duration: 1952.9787769839545
[2023-06-29 11:36:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 234.88888888888889
avg_sample_per_episode: 234.88888888888889
avg_envstep_per_sec: 2647.502260050121
avg_train_sample_per_sec: 2647.502260050121
avg_episode_per_sec: 11.271296282143373
collect_time: 0.7984884590655567
reward_mean: 1838.0165919027636
reward_std: 1063.335767822184
reward_max: 3272.3352630059367
reward_min: 58.5200883144453
total_envstep_count: 8906483
total_train_sample_count: 6721284
total_episode_count: 23349
total_duration: 1953.77726544302
[2023-06-29 11:36:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 253.625
avg_sample_per_episode: 253.625
avg_envstep_per_sec: 2722.7980204322316
avg_train_sample_per_sec: 2722.7980204322316
avg_episode_per_sec: 10.73552694108322
collect_time: 0.7451893180375919
reward_mean: 2306.9063421517867
reward_std: 581.9662689496972
reward_max: 3465.46169389184
reward_min: 1746.4772668440787
total_envstep_count: 8911347
total_train_sample_count: 6724513
total_episode_count: 23357
total_duration: 1954.5224547610576
[2023-06-29 11:36:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3157
train_sample_count: 3157
avg_envstep_per_episode: 242.84615384615384
avg_sample_per_episode: 242.84615384615384
avg_envstep_per_sec: 2583.818798601795
avg_train_sample_per_sec: 2583.818798601795
avg_episode_per_sec: 10.639735312582621
collect_time: 1.2218349064216019
reward_mean: 1644.795224227302
reward_std: 619.7161257697879
reward_max: 2532.538376408467
reward_min: 619.4782164770651
total_envstep_count: 8916547
total_train_sample_count: 6728070
total_episode_count: 23370
total_duration: 1955.7442896674793
[2023-06-29 11:36:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 248.30769230769232
avg_sample_per_episode: 248.30769230769232
avg_envstep_per_sec: 2635.924674812344
avg_train_sample_per_sec: 2635.924674812344
avg_episode_per_sec: 10.615557860148847
collect_time: 1.2246176952039824
reward_mean: 1443.2275462853713
reward_std: 462.93270396845014
reward_max: 1982.6851331516739
reward_min: 116.76222925090322
total_envstep_count: 8920579
total_train_sample_count: 6731298
total_episode_count: 23383
total_duration: 1956.9689073626832
[2023-06-29 11:36:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2323
train_sample_count: 2323
avg_envstep_per_episode: 387.1666666666667
avg_sample_per_episode: 387.1666666666667
avg_envstep_per_sec: 2479.772647294441
avg_train_sample_per_sec: 2479.772647294441
avg_episode_per_sec: 6.404922894432477
collect_time: 0.936779427152127
reward_mean: 1804.642181788111
reward_std: 380.1362958510025
reward_max: 2495.537847044724
reward_min: 1357.1213040255875
total_envstep_count: 8926323
total_train_sample_count: 6734821
total_episode_count: 23389
total_duration: 1957.9056867898353
[2023-06-29 11:36:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2630
train_sample_count: 2630
avg_envstep_per_episode: 239.0909090909091
avg_sample_per_episode: 239.0909090909091
avg_envstep_per_sec: 2560.2265081718742
avg_train_sample_per_sec: 2560.2265081718742
avg_episode_per_sec: 10.708171707182744
collect_time: 1.0272528589190912
reward_mean: 2018.0087213083339
reward_std: 911.6594064639442
reward_max: 3515.242802136642
reward_min: 637.9979676331334
total_envstep_count: 8931059
total_train_sample_count: 6738251
total_episode_count: 23400
total_duration: 1958.9329396487544
[2023-06-29 11:36:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1413
train_sample_count: 1413
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 2771.122410195536
avg_train_sample_per_sec: 2771.122410195536
avg_episode_per_sec: 11.76697414095769
collect_time: 0.5099016899438578
reward_mean: 1918.5598631312444
reward_std: 833.2123168613398
reward_max: 3440.2824865741018
reward_min: 1087.7564686405124
total_envstep_count: 8935795
total_train_sample_count: 6741664
total_episode_count: 23406
total_duration: 1959.4428413386984
[2023-06-29 11:36:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1047
train_sample_count: 1047
avg_envstep_per_episode: 130.875
avg_sample_per_episode: 130.875
avg_envstep_per_sec: 2801.453774624711
avg_train_sample_per_sec: 2801.453774624711
avg_episode_per_sec: 21.40556847850782
collect_time: 0.37373452651035033
reward_mean: 1975.8262057084285
reward_std: 747.0156535441178
reward_max: 3179.2741036030357
reward_min: 1050.1501608981862
total_envstep_count: 8940027
total_train_sample_count: 6745111
total_episode_count: 23414
total_duration: 1959.8165758652087
[2023-06-29 11:36:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 207.625
avg_sample_per_episode: 207.625
avg_envstep_per_sec: 2751.065556231579
avg_train_sample_per_sec: 2751.065556231579
avg_episode_per_sec: 13.25016523169936
collect_time: 0.6037660557515919
reward_mean: 1888.3947604349726
reward_std: 852.5993119228034
reward_max: 2861.087517006315
reward_min: 296.31871624489617
total_envstep_count: 8943939
total_train_sample_count: 6748372
total_episode_count: 23422
total_duration: 1960.4203419209603
[2023-06-29 11:36:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2936
train_sample_count: 2936
avg_envstep_per_episode: 293.6
avg_sample_per_episode: 293.6
avg_envstep_per_sec: 2590.99771220085
avg_train_sample_per_sec: 2590.99771220085
avg_episode_per_sec: 8.824924087877553
collect_time: 1.133154223245569
reward_mean: 2062.9056258047503
reward_std: 1097.5079248195232
reward_max: 3564.1156129736514
reward_min: 40.09199923322396
total_envstep_count: 8948563
total_train_sample_count: 6751708
total_episode_count: 23432
total_duration: 1961.5534961442058
[2023-06-29 11:36:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1536
train_sample_count: 1536
avg_envstep_per_episode: 307.2
avg_sample_per_episode: 307.2
avg_envstep_per_sec: 2455.3748560662957
avg_train_sample_per_sec: 2455.3748560662957
avg_episode_per_sec: 7.992756692924139
collect_time: 0.6255663961879911
reward_mean: 2252.3781860101362
reward_std: 572.6030823332652
reward_max: 2964.1919499150176
reward_min: 1346.9698168914822
total_envstep_count: 8953259
total_train_sample_count: 6755244
total_episode_count: 23437
total_duration: 1962.1790625403937
[2023-06-29 11:36:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2716
train_sample_count: 2716
avg_envstep_per_episode: 271.6
avg_sample_per_episode: 271.6
avg_envstep_per_sec: 2802.971517528528
avg_train_sample_per_sec: 2802.971517528528
avg_episode_per_sec: 10.320219136702974
collect_time: 0.9689716727463527
reward_mean: 2173.0118366575157
reward_std: 828.2602732536309
reward_max: 3528.7530665090585
reward_min: 875.4272078500642
total_envstep_count: 8957947
total_train_sample_count: 6758760
total_episode_count: 23447
total_duration: 1963.1480342131401
[2023-06-29 11:36:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 800
train_sample_count: 800
avg_envstep_per_episode: 400.0
avg_sample_per_episode: 400.0
avg_envstep_per_sec: 2751.528865617263
avg_train_sample_per_sec: 2751.528865617263
avg_episode_per_sec: 6.878822164043157
collect_time: 0.29074744953494513
reward_mean: 2369.6369746783257
reward_std: 1119.033639514851
reward_max: 3488.670614193177
reward_min: 1250.6033351634744
total_envstep_count: 8962347
total_train_sample_count: 6761960
total_episode_count: 23449
total_duration: 1963.4387816626752
[2023-06-29 11:37:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 206.85714285714286
avg_sample_per_episode: 206.85714285714286
avg_envstep_per_sec: 2522.4559918776276
avg_train_sample_per_sec: 2522.4559918776276
avg_episode_per_sec: 12.194193330900134
collect_time: 0.5740437116296961
reward_mean: 3252.989255843036
reward_std: 660.1359218482743
reward_max: 3593.324754162714
reward_min: 1638.3025939776562
total_envstep_count: 8966923
total_train_sample_count: 6765408
total_episode_count: 23456
total_duration: 1964.0128253743048
[2023-06-29 11:37:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2081
train_sample_count: 2081
avg_envstep_per_episode: 416.2
avg_sample_per_episode: 416.2
avg_envstep_per_sec: 2563.92023764525
avg_train_sample_per_sec: 2563.92023764525
avg_episode_per_sec: 6.16030811543789
collect_time: 0.8116477140923961
reward_mean: 3165.621987552693
reward_std: 587.458084980092
reward_max: 3668.56863446536
reward_min: 2063.851902215604
total_envstep_count: 8971011
total_train_sample_count: 6768689
total_episode_count: 23461
total_duration: 1964.8244730883973
[2023-06-29 11:37:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 366.1666666666667
avg_sample_per_episode: 366.1666666666667
avg_envstep_per_sec: 2548.4644451337595
avg_train_sample_per_sec: 2548.4644451337595
avg_episode_per_sec: 6.959848279837304
collect_time: 0.8620877580596137
reward_mean: 2669.0736690640647
reward_std: 846.3274630373443
reward_max: 3491.76083653514
reward_min: 1624.44382974395
total_envstep_count: 8976059
total_train_sample_count: 6772086
total_episode_count: 23467
total_duration: 1965.686560846457
[2023-06-29 11:37:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 857
train_sample_count: 857
avg_envstep_per_episode: 214.25
avg_sample_per_episode: 214.25
avg_envstep_per_sec: 2827.1646484445623
avg_train_sample_per_sec: 2827.1646484445623
avg_episode_per_sec: 13.195634298457701
collect_time: 0.3031305589051917
reward_mean: 3052.553000669654
reward_std: 488.58058606734596
reward_max: 3498.2763051742522
reward_min: 2282.1292134133023
total_envstep_count: 8979995
total_train_sample_count: 6775343
total_episode_count: 23471
total_duration: 1965.9896914053622
[2023-06-29 11:37:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1231
train_sample_count: 1231
avg_envstep_per_episode: 246.2
avg_sample_per_episode: 246.2
avg_envstep_per_sec: 2616.626608399726
avg_train_sample_per_sec: 2616.626608399726
avg_episode_per_sec: 10.628052836717002
collect_time: 0.4704530619876459
reward_mean: 3068.95336847089
reward_std: 664.041119127609
reward_max: 3492.007070594353
reward_min: 1762.5340831676315
total_envstep_count: 8984219
total_train_sample_count: 6778574
total_episode_count: 23476
total_duration: 1966.46014446735
[2023-06-29 11:37:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1413
train_sample_count: 1413
avg_envstep_per_episode: 282.6
avg_sample_per_episode: 282.6
avg_envstep_per_sec: 2776.7315993044194
avg_train_sample_per_sec: 2776.7315993044194
avg_episode_per_sec: 9.825660294778555
collect_time: 0.508871653405018
reward_mean: 3017.915807853773
reward_std: 454.68809961033304
reward_max: 3473.5181557566552
reward_min: 2287.1182208199484
total_envstep_count: 8987995
total_train_sample_count: 6781987
total_episode_count: 23481
total_duration: 1966.969016120755
[2023-06-29 11:37:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1217
train_sample_count: 1217
avg_envstep_per_episode: 243.4
avg_sample_per_episode: 243.4
avg_envstep_per_sec: 2725.090359451906
avg_train_sample_per_sec: 2725.090359451906
avg_episode_per_sec: 11.195934097994684
collect_time: 0.44659069589339184
reward_mean: 2622.1343034501865
reward_std: 566.6016363168
reward_max: 3432.112339084294
reward_min: 1709.519965632244
total_envstep_count: 8992267
total_train_sample_count: 6785204
total_episode_count: 23486
total_duration: 1967.4156068166483
[2023-06-29 11:37:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 425
train_sample_count: 425
avg_envstep_per_episode: 212.5
avg_sample_per_episode: 212.5
avg_envstep_per_sec: 2709.5717616702773
avg_train_sample_per_sec: 2709.5717616702773
avg_episode_per_sec: 12.750925937271894
collect_time: 0.15685135415568943
reward_mean: 3444.3687193465057
reward_std: 17.24637376806777
reward_max: 3461.6150931145735
reward_min: 3427.122345578438
total_envstep_count: 8995571
total_train_sample_count: 6788429
total_episode_count: 23488
total_duration: 1967.5724581708039
[2023-06-29 11:37:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 266.09090909090907
avg_sample_per_episode: 266.09090909090907
avg_envstep_per_sec: 2626.064354283795
avg_train_sample_per_sec: 2626.064354283795
avg_episode_per_sec: 9.869049503628885
collect_time: 1.1145956858312709
reward_mean: 2414.487201776084
reward_std: 1022.0448812468309
reward_max: 3461.703251820986
reward_min: 556.1021991383884
total_envstep_count: 9000683
total_train_sample_count: 6791756
total_episode_count: 23499
total_duration: 1968.6870538566352
[2023-06-29 11:37:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1643
train_sample_count: 1643
avg_envstep_per_episode: 273.8333333333333
avg_sample_per_episode: 273.8333333333333
avg_envstep_per_sec: 2757.076403035927
avg_train_sample_per_sec: 2757.076403035927
avg_episode_per_sec: 10.068446998305271
collect_time: 0.5959210989549754
reward_mean: 1837.612147941297
reward_std: 1026.8712798992267
reward_max: 3085.4495765687525
reward_min: 121.65052287988969
total_envstep_count: 9004963
total_train_sample_count: 6794999
total_episode_count: 23505
total_duration: 1969.2829749555901
[2023-06-29 11:37:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 207.16666666666666
avg_sample_per_episode: 207.16666666666666
avg_envstep_per_sec: 2693.4098004718066
avg_train_sample_per_sec: 2693.4098004718066
avg_episode_per_sec: 13.001173614505905
collect_time: 0.4614967985125259
reward_mean: 2098.590929179485
reward_std: 1403.6538551629183
reward_max: 3483.130451491001
reward_min: 42.086612324675436
total_envstep_count: 9008683
total_train_sample_count: 6798242
total_episode_count: 23511
total_duration: 1969.7444717541027
[2023-06-29 11:37:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1601
train_sample_count: 1601
avg_envstep_per_episode: 320.2
avg_sample_per_episode: 320.2
avg_envstep_per_sec: 2805.5891200744945
avg_train_sample_per_sec: 2805.5891200744945
avg_episode_per_sec: 8.761989756634899
collect_time: 0.5706466383635997
reward_mean: 2855.3264076227674
reward_std: 1178.2030272960021
reward_max: 3472.252311699094
reward_min: 499.2081043343793
total_envstep_count: 9012963
total_train_sample_count: 6801443
total_episode_count: 23516
total_duration: 1970.3151183924663
[2023-06-29 11:37:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1706
train_sample_count: 1706
avg_envstep_per_episode: 243.71428571428572
avg_sample_per_episode: 243.71428571428572
avg_envstep_per_sec: 2436.334413022626
avg_train_sample_per_sec: 2436.334413022626
avg_episode_per_sec: 9.996682820139732
collect_time: 0.7002322796415537
reward_mean: 2355.1446204540052
reward_std: 831.7635161408448
reward_max: 3472.6147698975496
reward_min: 1098.5806513678074
total_envstep_count: 9017547
total_train_sample_count: 6804749
total_episode_count: 23523
total_duration: 1971.0153506721078
[2023-06-29 11:37:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2662
train_sample_count: 2662
avg_envstep_per_episode: 332.75
avg_sample_per_episode: 332.75
avg_envstep_per_sec: 2757.309829243275
avg_train_sample_per_sec: 2757.309829243275
avg_episode_per_sec: 8.286430741527498
collect_time: 0.9654337614756074
reward_mean: 2342.6650208777055
reward_std: 945.6578346318016
reward_max: 3492.6831631890664
reward_min: 1286.5445977528452
total_envstep_count: 9022467
total_train_sample_count: 6808211
total_episode_count: 23531
total_duration: 1971.9807844335835
[2023-06-29 11:37:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 805
train_sample_count: 805
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 2723.204781997936
avg_train_sample_per_sec: 2723.204781997936
avg_episode_per_sec: 16.91431541613625
collect_time: 0.2956075890148059
reward_mean: 2221.532420576991
reward_std: 760.8268057882384
reward_max: 3388.951951114447
reward_min: 1572.7221057427896
total_envstep_count: 9026555
total_train_sample_count: 6811416
total_episode_count: 23536
total_duration: 1972.2763920225982
[2023-06-29 11:37:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 268.3333333333333
avg_sample_per_episode: 268.3333333333333
avg_envstep_per_sec: 2740.361984140427
avg_train_sample_per_sec: 2740.361984140427
avg_episode_per_sec: 10.212529133442585
collect_time: 0.5875136238634586
reward_mean: 2495.219206082696
reward_std: 922.9097517088003
reward_max: 3511.2759423102793
reward_min: 672.1334226472754
total_envstep_count: 9030467
total_train_sample_count: 6814626
total_episode_count: 23542
total_duration: 1972.8639056464617
[2023-06-29 11:37:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 244.11111111111111
avg_sample_per_episode: 244.11111111111111
avg_envstep_per_sec: 2590.4384845329596
avg_train_sample_per_sec: 2590.4384845329596
avg_episode_per_sec: 10.611718871550586
collect_time: 0.8481189625300466
reward_mean: 2053.3709809112843
reward_std: 927.7300005363885
reward_max: 3529.4753840505996
reward_min: 1019.5510218185094
total_envstep_count: 9034819
total_train_sample_count: 6818023
total_episode_count: 23551
total_duration: 1973.7120246089917
[2023-06-29 11:37:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1342
train_sample_count: 1342
avg_envstep_per_episode: 335.5
avg_sample_per_episode: 335.5
avg_envstep_per_sec: 2668.624082952481
avg_train_sample_per_sec: 2668.624082952481
avg_episode_per_sec: 7.954170142928408
collect_time: 0.5028808697983621
reward_mean: 2462.1685688047883
reward_std: 1005.5821141560011
reward_max: 3474.272337517392
reward_min: 1343.1065957963715
total_envstep_count: 9039155
total_train_sample_count: 6821365
total_episode_count: 23555
total_duration: 1974.2149054787901
[2023-06-29 11:37:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1620
train_sample_count: 1620
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 2667.3948865950138
avg_train_sample_per_sec: 2667.3948865950138
avg_episode_per_sec: 13.172320427629698
collect_time: 0.6073341476889327
reward_mean: 2296.5381108764636
reward_std: 809.4203017717415
reward_max: 3503.6707518071466
reward_min: 1317.6707402179272
total_envstep_count: 9043459
total_train_sample_count: 6824585
total_episode_count: 23563
total_duration: 1974.8222396264791
[2023-06-29 11:37:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 352.7142857142857
avg_sample_per_episode: 352.7142857142857
avg_envstep_per_sec: 2613.9385436203606
avg_train_sample_per_sec: 2613.9385436203606
avg_episode_per_sec: 7.410923371949179
collect_time: 0.9445516636287793
reward_mean: 2424.832376039795
reward_std: 784.1827931134058
reward_max: 3478.5717731942314
reward_min: 1354.6301265213483
total_envstep_count: 9047835
total_train_sample_count: 6827854
total_episode_count: 23570
total_duration: 1975.766791290108
[2023-06-29 11:38:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1702
train_sample_count: 1702
avg_envstep_per_episode: 243.14285714285714
avg_sample_per_episode: 243.14285714285714
avg_envstep_per_sec: 2638.043791144542
avg_train_sample_per_sec: 2638.043791144542
avg_episode_per_sec: 10.849768823743709
collect_time: 0.6451750367879868
reward_mean: 1917.7493625103125
reward_std: 673.3583090353477
reward_max: 3457.60546818526
reward_min: 1371.6163617653813
total_envstep_count: 9052155
total_train_sample_count: 6831156
total_episode_count: 23577
total_duration: 1976.411966326896
[2023-06-29 11:38:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1057
train_sample_count: 1057
avg_envstep_per_episode: 176.16666666666666
avg_sample_per_episode: 176.16666666666666
avg_envstep_per_sec: 2762.1382385070647
avg_train_sample_per_sec: 2762.1382385070647
avg_episode_per_sec: 15.67911961309592
collect_time: 0.3826745472997428
reward_mean: 2025.6223470103503
reward_std: 416.11731519767864
reward_max: 2570.696419050089
reward_min: 1307.4326980516576
total_envstep_count: 9056595
total_train_sample_count: 6834613
total_episode_count: 23583
total_duration: 1976.7946408741957
[2023-06-29 11:38:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1577
train_sample_count: 1577
avg_envstep_per_episode: 225.28571428571428
avg_sample_per_episode: 225.28571428571428
avg_envstep_per_sec: 2698.086912163531
avg_train_sample_per_sec: 2698.086912163531
avg_episode_per_sec: 11.976289400852705
collect_time: 0.5844882138120012
reward_mean: 2489.8645094427106
reward_std: 863.6863909300884
reward_max: 3467.535505369076
reward_min: 672.9542948313305
total_envstep_count: 9060979
total_train_sample_count: 6838190
total_episode_count: 23590
total_duration: 1977.3791290880076
[2023-06-29 11:38:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 190.55555555555554
avg_sample_per_episode: 190.55555555555554
avg_envstep_per_sec: 2680.102075085542
avg_train_sample_per_sec: 2680.102075085542
avg_episode_per_sec: 14.064675612693806
collect_time: 0.6399010007651524
reward_mean: 1852.5242777273643
reward_std: 596.304574154674
reward_max: 3373.190037261161
reward_min: 1349.4947567455729
total_envstep_count: 9065163
total_train_sample_count: 6841505
total_episode_count: 23599
total_duration: 1978.0190300887728
[2023-06-29 11:38:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2984
train_sample_count: 2984
avg_envstep_per_episode: 426.2857142857143
avg_sample_per_episode: 426.2857142857143
avg_envstep_per_sec: 2557.1223240636473
avg_train_sample_per_sec: 2557.1223240636473
avg_episode_per_sec: 5.998611350015258
collect_time: 1.1669367444487289
reward_mean: 2686.948248277781
reward_std: 624.5276461799765
reward_max: 3443.6008589563057
reward_min: 1886.2581838015349
total_envstep_count: 9069875
total_train_sample_count: 6844889
total_episode_count: 23606
total_duration: 1979.1859668332215
[2023-06-29 11:38:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2396
train_sample_count: 2396
avg_envstep_per_episode: 342.2857142857143
avg_sample_per_episode: 342.2857142857143
avg_envstep_per_sec: 2716.611902597742
avg_train_sample_per_sec: 2716.611902597742
avg_episode_per_sec: 7.936679181212101
collect_time: 0.8819809696441516
reward_mean: 1909.6723322488017
reward_std: 719.6516049106805
reward_max: 3350.0699514737767
reward_min: 1010.3882736279472
total_envstep_count: 9075019
total_train_sample_count: 6848485
total_episode_count: 23613
total_duration: 1980.0679478028658
[2023-06-29 11:38:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2461
train_sample_count: 2461
avg_envstep_per_episode: 273.44444444444446
avg_sample_per_episode: 273.44444444444446
avg_envstep_per_sec: 2664.1567345238727
avg_train_sample_per_sec: 2664.1567345238727
avg_episode_per_sec: 9.742954331863004
collect_time: 0.9237444509584456
reward_mean: 2035.101664163281
reward_std: 1033.699498020879
reward_max: 3425.9288515021058
reward_min: 829.8102258465001
total_envstep_count: 9079187
total_train_sample_count: 6851746
total_episode_count: 23622
total_duration: 1980.991692253824
[2023-06-29 11:38:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1509
train_sample_count: 1509
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2686.9293690904565
avg_train_sample_per_sec: 2686.9293690904565
avg_episode_per_sec: 10.683615781671795
collect_time: 0.561607616991736
reward_mean: 2130.3126198572477
reward_std: 801.2845991085194
reward_max: 3554.6170466785693
reward_min: 1154.7417908720977
total_envstep_count: 9083555
total_train_sample_count: 6855255
total_episode_count: 23628
total_duration: 1981.5532998708159
[2023-06-29 11:38:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1809
train_sample_count: 1809
avg_envstep_per_episode: 361.8
avg_sample_per_episode: 361.8
avg_envstep_per_sec: 2678.854891790819
avg_train_sample_per_sec: 2678.854891790819
avg_episode_per_sec: 7.404242376425702
collect_time: 0.6752885367339477
reward_mean: 2807.4029266346793
reward_std: 832.7916682321362
reward_max: 3438.8721761660927
reward_min: 1190.3716209118595
total_envstep_count: 9088227
total_train_sample_count: 6858664
total_episode_count: 23633
total_duration: 1982.2285884075498
[2023-06-29 11:38:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1340
train_sample_count: 1340
avg_envstep_per_episode: 223.33333333333334
avg_sample_per_episode: 223.33333333333334
avg_envstep_per_sec: 2767.9515216554164
avg_train_sample_per_sec: 2767.9515216554164
avg_episode_per_sec: 12.393812783531715
collect_time: 0.48411252491828044
reward_mean: 2756.478545549733
reward_std: 777.8597207704112
reward_max: 3565.121712845867
reward_min: 1703.3706600914295
total_envstep_count: 9092707
total_train_sample_count: 6862004
total_episode_count: 23639
total_duration: 1982.7127009324681
[2023-06-29 11:38:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 181.5
avg_sample_per_episode: 181.5
avg_envstep_per_sec: 2736.1547454477245
avg_train_sample_per_sec: 2736.1547454477245
avg_episode_per_sec: 15.075232757287738
collect_time: 0.3980038050888105
reward_mean: 2450.4439318260575
reward_std: 910.3175356610827
reward_max: 3559.012723296006
reward_min: 1243.2595368871298
total_envstep_count: 9096499
total_train_sample_count: 6865493
total_episode_count: 23645
total_duration: 1983.110704737557
[2023-06-29 11:38:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3069
train_sample_count: 3069
avg_envstep_per_episode: 255.75
avg_sample_per_episode: 255.75
avg_envstep_per_sec: 2750.0529132105576
avg_train_sample_per_sec: 2750.0529132105576
avg_episode_per_sec: 10.75289506631694
collect_time: 1.1159785272702578
reward_mean: 1755.9068372280299
reward_std: 1011.0171905198775
reward_max: 3473.7253743802116
reward_min: 261.7322919031387
total_envstep_count: 9101715
total_train_sample_count: 6868962
total_episode_count: 23657
total_duration: 1984.2266832648272
[2023-06-29 11:38:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1865
train_sample_count: 1865
avg_envstep_per_episode: 207.22222222222223
avg_sample_per_episode: 207.22222222222223
avg_envstep_per_sec: 2464.7228441996062
avg_train_sample_per_sec: 2464.7228441996062
avg_episode_per_sec: 11.894104878175044
collect_time: 0.7566773701915518
reward_mean: 1620.815299326662
reward_std: 677.2973867939857
reward_max: 3232.0047227638906
reward_min: 884.582065704597
total_envstep_count: 9106755
total_train_sample_count: 6872427
total_episode_count: 23666
total_duration: 1984.9833606350187
[2023-06-29 11:38:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3066
train_sample_count: 3066
avg_envstep_per_episode: 278.72727272727275
avg_sample_per_episode: 278.72727272727275
avg_envstep_per_sec: 2660.5553635935776
avg_train_sample_per_sec: 2660.5553635935776
avg_episode_per_sec: 9.545371493649496
collect_time: 1.1523909789491444
reward_mean: 2041.4191453704427
reward_std: 818.0603661945079
reward_max: 3216.0882039725843
reward_min: 984.6680361576646
total_envstep_count: 9111475
total_train_sample_count: 6875893
total_episode_count: 23677
total_duration: 1986.1357516139678
[2023-06-29 11:38:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3367
train_sample_count: 3367
avg_envstep_per_episode: 374.1111111111111
avg_sample_per_episode: 374.1111111111111
avg_envstep_per_sec: 2630.327034787056
avg_train_sample_per_sec: 2630.327034787056
avg_episode_per_sec: 7.030871194856996
collect_time: 1.2800689630871633
reward_mean: 2010.731228365801
reward_std: 767.4089639625728
reward_max: 3651.047819024584
reward_min: 1316.5880865475197
total_envstep_count: 9116571
total_train_sample_count: 6879260
total_episode_count: 23686
total_duration: 1987.415820577055
[2023-06-29 11:38:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2724
train_sample_count: 2724
avg_envstep_per_episode: 272.4
avg_sample_per_episode: 272.4
avg_envstep_per_sec: 2728.0623107080078
avg_train_sample_per_sec: 2728.0623107080078
avg_episode_per_sec: 10.014913034904582
collect_time: 0.998510917183943
reward_mean: 1620.7006669589853
reward_std: 373.5607588446503
reward_max: 2385.8787006818065
reward_min: 1075.5798407050104
total_envstep_count: 9120539
total_train_sample_count: 6882784
total_episode_count: 23696
total_duration: 1988.414331494239
[2023-06-29 11:38:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1689
train_sample_count: 1689
avg_envstep_per_episode: 337.8
avg_sample_per_episode: 337.8
avg_envstep_per_sec: 2754.4906529114637
avg_train_sample_per_sec: 2754.4906529114637
avg_episode_per_sec: 8.154205603645542
collect_time: 0.6131805160474032
reward_mean: 1831.1744297988
reward_std: 527.7141054300349
reward_max: 2765.5750426301956
reward_min: 1336.2400890857182
total_envstep_count: 9124667
total_train_sample_count: 6886073
total_episode_count: 23701
total_duration: 1989.0275120102863
[2023-06-29 11:38:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1803
train_sample_count: 1803
avg_envstep_per_episode: 225.375
avg_sample_per_episode: 225.375
avg_envstep_per_sec: 2689.318562250763
avg_train_sample_per_sec: 2689.318562250763
avg_episode_per_sec: 11.932639211317861
collect_time: 0.6704300581226126
reward_mean: 2095.7535208940008
reward_std: 851.8948779792294
reward_max: 3535.066226344718
reward_min: 1045.8625125381711
total_envstep_count: 9129635
total_train_sample_count: 6889476
total_episode_count: 23709
total_duration: 1989.6979420684088
[2023-06-29 11:38:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2930
train_sample_count: 2930
avg_envstep_per_episode: 325.55555555555554
avg_sample_per_episode: 325.55555555555554
avg_envstep_per_sec: 2603.738924281868
avg_train_sample_per_sec: 2603.738924281868
avg_episode_per_sec: 7.997832873220755
collect_time: 1.1253048347802832
reward_mean: 2463.3952708278102
reward_std: 658.3184113264766
reward_max: 3129.2847079764047
reward_min: 1415.7231811563104
total_envstep_count: 9134427
total_train_sample_count: 6892806
total_episode_count: 23718
total_duration: 1990.823246903189
[2023-06-29 11:38:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 274.8888888888889
avg_sample_per_episode: 274.8888888888889
avg_envstep_per_sec: 2572.2373965673587
avg_train_sample_per_sec: 2572.2373965673587
avg_episode_per_sec: 9.357371289048597
collect_time: 0.9618085808493196
reward_mean: 1741.0402332818483
reward_std: 360.2657611462433
reward_max: 2433.011329389202
reward_min: 1247.9314768797437
total_envstep_count: 9139243
total_train_sample_count: 6896080
total_episode_count: 23727
total_duration: 1991.7850554840384
[2023-06-29 11:39:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2031
train_sample_count: 2031
avg_envstep_per_episode: 225.66666666666666
avg_sample_per_episode: 225.66666666666666
avg_envstep_per_sec: 2751.0044661578263
avg_train_sample_per_sec: 2751.0044661578263
avg_episode_per_sec: 12.190566319754032
collect_time: 0.7382757916189732
reward_mean: 1727.7280545981314
reward_std: 268.536655882959
reward_max: 2315.245450348422
reward_min: 1365.9497218552456
total_envstep_count: 9144003
total_train_sample_count: 6899311
total_episode_count: 23736
total_duration: 1992.5233312756573
[2023-06-29 11:39:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2780
train_sample_count: 2780
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2586.248069571148
avg_train_sample_per_sec: 2586.248069571148
avg_episode_per_sec: 9.303050609968158
collect_time: 1.0749162204153835
reward_mean: 1806.5509590204997
reward_std: 787.9142526151778
reward_max: 3557.918205170981
reward_min: 364.2496057611333
total_envstep_count: 9148635
total_train_sample_count: 6902891
total_episode_count: 23746
total_duration: 1993.5982474960726
[2023-06-29 11:39:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1488
train_sample_count: 1488
avg_envstep_per_episode: 248.0
avg_sample_per_episode: 248.0
avg_envstep_per_sec: 2691.613929952593
avg_train_sample_per_sec: 2691.613929952593
avg_episode_per_sec: 10.853281975615294
collect_time: 0.5528281687954438
reward_mean: 2035.2873183845657
reward_std: 868.5019952429229
reward_max: 3364.7732369727523
reward_min: 683.759564379913
total_envstep_count: 9153059
total_train_sample_count: 6906379
total_episode_count: 23752
total_duration: 1994.1510756648681
[2023-06-29 11:39:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1909
train_sample_count: 1909
avg_envstep_per_episode: 238.625
avg_sample_per_episode: 238.625
avg_envstep_per_sec: 2501.829973470843
avg_train_sample_per_sec: 2501.829973470843
avg_episode_per_sec: 10.484358191601228
collect_time: 0.7630414617471398
reward_mean: 2239.6008975415293
reward_std: 956.477661285217
reward_max: 3476.002755933141
reward_min: 119.45288787873528
total_envstep_count: 9157867
total_train_sample_count: 6909888
total_episode_count: 23760
total_duration: 1994.9141171266153
[2023-06-29 11:39:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2486
train_sample_count: 2486
avg_envstep_per_episode: 310.75
avg_sample_per_episode: 310.75
avg_envstep_per_sec: 2760.0281857687287
avg_train_sample_per_sec: 2760.0281857687287
avg_episode_per_sec: 8.881828433688588
collect_time: 0.9007154393633825
reward_mean: 2396.6210109521257
reward_std: 702.2953389901651
reward_max: 3495.246228837086
reward_min: 1390.37092100673
total_envstep_count: 9162667
total_train_sample_count: 6913174
total_episode_count: 23768
total_duration: 1995.8148325659788
[2023-06-29 11:39:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1767
train_sample_count: 1767
avg_envstep_per_episode: 353.4
avg_sample_per_episode: 353.4
avg_envstep_per_sec: 2728.978662218518
avg_train_sample_per_sec: 2728.978662218518
avg_episode_per_sec: 7.722067521840741
collect_time: 0.6474949857480823
reward_mean: 2482.7214217564683
reward_std: 755.8443502952465
reward_max: 3492.1570339345103
reward_min: 1246.0480584351922
total_envstep_count: 9167267
total_train_sample_count: 6916541
total_episode_count: 23773
total_duration: 1996.462327551727
[2023-06-29 11:39:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2278
train_sample_count: 2278
avg_envstep_per_episode: 253.11111111111111
avg_sample_per_episode: 253.11111111111111
avg_envstep_per_sec: 2656.9572898450465
avg_train_sample_per_sec: 2656.9572898450465
avg_episode_per_sec: 10.497197369888243
collect_time: 0.8573717043576763
reward_mean: 2069.678876008378
reward_std: 879.220776664247
reward_max: 3442.243825485864
reward_min: 890.0662124856799
total_envstep_count: 9171963
total_train_sample_count: 6920019
total_episode_count: 23782
total_duration: 1997.3196992560847
[2023-06-29 11:39:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2193
train_sample_count: 2193
avg_envstep_per_episode: 365.5
avg_sample_per_episode: 365.5
avg_envstep_per_sec: 2754.7554875773617
avg_train_sample_per_sec: 2754.7554875773617
avg_episode_per_sec: 7.536950718405914
collect_time: 0.7960779132265596
reward_mean: 2728.881580615573
reward_std: 862.1873906649963
reward_max: 3580.8991849034155
reward_min: 1441.31649409459
total_envstep_count: 9176955
total_train_sample_count: 6923412
total_episode_count: 23788
total_duration: 1998.1157771693113
[2023-06-29 11:39:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3046
train_sample_count: 3046
avg_envstep_per_episode: 304.6
avg_sample_per_episode: 304.6
avg_envstep_per_sec: 2710.248915536909
avg_train_sample_per_sec: 2710.248915536909
avg_episode_per_sec: 8.89773117379156
collect_time: 1.1238820104449991
reward_mean: 2164.3392183876904
reward_std: 997.7959040855502
reward_max: 3559.8469260617376
reward_min: 849.7845476104372
total_envstep_count: 9181323
total_train_sample_count: 6926858
total_episode_count: 23798
total_duration: 1999.2396591797562
[2023-06-29 11:39:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2946
train_sample_count: 2946
avg_envstep_per_episode: 420.85714285714283
avg_sample_per_episode: 420.85714285714283
avg_envstep_per_sec: 2793.3671793551566
avg_train_sample_per_sec: 2793.3671793551566
avg_episode_per_sec: 6.6373286678499985
collect_time: 1.0546411591619254
reward_mean: 2290.564577775028
reward_std: 603.6375761680491
reward_max: 3549.7054538674324
reward_min: 1364.6830424525538
total_envstep_count: 9186195
total_train_sample_count: 6930204
total_episode_count: 23805
total_duration: 2000.2943003389182
[2023-06-29 11:39:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1729
train_sample_count: 1729
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 2718.6820712913527
avg_train_sample_per_sec: 2718.6820712913527
avg_episode_per_sec: 11.006810005228148
collect_time: 0.6359699128698556
reward_mean: 1766.6663279396987
reward_std: 769.6917528853809
reward_max: 3521.141764204149
reward_min: 900.5661136777178
total_envstep_count: 9190659
total_train_sample_count: 6933533
total_episode_count: 23812
total_duration: 2000.930270251788
[2023-06-29 11:39:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3292
train_sample_count: 3292
avg_envstep_per_episode: 299.27272727272725
avg_sample_per_episode: 299.27272727272725
avg_envstep_per_sec: 2613.50766750338
avg_train_sample_per_sec: 2613.50766750338
avg_episode_per_sec: 8.732862801499751
collect_time: 1.2596098496029158
reward_mean: 2012.791780431538
reward_std: 1002.9590831554784
reward_max: 3635.692227257437
reward_min: 698.0637304277532
total_envstep_count: 9195547
total_train_sample_count: 6936825
total_episode_count: 23823
total_duration: 2002.1898801013908
[2023-06-29 11:39:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2177
train_sample_count: 2177
avg_envstep_per_episode: 311.0
avg_sample_per_episode: 311.0
avg_envstep_per_sec: 2561.184446332023
avg_train_sample_per_sec: 2561.184446332023
avg_episode_per_sec: 8.235319763125476
collect_time: 0.8499973530285062
reward_mean: 1700.2574351319624
reward_std: 544.6864603313726
reward_max: 2620.6616368750742
reward_min: 967.0187070105435
total_envstep_count: 9199635
total_train_sample_count: 6940202
total_episode_count: 23830
total_duration: 2003.0398774544194
[2023-06-29 11:39:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2928
train_sample_count: 2928
avg_envstep_per_episode: 325.3333333333333
avg_sample_per_episode: 325.3333333333333
avg_envstep_per_sec: 2570.994113218808
avg_train_sample_per_sec: 2570.994113218808
avg_episode_per_sec: 7.9026458398119095
collect_time: 1.1388590837083759
reward_mean: 2033.6368778168892
reward_std: 867.3713943837811
reward_max: 3548.714447109313
reward_min: 1053.3992118517858
total_envstep_count: 9204323
total_train_sample_count: 6943530
total_episode_count: 23839
total_duration: 2004.1787365381279
[2023-06-29 11:39:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2284
train_sample_count: 2284
avg_envstep_per_episode: 326.2857142857143
avg_sample_per_episode: 326.2857142857143
avg_envstep_per_sec: 2711.130390047455
avg_train_sample_per_sec: 2711.130390047455
avg_episode_per_sec: 8.309068620986071
collect_time: 0.8424530256399883
reward_mean: 2012.2074682661114
reward_std: 758.1308493617231
reward_max: 3494.807081683188
reward_min: 986.3983792800906
total_envstep_count: 9209531
total_train_sample_count: 6947014
total_episode_count: 23846
total_duration: 2005.0211895637678
[2023-06-29 11:39:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2780
train_sample_count: 2780
avg_envstep_per_episode: 252.72727272727272
avg_sample_per_episode: 252.72727272727272
avg_envstep_per_sec: 2728.0277402078746
avg_train_sample_per_sec: 2728.0277402078746
avg_episode_per_sec: 10.794354367729
collect_time: 1.0190512211536988
reward_mean: 1798.0519082569676
reward_std: 924.2542302513032
reward_max: 3576.9362076737884
reward_min: 385.9194689346806
total_envstep_count: 9214491
total_train_sample_count: 6950594
total_episode_count: 23857
total_duration: 2006.0402407849215
[2023-06-29 11:39:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2521
train_sample_count: 2521
avg_envstep_per_episode: 210.08333333333334
avg_sample_per_episode: 210.08333333333334
avg_envstep_per_sec: 2618.1498066594595
avg_train_sample_per_sec: 2618.1498066594595
avg_episode_per_sec: 12.462434621147764
collect_time: 0.9628937173830345
reward_mean: 1461.6422204032413
reward_std: 774.3586936878764
reward_max: 3499.8516085828933
reward_min: 319.97184144994
total_envstep_count: 9219131
total_train_sample_count: 6953915
total_episode_count: 23869
total_duration: 2007.0031345023044
[2023-06-29 11:39:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1390
train_sample_count: 1390
avg_envstep_per_episode: 231.66666666666666
avg_sample_per_episode: 231.66666666666666
avg_envstep_per_sec: 2671.907219442963
avg_train_sample_per_sec: 2671.907219442963
avg_episode_per_sec: 11.533412458027179
collect_time: 0.5202276448393242
reward_mean: 1986.2803682106776
reward_std: 750.3100240009747
reward_max: 3493.2015566112664
reward_min: 1229.1995930397072
total_envstep_count: 9223651
total_train_sample_count: 6957305
total_episode_count: 23875
total_duration: 2007.5233621471436
[2023-06-29 11:39:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2428
train_sample_count: 2428
avg_envstep_per_episode: 242.8
avg_sample_per_episode: 242.8
avg_envstep_per_sec: 2733.470217441943
avg_train_sample_per_sec: 2733.470217441943
avg_episode_per_sec: 11.2581145693655
collect_time: 0.8882481998549775
reward_mean: 2002.58511420052
reward_std: 1004.3278715274959
reward_max: 3283.1242361714417
reward_min: 657.6093012831565
total_envstep_count: 9228539
total_train_sample_count: 6960533
total_episode_count: 23885
total_duration: 2008.4116103469987
[2023-06-29 11:39:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1441
train_sample_count: 1441
avg_envstep_per_episode: 180.125
avg_sample_per_episode: 180.125
avg_envstep_per_sec: 2740.2633033478946
avg_train_sample_per_sec: 2740.2633033478946
avg_episode_per_sec: 15.21312035168852
collect_time: 0.5258618754772469
reward_mean: 1705.4736827758093
reward_std: 811.9309987199371
reward_max: 3528.692725588192
reward_min: 843.0665917628035
total_envstep_count: 9232691
total_train_sample_count: 6963974
total_episode_count: 23893
total_duration: 2008.937472222476
[2023-06-29 11:40:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2073
train_sample_count: 2073
avg_envstep_per_episode: 259.125
avg_sample_per_episode: 259.125
avg_envstep_per_sec: 2786.782514061488
avg_train_sample_per_sec: 2786.782514061488
avg_episode_per_sec: 10.754587608534447
collect_time: 0.7438685974022373
reward_mean: 2069.148213852566
reward_std: 1055.9966958173377
reward_max: 3648.395120638297
reward_min: 816.3809547886366
total_envstep_count: 9237371
total_train_sample_count: 6967247
total_episode_count: 23901
total_duration: 2009.6813408198782
[2023-06-29 11:40:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2957
train_sample_count: 2957
avg_envstep_per_episode: 227.46153846153845
avg_sample_per_episode: 227.46153846153845
avg_envstep_per_sec: 2509.231666120602
avg_train_sample_per_sec: 2509.231666120602
avg_episode_per_sec: 11.03145473776389
collect_time: 1.1784483831943946
reward_mean: 1687.4663111539185
reward_std: 999.4781168801131
reward_max: 3667.5600065107856
reward_min: 856.7960961083011
total_envstep_count: 9241811
total_train_sample_count: 6970604
total_episode_count: 23914
total_duration: 2010.8597892030725
[2023-06-29 11:40:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2936
train_sample_count: 2936
avg_envstep_per_episode: 244.66666666666666
avg_sample_per_episode: 244.66666666666666
avg_envstep_per_sec: 2509.8985593030307
avg_train_sample_per_sec: 2509.8985593030307
avg_episode_per_sec: 10.258440978077783
collect_time: 1.1697683912832288
reward_mean: 1310.754067111787
reward_std: 639.4098877020331
reward_max: 2975.6803690004945
reward_min: 236.0664873988692
total_envstep_count: 9246307
total_train_sample_count: 6973940
total_episode_count: 23926
total_duration: 2012.0295575943558
[2023-06-29 11:40:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2341
train_sample_count: 2341
avg_envstep_per_episode: 292.625
avg_sample_per_episode: 292.625
avg_envstep_per_sec: 2795.755462857778
avg_train_sample_per_sec: 2795.755462857778
avg_episode_per_sec: 9.554055404896296
collect_time: 0.8373407585537062
reward_mean: 1726.419123357502
reward_std: 705.3810391748093
reward_max: 2531.7668944813286
reward_min: 397.1110777488168
total_envstep_count: 9251571
total_train_sample_count: 6977481
total_episode_count: 23934
total_duration: 2012.8668983529094
[2023-06-29 11:40:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2634
train_sample_count: 2634
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 2591.18872501408
avg_train_sample_per_sec: 2591.18872501408
avg_episode_per_sec: 11.80496002284319
collect_time: 1.0165218668067828
reward_mean: 1651.9785250607356
reward_std: 1028.4993134613571
reward_max: 3586.7925236337687
reward_min: 361.2898939036136
total_envstep_count: 9255795
total_train_sample_count: 6980915
total_episode_count: 23946
total_duration: 2013.883420219716
[2023-06-29 11:40:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2234
train_sample_count: 2234
avg_envstep_per_episode: 203.0909090909091
avg_sample_per_episode: 203.0909090909091
avg_envstep_per_sec: 2629.0461496431226
avg_train_sample_per_sec: 2629.0461496431226
avg_episode_per_sec: 12.945169044796039
collect_time: 0.8497378413472324
reward_mean: 1163.233055869595
reward_std: 515.0974067122688
reward_max: 2187.0433666281247
reward_min: 41.936271763178624
total_envstep_count: 9260635
total_train_sample_count: 6984349
total_episode_count: 23957
total_duration: 2014.7331580610632
[2023-06-29 11:40:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2646
train_sample_count: 2646
avg_envstep_per_episode: 203.53846153846155
avg_sample_per_episode: 203.53846153846155
avg_envstep_per_sec: 2480.834152760536
avg_train_sample_per_sec: 2480.834152760536
avg_episode_per_sec: 12.18852758347958
collect_time: 1.0665767387375236
reward_mean: 1512.3515217188283
reward_std: 782.3962640475748
reward_max: 3531.6964802037155
reward_min: 681.8121454359278
total_envstep_count: 9265003
total_train_sample_count: 6987795
total_episode_count: 23970
total_duration: 2015.7997347998007
[2023-06-29 11:40:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 208.58333333333334
avg_sample_per_episode: 208.58333333333334
avg_envstep_per_sec: 2542.4484690438258
avg_train_sample_per_sec: 2542.4484690438258
avg_episode_per_sec: 12.18912570056968
collect_time: 0.9844840634828436
reward_mean: 1243.7939267294603
reward_std: 473.74289668611533
reward_max: 2296.566784993295
reward_min: 799.8220784404443
total_envstep_count: 9269355
total_train_sample_count: 6991098
total_episode_count: 23982
total_duration: 2016.7842188632835
[2023-06-29 11:40:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1646
train_sample_count: 1646
avg_envstep_per_episode: 182.88888888888889
avg_sample_per_episode: 182.88888888888889
avg_envstep_per_sec: 2450.9773492109493
avg_train_sample_per_sec: 2450.9773492109493
avg_episode_per_sec: 13.401455736876395
collect_time: 0.6715688337674364
reward_mean: 1402.1752985719695
reward_std: 519.2594939016815
reward_max: 2502.447520582413
reward_min: 832.4691030824271
total_envstep_count: 9273555
total_train_sample_count: 6994344
total_episode_count: 23991
total_duration: 2017.455787697051
[2023-06-29 11:40:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3192
train_sample_count: 3192
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2791.5218565673904
avg_train_sample_per_sec: 2791.5218565673904
avg_episode_per_sec: 12.243516914769256
collect_time: 1.143462299064733
reward_mean: 1479.9655517694157
reward_std: 507.0443366056409
reward_max: 2501.1688627868284
reward_min: 813.0386485601717
total_envstep_count: 9278523
total_train_sample_count: 6997936
total_episode_count: 24005
total_duration: 2018.5992499961158
[2023-06-29 11:40:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2821
train_sample_count: 2821
avg_envstep_per_episode: 282.1
avg_sample_per_episode: 282.1
avg_envstep_per_sec: 2732.767657788176
avg_train_sample_per_sec: 2732.767657788176
avg_episode_per_sec: 9.687230265112285
collect_time: 1.032286807098426
reward_mean: 1595.9452393634083
reward_std: 684.7566862181922
reward_max: 3114.728724216399
reward_min: 536.7215971805474
total_envstep_count: 9282811
total_train_sample_count: 7001157
total_episode_count: 24015
total_duration: 2019.6315368032142
[2023-06-29 11:40:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3416
train_sample_count: 3416
avg_envstep_per_episode: 227.73333333333332
avg_sample_per_episode: 227.73333333333332
avg_envstep_per_sec: 2581.6512450190994
avg_train_sample_per_sec: 2581.6512450190994
avg_episode_per_sec: 11.336290595809862
collect_time: 1.3231841468093914
reward_mean: 1180.992878066899
reward_std: 559.0028726821981
reward_max: 2976.8128169060897
reward_min: 367.6203147307818
total_envstep_count: 9287691
total_train_sample_count: 7004573
total_episode_count: 24030
total_duration: 2020.9547209500236
[2023-06-29 11:40:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3013
train_sample_count: 3013
avg_envstep_per_episode: 231.76923076923077
avg_sample_per_episode: 231.76923076923077
avg_envstep_per_sec: 2572.0790417574826
avg_train_sample_per_sec: 2572.0790417574826
avg_episode_per_sec: 11.097586306952298
collect_time: 1.1714258975265548
reward_mean: 1236.7737030493504
reward_std: 299.8022206401391
reward_max: 1764.1324147938506
reward_min: 814.0056346718403
total_envstep_count: 9292667
total_train_sample_count: 7007986
total_episode_count: 24043
total_duration: 2022.1261468475502
[2023-06-29 11:40:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3431
train_sample_count: 3431
avg_envstep_per_episode: 285.9166666666667
avg_sample_per_episode: 285.9166666666667
avg_envstep_per_sec: 2579.366792725785
avg_train_sample_per_sec: 2579.366792725785
avg_episode_per_sec: 9.021393620725568
collect_time: 1.3301714241169393
reward_mean: 1603.5889040776572
reward_std: 747.8895251147595
reward_max: 3625.9814725890724
reward_min: 849.2422373096822
total_envstep_count: 9296739
total_train_sample_count: 7011417
total_episode_count: 24055
total_duration: 2023.4563182716672
[2023-06-29 11:40:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2370
train_sample_count: 2370
avg_envstep_per_episode: 338.57142857142856
avg_sample_per_episode: 338.57142857142856
avg_envstep_per_sec: 2756.292812516685
avg_train_sample_per_sec: 2756.292812516685
avg_episode_per_sec: 8.140949235281347
collect_time: 0.8598505896171558
reward_mean: 1540.5446522152622
reward_std: 517.7375704467366
reward_max: 2201.297124359934
reward_min: 875.1309115046117
total_envstep_count: 9301755
total_train_sample_count: 7014987
total_episode_count: 24062
total_duration: 2024.3161688612843
[2023-06-29 11:40:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2859
train_sample_count: 2859
avg_envstep_per_episode: 259.90909090909093
avg_sample_per_episode: 259.90909090909093
avg_envstep_per_sec: 2671.5952230281864
avg_train_sample_per_sec: 2671.5952230281864
avg_episode_per_sec: 10.27896028447361
collect_time: 1.0701471448056397
reward_mean: 1829.5673281254515
reward_std: 828.3710023367198
reward_max: 3347.886061891605
reward_min: 892.5950708168061
total_envstep_count: 9306395
total_train_sample_count: 7018246
total_episode_count: 24073
total_duration: 2025.3863160060898
[2023-06-29 11:40:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2293
train_sample_count: 2293
avg_envstep_per_episode: 254.77777777777777
avg_sample_per_episode: 254.77777777777777
avg_envstep_per_sec: 2521.779400028338
avg_train_sample_per_sec: 2521.779400028338
avg_episode_per_sec: 9.897956650787195
collect_time: 0.9092785831997172
reward_mean: 1545.5076841413238
reward_std: 565.8105740481436
reward_max: 2619.7109343473617
reward_min: 796.6236507350183
total_envstep_count: 9311235
total_train_sample_count: 7021739
total_episode_count: 24082
total_duration: 2026.2955945892895
[2023-06-29 11:40:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2346
train_sample_count: 2346
avg_envstep_per_episode: 234.6
avg_sample_per_episode: 234.6
avg_envstep_per_sec: 2520.7769032350834
avg_train_sample_per_sec: 2520.7769032350834
avg_episode_per_sec: 10.744999587532325
collect_time: 0.9306654615048319
reward_mean: 1852.9841178476368
reward_std: 778.2341875922352
reward_max: 3479.366828158536
reward_min: 977.8877462331214
total_envstep_count: 9316267
total_train_sample_count: 7025285
total_episode_count: 24092
total_duration: 2027.2262600507943
[2023-06-29 11:40:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2703
train_sample_count: 2703
avg_envstep_per_episode: 245.72727272727272
avg_sample_per_episode: 245.72727272727272
avg_envstep_per_sec: 2572.189560905135
avg_train_sample_per_sec: 2572.189560905135
avg_episode_per_sec: 10.467660070276168
collect_time: 1.0508556760679932
reward_mean: 1777.8329828059743
reward_std: 427.29768350613404
reward_max: 2388.5574638454705
reward_min: 1255.7410316865328
total_envstep_count: 9321387
total_train_sample_count: 7028788
total_episode_count: 24103
total_duration: 2028.2771157268623
[2023-06-29 11:41:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2909
train_sample_count: 2909
avg_envstep_per_episode: 242.41666666666666
avg_sample_per_episode: 242.41666666666666
avg_envstep_per_sec: 2816.3396174270783
avg_train_sample_per_sec: 2816.3396174270783
avg_episode_per_sec: 11.61776397701098
collect_time: 1.032900997450575
reward_mean: 1604.2103657120924
reward_std: 458.6341151252466
reward_max: 2692.3888537206644
reward_min: 1015.4677076464774
total_envstep_count: 9325603
total_train_sample_count: 7032097
total_episode_count: 24115
total_duration: 2029.3100167243128
[2023-06-29 11:41:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2136
train_sample_count: 2136
avg_envstep_per_episode: 237.33333333333334
avg_sample_per_episode: 237.33333333333334
avg_envstep_per_sec: 2494.419041303545
avg_train_sample_per_sec: 2494.419041303545
avg_episode_per_sec: 10.510192589762127
collect_time: 0.8563116159038617
reward_mean: 1378.180455759094
reward_std: 407.1677367582601
reward_max: 2251.60969148694
reward_min: 800.4698346432333
total_envstep_count: 9329795
total_train_sample_count: 7035433
total_episode_count: 24124
total_duration: 2030.1663283402168
[2023-06-29 11:41:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1464
train_sample_count: 1464
avg_envstep_per_episode: 244.0
avg_sample_per_episode: 244.0
avg_envstep_per_sec: 2411.2625537219706
avg_train_sample_per_sec: 2411.2625537219706
avg_episode_per_sec: 9.882223580827748
collect_time: 0.6071508047683163
reward_mean: 2005.2970061780568
reward_std: 553.0113857442524
reward_max: 2764.77079584982
reward_min: 1360.5509089225286
total_envstep_count: 9335179
total_train_sample_count: 7039297
total_episode_count: 24130
total_duration: 2030.773479144985
[2023-06-29 11:41:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3190
train_sample_count: 3190
avg_envstep_per_episode: 265.8333333333333
avg_sample_per_episode: 265.8333333333333
avg_envstep_per_sec: 2631.898303966538
avg_train_sample_per_sec: 2631.898303966538
avg_episode_per_sec: 9.900557883259705
collect_time: 1.2120529107041658
reward_mean: 2223.233314662651
reward_std: 920.3426997949027
reward_max: 3592.429134155961
reward_min: 1044.5985873961818
total_envstep_count: 9340131
total_train_sample_count: 7042887
total_episode_count: 24142
total_duration: 2031.9855320556892
[2023-06-29 11:41:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2851
train_sample_count: 2851
avg_envstep_per_episode: 285.1
avg_sample_per_episode: 285.1
avg_envstep_per_sec: 2583.676682316017
avg_train_sample_per_sec: 2583.676682316017
avg_episode_per_sec: 9.062352445864668
collect_time: 1.1034662423180417
reward_mean: 1629.9514585465745
reward_std: 475.702300374386
reward_max: 2246.8968027263436
reward_min: 840.3735526925719
total_envstep_count: 9344595
total_train_sample_count: 7046138
total_episode_count: 24152
total_duration: 2033.0889982980073
[2023-06-29 11:41:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3082
train_sample_count: 3082
avg_envstep_per_episode: 256.8333333333333
avg_sample_per_episode: 256.8333333333333
avg_envstep_per_sec: 2701.072122321396
avg_train_sample_per_sec: 2701.072122321396
avg_episode_per_sec: 10.516828510011925
collect_time: 1.1410283992532644
reward_mean: 1449.976436023675
reward_std: 735.3634106521721
reward_max: 3580.035664552645
reward_min: 683.1817189082557
total_envstep_count: 9349635
total_train_sample_count: 7049620
total_episode_count: 24164
total_duration: 2034.2300266972604
[2023-06-29 11:41:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2698
train_sample_count: 2698
avg_envstep_per_episode: 245.27272727272728
avg_sample_per_episode: 245.27272727272728
avg_envstep_per_sec: 2757.502351850164
avg_train_sample_per_sec: 2757.502351850164
avg_episode_per_sec: 11.242596690271238
collect_time: 0.9784216496460137
reward_mean: 1516.9422906284256
reward_std: 362.4213299557106
reward_max: 2201.8226347498894
reward_min: 1039.4998917470746
total_envstep_count: 9354323
total_train_sample_count: 7053118
total_episode_count: 24175
total_duration: 2035.2084483469064
[2023-06-29 11:41:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2624
train_sample_count: 2624
avg_envstep_per_episode: 291.55555555555554
avg_sample_per_episode: 291.55555555555554
avg_envstep_per_sec: 2597.0720356658785
avg_train_sample_per_sec: 2597.0720356658785
avg_episode_per_sec: 8.907640366232053
collect_time: 1.0103685858398677
reward_mean: 1859.4446773882814
reward_std: 645.7043812080042
reward_max: 3423.570526904136
reward_min: 1033.1346033218529
total_envstep_count: 9359003
total_train_sample_count: 7056542
total_episode_count: 24184
total_duration: 2036.2188169327462
[2023-06-29 11:41:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2338
train_sample_count: 2338
avg_envstep_per_episode: 233.8
avg_sample_per_episode: 233.8
avg_envstep_per_sec: 2641.8563551666593
avg_train_sample_per_sec: 2641.8563551666593
avg_episode_per_sec: 11.29964223766749
collect_time: 0.8849837711378934
reward_mean: 1592.863252127251
reward_std: 616.0524425888703
reward_max: 2498.4172874033097
reward_min: 722.6815944247454
total_envstep_count: 9364115
total_train_sample_count: 7060080
total_episode_count: 24194
total_duration: 2037.1038007038842
[2023-06-29 11:41:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 203.9
avg_sample_per_episode: 203.9
avg_envstep_per_sec: 2721.062324860638
avg_train_sample_per_sec: 2721.062324860638
avg_episode_per_sec: 13.345082515255704
collect_time: 0.7493396903742106
reward_mean: 1755.0049344537742
reward_std: 620.8128865085804
reward_max: 3225.2395121455934
reward_min: 1119.8588047195246
total_envstep_count: 9368755
total_train_sample_count: 7063319
total_episode_count: 24204
total_duration: 2037.8531403942584
[2023-06-29 11:41:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1888
train_sample_count: 1888
avg_envstep_per_episode: 269.7142857142857
avg_sample_per_episode: 269.7142857142857
avg_envstep_per_sec: 2737.5210926904083
avg_train_sample_per_sec: 2737.5210926904083
avg_episode_per_sec: 10.1497074411191
collect_time: 0.6896750512868167
reward_mean: 2133.1662627470537
reward_std: 730.1507186134777
reward_max: 2986.0575229775504
reward_min: 1301.6492263200503
total_envstep_count: 9373987
total_train_sample_count: 7066807
total_episode_count: 24211
total_duration: 2038.542815445545
[2023-06-29 11:41:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 188.33333333333334
avg_sample_per_episode: 188.33333333333334
avg_envstep_per_sec: 2740.516490138657
avg_train_sample_per_sec: 2740.516490138657
avg_episode_per_sec: 14.551414991886675
collect_time: 0.4123310347031801
reward_mean: 2528.033205013573
reward_std: 861.4940004192378
reward_max: 3644.193890524804
reward_min: 1617.5016116385143
total_envstep_count: 9378619
total_train_sample_count: 7070337
total_episode_count: 24217
total_duration: 2038.9551464802482
[2023-06-29 11:41:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2028
train_sample_count: 2028
avg_envstep_per_episode: 202.8
avg_sample_per_episode: 202.8
avg_envstep_per_sec: 2511.3523172581954
avg_train_sample_per_sec: 2511.3523172581954
avg_episode_per_sec: 12.38339406932049
collect_time: 0.8075330514414234
reward_mean: 2111.391421888534
reward_std: 887.8709590164879
reward_max: 3553.5667387234207
reward_min: 823.2759828494011
total_envstep_count: 9382883
total_train_sample_count: 7073565
total_episode_count: 24227
total_duration: 2039.7626795316896
[2023-06-29 11:41:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2211
train_sample_count: 2211
avg_envstep_per_episode: 245.66666666666666
avg_sample_per_episode: 245.66666666666666
avg_envstep_per_sec: 2667.897241392344
avg_train_sample_per_sec: 2667.897241392344
avg_episode_per_sec: 10.859825948679825
collect_time: 0.8287425638800486
reward_mean: 1870.4302118185628
reward_std: 728.3719773022547
reward_max: 3571.737604654768
reward_min: 1128.2251219293173
total_envstep_count: 9387051
total_train_sample_count: 7076976
total_episode_count: 24236
total_duration: 2040.5914220955697
[2023-06-29 11:41:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2109
train_sample_count: 2109
avg_envstep_per_episode: 301.2857142857143
avg_sample_per_episode: 301.2857142857143
avg_envstep_per_sec: 2760.0527840961163
avg_train_sample_per_sec: 2760.0527840961163
avg_episode_per_sec: 9.160914883201903
collect_time: 0.7641158213177695
reward_mean: 2188.3818445712022
reward_std: 768.8021059815533
reward_max: 3538.6415596730344
reward_min: 1376.6799762581581
total_envstep_count: 9392123
total_train_sample_count: 7080285
total_episode_count: 24243
total_duration: 2041.3555379168874
[2023-06-29 11:41:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1905
train_sample_count: 1905
avg_envstep_per_episode: 272.14285714285717
avg_sample_per_episode: 272.14285714285717
avg_envstep_per_sec: 2777.500263144425
avg_train_sample_per_sec: 2777.500263144425
avg_episode_per_sec: 10.206037712341718
collect_time: 0.6858685218784959
reward_mean: 2424.2571879793854
reward_std: 561.3053857305471
reward_max: 3443.327798180844
reward_min: 1935.7694161411039
total_envstep_count: 9397187
total_train_sample_count: 7083790
total_episode_count: 24250
total_duration: 2042.041406438766
[2023-06-29 11:41:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2109
train_sample_count: 2109
avg_envstep_per_episode: 210.9
avg_sample_per_episode: 210.9
avg_envstep_per_sec: 2775.968666808959
avg_train_sample_per_sec: 2775.968666808959
avg_episode_per_sec: 13.162487751583495
collect_time: 0.7597348000416535
reward_mean: 1900.8584251014468
reward_std: 811.1627732020048
reward_max: 3567.3423348047
reward_min: 485.54707521375815
total_envstep_count: 9401835
total_train_sample_count: 7087099
total_episode_count: 24260
total_duration: 2042.8011412388075
[2023-06-29 11:41:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2134
train_sample_count: 2134
avg_envstep_per_episode: 237.11111111111111
avg_sample_per_episode: 237.11111111111111
avg_envstep_per_sec: 2592.1768728379043
avg_train_sample_per_sec: 2592.1768728379043
avg_episode_per_sec: 10.932329829213279
collect_time: 0.8232462924737485
reward_mean: 1896.2666086542927
reward_std: 747.3018814661716
reward_max: 3586.418432520821
reward_min: 1137.2504176729574
total_envstep_count: 9406347
total_train_sample_count: 7090433
total_episode_count: 24269
total_duration: 2043.6243875312812
[2023-06-29 11:41:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1654
train_sample_count: 1654
avg_envstep_per_episode: 275.6666666666667
avg_sample_per_episode: 275.6666666666667
avg_envstep_per_sec: 2679.9605667647043
avg_train_sample_per_sec: 2679.9605667647043
avg_episode_per_sec: 9.72174328935201
collect_time: 0.617173260126263
reward_mean: 2306.1856551347637
reward_std: 595.6504188462515
reward_max: 3545.6683431820966
reward_min: 1768.8043928902375
total_envstep_count: 9411011
total_train_sample_count: 7093687
total_episode_count: 24275
total_duration: 2044.2415607914074
[2023-06-29 11:42:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2084
train_sample_count: 2084
avg_envstep_per_episode: 231.55555555555554
avg_sample_per_episode: 231.55555555555554
avg_envstep_per_sec: 2740.908302441143
avg_train_sample_per_sec: 2740.908302441143
avg_episode_per_sec: 11.836936047010694
collect_time: 0.7603318936806172
reward_mean: 2292.389280851237
reward_std: 793.8713106639182
reward_max: 3631.0713541729206
reward_min: 1407.8393274190078
total_envstep_count: 9415323
total_train_sample_count: 7096971
total_episode_count: 24284
total_duration: 2045.001892685088
[2023-06-29 11:42:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2123
train_sample_count: 2123
avg_envstep_per_episode: 303.2857142857143
avg_sample_per_episode: 303.2857142857143
avg_envstep_per_sec: 2757.2320359443797
avg_train_sample_per_sec: 2757.2320359443797
avg_episode_per_sec: 9.091203133118539
collect_time: 0.7699750954303892
reward_mean: 2032.3598084385744
reward_std: 562.1848924859029
reward_max: 2808.0070566881022
reward_min: 1334.3542244334094
total_envstep_count: 9419667
total_train_sample_count: 7100294
total_episode_count: 24291
total_duration: 2045.7718677805185
[2023-06-29 11:42:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1769
train_sample_count: 1769
avg_envstep_per_episode: 252.71428571428572
avg_sample_per_episode: 252.71428571428572
avg_envstep_per_sec: 2483.036544918887
avg_train_sample_per_sec: 2483.036544918887
avg_episode_per_sec: 9.82546965202499
collect_time: 0.7124341377979145
reward_mean: 2154.5421166463884
reward_std: 888.7583123517503
reward_max: 3524.4794476106767
reward_min: 1325.4602302657293
total_envstep_count: 9423851
total_train_sample_count: 7103663
total_episode_count: 24298
total_duration: 2046.4843019183165
[2023-06-29 11:42:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1516
train_sample_count: 1516
avg_envstep_per_episode: 379.0
avg_sample_per_episode: 379.0
avg_envstep_per_sec: 2728.0362640967514
avg_train_sample_per_sec: 2728.0362640967514
avg_episode_per_sec: 7.1979848656906364
collect_time: 0.5557110878443345
reward_mean: 3176.755365132626
reward_std: 605.9529261087453
reward_max: 3557.7093259839194
reward_min: 2128.31484109561
total_envstep_count: 9428531
total_train_sample_count: 7107179
total_episode_count: 24302
total_duration: 2047.040013006161
[2023-06-29 11:42:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1930
train_sample_count: 1930
avg_envstep_per_episode: 275.7142857142857
avg_sample_per_episode: 275.7142857142857
avg_envstep_per_sec: 2666.8193853225753
avg_train_sample_per_sec: 2666.8193853225753
avg_episode_per_sec: 9.672401915677735
collect_time: 0.7237085535759106
reward_mean: 2669.6968557411697
reward_std: 911.4692224074081
reward_max: 3546.455459075113
reward_min: 1058.543446237475
total_envstep_count: 9433891
total_train_sample_count: 7110709
total_episode_count: 24309
total_duration: 2047.763721559737
[2023-06-29 11:42:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2299
train_sample_count: 2299
avg_envstep_per_episode: 287.375
avg_sample_per_episode: 287.375
avg_envstep_per_sec: 2729.3810253272045
avg_train_sample_per_sec: 2729.3810253272045
avg_episode_per_sec: 9.497628622278224
collect_time: 0.8423155208695681
reward_mean: 2787.3422451144706
reward_std: 753.4840343595823
reward_max: 3546.9850463530915
reward_min: 1169.7243526306427
total_envstep_count: 9438291
total_train_sample_count: 7114208
total_episode_count: 24317
total_duration: 2048.6060370806067
[2023-06-29 11:42:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1822
train_sample_count: 1822
avg_envstep_per_episode: 303.6666666666667
avg_sample_per_episode: 303.6666666666667
avg_envstep_per_sec: 2508.5074385201447
avg_train_sample_per_sec: 2508.5074385201447
avg_episode_per_sec: 8.260727020373693
collect_time: 0.7263283225800841
reward_mean: 2099.214804880273
reward_std: 1024.3639112175536
reward_max: 3547.675618554898
reward_min: 1113.656070921431
total_envstep_count: 9443107
total_train_sample_count: 7117630
total_episode_count: 24323
total_duration: 2049.332365403187
[2023-06-29 11:42:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2603
train_sample_count: 2603
avg_envstep_per_episode: 236.63636363636363
avg_sample_per_episode: 236.63636363636363
avg_envstep_per_sec: 2520.7029354629585
avg_train_sample_per_sec: 2520.7029354629585
avg_episode_per_sec: 10.652221394580309
collect_time: 1.0326484582452102
reward_mean: 1915.573155100352
reward_std: 902.1478462578613
reward_max: 3497.1198394262906
reward_min: 564.7883570247988
total_envstep_count: 9447563
total_train_sample_count: 7121033
total_episode_count: 24334
total_duration: 2050.365013861432
[2023-06-29 11:42:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2256
train_sample_count: 2256
avg_envstep_per_episode: 250.66666666666666
avg_sample_per_episode: 250.66666666666666
avg_envstep_per_sec: 2492.8670763815353
avg_train_sample_per_sec: 2492.8670763815353
avg_episode_per_sec: 9.944948443011445
collect_time: 0.904982067184523
reward_mean: 1593.5083546034728
reward_std: 462.52287278848206
reward_max: 2591.8664715367
reward_min: 845.9514065960283
total_envstep_count: 9452771
total_train_sample_count: 7124489
total_episode_count: 24343
total_duration: 2051.2699959286165
[2023-06-29 11:42:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3082
train_sample_count: 3082
avg_envstep_per_episode: 256.8333333333333
avg_sample_per_episode: 256.8333333333333
avg_envstep_per_sec: 2787.6908665542574
avg_train_sample_per_sec: 2787.6908665542574
avg_episode_per_sec: 10.854085139082118
collect_time: 1.105574522977695
reward_mean: 1906.631922998662
reward_std: 890.5656455078437
reward_max: 3522.874675515475
reward_min: 410.548647910454
total_envstep_count: 9457603
total_train_sample_count: 7127971
total_episode_count: 24355
total_duration: 2052.3755704515943
[2023-06-29 11:42:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2177
train_sample_count: 2177
avg_envstep_per_episode: 311.0
avg_sample_per_episode: 311.0
avg_envstep_per_sec: 2745.158182214266
avg_train_sample_per_sec: 2745.158182214266
avg_episode_per_sec: 8.826875183968701
collect_time: 0.7930326252616943
reward_mean: 1951.9129835508595
reward_std: 452.78857770164126
reward_max: 2697.5860669463186
reward_min: 1491.5225865613522
total_envstep_count: 9462243
total_train_sample_count: 7131348
total_episode_count: 24362
total_duration: 2053.168603076856
[2023-06-29 11:42:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1879
train_sample_count: 1879
avg_envstep_per_episode: 313.1666666666667
avg_sample_per_episode: 313.1666666666667
avg_envstep_per_sec: 2506.7096125556996
avg_train_sample_per_sec: 2506.7096125556996
avg_episode_per_sec: 8.004394718112932
collect_time: 0.7495882213832809
reward_mean: 2538.2877286025296
reward_std: 572.4266184354958
reward_max: 3565.4602135841355
reward_min: 1858.592489233783
total_envstep_count: 9466955
total_train_sample_count: 7134827
total_episode_count: 24368
total_duration: 2053.9181912982394
[2023-06-29 11:42:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2526
train_sample_count: 2526
avg_envstep_per_episode: 315.75
avg_sample_per_episode: 315.75
avg_envstep_per_sec: 2525.8657565463895
avg_train_sample_per_sec: 2525.8657565463895
avg_episode_per_sec: 7.999574842585557
collect_time: 1.0000531475013121
reward_mean: 2430.0438158141533
reward_std: 906.5519424833974
reward_max: 3644.9562147625325
reward_min: 1404.8824843175619
total_envstep_count: 9471483
total_train_sample_count: 7138153
total_episode_count: 24376
total_duration: 2054.9182444457406
[2023-06-29 11:42:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1199
train_sample_count: 1199
avg_envstep_per_episode: 239.8
avg_sample_per_episode: 239.8
avg_envstep_per_sec: 2732.28657615145
avg_train_sample_per_sec: 2732.28657615145
avg_episode_per_sec: 11.394022419313803
collect_time: 0.4388265895918012
reward_mean: 2283.451863565374
reward_std: 738.8053469491226
reward_max: 3679.437222674302
reward_min: 1475.1002402663794
total_envstep_count: 9476475
total_train_sample_count: 7141752
total_episode_count: 24381
total_duration: 2055.3570710353324
[2023-06-29 11:42:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 182.66666666666666
avg_sample_per_episode: 182.66666666666666
avg_envstep_per_sec: 2773.472184449794
avg_train_sample_per_sec: 2773.472184449794
avg_episode_per_sec: 15.183241885674054
collect_time: 0.5927587841758505
reward_mean: 2277.5276416882716
reward_std: 832.0724677325379
reward_max: 3450.4868187684315
reward_min: 1309.0615755237357
total_envstep_count: 9480611
total_train_sample_count: 7144996
total_episode_count: 24390
total_duration: 2055.949829819508
[2023-06-29 11:42:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1782
train_sample_count: 1782
avg_envstep_per_episode: 222.75
avg_sample_per_episode: 222.75
avg_envstep_per_sec: 2569.996772996483
avg_train_sample_per_sec: 2569.996772996483
avg_episode_per_sec: 11.537583717155927
collect_time: 0.6933860846534373
reward_mean: 1996.596221131616
reward_std: 479.81751019770473
reward_max: 2739.6427750823723
reward_min: 1263.7134513532462
total_envstep_count: 9485451
total_train_sample_count: 7148378
total_episode_count: 24398
total_duration: 2056.6432159041615
[2023-06-29 11:42:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1861
train_sample_count: 1861
avg_envstep_per_episode: 206.77777777777777
avg_sample_per_episode: 206.77777777777777
avg_envstep_per_sec: 2525.0321971609583
avg_train_sample_per_sec: 2525.0321971609583
avg_episode_per_sec: 12.211332495673629
collect_time: 0.7370203049657867
reward_mean: 2043.9937181215184
reward_std: 593.9826853384149
reward_max: 3306.5440916240204
reward_min: 1420.883623651542
total_envstep_count: 9490195
total_train_sample_count: 7151839
total_episode_count: 24407
total_duration: 2057.3802362091274
[2023-06-29 11:42:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2501
train_sample_count: 2501
avg_envstep_per_episode: 277.8888888888889
avg_sample_per_episode: 277.8888888888889
avg_envstep_per_sec: 2717.293009237206
avg_train_sample_per_sec: 2717.293009237206
avg_episode_per_sec: 9.7783434958556
collect_time: 0.9204012933084741
reward_mean: 2201.3672914041545
reward_std: 629.2477622670257
reward_max: 3299.784086515021
reward_min: 1175.5599534246473
total_envstep_count: 9494811
total_train_sample_count: 7155140
total_episode_count: 24416
total_duration: 2058.3006375024356
[2023-06-29 11:42:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3093
train_sample_count: 3093
avg_envstep_per_episode: 281.1818181818182
avg_sample_per_episode: 281.1818181818182
avg_envstep_per_sec: 2605.057193784576
avg_train_sample_per_sec: 2605.057193784576
avg_episode_per_sec: 9.264671558884686
collect_time: 1.187305985979736
reward_mean: 1655.2162675010643
reward_std: 297.78477890084395
reward_max: 2381.644994246006
reward_min: 1261.9538231536403
total_envstep_count: 9499651
total_train_sample_count: 7158633
total_episode_count: 24427
total_duration: 2059.4879434884156
[2023-06-29 11:43:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2335
train_sample_count: 2335
avg_envstep_per_episode: 291.875
avg_sample_per_episode: 291.875
avg_envstep_per_sec: 2732.108548310328
avg_train_sample_per_sec: 2732.108548310328
avg_episode_per_sec: 9.360543206202408
collect_time: 0.8546512551428751
reward_mean: 1956.902413564795
reward_std: 707.2811963663429
reward_max: 3538.7268025016224
reward_min: 1199.427870196128
total_envstep_count: 9504027
total_train_sample_count: 7162168
total_episode_count: 24435
total_duration: 2060.3425947435585
[2023-06-29 11:43:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2638
train_sample_count: 2638
avg_envstep_per_episode: 263.8
avg_sample_per_episode: 263.8
avg_envstep_per_sec: 2545.9634370367403
avg_train_sample_per_sec: 2545.9634370367403
avg_episode_per_sec: 9.651112346613877
collect_time: 1.0361499939961358
reward_mean: 1691.0534311513584
reward_std: 520.6542069941444
reward_max: 2717.34366458904
reward_min: 982.5801460142393
total_envstep_count: 9508451
total_train_sample_count: 7165606
total_episode_count: 24445
total_duration: 2061.378744737555
[2023-06-29 11:43:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2142
train_sample_count: 2142
avg_envstep_per_episode: 267.75
avg_sample_per_episode: 267.75
avg_envstep_per_sec: 2494.473170380621
avg_train_sample_per_sec: 2494.473170380621
avg_episode_per_sec: 9.316426406650312
collect_time: 0.8586983517939226
reward_mean: 1810.0239679803385
reward_std: 361.4450025441054
reward_max: 2325.652278396995
reward_min: 1289.2046153454412
total_envstep_count: 9512867
total_train_sample_count: 7168948
total_episode_count: 24453
total_duration: 2062.2374430893487
[2023-06-29 11:43:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2486
train_sample_count: 2486
avg_envstep_per_episode: 310.75
avg_sample_per_episode: 310.75
avg_envstep_per_sec: 2568.8220557291015
avg_train_sample_per_sec: 2568.8220557291015
avg_episode_per_sec: 8.266523107736448
collect_time: 0.9677587415818125
reward_mean: 2181.6458687796144
reward_std: 683.4611356335867
reward_max: 3268.1904979317305
reward_min: 1418.1512195004107
total_envstep_count: 9517603
total_train_sample_count: 7172234
total_episode_count: 24461
total_duration: 2063.2052018309305
[2023-06-29 11:43:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 181.83333333333334
avg_sample_per_episode: 181.83333333333334
avg_envstep_per_sec: 2701.6916338144542
avg_train_sample_per_sec: 2701.6916338144542
avg_episode_per_sec: 14.858065813828345
collect_time: 0.4038210676396266
reward_mean: 1737.156027040666
reward_std: 375.23194117865023
reward_max: 2428.882864612708
reward_min: 1195.183770833656
total_envstep_count: 9522347
total_train_sample_count: 7175725
total_episode_count: 24467
total_duration: 2063.60902289857
[2023-06-29 11:43:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1852
train_sample_count: 1852
avg_envstep_per_episode: 264.57142857142856
avg_sample_per_episode: 264.57142857142856
avg_envstep_per_sec: 2687.1395528895773
avg_train_sample_per_sec: 2687.1395528895773
avg_episode_per_sec: 10.156574983923889
collect_time: 0.6892087156428024
reward_mean: 2765.73483014305
reward_std: 656.626380348577
reward_max: 3613.756091387077
reward_min: 1687.9743429521134
total_envstep_count: 9526691
total_train_sample_count: 7179177
total_episode_count: 24474
total_duration: 2064.298231614213
[2023-06-29 11:43:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 2598.5432141730444
avg_train_sample_per_sec: 2598.5432141730444
avg_episode_per_sec: 17.98299802195878
collect_time: 0.33364848245400935
reward_mean: 2171.813678984126
reward_std: 1048.7681133805052
reward_max: 3587.139663778302
reward_min: 878.644264212805
total_envstep_count: 9530139
total_train_sample_count: 7182444
total_episode_count: 24480
total_duration: 2064.631880096667
[2023-06-29 11:43:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 207.2
avg_sample_per_episode: 207.2
avg_envstep_per_sec: 2757.1218485617046
avg_train_sample_per_sec: 2757.1218485617046
avg_episode_per_sec: 13.306572628193555
collect_time: 0.7515083169359711
reward_mean: 1851.6847961409633
reward_std: 700.7535727794393
reward_max: 2670.864869241534
reward_min: 256.842814963817
total_envstep_count: 9534355
total_train_sample_count: 7185716
total_episode_count: 24490
total_duration: 2065.383388413603
[2023-06-29 11:43:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3275
train_sample_count: 3275
avg_envstep_per_episode: 327.5
avg_sample_per_episode: 327.5
avg_envstep_per_sec: 2785.3070309681552
avg_train_sample_per_sec: 2785.3070309681552
avg_episode_per_sec: 8.504754293032535
collect_time: 1.1758129224488514
reward_mean: 1971.3494341117141
reward_std: 664.3684255139244
reward_max: 3551.2284718577503
reward_min: 1216.4262403014093
total_envstep_count: 9538763
total_train_sample_count: 7188991
total_episode_count: 24500
total_duration: 2066.559201336052
[2023-06-29 11:43:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2245
train_sample_count: 2245
avg_envstep_per_episode: 249.44444444444446
avg_sample_per_episode: 249.44444444444446
avg_envstep_per_sec: 2697.953064343077
avg_train_sample_per_sec: 2697.953064343077
avg_episode_per_sec: 10.815847473981156
collect_time: 0.8321123260706663
reward_mean: 1303.6311265683055
reward_std: 314.24704390556076
reward_max: 1976.8392858445302
reward_min: 769.853528499862
total_envstep_count: 9543075
total_train_sample_count: 7192436
total_episode_count: 24509
total_duration: 2067.3913136621227
[2023-06-29 11:43:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2070
train_sample_count: 2070
avg_envstep_per_episode: 345.0
avg_sample_per_episode: 345.0
avg_envstep_per_sec: 2478.0935232746474
avg_train_sample_per_sec: 2478.0935232746474
avg_episode_per_sec: 7.182879777607673
collect_time: 0.8353195634298027
reward_mean: 2498.6900135891883
reward_std: 664.8742511638817
reward_max: 3410.3597760215284
reward_min: 1465.4039076389224
total_envstep_count: 9546931
total_train_sample_count: 7195706
total_episode_count: 24515
total_duration: 2068.2266332255526
[2023-06-29 11:43:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2294
train_sample_count: 2294
avg_envstep_per_episode: 286.75
avg_sample_per_episode: 286.75
avg_envstep_per_sec: 2490.815374987223
avg_train_sample_per_sec: 2490.815374987223
avg_episode_per_sec: 8.686365736659889
collect_time: 0.9209835554398597
reward_mean: 1834.258561651107
reward_std: 802.3500948527392
reward_max: 3490.8685894754326
reward_min: 934.3444583214567
total_envstep_count: 9551619
total_train_sample_count: 7199200
total_episode_count: 24523
total_duration: 2069.1476167809924
[2023-06-29 11:43:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2160
train_sample_count: 2160
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2732.5527011130957
avg_train_sample_per_sec: 2732.5527011130957
avg_episode_per_sec: 12.650706949597666
collect_time: 0.7904696583235638
reward_mean: 1594.559899166559
reward_std: 932.6862944192777
reward_max: 3609.4125908796136
reward_min: 446.0105379968063
total_envstep_count: 9556203
total_train_sample_count: 7202560
total_episode_count: 24533
total_duration: 2069.938086439316
[2023-06-29 11:43:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2939
train_sample_count: 2939
avg_envstep_per_episode: 267.1818181818182
avg_sample_per_episode: 267.1818181818182
avg_envstep_per_sec: 2716.718298977663
avg_train_sample_per_sec: 2716.718298977663
avg_episode_per_sec: 10.168050795765327
collect_time: 1.081819929989055
reward_mean: 1732.7490491789547
reward_std: 449.97108355062034
reward_max: 2601.846046005558
reward_min: 1268.0328369344302
total_envstep_count: 9560875
total_train_sample_count: 7205899
total_episode_count: 24544
total_duration: 2071.0199063693053
[2023-06-29 11:43:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2222
train_sample_count: 2222
avg_envstep_per_episode: 246.88888888888889
avg_sample_per_episode: 246.88888888888889
avg_envstep_per_sec: 2567.413290733712
avg_train_sample_per_sec: 2567.413290733712
avg_episode_per_sec: 10.399063733844917
collect_time: 0.865462529161014
reward_mean: 1576.937021534366
reward_std: 844.4391662693166
reward_max: 3448.8673778389248
reward_min: 758.684022999352
total_envstep_count: 9565371
total_train_sample_count: 7209321
total_episode_count: 24553
total_duration: 2071.8853688984664
[2023-06-29 11:43:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2594
train_sample_count: 2594
avg_envstep_per_episode: 324.25
avg_sample_per_episode: 324.25
avg_envstep_per_sec: 2565.903508801013
avg_train_sample_per_sec: 2565.903508801013
avg_episode_per_sec: 7.9133492946831545
collect_time: 1.0109499406749383
reward_mean: 2252.699005973658
reward_std: 799.1560999290913
reward_max: 3473.402585550604
reward_min: 1283.53980360306
total_envstep_count: 9569843
total_train_sample_count: 7212715
total_episode_count: 24561
total_duration: 2072.8963188391413
[2023-06-29 11:43:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2295
train_sample_count: 2295
avg_envstep_per_episode: 286.875
avg_sample_per_episode: 286.875
avg_envstep_per_sec: 2539.1549889461544
avg_train_sample_per_sec: 2539.1549889461544
avg_episode_per_sec: 8.851084928788337
collect_time: 0.9038439992796627
reward_mean: 1833.0670984081223
reward_std: 574.2625765019128
reward_max: 2660.3195555872203
reward_min: 750.1931959223041
total_envstep_count: 9574243
total_train_sample_count: 7216210
total_episode_count: 24569
total_duration: 2073.800162838421
[2023-06-29 11:43:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 237.27272727272728
avg_sample_per_episode: 237.27272727272728
avg_envstep_per_sec: 2704.473695040154
avg_train_sample_per_sec: 2704.473695040154
avg_episode_per_sec: 11.398164998253522
collect_time: 0.9650676228748636
reward_mean: 1581.1760029646948
reward_std: 658.3479113862875
reward_max: 3029.04932536839
reward_min: 855.3709105566037
total_envstep_count: 9578643
total_train_sample_count: 7219620
total_episode_count: 24580
total_duration: 2074.7652304612957
[2023-06-29 11:43:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2473
train_sample_count: 2473
avg_envstep_per_episode: 309.125
avg_sample_per_episode: 309.125
avg_envstep_per_sec: 2464.693670716305
avg_train_sample_per_sec: 2464.693670716305
avg_episode_per_sec: 7.973129545382305
collect_time: 1.0033701264308765
reward_mean: 1907.0092266494444
reward_std: 512.1428338008553
reward_max: 2615.8156232281294
reward_min: 1110.5617708527082
total_envstep_count: 9582707
total_train_sample_count: 7222893
total_episode_count: 24588
total_duration: 2075.7686005877267
[2023-06-29 11:43:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2698
train_sample_count: 2698
avg_envstep_per_episode: 245.27272727272728
avg_sample_per_episode: 245.27272727272728
avg_envstep_per_sec: 2571.6713435199354
avg_train_sample_per_sec: 2571.6713435199354
avg_episode_per_sec: 10.484946174469714
collect_time: 1.0491231730673463
reward_mean: 1381.397451369022
reward_std: 594.1859201148428
reward_max: 2607.854109025801
reward_min: 279.3713725753198
total_envstep_count: 9587859
total_train_sample_count: 7226391
total_episode_count: 24599
total_duration: 2076.8177237607943
[2023-06-29 11:44:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2934
train_sample_count: 2934
avg_envstep_per_episode: 244.5
avg_sample_per_episode: 244.5
avg_envstep_per_sec: 2608.4844157318216
avg_train_sample_per_sec: 2608.4844157318216
avg_episode_per_sec: 10.668647917103565
collect_time: 1.124791078798473
reward_mean: 1598.1657215723008
reward_std: 519.3691039728616
reward_max: 2642.249432671005
reward_min: 321.7973980392779
total_envstep_count: 9592451
total_train_sample_count: 7229725
total_episode_count: 24611
total_duration: 2077.9425148395926
[2023-06-29 11:44:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1685
train_sample_count: 1685
avg_envstep_per_episode: 210.625
avg_sample_per_episode: 210.625
avg_envstep_per_sec: 2792.5072916609565
avg_train_sample_per_sec: 2792.5072916609565
avg_episode_per_sec: 13.258194856550535
collect_time: 0.6034003939870747
reward_mean: 1270.3477225282215
reward_std: 529.41134748125
reward_max: 2275.377629351703
reward_min: 426.07111336972804
total_envstep_count: 9596779
total_train_sample_count: 7233010
total_episode_count: 24619
total_duration: 2078.5459152335798
[2023-06-29 11:44:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 247.9
avg_sample_per_episode: 247.9
avg_envstep_per_sec: 2789.6010837811496
avg_train_sample_per_sec: 2789.6010837811496
avg_episode_per_sec: 11.252928938205525
collect_time: 0.8886575268460438
reward_mean: 1947.2930005319042
reward_std: 947.6968094403873
reward_max: 3495.735265597477
reward_min: 259.73232060218993
total_envstep_count: 9601371
total_train_sample_count: 7236289
total_episode_count: 24629
total_duration: 2079.434572760426
[2023-06-29 11:44:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 248.77777777777777
avg_sample_per_episode: 248.77777777777777
avg_envstep_per_sec: 2585.867185758906
avg_train_sample_per_sec: 2585.867185758906
avg_episode_per_sec: 10.394285248695915
collect_time: 0.8658604016210885
reward_mean: 1792.5486825210974
reward_std: 607.9188468827875
reward_max: 2839.4676962566477
reward_min: 1156.562669187154
total_envstep_count: 9605291
total_train_sample_count: 7239728
total_episode_count: 24638
total_duration: 2080.300433162047
[2023-06-29 11:44:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2054
train_sample_count: 2054
avg_envstep_per_episode: 342.3333333333333
avg_sample_per_episode: 342.3333333333333
avg_envstep_per_sec: 2537.067674276533
avg_train_sample_per_sec: 2537.067674276533
avg_episode_per_sec: 7.41110323547186
collect_time: 0.8095960627403114
reward_mean: 2243.493208394842
reward_std: 488.316751566628
reward_max: 3018.3293825744518
reward_min: 1531.1614901202522
total_envstep_count: 9609667
total_train_sample_count: 7242982
total_episode_count: 24644
total_duration: 2081.110029224787
[2023-06-29 11:44:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1499
train_sample_count: 1499
avg_envstep_per_episode: 299.8
avg_sample_per_episode: 299.8
avg_envstep_per_sec: 2764.4898784941897
avg_train_sample_per_sec: 2764.4898784941897
avg_episode_per_sec: 9.22111367076114
collect_time: 0.5422338535804303
reward_mean: 2390.290883169306
reward_std: 455.79783996607136
reward_max: 3123.322612212596
reward_min: 1926.2073627369882
total_envstep_count: 9613955
total_train_sample_count: 7246481
total_episode_count: 24649
total_duration: 2081.6522630783675
[2023-06-29 11:44:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1713
train_sample_count: 1713
avg_envstep_per_episode: 244.71428571428572
avg_sample_per_episode: 244.71428571428572
avg_envstep_per_sec: 2735.0993623474237
avg_train_sample_per_sec: 2735.0993623474237
avg_episode_per_sec: 11.176704924945689
collect_time: 0.6263026578053831
reward_mean: 2564.2358912869954
reward_std: 899.4838049225687
reward_max: 3600.199377345364
reward_min: 1454.1197214239285
total_envstep_count: 9618507
total_train_sample_count: 7249794
total_episode_count: 24656
total_duration: 2082.278565736173
[2023-06-29 11:44:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1278
train_sample_count: 1278
avg_envstep_per_episode: 255.6
avg_sample_per_episode: 255.6
avg_envstep_per_sec: 2570.5374675725625
avg_train_sample_per_sec: 2570.5374675725625
avg_episode_per_sec: 10.056875851222859
collect_time: 0.49717229027859866
reward_mean: 2267.5781569592273
reward_std: 793.6884441886796
reward_max: 3493.5583810238813
reward_min: 1353.2666266232704
total_envstep_count: 9622955
total_train_sample_count: 7253072
total_episode_count: 24661
total_duration: 2082.7757380264516
[2023-06-29 11:44:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2940
train_sample_count: 2940
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 2585.6328805358803
avg_train_sample_per_sec: 2585.6328805358803
avg_episode_per_sec: 10.553603594024002
collect_time: 1.1370523720253263
reward_mean: 2116.0157868435213
reward_std: 1114.4900594545322
reward_max: 3712.9015347678946
reward_min: 642.3766534735105
total_envstep_count: 9627955
total_train_sample_count: 7256412
total_episode_count: 24673
total_duration: 2083.912790398477
[2023-06-29 11:44:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2749
train_sample_count: 2749
avg_envstep_per_episode: 211.46153846153845
avg_sample_per_episode: 211.46153846153845
avg_envstep_per_sec: 2622.1413200729885
avg_train_sample_per_sec: 2622.1413200729885
avg_episode_per_sec: 12.40008627171657
collect_time: 1.0483798027802256
reward_mean: 1302.2525431071672
reward_std: 300.0264518700039
reward_max: 1630.6277373174228
reward_min: 437.2036695566536
total_envstep_count: 9633019
total_train_sample_count: 7259961
total_episode_count: 24686
total_duration: 2084.961170201257
[2023-06-29 11:44:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2876
train_sample_count: 2876
avg_envstep_per_episode: 221.23076923076923
avg_sample_per_episode: 221.23076923076923
avg_envstep_per_sec: 2773.1472033237096
avg_train_sample_per_sec: 2773.1472033237096
avg_episode_per_sec: 12.535088193048757
collect_time: 1.0370888341423123
reward_mean: 1392.9420978560158
reward_std: 775.6409463870509
reward_max: 2908.288031592851
reward_min: 119.06860648201716
total_envstep_count: 9637035
total_train_sample_count: 7263237
total_episode_count: 24699
total_duration: 2085.9982590353993
[2023-06-29 11:44:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3474
train_sample_count: 3474
avg_envstep_per_episode: 315.8181818181818
avg_sample_per_episode: 315.8181818181818
avg_envstep_per_sec: 2776.0960338941204
avg_train_sample_per_sec: 2776.0960338941204
avg_episode_per_sec: 8.790171667482822
collect_time: 1.2513976309122516
reward_mean: 1461.7375245812295
reward_std: 802.1473061063307
reward_max: 3469.830626185728
reward_min: 301.18272206249736
total_envstep_count: 9641835
total_train_sample_count: 7266711
total_episode_count: 24710
total_duration: 2087.2496566663117
[2023-06-29 11:44:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2973
train_sample_count: 2973
avg_envstep_per_episode: 247.75
avg_sample_per_episode: 247.75
avg_envstep_per_sec: 2482.4093984693345
avg_train_sample_per_sec: 2482.4093984693345
avg_episode_per_sec: 10.019815937313156
collect_time: 1.197626790259965
reward_mean: 1245.6046305884101
reward_std: 834.3577443694799
reward_max: 3586.7032090559687
reward_min: 323.57163917762415
total_envstep_count: 9646691
total_train_sample_count: 7270084
total_episode_count: 24722
total_duration: 2088.4472834565718
[2023-06-29 11:44:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2243
train_sample_count: 2243
avg_envstep_per_episode: 224.3
avg_sample_per_episode: 224.3
avg_envstep_per_sec: 2559.298151545943
avg_train_sample_per_sec: 2559.298151545943
avg_episode_per_sec: 11.410156716656008
collect_time: 0.8764121517632156
reward_mean: 1437.85298926733
reward_std: 837.749681830572
reward_max: 3480.4750738313355
reward_min: 337.54217443688555
total_envstep_count: 9651139
total_train_sample_count: 7273527
total_episode_count: 24732
total_duration: 2089.323695608335
[2023-06-29 11:44:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 250.875
avg_sample_per_episode: 250.875
avg_envstep_per_sec: 2804.6467951251525
avg_train_sample_per_sec: 2804.6467951251525
avg_episode_per_sec: 11.179459073742512
collect_time: 0.7155981293218211
reward_mean: 1696.8550927016781
reward_std: 816.3710578089106
reward_max: 3033.5087114250423
reward_min: 280.79279210826263
total_envstep_count: 9655483
total_train_sample_count: 7276734
total_episode_count: 24740
total_duration: 2090.039293737657
[2023-06-29 11:44:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2842
train_sample_count: 2842
avg_envstep_per_episode: 258.3636363636364
avg_sample_per_episode: 258.3636363636364
avg_envstep_per_sec: 2720.6277463486
avg_train_sample_per_sec: 2720.6277463486
avg_episode_per_sec: 10.530227026683532
collect_time: 1.0446118561476467
reward_mean: 1831.5223068733844
reward_std: 781.809215766674
reward_max: 3504.272771775355
reward_min: 548.8676863143836
total_envstep_count: 9660355
total_train_sample_count: 7279976
total_episode_count: 24751
total_duration: 2091.0839055938045
[2023-06-29 11:44:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1766
train_sample_count: 1766
avg_envstep_per_episode: 252.28571428571428
avg_sample_per_episode: 252.28571428571428
avg_envstep_per_sec: 2477.3603198609144
avg_train_sample_per_sec: 2477.3603198609144
avg_episode_per_sec: 9.819661517002492
collect_time: 0.7128555284598842
reward_mean: 1772.4408052967385
reward_std: 624.7352681664312
reward_max: 3195.212690725062
reward_min: 1325.0386544223816
total_envstep_count: 9664947
total_train_sample_count: 7283342
total_episode_count: 24758
total_duration: 2091.7967611222643
[2023-06-29 11:44:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2179
train_sample_count: 2179
avg_envstep_per_episode: 272.375
avg_sample_per_episode: 272.375
avg_envstep_per_sec: 2664.3392155262727
avg_train_sample_per_sec: 2664.3392155262727
avg_episode_per_sec: 9.781878716939046
collect_time: 0.8178388049472123
reward_mean: 2266.8047579539457
reward_std: 934.3072302515586
reward_max: 3599.8981762374196
reward_min: 1105.0498763998608
total_envstep_count: 9670195
total_train_sample_count: 7286721
total_episode_count: 24766
total_duration: 2092.6145999272117
[2023-06-29 11:44:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3162
train_sample_count: 3162
avg_envstep_per_episode: 263.5
avg_sample_per_episode: 263.5
avg_envstep_per_sec: 2624.875399760316
avg_train_sample_per_sec: 2624.875399760316
avg_episode_per_sec: 9.96157646967862
collect_time: 1.2046286083860323
reward_mean: 1960.9575143510165
reward_std: 867.7453518287983
reward_max: 3563.291430560788
reward_min: 751.9073841488183
total_envstep_count: 9674803
total_train_sample_count: 7290283
total_episode_count: 24778
total_duration: 2093.8192285355976
[2023-06-29 11:45:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 285.7142857142857
avg_sample_per_episode: 285.7142857142857
avg_envstep_per_sec: 2812.973124037043
avg_train_sample_per_sec: 2812.973124037043
avg_episode_per_sec: 9.84540593412965
collect_time: 0.7109915067832916
reward_mean: 1676.7219112108846
reward_std: 565.7211339522781
reward_max: 2675.740545686533
reward_min: 896.416143538305
total_envstep_count: 9679547
total_train_sample_count: 7293483
total_episode_count: 24785
total_duration: 2094.5302200423807
[2023-06-29 11:45:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1294
train_sample_count: 1294
avg_envstep_per_episode: 215.66666666666666
avg_sample_per_episode: 215.66666666666666
avg_envstep_per_sec: 2791.782832608136
avg_train_sample_per_sec: 2791.782832608136
avg_episode_per_sec: 12.944897214566318
collect_time: 0.46350310091674324
reward_mean: 2366.0875536173103
reward_std: 819.5097068955035
reward_max: 3524.440381649903
reward_min: 1244.5369691168696
total_envstep_count: 9684123
total_train_sample_count: 7296777
total_episode_count: 24791
total_duration: 2094.9937231432973
[2023-06-29 11:45:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1629
train_sample_count: 1629
avg_envstep_per_episode: 203.625
avg_sample_per_episode: 203.625
avg_envstep_per_sec: 2771.633952099151
avg_train_sample_per_sec: 2771.633952099151
avg_episode_per_sec: 13.611462011536654
collect_time: 0.5877399498466401
reward_mean: 2130.07109769194
reward_std: 773.0676908514034
reward_max: 3327.3324942146555
reward_min: 1229.8545785647013
total_envstep_count: 9688027
total_train_sample_count: 7300006
total_episode_count: 24799
total_duration: 2095.581463093144
[2023-06-29 11:45:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1726
train_sample_count: 1726
avg_envstep_per_episode: 287.6666666666667
avg_sample_per_episode: 287.6666666666667
avg_envstep_per_sec: 2505.9449326118133
avg_train_sample_per_sec: 2505.9449326118133
avg_episode_per_sec: 8.711280182891587
collect_time: 0.688762142191641
reward_mean: 2612.733762866281
reward_std: 1025.7125154226596
reward_max: 3546.643178692183
reward_min: 989.2806612822059
total_envstep_count: 9692995
total_train_sample_count: 7303332
total_episode_count: 24805
total_duration: 2096.2702252353356
[2023-06-29 11:45:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1916
train_sample_count: 1916
avg_envstep_per_episode: 319.3333333333333
avg_sample_per_episode: 319.3333333333333
avg_envstep_per_sec: 2754.9493961953644
avg_train_sample_per_sec: 2754.9493961953644
avg_episode_per_sec: 8.627190175977132
collect_time: 0.6954755694046617
reward_mean: 2730.422249969564
reward_std: 822.8811212957702
reward_max: 3533.7381174628867
reward_min: 1419.732181670001
total_envstep_count: 9698203
total_train_sample_count: 7306848
total_episode_count: 24811
total_duration: 2096.96570080474
[2023-06-29 11:45:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1730
train_sample_count: 1730
avg_envstep_per_episode: 247.14285714285714
avg_sample_per_episode: 247.14285714285714
avg_envstep_per_sec: 2746.8828810658174
avg_train_sample_per_sec: 2746.8828810658174
avg_episode_per_sec: 11.114555010092904
collect_time: 0.6298047914328051
reward_mean: 2523.8239395830237
reward_std: 841.8922987186056
reward_max: 3517.5928154037356
reward_min: 1286.0718615594294
total_envstep_count: 9702811
total_train_sample_count: 7310178
total_episode_count: 24818
total_duration: 2097.595505596173
[2023-06-29 11:45:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1723
train_sample_count: 1723
avg_envstep_per_episode: 191.44444444444446
avg_sample_per_episode: 191.44444444444446
avg_envstep_per_sec: 2710.0271229480977
avg_train_sample_per_sec: 2710.0271229480977
avg_episode_per_sec: 14.155684333449146
collect_time: 0.635786994679831
reward_mean: 1982.582026454964
reward_std: 824.5337134457159
reward_max: 3505.947787761001
reward_min: 1121.0699650271017
total_envstep_count: 9707611
total_train_sample_count: 7313501
total_episode_count: 24827
total_duration: 2098.2312925908527
[2023-06-29 11:45:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2905
train_sample_count: 2905
avg_envstep_per_episode: 363.125
avg_sample_per_episode: 363.125
avg_envstep_per_sec: 2617.6468313710348
avg_train_sample_per_sec: 2617.6468313710348
avg_episode_per_sec: 7.208665972794589
collect_time: 1.1097753773294388
reward_mean: 2725.482371855054
reward_std: 822.2350874424754
reward_max: 3534.268308529657
reward_min: 1230.2701018907799
total_envstep_count: 9712411
total_train_sample_count: 7316806
total_episode_count: 24835
total_duration: 2099.341067968182
[2023-06-29 11:45:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1197
train_sample_count: 1197
avg_envstep_per_episode: 239.4
avg_sample_per_episode: 239.4
avg_envstep_per_sec: 2647.861134646484
avg_train_sample_per_sec: 2647.861134646484
avg_episode_per_sec: 11.060405742048806
collect_time: 0.45206298182997856
reward_mean: 1827.835129626606
reward_std: 590.5332811298956
reward_max: 2954.63868036655
reward_min: 1400.6411490193314
total_envstep_count: 9717355
total_train_sample_count: 7320403
total_episode_count: 24840
total_duration: 2099.793130950012
[2023-06-29 11:45:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3024
train_sample_count: 3024
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 2531.3339610129124
avg_train_sample_per_sec: 2531.3339610129124
avg_episode_per_sec: 10.044976035765526
collect_time: 1.1946270411470905
reward_mean: 2256.8511105731195
reward_std: 892.2171816065794
reward_max: 3577.128101173989
reward_min: 980.5258460773181
total_envstep_count: 9722275
total_train_sample_count: 7323827
total_episode_count: 24852
total_duration: 2100.987757991159
[2023-06-29 11:45:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2724
train_sample_count: 2724
avg_envstep_per_episode: 247.63636363636363
avg_sample_per_episode: 247.63636363636363
avg_envstep_per_sec: 2602.902922319197
avg_train_sample_per_sec: 2602.902922319197
avg_episode_per_sec: 10.510988305987945
collect_time: 1.0465238548247144
reward_mean: 1513.6214512619918
reward_std: 328.48071134116594
reward_max: 2151.593411725224
reward_min: 1111.1945004099632
total_envstep_count: 9726955
total_train_sample_count: 7327351
total_episode_count: 24863
total_duration: 2102.0342818459835
[2023-06-29 11:45:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 260.6
avg_sample_per_episode: 260.6
avg_envstep_per_sec: 2759.645841752648
avg_train_sample_per_sec: 2759.645841752648
avg_episode_per_sec: 10.589584964515149
collect_time: 0.47216203626058995
reward_mean: 1614.785888846344
reward_std: 278.7077345897738
reward_max: 1985.0195284836627
reward_min: 1196.759871105623
total_envstep_count: 9730763
total_train_sample_count: 7330654
total_episode_count: 24868
total_duration: 2102.506443882244
[2023-06-29 11:45:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 250.75
avg_sample_per_episode: 250.75
avg_envstep_per_sec: 2742.9310180567486
avg_train_sample_per_sec: 2742.9310180567486
avg_episode_per_sec: 10.938907350176464
collect_time: 0.731334469147958
reward_mean: 2205.700973900395
reward_std: 765.4832905453063
reward_max: 3510.8440604813522
reward_min: 1435.7812448478396
total_envstep_count: 9734835
total_train_sample_count: 7333860
total_episode_count: 24876
total_duration: 2103.237778351392
[2023-06-29 11:45:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2540
train_sample_count: 2540
avg_envstep_per_episode: 317.5
avg_sample_per_episode: 317.5
avg_envstep_per_sec: 2563.16727526834
avg_train_sample_per_sec: 2563.16727526834
avg_episode_per_sec: 8.072967796120755
collect_time: 0.9909614657256756
reward_mean: 2359.3687528088976
reward_std: 636.6986571351282
reward_max: 3495.322297893217
reward_min: 1557.2066843193309
total_envstep_count: 9739987
total_train_sample_count: 7337200
total_episode_count: 24884
total_duration: 2104.228739817118
[2023-06-29 11:45:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 223.11111111111111
avg_sample_per_episode: 223.11111111111111
avg_envstep_per_sec: 2430.5374169402335
avg_train_sample_per_sec: 2430.5374169402335
avg_episode_per_sec: 10.893843004214194
collect_time: 0.8261547368103638
reward_mean: 1833.1055476583897
reward_std: 714.2845306202697
reward_max: 2839.6523034966845
reward_min: 454.30608811126535
total_envstep_count: 9744099
total_train_sample_count: 7340408
total_episode_count: 24893
total_duration: 2105.054894553928
[2023-06-29 11:45:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2262
train_sample_count: 2262
avg_envstep_per_episode: 251.33333333333334
avg_sample_per_episode: 251.33333333333334
avg_envstep_per_sec: 2784.0237222028063
avg_train_sample_per_sec: 2784.0237222028063
avg_episode_per_sec: 11.077017462345385
collect_time: 0.8124930768227201
reward_mean: 1707.9507737514616
reward_std: 673.8641008962464
reward_max: 3169.8722880299074
reward_min: 756.2997017705065
total_envstep_count: 9748659
total_train_sample_count: 7343870
total_episode_count: 24902
total_duration: 2105.8673876307507
[2023-06-29 11:45:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 201.5
avg_sample_per_episode: 201.5
avg_envstep_per_sec: 2769.5360840959916
avg_train_sample_per_sec: 2769.5360840959916
avg_episode_per_sec: 13.744595950848593
collect_time: 0.43653520419634884
reward_mean: 1981.951034001798
reward_std: 672.0600005859027
reward_max: 3212.6466819467373
reward_min: 1290.8111682153235
total_envstep_count: 9752571
total_train_sample_count: 7347079
total_episode_count: 24908
total_duration: 2106.303922834947
[2023-06-29 11:45:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 244.88888888888889
avg_sample_per_episode: 244.88888888888889
avg_envstep_per_sec: 2525.856707871448
avg_train_sample_per_sec: 2525.856707871448
avg_episode_per_sec: 10.31429690147143
collect_time: 0.8725752308638766
reward_mean: 2020.5371806370301
reward_std: 863.7446132678754
reward_max: 3024.3987596427287
reward_min: 203.84957563246164
total_envstep_count: 9757203
total_train_sample_count: 7350483
total_episode_count: 24917
total_duration: 2107.176498065811
[2023-06-29 11:45:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2518
train_sample_count: 2518
avg_envstep_per_episode: 359.7142857142857
avg_sample_per_episode: 359.7142857142857
avg_envstep_per_sec: 2794.5864851208607
avg_train_sample_per_sec: 2794.5864851208607
avg_episode_per_sec: 7.768906034887222
collect_time: 0.901027759708464
reward_mean: 2342.974470386652
reward_std: 868.3185955086813
reward_max: 3564.855032418638
reward_min: 1074.7743109811677
total_envstep_count: 9761699
total_train_sample_count: 7353801
total_episode_count: 24924
total_duration: 2108.0775258255194
[2023-06-29 11:46:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1483
train_sample_count: 1483
avg_envstep_per_episode: 247.16666666666666
avg_sample_per_episode: 247.16666666666666
avg_envstep_per_sec: 2713.689976805685
avg_train_sample_per_sec: 2713.689976805685
avg_episode_per_sec: 10.979190735559078
collect_time: 0.546488365537487
reward_mean: 2167.9273750429156
reward_std: 1007.8072966944543
reward_max: 3517.6442222040937
reward_min: 1065.2745848510924
total_envstep_count: 9766923
total_train_sample_count: 7357284
total_episode_count: 24930
total_duration: 2108.624014191057
[2023-06-29 11:46:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2508
train_sample_count: 2508
avg_envstep_per_episode: 278.6666666666667
avg_sample_per_episode: 278.6666666666667
avg_envstep_per_sec: 2795.404041177605
avg_train_sample_per_sec: 2795.404041177605
avg_episode_per_sec: 10.031354214752172
collect_time: 0.8971869407985359
reward_mean: 2270.4197777956706
reward_std: 929.4205757490321
reward_max: 3569.581573879908
reward_min: 1199.6013362841359
total_envstep_count: 9771203
total_train_sample_count: 7360592
total_episode_count: 24939
total_duration: 2109.521201131856
[2023-06-29 11:46:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1681
train_sample_count: 1681
avg_envstep_per_episode: 210.125
avg_sample_per_episode: 210.125
avg_envstep_per_sec: 2571.863434816898
avg_train_sample_per_sec: 2571.863434816898
avg_episode_per_sec: 12.239683211502191
collect_time: 0.653611687636003
reward_mean: 1808.0437713413676
reward_std: 1078.815689207003
reward_max: 3618.843710855565
reward_min: 422.8710812822968
total_envstep_count: 9775291
total_train_sample_count: 7363873
total_episode_count: 24947
total_duration: 2110.1748128194918
[2023-06-29 11:46:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2906
train_sample_count: 2906
avg_envstep_per_episode: 322.8888888888889
avg_sample_per_episode: 322.8888888888889
avg_envstep_per_sec: 2554.93754254795
avg_train_sample_per_sec: 2554.93754254795
avg_episode_per_sec: 7.91274531415401
collect_time: 1.1374054948920385
reward_mean: 2084.6234559017485
reward_std: 958.3992999717461
reward_max: 3475.472751716854
reward_min: 599.073457317259
total_envstep_count: 9779843
total_train_sample_count: 7367179
total_episode_count: 24956
total_duration: 2111.3122183143837
[2023-06-29 11:46:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2526
train_sample_count: 2526
avg_envstep_per_episode: 229.63636363636363
avg_sample_per_episode: 229.63636363636363
avg_envstep_per_sec: 2651.9345700217414
avg_train_sample_per_sec: 2651.9345700217414
avg_episode_per_sec: 11.548408658051923
collect_time: 0.9525121881039814
reward_mean: 1150.7182909680705
reward_std: 805.5077304809546
reward_max: 2994.048239581151
reward_min: 289.1317243889786
total_envstep_count: 9784483
total_train_sample_count: 7370505
total_episode_count: 24967
total_duration: 2112.2647305024875
[2023-06-29 11:46:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1482
train_sample_count: 1482
avg_envstep_per_episode: 185.25
avg_sample_per_episode: 185.25
avg_envstep_per_sec: 2738.1146182905477
avg_train_sample_per_sec: 2738.1146182905477
avg_episode_per_sec: 14.780645712769488
collect_time: 0.5412483429657295
reward_mean: 1455.245498585038
reward_std: 966.8864423473624
reward_max: 3408.7734638399247
reward_min: 394.5301799704991
total_envstep_count: 9789187
total_train_sample_count: 7373987
total_episode_count: 24975
total_duration: 2112.8059788454534
[2023-06-29 11:46:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1968
train_sample_count: 1968
avg_envstep_per_episode: 196.8
avg_sample_per_episode: 196.8
avg_envstep_per_sec: 2424.140672184577
avg_train_sample_per_sec: 2424.140672184577
avg_episode_per_sec: 12.317787968417566
collect_time: 0.8118340748874471
reward_mean: 1991.7352475068267
reward_std: 1121.7715437159054
reward_max: 3575.675619463548
reward_min: 339.24395855900707
total_envstep_count: 9793899
total_train_sample_count: 7377555
total_episode_count: 24985
total_duration: 2113.617812920341
[2023-06-29 11:46:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3068
train_sample_count: 3068
avg_envstep_per_episode: 278.90909090909093
avg_sample_per_episode: 278.90909090909093
avg_envstep_per_sec: 2547.741602255156
avg_train_sample_per_sec: 2547.741602255156
avg_episode_per_sec: 9.13466676167103
collect_time: 1.2042037533493712
reward_mean: 1851.2926148491983
reward_std: 964.9591566417434
reward_max: 3564.3014087959546
reward_min: 255.0601228259415
total_envstep_count: 9798763
total_train_sample_count: 7381023
total_episode_count: 24996
total_duration: 2114.82201667369
[2023-06-29 11:46:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3455
train_sample_count: 3455
avg_envstep_per_episode: 314.09090909090907
avg_sample_per_episode: 314.09090909090907
avg_envstep_per_sec: 2569.4843366513223
avg_train_sample_per_sec: 2569.4843366513223
avg_episode_per_sec: 8.180702663723459
collect_time: 1.3446277724746611
reward_mean: 1668.5083189929633
reward_std: 607.240201060621
reward_max: 3337.358972556245
reward_min: 1021.073189683383
total_envstep_count: 9803371
total_train_sample_count: 7384478
total_episode_count: 25007
total_duration: 2116.166644446165
[2023-06-29 11:46:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2120
train_sample_count: 2120
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 2683.7478109209305
avg_train_sample_per_sec: 2683.7478109209305
avg_episode_per_sec: 10.127350229890304
collect_time: 0.7899400947336106
reward_mean: 1442.484495715883
reward_std: 389.82097342489345
reward_max: 2248.5289386369873
reward_min: 964.6799175040428
total_envstep_count: 9808387
total_train_sample_count: 7387798
total_episode_count: 25015
total_duration: 2116.9565845408983
[2023-06-29 11:46:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2833
train_sample_count: 2833
avg_envstep_per_episode: 236.08333333333334
avg_sample_per_episode: 236.08333333333334
avg_envstep_per_sec: 2766.296516079945
avg_train_sample_per_sec: 2766.296516079945
avg_episode_per_sec: 11.7174578866782
collect_time: 1.0241129190353675
reward_mean: 1661.4608394162094
reward_std: 856.8281957583561
reward_max: 3450.8252209519087
reward_min: 908.8335568764174
total_envstep_count: 9812475
total_train_sample_count: 7391031
total_episode_count: 25027
total_duration: 2117.9806974599337
[2023-06-29 11:46:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2524
train_sample_count: 2524
avg_envstep_per_episode: 280.44444444444446
avg_sample_per_episode: 280.44444444444446
avg_envstep_per_sec: 2698.365303155015
avg_train_sample_per_sec: 2698.365303155015
avg_episode_per_sec: 9.621746326622478
collect_time: 0.9353811350334436
reward_mean: 1324.5632605101416
reward_std: 494.2376200894578
reward_max: 2247.2466644310466
reward_min: 662.8023875015629
total_envstep_count: 9817467
total_train_sample_count: 7394355
total_episode_count: 25036
total_duration: 2118.916078594967
[2023-06-29 11:46:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2330
train_sample_count: 2330
avg_envstep_per_episode: 211.8181818181818
avg_sample_per_episode: 211.8181818181818
avg_envstep_per_sec: 2729.1273457569173
avg_train_sample_per_sec: 2729.1273457569173
avg_episode_per_sec: 12.884292190268708
collect_time: 0.8537527585960925
reward_mean: 1498.2510763847931
reward_std: 848.8932804026309
reward_max: 3481.2971032017467
reward_min: 567.387274742444
total_envstep_count: 9821883
total_train_sample_count: 7397885
total_episode_count: 25047
total_duration: 2119.769831353563
[2023-06-29 11:46:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 2753.321379548645
avg_train_sample_per_sec: 2753.321379548645
avg_episode_per_sec: 9.46158549673074
collect_time: 1.1625958465207369
reward_mean: 1810.1340864990698
reward_std: 736.8697982312945
reward_max: 3299.1362248984283
reward_min: 978.0901885902251
total_envstep_count: 9826123
total_train_sample_count: 7401086
total_episode_count: 25058
total_duration: 2120.9324272000836
[2023-06-29 11:46:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1740
train_sample_count: 1740
avg_envstep_per_episode: 217.5
avg_sample_per_episode: 217.5
avg_envstep_per_sec: 2412.340079354532
avg_train_sample_per_sec: 2412.340079354532
avg_episode_per_sec: 11.09121875565302
collect_time: 0.7212913365289567
reward_mean: 1203.8152891563473
reward_std: 107.54759568776068
reward_max: 1350.3201526376256
reward_min: 1014.5343568900156
total_envstep_count: 9830971
total_train_sample_count: 7404426
total_episode_count: 25066
total_duration: 2121.6537185366124
[2023-06-29 11:46:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2920
train_sample_count: 2920
avg_envstep_per_episode: 324.44444444444446
avg_sample_per_episode: 324.44444444444446
avg_envstep_per_sec: 2680.7504574483005
avg_train_sample_per_sec: 2680.7504574483005
avg_episode_per_sec: 8.262587026381748
collect_time: 1.0892472262335942
reward_mean: 2386.4292941255
reward_std: 888.0723521349315
reward_max: 3517.051875757136
reward_min: 1056.422380778631
total_envstep_count: 9835579
total_train_sample_count: 7407746
total_episode_count: 25075
total_duration: 2122.742965762846
[2023-06-29 11:46:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2324
train_sample_count: 2324
avg_envstep_per_episode: 232.4
avg_sample_per_episode: 232.4
avg_envstep_per_sec: 2738.718726977153
avg_train_sample_per_sec: 2738.718726977153
avg_episode_per_sec: 11.784503988714084
collect_time: 0.8485719899265096
reward_mean: 1295.0425568078613
reward_std: 520.8129431017393
reward_max: 1974.027799503287
reward_min: 254.64991821314496
total_envstep_count: 9840091
total_train_sample_count: 7411270
total_episode_count: 25085
total_duration: 2123.591537752772
[2023-06-29 11:46:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2203
train_sample_count: 2203
avg_envstep_per_episode: 244.77777777777777
avg_sample_per_episode: 244.77777777777777
avg_envstep_per_sec: 2726.379329017415
avg_train_sample_per_sec: 2726.379329017415
avg_episode_per_sec: 11.138181552953577
collect_time: 0.8080313610630109
reward_mean: 1883.6783776580403
reward_std: 791.6920847866982
reward_max: 3390.4811743886994
reward_min: 1082.8041975884344
total_envstep_count: 9844427
total_train_sample_count: 7414673
total_episode_count: 25094
total_duration: 2124.3995691138352
[2023-06-29 11:46:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2793
train_sample_count: 2793
avg_envstep_per_episode: 253.9090909090909
avg_sample_per_episode: 253.9090909090909
avg_envstep_per_sec: 2556.3850704019424
avg_train_sample_per_sec: 2556.3850704019424
avg_episode_per_sec: 10.068111627075318
collect_time: 1.092558406922966
reward_mean: 1542.816847702107
reward_std: 978.2339842967385
reward_max: 3474.0893588802605
reward_min: 268.7927616617161
total_envstep_count: 9848875
total_train_sample_count: 7418266
total_episode_count: 25105
total_duration: 2125.492127520758
[2023-06-29 11:46:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 198.85714285714286
avg_sample_per_episode: 198.85714285714286
avg_envstep_per_sec: 2426.3968206095506
avg_train_sample_per_sec: 2426.3968206095506
avg_episode_per_sec: 12.201708149616994
collect_time: 0.5736901681441813
reward_mean: 1562.2798363508307
reward_std: 1207.5542105035715
reward_max: 3559.317872559941
reward_min: 274.8811173714676
total_envstep_count: 9852843
total_train_sample_count: 7421658
total_episode_count: 25112
total_duration: 2126.0658176889024
[2023-06-29 11:47:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 325.6
avg_sample_per_episode: 325.6
avg_envstep_per_sec: 2752.027378642804
avg_train_sample_per_sec: 2752.027378642804
avg_episode_per_sec: 8.45217253882925
collect_time: 0.5915638821888713
reward_mean: 2278.500784794399
reward_std: 682.0479085446436
reward_max: 3566.7953689088104
reward_min: 1734.4568940665706
total_envstep_count: 9856859
total_train_sample_count: 7424886
total_episode_count: 25117
total_duration: 2126.6573815710913
[2023-06-29 11:47:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2899
train_sample_count: 2899
avg_envstep_per_episode: 289.9
avg_sample_per_episode: 289.9
avg_envstep_per_sec: 2716.1286707090253
avg_train_sample_per_sec: 2716.1286707090253
avg_episode_per_sec: 9.369191689234306
collect_time: 1.0673279330478984
reward_mean: 2188.622583497924
reward_std: 1217.954453867044
reward_max: 3551.0469045338587
reward_min: 260.79334502749754
total_envstep_count: 9861339
total_train_sample_count: 7428185
total_episode_count: 25127
total_duration: 2127.7247095041394
[2023-06-29 11:47:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 267.45454545454544
avg_sample_per_episode: 267.45454545454544
avg_envstep_per_sec: 2588.8822480625067
avg_train_sample_per_sec: 2588.8822480625067
avg_episode_per_sec: 9.679709289152813
collect_time: 1.1363977647889405
reward_mean: 1347.769399010285
reward_std: 607.3481046902893
reward_max: 2428.691950414727
reward_min: 364.8177788851795
total_envstep_count: 9865875
total_train_sample_count: 7431527
total_episode_count: 25138
total_duration: 2128.861107268928
[2023-06-29 11:47:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1739
train_sample_count: 1739
avg_envstep_per_episode: 217.375
avg_sample_per_episode: 217.375
avg_envstep_per_sec: 2725.5936911306926
avg_train_sample_per_sec: 2725.5936911306926
avg_episode_per_sec: 12.538671379554652
collect_time: 0.6380261319428681
reward_mean: 1512.4453320599516
reward_std: 1051.212313436606
reward_max: 3460.6735524479195
reward_min: 340.3505842893415
total_envstep_count: 9870619
total_train_sample_count: 7434866
total_episode_count: 25146
total_duration: 2129.499133400871
[2023-06-29 11:47:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3407
train_sample_count: 3407
avg_envstep_per_episode: 262.0769230769231
avg_sample_per_episode: 262.0769230769231
avg_envstep_per_sec: 2680.008855580509
avg_train_sample_per_sec: 2680.008855580509
avg_episode_per_sec: 10.226039073245266
collect_time: 1.2712644560504704
reward_mean: 1735.7455774401278
reward_std: 986.2027735883912
reward_max: 3523.2687818019676
reward_min: 283.30032904357563
total_envstep_count: 9875651
total_train_sample_count: 7438273
total_episode_count: 25159
total_duration: 2130.7703978569216
[2023-06-29 11:47:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3091
train_sample_count: 3091
avg_envstep_per_episode: 257.5833333333333
avg_sample_per_episode: 257.5833333333333
avg_envstep_per_sec: 2806.3781049475283
avg_train_sample_per_sec: 2806.3781049475283
avg_episode_per_sec: 10.89502984774194
collect_time: 1.101419653520919
reward_mean: 1383.5006913537152
reward_std: 542.2727694847795
reward_max: 2728.402447433587
reward_min: 267.4233129767374
total_envstep_count: 9880187
total_train_sample_count: 7441764
total_episode_count: 25171
total_duration: 2131.8718175104427
[2023-06-29 11:47:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1710
train_sample_count: 1710
avg_envstep_per_episode: 285.0
avg_sample_per_episode: 285.0
avg_envstep_per_sec: 2737.0787842479485
avg_train_sample_per_sec: 2737.0787842479485
avg_episode_per_sec: 9.603785207887539
collect_time: 0.6247536643231287
reward_mean: 1563.8562561744639
reward_std: 287.7095868890171
reward_max: 1994.88889272898
reward_min: 1146.9543500168859
total_envstep_count: 9884939
total_train_sample_count: 7445074
total_episode_count: 25177
total_duration: 2132.496571174766
[2023-06-29 11:47:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 2575.7705896595417
avg_train_sample_per_sec: 2575.7705896595417
avg_episode_per_sec: 11.498975846694382
collect_time: 1.1305354644898327
reward_mean: 1770.156840699368
reward_std: 746.0399313513761
reward_max: 3525.998332933314
reward_min: 483.2541967767487
total_envstep_count: 9889283
total_train_sample_count: 7448386
total_episode_count: 25190
total_duration: 2133.6271066392555
[2023-06-29 11:47:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1996
train_sample_count: 1996
avg_envstep_per_episode: 249.5
avg_sample_per_episode: 249.5
avg_envstep_per_sec: 2816.7416936259206
avg_train_sample_per_sec: 2816.7416936259206
avg_episode_per_sec: 11.289545866236153
collect_time: 0.7086201778873801
reward_mean: 1478.169716718076
reward_std: 635.3475534605345
reward_max: 2199.6262384105307
reward_min: 384.3599383951454
total_envstep_count: 9894339
total_train_sample_count: 7451982
total_episode_count: 25198
total_duration: 2134.335726817143
[2023-06-29 11:47:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 227.0909090909091
avg_sample_per_episode: 227.0909090909091
avg_envstep_per_sec: 2554.6256162880322
avg_train_sample_per_sec: 2554.6256162880322
avg_episode_per_sec: 11.24935219342208
collect_time: 0.9778340842090547
reward_mean: 1812.8304565307772
reward_std: 623.8907636776997
reward_max: 3464.993422216745
reward_min: 1266.8981037299413
total_envstep_count: 9898827
total_train_sample_count: 7455280
total_episode_count: 25209
total_duration: 2135.313560901352
[2023-06-29 11:47:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1383
train_sample_count: 1383
avg_envstep_per_episode: 197.57142857142858
avg_sample_per_episode: 197.57142857142858
avg_envstep_per_sec: 2696.8623298729317
avg_train_sample_per_sec: 2696.8623298729317
avg_episode_per_sec: 13.65006240716596
collect_time: 0.512818168239668
reward_mean: 1709.9811645484133
reward_std: 366.608374614897
reward_max: 2525.5903068342895
reward_min: 1257.6832438218762
total_envstep_count: 9903395
total_train_sample_count: 7458663
total_episode_count: 25216
total_duration: 2135.826379069592
[2023-06-29 11:47:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2133
train_sample_count: 2133
avg_envstep_per_episode: 213.3
avg_sample_per_episode: 213.3
avg_envstep_per_sec: 2573.009879110248
avg_train_sample_per_sec: 2573.009879110248
avg_episode_per_sec: 12.062868631552968
collect_time: 0.8289902099939063
reward_mean: 1758.8100075392285
reward_std: 1113.4104191752506
reward_max: 3467.2476195658055
reward_min: 304.24727038153617
total_envstep_count: 9907891
total_train_sample_count: 7461996
total_episode_count: 25226
total_duration: 2136.655369279586
[2023-06-29 11:47:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2512
train_sample_count: 2512
avg_envstep_per_episode: 251.2
avg_sample_per_episode: 251.2
avg_envstep_per_sec: 2546.926257096968
avg_train_sample_per_sec: 2546.926257096968
avg_episode_per_sec: 10.139037647679013
collect_time: 0.9862868989631535
reward_mean: 1838.9502570160898
reward_std: 1049.2676841463838
reward_max: 3486.1579253273935
reward_min: 376.65024705146215
total_envstep_count: 9912691
total_train_sample_count: 7465308
total_episode_count: 25236
total_duration: 2137.641656178549
[2023-06-29 11:47:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1756
train_sample_count: 1756
avg_envstep_per_episode: 250.85714285714286
avg_sample_per_episode: 250.85714285714286
avg_envstep_per_sec: 2736.652099201388
avg_train_sample_per_sec: 2736.652099201388
avg_episode_per_sec: 10.909205406839247
collect_time: 0.6416599320434034
reward_mean: 1773.5428145711835
reward_std: 342.2947379380722
reward_max: 2237.3978822478575
reward_min: 1272.3914232309908
total_envstep_count: 9916499
total_train_sample_count: 7468664
total_episode_count: 25243
total_duration: 2138.2833161105923
[2023-06-29 11:47:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2861
train_sample_count: 2861
avg_envstep_per_episode: 317.8888888888889
avg_sample_per_episode: 317.8888888888889
avg_envstep_per_sec: 2717.9046282798795
avg_train_sample_per_sec: 2717.9046282798795
avg_episode_per_sec: 8.549857271764738
collect_time: 1.052649151199497
reward_mean: 2128.561335406125
reward_std: 967.5772213940517
reward_max: 3524.558308331426
reward_min: 804.952591438475
total_envstep_count: 9921339
total_train_sample_count: 7471925
total_episode_count: 25252
total_duration: 2139.335965261792
[2023-06-29 11:47:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2751
train_sample_count: 2751
avg_envstep_per_episode: 305.6666666666667
avg_sample_per_episode: 305.6666666666667
avg_envstep_per_sec: 2592.914091008276
avg_train_sample_per_sec: 2592.914091008276
avg_episode_per_sec: 8.482816001117587
collect_time: 1.060968432984315
reward_mean: 1832.9374905763034
reward_std: 587.7718221347715
reward_max: 3073.783671307569
reward_min: 1123.4611009020764
total_envstep_count: 9926555
total_train_sample_count: 7475476
total_episode_count: 25261
total_duration: 2140.396933694776
[2023-06-29 11:47:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1492
train_sample_count: 1492
avg_envstep_per_episode: 213.14285714285714
avg_sample_per_episode: 213.14285714285714
avg_envstep_per_sec: 2538.838317374344
avg_train_sample_per_sec: 2538.838317374344
avg_episode_per_sec: 11.91143982682333
collect_time: 0.5876703489897774
reward_mean: 1856.078325952256
reward_std: 647.3820091066431
reward_max: 3149.325445332788
reward_min: 1187.7326725583905
total_envstep_count: 9931147
total_train_sample_count: 7478968
total_episode_count: 25268
total_duration: 2140.984604043766
[2023-06-29 11:47:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 849
train_sample_count: 849
avg_envstep_per_episode: 212.25
avg_sample_per_episode: 212.25
avg_envstep_per_sec: 2600.5459892487997
avg_train_sample_per_sec: 2600.5459892487997
avg_episode_per_sec: 12.252277923433686
collect_time: 0.3264699042085559
reward_mean: 3048.2931000221643
reward_std: 552.3233085138761
reward_max: 3481.1235563203986
reward_min: 2124.8772529002085
total_envstep_count: 9935763
total_train_sample_count: 7482217
total_episode_count: 25272
total_duration: 2141.3110739479744
[2023-06-29 11:47:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2062
train_sample_count: 2062
avg_envstep_per_episode: 294.57142857142856
avg_sample_per_episode: 294.57142857142856
avg_envstep_per_sec: 2513.5715039583934
avg_train_sample_per_sec: 2513.5715039583934
avg_episode_per_sec: 8.532977947482422
collect_time: 0.8203466647965834
reward_mean: 3148.0434004086997
reward_std: 569.621630226344
reward_max: 3506.1230004347644
reward_min: 1918.8578451994765
total_envstep_count: 9940347
total_train_sample_count: 7485479
total_episode_count: 25279
total_duration: 2142.131420612771
[2023-06-29 11:48:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 302.25
avg_sample_per_episode: 302.25
avg_envstep_per_sec: 2738.2094265101277
avg_train_sample_per_sec: 2738.2094265101277
avg_episode_per_sec: 9.05941911169604
collect_time: 0.44152941272314633
reward_mean: 3081.518553721663
reward_std: 694.5448753013859
reward_max: 3492.134336027363
reward_min: 1878.6457043398243
total_envstep_count: 9944627
total_train_sample_count: 7488688
total_episode_count: 25283
total_duration: 2142.572950025494
[2023-06-29 11:48:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1774
train_sample_count: 1774
avg_envstep_per_episode: 295.6666666666667
avg_sample_per_episode: 295.6666666666667
avg_envstep_per_sec: 2780.62278509287
avg_train_sample_per_sec: 2780.62278509287
avg_episode_per_sec: 9.404586646311849
collect_time: 0.6379865724723788
reward_mean: 3121.3826246570875
reward_std: 918.8460761526499
reward_max: 3619.6912854362736
reward_min: 1069.2396444684643
total_envstep_count: 9949155
total_train_sample_count: 7492062
total_episode_count: 25289
total_duration: 2143.2109365979663
[2023-06-29 11:48:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1759
train_sample_count: 1759
avg_envstep_per_episode: 439.75
avg_sample_per_episode: 439.75
avg_envstep_per_sec: 2705.418181247908
avg_train_sample_per_sec: 2705.418181247908
avg_episode_per_sec: 6.152173237630262
collect_time: 0.6501767498245463
reward_mean: 3497.624767496308
reward_std: 93.41844485856907
reward_max: 3625.3475318405135
reward_min: 3370.1698805394167
total_envstep_count: 9953955
total_train_sample_count: 7495421
total_episode_count: 25293
total_duration: 2143.8611133477907
[2023-06-29 11:48:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 208.5
avg_sample_per_episode: 208.5
avg_envstep_per_sec: 2810.6570997103236
avg_train_sample_per_sec: 2810.6570997103236
avg_episode_per_sec: 13.480369782783328
collect_time: 0.4450916478317232
reward_mean: 2628.794866707441
reward_std: 870.1652575354514
reward_max: 3486.176261974056
reward_min: 1292.2848644211479
total_envstep_count: 9958459
total_train_sample_count: 7498672
total_episode_count: 25299
total_duration: 2144.3062049956225
[2023-06-29 11:48:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 278.6666666666667
avg_sample_per_episode: 278.6666666666667
avg_envstep_per_sec: 2852.240440974731
avg_train_sample_per_sec: 2852.240440974731
avg_episode_per_sec: 10.235312587229895
collect_time: 0.29310291937179866
reward_mean: 3467.2758626923005
reward_std: 37.66545678641339
reward_max: 3502.5235354639644
reward_min: 3415.0654519526815
total_envstep_count: 9962003
total_train_sample_count: 7501908
total_episode_count: 25302
total_duration: 2144.5993079149944
[2023-06-29 11:48:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2109
train_sample_count: 2109
avg_envstep_per_episode: 301.2857142857143
avg_sample_per_episode: 301.2857142857143
avg_envstep_per_sec: 2739.5715029615067
avg_train_sample_per_sec: 2739.5715029615067
avg_episode_per_sec: 9.092935287212207
collect_time: 0.7698284194152801
reward_mean: 3069.3025979787085
reward_std: 823.6900603113199
reward_max: 3569.23223330861
reward_min: 1066.503536097415
total_envstep_count: 9966803
total_train_sample_count: 7505217
total_episode_count: 25309
total_duration: 2145.3691363344096
[2023-06-29 11:48:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2357
train_sample_count: 2357
avg_envstep_per_episode: 336.7142857142857
avg_sample_per_episode: 336.7142857142857
avg_envstep_per_sec: 2664.295130060427
avg_train_sample_per_sec: 2664.295130060427
avg_episode_per_sec: 7.912628727375049
collect_time: 0.8846617528991777
reward_mean: 2414.5109583830804
reward_std: 733.3533861582587
reward_max: 3505.317997879089
reward_min: 1612.6922590995036
total_envstep_count: 9971787
total_train_sample_count: 7508774
total_episode_count: 25316
total_duration: 2146.253798087309
[2023-06-29 11:48:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1312
train_sample_count: 1312
avg_envstep_per_episode: 328.0
avg_sample_per_episode: 328.0
avg_envstep_per_sec: 2795.01206093134
avg_train_sample_per_sec: 2795.01206093134
avg_episode_per_sec: 8.521378234546768
collect_time: 0.46940763452835405
reward_mean: 2913.8199665179845
reward_std: 942.3767762471009
reward_max: 3480.268470803543
reward_min: 1281.7493248150226
total_envstep_count: 9976587
total_train_sample_count: 7512086
total_episode_count: 25320
total_duration: 2146.7232057218375
[2023-06-29 11:48:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1852
train_sample_count: 1852
avg_envstep_per_episode: 205.77777777777777
avg_sample_per_episode: 205.77777777777777
avg_envstep_per_sec: 2811.585625449219
avg_train_sample_per_sec: 2811.585625449219
avg_episode_per_sec: 13.663213082636593
collect_time: 0.6587030404610559
reward_mean: 2301.0370526586103
reward_std: 1209.3019737056864
reward_max: 3539.3841137262343
reward_min: 39.2288876763069
total_envstep_count: 9981283
total_train_sample_count: 7515538
total_episode_count: 25329
total_duration: 2147.3819087622987
[2023-06-29 11:48:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1249
train_sample_count: 1249
avg_envstep_per_episode: 416.3333333333333
avg_sample_per_episode: 416.3333333333333
avg_envstep_per_sec: 2796.9628982703807
avg_train_sample_per_sec: 2796.9628982703807
avg_episode_per_sec: 6.718085424188264
collect_time: 0.4465557983526959
reward_mean: 3080.7165914856582
reward_std: 506.0002690397184
reward_max: 3500.3238936121447
reward_min: 2368.915238830067
total_envstep_count: 9985523
total_train_sample_count: 7518787
total_episode_count: 25332
total_duration: 2147.8284645606514
[2023-06-29 11:48:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1379
train_sample_count: 1379
avg_envstep_per_episode: 197.0
avg_sample_per_episode: 197.0
avg_envstep_per_sec: 2701.571061420702
avg_train_sample_per_sec: 2701.571061420702
avg_episode_per_sec: 13.713558687414729
collect_time: 0.5104437265014276
reward_mean: 2761.5530318637025
reward_std: 987.0463162083015
reward_max: 3518.8131183123633
reward_min: 1026.6190891519827
total_envstep_count: 9990227
total_train_sample_count: 7522166
total_episode_count: 25339
total_duration: 2148.3389082871527
[2023-06-29 11:48:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1851
train_sample_count: 1851
avg_envstep_per_episode: 308.5
avg_sample_per_episode: 308.5
avg_envstep_per_sec: 2610.1157891399976
avg_train_sample_per_sec: 2610.1157891399976
avg_episode_per_sec: 8.460667063662877
collect_time: 0.7091639411943034
reward_mean: 2786.1237705277326
reward_std: 823.8368373074253
reward_max: 3495.5106892359927
reward_min: 1183.5946464537797
total_envstep_count: 9995243
total_train_sample_count: 7525617
total_episode_count: 25345
total_duration: 2149.048072228347
[2023-06-29 11:48:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 177.6
avg_sample_per_episode: 177.6
avg_envstep_per_sec: 2208.6240380391127
avg_train_sample_per_sec: 2208.6240380391127
avg_episode_per_sec: 12.435946160130138
collect_time: 0.4020602803854272
reward_mean: 2806.152869073014
reward_std: 844.0789397213035
reward_max: 3493.193789301672
reward_min: 1477.8308528322866
total_envstep_count: 9999107
total_train_sample_count: 7528905
total_episode_count: 25350
total_duration: 2149.450132508732
[2023-06-29 11:48:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 306.5
avg_sample_per_episode: 306.5
avg_envstep_per_sec: 2479.0073067041044
avg_train_sample_per_sec: 2479.0073067041044
avg_episode_per_sec: 8.088115193161842
collect_time: 0.9891055961670354
reward_mean: 2524.719246751234
reward_std: 840.099828856483
reward_max: 3479.658901673018
reward_min: 1240.2004102768963
total_envstep_count: 10003403
total_train_sample_count: 7532157
total_episode_count: 25358
total_duration: 2150.4392381048992
[2023-06-29 11:48:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 481
train_sample_count: 481
avg_envstep_per_episode: 240.5
avg_sample_per_episode: 240.5
avg_envstep_per_sec: 2712.032935121426
avg_train_sample_per_sec: 2712.032935121426
avg_episode_per_sec: 11.27664422087911
collect_time: 0.17735772813484074
reward_mean: 3385.8629310488222
reward_std: 40.40237395461213
reward_max: 3426.265305003434
reward_min: 3345.46055709421
total_envstep_count: 10007107
total_train_sample_count: 7535438
total_episode_count: 25360
total_duration: 2150.616595833034
[2023-06-29 11:48:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2546
train_sample_count: 2546
avg_envstep_per_episode: 363.7142857142857
avg_sample_per_episode: 363.7142857142857
avg_envstep_per_sec: 2684.256106143411
avg_train_sample_per_sec: 2684.256106143411
avg_episode_per_sec: 7.380122837000737
collect_time: 0.9484936978155748
reward_mean: 3000.3693947375627
reward_std: 920.5486838652322
reward_max: 3482.314374271074
reward_min: 782.5415492401555
total_envstep_count: 10011403
total_train_sample_count: 7538784
total_episode_count: 25367
total_duration: 2151.5650895308495
[2023-06-29 11:48:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 261.3333333333333
avg_sample_per_episode: 261.3333333333333
avg_envstep_per_sec: 2789.4694875734754
avg_train_sample_per_sec: 2789.4694875734754
avg_episode_per_sec: 10.673990386122993
collect_time: 0.5621140532223508
reward_mean: 2031.100609850956
reward_std: 1026.2556336723608
reward_max: 3469.0673656025665
reward_min: 1083.987295683439
total_envstep_count: 10016715
total_train_sample_count: 7542352
total_episode_count: 25373
total_duration: 2152.127203584072
[2023-06-29 11:48:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1546
train_sample_count: 1546
avg_envstep_per_episode: 257.6666666666667
avg_sample_per_episode: 257.6666666666667
avg_envstep_per_sec: 2713.5321640179122
avg_train_sample_per_sec: 2713.5321640179122
avg_episode_per_sec: 10.531172693471847
collect_time: 0.5697371199429035
reward_mean: 3117.1894672305843
reward_std: 547.691489457197
reward_max: 3538.95032584896
reward_min: 2245.6942797591573
total_envstep_count: 10021427
total_train_sample_count: 7545898
total_episode_count: 25379
total_duration: 2152.696940704015
[2023-06-29 11:48:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1255
train_sample_count: 1255
avg_envstep_per_episode: 209.16666666666666
avg_sample_per_episode: 209.16666666666666
avg_envstep_per_sec: 2703.9170794672514
avg_train_sample_per_sec: 2703.9170794672514
avg_episode_per_sec: 12.927093607014749
collect_time: 0.46414145223982634
reward_mean: 2141.8581425815105
reward_std: 1076.4050558777233
reward_max: 3477.385842898424
reward_min: 433.74667287362854
total_envstep_count: 10025843
total_train_sample_count: 7549153
total_episode_count: 25385
total_duration: 2153.161082156255
[2023-06-29 11:48:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1324
train_sample_count: 1324
avg_envstep_per_episode: 165.5
avg_sample_per_episode: 165.5
avg_envstep_per_sec: 2584.188117773878
avg_train_sample_per_sec: 2584.188117773878
avg_episode_per_sec: 15.614429714645786
collect_time: 0.5123466015858575
reward_mean: 2108.707566032862
reward_std: 1175.2470964647714
reward_max: 3500.675858897239
reward_min: 229.16170946853774
total_envstep_count: 10030251
total_train_sample_count: 7552477
total_episode_count: 25393
total_duration: 2153.6734287578406
[2023-06-29 11:49:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1534
train_sample_count: 1534
avg_envstep_per_episode: 219.14285714285714
avg_sample_per_episode: 219.14285714285714
avg_envstep_per_sec: 2401.746318953699
avg_train_sample_per_sec: 2401.746318953699
avg_episode_per_sec: 10.959728965238522
collect_time: 0.6387019261335953
reward_mean: 2413.1466523301615
reward_std: 1045.7621014625165
reward_max: 3502.5676561498926
reward_min: 848.2084343843786
total_envstep_count: 10034475
total_train_sample_count: 7556011
total_episode_count: 25400
total_duration: 2154.3121306839744
[2023-06-29 11:49:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1667
train_sample_count: 1667
avg_envstep_per_episode: 208.375
avg_sample_per_episode: 208.375
avg_envstep_per_sec: 2737.734938122001
avg_train_sample_per_sec: 2737.734938122001
avg_episode_per_sec: 13.138500002985008
collect_time: 0.6088975147986784
reward_mean: 2033.1286537057995
reward_std: 950.5240330095853
reward_max: 3532.9103139089098
reward_min: 253.02849621994088
total_envstep_count: 10038747
total_train_sample_count: 7559278
total_episode_count: 25408
total_duration: 2154.921028198773
[2023-06-29 11:49:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2051
train_sample_count: 2051
avg_envstep_per_episode: 341.8333333333333
avg_sample_per_episode: 341.8333333333333
avg_envstep_per_sec: 2716.5335493819316
avg_train_sample_per_sec: 2716.5335493819316
avg_episode_per_sec: 7.946953338026129
collect_time: 0.7550063206348567
reward_mean: 2683.415362277594
reward_std: 714.7672713197865
reward_max: 3463.5733284420016
reward_min: 1619.6831187832988
total_envstep_count: 10043547
total_train_sample_count: 7562529
total_episode_count: 25414
total_duration: 2155.676034519408
[2023-06-29 11:49:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2550
train_sample_count: 2550
avg_envstep_per_episode: 283.3333333333333
avg_sample_per_episode: 283.3333333333333
avg_envstep_per_sec: 2516.306596563601
avg_train_sample_per_sec: 2516.306596563601
avg_episode_per_sec: 8.881082105518592
collect_time: 1.0133900230927393
reward_mean: 2029.8155937946985
reward_std: 1066.9564956488812
reward_max: 3506.3628457864943
reward_min: 850.683559546615
total_envstep_count: 10048315
total_train_sample_count: 7565879
total_episode_count: 25423
total_duration: 2156.6894245425005
[2023-06-29 11:49:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 276.0
avg_sample_per_episode: 276.0
avg_envstep_per_sec: 2686.2544636122657
avg_train_sample_per_sec: 2686.2544636122657
avg_episode_per_sec: 9.732806027580672
collect_time: 0.9247076305123046
reward_mean: 1936.1761053349853
reward_std: 659.4118783167439
reward_max: 3537.2976813328196
reward_min: 1120.2567590776364
total_envstep_count: 10052875
total_train_sample_count: 7569163
total_episode_count: 25432
total_duration: 2157.614132173013
[2023-06-29 11:49:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2593
train_sample_count: 2593
avg_envstep_per_episode: 216.08333333333334
avg_sample_per_episode: 216.08333333333334
avg_envstep_per_sec: 2737.7660017677454
avg_train_sample_per_sec: 2737.7660017677454
avg_episode_per_sec: 12.669954501046258
collect_time: 0.947122580354102
reward_mean: 1365.8321714921942
reward_std: 447.73528699147334
reward_max: 1890.2350948756582
reward_min: 39.49790218904403
total_envstep_count: 10057267
total_train_sample_count: 7572556
total_episode_count: 25444
total_duration: 2158.561254753367
[2023-06-29 11:49:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2952
train_sample_count: 2952
avg_envstep_per_episode: 268.3636363636364
avg_sample_per_episode: 268.3636363636364
avg_envstep_per_sec: 2779.4063972956874
avg_train_sample_per_sec: 2779.4063972956874
avg_episode_per_sec: 10.35686665658962
collect_time: 1.0620972891449927
reward_mean: 1507.831248848198
reward_std: 596.3353491794902
reward_max: 2572.2378305800357
reward_min: 722.1743120538024
total_envstep_count: 10061347
total_train_sample_count: 7575908
total_episode_count: 25455
total_duration: 2159.623352042512
[2023-06-29 11:49:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2901
train_sample_count: 2901
avg_envstep_per_episode: 362.625
avg_sample_per_episode: 362.625
avg_envstep_per_sec: 2679.3129919136804
avg_train_sample_per_sec: 2679.3129919136804
avg_episode_per_sec: 7.3886604396102875
collect_time: 1.0827402430232613
reward_mean: 1788.2481843867592
reward_std: 557.2834967638714
reward_max: 2614.4023190485646
reward_min: 806.1789913393459
total_envstep_count: 10065755
total_train_sample_count: 7579209
total_episode_count: 25463
total_duration: 2160.7060922855353
[2023-06-29 11:49:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2005
train_sample_count: 2005
avg_envstep_per_episode: 250.625
avg_sample_per_episode: 250.625
avg_envstep_per_sec: 2485.610350299153
avg_train_sample_per_sec: 2485.610350299153
avg_episode_per_sec: 9.91764728298914
collect_time: 0.8066429236419498
reward_mean: 1376.8183430077695
reward_std: 367.08618046738513
reward_max: 2159.7718241074713
reward_min: 1052.8925065156102
total_envstep_count: 10070107
total_train_sample_count: 7582414
total_episode_count: 25471
total_duration: 2161.512735209177
[2023-06-29 11:49:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 2738.3675224220665
avg_train_sample_per_sec: 2738.3675224220665
avg_episode_per_sec: 14.018946360522525
collect_time: 0.42799222179036595
reward_mean: 2171.7257053063627
reward_std: 926.1721158390509
reward_max: 3498.0343039827508
reward_min: 766.8178105731151
total_envstep_count: 10075291
total_train_sample_count: 7585986
total_episode_count: 25477
total_duration: 2161.9407274309674
[2023-06-29 11:49:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2310
train_sample_count: 2310
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 2762.4330753307418
avg_train_sample_per_sec: 2762.4330753307418
avg_episode_per_sec: 11.958584741691523
collect_time: 0.8362193533768877
reward_mean: 2328.8963884140967
reward_std: 893.458773225031
reward_max: 3522.0473355081467
reward_min: 502.20326587257716
total_envstep_count: 10080051
total_train_sample_count: 7589496
total_episode_count: 25487
total_duration: 2162.776946784344
[2023-06-29 11:49:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1234
train_sample_count: 1234
avg_envstep_per_episode: 176.28571428571428
avg_sample_per_episode: 176.28571428571428
avg_envstep_per_sec: 2309.786030155263
avg_train_sample_per_sec: 2309.786030155263
avg_episode_per_sec: 13.102513947396142
collect_time: 0.5342486203871668
reward_mean: 1720.8149029230729
reward_std: 395.58460439603573
reward_max: 2362.875120708584
reward_min: 1156.0091533503585
total_envstep_count: 10084035
total_train_sample_count: 7592730
total_episode_count: 25494
total_duration: 2163.3111954047313
[2023-06-29 11:49:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1511
train_sample_count: 1511
avg_envstep_per_episode: 251.83333333333334
avg_sample_per_episode: 251.83333333333334
avg_envstep_per_sec: 2759.572960997076
avg_train_sample_per_sec: 2759.572960997076
avg_episode_per_sec: 10.957933663787198
collect_time: 0.5475484871594236
reward_mean: 2619.9024923070856
reward_std: 770.3065920135509
reward_max: 3452.7633634937515
reward_min: 1389.8269652727959
total_envstep_count: 10089067
total_train_sample_count: 7596241
total_episode_count: 25500
total_duration: 2163.8587438918908
[2023-06-29 11:49:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1979
train_sample_count: 1979
avg_envstep_per_episode: 219.88888888888889
avg_sample_per_episode: 219.88888888888889
avg_envstep_per_sec: 2744.5695547367354
avg_train_sample_per_sec: 2744.5695547367354
avg_episode_per_sec: 12.481620006382323
collect_time: 0.7210602466184646
reward_mean: 2215.8732425252047
reward_std: 1083.7211352396375
reward_max: 3592.9285377637034
reward_min: 866.4869044207404
total_envstep_count: 10094107
total_train_sample_count: 7599820
total_episode_count: 25509
total_duration: 2164.579804138509
[2023-06-29 11:49:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2890
train_sample_count: 2890
avg_envstep_per_episode: 321.1111111111111
avg_sample_per_episode: 321.1111111111111
avg_envstep_per_sec: 2707.054361393323
avg_train_sample_per_sec: 2707.054361393323
avg_episode_per_sec: 8.430273097764674
collect_time: 1.0675810730718074
reward_mean: 2339.3540137749897
reward_std: 845.1414996017553
reward_max: 3518.2076344378747
reward_min: 1095.2436548554426
total_envstep_count: 10098907
total_train_sample_count: 7603110
total_episode_count: 25518
total_duration: 2165.647385211581
[2023-06-29 11:49:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2811
train_sample_count: 2811
avg_envstep_per_episode: 351.375
avg_sample_per_episode: 351.375
avg_envstep_per_sec: 2571.5685296572124
avg_train_sample_per_sec: 2571.5685296572124
avg_episode_per_sec: 7.318587064125826
collect_time: 1.0931071708109228
reward_mean: 2111.117475669426
reward_std: 496.56637511065065
reward_max: 2753.8813787056524
reward_min: 1035.306420070895
total_envstep_count: 10102659
total_train_sample_count: 7606321
total_episode_count: 25526
total_duration: 2166.740492382392
[2023-06-29 11:49:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3118
train_sample_count: 3118
avg_envstep_per_episode: 346.44444444444446
avg_sample_per_episode: 346.44444444444446
avg_envstep_per_sec: 2520.606085246723
avg_train_sample_per_sec: 2520.606085246723
avg_episode_per_sec: 7.2756429657538515
collect_time: 1.2370040754284708
reward_mean: 1604.563977002812
reward_std: 712.9457462639938
reward_max: 3416.575512045704
reward_min: 862.8078741579511
total_envstep_count: 10107899
total_train_sample_count: 7609839
total_episode_count: 25535
total_duration: 2167.9774964578205
[2023-06-29 11:49:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1683
train_sample_count: 1683
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 2697.198189729491
avg_train_sample_per_sec: 2697.198189729491
avg_episode_per_sec: 14.423519731173748
collect_time: 0.6239808429386469
reward_mean: 1506.0336954022932
reward_std: 332.00628806053714
reward_max: 2086.2706320626453
reward_min: 879.5906095902455
total_envstep_count: 10112315
total_train_sample_count: 7613122
total_episode_count: 25544
total_duration: 2168.601477300759
[2023-06-29 11:49:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1904
train_sample_count: 1904
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 2715.6528547643
avg_train_sample_per_sec: 2715.6528547643
avg_episode_per_sec: 11.410306112455043
collect_time: 0.7011205414785072
reward_mean: 1994.5229553485274
reward_std: 368.1254262067221
reward_max: 2593.999293052067
reward_min: 1482.220991101451
total_envstep_count: 10116995
total_train_sample_count: 7616626
total_episode_count: 25552
total_duration: 2169.3025978422374
[2023-06-29 11:50:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3041
train_sample_count: 3041
avg_envstep_per_episode: 253.41666666666666
avg_sample_per_episode: 253.41666666666666
avg_envstep_per_sec: 2581.476115761202
avg_train_sample_per_sec: 2581.476115761202
avg_episode_per_sec: 10.18668641536811
collect_time: 1.1780081874215977
reward_mean: 1816.404076588199
reward_std: 832.8185456579039
reward_max: 3303.8971302098525
reward_min: 663.1033393982107
total_envstep_count: 10121675
total_train_sample_count: 7620067
total_episode_count: 25564
total_duration: 2170.480606029659
[2023-06-29 11:50:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2367
train_sample_count: 2367
avg_envstep_per_episode: 295.875
avg_sample_per_episode: 295.875
avg_envstep_per_sec: 2561.9444722963813
avg_train_sample_per_sec: 2561.9444722963813
avg_episode_per_sec: 8.658874431081982
collect_time: 0.9239076122045518
reward_mean: 1750.075324191634
reward_std: 473.2429237791293
reward_max: 2572.89428491249
reward_min: 1320.445610203049
total_envstep_count: 10126587
total_train_sample_count: 7623634
total_episode_count: 25572
total_duration: 2171.4045136418636
[2023-06-29 11:50:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2809
train_sample_count: 2809
avg_envstep_per_episode: 234.08333333333334
avg_sample_per_episode: 234.08333333333334
avg_envstep_per_sec: 2697.8903845984214
avg_train_sample_per_sec: 2697.8903845984214
avg_episode_per_sec: 11.52534162163797
collect_time: 1.0411838879873976
reward_mean: 1596.7938896533572
reward_std: 477.97906873614687
reward_max: 2760.806826951731
reward_min: 1026.017213319428
total_envstep_count: 10130899
total_train_sample_count: 7626843
total_episode_count: 25584
total_duration: 2172.445697529851
[2023-06-29 11:50:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1400
train_sample_count: 1400
avg_envstep_per_episode: 350.0
avg_sample_per_episode: 350.0
avg_envstep_per_sec: 2743.3428831846045
avg_train_sample_per_sec: 2743.3428831846045
avg_episode_per_sec: 7.838122523384584
collect_time: 0.5103262915406377
reward_mean: 2313.3221502818033
reward_std: 878.5536012711071
reward_max: 3444.1535264861113
reward_min: 1305.4837371567428
total_envstep_count: 10136227
total_train_sample_count: 7630243
total_episode_count: 25588
total_duration: 2172.956023821391
[2023-06-29 11:50:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1998
train_sample_count: 1998
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2565.448117580164
avg_train_sample_per_sec: 2565.448117580164
avg_episode_per_sec: 11.556072601712449
collect_time: 0.7788113064179196
reward_mean: 2539.653127250298
reward_std: 988.9277098341865
reward_max: 3491.537942618998
reward_min: 1269.887316538288
total_envstep_count: 10141323
total_train_sample_count: 7633841
total_episode_count: 25597
total_duration: 2173.734835127809
[2023-06-29 11:50:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2510
train_sample_count: 2510
avg_envstep_per_episode: 358.57142857142856
avg_sample_per_episode: 358.57142857142856
avg_envstep_per_sec: 2657.8816677430154
avg_train_sample_per_sec: 2657.8816677430154
avg_episode_per_sec: 7.412418993705621
collect_time: 0.9443610791489482
reward_mean: 2754.4023256009
reward_std: 817.3528867221934
reward_max: 3549.8851050104836
reward_min: 1346.6089481457082
total_envstep_count: 10145523
total_train_sample_count: 7637151
total_episode_count: 25604
total_duration: 2174.6791962069583
[2023-06-29 11:50:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2620
train_sample_count: 2620
avg_envstep_per_episode: 327.5
avg_sample_per_episode: 327.5
avg_envstep_per_sec: 2549.3663328635657
avg_train_sample_per_sec: 2549.3663328635657
avg_episode_per_sec: 7.784324680499438
collect_time: 1.0277063622539861
reward_mean: 1912.2874332664646
reward_std: 781.0093601846349
reward_max: 3488.1990777255232
reward_min: 1028.8202359890408
total_envstep_count: 10150667
total_train_sample_count: 7640571
total_episode_count: 25612
total_duration: 2175.706902569212
[2023-06-29 11:50:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 195.85714285714286
avg_sample_per_episode: 195.85714285714286
avg_envstep_per_sec: 2767.7961893915767
avg_train_sample_per_sec: 2767.7961893915767
avg_episode_per_sec: 14.131709209147365
collect_time: 0.4953399405833333
reward_mean: 1982.229414923138
reward_std: 677.3374831924261
reward_max: 3244.602781424087
reward_min: 1262.8666074918126
total_envstep_count: 10155219
total_train_sample_count: 7643942
total_episode_count: 25619
total_duration: 2176.2022425097953
[2023-06-29 11:50:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3039
train_sample_count: 3039
avg_envstep_per_episode: 303.9
avg_sample_per_episode: 303.9
avg_envstep_per_sec: 2703.612337418985
avg_train_sample_per_sec: 2703.612337418985
avg_episode_per_sec: 8.89638807969393
collect_time: 1.1240516837192696
reward_mean: 2254.790534163595
reward_std: 894.760138918503
reward_max: 3484.1061150800188
reward_min: 1183.0864914051776
total_envstep_count: 10160107
total_train_sample_count: 7647381
total_episode_count: 25629
total_duration: 2177.3262941935145
[2023-06-29 11:50:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 323.77777777777777
avg_sample_per_episode: 323.77777777777777
avg_envstep_per_sec: 2809.1242276667253
avg_train_sample_per_sec: 2809.1242276667253
avg_episode_per_sec: 8.67608718222393
collect_time: 1.037333974517882
reward_mean: 1890.908662424218
reward_std: 721.5399819521455
reward_max: 3558.7540578130697
reward_min: 669.0063345292436
total_envstep_count: 10165019
total_train_sample_count: 7650695
total_episode_count: 25638
total_duration: 2178.3636281680324
[2023-06-29 11:50:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2795
train_sample_count: 2795
avg_envstep_per_episode: 279.5
avg_sample_per_episode: 279.5
avg_envstep_per_sec: 2627.3595378361533
avg_train_sample_per_sec: 2627.3595378361533
avg_episode_per_sec: 9.400213015513964
collect_time: 1.0638056800942868
reward_mean: 1713.2397317239756
reward_std: 673.4380053852304
reward_max: 3119.0077052300867
reward_min: 867.3007736293067
total_envstep_count: 10170587
total_train_sample_count: 7654290
total_episode_count: 25648
total_duration: 2179.427433848127
[2023-06-29 11:50:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1806
train_sample_count: 1806
avg_envstep_per_episode: 225.75
avg_sample_per_episode: 225.75
avg_envstep_per_sec: 2781.566333876688
avg_train_sample_per_sec: 2781.566333876688
avg_episode_per_sec: 12.321445554271044
collect_time: 0.6492744674123825
reward_mean: 1710.8570648843167
reward_std: 599.8754720485587
reward_max: 2842.9774913920983
reward_min: 929.1669703008153
total_envstep_count: 10174723
total_train_sample_count: 7657696
total_episode_count: 25656
total_duration: 2180.0767083155392
[2023-06-29 11:50:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2860
train_sample_count: 2860
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2674.639025826693
avg_train_sample_per_sec: 2674.639025826693
avg_episode_per_sec: 9.351884705687736
collect_time: 1.0693031741417947
reward_mean: 1952.4750592317137
reward_std: 1082.8201772532022
reward_max: 3472.0844641825565
reward_min: 242.71171419015943
total_envstep_count: 10179451
total_train_sample_count: 7660956
total_episode_count: 25666
total_duration: 2181.146011489681
[2023-06-29 11:50:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 179.8
avg_sample_per_episode: 179.8
avg_envstep_per_sec: 2806.166464085049
avg_train_sample_per_sec: 2806.166464085049
avg_episode_per_sec: 15.607154972664343
collect_time: 0.32036588402930655
reward_mean: 1621.621958141514
reward_std: 861.3748889805495
reward_max: 3341.9971888278465
reward_min: 1141.9964203951347
total_envstep_count: 10183211
total_train_sample_count: 7664255
total_episode_count: 25671
total_duration: 2181.46637737371
[2023-06-29 11:50:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3159
train_sample_count: 3159
avg_envstep_per_episode: 263.25
avg_sample_per_episode: 263.25
avg_envstep_per_sec: 2560.693346469738
avg_train_sample_per_sec: 2560.693346469738
avg_episode_per_sec: 9.727230186019899
collect_time: 1.233650255058892
reward_mean: 1999.124711299676
reward_std: 1010.7520863475238
reward_max: 3436.5139011763076
reward_min: 53.70810507289179
total_envstep_count: 10187875
total_train_sample_count: 7667814
total_episode_count: 25683
total_duration: 2182.700027628769
[2023-06-29 11:50:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2179
train_sample_count: 2179
avg_envstep_per_episode: 311.2857142857143
avg_sample_per_episode: 311.2857142857143
avg_envstep_per_sec: 2692.536255743941
avg_train_sample_per_sec: 2692.536255743941
avg_episode_per_sec: 8.649726383757498
collect_time: 0.8092741538211703
reward_mean: 1707.474337345187
reward_std: 361.23049000383696
reward_max: 2126.297657086617
reward_min: 1148.765095827923
total_envstep_count: 10192827
total_train_sample_count: 7671193
total_episode_count: 25690
total_duration: 2183.5093017825902
[2023-06-29 11:50:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2025
train_sample_count: 2025
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 2565.782281642968
avg_train_sample_per_sec: 2565.782281642968
avg_episode_per_sec: 12.6705297858912
collect_time: 0.789232981491834
reward_mean: 1715.6486421988866
reward_std: 679.4825440519775
reward_max: 3456.34455963698
reward_min: 1154.5541106280398
total_envstep_count: 10196467
total_train_sample_count: 7674418
total_episode_count: 25700
total_duration: 2184.298534764082
[2023-06-29 11:50:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1966
train_sample_count: 1966
avg_envstep_per_episode: 245.75
avg_sample_per_episode: 245.75
avg_envstep_per_sec: 2714.1194547101395
avg_train_sample_per_sec: 2714.1194547101395
avg_episode_per_sec: 11.044229724151128
collect_time: 0.7243601590888575
reward_mean: 1755.5968969789242
reward_std: 651.0005010236803
reward_max: 2834.4470476791375
reward_min: 896.1858445157789
total_envstep_count: 10201363
total_train_sample_count: 7677984
total_episode_count: 25708
total_duration: 2185.022894923171
[2023-06-29 11:50:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2825
train_sample_count: 2825
avg_envstep_per_episode: 256.8181818181818
avg_sample_per_episode: 256.8181818181818
avg_envstep_per_sec: 2759.831944974309
avg_train_sample_per_sec: 2759.831944974309
avg_episode_per_sec: 10.746248281315895
collect_time: 1.023613051926717
reward_mean: 1878.2085828780853
reward_std: 808.8447519700194
reward_max: 3452.018617102885
reward_min: 1026.4164609951783
total_envstep_count: 10205395
total_train_sample_count: 7681209
total_episode_count: 25719
total_duration: 2186.0465079750975
[2023-06-29 11:51:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2001
train_sample_count: 2001
avg_envstep_per_episode: 222.33333333333334
avg_sample_per_episode: 222.33333333333334
avg_envstep_per_sec: 2595.266251552313
avg_train_sample_per_sec: 2595.266251552313
avg_episode_per_sec: 11.67286170113484
collect_time: 0.7710191579777748
reward_mean: 1263.8691289029166
reward_std: 453.57928884596845
reward_max: 1568.988511625261
reward_min: 38.251263532395164
total_envstep_count: 10209363
total_train_sample_count: 7684410
total_episode_count: 25728
total_duration: 2186.817527133075
[2023-06-29 11:51:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2265
train_sample_count: 2265
avg_envstep_per_episode: 283.125
avg_sample_per_episode: 283.125
avg_envstep_per_sec: 2816.2304840269717
avg_train_sample_per_sec: 2816.2304840269717
avg_episode_per_sec: 9.946950936960606
collect_time: 0.8042665587374942
reward_mean: 1760.8715348610158
reward_std: 598.1046687679601
reward_max: 2714.7198647505215
reward_min: 965.8288477813044
total_envstep_count: 10214387
total_train_sample_count: 7687875
total_episode_count: 25736
total_duration: 2187.621793691813
[2023-06-29 11:51:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2425
train_sample_count: 2425
avg_envstep_per_episode: 303.125
avg_sample_per_episode: 303.125
avg_envstep_per_sec: 2504.520930552104
avg_train_sample_per_sec: 2504.520930552104
avg_episode_per_sec: 8.262337090481168
collect_time: 0.9682490453235805
reward_mean: 2263.0659143948883
reward_std: 804.7152758290725
reward_max: 3398.443646843606
reward_min: 1542.7676070998882
total_envstep_count: 10218955
total_train_sample_count: 7691100
total_episode_count: 25744
total_duration: 2188.5900427371366
[2023-06-29 11:51:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1564
train_sample_count: 1564
avg_envstep_per_episode: 223.42857142857142
avg_sample_per_episode: 223.42857142857142
avg_envstep_per_sec: 2748.923996465691
avg_train_sample_per_sec: 2748.923996465691
avg_episode_per_sec: 12.303368270626493
collect_time: 0.5689498880328612
reward_mean: 1792.854602682368
reward_std: 1155.0048023952681
reward_max: 3388.8375243393652
reward_min: 58.81129355970901
total_envstep_count: 10223955
total_train_sample_count: 7694664
total_episode_count: 25751
total_duration: 2189.1589926251695
[2023-06-29 11:51:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1619
train_sample_count: 1619
avg_envstep_per_episode: 202.375
avg_sample_per_episode: 202.375
avg_envstep_per_sec: 2791.0491737731586
avg_train_sample_per_sec: 2791.0491737731586
avg_episode_per_sec: 13.791472137236113
collect_time: 0.5800686047431078
reward_mean: 2096.6420733090517
reward_std: 1014.5331368973052
reward_max: 3374.150545084764
reward_min: 267.2342510167629
total_envstep_count: 10228339
total_train_sample_count: 7697883
total_episode_count: 25759
total_duration: 2189.7390612299127
[2023-06-29 11:51:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1955
train_sample_count: 1955
avg_envstep_per_episode: 217.22222222222223
avg_sample_per_episode: 217.22222222222223
avg_envstep_per_sec: 2622.0186637313354
avg_train_sample_per_sec: 2622.0186637313354
avg_episode_per_sec: 12.070674155284921
collect_time: 0.745608727749437
reward_mean: 1924.0771625544803
reward_std: 812.967108474431
reward_max: 3427.437129190279
reward_min: 997.6241545691479
total_envstep_count: 10233043
total_train_sample_count: 7701438
total_episode_count: 25768
total_duration: 2190.4846699576624
[2023-06-29 11:51:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2441
train_sample_count: 2441
avg_envstep_per_episode: 305.125
avg_sample_per_episode: 305.125
avg_envstep_per_sec: 2546.7046094471334
avg_train_sample_per_sec: 2546.7046094471334
avg_episode_per_sec: 8.346430510273278
collect_time: 0.9584935728097335
reward_mean: 2196.803991077716
reward_std: 896.5269801984924
reward_max: 3372.190513783483
reward_min: 605.3328191641926
total_envstep_count: 10237435
total_train_sample_count: 7704679
total_episode_count: 25776
total_duration: 2191.4431635304722
[2023-06-29 11:51:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1105
train_sample_count: 1105
avg_envstep_per_episode: 276.25
avg_sample_per_episode: 276.25
avg_envstep_per_sec: 2675.145711020668
avg_train_sample_per_sec: 2675.145711020668
avg_episode_per_sec: 9.683785379260337
collect_time: 0.41306161210127174
reward_mean: 2466.029629939281
reward_std: 961.6863964832982
reward_max: 3433.8332531617607
reward_min: 1448.787722861196
total_envstep_count: 10241955
total_train_sample_count: 7708184
total_episode_count: 25780
total_duration: 2191.8562251425733
[2023-06-29 11:51:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1731
train_sample_count: 1731
avg_envstep_per_episode: 247.28571428571428
avg_sample_per_episode: 247.28571428571428
avg_envstep_per_sec: 2712.5146374621695
avg_train_sample_per_sec: 2712.5146374621695
avg_episode_per_sec: 10.969152202331129
collect_time: 0.6381532383617015
reward_mean: 2779.23284555485
reward_std: 945.4971542093703
reward_max: 3481.4327160100524
reward_min: 1037.39200095228
total_envstep_count: 10246299
total_train_sample_count: 7711515
total_episode_count: 25787
total_duration: 2192.494378380935
[2023-06-29 11:51:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1986
train_sample_count: 1986
avg_envstep_per_episode: 397.2
avg_sample_per_episode: 397.2
avg_envstep_per_sec: 2490.542724101907
avg_train_sample_per_sec: 2490.542724101907
avg_episode_per_sec: 6.2702485501055065
collect_time: 0.7974165553478526
reward_mean: 3053.398860240205
reward_std: 293.6470458189139
reward_max: 3484.683340228476
reward_min: 2754.751918903516
total_envstep_count: 10251219
total_train_sample_count: 7715101
total_episode_count: 25792
total_duration: 2193.2917949362827
[2023-06-29 11:51:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2017
train_sample_count: 2017
avg_envstep_per_episode: 288.14285714285717
avg_sample_per_episode: 288.14285714285717
avg_envstep_per_sec: 2714.2450313249656
avg_train_sample_per_sec: 2714.2450313249656
avg_episode_per_sec: 9.419789399739592
collect_time: 0.7431164013277741
reward_mean: 2474.522254303876
reward_std: 701.6385211797759
reward_max: 3379.712101303865
reward_min: 1351.9385479294806
total_envstep_count: 10255523
total_train_sample_count: 7718318
total_episode_count: 25799
total_duration: 2194.0349113376105
[2023-06-29 11:51:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2068
train_sample_count: 2068
avg_envstep_per_episode: 258.5
avg_sample_per_episode: 258.5
avg_envstep_per_sec: 2458.000059163162
avg_train_sample_per_sec: 2458.000059163162
avg_episode_per_sec: 9.508704290766584
collect_time: 0.8413343979755886
reward_mean: 2059.3166825922926
reward_std: 807.657314248567
reward_max: 3399.9209539027092
reward_min: 1312.9941140746105
total_envstep_count: 10259923
total_train_sample_count: 7721586
total_episode_count: 25807
total_duration: 2194.876245735586
[2023-06-29 11:51:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2508
train_sample_count: 2508
avg_envstep_per_episode: 358.2857142857143
avg_sample_per_episode: 358.2857142857143
avg_envstep_per_sec: 2751.3223798365334
avg_train_sample_per_sec: 2751.3223798365334
avg_episode_per_sec: 7.6791294493045195
collect_time: 0.911561661541462
reward_mean: 2290.697717528753
reward_std: 717.816960972716
reward_max: 3356.4017537566374
reward_min: 1098.0707174993745
total_envstep_count: 10264043
total_train_sample_count: 7724894
total_episode_count: 25814
total_duration: 2195.7878073971274
[2023-06-29 11:51:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2127
train_sample_count: 2127
avg_envstep_per_episode: 265.875
avg_sample_per_episode: 265.875
avg_envstep_per_sec: 2475.8342250950996
avg_train_sample_per_sec: 2475.8342250950996
avg_episode_per_sec: 9.312023413615794
collect_time: 0.8591043691216037
reward_mean: 1695.3145874785303
reward_std: 703.7009362415768
reward_max: 3379.9069085408173
reward_min: 919.0947859266744
total_envstep_count: 10268347
total_train_sample_count: 7728221
total_episode_count: 25822
total_duration: 2196.646911766249
[2023-06-29 11:51:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1677
train_sample_count: 1677
avg_envstep_per_episode: 209.625
avg_sample_per_episode: 209.625
avg_envstep_per_sec: 2660.755637348016
avg_train_sample_per_sec: 2660.755637348016
avg_episode_per_sec: 12.692930887766327
collect_time: 0.6302720837872475
reward_mean: 1819.993749569176
reward_std: 658.2727783714804
reward_max: 2926.396879016616
reward_min: 1106.9688823460442
total_envstep_count: 10272995
total_train_sample_count: 7731498
total_episode_count: 25830
total_duration: 2197.277183850036
[2023-06-29 11:51:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2285
train_sample_count: 2285
avg_envstep_per_episode: 228.5
avg_sample_per_episode: 228.5
avg_envstep_per_sec: 2568.624573448353
avg_train_sample_per_sec: 2568.624573448353
avg_episode_per_sec: 11.241245398023429
collect_time: 0.8895811492344363
reward_mean: 1871.891164731857
reward_std: 640.3060765691357
reward_max: 3378.6879590373483
reward_min: 1024.930380773643
total_envstep_count: 10277227
total_train_sample_count: 7734983
total_episode_count: 25840
total_duration: 2198.1667649992705
[2023-06-29 11:51:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2748
train_sample_count: 2748
avg_envstep_per_episode: 343.5
avg_sample_per_episode: 343.5
avg_envstep_per_sec: 2765.973866882381
avg_train_sample_per_sec: 2765.973866882381
avg_episode_per_sec: 8.052325667779858
collect_time: 0.9935017943959681
reward_mean: 2026.4621108480255
reward_std: 873.0643381251576
reward_max: 3393.698155595075
reward_min: 802.949807394337
total_envstep_count: 10282259
total_train_sample_count: 7738531
total_episode_count: 25848
total_duration: 2199.1602667936663
[2023-06-29 11:51:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 326.3333333333333
avg_sample_per_episode: 326.3333333333333
avg_envstep_per_sec: 2778.052889684628
avg_train_sample_per_sec: 2778.052889684628
avg_episode_per_sec: 8.512930203323682
collect_time: 1.0572152930945156
reward_mean: 2094.649366424809
reward_std: 777.4089227787563
reward_max: 3561.6213542041755
reward_min: 1078.1617661710904
total_envstep_count: 10286955
total_train_sample_count: 7741868
total_episode_count: 25857
total_duration: 2200.217482086761
[2023-06-29 11:51:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3360
train_sample_count: 3360
avg_envstep_per_episode: 258.46153846153845
avg_sample_per_episode: 258.46153846153845
avg_envstep_per_sec: 2638.796468845877
avg_train_sample_per_sec: 2638.796468845877
avg_episode_per_sec: 10.209629194939405
collect_time: 1.2733077521016822
reward_mean: 1435.671504967828
reward_std: 588.2394792806253
reward_max: 3140.288626922325
reward_min: 907.1713635577199
total_envstep_count: 10291411
total_train_sample_count: 7745228
total_episode_count: 25870
total_duration: 2201.4907898388624
[2023-06-29 11:51:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2473
train_sample_count: 2473
avg_envstep_per_episode: 309.125
avg_sample_per_episode: 309.125
avg_envstep_per_sec: 2591.761943934714
avg_train_sample_per_sec: 2591.761943934714
avg_episode_per_sec: 8.384187444997053
collect_time: 0.9541771402992305
reward_mean: 1486.2153825876148
reward_std: 244.39605209840823
reward_max: 1896.1264735715629
reward_min: 1025.1113353774545
total_envstep_count: 10296267
total_train_sample_count: 7748501
total_episode_count: 25878
total_duration: 2202.4449669791616
[2023-06-29 11:52:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2712
train_sample_count: 2712
avg_envstep_per_episode: 246.54545454545453
avg_sample_per_episode: 246.54545454545453
avg_envstep_per_sec: 2451.320682786637
avg_train_sample_per_sec: 2451.320682786637
avg_episode_per_sec: 9.942672385934
collect_time: 1.106342396995984
reward_mean: 1715.6852351687232
reward_std: 670.9946808504408
reward_max: 3330.35145608966
reward_min: 980.4038856862629
total_envstep_count: 10301179
total_train_sample_count: 7752413
total_episode_count: 25889
total_duration: 2203.5513093761574
[2023-06-29 11:52:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 264.54545454545456
avg_sample_per_episode: 264.54545454545456
avg_envstep_per_sec: 2750.089613733522
avg_train_sample_per_sec: 2750.089613733522
avg_episode_per_sec: 10.395527749508158
collect_time: 1.0581473365332934
reward_mean: 1609.4668355707834
reward_std: 691.9489825082483
reward_max: 3380.9383167300844
reward_min: 538.9189587949012
total_envstep_count: 10305979
total_train_sample_count: 7755723
total_episode_count: 25900
total_duration: 2204.6094567126906
[2023-06-29 11:52:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2743
train_sample_count: 2743
avg_envstep_per_episode: 274.3
avg_sample_per_episode: 274.3
avg_envstep_per_sec: 2704.7162897925723
avg_train_sample_per_sec: 2704.7162897925723
avg_episode_per_sec: 9.860431242408211
collect_time: 1.014154427343048
reward_mean: 1654.9690295566966
reward_std: 563.1384600650119
reward_max: 2680.8909580050613
reward_min: 1063.8128694770435
total_envstep_count: 10310755
total_train_sample_count: 7759266
total_episode_count: 25910
total_duration: 2205.6236111400335
[2023-06-29 11:52:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2026
train_sample_count: 2026
avg_envstep_per_episode: 184.1818181818182
avg_sample_per_episode: 184.1818181818182
avg_envstep_per_sec: 2576.042891168962
avg_train_sample_per_sec: 2576.042891168962
avg_episode_per_sec: 13.986412538429706
collect_time: 0.7864775881431996
reward_mean: 1232.4831643315474
reward_std: 500.36391986951946
reward_max: 2258.2301407962227
reward_min: 43.19070403850593
total_envstep_count: 10314883
total_train_sample_count: 7762492
total_episode_count: 25921
total_duration: 2206.4100887281766
[2023-06-29 11:52:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 241.25
avg_sample_per_episode: 241.25
avg_envstep_per_sec: 2611.505359483898
avg_train_sample_per_sec: 2611.505359483898
avg_episode_per_sec: 10.82489268179854
collect_time: 1.1085560247795656
reward_mean: 1577.1110916188309
reward_std: 571.4269555517353
reward_max: 3075.5729286125556
reward_min: 846.1996480004844
total_envstep_count: 10319115
total_train_sample_count: 7765787
total_episode_count: 25933
total_duration: 2207.5186447529563
[2023-06-29 11:52:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2768
train_sample_count: 2768
avg_envstep_per_episode: 276.8
avg_sample_per_episode: 276.8
avg_envstep_per_sec: 2709.7704211835103
avg_train_sample_per_sec: 2709.7704211835103
avg_episode_per_sec: 9.789633024506902
collect_time: 1.021488749881275
reward_mean: 1471.4645536174635
reward_std: 491.08543967867115
reward_max: 2448.970150906354
reward_min: 1124.4421981316277
total_envstep_count: 10323939
total_train_sample_count: 7769355
total_episode_count: 25943
total_duration: 2208.5401335028378
[2023-06-29 11:52:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1427
train_sample_count: 1427
avg_envstep_per_episode: 203.85714285714286
avg_sample_per_episode: 203.85714285714286
avg_envstep_per_sec: 2674.878623515195
avg_train_sample_per_sec: 2674.878623515195
avg_episode_per_sec: 13.121338727825064
collect_time: 0.5334821503506975
reward_mean: 1485.6854361069975
reward_std: 560.0599289516153
reward_max: 2724.273194446645
reward_min: 939.3478881569531
total_envstep_count: 10328651
total_train_sample_count: 7772782
total_episode_count: 25950
total_duration: 2209.0736156531884
[2023-06-29 11:52:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1941
train_sample_count: 1941
avg_envstep_per_episode: 215.66666666666666
avg_sample_per_episode: 215.66666666666666
avg_envstep_per_sec: 2562.0301483163353
avg_train_sample_per_sec: 2562.0301483163353
avg_episode_per_sec: 11.879583377046377
collect_time: 0.7576023261379451
reward_mean: 2097.1000552437195
reward_std: 878.7129737525055
reward_max: 3428.884590540203
reward_min: 746.29911580442
total_envstep_count: 10333867
total_train_sample_count: 7776323
total_episode_count: 25959
total_duration: 2209.8312179793265
[2023-06-29 11:52:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1955
train_sample_count: 1955
avg_envstep_per_episode: 244.375
avg_sample_per_episode: 244.375
avg_envstep_per_sec: 2524.442094615822
avg_train_sample_per_sec: 2524.442094615822
avg_episode_per_sec: 10.330197829629963
collect_time: 0.7744285377627242
reward_mean: 2238.436938641949
reward_std: 867.2730847780954
reward_max: 3387.626268420645
reward_min: 1005.1483226214441
total_envstep_count: 10338723
total_train_sample_count: 7779878
total_episode_count: 25967
total_duration: 2210.605646517089
[2023-06-29 11:52:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1289
train_sample_count: 1289
avg_envstep_per_episode: 214.83333333333334
avg_sample_per_episode: 214.83333333333334
avg_envstep_per_sec: 2679.1503293681208
avg_train_sample_per_sec: 2679.1503293681208
avg_episode_per_sec: 12.470831633986599
collect_time: 0.4811226850058882
reward_mean: 2208.0081270165438
reward_std: 846.8646592510005
reward_max: 3417.0607612625
reward_min: 1384.779879622235
total_envstep_count: 10342939
total_train_sample_count: 7783167
total_episode_count: 25973
total_duration: 2211.086769202095
[2023-06-29 11:52:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 270.125
avg_sample_per_episode: 270.125
avg_envstep_per_sec: 2760.350336599494
avg_train_sample_per_sec: 2760.350336599494
avg_episode_per_sec: 10.218788844422004
collect_time: 0.78287164181564
reward_mean: 2491.6069762981065
reward_std: 707.163881844159
reward_max: 3323.3721406994496
reward_min: 1453.6796316494742
total_envstep_count: 10347227
total_train_sample_count: 7786528
total_episode_count: 25981
total_duration: 2211.869640843911
[2023-06-29 11:52:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2136
train_sample_count: 2136
avg_envstep_per_episode: 305.14285714285717
avg_sample_per_episode: 305.14285714285717
avg_envstep_per_sec: 2705.0208284395285
avg_train_sample_per_sec: 2705.0208284395285
avg_episode_per_sec: 8.864768632526545
collect_time: 0.7896427182899789
reward_mean: 1812.2324622362175
reward_std: 1149.680388882696
reward_max: 3403.9904809637583
reward_min: 250.60426045844792
total_envstep_count: 10351499
total_train_sample_count: 7789864
total_episode_count: 25988
total_duration: 2212.659283562201
[2023-06-29 11:52:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 289.0
avg_sample_per_episode: 289.0
avg_envstep_per_sec: 2670.741572558375
avg_train_sample_per_sec: 2670.741572558375
avg_episode_per_sec: 9.241320320271194
collect_time: 0.7574675216749309
reward_mean: 2296.488455117168
reward_std: 910.2100174187616
reward_max: 3447.1787408276123
reward_min: 1297.6949717179527
total_envstep_count: 10355723
total_train_sample_count: 7793087
total_episode_count: 25995
total_duration: 2213.416751083876
[2023-06-29 11:52:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2381
train_sample_count: 2381
avg_envstep_per_episode: 297.625
avg_sample_per_episode: 297.625
avg_envstep_per_sec: 2537.2428309561765
avg_train_sample_per_sec: 2537.2428309561765
avg_episode_per_sec: 8.5249654127045
collect_time: 0.9384202296091244
reward_mean: 1940.201245106225
reward_std: 790.4172016721275
reward_max: 3393.7647526699548
reward_min: 1172.6476272839532
total_envstep_count: 10361179
total_train_sample_count: 7796668
total_episode_count: 26003
total_duration: 2214.3551713134852
[2023-06-29 11:52:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 256.625
avg_sample_per_episode: 256.625
avg_envstep_per_sec: 2489.9356467839466
avg_train_sample_per_sec: 2489.9356467839466
avg_episode_per_sec: 9.70262307563155
collect_time: 0.8245193013930694
reward_mean: 1955.0961319540734
reward_std: 951.9436286495858
reward_max: 3358.698664269202
reward_min: 571.1937600734451
total_envstep_count: 10365819
total_train_sample_count: 7799921
total_episode_count: 26011
total_duration: 2215.1796906148784
[2023-06-29 11:52:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 206.16666666666666
avg_sample_per_episode: 206.16666666666666
avg_envstep_per_sec: 2686.685425645861
avg_train_sample_per_sec: 2686.685425645861
avg_episode_per_sec: 13.031618879446375
collect_time: 0.920837242940441
reward_mean: 1619.2934434224733
reward_std: 831.675187374371
reward_max: 3375.7011735865676
reward_min: 939.9987057130788
total_envstep_count: 10370027
total_train_sample_count: 7803195
total_episode_count: 26023
total_duration: 2216.1005278578186
[2023-06-29 11:52:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2488
train_sample_count: 2488
avg_envstep_per_episode: 276.44444444444446
avg_sample_per_episode: 276.44444444444446
avg_envstep_per_sec: 2715.330344899704
avg_train_sample_per_sec: 2715.330344899704
avg_episode_per_sec: 9.822336456630762
collect_time: 0.9162789362529291
reward_mean: 1730.604473654077
reward_std: 859.0632762233511
reward_max: 3292.4097074621586
reward_min: 954.3127136854933
total_envstep_count: 10374891
total_train_sample_count: 7806483
total_episode_count: 26032
total_duration: 2217.0168067940717
[2023-06-29 11:52:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2905
train_sample_count: 2905
avg_envstep_per_episode: 223.46153846153845
avg_sample_per_episode: 223.46153846153845
avg_envstep_per_sec: 2510.914093827954
avg_train_sample_per_sec: 2510.914093827954
avg_episode_per_sec: 11.236448612655215
collect_time: 1.156949179241434
reward_mean: 1353.5487376113035
reward_std: 758.4883440449997
reward_max: 3438.2024396198394
reward_min: 75.67918209255683
total_envstep_count: 10379691
total_train_sample_count: 7809788
total_episode_count: 26045
total_duration: 2218.1737559733133
[2023-06-29 11:52:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2381
train_sample_count: 2381
avg_envstep_per_episode: 198.41666666666666
avg_sample_per_episode: 198.41666666666666
avg_envstep_per_sec: 2611.5484823038105
avg_train_sample_per_sec: 2611.5484823038105
avg_episode_per_sec: 13.161941111988964
collect_time: 0.9117196238683537
reward_mean: 1312.2490369012553
reward_std: 813.8571405392216
reward_max: 3053.025383729039
reward_min: 52.84633409025124
total_envstep_count: 10385163
total_train_sample_count: 7813369
total_episode_count: 26057
total_duration: 2219.085475597182
[2023-06-29 11:53:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2577
train_sample_count: 2577
avg_envstep_per_episode: 234.27272727272728
avg_sample_per_episode: 234.27272727272728
avg_envstep_per_sec: 2546.9939118447055
avg_train_sample_per_sec: 2546.9939118447055
avg_episode_per_sec: 10.871918133601769
collect_time: 1.0117809814997014
reward_mean: 1827.2315280299044
reward_std: 760.6490618549524
reward_max: 3335.8992864069814
reward_min: 1004.790300608062
total_envstep_count: 10389443
total_train_sample_count: 7816746
total_episode_count: 26068
total_duration: 2220.0972565786815
[2023-06-29 11:53:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2824
train_sample_count: 2824
avg_envstep_per_episode: 256.72727272727275
avg_sample_per_episode: 256.72727272727275
avg_envstep_per_sec: 2732.5380295928853
avg_train_sample_per_sec: 2732.5380295928853
avg_episode_per_sec: 10.643738783824977
collect_time: 1.0334714354993777
reward_mean: 1332.2777416376614
reward_std: 543.8534703695709
reward_max: 2521.7826318087014
reward_min: 703.683021091285
total_envstep_count: 10393867
total_train_sample_count: 7819970
total_episode_count: 26079
total_duration: 2221.130728014181
[2023-06-29 11:53:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2424
train_sample_count: 2424
avg_envstep_per_episode: 303.0
avg_sample_per_episode: 303.0
avg_envstep_per_sec: 2780.303913190802
avg_train_sample_per_sec: 2780.303913190802
avg_episode_per_sec: 9.175920505580205
collect_time: 0.8718471345882862
reward_mean: 1909.3586494702752
reward_std: 940.7208763898929
reward_max: 3503.1461363577214
reward_min: 973.3465399138455
total_envstep_count: 10399075
total_train_sample_count: 7823594
total_episode_count: 26087
total_duration: 2222.002575148769
[2023-06-29 11:53:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 201.3125
avg_sample_per_episode: 201.3125
avg_envstep_per_sec: 2562.7206095685947
avg_train_sample_per_sec: 2562.7206095685947
avg_episode_per_sec: 12.730062015863869
collect_time: 1.2568674041070045
reward_mean: 1321.1345048695812
reward_std: 690.7190728029829
reward_max: 3382.4914403734583
reward_min: 558.6654651597249
total_envstep_count: 10403299
total_train_sample_count: 7826815
total_episode_count: 26103
total_duration: 2223.2594425528764
[2023-06-29 11:53:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2806
train_sample_count: 2806
avg_envstep_per_episode: 233.83333333333334
avg_sample_per_episode: 233.83333333333334
avg_envstep_per_sec: 2530.3346691557254
avg_train_sample_per_sec: 2530.3346691557254
avg_episode_per_sec: 10.821103360608946
collect_time: 1.1089442176185547
reward_mean: 1117.004916749792
reward_std: 237.33434205588244
reward_max: 1528.2654676347559
reward_min: 796.9119871308566
total_envstep_count: 10407467
total_train_sample_count: 7830021
total_episode_count: 26115
total_duration: 2224.368386770495
[2023-06-29 11:53:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2781
train_sample_count: 2781
avg_envstep_per_episode: 278.1
avg_sample_per_episode: 278.1
avg_envstep_per_sec: 2557.040268166553
avg_train_sample_per_sec: 2557.040268166553
avg_episode_per_sec: 9.194679137599973
collect_time: 1.0875855318438261
reward_mean: 1427.4087522829607
reward_std: 674.6862395937
reward_max: 2910.316743914513
reward_min: 353.7714016550362
total_envstep_count: 10412203
total_train_sample_count: 7833602
total_episode_count: 26125
total_duration: 2225.4559723023385
[2023-06-29 11:53:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2070
train_sample_count: 2070
avg_envstep_per_episode: 258.75
avg_sample_per_episode: 258.75
avg_envstep_per_sec: 2751.579287381333
avg_train_sample_per_sec: 2751.579287381333
avg_episode_per_sec: 10.63412284978293
collect_time: 0.7522952398620542
reward_mean: 1714.9890323050786
reward_std: 897.0916750457615
reward_max: 3468.3655626955824
reward_min: 828.066517287859
total_envstep_count: 10417003
total_train_sample_count: 7836872
total_episode_count: 26133
total_duration: 2226.2082675422007
[2023-06-29 11:53:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1354
train_sample_count: 1354
avg_envstep_per_episode: 193.42857142857142
avg_sample_per_episode: 193.42857142857142
avg_envstep_per_sec: 2530.4767903897396
avg_train_sample_per_sec: 2530.4767903897396
avg_episode_per_sec: 13.082228606150794
collect_time: 0.5350770278321578
reward_mean: 2057.633146607627
reward_std: 1099.7611350588884
reward_max: 3528.7978347548888
reward_min: 387.1088431576766
total_envstep_count: 10421411
total_train_sample_count: 7840226
total_episode_count: 26140
total_duration: 2226.743344570033
[2023-06-29 11:53:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2040
train_sample_count: 2040
avg_envstep_per_episode: 226.66666666666666
avg_sample_per_episode: 226.66666666666666
avg_envstep_per_sec: 2623.4099356390952
avg_train_sample_per_sec: 2623.4099356390952
avg_episode_per_sec: 11.573867363113656
collect_time: 0.7776138880494979
reward_mean: 2028.4427433447797
reward_std: 913.6794653132744
reward_max: 3529.200228528833
reward_min: 843.5789167771321
total_envstep_count: 10425435
total_train_sample_count: 7843466
total_episode_count: 26149
total_duration: 2227.5209584580825
[2023-06-29 11:53:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2837
train_sample_count: 2837
avg_envstep_per_episode: 236.41666666666666
avg_sample_per_episode: 236.41666666666666
avg_envstep_per_sec: 2569.643464456162
avg_train_sample_per_sec: 2569.643464456162
avg_episode_per_sec: 10.869129916628108
collect_time: 1.1040442143986
reward_mean: 1316.8907297965677
reward_std: 711.2906362670002
reward_max: 3130.335128230117
reward_min: 248.7423150823925
total_envstep_count: 10430171
total_train_sample_count: 7846703
total_episode_count: 26161
total_duration: 2228.625002672481
[2023-06-29 11:53:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2230
train_sample_count: 2230
avg_envstep_per_episode: 247.77777777777777
avg_sample_per_episode: 247.77777777777777
avg_envstep_per_sec: 2680.0732160573257
avg_train_sample_per_sec: 2680.0732160573257
avg_episode_per_sec: 10.816438988572166
collect_time: 0.832066820652224
reward_mean: 1696.4164424967323
reward_std: 833.1435017153888
reward_max: 3458.580583465421
reward_min: 878.985940876025
total_envstep_count: 10434699
total_train_sample_count: 7850133
total_episode_count: 26170
total_duration: 2229.457069493133
[2023-06-29 11:53:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2130
train_sample_count: 2130
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2737.370726125663
avg_train_sample_per_sec: 2737.370726125663
avg_episode_per_sec: 12.851505756458513
collect_time: 0.7781189371505755
reward_mean: 1490.4495026329819
reward_std: 731.4385702049019
reward_max: 2761.6249634362302
reward_min: 555.6565779918582
total_envstep_count: 10439219
total_train_sample_count: 7853463
total_episode_count: 26180
total_duration: 2230.235188430284
[2023-06-29 11:53:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2500
train_sample_count: 2500
avg_envstep_per_episode: 208.33333333333334
avg_sample_per_episode: 208.33333333333334
avg_envstep_per_sec: 2591.1911338168056
avg_train_sample_per_sec: 2591.1911338168056
avg_episode_per_sec: 12.437717442320668
collect_time: 0.9648072530711072
reward_mean: 1573.3421924510105
reward_std: 721.4537790270704
reward_max: 3463.231357130284
reward_min: 831.3850837097216
total_envstep_count: 10443323
total_train_sample_count: 7856763
total_episode_count: 26192
total_duration: 2231.199995683355
[2023-06-29 11:53:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2975
train_sample_count: 2975
avg_envstep_per_episode: 270.45454545454544
avg_sample_per_episode: 270.45454545454544
avg_envstep_per_sec: 2571.9521182554354
avg_train_sample_per_sec: 2571.9521182554354
avg_episode_per_sec: 9.509738924641946
collect_time: 1.1567089367192238
reward_mean: 1487.535890532796
reward_std: 470.6404488814861
reward_max: 2437.6007760340813
reward_min: 778.7361290266142
total_envstep_count: 10448235
total_train_sample_count: 7860138
total_episode_count: 26203
total_duration: 2232.356704620074
[2023-06-29 11:53:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2611
train_sample_count: 2611
avg_envstep_per_episode: 261.1
avg_sample_per_episode: 261.1
avg_envstep_per_sec: 2703.3523580917067
avg_train_sample_per_sec: 2703.3523580917067
avg_episode_per_sec: 10.353704933327105
collect_time: 0.9658378391498701
reward_mean: 1629.351795024858
reward_std: 596.3698969843466
reward_max: 2661.061612453824
reward_min: 943.1931123769107
total_envstep_count: 10452563
total_train_sample_count: 7863549
total_episode_count: 26213
total_duration: 2233.322542459224
[2023-06-29 11:53:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1704
train_sample_count: 1704
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2764.34457280965
avg_train_sample_per_sec: 2764.34457280965
avg_episode_per_sec: 9.733607650738204
collect_time: 0.6164209833899515
reward_mean: 1820.6672694267581
reward_std: 882.4367821150718
reward_max: 3458.567228789837
reward_min: 994.777257204223
total_envstep_count: 10457363
total_train_sample_count: 7866853
total_episode_count: 26219
total_duration: 2233.9389634426143
[2023-06-29 11:53:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2560
train_sample_count: 2560
avg_envstep_per_episode: 256.0
avg_sample_per_episode: 256.0
avg_envstep_per_sec: 2598.090292429411
avg_train_sample_per_sec: 2598.090292429411
avg_episode_per_sec: 10.148790204802387
collect_time: 0.9853391190674157
reward_mean: 2153.954706947161
reward_std: 1083.0734251172898
reward_max: 3646.924304469739
reward_min: 939.320560466196
total_envstep_count: 10461403
total_train_sample_count: 7870213
total_episode_count: 26229
total_duration: 2234.9243025616815
[2023-06-29 11:53:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3092
train_sample_count: 3092
avg_envstep_per_episode: 237.84615384615384
avg_sample_per_episode: 237.84615384615384
avg_envstep_per_sec: 2584.49454383735
avg_train_sample_per_sec: 2584.49454383735
avg_episode_per_sec: 10.86624484795781
collect_time: 1.19636545852758
reward_mean: 1256.8034232199652
reward_std: 175.8852238766559
reward_max: 1541.4481533658397
reward_min: 992.1338214456782
total_envstep_count: 10466266
total_train_sample_count: 7873705
total_episode_count: 26242
total_duration: 2236.120668020209
[2023-06-29 11:53:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2374
train_sample_count: 2374
avg_envstep_per_episode: 237.4
avg_sample_per_episode: 237.4
avg_envstep_per_sec: 2726.208655152632
avg_train_sample_per_sec: 2726.208655152632
avg_episode_per_sec: 11.483608488427263
collect_time: 0.870806420305744
reward_mean: 1481.2647871730765
reward_std: 380.8588388215297
reward_max: 2181.9767480898245
reward_min: 860.3009612013482
total_envstep_count: 10471050
total_train_sample_count: 7877279
total_episode_count: 26252
total_duration: 2236.9914744405146
[2023-06-29 11:54:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2689
train_sample_count: 2689
avg_envstep_per_episode: 244.45454545454547
avg_sample_per_episode: 244.45454545454547
avg_envstep_per_sec: 2736.4940257974754
avg_train_sample_per_sec: 2736.4940257974754
avg_episode_per_sec: 11.194285713563492
collect_time: 0.9826442062910645
reward_mean: 1564.8339919049786
reward_std: 605.665270260353
reward_max: 2899.457363439181
reward_min: 944.1494768897214
total_envstep_count: 10475682
total_train_sample_count: 7880768
total_episode_count: 26263
total_duration: 2237.9741186468054
[2023-06-29 11:54:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3002
train_sample_count: 3002
avg_envstep_per_episode: 250.16666666666666
avg_sample_per_episode: 250.16666666666666
avg_envstep_per_sec: 2793.8914922122935
avg_train_sample_per_sec: 2793.8914922122935
avg_episode_per_sec: 11.168120555145743
collect_time: 1.0744869685769076
reward_mean: 1557.9872106604364
reward_std: 652.8447709317378
reward_max: 3103.0989960325883
reward_min: 864.0813921822621
total_envstep_count: 10480162
total_train_sample_count: 7884170
total_episode_count: 26275
total_duration: 2239.0486056153823
[2023-06-29 11:54:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3244
train_sample_count: 3244
avg_envstep_per_episode: 294.90909090909093
avg_sample_per_episode: 294.90909090909093
avg_envstep_per_sec: 2589.260885452204
avg_train_sample_per_sec: 2589.260885452204
avg_episode_per_sec: 8.779861202211542
collect_time: 1.252867186240852
reward_mean: 1536.568696182964
reward_std: 477.8029164725178
reward_max: 2386.0503255037015
reward_min: 999.2790629944191
total_envstep_count: 10484850
total_train_sample_count: 7887414
total_episode_count: 26286
total_duration: 2240.3014728016233
[2023-06-29 11:54:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 206.33333333333334
avg_sample_per_episode: 206.33333333333334
avg_envstep_per_sec: 2722.698884280846
avg_train_sample_per_sec: 2722.698884280846
avg_episode_per_sec: 13.195632718647072
collect_time: 0.9093917855899782
reward_mean: 1169.802367460042
reward_std: 261.5304497549966
reward_max: 1840.559790673982
reward_min: 891.6910754750653
total_envstep_count: 10489090
total_train_sample_count: 7890690
total_episode_count: 26298
total_duration: 2241.210864587213
[2023-06-29 11:54:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 202.16666666666666
avg_sample_per_episode: 202.16666666666666
avg_envstep_per_sec: 2595.0195864131974
avg_train_sample_per_sec: 2595.0195864131974
avg_episode_per_sec: 12.836040823148544
collect_time: 0.934867703003809
reward_mean: 1225.5664993847406
reward_std: 466.3297992670465
reward_max: 1843.146717574835
reward_min: 248.23826749208362
total_envstep_count: 10493514
total_train_sample_count: 7893916
total_episode_count: 26310
total_duration: 2242.145732290217
[2023-06-29 11:54:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2636
train_sample_count: 2636
avg_envstep_per_episode: 219.66666666666666
avg_sample_per_episode: 219.66666666666666
avg_envstep_per_sec: 2507.4778250005174
avg_train_sample_per_sec: 2507.4778250005174
avg_episode_per_sec: 11.414921813355923
collect_time: 1.0512555579626934
reward_mean: 1340.6703649317242
reward_std: 573.7904829510153
reward_max: 2318.3274067698485
reward_min: 244.90874916864016
total_envstep_count: 10497946
total_train_sample_count: 7897352
total_episode_count: 26322
total_duration: 2243.1969878481796
[2023-06-29 11:54:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2140
train_sample_count: 2140
avg_envstep_per_episode: 214.0
avg_sample_per_episode: 214.0
avg_envstep_per_sec: 2637.9714412388184
avg_train_sample_per_sec: 2637.9714412388184
avg_episode_per_sec: 12.326969351583264
collect_time: 0.8112294039828702
reward_mean: 1380.5458289079754
reward_std: 642.8270553349786
reward_max: 2735.126700402528
reward_min: 728.522837924378
total_envstep_count: 10502218
total_train_sample_count: 7900692
total_episode_count: 26332
total_duration: 2244.0082172521625
[2023-06-29 11:54:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2899
train_sample_count: 2899
avg_envstep_per_episode: 322.1111111111111
avg_sample_per_episode: 322.1111111111111
avg_envstep_per_sec: 2709.40602900366
avg_train_sample_per_sec: 2709.40602900366
avg_episode_per_sec: 8.411401952753689
collect_time: 1.0699762121168896
reward_mean: 1969.4189637174577
reward_std: 478.26687519761936
reward_max: 2904.455496653815
reward_min: 1459.901706566102
total_envstep_count: 10507146
total_train_sample_count: 7903991
total_episode_count: 26341
total_duration: 2245.078193464279
[2023-06-29 11:54:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1936
train_sample_count: 1936
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2752.631655540533
avg_train_sample_per_sec: 2752.631655540533
avg_episode_per_sec: 11.374510973307986
collect_time: 0.70332694027666
reward_mean: 1760.6756986418911
reward_std: 740.8974224856031
reward_max: 3543.199932557926
reward_min: 1099.6963416068254
total_envstep_count: 10512130
total_train_sample_count: 7907527
total_episode_count: 26349
total_duration: 2245.781520404556
[2023-06-29 11:54:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2583
train_sample_count: 2583
avg_envstep_per_episode: 234.8181818181818
avg_sample_per_episode: 234.8181818181818
avg_envstep_per_sec: 2746.581220540613
avg_train_sample_per_sec: 2746.581220540613
avg_episode_per_sec: 11.696629278337879
collect_time: 0.9404418775904924
reward_mean: 1862.346947741934
reward_std: 717.882122263216
reward_max: 3488.8913791024393
reward_min: 952.5323001059438
total_envstep_count: 10516890
total_train_sample_count: 7910910
total_episode_count: 26360
total_duration: 2246.7219622821463
[2023-06-29 11:54:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3051
train_sample_count: 3051
avg_envstep_per_episode: 277.3636363636364
avg_sample_per_episode: 277.3636363636364
avg_envstep_per_sec: 2609.773869427228
avg_train_sample_per_sec: 2609.773869427228
avg_episode_per_sec: 9.409214212946413
collect_time: 1.1690668052667754
reward_mean: 1679.1909880217222
reward_std: 707.5635109125825
reward_max: 3507.545874098825
reward_min: 915.3129816679876
total_envstep_count: 10521674
total_train_sample_count: 7914361
total_episode_count: 26371
total_duration: 2247.8910290874132
[2023-06-29 11:54:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3014
train_sample_count: 3014
avg_envstep_per_episode: 274.0
avg_sample_per_episode: 274.0
avg_envstep_per_sec: 2667.3499139345304
avg_train_sample_per_sec: 2667.3499139345304
avg_episode_per_sec: 9.734853700490987
collect_time: 1.129960484094918
reward_mean: 1545.1513025506065
reward_std: 337.4544609790973
reward_max: 2194.183406913362
reward_min: 1137.2979074414486
total_envstep_count: 10525850
total_train_sample_count: 7917775
total_episode_count: 26382
total_duration: 2249.0209895715084
[2023-06-29 11:54:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1907
train_sample_count: 1907
avg_envstep_per_episode: 272.42857142857144
avg_sample_per_episode: 272.42857142857144
avg_envstep_per_sec: 2804.281129089034
avg_train_sample_per_sec: 2804.281129089034
avg_episode_per_sec: 10.293638124605788
collect_time: 0.6800316773587838
reward_mean: 1542.803009534195
reward_std: 469.832090041093
reward_max: 2509.0745808733154
reward_min: 949.7840209319031
total_envstep_count: 10530434
total_train_sample_count: 7921282
total_episode_count: 26389
total_duration: 2249.701021248867
[2023-06-29 11:54:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2298
train_sample_count: 2298
avg_envstep_per_episode: 255.33333333333334
avg_sample_per_episode: 255.33333333333334
avg_envstep_per_sec: 2678.6625923563793
avg_train_sample_per_sec: 2678.6625923563793
avg_episode_per_sec: 10.490845661970154
collect_time: 0.8578908021328971
reward_mean: 1948.7002247004957
reward_std: 679.7713229615317
reward_max: 3534.3216698628785
reward_min: 1203.37233646083
total_envstep_count: 10534858
total_train_sample_count: 7924780
total_episode_count: 26398
total_duration: 2250.558912051
[2023-06-29 11:54:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1629
train_sample_count: 1629
avg_envstep_per_episode: 271.5
avg_sample_per_episode: 271.5
avg_envstep_per_sec: 2592.2077124792777
avg_train_sample_per_sec: 2592.2077124792777
avg_episode_per_sec: 9.547726381139144
collect_time: 0.628421863015741
reward_mean: 2219.1433420292055
reward_std: 915.605731890752
reward_max: 3472.7882179256294
reward_min: 935.7864619074007
total_envstep_count: 10539090
total_train_sample_count: 7928009
total_episode_count: 26404
total_duration: 2251.1873339140157
[2023-06-29 11:54:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3079
train_sample_count: 3079
avg_envstep_per_episode: 342.1111111111111
avg_sample_per_episode: 342.1111111111111
avg_envstep_per_sec: 2629.5722107198426
avg_train_sample_per_sec: 2629.5722107198426
avg_episode_per_sec: 7.686310456797201
collect_time: 1.1709128912482412
reward_mean: 2202.825520234915
reward_std: 935.639429989868
reward_max: 3495.298089163264
reward_min: 970.5592133267862
total_envstep_count: 10543898
total_train_sample_count: 7931488
total_episode_count: 26413
total_duration: 2252.358246805264
[2023-06-29 11:54:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2001
train_sample_count: 2001
avg_envstep_per_episode: 250.125
avg_sample_per_episode: 250.125
avg_envstep_per_sec: 2538.346630944802
avg_train_sample_per_sec: 2538.346630944802
avg_episode_per_sec: 10.14831236759541
collect_time: 0.7883084113122897
reward_mean: 1721.8952463293867
reward_std: 722.0415554386626
reward_max: 3503.974034335539
reward_min: 1057.3150794656246
total_envstep_count: 10548490
total_train_sample_count: 7934689
total_episode_count: 26421
total_duration: 2253.1465552165764
[2023-06-29 11:54:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2138
train_sample_count: 2138
avg_envstep_per_episode: 267.25
avg_sample_per_episode: 267.25
avg_envstep_per_sec: 2702.233610233875
avg_train_sample_per_sec: 2702.233610233875
avg_episode_per_sec: 10.11125766224088
collect_time: 0.791197323541157
reward_mean: 2077.8683290033614
reward_std: 746.6444433880544
reward_max: 3426.581907819055
reward_min: 1103.284298427753
total_envstep_count: 10552570
total_train_sample_count: 7938027
total_episode_count: 26429
total_duration: 2253.937752540118
[2023-06-29 11:54:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2096
train_sample_count: 2096
avg_envstep_per_episode: 232.88888888888889
avg_sample_per_episode: 232.88888888888889
avg_envstep_per_sec: 2793.734472042888
avg_train_sample_per_sec: 2793.734472042888
avg_episode_per_sec: 11.995997255909346
collect_time: 0.7502502549812198
reward_mean: 1678.2886492139012
reward_std: 443.02450949166314
reward_max: 2616.3367833160455
reward_min: 911.7392207050295
total_envstep_count: 10557186
total_train_sample_count: 7941323
total_episode_count: 26438
total_duration: 2254.6880027950992
[2023-06-29 11:54:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3056
train_sample_count: 3056
avg_envstep_per_episode: 235.07692307692307
avg_sample_per_episode: 235.07692307692307
avg_envstep_per_sec: 2644.5238114393596
avg_train_sample_per_sec: 2644.5238114393596
avg_episode_per_sec: 11.24961045442136
collect_time: 1.1555955695239826
reward_mean: 1535.6225695216935
reward_std: 420.8954049090918
reward_max: 2234.3074789510833
reward_min: 861.5475736737545
total_envstep_count: 10561858
total_train_sample_count: 7944779
total_episode_count: 26451
total_duration: 2255.843598364623
[2023-06-29 11:55:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2553
train_sample_count: 2553
avg_envstep_per_episode: 232.0909090909091
avg_sample_per_episode: 232.0909090909091
avg_envstep_per_sec: 2597.8063133403525
avg_train_sample_per_sec: 2597.8063133403525
avg_episode_per_sec: 11.193055012433952
collect_time: 0.982752250192687
reward_mean: 1365.110625149259
reward_std: 302.37485799186214
reward_max: 2026.6805773757496
reward_min: 928.87761897016
total_envstep_count: 10566258
total_train_sample_count: 7948132
total_episode_count: 26462
total_duration: 2256.826350614816
[2023-06-29 11:55:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 291.2857142857143
avg_sample_per_episode: 291.2857142857143
avg_envstep_per_sec: 2507.5418094808592
avg_train_sample_per_sec: 2507.5418094808592
avg_episode_per_sec: 8.608529998217762
collect_time: 0.813146960218437
reward_mean: 1859.433346633894
reward_std: 591.9722590435446
reward_max: 2804.78785688403
reward_min: 1083.5855015627662
total_envstep_count: 10570770
total_train_sample_count: 7951371
total_episode_count: 26469
total_duration: 2257.6394975750345
[2023-06-29 11:55:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2938
train_sample_count: 2938
avg_envstep_per_episode: 367.25
avg_sample_per_episode: 367.25
avg_envstep_per_sec: 2767.9176376166342
avg_train_sample_per_sec: 2767.9176376166342
avg_episode_per_sec: 7.536875800181441
collect_time: 1.0614477685578168
reward_mean: 2553.241122610246
reward_std: 878.1280896963713
reward_max: 3519.098343999115
reward_min: 1078.8337149186307
total_envstep_count: 10575794
total_train_sample_count: 7954709
total_episode_count: 26477
total_duration: 2258.700945343592
[2023-06-29 11:55:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2674
train_sample_count: 2674
avg_envstep_per_episode: 267.4
avg_sample_per_episode: 267.4
avg_envstep_per_sec: 2656.2144035391552
avg_train_sample_per_sec: 2656.2144035391552
avg_episode_per_sec: 9.933486924230198
collect_time: 1.0066958436928688
reward_mean: 1665.3462558737006
reward_std: 681.1198961054087
reward_max: 3348.182555698099
reward_min: 1018.2626440015558
total_envstep_count: 10580186
total_train_sample_count: 7958183
total_episode_count: 26487
total_duration: 2259.707641187285
[2023-06-29 11:55:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 205.45454545454547
avg_sample_per_episode: 205.45454545454547
avg_envstep_per_sec: 2828.1096565459334
avg_train_sample_per_sec: 2828.1096565459334
avg_episode_per_sec: 13.765135496462507
collect_time: 0.7991203575748951
reward_mean: 1282.9206736649394
reward_std: 416.69992432906844
reward_max: 2284.961935315711
reward_min: 801.0883238984815
total_envstep_count: 10584698
total_train_sample_count: 7962043
total_episode_count: 26498
total_duration: 2260.5067615448597
[2023-06-29 11:55:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3468
train_sample_count: 3468
avg_envstep_per_episode: 247.71428571428572
avg_sample_per_episode: 247.71428571428572
avg_envstep_per_sec: 2613.674243505812
avg_train_sample_per_sec: 2613.674243505812
avg_episode_per_sec: 10.551164766171096
collect_time: 1.326867726005614
reward_mean: 1463.0871685970835
reward_std: 491.04582265989563
reward_max: 2489.7702238442935
reward_min: 815.5244137686251
total_envstep_count: 10589610
total_train_sample_count: 7965511
total_episode_count: 26512
total_duration: 2261.8336292708655
[2023-06-29 11:55:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3036
train_sample_count: 3036
avg_envstep_per_episode: 233.53846153846155
avg_sample_per_episode: 233.53846153846155
avg_envstep_per_sec: 2520.5336652797487
avg_train_sample_per_sec: 2520.5336652797487
avg_episode_per_sec: 10.792798962001559
collect_time: 1.2045068240193653
reward_mean: 1222.1287871764712
reward_std: 185.24402180710064
reward_max: 1509.3219281529725
reward_min: 917.7824834416887
total_envstep_count: 10594730
total_train_sample_count: 7969347
total_episode_count: 26525
total_duration: 2263.038136094885
[2023-06-29 11:55:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3377
train_sample_count: 3377
avg_envstep_per_episode: 307.0
avg_sample_per_episode: 307.0
avg_envstep_per_sec: 2715.783384122999
avg_train_sample_per_sec: 2715.783384122999
avg_episode_per_sec: 8.846199948283385
collect_time: 1.243471780460328
reward_mean: 1778.7578132164997
reward_std: 809.1495972165671
reward_max: 3173.741219868558
reward_min: 936.5563238550906
total_envstep_count: 10599594
total_train_sample_count: 7972724
total_episode_count: 26536
total_duration: 2264.2816078753453
[2023-06-29 11:55:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2214
train_sample_count: 2214
avg_envstep_per_episode: 221.4
avg_sample_per_episode: 221.4
avg_envstep_per_sec: 2522.3882000815624
avg_train_sample_per_sec: 2522.3882000815624
avg_episode_per_sec: 11.39290063270805
collect_time: 0.8777395961210132
reward_mean: 1229.6295497958893
reward_std: 198.5181903895259
reward_max: 1643.407193286721
reward_min: 1003.660797615377
total_envstep_count: 10603842
total_train_sample_count: 7976138
total_episode_count: 26546
total_duration: 2265.1593474714664
[2023-06-29 11:55:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2287
train_sample_count: 2287
avg_envstep_per_episode: 228.7
avg_sample_per_episode: 228.7
avg_envstep_per_sec: 2794.9062066332294
avg_train_sample_per_sec: 2794.9062066332294
avg_episode_per_sec: 12.220840431277786
collect_time: 0.8182743286956101
reward_mean: 1620.5964256785603
reward_std: 694.7673580915015
reward_max: 3464.45824886969
reward_min: 970.6831413413183
total_envstep_count: 10608434
total_train_sample_count: 7979625
total_episode_count: 26556
total_duration: 2265.977621800162
[2023-06-29 11:55:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 291.8181818181818
avg_sample_per_episode: 291.8181818181818
avg_envstep_per_sec: 2632.2531142847415
avg_train_sample_per_sec: 2632.2531142847415
avg_episode_per_sec: 9.02018201156765
collect_time: 1.2194875874891875
reward_mean: 1780.286688917506
reward_std: 950.9804965762117
reward_max: 3477.2582489510414
reward_min: 973.4256635631843
total_envstep_count: 10612898
total_train_sample_count: 7982835
total_episode_count: 26567
total_duration: 2267.1971093876514
[2023-06-29 11:55:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2674
train_sample_count: 2674
avg_envstep_per_episode: 222.83333333333334
avg_sample_per_episode: 222.83333333333334
avg_envstep_per_sec: 2758.5376484435265
avg_train_sample_per_sec: 2758.5376484435265
avg_episode_per_sec: 12.379376133628393
collect_time: 0.9693541799252854
reward_mean: 1139.5623799705115
reward_std: 325.0661907251672
reward_max: 1908.5364326054566
reward_min: 836.0655714877254
total_envstep_count: 10617826
total_train_sample_count: 7986309
total_episode_count: 26579
total_duration: 2268.1664635675766
[2023-06-29 11:55:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2050
train_sample_count: 2050
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2400.820750743765
avg_train_sample_per_sec: 2400.820750743765
avg_episode_per_sec: 11.71132073533544
collect_time: 0.8538746590577068
reward_mean: 1534.3107198141108
reward_std: 797.2220749228185
reward_max: 3564.950853880317
reward_min: 814.869420479966
total_envstep_count: 10622154
total_train_sample_count: 7989559
total_episode_count: 26589
total_duration: 2269.020338226634
[2023-06-29 11:55:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 520
train_sample_count: 520
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 2575.6315617539303
avg_train_sample_per_sec: 2575.6315617539303
avg_episode_per_sec: 9.906275237515116
collect_time: 0.20189223013166335
reward_mean: 2073.446391179912
reward_std: 964.4831792260048
reward_max: 3037.929570405917
reward_min: 1108.9632119539071
total_envstep_count: 10626058
total_train_sample_count: 7992879
total_episode_count: 26591
total_duration: 2269.222230456766
[2023-06-29 11:55:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1768
train_sample_count: 1768
avg_envstep_per_episode: 221.0
avg_sample_per_episode: 221.0
avg_envstep_per_sec: 2441.263297655869
avg_train_sample_per_sec: 2441.263297655869
avg_episode_per_sec: 11.046440260886286
collect_time: 0.724215205175802
reward_mean: 2728.526712993763
reward_std: 990.6767429816085
reward_max: 3445.794709659129
reward_min: 1012.8626469095846
total_envstep_count: 10630154
total_train_sample_count: 7996247
total_episode_count: 26599
total_duration: 2269.9464456619417
[2023-06-29 11:55:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 253.66666666666666
avg_sample_per_episode: 253.66666666666666
avg_envstep_per_sec: 2686.234299270284
avg_train_sample_per_sec: 2686.234299270284
avg_episode_per_sec: 10.589622730369056
collect_time: 1.1331848457250744
reward_mean: 1687.689659518918
reward_std: 906.5554208153042
reward_max: 3447.4689073831355
reward_min: 748.9888978983307
total_envstep_count: 10634770
total_train_sample_count: 7999691
total_episode_count: 26611
total_duration: 2271.079630507667
[2023-06-29 11:55:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1470
train_sample_count: 1470
avg_envstep_per_episode: 210.0
avg_sample_per_episode: 210.0
avg_envstep_per_sec: 2738.1370045367944
avg_train_sample_per_sec: 2738.1370045367944
avg_episode_per_sec: 13.038747640651401
collect_time: 0.5368613760247827
reward_mean: 1341.6871360717028
reward_std: 601.8142700681834
reward_max: 2486.1462468780337
reward_min: 864.1924672304261
total_envstep_count: 10639442
total_train_sample_count: 8003161
total_episode_count: 26618
total_duration: 2271.6164918836917
[2023-06-29 11:55:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2363
train_sample_count: 2363
avg_envstep_per_episode: 295.375
avg_sample_per_episode: 295.375
avg_envstep_per_sec: 2442.3859271671204
avg_train_sample_per_sec: 2442.3859271671204
avg_episode_per_sec: 8.268763189732104
collect_time: 0.9674965670723469
reward_mean: 2527.254288774827
reward_std: 943.5150948080069
reward_max: 3443.7970626746524
reward_min: 1126.1971715950833
total_envstep_count: 10643858
total_train_sample_count: 8006724
total_episode_count: 26626
total_duration: 2272.583988450764
[2023-06-29 11:55:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2442
train_sample_count: 2442
avg_envstep_per_episode: 305.25
avg_sample_per_episode: 305.25
avg_envstep_per_sec: 2728.561082525553
avg_train_sample_per_sec: 2728.561082525553
avg_episode_per_sec: 8.938775045128757
collect_time: 0.8949772155145186
reward_mean: 1938.7721150324842
reward_std: 975.5284836751771
reward_max: 3399.979465833092
reward_min: 910.8568629335969
total_envstep_count: 10648978
total_train_sample_count: 8009966
total_episode_count: 26634
total_duration: 2273.478965666279
[2023-06-29 11:56:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2528
train_sample_count: 2528
avg_envstep_per_episode: 229.8181818181818
avg_sample_per_episode: 229.8181818181818
avg_envstep_per_sec: 2720.7302453475622
avg_train_sample_per_sec: 2720.7302453475622
avg_episode_per_sec: 11.838620529597778
collect_time: 0.929162310127169
reward_mean: 1621.2266497190153
reward_std: 772.540383726794
reward_max: 3596.42744256718
reward_min: 799.0234837801308
total_envstep_count: 10653722
total_train_sample_count: 8013294
total_episode_count: 26645
total_duration: 2274.408127976406
[2023-06-29 11:56:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 233.41666666666666
avg_sample_per_episode: 233.41666666666666
avg_envstep_per_sec: 2592.632007786803
avg_train_sample_per_sec: 2592.632007786803
avg_episode_per_sec: 11.107313135823505
collect_time: 1.0803692894276462
reward_mean: 1491.2189733309815
reward_std: 645.0118869405129
reward_max: 3499.2321720546774
reward_min: 948.8593924211891
total_envstep_count: 10658114
total_train_sample_count: 8016495
total_episode_count: 26657
total_duration: 2275.4884972658338
[2023-06-29 11:56:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2670
train_sample_count: 2670
avg_envstep_per_episode: 242.72727272727272
avg_sample_per_episode: 242.72727272727272
avg_envstep_per_sec: 2525.1395267405824
avg_train_sample_per_sec: 2525.1395267405824
avg_episode_per_sec: 10.403196552114759
collect_time: 1.0573673144495115
reward_mean: 1476.1441861464389
reward_std: 702.0590028368895
reward_max: 3493.324471499894
reward_min: 910.0545583222206
total_envstep_count: 10663098
total_train_sample_count: 8019965
total_episode_count: 26668
total_duration: 2276.5458645802833
[2023-06-29 11:56:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2102
train_sample_count: 2102
avg_envstep_per_episode: 210.2
avg_sample_per_episode: 210.2
avg_envstep_per_sec: 2403.1755039243185
avg_train_sample_per_sec: 2403.1755039243185
avg_episode_per_sec: 11.432804490600944
collect_time: 0.8746760261859746
reward_mean: 1491.7274185618396
reward_std: 770.5373972040857
reward_max: 3430.5693432181833
reward_min: 834.9209465617718
total_envstep_count: 10667330
total_train_sample_count: 8023267
total_episode_count: 26678
total_duration: 2277.4205406064693
[2023-06-29 11:56:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1892
train_sample_count: 1892
avg_envstep_per_episode: 236.5
avg_sample_per_episode: 236.5
avg_envstep_per_sec: 2718.297396083455
avg_train_sample_per_sec: 2718.297396083455
avg_episode_per_sec: 11.49385791155795
collect_time: 0.6960239165611566
reward_mean: 1757.8128077673107
reward_std: 1020.1757282021648
reward_max: 3445.8059602091553
reward_min: 895.1193138945752
total_envstep_count: 10671962
total_train_sample_count: 8026759
total_episode_count: 26686
total_duration: 2278.1165645230303
[2023-06-29 11:56:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 263.25
avg_sample_per_episode: 263.25
avg_envstep_per_sec: 2700.9314222410917
avg_train_sample_per_sec: 2700.9314222410917
avg_episode_per_sec: 10.259948422568248
collect_time: 0.3898655076278374
reward_mean: 2520.081971056292
reward_std: 1025.257670583344
reward_max: 3552.371937668821
reward_min: 1112.060987655615
total_envstep_count: 10676314
total_train_sample_count: 8030212
total_episode_count: 26690
total_duration: 2278.506430030658
[2023-06-29 11:56:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1737
train_sample_count: 1737
avg_envstep_per_episode: 217.125
avg_sample_per_episode: 217.125
avg_envstep_per_sec: 2748.5395607084592
avg_train_sample_per_sec: 2748.5395607084592
avg_episode_per_sec: 12.65878899577874
collect_time: 0.6319719842607154
reward_mean: 2551.911548188882
reward_std: 1108.521246592397
reward_max: 3486.1340746997284
reward_min: 1037.4053205661496
total_envstep_count: 10680570
total_train_sample_count: 8033549
total_episode_count: 26698
total_duration: 2279.138402014919
[2023-06-29 11:56:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3300
train_sample_count: 3300
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2548.7005805896065
avg_train_sample_per_sec: 2548.7005805896065
avg_episode_per_sec: 9.268002111234933
collect_time: 1.2947774348749082
reward_mean: 1825.5641089600085
reward_std: 977.9006347879072
reward_max: 3490.0416375896953
reward_min: 919.2090009145726
total_envstep_count: 10685066
total_train_sample_count: 8036849
total_episode_count: 26710
total_duration: 2280.433179449794
[2023-06-29 11:56:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2952
train_sample_count: 2952
avg_envstep_per_episode: 246.0
avg_sample_per_episode: 246.0
avg_envstep_per_sec: 2448.7762898167252
avg_train_sample_per_sec: 2448.7762898167252
avg_episode_per_sec: 9.954375161856607
collect_time: 1.205500074578449
reward_mean: 1203.4470958235042
reward_std: 314.172451139639
reward_max: 1662.7743758766221
reward_min: 598.5568643480632
total_envstep_count: 10689498
total_train_sample_count: 8040201
total_episode_count: 26722
total_duration: 2281.6386795243725
[2023-06-29 11:56:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2790
train_sample_count: 2790
avg_envstep_per_episode: 253.63636363636363
avg_sample_per_episode: 253.63636363636363
avg_envstep_per_sec: 2630.0659424505316
avg_train_sample_per_sec: 2630.0659424505316
avg_episode_per_sec: 10.369435615396362
collect_time: 1.0608099040286616
reward_mean: 1374.7272199350216
reward_std: 409.4226862211472
reward_max: 2003.114807121519
reward_min: 871.405089934876
total_envstep_count: 10694146
total_train_sample_count: 8043791
total_episode_count: 26733
total_duration: 2282.699489428401
[2023-06-29 11:56:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 203.25
avg_sample_per_episode: 203.25
avg_envstep_per_sec: 2548.7778183482897
avg_train_sample_per_sec: 2548.7778183482897
avg_episode_per_sec: 12.540112267396259
collect_time: 0.6379528212677688
reward_mean: 1311.068039296497
reward_std: 338.58260484844646
reward_max: 1933.5110333825178
reward_min: 829.566678513859
total_envstep_count: 10698802
total_train_sample_count: 8047017
total_episode_count: 26741
total_duration: 2283.337442249669
[2023-06-29 11:56:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1994
train_sample_count: 1994
avg_envstep_per_episode: 249.25
avg_sample_per_episode: 249.25
avg_envstep_per_sec: 2528.340449440444
avg_train_sample_per_sec: 2528.340449440444
avg_episode_per_sec: 10.143793177293656
collect_time: 0.7886596128465608
reward_mean: 2356.466752187628
reward_std: 1068.395494009094
reward_max: 3479.6173577495724
reward_min: 919.2042240577422
total_envstep_count: 10703514
total_train_sample_count: 8050611
total_episode_count: 26749
total_duration: 2284.1261018625155
[2023-06-29 11:56:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 356.125
avg_sample_per_episode: 356.125
avg_envstep_per_sec: 2507.3933564908266
avg_train_sample_per_sec: 2507.3933564908266
avg_episode_per_sec: 7.0407675857938266
collect_time: 1.136239749788307
reward_mean: 2603.984812763073
reward_std: 805.1269178827565
reward_max: 3632.365554929837
reward_min: 1467.6121159565337
total_envstep_count: 10708162
total_train_sample_count: 8053860
total_episode_count: 26757
total_duration: 2285.2623416123038
[2023-06-29 11:56:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2466
train_sample_count: 2466
avg_envstep_per_episode: 308.25
avg_sample_per_episode: 308.25
avg_envstep_per_sec: 2646.1524332946824
avg_train_sample_per_sec: 2646.1524332946824
avg_episode_per_sec: 8.584436117744307
collect_time: 0.9319191022301094
reward_mean: 1658.341415683305
reward_std: 808.9650606223967
reward_max: 3552.736869120861
reward_min: 1004.0041085391738
total_envstep_count: 10712474
total_train_sample_count: 8057126
total_episode_count: 26765
total_duration: 2286.194260714534
[2023-06-29 11:56:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2352
train_sample_count: 2352
avg_envstep_per_episode: 336.0
avg_sample_per_episode: 336.0
avg_envstep_per_sec: 2761.433807362839
avg_train_sample_per_sec: 2761.433807362839
avg_episode_per_sec: 8.218552998103688
collect_time: 0.8517314424589278
reward_mean: 2265.8616176543933
reward_std: 874.0716940444024
reward_max: 3584.5396613938406
reward_min: 1386.7994631382608
total_envstep_count: 10717106
total_train_sample_count: 8060678
total_episode_count: 26772
total_duration: 2287.0459921569927
[2023-06-29 11:56:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2902
train_sample_count: 2902
avg_envstep_per_episode: 223.23076923076923
avg_sample_per_episode: 223.23076923076923
avg_envstep_per_sec: 2594.4226740814634
avg_train_sample_per_sec: 2594.4226740814634
avg_episode_per_sec: 11.622155328414548
collect_time: 1.1185532831605522
reward_mean: 1476.8895326237396
reward_std: 821.7503139481593
reward_max: 3460.652313814878
reward_min: 39.48944215067972
total_envstep_count: 10721418
total_train_sample_count: 8063980
total_episode_count: 26785
total_duration: 2288.1645454401532
[2023-06-29 11:56:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2716
train_sample_count: 2716
avg_envstep_per_episode: 271.6
avg_sample_per_episode: 271.6
avg_envstep_per_sec: 2562.548242153129
avg_train_sample_per_sec: 2562.548242153129
avg_episode_per_sec: 9.435008255350255
collect_time: 1.059882485458278
reward_mean: 1429.0604675172503
reward_std: 525.7176808604755
reward_max: 2484.716949492874
reward_min: 777.0028940678884
total_envstep_count: 10725866
total_train_sample_count: 8067496
total_episode_count: 26795
total_duration: 2289.2244279256115
[2023-06-29 11:56:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2147
train_sample_count: 2147
avg_envstep_per_episode: 268.375
avg_sample_per_episode: 268.375
avg_envstep_per_sec: 2443.8750149425455
avg_train_sample_per_sec: 2443.8750149425455
avg_episode_per_sec: 9.106194745943347
collect_time: 0.8785228323349732
reward_mean: 1676.1452123944186
reward_std: 532.599604637741
reward_max: 2520.413108168989
reward_min: 933.9386070263112
total_envstep_count: 10730218
total_train_sample_count: 8070843
total_episode_count: 26803
total_duration: 2290.1029507579465
[2023-06-29 11:56:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1857
train_sample_count: 1857
avg_envstep_per_episode: 232.125
avg_sample_per_episode: 232.125
avg_envstep_per_sec: 2728.4293693126733
avg_train_sample_per_sec: 2728.4293693126733
avg_episode_per_sec: 11.754138370760037
collect_time: 0.680611351309344
reward_mean: 1765.9436191787
reward_std: 727.3419563449002
reward_max: 3430.234362355545
reward_min: 1040.7920689624334
total_envstep_count: 10735362
total_train_sample_count: 8074300
total_episode_count: 26811
total_duration: 2290.783562109256
[2023-06-29 11:57:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2993
train_sample_count: 2993
avg_envstep_per_episode: 299.3
avg_sample_per_episode: 299.3
avg_envstep_per_sec: 2761.8585096526026
avg_train_sample_per_sec: 2761.8585096526026
avg_episode_per_sec: 9.227726393760785
collect_time: 1.0836905618226154
reward_mean: 2241.7501118336577
reward_std: 925.2858692546312
reward_max: 3452.9163713341422
reward_min: 705.4010664426618
total_envstep_count: 10740042
total_train_sample_count: 8077693
total_episode_count: 26821
total_duration: 2291.8672526710784
[2023-06-29 11:57:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3388
train_sample_count: 3388
avg_envstep_per_episode: 260.61538461538464
avg_sample_per_episode: 260.61538461538464
avg_envstep_per_sec: 2592.0927053100413
avg_train_sample_per_sec: 2592.0927053100413
avg_episode_per_sec: 9.946046389914562
collect_time: 1.3070520174913112
reward_mean: 1398.1220153029028
reward_std: 499.8763811557973
reward_max: 2484.4110088413436
reward_min: 793.7848839521172
total_envstep_count: 10744378
total_train_sample_count: 8081081
total_episode_count: 26834
total_duration: 2293.17430468857
[2023-06-29 11:57:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2207
train_sample_count: 2207
avg_envstep_per_episode: 315.2857142857143
avg_sample_per_episode: 315.2857142857143
avg_envstep_per_sec: 2438.0026891270986
avg_train_sample_per_sec: 2438.0026891270986
avg_episode_per_sec: 7.732677310326095
collect_time: 0.9052492065913976
reward_mean: 1589.8833151033598
reward_std: 562.9271055178417
reward_max: 2419.294345268011
reward_min: 686.1630546477862
total_envstep_count: 10748570
total_train_sample_count: 8084488
total_episode_count: 26841
total_duration: 2294.079553895161
[2023-06-29 11:57:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2870
train_sample_count: 2870
avg_envstep_per_episode: 239.16666666666666
avg_sample_per_episode: 239.16666666666666
avg_envstep_per_sec: 2515.1759247992813
avg_train_sample_per_sec: 2515.1759247992813
avg_episode_per_sec: 10.516415016582362
collect_time: 1.1410732631869616
reward_mean: 1426.2309132922264
reward_std: 410.059122948358
reward_max: 2237.929273126433
reward_min: 973.9206769352369
total_envstep_count: 10752954
total_train_sample_count: 8087758
total_episode_count: 26853
total_duration: 2295.220627158348
[2023-06-29 11:57:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2973
train_sample_count: 2973
avg_envstep_per_episode: 371.625
avg_sample_per_episode: 371.625
avg_envstep_per_sec: 2715.400511265906
avg_train_sample_per_sec: 2715.400511265906
avg_episode_per_sec: 7.306829495501934
collect_time: 1.0948661118922756
reward_mean: 1971.2258109305612
reward_std: 810.4912161197311
reward_max: 3452.9090733425587
reward_min: 1023.3146776431768
total_envstep_count: 10757802
total_train_sample_count: 8091131
total_episode_count: 26861
total_duration: 2296.3154932702405
[2023-06-29 11:57:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2634
train_sample_count: 2634
avg_envstep_per_episode: 329.25
avg_sample_per_episode: 329.25
avg_envstep_per_sec: 2609.8870079182143
avg_train_sample_per_sec: 2609.8870079182143
avg_episode_per_sec: 7.926763881300576
collect_time: 1.0092390942629426
reward_mean: 1967.3437392856042
reward_std: 640.2311443045556
reward_max: 3520.9907102507473
reward_min: 1514.1967370393916
total_envstep_count: 10763098
total_train_sample_count: 8094565
total_episode_count: 26869
total_duration: 2297.3247323645032
[2023-06-29 11:57:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 877
train_sample_count: 877
avg_envstep_per_episode: 219.25
avg_sample_per_episode: 219.25
avg_envstep_per_sec: 2775.5879580137503
avg_train_sample_per_sec: 2775.5879580137503
avg_episode_per_sec: 12.659466171100343
collect_time: 0.3159690895285457
reward_mean: 1860.933110152097
reward_std: 1015.267659208778
reward_max: 3568.626649398524
reward_min: 1030.5820370775043
total_envstep_count: 10767266
total_train_sample_count: 8097842
total_episode_count: 26873
total_duration: 2297.640701454032
[2023-06-29 11:57:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 205.45454545454547
avg_sample_per_episode: 205.45454545454547
avg_envstep_per_sec: 2420.8710368384336
avg_train_sample_per_sec: 2420.8710368384336
avg_episode_per_sec: 11.783000621779985
collect_time: 0.9335482830805705
reward_mean: 2263.6834097126816
reward_std: 1110.308319255113
reward_max: 3488.0033437083703
reward_min: 896.2353754663778
total_envstep_count: 10771522
total_train_sample_count: 8101302
total_episode_count: 26884
total_duration: 2298.5742497371125
[2023-06-29 11:57:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1747
train_sample_count: 1747
avg_envstep_per_episode: 218.375
avg_sample_per_episode: 218.375
avg_envstep_per_sec: 2723.804826913922
avg_train_sample_per_sec: 2723.804826913922
avg_episode_per_sec: 12.473061600063755
collect_time: 0.6413822248708456
reward_mean: 1654.1064849699628
reward_std: 901.0954709753252
reward_max: 2817.1308385273
reward_min: 42.14141536740302
total_envstep_count: 10776490
total_train_sample_count: 8104649
total_episode_count: 26892
total_duration: 2299.2156319619835
[2023-06-29 11:57:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1868
train_sample_count: 1868
avg_envstep_per_episode: 233.5
avg_sample_per_episode: 233.5
avg_envstep_per_sec: 2553.3735041175755
avg_train_sample_per_sec: 2553.3735041175755
avg_episode_per_sec: 10.935218433051714
collect_time: 0.731581179560162
reward_mean: 2207.0657397619398
reward_std: 638.8718989207775
reward_max: 3420.321959588698
reward_min: 1201.0642876228808
total_envstep_count: 10780946
total_train_sample_count: 8108117
total_episode_count: 26900
total_duration: 2299.9472131415437
[2023-06-29 11:57:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2174
train_sample_count: 2174
avg_envstep_per_episode: 310.57142857142856
avg_sample_per_episode: 310.57142857142856
avg_envstep_per_sec: 2669.4681237268255
avg_train_sample_per_sec: 2669.4681237268255
avg_episode_per_sec: 8.595343544658592
collect_time: 0.8143944408539683
reward_mean: 2347.3231730498264
reward_std: 581.7710085314943
reward_max: 3433.6836910822867
reward_min: 1723.8664624205237
total_envstep_count: 10785562
total_train_sample_count: 8111491
total_episode_count: 26907
total_duration: 2300.7616075823976
[2023-06-29 11:57:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1772
train_sample_count: 1772
avg_envstep_per_episode: 295.3333333333333
avg_sample_per_episode: 295.3333333333333
avg_envstep_per_sec: 2772.9683824579924
avg_train_sample_per_sec: 2772.9683824579924
avg_episode_per_sec: 9.389283462047379
collect_time: 0.6390263990061358
reward_mean: 2409.6034445542714
reward_std: 1023.4636203550051
reward_max: 3439.5075576209874
reward_min: 1027.881497366754
total_envstep_count: 10790506
total_train_sample_count: 8114863
total_episode_count: 26913
total_duration: 2301.4006339814036
[2023-06-29 11:57:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 248.77777777777777
avg_sample_per_episode: 248.77777777777777
avg_envstep_per_sec: 2717.0597188425977
avg_train_sample_per_sec: 2717.0597188425977
avg_episode_per_sec: 10.9216335281748
collect_time: 0.824052553748712
reward_mean: 2262.7328909993257
reward_std: 743.4369451003267
reward_max: 3437.7559234426253
reward_min: 1409.0241688415126
total_envstep_count: 10794746
total_train_sample_count: 8118302
total_episode_count: 26922
total_duration: 2302.224686535152
[2023-06-29 11:57:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3004
train_sample_count: 3004
avg_envstep_per_episode: 333.77777777777777
avg_sample_per_episode: 333.77777777777777
avg_envstep_per_sec: 2669.9162083336428
avg_train_sample_per_sec: 2669.9162083336428
avg_episode_per_sec: 7.999083180759915
collect_time: 1.1251289424827555
reward_mean: 1994.0028786897715
reward_std: 783.6804427607784
reward_max: 3472.4374726984584
reward_min: 1171.1708315245169
total_envstep_count: 10799378
total_train_sample_count: 8121706
total_episode_count: 26931
total_duration: 2303.349815477635
[2023-06-29 11:57:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 290.75
avg_sample_per_episode: 290.75
avg_envstep_per_sec: 2600.2179060411754
avg_train_sample_per_sec: 2600.2179060411754
avg_episode_per_sec: 8.943139831611953
collect_time: 0.8945404131691903
reward_mean: 1730.0556107535326
reward_std: 682.7753127660751
reward_max: 2898.438887643206
reward_min: 817.8696534831794
total_envstep_count: 10804362
total_train_sample_count: 8125232
total_episode_count: 26939
total_duration: 2304.244355890804
[2023-06-29 11:57:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 2710.1578145258222
avg_train_sample_per_sec: 2710.1578145258222
avg_episode_per_sec: 12.318899156935554
collect_time: 0.8929369304729625
reward_mean: 1592.7523290305116
reward_std: 599.1326628341726
reward_max: 2944.193144960393
reward_min: 826.2361357030143
total_envstep_count: 10808962
total_train_sample_count: 8128452
total_episode_count: 26950
total_duration: 2305.137292821277
[2023-06-29 11:57:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 991
train_sample_count: 991
avg_envstep_per_episode: 247.75
avg_sample_per_episode: 247.75
avg_envstep_per_sec: 2603.8685051101547
avg_train_sample_per_sec: 2603.8685051101547
avg_episode_per_sec: 10.510064601857335
collect_time: 0.38058757500816137
reward_mean: 2228.811877490088
reward_std: 696.1913318986004
reward_max: 3414.6548531604813
reward_min: 1638.7752135279966
total_envstep_count: 10813458
total_train_sample_count: 8131843
total_episode_count: 26954
total_duration: 2305.517880396285
[2023-06-29 11:57:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2351
train_sample_count: 2351
avg_envstep_per_episode: 195.91666666666666
avg_sample_per_episode: 195.91666666666666
avg_envstep_per_sec: 2731.1167385939116
avg_train_sample_per_sec: 2731.1167385939116
avg_episode_per_sec: 13.940196028552505
collect_time: 0.8608200326180085
reward_mean: 1935.4124998921495
reward_std: 938.1283855625495
reward_max: 3558.6279393448262
reward_min: 925.7546867730359
total_envstep_count: 10817826
total_train_sample_count: 8135394
total_episode_count: 26966
total_duration: 2306.378700428903
[2023-06-29 11:57:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1347
train_sample_count: 1347
avg_envstep_per_episode: 269.4
avg_sample_per_episode: 269.4
avg_envstep_per_sec: 2569.2289502181343
avg_train_sample_per_sec: 2569.2289502181343
avg_episode_per_sec: 9.536855791455585
collect_time: 0.5242818083167077
reward_mean: 2146.5281694936943
reward_std: 824.378485143448
reward_max: 3425.730022907617
reward_min: 922.3671452190123
total_envstep_count: 10822042
total_train_sample_count: 8138741
total_episode_count: 26971
total_duration: 2306.9029822372195
[2023-06-29 11:57:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1659
train_sample_count: 1659
avg_envstep_per_episode: 276.5
avg_sample_per_episode: 276.5
avg_envstep_per_sec: 2403.4861979726666
avg_train_sample_per_sec: 2403.4861979726666
avg_episode_per_sec: 8.692535978201326
collect_time: 0.6902473587738351
reward_mean: 2869.298936502495
reward_std: 688.7960931198057
reward_max: 3470.060024667433
reward_min: 1548.3385273171612
total_envstep_count: 10825826
total_train_sample_count: 8142000
total_episode_count: 26977
total_duration: 2307.5932295959933
[2023-06-29 11:58:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1542
train_sample_count: 1542
avg_envstep_per_episode: 220.28571428571428
avg_sample_per_episode: 220.28571428571428
avg_envstep_per_sec: 2706.192018712776
avg_train_sample_per_sec: 2706.192018712776
avg_episode_per_sec: 12.284918372885494
collect_time: 0.5698043558392674
reward_mean: 1922.3542154978034
reward_std: 909.0480593720116
reward_max: 3133.702028178741
reward_min: 43.633140607653
total_envstep_count: 10830474
total_train_sample_count: 8145542
total_episode_count: 26984
total_duration: 2308.1630339518324
[2023-06-29 11:58:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2379
train_sample_count: 2379
avg_envstep_per_episode: 264.3333333333333
avg_sample_per_episode: 264.3333333333333
avg_envstep_per_sec: 2678.985796221944
avg_train_sample_per_sec: 2678.985796221944
avg_episode_per_sec: 10.134876908784152
collect_time: 0.8880226253364236
reward_mean: 2193.5136932528426
reward_std: 801.9875740634559
reward_max: 3429.783741446775
reward_min: 1052.8200902071642
total_envstep_count: 10835666
total_train_sample_count: 8149121
total_episode_count: 26993
total_duration: 2309.0510565771688
[2023-06-29 11:58:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1648
train_sample_count: 1648
avg_envstep_per_episode: 274.6666666666667
avg_sample_per_episode: 274.6666666666667
avg_envstep_per_sec: 2577.843920829184
avg_train_sample_per_sec: 2577.843920829184
avg_episode_per_sec: 9.385354080688776
collect_time: 0.6392939412212
reward_mean: 2397.3502336612346
reward_std: 686.7691285966514
reward_max: 3370.016017516709
reward_min: 1569.2565930503
total_envstep_count: 10839506
total_train_sample_count: 8152369
total_episode_count: 26999
total_duration: 2309.69035051839
[2023-06-29 11:58:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1643
train_sample_count: 1643
avg_envstep_per_episode: 234.71428571428572
avg_sample_per_episode: 234.71428571428572
avg_envstep_per_sec: 2423.196139912492
avg_train_sample_per_sec: 2423.196139912492
avg_episode_per_sec: 10.324024941806114
collect_time: 0.6780301325749607
reward_mean: 2068.7366559280554
reward_std: 745.5053861124322
reward_max: 3240.6421447976436
reward_min: 1106.860551846379
total_envstep_count: 10844026
total_train_sample_count: 8155612
total_episode_count: 27006
total_duration: 2310.368380650965
[2023-06-29 11:58:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1933
train_sample_count: 1933
avg_envstep_per_episode: 214.77777777777777
avg_sample_per_episode: 214.77777777777777
avg_envstep_per_sec: 2740.3743961552623
avg_train_sample_per_sec: 2740.3743961552623
avg_episode_per_sec: 12.759115139884823
collect_time: 0.7053780690375715
reward_mean: 2052.004141682162
reward_std: 752.3622114126625
reward_max: 3113.8245699792183
reward_min: 1024.5603458186251
total_envstep_count: 10848794
total_train_sample_count: 8159145
total_episode_count: 27015
total_duration: 2311.0737587200024
[2023-06-29 11:58:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2195
train_sample_count: 2195
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 2804.64481423303
avg_train_sample_per_sec: 2804.64481423303
avg_episode_per_sec: 12.77742512179057
collect_time: 0.7826302955942227
reward_mean: 1635.8102964296484
reward_std: 392.7486993001338
reward_max: 2466.370676975299
reward_min: 1119.4709978173485
total_envstep_count: 10852554
total_train_sample_count: 8162540
total_episode_count: 27025
total_duration: 2311.8563890155965
[2023-06-29 11:58:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2218
train_sample_count: 2218
avg_envstep_per_episode: 316.85714285714283
avg_sample_per_episode: 316.85714285714283
avg_envstep_per_sec: 2648.867197034505
avg_train_sample_per_sec: 2648.867197034505
avg_episode_per_sec: 8.359815319766247
collect_time: 0.837339071767405
reward_mean: 2080.4211313324627
reward_std: 936.1216705850345
reward_max: 3544.9516237407324
reward_min: 1151.813903327043
total_envstep_count: 10856778
total_train_sample_count: 8165958
total_episode_count: 27032
total_duration: 2312.693728087364
[2023-06-29 11:58:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2925
train_sample_count: 2925
avg_envstep_per_episode: 292.5
avg_sample_per_episode: 292.5
avg_envstep_per_sec: 2576.5740448077718
avg_train_sample_per_sec: 2576.5740448077718
avg_episode_per_sec: 8.808800153188963
collect_time: 1.1352283882135523
reward_mean: 1847.3403751148685
reward_std: 858.1989490366022
reward_max: 3573.916438019654
reward_min: 972.791410848226
total_envstep_count: 10861282
total_train_sample_count: 8169283
total_episode_count: 27042
total_duration: 2313.8289564755773
[2023-06-29 11:58:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1870
train_sample_count: 1870
avg_envstep_per_episode: 267.14285714285717
avg_sample_per_episode: 267.14285714285717
avg_envstep_per_sec: 2678.9851920703436
avg_train_sample_per_sec: 2678.9851920703436
avg_episode_per_sec: 10.02828681523658
collect_time: 0.6980255081420765
reward_mean: 1722.7953101168266
reward_std: 542.6489001532145
reward_max: 2792.451190789635
reward_min: 1168.7141969207123
total_envstep_count: 10865682
total_train_sample_count: 8172753
total_episode_count: 27049
total_duration: 2314.5269819837195
[2023-06-29 11:58:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2141
train_sample_count: 2141
avg_envstep_per_episode: 237.88888888888889
avg_sample_per_episode: 237.88888888888889
avg_envstep_per_sec: 2749.855744545059
avg_train_sample_per_sec: 2749.855744545059
avg_episode_per_sec: 11.559412284402397
collect_time: 0.7785862964801489
reward_mean: 1829.7467922368394
reward_std: 690.547399998672
reward_max: 3122.374649929803
reward_min: 1054.6341527322486
total_envstep_count: 10870314
total_train_sample_count: 8176094
total_episode_count: 27058
total_duration: 2315.3055682801996
[2023-06-29 11:58:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2977
train_sample_count: 2977
avg_envstep_per_episode: 248.08333333333334
avg_sample_per_episode: 248.08333333333334
avg_envstep_per_sec: 2667.0591000665727
avg_train_sample_per_sec: 2667.0591000665727
avg_episode_per_sec: 10.750658112461831
collect_time: 1.1162107356097548
reward_mean: 1658.6737664843165
reward_std: 736.7129859004701
reward_max: 3519.8946285858074
reward_min: 529.5171375562597
total_envstep_count: 10874946
total_train_sample_count: 8179471
total_episode_count: 27070
total_duration: 2316.4217790158095
[2023-06-29 11:58:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 275.8888888888889
avg_sample_per_episode: 275.8888888888889
avg_envstep_per_sec: 2558.262621213052
avg_train_sample_per_sec: 2558.262621213052
avg_episode_per_sec: 9.272800479628462
collect_time: 0.9705805726945402
reward_mean: 1716.770461438187
reward_std: 484.3023028173371
reward_max: 2661.51965784185
reward_min: 1099.873495783541
total_envstep_count: 10879146
total_train_sample_count: 8182754
total_episode_count: 27079
total_duration: 2317.392359588504
[2023-06-29 11:58:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1735
train_sample_count: 1735
avg_envstep_per_episode: 289.1666666666667
avg_sample_per_episode: 289.1666666666667
avg_envstep_per_sec: 2485.859296793466
avg_train_sample_per_sec: 2485.859296793466
avg_episode_per_sec: 8.596631573925531
collect_time: 0.6979477890152485
reward_mean: 1914.0816232585792
reward_std: 502.3914681612833
reward_max: 2603.9065489100813
reward_min: 1261.2988433241953
total_envstep_count: 10883290
total_train_sample_count: 8186089
total_episode_count: 27085
total_duration: 2318.0903073775194
[2023-06-29 11:58:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 139.33333333333334
avg_sample_per_episode: 139.33333333333334
avg_envstep_per_sec: 2739.705301668087
avg_train_sample_per_sec: 2739.705301668087
avg_episode_per_sec: 19.66295671053651
collect_time: 0.30514230836834755
reward_mean: 1814.6814181027942
reward_std: 1047.3532808942823
reward_max: 3333.928107908157
reward_min: 39.37216604385703
total_envstep_count: 10887266
total_train_sample_count: 8189325
total_episode_count: 27091
total_duration: 2318.395449685888
[2023-06-29 11:58:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1790
train_sample_count: 1790
avg_envstep_per_episode: 198.88888888888889
avg_sample_per_episode: 198.88888888888889
avg_envstep_per_sec: 2517.6204950803804
avg_train_sample_per_sec: 2517.6204950803804
avg_episode_per_sec: 12.65842707023655
collect_time: 0.7109888100679965
reward_mean: 2146.2677897643957
reward_std: 874.6146414742682
reward_max: 3474.2884243167296
reward_min: 988.6489284296252
total_envstep_count: 10892106
total_train_sample_count: 8192715
total_episode_count: 27100
total_duration: 2319.106438495956
[2023-06-29 11:58:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1787
train_sample_count: 1787
avg_envstep_per_episode: 297.8333333333333
avg_sample_per_episode: 297.8333333333333
avg_envstep_per_sec: 2604.1466167988087
avg_train_sample_per_sec: 2604.1466167988087
avg_episode_per_sec: 8.74363721365017
collect_time: 0.6862132832584903
reward_mean: 2328.208058720869
reward_std: 648.6177979158656
reward_max: 3529.7060428986833
reward_min: 1366.7690618158647
total_envstep_count: 10896066
total_train_sample_count: 8196102
total_episode_count: 27106
total_duration: 2319.7926517792143
[2023-06-29 11:58:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2621
train_sample_count: 2621
avg_envstep_per_episode: 262.1
avg_sample_per_episode: 262.1
avg_envstep_per_sec: 2780.050374480315
avg_train_sample_per_sec: 2780.050374480315
avg_episode_per_sec: 10.606830883175562
collect_time: 0.9427886717664076
reward_mean: 2019.356442511292
reward_std: 816.4560040534678
reward_max: 3543.201717662347
reward_min: 1095.8109289328506
total_envstep_count: 10900378
total_train_sample_count: 8199523
total_episode_count: 27116
total_duration: 2320.7354404509806
[2023-06-29 11:58:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2805
train_sample_count: 2805
avg_envstep_per_episode: 311.6666666666667
avg_sample_per_episode: 311.6666666666667
avg_envstep_per_sec: 2475.576695818579
avg_train_sample_per_sec: 2475.576695818579
avg_episode_per_sec: 7.943026831503461
collect_time: 1.1330693186512217
reward_mean: 1851.61927062383
reward_std: 764.8582564639183
reward_max: 3228.8324619954437
reward_min: 712.8438011484013
total_envstep_count: 10904818
total_train_sample_count: 8202728
total_episode_count: 27125
total_duration: 2321.8685097696316
[2023-06-29 11:58:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2528
train_sample_count: 2528
avg_envstep_per_episode: 280.8888888888889
avg_sample_per_episode: 280.8888888888889
avg_envstep_per_sec: 2754.4924050878076
avg_train_sample_per_sec: 2754.4924050878076
avg_episode_per_sec: 9.80634163203729
collect_time: 0.9177734508654101
reward_mean: 1583.4423174610756
reward_std: 698.541546070531
reward_max: 2766.744202973317
reward_min: 772.0982139232091
total_envstep_count: 10909490
total_train_sample_count: 8206056
total_episode_count: 27134
total_duration: 2322.786283220497
[2023-06-29 11:59:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2973
train_sample_count: 2973
avg_envstep_per_episode: 270.27272727272725
avg_sample_per_episode: 270.27272727272725
avg_envstep_per_sec: 2583.2812505462066
avg_train_sample_per_sec: 2583.2812505462066
avg_episode_per_sec: 9.558053735623368
collect_time: 1.1508619122952222
reward_mean: 1666.8283863819095
reward_std: 470.30649217284275
reward_max: 2854.862333238402
reward_min: 1030.7188047058578
total_envstep_count: 10914362
total_train_sample_count: 8209429
total_episode_count: 27145
total_duration: 2323.937145132792
[2023-06-29 11:59:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3556
train_sample_count: 3556
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2619.115563657772
avg_train_sample_per_sec: 2619.115563657772
avg_episode_per_sec: 10.311478597077842
collect_time: 1.3577102321647105
reward_mean: 1436.7788171825293
reward_std: 551.9517409618052
reward_max: 2953.8451543747974
reward_min: 883.2399824871777
total_envstep_count: 10919106
total_train_sample_count: 8212985
total_episode_count: 27159
total_duration: 2325.2948553649567
[2023-06-29 11:59:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2461
train_sample_count: 2461
avg_envstep_per_episode: 246.1
avg_sample_per_episode: 246.1
avg_envstep_per_sec: 2783.86402001706
avg_train_sample_per_sec: 2783.86402001706
avg_episode_per_sec: 11.311922064270865
collect_time: 0.8840230637360365
reward_mean: 1247.6776015589298
reward_std: 373.80943007917455
reward_max: 2035.7771491910598
reward_min: 690.08122049601
total_envstep_count: 10923874
total_train_sample_count: 8216246
total_episode_count: 27169
total_duration: 2326.1788784286928
[2023-06-29 11:59:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3067
train_sample_count: 3067
avg_envstep_per_episode: 306.7
avg_sample_per_episode: 306.7
avg_envstep_per_sec: 2689.492213846951
avg_train_sample_per_sec: 2689.492213846951
avg_episode_per_sec: 8.769130139703133
collect_time: 1.140363963208161
reward_mean: 1993.7968454191675
reward_std: 557.9602202586219
reward_max: 2929.6784160673183
reward_min: 1099.376566341063
total_envstep_count: 10928282
total_train_sample_count: 8219713
total_episode_count: 27179
total_duration: 2327.319242391901
[2023-06-29 11:59:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2816
train_sample_count: 2816
avg_envstep_per_episode: 312.8888888888889
avg_sample_per_episode: 312.8888888888889
avg_envstep_per_sec: 2809.192160331267
avg_train_sample_per_sec: 2809.192160331267
avg_episode_per_sec: 8.978241989695102
collect_time: 1.002423415444791
reward_mean: 1669.7944856583708
reward_std: 537.7255951352269
reward_max: 2753.8949815074775
reward_min: 1157.712480203792
total_envstep_count: 10933018
total_train_sample_count: 8222929
total_episode_count: 27188
total_duration: 2328.3216658073457
[2023-06-29 11:59:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2842
train_sample_count: 2842
avg_envstep_per_episode: 258.3636363636364
avg_sample_per_episode: 258.3636363636364
avg_envstep_per_sec: 2643.7167788316883
avg_train_sample_per_sec: 2643.7167788316883
avg_episode_per_sec: 10.232542071480848
collect_time: 1.075001688061282
reward_mean: 1487.9814995755314
reward_std: 461.18188852630027
reward_max: 2570.781600005471
reward_min: 873.8973407318596
total_envstep_count: 10937434
total_train_sample_count: 8226171
total_episode_count: 27199
total_duration: 2329.3966674954067
[2023-06-29 11:59:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 352.3333333333333
avg_sample_per_episode: 352.3333333333333
avg_envstep_per_sec: 2647.697162923841
avg_train_sample_per_sec: 2647.697162923841
avg_episode_per_sec: 7.514750698932377
collect_time: 0.7984296805551276
reward_mean: 2099.4033439352356
reward_std: 725.7227842230621
reward_max: 3471.370874246212
reward_min: 1353.856197232945
total_envstep_count: 10942146
total_train_sample_count: 8229485
total_episode_count: 27205
total_duration: 2330.195097175962
[2023-06-29 11:59:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1787
train_sample_count: 1787
avg_envstep_per_episode: 198.55555555555554
avg_sample_per_episode: 198.55555555555554
avg_envstep_per_sec: 2683.187411030221
avg_train_sample_per_sec: 2683.187411030221
avg_episode_per_sec: 13.513534806531611
collect_time: 0.6659989505965496
reward_mean: 1880.6291761228595
reward_std: 701.8062318232426
reward_max: 3687.894867252987
reward_min: 1325.7077538954184
total_envstep_count: 10946602
total_train_sample_count: 8232872
total_episode_count: 27214
total_duration: 2330.8610961265586
[2023-06-29 11:59:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2877
train_sample_count: 2877
avg_envstep_per_episode: 319.6666666666667
avg_sample_per_episode: 319.6666666666667
avg_envstep_per_sec: 2750.0840585348005
avg_train_sample_per_sec: 2750.0840585348005
avg_episode_per_sec: 8.602974114290303
collect_time: 1.0461498407917096
reward_mean: 2267.4378004965347
reward_std: 599.63653990106
reward_max: 3177.3384386687712
reward_min: 1237.989996807989
total_envstep_count: 10951370
total_train_sample_count: 8236149
total_episode_count: 27223
total_duration: 2331.9072459673503
[2023-06-29 11:59:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3302
train_sample_count: 3302
avg_envstep_per_episode: 330.2
avg_sample_per_episode: 330.2
avg_envstep_per_sec: 2666.3415545611592
avg_train_sample_per_sec: 2666.3415545611592
avg_episode_per_sec: 8.074928996248211
collect_time: 1.2384009821815423
reward_mean: 1882.2778765298467
reward_std: 762.0262258732154
reward_max: 3153.2591875676753
reward_min: 907.4222180261646
total_envstep_count: 10956186
total_train_sample_count: 8239451
total_episode_count: 27233
total_duration: 2333.145646949532
[2023-06-29 11:59:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2077
train_sample_count: 2077
avg_envstep_per_episode: 296.7142857142857
avg_sample_per_episode: 296.7142857142857
avg_envstep_per_sec: 2603.64325545068
avg_train_sample_per_sec: 2603.64325545068
avg_episode_per_sec: 8.774917086256504
collect_time: 0.7977283353438833
reward_mean: 1871.9987220209775
reward_std: 747.821927684956
reward_max: 3287.218189120622
reward_min: 1021.9101600868257
total_envstep_count: 10960394
total_train_sample_count: 8242728
total_episode_count: 27240
total_duration: 2333.943375284876
[2023-06-29 11:59:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1970
train_sample_count: 1970
avg_envstep_per_episode: 197.0
avg_sample_per_episode: 197.0
avg_envstep_per_sec: 2733.4746591292737
avg_train_sample_per_sec: 2733.4746591292737
avg_episode_per_sec: 13.875505883904944
collect_time: 0.7206944441283123
reward_mean: 1236.7219445086525
reward_std: 657.3262002522819
reward_max: 2060.0051594846827
reward_min: 42.504043860981824
total_envstep_count: 10964234
total_train_sample_count: 8246298
total_episode_count: 27250
total_duration: 2334.664069729004
[2023-06-29 11:59:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2040
train_sample_count: 2040
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2741.737203545335
avg_train_sample_per_sec: 2741.737203545335
avg_episode_per_sec: 10.751910602138569
collect_time: 0.7440538055077197
reward_mean: 1970.680365189899
reward_std: 874.7453694492818
reward_max: 3619.587595604982
reward_min: 859.1479824916745
total_envstep_count: 10968042
total_train_sample_count: 8249538
total_episode_count: 27258
total_duration: 2335.4081235345116
[2023-06-29 11:59:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 271.1666666666667
avg_sample_per_episode: 271.1666666666667
avg_envstep_per_sec: 2585.465819596239
avg_train_sample_per_sec: 2585.465819596239
avg_episode_per_sec: 9.53460044104329
collect_time: 0.6292869886998087
reward_mean: 1702.1777322925484
reward_std: 747.0206991630611
reward_max: 3218.175648334351
reward_min: 994.7711513483982
total_envstep_count: 10972178
total_train_sample_count: 8252765
total_episode_count: 27264
total_duration: 2336.0374105232113
[2023-06-29 11:59:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1876
train_sample_count: 1876
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2482.6537796400994
avg_train_sample_per_sec: 2482.6537796400994
avg_episode_per_sec: 9.263633506119774
collect_time: 0.7556430201362819
reward_mean: 2078.5163238598498
reward_std: 1035.9084567486304
reward_max: 3476.842514947083
reward_min: 873.3924675169179
total_envstep_count: 10976874
total_train_sample_count: 8256241
total_episode_count: 27271
total_duration: 2336.7930535433475
[2023-06-29 11:59:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2325
train_sample_count: 2325
avg_envstep_per_episode: 258.3333333333333
avg_sample_per_episode: 258.3333333333333
avg_envstep_per_sec: 2444.959885035186
avg_train_sample_per_sec: 2444.959885035186
avg_episode_per_sec: 9.464360845297495
collect_time: 0.9509358473448084
reward_mean: 2310.330605941584
reward_std: 982.6915389144631
reward_max: 3625.050527825938
reward_min: 1196.532368832851
total_envstep_count: 10982506
total_train_sample_count: 8259766
total_episode_count: 27280
total_duration: 2337.743989390692
[2023-06-29 11:59:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1621
train_sample_count: 1621
avg_envstep_per_episode: 324.2
avg_sample_per_episode: 324.2
avg_envstep_per_sec: 2405.298009024857
avg_train_sample_per_sec: 2405.298009024857
avg_episode_per_sec: 7.4191795466528605
collect_time: 0.6739289659401402
reward_mean: 2535.360042336809
reward_std: 926.839225654611
reward_max: 3458.756606076139
reward_min: 1359.7216290690085
total_envstep_count: 10986962
total_train_sample_count: 8262987
total_episode_count: 27285
total_duration: 2338.417918356632
[2023-06-29 11:59:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 244.7
avg_sample_per_episode: 244.7
avg_envstep_per_sec: 2622.7100896506854
avg_train_sample_per_sec: 2622.7100896506854
avg_episode_per_sec: 10.718063300574931
collect_time: 0.9330043795751409
reward_mean: 2174.968852375668
reward_std: 974.4648457954396
reward_max: 3491.739206182419
reward_min: 1163.627489902422
total_envstep_count: 10991210
total_train_sample_count: 8266234
total_episode_count: 27295
total_duration: 2339.3509227362074
[2023-06-29 11:59:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2933
train_sample_count: 2933
avg_envstep_per_episode: 366.625
avg_sample_per_episode: 366.625
avg_envstep_per_sec: 2579.024365711127
avg_train_sample_per_sec: 2579.024365711127
avg_episode_per_sec: 7.034502190824758
collect_time: 1.1372517603924497
reward_mean: 2140.2857454066
reward_std: 795.1705914554437
reward_max: 3450.735289167436
reward_min: 1283.8598948573833
total_envstep_count: 10995946
total_train_sample_count: 8269967
total_episode_count: 27303
total_duration: 2340.4881744965996
[2023-06-29 11:59:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1834
train_sample_count: 1834
avg_envstep_per_episode: 305.6666666666667
avg_sample_per_episode: 305.6666666666667
avg_envstep_per_sec: 2509.411181411391
avg_train_sample_per_sec: 2509.411181411391
avg_episode_per_sec: 8.209633090767909
collect_time: 0.730848739969544
reward_mean: 2061.809318190229
reward_std: 791.3201089454902
reward_max: 3425.6139574346576
reward_min: 954.4209604860819
total_envstep_count: 11001130
total_train_sample_count: 8273401
total_episode_count: 27309
total_duration: 2341.2190232365692
[2023-06-29 12:00:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3002
train_sample_count: 3002
avg_envstep_per_episode: 300.2
avg_sample_per_episode: 300.2
avg_envstep_per_sec: 2520.777193869772
avg_train_sample_per_sec: 2520.777193869772
avg_episode_per_sec: 8.39699265113182
collect_time: 1.1909025546964263
reward_mean: 2316.5066967417492
reward_std: 849.1682137314594
reward_max: 3492.580698975836
reward_min: 922.9195962024337
total_envstep_count: 11005610
total_train_sample_count: 8276803
total_episode_count: 27319
total_duration: 2342.409925791266
[2023-06-29 12:00:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 305.0
avg_sample_per_episode: 305.0
avg_envstep_per_sec: 2350.563597002126
avg_train_sample_per_sec: 2350.563597002126
avg_episode_per_sec: 7.706765891810249
collect_time: 0.9082928037866951
reward_mean: 1476.1139406750312
reward_std: 416.94363424822507
reward_max: 2144.8536041626103
reward_min: 851.0405510690942
total_envstep_count: 11010426
total_train_sample_count: 8280138
total_episode_count: 27326
total_duration: 2343.3182185950523
[2023-06-29 12:00:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2172
train_sample_count: 2172
avg_envstep_per_episode: 241.33333333333334
avg_sample_per_episode: 241.33333333333334
avg_envstep_per_sec: 2730.497259480947
avg_train_sample_per_sec: 2730.497259480947
avg_episode_per_sec: 11.314215163595085
collect_time: 0.7954595055747778
reward_mean: 2114.2792027462074
reward_std: 907.8649803980173
reward_max: 3402.275785801661
reward_min: 980.0726718819967
total_envstep_count: 11015002
total_train_sample_count: 8283510
total_episode_count: 27335
total_duration: 2344.113678100627
[2023-06-29 12:00:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 342.1666666666667
avg_sample_per_episode: 342.1666666666667
avg_envstep_per_sec: 2466.415040322674
avg_train_sample_per_sec: 2466.415040322674
avg_episode_per_sec: 7.208227102745273
collect_time: 0.8323822091724724
reward_mean: 2392.9135768282063
reward_std: 933.8286998914202
reward_max: 3534.335212895403
reward_min: 1394.4506759305045
total_envstep_count: 11019498
total_train_sample_count: 8286763
total_episode_count: 27341
total_duration: 2344.9460603097996
[2023-06-29 12:00:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1450
train_sample_count: 1450
avg_envstep_per_episode: 207.14285714285714
avg_sample_per_episode: 207.14285714285714
avg_envstep_per_sec: 2689.5509974756037
avg_train_sample_per_sec: 2689.5509974756037
avg_episode_per_sec: 12.984039298158086
collect_time: 0.5391234452743083
reward_mean: 1823.340099199692
reward_std: 812.0966550930684
reward_max: 3391.7174089351115
reward_min: 981.6655779563544
total_envstep_count: 11024034
total_train_sample_count: 8290213
total_episode_count: 27348
total_duration: 2345.485183755074
[2023-06-29 12:00:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 220.54545454545453
avg_sample_per_episode: 220.54545454545453
avg_envstep_per_sec: 2487.415939463542
avg_train_sample_per_sec: 2487.415939463542
avg_episode_per_sec: 11.278472932439803
collect_time: 0.9753093407141278
reward_mean: 2020.4221071459694
reward_std: 753.5760112173118
reward_max: 3419.8227748189847
reward_min: 1138.933845493195
total_envstep_count: 11028146
total_train_sample_count: 8293439
total_episode_count: 27359
total_duration: 2346.460493095788
[2023-06-29 12:00:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1877
train_sample_count: 1877
avg_envstep_per_episode: 268.14285714285717
avg_sample_per_episode: 268.14285714285717
avg_envstep_per_sec: 2685.093550522052
avg_train_sample_per_sec: 2685.093550522052
avg_episode_per_sec: 10.013668009405627
collect_time: 0.699044545258046
reward_mean: 1761.872520257192
reward_std: 583.2769403949615
reward_max: 2922.1100159331168
reward_min: 1162.9283471789417
total_envstep_count: 11032466
total_train_sample_count: 8296916
total_episode_count: 27366
total_duration: 2347.159537641046
[2023-06-29 12:00:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2530
train_sample_count: 2530
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2410.1085973653844
avg_train_sample_per_sec: 2410.1085973653844
avg_episode_per_sec: 9.5261209382031
collect_time: 1.0497452283957973
reward_mean: 1823.5531350888746
reward_std: 540.887181085181
reward_max: 2909.214283685119
reward_min: 967.4128914500386
total_envstep_count: 11036890
total_train_sample_count: 8300246
total_episode_count: 27376
total_duration: 2348.2092828694417
[2023-06-29 12:00:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2871
train_sample_count: 2871
avg_envstep_per_episode: 287.1
avg_sample_per_episode: 287.1
avg_envstep_per_sec: 2590.6366432006407
avg_train_sample_per_sec: 2590.6366432006407
avg_episode_per_sec: 9.023464448626404
collect_time: 1.1082217985047027
reward_mean: 1702.1332595929666
reward_std: 634.8332448370242
reward_max: 3033.423533025605
reward_min: 972.3703129392292
total_envstep_count: 11041786
total_train_sample_count: 8303517
total_episode_count: 27386
total_duration: 2349.3175046679467
[2023-06-29 12:00:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1561
train_sample_count: 1561
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2736.664604789396
avg_train_sample_per_sec: 2736.664604789396
avg_episode_per_sec: 12.272038586499534
collect_time: 0.5704023785991594
reward_mean: 1648.0268341492151
reward_std: 701.9758824442632
reward_max: 3159.0198417224183
reward_min: 881.7939257355174
total_envstep_count: 11046378
total_train_sample_count: 8307078
total_episode_count: 27393
total_duration: 2349.887907046546
[2023-06-29 12:00:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2001
train_sample_count: 2001
avg_envstep_per_episode: 222.33333333333334
avg_sample_per_episode: 222.33333333333334
avg_envstep_per_sec: 2657.4886269966514
avg_train_sample_per_sec: 2657.4886269966514
avg_episode_per_sec: 11.952722460254805
collect_time: 0.7529665337689219
reward_mean: 2097.800914232089
reward_std: 652.9321644211983
reward_max: 3547.3223227586072
reward_min: 1374.754467580777
total_envstep_count: 11050658
total_train_sample_count: 8310279
total_episode_count: 27402
total_duration: 2350.6408735803147
[2023-06-29 12:00:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1678
train_sample_count: 1678
avg_envstep_per_episode: 335.6
avg_sample_per_episode: 335.6
avg_envstep_per_sec: 2757.128510789272
avg_train_sample_per_sec: 2757.128510789272
avg_episode_per_sec: 8.215519996392347
collect_time: 0.608604203044437
reward_mean: 2307.857845681932
reward_std: 421.45185411004377
reward_max: 2803.924645109194
reward_min: 1574.216342626999
total_envstep_count: 11054514
total_train_sample_count: 8313557
total_episode_count: 27407
total_duration: 2351.249477783359
[2023-06-29 12:00:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1035
train_sample_count: 1035
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 2124.158604929612
avg_train_sample_per_sec: 2124.158604929612
avg_episode_per_sec: 12.313962927128186
collect_time: 0.48725175116304303
reward_mean: 2231.7716606880617
reward_std: 769.7827310132067
reward_max: 3493.7867011971193
reward_min: 1323.7207248668572
total_envstep_count: 11058402
total_train_sample_count: 8316992
total_episode_count: 27413
total_duration: 2351.736729534522
[2023-06-29 12:00:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2080
train_sample_count: 2080
avg_envstep_per_episode: 231.11111111111111
avg_sample_per_episode: 231.11111111111111
avg_envstep_per_sec: 2467.8996320699334
avg_train_sample_per_sec: 2467.8996320699334
avg_episode_per_sec: 10.678411869533365
collect_time: 0.8428219579802825
reward_mean: 1953.8687918336752
reward_std: 756.9025827214443
reward_max: 3298.0969286385243
reward_min: 997.927150711754
total_envstep_count: 11063130
total_train_sample_count: 8320272
total_episode_count: 27422
total_duration: 2352.5795514925026
[2023-06-29 12:00:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2416
train_sample_count: 2416
avg_envstep_per_episode: 241.6
avg_sample_per_episode: 241.6
avg_envstep_per_sec: 2767.4607929017848
avg_train_sample_per_sec: 2767.4607929017848
avg_episode_per_sec: 11.454721824924606
collect_time: 0.8730024310359732
reward_mean: 1862.80683081569
reward_std: 771.6447490709588
reward_max: 3452.6559176235633
reward_min: 803.6691542397488
total_envstep_count: 11067770
total_train_sample_count: 8323488
total_episode_count: 27432
total_duration: 2353.4525539235387
[2023-06-29 12:00:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2877
train_sample_count: 2877
avg_envstep_per_episode: 287.7
avg_sample_per_episode: 287.7
avg_envstep_per_sec: 2758.7072116553827
avg_train_sample_per_sec: 2758.7072116553827
avg_episode_per_sec: 9.58883285246918
collect_time: 1.0428797908835112
reward_mean: 1895.873169860363
reward_std: 677.6234518464436
reward_max: 3419.6038516908843
reward_min: 848.7237444660891
total_envstep_count: 11072514
total_train_sample_count: 8326765
total_episode_count: 27442
total_duration: 2354.4954337144222
[2023-06-29 12:00:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2067
train_sample_count: 2067
avg_envstep_per_episode: 258.375
avg_sample_per_episode: 258.375
avg_envstep_per_sec: 2476.5084974066112
avg_train_sample_per_sec: 2476.5084974066112
avg_episode_per_sec: 9.584938548259743
collect_time: 0.8346428054515271
reward_mean: 1725.7123142304777
reward_std: 535.3455881607587
reward_max: 2578.52271862843
reward_min: 976.1973202045549
total_envstep_count: 11076730
total_train_sample_count: 8330032
total_episode_count: 27450
total_duration: 2355.3300765198737
[2023-06-29 12:00:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2491
train_sample_count: 2491
avg_envstep_per_episode: 311.375
avg_sample_per_episode: 311.375
avg_envstep_per_sec: 2762.9573021236624
avg_train_sample_per_sec: 2762.9573021236624
avg_episode_per_sec: 8.873407634279125
collect_time: 0.9015702117746696
reward_mean: 2167.4419323647126
reward_std: 851.4060273937296
reward_max: 3648.610734635022
reward_min: 1306.7014608053726
total_envstep_count: 11080634
total_train_sample_count: 8333323
total_episode_count: 27458
total_duration: 2356.231646731648
[2023-06-29 12:00:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3393
train_sample_count: 3393
avg_envstep_per_episode: 377.0
avg_sample_per_episode: 377.0
avg_envstep_per_sec: 2761.5612886401427
avg_train_sample_per_sec: 2761.5612886401427
avg_episode_per_sec: 7.325096256339902
collect_time: 1.2286527965022251
reward_mean: 1944.3331387832409
reward_std: 816.2738615764003
reward_max: 3417.8506679032052
reward_min: 1050.2616416076864
total_envstep_count: 11085490
total_train_sample_count: 8336716
total_episode_count: 27467
total_duration: 2357.4602995281502
[2023-06-29 12:01:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2631
train_sample_count: 2631
avg_envstep_per_episode: 263.1
avg_sample_per_episode: 263.1
avg_envstep_per_sec: 2805.7902439496243
avg_train_sample_per_sec: 2805.7902439496243
avg_episode_per_sec: 10.66434908380701
collect_time: 0.9377037380728869
reward_mean: 1486.8368391902982
reward_std: 553.8701852892116
reward_max: 2355.7391956899337
reward_min: 755.7300601106023
total_envstep_count: 11090546
total_train_sample_count: 8340147
total_episode_count: 27477
total_duration: 2358.398003266223
[2023-06-29 12:01:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2814
train_sample_count: 2814
avg_envstep_per_episode: 255.8181818181818
avg_sample_per_episode: 255.8181818181818
avg_envstep_per_sec: 2564.64781111085
avg_train_sample_per_sec: 2564.64781111085
avg_episode_per_sec: 10.025275736396358
collect_time: 1.0972266787700358
reward_mean: 1725.6108130244068
reward_std: 576.0920693488225
reward_max: 3069.7389228631705
reward_min: 881.9000796799754
total_envstep_count: 11094738
total_train_sample_count: 8343361
total_episode_count: 27488
total_duration: 2359.495229944993
[2023-06-29 12:01:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2108
train_sample_count: 2108
avg_envstep_per_episode: 210.8
avg_sample_per_episode: 210.8
avg_envstep_per_sec: 2499.110787695992
avg_train_sample_per_sec: 2499.110787695992
avg_episode_per_sec: 11.855364268007552
collect_time: 0.8435000202385708
reward_mean: 1248.6038619993626
reward_std: 693.0704064649232
reward_max: 2808.3449659002636
reward_min: 433.7700321199959
total_envstep_count: 11099178
total_train_sample_count: 8346669
total_episode_count: 27498
total_duration: 2360.3387299652313
[2023-06-29 12:01:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 290.2857142857143
avg_sample_per_episode: 290.2857142857143
avg_envstep_per_sec: 2693.551915255872
avg_train_sample_per_sec: 2693.551915255872
avg_episode_per_sec: 9.278968212003496
collect_time: 0.7543942214334383
reward_mean: 2004.7999933220108
reward_std: 750.8242004742366
reward_max: 3542.4576070412163
reward_min: 1211.197437682679
total_envstep_count: 11103202
total_train_sample_count: 8349901
total_episode_count: 27505
total_duration: 2361.0931241866647
[2023-06-29 12:01:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1348
train_sample_count: 1348
avg_envstep_per_episode: 224.66666666666666
avg_sample_per_episode: 224.66666666666666
avg_envstep_per_sec: 2704.3113921034555
avg_train_sample_per_sec: 2704.3113921034555
avg_episode_per_sec: 12.03699432686998
collect_time: 0.4984633071236314
reward_mean: 2213.9144007260015
reward_std: 753.1720140942903
reward_max: 3486.2524164095917
reward_min: 1183.2866573137035
total_envstep_count: 11107178
total_train_sample_count: 8353249
total_episode_count: 27511
total_duration: 2361.591587493788
[2023-06-29 12:01:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3070
train_sample_count: 3070
avg_envstep_per_episode: 279.09090909090907
avg_sample_per_episode: 279.09090909090907
avg_envstep_per_sec: 2638.9605207328646
avg_train_sample_per_sec: 2638.9605207328646
avg_episode_per_sec: 9.45555886907541
collect_time: 1.1633368426244708
reward_mean: 1901.3741798072485
reward_std: 983.5307322419851
reward_max: 3552.0920911624908
reward_min: 429.32310108675637
total_envstep_count: 11111730
total_train_sample_count: 8356719
total_episode_count: 27522
total_duration: 2362.754924336413
[2023-06-29 12:01:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2655
train_sample_count: 2655
avg_envstep_per_episode: 265.5
avg_sample_per_episode: 265.5
avg_envstep_per_sec: 2714.33852788334
avg_train_sample_per_sec: 2714.33852788334
avg_episode_per_sec: 10.223497280163238
collect_time: 0.9781388624617828
reward_mean: 1494.6276204637074
reward_std: 425.15911090614185
reward_max: 2168.9401598641234
reward_min: 900.7979758858759
total_envstep_count: 11116418
total_train_sample_count: 8360174
total_episode_count: 27532
total_duration: 2363.733063198875
[2023-06-29 12:01:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1505
train_sample_count: 1505
avg_envstep_per_episode: 188.125
avg_sample_per_episode: 188.125
avg_envstep_per_sec: 2785.180142573856
avg_train_sample_per_sec: 2785.180142573856
avg_episode_per_sec: 14.804944279462358
collect_time: 0.5403600208815187
reward_mean: 1427.835202771853
reward_std: 756.1309633847765
reward_max: 2768.3185370698347
reward_min: 43.5372313560683
total_envstep_count: 11121674
total_train_sample_count: 8363679
total_episode_count: 27540
total_duration: 2364.2734232197563
[2023-06-29 12:01:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1816
train_sample_count: 1816
avg_envstep_per_episode: 181.6
avg_sample_per_episode: 181.6
avg_envstep_per_sec: 2776.2526138224175
avg_train_sample_per_sec: 2776.2526138224175
avg_episode_per_sec: 15.287734657612432
collect_time: 0.6541191500220448
reward_mean: 1903.2823713857128
reward_std: 1303.7212247373554
reward_max: 3612.5082237181214
reward_min: 63.29587631906699
total_envstep_count: 11126002
total_train_sample_count: 8367095
total_episode_count: 27550
total_duration: 2364.927542369778
[2023-06-29 12:01:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1608
train_sample_count: 1608
avg_envstep_per_episode: 229.71428571428572
avg_sample_per_episode: 229.71428571428572
avg_envstep_per_sec: 2442.944743746915
avg_train_sample_per_sec: 2442.944743746915
avg_episode_per_sec: 10.634709705365921
collect_time: 0.6582220101850107
reward_mean: 2392.119111298836
reward_std: 981.1731117313523
reward_max: 3501.4005041054465
reward_min: 858.086823641617
total_envstep_count: 11130290
total_train_sample_count: 8370303
total_episode_count: 27557
total_duration: 2365.585764379963
[2023-06-29 12:01:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2564
train_sample_count: 2564
avg_envstep_per_episode: 256.4
avg_sample_per_episode: 256.4
avg_envstep_per_sec: 2597.9707775554293
avg_train_sample_per_sec: 2597.9707775554293
avg_episode_per_sec: 10.132491332119459
collect_time: 0.9869241109834984
reward_mean: 1749.6856075144344
reward_std: 861.0599015129657
reward_max: 3432.2876599700603
reward_min: 851.9375150631552
total_envstep_count: 11135266
total_train_sample_count: 8373667
total_episode_count: 27567
total_duration: 2366.572688490947
[2023-06-29 12:01:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 230.22222222222223
avg_sample_per_episode: 230.22222222222223
avg_envstep_per_sec: 2797.18553893965
avg_train_sample_per_sec: 2797.18553893965
avg_episode_per_sec: 12.149937186513924
collect_time: 0.7407445702673868
reward_mean: 1956.4525016899424
reward_std: 993.3945988504289
reward_max: 3495.464132028917
reward_min: 72.2876551778478
total_envstep_count: 11140210
total_train_sample_count: 8376939
total_episode_count: 27576
total_duration: 2367.3134330612143
[2023-06-29 12:01:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2929
train_sample_count: 2929
avg_envstep_per_episode: 266.27272727272725
avg_sample_per_episode: 266.27272727272725
avg_envstep_per_sec: 2538.411669852887
avg_train_sample_per_sec: 2538.411669852887
avg_episode_per_sec: 9.533126790161065
collect_time: 1.1538711528889833
reward_mean: 1814.3282575703115
reward_std: 960.6454736394412
reward_max: 3328.651972644791
reward_min: 311.25935639257773
total_envstep_count: 11144858
total_train_sample_count: 8380268
total_episode_count: 27587
total_duration: 2368.467304214103
[2023-06-29 12:01:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1817
train_sample_count: 1817
avg_envstep_per_episode: 259.57142857142856
avg_sample_per_episode: 259.57142857142856
avg_envstep_per_sec: 2678.9148641226125
avg_train_sample_per_sec: 2678.9148641226125
avg_episode_per_sec: 10.32053057174369
collect_time: 0.6782597029618919
reward_mean: 1898.1648747496417
reward_std: 936.9199448232274
reward_max: 3616.1791078920187
reward_min: 1039.7592322096593
total_envstep_count: 11149090
total_train_sample_count: 8383685
total_episode_count: 27594
total_duration: 2369.145563917065
[2023-06-29 12:01:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1969
train_sample_count: 1969
avg_envstep_per_episode: 218.77777777777777
avg_sample_per_episode: 218.77777777777777
avg_envstep_per_sec: 2512.0959739857108
avg_train_sample_per_sec: 2512.0959739857108
avg_episode_per_sec: 11.482409225937733
collect_time: 0.7838076333031057
reward_mean: 1833.9338697965306
reward_std: 1018.0469697105823
reward_max: 3113.276300417034
reward_min: 80.52987624121785
total_envstep_count: 11153650
total_train_sample_count: 8387254
total_episode_count: 27603
total_duration: 2369.929371550368
[2023-06-29 12:01:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2274
train_sample_count: 2274
avg_envstep_per_episode: 324.85714285714283
avg_sample_per_episode: 324.85714285714283
avg_envstep_per_sec: 2497.8523318915154
avg_train_sample_per_sec: 2497.8523318915154
avg_episode_per_sec: 7.689079297819089
collect_time: 0.9103820794234054
reward_mean: 2486.503278968935
reward_std: 724.752099811658
reward_max: 3535.283749209975
reward_min: 1357.91203631521
total_envstep_count: 11158058
total_train_sample_count: 8390728
total_episode_count: 27610
total_duration: 2370.8397536297916
[2023-06-29 12:01:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1077
train_sample_count: 1077
avg_envstep_per_episode: 179.5
avg_sample_per_episode: 179.5
avg_envstep_per_sec: 2701.22264555633
avg_train_sample_per_sec: 2701.22264555633
avg_episode_per_sec: 15.048594125662007
collect_time: 0.3987083411179483
reward_mean: 1835.4065128481514
reward_std: 1003.5031855453173
reward_max: 3473.89297767403
reward_min: 704.9636441699806
total_envstep_count: 11162394
total_train_sample_count: 8394205
total_episode_count: 27616
total_duration: 2371.2384619709096
[2023-06-29 12:01:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2086
train_sample_count: 2086
avg_envstep_per_episode: 231.77777777777777
avg_sample_per_episode: 231.77777777777777
avg_envstep_per_sec: 2671.868304218631
avg_train_sample_per_sec: 2671.868304218631
avg_episode_per_sec: 11.527715598258714
collect_time: 0.7807271027192473
reward_mean: 2197.7352442559795
reward_std: 919.1532140603547
reward_max: 3269.688383030398
reward_min: 979.9149653019207
total_envstep_count: 11166674
total_train_sample_count: 8397491
total_episode_count: 27625
total_duration: 2372.0191890736287
[2023-06-29 12:01:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 210.83333333333334
avg_sample_per_episode: 210.83333333333334
avg_envstep_per_sec: 2601.946711159754
avg_train_sample_per_sec: 2601.946711159754
avg_episode_per_sec: 12.341249222892115
collect_time: 0.4861744456849991
reward_mean: 1975.2699009183718
reward_std: 788.5814440705622
reward_max: 3509.295331914141
reward_min: 1060.4251237279539
total_envstep_count: 11170690
total_train_sample_count: 8400756
total_episode_count: 27631
total_duration: 2372.5053635193135
[2023-06-29 12:02:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2638
train_sample_count: 2638
avg_envstep_per_episode: 293.1111111111111
avg_sample_per_episode: 293.1111111111111
avg_envstep_per_sec: 2665.0620998915438
avg_train_sample_per_sec: 2665.0620998915438
avg_episode_per_sec: 9.09232710349655
collect_time: 0.9898456025123598
reward_mean: 2213.4336570755986
reward_std: 1034.7665557380076
reward_max: 3532.5170763728042
reward_min: 710.1513558429372
total_envstep_count: 11174810
total_train_sample_count: 8404194
total_episode_count: 27640
total_duration: 2373.495209121826
[2023-06-29 12:02:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 780
train_sample_count: 780
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 2748.6816052476147
avg_train_sample_per_sec: 2748.6816052476147
avg_episode_per_sec: 10.57185232787544
collect_time: 0.2837724087471142
reward_mean: 2236.2722953073267
reward_std: 1053.618121688227
reward_max: 3490.2663119225695
reward_min: 912.2882180776064
total_envstep_count: 11180306
total_train_sample_count: 8407774
total_episode_count: 27643
total_duration: 2373.778981530573
[2023-06-29 12:02:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2132
train_sample_count: 2132
avg_envstep_per_episode: 213.2
avg_sample_per_episode: 213.2
avg_envstep_per_sec: 2770.346493079173
avg_train_sample_per_sec: 2770.346493079173
avg_episode_per_sec: 12.994120511628392
collect_time: 0.7695788253657518
reward_mean: 2455.8512868937573
reward_std: 1208.1169233459832
reward_max: 3559.5583588445857
reward_min: 340.14794371402445
total_envstep_count: 11184922
total_train_sample_count: 8411106
total_episode_count: 27653
total_duration: 2374.548560355939
[2023-06-29 12:02:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1333
train_sample_count: 1333
avg_envstep_per_episode: 222.16666666666666
avg_sample_per_episode: 222.16666666666666
avg_envstep_per_sec: 2769.175494141001
avg_train_sample_per_sec: 2769.175494141001
avg_episode_per_sec: 12.464405825090775
collect_time: 0.4813707194868475
reward_mean: 2502.1770646149766
reward_std: 808.2132345839574
reward_max: 3573.277050115543
reward_min: 1328.3297230149096
total_envstep_count: 11188906
total_train_sample_count: 8414439
total_episode_count: 27659
total_duration: 2375.029931075426
[2023-06-29 12:02:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3436
train_sample_count: 3436
avg_envstep_per_episode: 245.42857142857142
avg_sample_per_episode: 245.42857142857142
avg_envstep_per_sec: 2645.0859633744208
avg_train_sample_per_sec: 2645.0859633744208
avg_episode_per_sec: 10.777416614447581
collect_time: 1.299012602076866
reward_mean: 1556.0663724624285
reward_std: 779.3138397963346
reward_max: 3314.0118225793913
reward_min: 791.7863058002681
total_envstep_count: 11193042
total_train_sample_count: 8417875
total_episode_count: 27673
total_duration: 2376.3289436775026
[2023-06-29 12:02:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 855
train_sample_count: 855
avg_envstep_per_episode: 285.0
avg_sample_per_episode: 285.0
avg_envstep_per_sec: 2769.659024056377
avg_train_sample_per_sec: 2769.659024056377
avg_episode_per_sec: 9.718101838794304
collect_time: 0.30870225994382056
reward_mean: 1275.529705134263
reward_std: 644.3709402402415
reward_max: 1993.175167932914
reward_min: 430.3330381334072
total_envstep_count: 11197482
total_train_sample_count: 8421130
total_episode_count: 27676
total_duration: 2376.6376459374465
[2023-06-29 12:02:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2261
train_sample_count: 2261
avg_envstep_per_episode: 282.625
avg_sample_per_episode: 282.625
avg_envstep_per_sec: 2782.585019728528
avg_train_sample_per_sec: 2782.585019728528
avg_episode_per_sec: 9.845502060074402
collect_time: 0.812553788642399
reward_mean: 2594.820444302029
reward_std: 1006.6208509130489
reward_max: 3497.169438945314
reward_min: 845.5728815116319
total_envstep_count: 11202410
total_train_sample_count: 8424591
total_episode_count: 27684
total_duration: 2377.450199726089
[2023-06-29 12:02:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1316
train_sample_count: 1316
avg_envstep_per_episode: 263.2
avg_sample_per_episode: 263.2
avg_envstep_per_sec: 2510.443861342355
avg_train_sample_per_sec: 2510.443861342355
avg_episode_per_sec: 9.538160567410165
collect_time: 0.5242100890064612
reward_mean: 2515.652020359298
reward_std: 1281.697208829755
reward_max: 3592.037093031126
reward_min: 722.7689418974522
total_envstep_count: 11207426
total_train_sample_count: 8427907
total_episode_count: 27689
total_duration: 2377.9744098150954
[2023-06-29 12:02:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1168
train_sample_count: 1168
avg_envstep_per_episode: 166.85714285714286
avg_sample_per_episode: 166.85714285714286
avg_envstep_per_sec: 2712.634652640306
avg_train_sample_per_sec: 2712.634652640306
avg_episode_per_sec: 16.257228226440187
collect_time: 0.4305777038065717
reward_mean: 2599.2691819959828
reward_std: 1048.264671920595
reward_max: 3522.8311673095195
reward_min: 995.5323786844539
total_envstep_count: 11212242
total_train_sample_count: 8431475
total_episode_count: 27696
total_duration: 2378.404987518902
[2023-06-29 12:02:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2410
train_sample_count: 2410
avg_envstep_per_episode: 344.2857142857143
avg_sample_per_episode: 344.2857142857143
avg_envstep_per_sec: 2576.065097025986
avg_train_sample_per_sec: 2576.065097025986
avg_episode_per_sec: 7.482346754847261
collect_time: 0.9355353646855802
reward_mean: 3052.550679649095
reward_std: 737.5879629038135
reward_max: 3525.097706781249
reward_min: 1336.3399931258264
total_envstep_count: 11216714
total_train_sample_count: 8434685
total_episode_count: 27703
total_duration: 2379.3405228835877
[2023-06-29 12:02:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1389
train_sample_count: 1389
avg_envstep_per_episode: 277.8
avg_sample_per_episode: 277.8
avg_envstep_per_sec: 2794.408866330401
avg_train_sample_per_sec: 2794.408866330401
avg_episode_per_sec: 10.05906719341397
collect_time: 0.49706398256029927
reward_mean: 2183.70028257106
reward_std: 1002.8741094886384
reward_max: 3513.7455005620814
reward_min: 1100.3441061220221
total_envstep_count: 11220754
total_train_sample_count: 8438074
total_episode_count: 27708
total_duration: 2379.837586866148
[2023-06-29 12:02:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2046
train_sample_count: 2046
avg_envstep_per_episode: 341.0
avg_sample_per_episode: 341.0
avg_envstep_per_sec: 2753.402913906832
avg_train_sample_per_sec: 2753.402913906832
avg_episode_per_sec: 8.074495348700387
collect_time: 0.7430804949272424
reward_mean: 2840.9546783969777
reward_std: 848.3004281330726
reward_max: 3515.189388802921
reward_min: 1391.608311482864
total_envstep_count: 11224858
total_train_sample_count: 8441320
total_episode_count: 27714
total_duration: 2380.580667361075
[2023-06-29 12:02:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 350.57142857142856
avg_sample_per_episode: 350.57142857142856
avg_envstep_per_sec: 2515.1794952189666
avg_train_sample_per_sec: 2515.1794952189666
avg_episode_per_sec: 7.174513637543915
collect_time: 0.9756758929789062
reward_mean: 2552.352044528314
reward_std: 1060.7564145973024
reward_max: 3553.289534703981
reward_min: 780.1983755118915
total_envstep_count: 11229658
total_train_sample_count: 8444574
total_episode_count: 27721
total_duration: 2381.556343254054
[2023-06-29 12:02:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2166
train_sample_count: 2166
avg_envstep_per_episode: 361.0
avg_sample_per_episode: 361.0
avg_envstep_per_sec: 2722.2685822693948
avg_train_sample_per_sec: 2722.2685822693948
avg_episode_per_sec: 7.540910200192229
collect_time: 0.7956599191231651
reward_mean: 2401.730400673743
reward_std: 709.1295765812787
reward_max: 3585.008522341742
reward_min: 1329.427027740265
total_envstep_count: 11234010
total_train_sample_count: 8447940
total_episode_count: 27727
total_duration: 2382.352003173177
[2023-06-29 12:02:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2249
train_sample_count: 2249
avg_envstep_per_episode: 281.125
avg_sample_per_episode: 281.125
avg_envstep_per_sec: 2742.6013419425894
avg_train_sample_per_sec: 2742.6013419425894
avg_episode_per_sec: 9.755807352396939
collect_time: 0.8200243927566335
reward_mean: 2179.9599961962267
reward_std: 1027.6998706997886
reward_max: 3503.5907410782197
reward_min: 979.3754971455695
total_envstep_count: 11238330
total_train_sample_count: 8451389
total_episode_count: 27735
total_duration: 2383.1720275659336
[2023-06-29 12:02:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3137
train_sample_count: 3137
avg_envstep_per_episode: 285.1818181818182
avg_sample_per_episode: 285.1818181818182
avg_envstep_per_sec: 2663.9684303994422
avg_train_sample_per_sec: 2663.9684303994422
avg_episode_per_sec: 9.341298289574073
collect_time: 1.1775665072463453
reward_mean: 1771.4153354336993
reward_std: 764.2313244385375
reward_max: 2814.83861682868
reward_min: 796.5657541190344
total_envstep_count: 11242938
total_train_sample_count: 8454926
total_episode_count: 27746
total_duration: 2384.34959407318
[2023-06-29 12:02:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2226
train_sample_count: 2226
avg_envstep_per_episode: 247.33333333333334
avg_sample_per_episode: 247.33333333333334
avg_envstep_per_sec: 2601.7453867284444
avg_train_sample_per_sec: 2601.7453867284444
avg_episode_per_sec: 10.519186199710692
collect_time: 0.8555794934257867
reward_mean: 1470.0110960925679
reward_std: 852.8957086602085
reward_max: 3406.7471090648482
reward_min: 592.8065237521167
total_envstep_count: 11247162
total_train_sample_count: 8458352
total_episode_count: 27755
total_duration: 2385.205173566606
[2023-06-29 12:02:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2296
train_sample_count: 2296
avg_envstep_per_episode: 255.11111111111111
avg_sample_per_episode: 255.11111111111111
avg_envstep_per_sec: 2536.764011946052
avg_train_sample_per_sec: 2536.764011946052
avg_episode_per_sec: 9.943761370868671
collect_time: 0.9050901026614011
reward_mean: 1658.9602038947305
reward_std: 826.955409949797
reward_max: 2655.247547708067
reward_min: 640.7405840073963
total_envstep_count: 11251442
total_train_sample_count: 8461848
total_episode_count: 27764
total_duration: 2386.110263669267
[2023-06-29 12:02:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2082
train_sample_count: 2082
avg_envstep_per_episode: 231.33333333333334
avg_sample_per_episode: 231.33333333333334
avg_envstep_per_sec: 2505.6414042333818
avg_train_sample_per_sec: 2505.6414042333818
avg_episode_per_sec: 10.831302900144301
collect_time: 0.8309249665504319
reward_mean: 1680.434995081274
reward_std: 670.1790617294129
reward_max: 2893.703953400283
reward_min: 759.2730451663753
total_envstep_count: 11255826
total_train_sample_count: 8465130
total_episode_count: 27773
total_duration: 2386.9411886358175
[2023-06-29 12:02:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2423
train_sample_count: 2423
avg_envstep_per_episode: 242.3
avg_sample_per_episode: 242.3
avg_envstep_per_sec: 2727.783005450518
avg_train_sample_per_sec: 2727.783005450518
avg_episode_per_sec: 11.257874558194462
collect_time: 0.8882671367768198
reward_mean: 1705.7703431590987
reward_std: 892.740779994732
reward_max: 3158.046939565583
reward_min: 654.4906305439047
total_envstep_count: 11260722
total_train_sample_count: 8468353
total_episode_count: 27783
total_duration: 2387.8294557725944
[2023-06-29 12:03:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2516
train_sample_count: 2516
avg_envstep_per_episode: 251.6
avg_sample_per_episode: 251.6
avg_envstep_per_sec: 2679.1337454339964
avg_train_sample_per_sec: 2679.1337454339964
avg_episode_per_sec: 10.648385315715407
collect_time: 0.9391095178760588
reward_mean: 1817.478826694267
reward_std: 630.1601175756313
reward_max: 2810.320784019895
reward_min: 902.850843895658
total_envstep_count: 11265210
total_train_sample_count: 8471669
total_episode_count: 27793
total_duration: 2388.7685652904706
[2023-06-29 12:03:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2959
train_sample_count: 2959
avg_envstep_per_episode: 246.58333333333334
avg_sample_per_episode: 246.58333333333334
avg_envstep_per_sec: 2552.3032231028938
avg_train_sample_per_sec: 2552.3032231028938
avg_episode_per_sec: 10.350672077470337
collect_time: 1.1593450077623126
reward_mean: 1497.95866792177
reward_std: 619.2997261966873
reward_max: 2726.7924398137893
reward_min: 884.7337457192107
total_envstep_count: 11269698
total_train_sample_count: 8475028
total_episode_count: 27805
total_duration: 2389.9279102982327
[2023-06-29 12:03:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1583
train_sample_count: 1583
avg_envstep_per_episode: 226.14285714285714
avg_sample_per_episode: 226.14285714285714
avg_envstep_per_sec: 2767.086070433517
avg_train_sample_per_sec: 2767.086070433517
avg_episode_per_sec: 12.236009155423005
collect_time: 0.5720819518100472
reward_mean: 1319.3126797890563
reward_std: 479.2358947344309
reward_max: 2389.412154624834
reward_min: 800.7775573252279
total_envstep_count: 11273850
total_train_sample_count: 8478611
total_episode_count: 27812
total_duration: 2390.499992250043
[2023-06-29 12:03:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2538
train_sample_count: 2538
avg_envstep_per_episode: 282.0
avg_sample_per_episode: 282.0
avg_envstep_per_sec: 2567.182931786763
avg_train_sample_per_sec: 2567.182931786763
avg_episode_per_sec: 9.103485573711927
collect_time: 0.9886323130987584
reward_mean: 2241.1572238958634
reward_std: 874.9309044902643
reward_max: 3559.3990689617845
reward_min: 1035.1952573353778
total_envstep_count: 11278650
total_train_sample_count: 8481949
total_episode_count: 27821
total_duration: 2391.4886245631415
[2023-06-29 12:03:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2113
train_sample_count: 2113
avg_envstep_per_episode: 234.77777777777777
avg_sample_per_episode: 234.77777777777777
avg_envstep_per_sec: 2785.0197079184113
avg_train_sample_per_sec: 2785.0197079184113
avg_episode_per_sec: 11.862365059756602
collect_time: 0.7587019919436425
reward_mean: 1788.0789433533355
reward_std: 821.7286303432523
reward_max: 3229.87272174821
reward_min: 860.9901285183669
total_envstep_count: 11283666
total_train_sample_count: 8485262
total_episode_count: 27830
total_duration: 2392.2473265550852
[2023-06-29 12:03:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1335
train_sample_count: 1335
avg_envstep_per_episode: 148.33333333333334
avg_sample_per_episode: 148.33333333333334
avg_envstep_per_sec: 2804.7537387411435
avg_train_sample_per_sec: 2804.7537387411435
avg_episode_per_sec: 18.908452171288605
collect_time: 0.47597761670127503
reward_mean: 1451.2915000543578
reward_std: 515.3879197452602
reward_max: 2112.636082742537
reward_min: 711.7445082397379
total_envstep_count: 11287498
total_train_sample_count: 8488597
total_episode_count: 27839
total_duration: 2392.7233041717864
[2023-06-29 12:03:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2431
train_sample_count: 2431
avg_envstep_per_episode: 202.58333333333334
avg_sample_per_episode: 202.58333333333334
avg_envstep_per_sec: 2614.6850428083817
avg_train_sample_per_sec: 2614.6850428083817
avg_episode_per_sec: 12.906713498025743
collect_time: 0.9297486925572155
reward_mean: 1687.3623659728944
reward_std: 826.6413149110127
reward_max: 3364.059186857181
reward_min: 962.7530322454528
total_envstep_count: 11291794
total_train_sample_count: 8491828
total_episode_count: 27851
total_duration: 2393.6530528643434
[2023-06-29 12:03:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 244.7
avg_sample_per_episode: 244.7
avg_envstep_per_sec: 2716.177193126711
avg_train_sample_per_sec: 2716.177193126711
avg_episode_per_sec: 11.10002939569559
collect_time: 0.900898515086621
reward_mean: 1547.3598464757517
reward_std: 497.9626355678608
reward_max: 2520.729141575685
reward_min: 972.1835319284415
total_envstep_count: 11296106
total_train_sample_count: 8495075
total_episode_count: 27861
total_duration: 2394.55395137943
[2023-06-29 12:03:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3440
train_sample_count: 3440
avg_envstep_per_episode: 245.71428571428572
avg_sample_per_episode: 245.71428571428572
avg_envstep_per_sec: 2744.3910817985557
avg_train_sample_per_sec: 2744.3910817985557
avg_episode_per_sec: 11.169033472435983
collect_time: 1.25346566778142
reward_mean: 1377.4558941721186
reward_std: 634.1535656187748
reward_max: 3196.2797499581307
reward_min: 531.2018855628959
total_envstep_count: 11300674
total_train_sample_count: 8498515
total_episode_count: 27875
total_duration: 2395.8074170472114
[2023-06-29 12:03:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 247.9
avg_sample_per_episode: 247.9
avg_envstep_per_sec: 2674.9629646982085
avg_train_sample_per_sec: 2674.9629646982085
avg_episode_per_sec: 10.790491991521614
collect_time: 0.9267418026775122
reward_mean: 1309.3151417597867
reward_std: 393.5426161600765
reward_max: 1937.3663426771338
reward_min: 785.2170227535505
total_envstep_count: 11305026
total_train_sample_count: 8501794
total_episode_count: 27885
total_duration: 2396.734158849889
[2023-06-29 12:03:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2835
train_sample_count: 2835
avg_envstep_per_episode: 236.25
avg_sample_per_episode: 236.25
avg_envstep_per_sec: 2622.461068110834
avg_train_sample_per_sec: 2622.461068110834
avg_episode_per_sec: 11.100364309463847
collect_time: 1.0810456004375595
reward_mean: 1419.5643381156135
reward_std: 960.36821454689
reward_max: 2828.9555747551094
reward_min: 77.56808946812615
total_envstep_count: 11309370
total_train_sample_count: 8505029
total_episode_count: 27897
total_duration: 2397.8152044503263
[2023-06-29 12:03:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3031
train_sample_count: 3031
avg_envstep_per_episode: 233.15384615384616
avg_sample_per_episode: 233.15384615384616
avg_envstep_per_sec: 2552.214453127985
avg_train_sample_per_sec: 2552.214453127985
avg_episode_per_sec: 10.946482312987069
collect_time: 1.1875961270751434
reward_mean: 1258.1399316195436
reward_std: 346.6518677963614
reward_max: 2056.858440369562
reward_min: 713.2970552159081
total_envstep_count: 11313522
total_train_sample_count: 8508460
total_episode_count: 27910
total_duration: 2399.0028005774016
[2023-06-29 12:03:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2026
train_sample_count: 2026
avg_envstep_per_episode: 253.25
avg_sample_per_episode: 253.25
avg_envstep_per_sec: 2696.423338326883
avg_train_sample_per_sec: 2696.423338326883
avg_episode_per_sec: 10.647278729819872
collect_time: 0.7513656966257839
reward_mean: 1354.8763947371758
reward_std: 711.1763200392098
reward_max: 2594.3901559577666
reward_min: 84.09224436596149
total_envstep_count: 11317810
total_train_sample_count: 8511686
total_episode_count: 27918
total_duration: 2399.7541662740273
[2023-06-29 12:03:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2582
train_sample_count: 2582
avg_envstep_per_episode: 234.72727272727272
avg_sample_per_episode: 234.72727272727272
avg_envstep_per_sec: 2729.160937017465
avg_train_sample_per_sec: 2729.160937017465
avg_episode_per_sec: 11.626944348254112
collect_time: 0.9460783220874147
reward_mean: 1652.0243933251506
reward_std: 529.1770766349435
reward_max: 2561.6666790844056
reward_min: 898.2833896412054
total_envstep_count: 11321914
total_train_sample_count: 8515068
total_episode_count: 27929
total_duration: 2400.7002445961148
[2023-06-29 12:03:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1801
train_sample_count: 1801
avg_envstep_per_episode: 225.125
avg_sample_per_episode: 225.125
avg_envstep_per_sec: 2658.8285358269327
avg_train_sample_per_sec: 2658.8285358269327
avg_episode_per_sec: 11.810454351257892
collect_time: 0.677365981195122
reward_mean: 1220.1650227518753
reward_std: 353.4963610293114
reward_max: 1889.4793263916135
reward_min: 829.3307796799827
total_envstep_count: 11326130
total_train_sample_count: 8518469
total_episode_count: 27937
total_duration: 2401.37761057731
[2023-06-29 12:03:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2478
train_sample_count: 2478
avg_envstep_per_episode: 247.8
avg_sample_per_episode: 247.8
avg_envstep_per_sec: 2532.2650522160525
avg_train_sample_per_sec: 2532.2650522160525
avg_episode_per_sec: 10.2189872970785
collect_time: 0.9785705480678005
reward_mean: 1994.8903728462676
reward_std: 1055.4100532555256
reward_max: 3547.603182382509
reward_min: 661.2475346922201
total_envstep_count: 11330586
total_train_sample_count: 8521747
total_episode_count: 27947
total_duration: 2402.3561811253776
[2023-06-29 12:03:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2979
train_sample_count: 2979
avg_envstep_per_episode: 372.375
avg_sample_per_episode: 372.375
avg_envstep_per_sec: 2812.4369861073224
avg_train_sample_per_sec: 2812.4369861073224
avg_episode_per_sec: 7.552700869036112
collect_time: 1.0592237318437547
reward_mean: 2263.9580341861447
reward_std: 842.1919343668458
reward_max: 3498.9179669039204
reward_min: 1214.928941469082
total_envstep_count: 11335418
total_train_sample_count: 8525126
total_episode_count: 27955
total_duration: 2403.4154048572213
[2023-06-29 12:03:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2975
train_sample_count: 2975
avg_envstep_per_episode: 297.5
avg_sample_per_episode: 297.5
avg_envstep_per_sec: 2760.188523576282
avg_train_sample_per_sec: 2760.188523576282
avg_episode_per_sec: 9.277944617063133
collect_time: 1.0778249291991817
reward_mean: 1772.3638301690978
reward_std: 668.2970034051293
reward_max: 2880.752007219187
reward_min: 440.4315849753544
total_envstep_count: 11340194
total_train_sample_count: 8528501
total_episode_count: 27965
total_duration: 2404.4932297864207
[2023-06-29 12:03:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1214
train_sample_count: 1214
avg_envstep_per_episode: 303.5
avg_sample_per_episode: 303.5
avg_envstep_per_sec: 2538.645906621351
avg_train_sample_per_sec: 2538.645906621351
avg_episode_per_sec: 8.3645664139089
collect_time: 0.47820769207458946
reward_mean: 1883.4402978317905
reward_std: 309.0228461035086
reward_max: 2146.2916860783635
reward_min: 1360.8975006140272
total_envstep_count: 11344714
total_train_sample_count: 8531715
total_episode_count: 27969
total_duration: 2404.9714374784953
[2023-06-29 12:03:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2858
train_sample_count: 2858
avg_envstep_per_episode: 317.55555555555554
avg_sample_per_episode: 317.55555555555554
avg_envstep_per_sec: 2684.5085123574854
avg_train_sample_per_sec: 2684.5085123574854
avg_episode_per_sec: 8.453665714211814
collect_time: 1.064626909113489
reward_mean: 2794.6054973527002
reward_std: 862.3909549018722
reward_max: 3563.845604168064
reward_min: 1282.1467509115917
total_envstep_count: 11349082
total_train_sample_count: 8534973
total_episode_count: 27978
total_duration: 2406.036064387609
[2023-06-29 12:04:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1261
train_sample_count: 1261
avg_envstep_per_episode: 315.25
avg_sample_per_episode: 315.25
avg_envstep_per_sec: 2702.2331530595243
avg_train_sample_per_sec: 2702.2331530595243
avg_episode_per_sec: 8.571714997809751
collect_time: 0.466651072862558
reward_mean: 2014.86791830539
reward_std: 867.2504034733126
reward_max: 3505.6221766007725
reward_min: 1345.0643300892878
total_envstep_count: 11353594
total_train_sample_count: 8538234
total_episode_count: 27982
total_duration: 2406.5027154604713
[2023-06-29 12:04:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1390
train_sample_count: 1390
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2718.4781414278496
avg_train_sample_per_sec: 2718.4781414278496
avg_episode_per_sec: 9.77869835045989
collect_time: 0.5113154962761328
reward_mean: 3296.7145424204236
reward_std: 461.66972283328585
reward_max: 3687.567546412943
reward_min: 2416.9015088342962
total_envstep_count: 11357674
total_train_sample_count: 8541624
total_episode_count: 27987
total_duration: 2407.0140309567473
[2023-06-29 12:04:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2415
train_sample_count: 2415
avg_envstep_per_episode: 301.875
avg_sample_per_episode: 301.875
avg_envstep_per_sec: 2505.8582065043765
avg_train_sample_per_sec: 2505.8582065043765
avg_episode_per_sec: 8.300979566060047
collect_time: 0.9637416808865966
reward_mean: 2452.910792865202
reward_std: 1132.3334883393045
reward_max: 3543.2819075581174
reward_min: 1017.4801856794666
total_envstep_count: 11362298
total_train_sample_count: 8544839
total_episode_count: 27995
total_duration: 2407.9777726376337
[2023-06-29 12:04:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2931
train_sample_count: 2931
avg_envstep_per_episode: 266.45454545454544
avg_sample_per_episode: 266.45454545454544
avg_envstep_per_sec: 2638.1915597100506
avg_train_sample_per_sec: 2638.1915597100506
avg_episode_per_sec: 9.901094219314418
collect_time: 1.1109883166793735
reward_mean: 1682.7802425254733
reward_std: 729.1224706078013
reward_max: 3535.158519977182
reward_min: 416.3584325956425
total_envstep_count: 11367034
total_train_sample_count: 8548170
total_episode_count: 28006
total_duration: 2409.0887609543133
[2023-06-29 12:04:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1304
train_sample_count: 1304
avg_envstep_per_episode: 217.33333333333334
avg_sample_per_episode: 217.33333333333334
avg_envstep_per_sec: 2721.229072792475
avg_train_sample_per_sec: 2721.229072792475
avg_episode_per_sec: 12.520992666223044
collect_time: 0.4791952331531793
reward_mean: 1875.684584861253
reward_std: 831.6935323404155
reward_max: 3493.8358817049875
reward_min: 823.2638998594095
total_envstep_count: 11370890
total_train_sample_count: 8551474
total_episode_count: 28012
total_duration: 2409.5679561874667
[2023-06-29 12:04:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 308.7142857142857
avg_sample_per_episode: 308.7142857142857
avg_envstep_per_sec: 2768.740510370124
avg_train_sample_per_sec: 2768.740510370124
avg_episode_per_sec: 8.96861803451683
collect_time: 0.7804992890832946
reward_mean: 2441.5740957360185
reward_std: 774.9958146593355
reward_max: 3516.6305488635217
reward_min: 1306.0876577478382
total_envstep_count: 11375410
total_train_sample_count: 8554835
total_episode_count: 28019
total_duration: 2410.34845547655
[2023-06-29 12:04:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2095
train_sample_count: 2095
avg_envstep_per_episode: 261.875
avg_sample_per_episode: 261.875
avg_envstep_per_sec: 2755.9484214935164
avg_train_sample_per_sec: 2755.9484214935164
avg_episode_per_sec: 10.523908053435862
collect_time: 0.7601738783139736
reward_mean: 2014.531778515284
reward_std: 793.0559612016474
reward_max: 3561.288855499172
reward_min: 1280.550571530942
total_envstep_count: 11380450
total_train_sample_count: 8558130
total_episode_count: 28027
total_duration: 2411.108629354864
[2023-06-29 12:04:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 229.25
avg_sample_per_episode: 229.25
avg_envstep_per_sec: 2607.4604320769486
avg_train_sample_per_sec: 2607.4604320769486
avg_episode_per_sec: 11.373873204261498
collect_time: 0.3516831890214235
reward_mean: 2240.1495387243162
reward_std: 968.9393512184654
reward_max: 3551.156844964526
reward_min: 1076.3440371650859
total_envstep_count: 11384290
total_train_sample_count: 8561447
total_episode_count: 28031
total_duration: 2411.4603125438857
[2023-06-29 12:04:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1311
train_sample_count: 1311
avg_envstep_per_episode: 218.5
avg_sample_per_episode: 218.5
avg_envstep_per_sec: 2760.9248216233486
avg_train_sample_per_sec: 2760.9248216233486
avg_episode_per_sec: 12.635811540610291
collect_time: 0.47484089017286885
reward_mean: 3146.9158360356664
reward_std: 796.8838640811447
reward_max: 3578.0330073835335
reward_min: 1368.6976986375266
total_envstep_count: 11388610
total_train_sample_count: 8564758
total_episode_count: 28037
total_duration: 2411.9351534340585
[2023-06-29 12:04:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 306.75
avg_sample_per_episode: 306.75
avg_envstep_per_sec: 2790.0580628065554
avg_train_sample_per_sec: 2790.0580628065554
avg_episode_per_sec: 9.095543807030335
collect_time: 0.43977579404413714
reward_mean: 3462.8664947098846
reward_std: 123.16363759778237
reward_max: 3579.323075203378
reward_min: 3261.5549119739662
total_envstep_count: 11392290
total_train_sample_count: 8567985
total_episode_count: 28041
total_duration: 2412.3749292281027
[2023-06-29 12:04:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1742
train_sample_count: 1742
avg_envstep_per_episode: 248.85714285714286
avg_sample_per_episode: 248.85714285714286
avg_envstep_per_sec: 2761.8988074846607
avg_train_sample_per_sec: 2761.8988074846607
avg_episode_per_sec: 11.098330454875214
collect_time: 0.6307254977189004
reward_mean: 2540.226542805096
reward_std: 984.272665624919
reward_max: 3555.8013840034737
reward_min: 994.5011282380383
total_envstep_count: 11397090
total_train_sample_count: 8571327
total_episode_count: 28048
total_duration: 2413.0056547258214
[2023-06-29 12:04:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 265.6
avg_sample_per_episode: 265.6
avg_envstep_per_sec: 2579.8477619601326
avg_train_sample_per_sec: 2579.8477619601326
avg_episode_per_sec: 9.713282236295681
collect_time: 0.5147590565541759
reward_mean: 2450.116552205126
reward_std: 940.5517661551404
reward_max: 3660.827840452223
reward_min: 1341.9273982528096
total_envstep_count: 11401410
total_train_sample_count: 8574655
total_episode_count: 28053
total_duration: 2413.5204137823757
[2023-06-29 12:04:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1732
train_sample_count: 1732
avg_envstep_per_episode: 247.42857142857142
avg_sample_per_episode: 247.42857142857142
avg_envstep_per_sec: 2751.611377766171
avg_train_sample_per_sec: 2751.611377766171
avg_episode_per_sec: 11.120831203442954
collect_time: 0.6294493524758145
reward_mean: 2894.0205177215075
reward_std: 877.7529143675467
reward_max: 3563.908337449343
reward_min: 1503.7113297253036
total_envstep_count: 11405770
total_train_sample_count: 8577987
total_episode_count: 28060
total_duration: 2414.1498631348513
[2023-06-29 12:04:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2056
train_sample_count: 2056
avg_envstep_per_episode: 293.7142857142857
avg_sample_per_episode: 293.7142857142857
avg_envstep_per_sec: 2753.6811528240405
avg_train_sample_per_sec: 2753.6811528240405
avg_episode_per_sec: 9.375373574790022
collect_time: 0.7466369146956129
reward_mean: 2453.5447063459255
reward_std: 955.6523530924972
reward_max: 3549.3016355972786
reward_min: 1021.1090449796436
total_envstep_count: 11410402
total_train_sample_count: 8581243
total_episode_count: 28067
total_duration: 2414.896500049547
[2023-06-29 12:04:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2150
train_sample_count: 2150
avg_envstep_per_episode: 307.14285714285717
avg_sample_per_episode: 307.14285714285717
avg_envstep_per_sec: 2798.6663445108516
avg_train_sample_per_sec: 2798.6663445108516
avg_episode_per_sec: 9.111936935616725
collect_time: 0.7682230517463757
reward_mean: 2271.739925425126
reward_std: 1042.4182700964557
reward_max: 3587.279447435485
reward_min: 967.3327166798025
total_envstep_count: 11414962
total_train_sample_count: 8584593
total_episode_count: 28074
total_duration: 2415.664723101293
[2023-06-29 12:04:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1524
train_sample_count: 1524
avg_envstep_per_episode: 304.8
avg_sample_per_episode: 304.8
avg_envstep_per_sec: 2783.0262452253764
avg_train_sample_per_sec: 2783.0262452253764
avg_episode_per_sec: 9.130663534203991
collect_time: 0.5476053280541674
reward_mean: 2898.242402071576
reward_std: 787.4225654527722
reward_max: 3628.9469496702604
reward_min: 1782.898533752086
total_envstep_count: 11420610
total_train_sample_count: 8588117
total_episode_count: 28079
total_duration: 2416.212328429347
[2023-06-29 12:04:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1108
train_sample_count: 1108
avg_envstep_per_episode: 221.6
avg_sample_per_episode: 221.6
avg_envstep_per_sec: 2338.584410036096
avg_train_sample_per_sec: 2338.584410036096
avg_episode_per_sec: 10.553178745650253
collect_time: 0.47379089471604663
reward_mean: 3068.139277444511
reward_std: 772.1586533547093
reward_max: 3507.887609415639
reward_min: 1526.8318596030892
total_envstep_count: 11425386
total_train_sample_count: 8591625
total_episode_count: 28084
total_duration: 2416.686119324063
[2023-06-29 12:04:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 157.71428571428572
avg_sample_per_episode: 157.71428571428572
avg_envstep_per_sec: 2224.1919291893846
avg_train_sample_per_sec: 2224.1919291893846
avg_episode_per_sec: 14.102666217686316
collect_time: 0.4963600422749295
reward_mean: 2559.440226203409
reward_std: 1229.8351360742322
reward_max: 3544.157608739852
reward_min: 47.653438017865064
total_envstep_count: 11429610
total_train_sample_count: 8595129
total_episode_count: 28091
total_duration: 2417.1824793663377
[2023-06-29 12:04:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1743
train_sample_count: 1743
avg_envstep_per_episode: 348.6
avg_sample_per_episode: 348.6
avg_envstep_per_sec: 2748.5492551078864
avg_train_sample_per_sec: 2748.5492551078864
avg_episode_per_sec: 7.884536015800018
collect_time: 0.6341527250278742
reward_mean: 3397.2561226492444
reward_std: 55.475968480176675
reward_max: 3478.9162453969143
reward_min: 3347.815262884789
total_envstep_count: 11434010
total_train_sample_count: 8598472
total_episode_count: 28096
total_duration: 2417.8166320913656
[2023-06-29 12:04:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 953
train_sample_count: 953
avg_envstep_per_episode: 238.25
avg_sample_per_episode: 238.25
avg_envstep_per_sec: 2741.304125785055
avg_train_sample_per_sec: 2741.304125785055
avg_episode_per_sec: 11.505998429318174
collect_time: 0.3476447545662522
reward_mean: 3195.010803301492
reward_std: 242.75138548677523
reward_max: 3436.352021088277
reward_min: 2914.295442975968
total_envstep_count: 11438162
total_train_sample_count: 8601825
total_episode_count: 28100
total_duration: 2418.164276845932
[2023-06-29 12:05:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1524
train_sample_count: 1524
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2701.998104329802
avg_train_sample_per_sec: 2701.998104329802
avg_episode_per_sec: 10.637787812322056
collect_time: 0.5640270426385106
reward_mean: 2751.816270479733
reward_std: 630.9985362234765
reward_max: 3436.4950173506836
reward_min: 1858.3403342745346
total_envstep_count: 11442266
total_train_sample_count: 8605349
total_episode_count: 28106
total_duration: 2418.7283038885703
[2023-06-29 12:05:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1128
train_sample_count: 1128
avg_envstep_per_episode: 282.0
avg_sample_per_episode: 282.0
avg_envstep_per_sec: 2789.018215451494
avg_train_sample_per_sec: 2789.018215451494
avg_episode_per_sec: 9.89013551578544
collect_time: 0.4044433965152129
reward_mean: 3017.016550084329
reward_std: 625.4775962841821
reward_max: 3447.0656585746387
reward_min: 1936.5826807280346
total_envstep_count: 11446730
total_train_sample_count: 8608877
total_episode_count: 28110
total_duration: 2419.1327472850853
[2023-06-29 12:05:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1716
train_sample_count: 1716
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2787.3809962745445
avg_train_sample_per_sec: 2787.3809962745445
avg_episode_per_sec: 9.746087399561343
collect_time: 0.6156316636633128
reward_mean: 3203.8953306724957
reward_std: 352.1826645018037
reward_max: 3570.516038535569
reward_min: 2546.687903455087
total_envstep_count: 11452178
total_train_sample_count: 8612193
total_episode_count: 28116
total_duration: 2419.7483789487487
[2023-06-29 12:05:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1306
train_sample_count: 1306
avg_envstep_per_episode: 326.5
avg_sample_per_episode: 326.5
avg_envstep_per_sec: 2758.2993887012663
avg_train_sample_per_sec: 2758.2993887012663
avg_episode_per_sec: 8.448083885761918
collect_time: 0.4734801469882951
reward_mean: 3358.428981490089
reward_std: 150.43072330565823
reward_max: 3477.2656187791295
reward_min: 3104.552302059475
total_envstep_count: 11456978
total_train_sample_count: 8615499
total_episode_count: 28120
total_duration: 2420.221859095737
[2023-06-29 12:05:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1118
train_sample_count: 1118
avg_envstep_per_episode: 186.33333333333334
avg_sample_per_episode: 186.33333333333334
avg_envstep_per_sec: 2750.3904567182212
avg_train_sample_per_sec: 2750.3904567182212
avg_episode_per_sec: 14.760592790974355
collect_time: 0.40648773968406027
reward_mean: 3166.9870844285874
reward_std: 483.5968357637774
reward_max: 3549.458724688472
reward_min: 2153.1581053882605
total_envstep_count: 11461154
total_train_sample_count: 8619017
total_episode_count: 28126
total_duration: 2420.628346835421
[2023-06-29 12:05:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 327.2
avg_sample_per_episode: 327.2
avg_envstep_per_sec: 2673.8114975622093
avg_train_sample_per_sec: 2673.8114975622093
avg_episode_per_sec: 8.17179553044685
collect_time: 0.6118606347125024
reward_mean: 3068.472728014591
reward_std: 502.9999755164947
reward_max: 3484.2360179635753
reward_min: 2093.974580033042
total_envstep_count: 11465290
total_train_sample_count: 8622253
total_episode_count: 28131
total_duration: 2421.2402074701336
[2023-06-29 12:05:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1499
train_sample_count: 1499
avg_envstep_per_episode: 299.8
avg_sample_per_episode: 299.8
avg_envstep_per_sec: 2423.9974669059015
avg_train_sample_per_sec: 2423.9974669059015
avg_episode_per_sec: 8.085381810893601
collect_time: 0.6183999861655757
reward_mean: 2872.950466213081
reward_std: 1135.2327287397848
reward_max: 3474.7358039895016
reward_min: 602.9067954578976
total_envstep_count: 11470162
total_train_sample_count: 8625752
total_episode_count: 28136
total_duration: 2421.858607456299
[2023-06-29 12:05:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1554
train_sample_count: 1554
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2776.498727552416
avg_train_sample_per_sec: 2776.498727552416
avg_episode_per_sec: 10.720072307152185
collect_time: 0.559697717336938
reward_mean: 2861.3609149026147
reward_std: 684.4665012701514
reward_max: 3477.2283033351964
reward_min: 1743.01807856653
total_envstep_count: 11475690
total_train_sample_count: 8629306
total_episode_count: 28142
total_duration: 2422.418305173636
[2023-06-29 12:05:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2096
train_sample_count: 2096
avg_envstep_per_episode: 232.88888888888889
avg_sample_per_episode: 232.88888888888889
avg_envstep_per_sec: 2805.8510342717836
avg_train_sample_per_sec: 2805.8510342717836
avg_episode_per_sec: 12.048024479220445
collect_time: 0.7470104344096034
reward_mean: 2322.6839097154434
reward_std: 990.5098111067489
reward_max: 3343.442672997786
reward_min: 427.7342824106741
total_envstep_count: 11480298
total_train_sample_count: 8632602
total_episode_count: 28151
total_duration: 2423.1653156080456
[2023-06-29 12:05:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2729.344215134674
avg_train_sample_per_sec: 2729.344215134674
avg_episode_per_sec: 12.51992759236089
collect_time: 0.3194906656201929
reward_mean: 2760.063937764013
reward_std: 641.0652946279482
reward_max: 3421.7043517567263
reward_min: 1821.0246838287003
total_envstep_count: 11483802
total_train_sample_count: 8635874
total_episode_count: 28155
total_duration: 2423.484806273666
[2023-06-29 12:05:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1823
train_sample_count: 1823
avg_envstep_per_episode: 303.8333333333333
avg_sample_per_episode: 303.8333333333333
avg_envstep_per_sec: 2535.3623518795
avg_train_sample_per_sec: 2535.3623518795
avg_episode_per_sec: 8.344582617266594
collect_time: 0.7190293721323835
reward_mean: 2405.012398722114
reward_std: 886.8523755974708
reward_max: 3383.6150815401757
reward_min: 1075.029356883739
total_envstep_count: 11488530
total_train_sample_count: 8639297
total_episode_count: 28161
total_duration: 2424.2038356457983
[2023-06-29 12:05:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1699
train_sample_count: 1699
avg_envstep_per_episode: 242.71428571428572
avg_sample_per_episode: 242.71428571428572
avg_envstep_per_sec: 2760.6640218947214
avg_train_sample_per_sec: 2760.6640218947214
avg_episode_per_sec: 11.374130755304915
collect_time: 0.6154316448960452
reward_mean: 2597.9048643373853
reward_std: 1070.951842737335
reward_max: 3370.9472350346477
reward_min: 272.8813192140397
total_envstep_count: 11492402
total_train_sample_count: 8642596
total_episode_count: 28168
total_duration: 2424.8192672906944
[2023-06-29 12:05:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 409
train_sample_count: 409
avg_envstep_per_episode: 204.5
avg_sample_per_episode: 204.5
avg_envstep_per_sec: 2730.0781530456165
avg_train_sample_per_sec: 2730.0781530456165
avg_episode_per_sec: 13.350015418315973
collect_time: 0.14981256105937055
reward_mean: 2419.800546132002
reward_std: 520.8027324602525
reward_max: 2940.603278592255
reward_min: 1898.9978136717498
total_envstep_count: 11495938
total_train_sample_count: 8645805
total_episode_count: 28170
total_duration: 2424.9690798517536
[2023-06-29 12:05:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1815
train_sample_count: 1815
avg_envstep_per_episode: 302.5
avg_sample_per_episode: 302.5
avg_envstep_per_sec: 2728.071460642732
avg_train_sample_per_sec: 2728.071460642732
avg_episode_per_sec: 9.01841805171151
collect_time: 0.6653051528101787
reward_mean: 2700.985796876718
reward_std: 927.9261394568032
reward_max: 3388.1906340639666
reward_min: 1196.415742048113
total_envstep_count: 11499802
total_train_sample_count: 8649220
total_episode_count: 28176
total_duration: 2425.6343850045637
[2023-06-29 12:05:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 175
train_sample_count: 175
avg_envstep_per_episode: 58.333333333333336
avg_sample_per_episode: 58.333333333333336
avg_envstep_per_sec: 2731.498200877249
avg_train_sample_per_sec: 2731.498200877249
avg_episode_per_sec: 46.82568344360998
collect_time: 0.06406740445364267
reward_mean: 3300.839227779841
reward_std: 80.74159385862461
reward_max: 3393.2925856487577
reward_min: 3196.5773015182785
total_envstep_count: 11503938
total_train_sample_count: 8652595
total_episode_count: 28179
total_duration: 2425.698452409017
[2023-06-29 12:05:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2222
train_sample_count: 2222
avg_envstep_per_episode: 370.3333333333333
avg_sample_per_episode: 370.3333333333333
avg_envstep_per_sec: 2494.2143138853235
avg_train_sample_per_sec: 2494.2143138853235
avg_episode_per_sec: 6.735052152705644
collect_time: 0.8908616984635591
reward_mean: 3368.144365773773
reward_std: 153.41309491034676
reward_max: 3480.4329042904546
reward_min: 3028.2216356651847
total_envstep_count: 11507802
total_train_sample_count: 8656017
total_episode_count: 28185
total_duration: 2426.5893141074807
[2023-06-29 12:05:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1808
train_sample_count: 1808
avg_envstep_per_episode: 301.3333333333333
avg_sample_per_episode: 301.3333333333333
avg_envstep_per_sec: 2738.6475061978376
avg_train_sample_per_sec: 2738.6475061978376
avg_episode_per_sec: 9.088431989594595
collect_time: 0.6601798865711312
reward_mean: 2190.8185676634753
reward_std: 864.0258274875217
reward_max: 3411.1394934996406
reward_min: 1269.9593164806079
total_envstep_count: 11511698
total_train_sample_count: 8659425
total_episode_count: 28191
total_duration: 2427.249493994052
[2023-06-29 12:05:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1414
train_sample_count: 1414
avg_envstep_per_episode: 282.8
avg_sample_per_episode: 282.8
avg_envstep_per_sec: 2558.8324495440756
avg_train_sample_per_sec: 2558.8324495440756
avg_episode_per_sec: 9.048205267128981
collect_time: 0.5525957747846842
reward_mean: 2758.733758637033
reward_std: 766.4732548736447
reward_max: 3407.624395723276
reward_min: 1667.764663962251
total_envstep_count: 11515370
total_train_sample_count: 8662839
total_episode_count: 28196
total_duration: 2427.8020897688366
[2023-06-29 12:05:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1629
train_sample_count: 1629
avg_envstep_per_episode: 407.25
avg_sample_per_episode: 407.25
avg_envstep_per_sec: 2741.3376665702153
avg_train_sample_per_sec: 2741.3376665702153
avg_episode_per_sec: 6.731338653333863
collect_time: 0.5942354420125484
reward_mean: 2609.979351990649
reward_std: 433.23749166657296
reward_max: 3068.525731349152
reward_min: 1900.5543211273093
total_envstep_count: 11519618
total_train_sample_count: 8666068
total_episode_count: 28200
total_duration: 2428.396325210849
[2023-06-29 12:05:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1603
train_sample_count: 1603
avg_envstep_per_episode: 267.1666666666667
avg_sample_per_episode: 267.1666666666667
avg_envstep_per_sec: 2842.3704120698344
avg_train_sample_per_sec: 2842.3704120698344
avg_episode_per_sec: 10.638941030829073
collect_time: 0.5639659043708818
reward_mean: 2904.647564392233
reward_std: 615.1570157392115
reward_max: 3351.241683177335
reward_min: 1839.9769031065807
total_envstep_count: 11523346
total_train_sample_count: 8669271
total_episode_count: 28206
total_duration: 2428.96029111522
[2023-06-29 12:06:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1298
train_sample_count: 1298
avg_envstep_per_episode: 432.6666666666667
avg_sample_per_episode: 432.6666666666667
avg_envstep_per_sec: 2814.8679867270575
avg_train_sample_per_sec: 2814.8679867270575
avg_episode_per_sec: 6.505858212774401
collect_time: 0.4611228683264925
reward_mean: 2608.38626851783
reward_std: 593.6502090290363
reward_max: 3380.4543485450226
reward_min: 1936.7580831288933
total_envstep_count: 11527618
total_train_sample_count: 8672569
total_episode_count: 28209
total_duration: 2429.4214139835467
[2023-06-29 12:06:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2052
train_sample_count: 2052
avg_envstep_per_episode: 256.5
avg_sample_per_episode: 256.5
avg_envstep_per_sec: 2556.9762378177866
avg_train_sample_per_sec: 2556.9762378177866
avg_episode_per_sec: 9.968718276092735
collect_time: 0.8025103908479215
reward_mean: 2630.9352595118316
reward_std: 1011.8957524045201
reward_max: 3403.8619952073495
reward_min: 723.4670344999485
total_envstep_count: 11531594
total_train_sample_count: 8675821
total_episode_count: 28217
total_duration: 2430.2239243743948
[2023-06-29 12:06:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1526
train_sample_count: 1526
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 2802.3165807628734
avg_train_sample_per_sec: 2802.3165807628734
avg_episode_per_sec: 11.01828275529308
collect_time: 0.5445494668502363
reward_mean: 1807.852293023987
reward_std: 1188.2690198480077
reward_max: 3395.3700692070734
reward_min: 166.9078811248662
total_envstep_count: 11535698
total_train_sample_count: 8679347
total_episode_count: 28223
total_duration: 2430.768473841245
[2023-06-29 12:06:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1200
train_sample_count: 1200
avg_envstep_per_episode: 400.0
avg_sample_per_episode: 400.0
avg_envstep_per_sec: 2756.1181395337444
avg_train_sample_per_sec: 2756.1181395337444
avg_episode_per_sec: 6.8902953488343615
collect_time: 0.4353949791872874
reward_mean: 3266.218102736782
reward_std: 230.5878624649816
reward_max: 3433.1856546733106
reward_min: 2940.1492470037147
total_envstep_count: 11539042
total_train_sample_count: 8682547
total_episode_count: 28226
total_duration: 2431.203868820432
[2023-06-29 12:06:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2702
train_sample_count: 2702
avg_envstep_per_episode: 300.22222222222223
avg_sample_per_episode: 300.22222222222223
avg_envstep_per_sec: 2804.0833657705207
avg_train_sample_per_sec: 2804.0833657705207
avg_episode_per_sec: 9.340026014779676
collect_time: 0.963594746498391
reward_mean: 2348.1927965814193
reward_std: 1173.3845017503024
reward_max: 3509.7592876634394
reward_min: 673.6560748653748
total_envstep_count: 11543434
total_train_sample_count: 8686049
total_episode_count: 28235
total_duration: 2432.1674635669306
[2023-06-29 12:06:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1830
train_sample_count: 1830
avg_envstep_per_episode: 228.75
avg_sample_per_episode: 228.75
avg_envstep_per_sec: 2451.5454348162366
avg_train_sample_per_sec: 2451.5454348162366
avg_episode_per_sec: 10.717138512857865
collect_time: 0.7464679112248122
reward_mean: 1413.042707865034
reward_std: 1058.8431236786887
reward_max: 3473.316907362979
reward_min: 176.78865132868003
total_envstep_count: 11548330
total_train_sample_count: 8689479
total_episode_count: 28243
total_duration: 2432.9139314781555
[2023-06-29 12:06:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2466
train_sample_count: 2466
avg_envstep_per_episode: 352.2857142857143
avg_sample_per_episode: 352.2857142857143
avg_envstep_per_sec: 2746.555597636754
avg_train_sample_per_sec: 2746.555597636754
avg_episode_per_sec: 7.796386530193544
collect_time: 0.8978518410921099
reward_mean: 2525.9360783613824
reward_std: 1147.4321904320063
reward_max: 3538.353455919092
reward_min: 657.4581918233538
total_envstep_count: 11553018
total_train_sample_count: 8692745
total_episode_count: 28250
total_duration: 2433.8117833192478
[2023-06-29 12:06:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 494
train_sample_count: 494
avg_envstep_per_episode: 164.66666666666666
avg_sample_per_episode: 164.66666666666666
avg_envstep_per_sec: 2716.442016849716
avg_train_sample_per_sec: 2716.442016849716
avg_episode_per_sec: 16.4966114383586
collect_time: 0.18185552901029584
reward_mean: 2630.2840947286436
reward_std: 1158.9938251400945
reward_max: 3478.6236323355947
reward_min: 991.5608887438641
total_envstep_count: 11557410
total_train_sample_count: 8696039
total_episode_count: 28253
total_duration: 2433.993638848258
[2023-06-29 12:06:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 178.88888888888889
avg_sample_per_episode: 178.88888888888889
avg_envstep_per_sec: 2728.0355107671135
avg_train_sample_per_sec: 2728.0355107671135
avg_episode_per_sec: 15.249887948387592
collect_time: 0.5901682707741858
reward_mean: 2411.392805846589
reward_std: 1003.4563355323227
reward_max: 3474.1397778541614
reward_min: 674.9267475651993
total_envstep_count: 11561690
total_train_sample_count: 8699249
total_episode_count: 28262
total_duration: 2434.583807119032
[2023-06-29 12:06:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3327
train_sample_count: 3327
avg_envstep_per_episode: 277.25
avg_sample_per_episode: 277.25
avg_envstep_per_sec: 2552.5329257558046
avg_train_sample_per_sec: 2552.5329257558046
avg_episode_per_sec: 9.206611093799115
collect_time: 1.3034111985117198
reward_mean: 1824.5163498865193
reward_std: 1054.2549731799984
reward_max: 3407.4720330522955
reward_min: 680.2211175441579
total_envstep_count: 11566450
total_train_sample_count: 8702576
total_episode_count: 28274
total_duration: 2435.8872183175436
[2023-06-29 12:06:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1600
train_sample_count: 1600
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 2650.6039655137006
avg_train_sample_per_sec: 2650.6039655137006
avg_episode_per_sec: 13.253019827568503
collect_time: 0.6036360093085094
reward_mean: 1135.9671574159818
reward_std: 470.91714675685523
reward_max: 1662.5209703515607
reward_min: 614.3280752765727
total_envstep_count: 11571050
total_train_sample_count: 8705776
total_episode_count: 28282
total_duration: 2436.490854326852
[2023-06-29 12:06:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2623
train_sample_count: 2623
avg_envstep_per_episode: 291.44444444444446
avg_sample_per_episode: 291.44444444444446
avg_envstep_per_sec: 2674.1128632843097
avg_train_sample_per_sec: 2674.1128632843097
avg_episode_per_sec: 9.175377723811966
collect_time: 0.9808860486084594
reward_mean: 2338.0793497942186
reward_std: 1291.3423705333971
reward_max: 3532.4216386938783
reward_min: 694.1720827377619
total_envstep_count: 11575978
total_train_sample_count: 8709199
total_episode_count: 28291
total_duration: 2437.4717403754607
[2023-06-29 12:06:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2611
train_sample_count: 2611
avg_envstep_per_episode: 237.36363636363637
avg_sample_per_episode: 237.36363636363637
avg_envstep_per_sec: 2702.6679004598986
avg_train_sample_per_sec: 2702.6679004598986
avg_episode_per_sec: 11.38619184414358
collect_time: 0.9660824400791899
reward_mean: 1611.9254510791898
reward_std: 721.896717504983
reward_max: 3376.3249609412796
reward_min: 450.8747747295803
total_envstep_count: 11580650
total_train_sample_count: 8712610
total_episode_count: 28302
total_duration: 2438.43782281554
[2023-06-29 12:06:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1485
train_sample_count: 1485
avg_envstep_per_episode: 212.14285714285714
avg_sample_per_episode: 212.14285714285714
avg_envstep_per_sec: 2827.1567188005897
avg_train_sample_per_sec: 2827.1567188005897
avg_episode_per_sec: 13.326664667746886
collect_time: 0.5252627101019025
reward_mean: 1287.0274566038838
reward_std: 933.2473689735499
reward_max: 3554.1956232010657
reward_min: 634.8920614012113
total_envstep_count: 11585386
total_train_sample_count: 8716095
total_episode_count: 28309
total_duration: 2438.963085525642
[2023-06-29 12:06:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1234
train_sample_count: 1234
avg_envstep_per_episode: 205.66666666666666
avg_sample_per_episode: 205.66666666666666
avg_envstep_per_sec: 2644.6736507186347
avg_train_sample_per_sec: 2644.6736507186347
avg_episode_per_sec: 12.859029095876668
collect_time: 0.46659821322932843
reward_mean: 2905.646527567742
reward_std: 921.1873753507748
reward_max: 3544.2162389125506
reward_min: 986.2199667540553
total_envstep_count: 11589226
total_train_sample_count: 8719329
total_episode_count: 28315
total_duration: 2439.429683738871
[2023-06-29 12:06:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3001
train_sample_count: 3001
avg_envstep_per_episode: 272.8181818181818
avg_sample_per_episode: 272.8181818181818
avg_envstep_per_sec: 2549.656319048129
avg_train_sample_per_sec: 2549.656319048129
avg_episode_per_sec: 9.345624628300373
collect_time: 1.1770213803248482
reward_mean: 2012.4841426316793
reward_std: 1060.347225939418
reward_max: 3551.0694617621507
reward_min: 718.2091859707217
total_envstep_count: 11593938
total_train_sample_count: 8722730
total_episode_count: 28326
total_duration: 2440.606705119196
[2023-06-29 12:06:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2825
train_sample_count: 2825
avg_envstep_per_episode: 256.8181818181818
avg_sample_per_episode: 256.8181818181818
avg_envstep_per_sec: 2731.8451056380013
avg_train_sample_per_sec: 2731.8451056380013
avg_episode_per_sec: 10.637272977705493
collect_time: 1.0340996252568437
reward_mean: 1470.957570731837
reward_std: 580.0465609581232
reward_max: 2712.0288276190076
reward_min: 615.3447843014638
total_envstep_count: 11597482
total_train_sample_count: 8725955
total_episode_count: 28337
total_duration: 2441.6408047444525
[2023-06-29 12:06:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2405
train_sample_count: 2405
avg_envstep_per_episode: 267.22222222222223
avg_sample_per_episode: 267.22222222222223
avg_envstep_per_sec: 2768.3926339425416
avg_train_sample_per_sec: 2768.3926339425416
avg_episode_per_sec: 10.359889274629055
collect_time: 0.868735153573565
reward_mean: 1275.721417602156
reward_std: 431.066492048846
reward_max: 2126.860474400629
reward_min: 705.2763573833381
total_envstep_count: 11601282
total_train_sample_count: 8729160
total_episode_count: 28346
total_duration: 2442.509539898026
[2023-06-29 12:06:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2661
train_sample_count: 2661
avg_envstep_per_episode: 266.1
avg_sample_per_episode: 266.1
avg_envstep_per_sec: 2620.3056335994866
avg_train_sample_per_sec: 2620.3056335994866
avg_episode_per_sec: 9.847071152196492
collect_time: 1.0155303892334926
reward_mean: 1467.8978203793872
reward_std: 677.6105402757493
reward_max: 2914.947983739696
reward_min: 896.2357552566106
total_envstep_count: 11606034
total_train_sample_count: 8732621
total_episode_count: 28356
total_duration: 2443.5250702872595
[2023-06-29 12:06:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2119
train_sample_count: 2119
avg_envstep_per_episode: 235.44444444444446
avg_sample_per_episode: 235.44444444444446
avg_envstep_per_sec: 2536.755007272361
avg_train_sample_per_sec: 2536.755007272361
avg_episode_per_sec: 10.774325184262034
collect_time: 0.8353191356379538
reward_mean: 1524.248104281947
reward_std: 821.206684694843
reward_max: 3545.686966067189
reward_min: 641.642254643936
total_envstep_count: 11610306
total_train_sample_count: 8735940
total_episode_count: 28365
total_duration: 2444.3603894228972
[2023-06-29 12:07:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2415
train_sample_count: 2415
avg_envstep_per_episode: 268.3333333333333
avg_sample_per_episode: 268.3333333333333
avg_envstep_per_sec: 2491.905553132202
avg_train_sample_per_sec: 2491.905553132202
avg_episode_per_sec: 9.286604545834292
collect_time: 0.9691378539465368
reward_mean: 1851.926471194533
reward_std: 899.8184026232684
reward_max: 3396.5296777288404
reward_min: 984.7976345494761
total_envstep_count: 11614714
total_train_sample_count: 8739155
total_episode_count: 28374
total_duration: 2445.3295272768437
[2023-06-29 12:07:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2549
train_sample_count: 2549
avg_envstep_per_episode: 254.9
avg_sample_per_episode: 254.9
avg_envstep_per_sec: 2746.5472953046283
avg_train_sample_per_sec: 2746.5472953046283
avg_episode_per_sec: 10.774999196958133
collect_time: 0.9280743151074274
reward_mean: 1776.719519802176
reward_std: 913.6124075733376
reward_max: 3507.047574080559
reward_min: 687.9726798079934
total_envstep_count: 11618882
total_train_sample_count: 8742504
total_episode_count: 28384
total_duration: 2446.2576015919512
[2023-06-29 12:07:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1895
train_sample_count: 1895
avg_envstep_per_episode: 236.875
avg_sample_per_episode: 236.875
avg_envstep_per_sec: 2709.220876791387
avg_train_sample_per_sec: 2709.220876791387
avg_episode_per_sec: 11.437344070887123
collect_time: 0.6994630877953023
reward_mean: 1542.9119784029444
reward_std: 865.9997345333036
reward_max: 3517.8339681540606
reward_min: 679.2845089383586
total_envstep_count: 11623250
total_train_sample_count: 8745999
total_episode_count: 28392
total_duration: 2446.9570646797465
[2023-06-29 12:07:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3430
train_sample_count: 3430
avg_envstep_per_episode: 263.84615384615387
avg_sample_per_episode: 263.84615384615387
avg_envstep_per_sec: 2658.128767122245
avg_train_sample_per_sec: 2658.128767122245
avg_episode_per_sec: 10.074540516789849
collect_time: 1.2903814301341774
reward_mean: 1658.7644520340439
reward_std: 812.169328258029
reward_max: 3325.804575835989
reward_min: 644.258960153551
total_envstep_count: 11627850
total_train_sample_count: 8749429
total_episode_count: 28405
total_duration: 2448.247446109881
[2023-06-29 12:07:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2511
train_sample_count: 2511
avg_envstep_per_episode: 228.27272727272728
avg_sample_per_episode: 228.27272727272728
avg_envstep_per_sec: 2563.5831397276597
avg_train_sample_per_sec: 2563.5831397276597
avg_episode_per_sec: 11.230352264836423
collect_time: 0.9794884203625844
reward_mean: 1167.0538679828596
reward_std: 507.560495395714
reward_max: 2176.3420088378157
reward_min: 682.383955718798
total_envstep_count: 11632442
total_train_sample_count: 8752740
total_episode_count: 28416
total_duration: 2449.2269345302434
[2023-06-29 12:07:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2222
train_sample_count: 2222
avg_envstep_per_episode: 222.2
avg_sample_per_episode: 222.2
avg_envstep_per_sec: 2738.7325649069076
avg_train_sample_per_sec: 2738.7325649069076
avg_episode_per_sec: 12.325529094990582
collect_time: 0.8113241973575205
reward_mean: 1418.307522170518
reward_std: 631.1109906212139
reward_max: 2491.442849369016
reward_min: 704.401980125788
total_envstep_count: 11636874
total_train_sample_count: 8756162
total_episode_count: 28426
total_duration: 2450.038258727601
[2023-06-29 12:07:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 263.1818181818182
avg_sample_per_episode: 263.1818181818182
avg_envstep_per_sec: 2729.056608263224
avg_train_sample_per_sec: 2729.056608263224
avg_episode_per_sec: 10.369472432088243
collect_time: 1.0608061376353723
reward_mean: 1796.924879173095
reward_std: 1096.785781978429
reward_max: 3579.0272790844415
reward_min: 690.0739828200196
total_envstep_count: 11641050
total_train_sample_count: 8759457
total_episode_count: 28437
total_duration: 2451.099064865236
[2023-06-29 12:07:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2632
train_sample_count: 2632
avg_envstep_per_episode: 239.27272727272728
avg_sample_per_episode: 239.27272727272728
avg_envstep_per_sec: 2601.838979720891
avg_train_sample_per_sec: 2601.838979720891
avg_episode_per_sec: 10.873947103696732
collect_time: 1.011592193257995
reward_mean: 1208.305682043194
reward_std: 459.3636854905262
reward_max: 2092.323697400922
reward_min: 717.0842987350464
total_envstep_count: 11645866
total_train_sample_count: 8762889
total_episode_count: 28448
total_duration: 2452.110657058494
[2023-06-29 12:07:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1521
train_sample_count: 1521
avg_envstep_per_episode: 169.0
avg_sample_per_episode: 169.0
avg_envstep_per_sec: 2410.1715760713537
avg_train_sample_per_sec: 2410.1715760713537
avg_episode_per_sec: 14.261370272611561
collect_time: 0.6310754035525022
reward_mean: 1504.0266004249036
reward_std: 931.6548886543244
reward_max: 3541.3147250503102
reward_min: 665.1252140823026
total_envstep_count: 11650658
total_train_sample_count: 8766410
total_episode_count: 28457
total_duration: 2452.7417324620465
[2023-06-29 12:07:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 284.3
avg_sample_per_episode: 284.3
avg_envstep_per_sec: 2540.2323511557506
avg_train_sample_per_sec: 2540.2323511557506
avg_episode_per_sec: 8.935041685387796
collect_time: 1.1191889587212354
reward_mean: 2258.6090548055104
reward_std: 1046.5900131732656
reward_max: 3590.524430533062
reward_min: 854.4525264052804
total_envstep_count: 11654962
total_train_sample_count: 8769653
total_episode_count: 28467
total_duration: 2453.8609214207677
[2023-06-29 12:07:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 307.25
avg_sample_per_episode: 307.25
avg_envstep_per_sec: 2789.2688324040128
avg_train_sample_per_sec: 2789.2688324040128
avg_episode_per_sec: 9.078173579834052
collect_time: 0.4406172634642572
reward_mean: 1378.907321077018
reward_std: 935.9345343219456
reward_max: 2911.6982942696827
reward_min: 381.60991015369757
total_envstep_count: 11658858
total_train_sample_count: 8772882
total_episode_count: 28471
total_duration: 2454.301538684232
[2023-06-29 12:07:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2705
train_sample_count: 2705
avg_envstep_per_episode: 245.9090909090909
avg_sample_per_episode: 245.9090909090909
avg_envstep_per_sec: 2723.5530906276963
avg_train_sample_per_sec: 2723.5530906276963
avg_episode_per_sec: 11.075446948948118
collect_time: 0.9931879093190652
reward_mean: 2078.947473651249
reward_std: 1163.70444562771
reward_max: 3556.397621353507
reward_min: 685.2622124866739
total_envstep_count: 11662762
total_train_sample_count: 8776387
total_episode_count: 28482
total_duration: 2455.2947265935513
[2023-06-29 12:07:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2073
train_sample_count: 2073
avg_envstep_per_episode: 414.6
avg_sample_per_episode: 414.6
avg_envstep_per_sec: 2534.4725898077077
avg_train_sample_per_sec: 2534.4725898077077
avg_episode_per_sec: 6.113054968180674
collect_time: 0.8179216489996761
reward_mean: 2178.6385754887147
reward_std: 1046.2306940642343
reward_max: 3437.805022618835
reward_min: 998.2468643728939
total_envstep_count: 11667402
total_train_sample_count: 8779660
total_episode_count: 28487
total_duration: 2456.112648242551
[2023-06-29 12:07:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 639
train_sample_count: 639
avg_envstep_per_episode: 127.8
avg_sample_per_episode: 127.8
avg_envstep_per_sec: 2744.1387179187564
avg_train_sample_per_sec: 2744.1387179187564
avg_episode_per_sec: 21.472133943026265
collect_time: 0.23285994830634446
reward_mean: 1902.0956196531843
reward_std: 1036.5344517235865
reward_max: 3468.3815989758496
reward_min: 690.7493082910569
total_envstep_count: 11671498
total_train_sample_count: 8783099
total_episode_count: 28492
total_duration: 2456.3455081908573
[2023-06-29 12:07:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2591
train_sample_count: 2591
avg_envstep_per_episode: 370.14285714285717
avg_sample_per_episode: 370.14285714285717
avg_envstep_per_sec: 2766.270036349998
avg_train_sample_per_sec: 2766.270036349998
avg_episode_per_sec: 7.473519974700883
collect_time: 0.936640301182866
reward_mean: 3123.278733245661
reward_std: 489.5428226361728
reward_max: 3486.5709822188333
reward_min: 2267.370062970465
total_envstep_count: 11676186
total_train_sample_count: 8786490
total_episode_count: 28499
total_duration: 2457.28214849204
[2023-06-29 12:07:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1363
train_sample_count: 1363
avg_envstep_per_episode: 194.71428571428572
avg_sample_per_episode: 194.71428571428572
avg_envstep_per_sec: 2781.20604254804
avg_train_sample_per_sec: 2781.20604254804
avg_episode_per_sec: 14.283523329300278
collect_time: 0.49007516133226464
reward_mean: 1495.9853391712475
reward_std: 910.8493799239278
reward_max: 3297.887267047407
reward_min: 721.3814855076953
total_envstep_count: 11680826
total_train_sample_count: 8789853
total_episode_count: 28506
total_duration: 2457.7722236533723
[2023-06-29 12:07:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1266
train_sample_count: 1266
avg_envstep_per_episode: 211.0
avg_sample_per_episode: 211.0
avg_envstep_per_sec: 2663.344846419783
avg_train_sample_per_sec: 2663.344846419783
avg_episode_per_sec: 12.62248742379044
collect_time: 0.4753421254111453
reward_mean: 2695.091016315191
reward_std: 900.2149781498591
reward_max: 3419.372262816589
reward_min: 787.3184231598411
total_envstep_count: 11685570
total_train_sample_count: 8793119
total_episode_count: 28512
total_duration: 2458.2475657787836
[2023-06-29 12:07:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1857
train_sample_count: 1857
avg_envstep_per_episode: 265.2857142857143
avg_sample_per_episode: 265.2857142857143
avg_envstep_per_sec: 2710.739172456957
avg_train_sample_per_sec: 2710.739172456957
avg_episode_per_sec: 10.218187510607809
collect_time: 0.6850529991481453
reward_mean: 2871.6835095750534
reward_std: 743.1814595085107
reward_max: 3516.185731153061
reward_min: 1195.7714649123548
total_envstep_count: 11690010
total_train_sample_count: 8796576
total_episode_count: 28519
total_duration: 2458.9326187779316
[2023-06-29 12:07:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1887
train_sample_count: 1887
avg_envstep_per_episode: 269.57142857142856
avg_sample_per_episode: 269.57142857142856
avg_envstep_per_sec: 2709.297841614364
avg_train_sample_per_sec: 2709.297841614364
avg_episode_per_sec: 10.05038944954984
collect_time: 0.696490423096344
reward_mean: 2116.66270681985
reward_std: 1186.8739889544468
reward_max: 3498.828648234055
reward_min: 691.4467200507396
total_envstep_count: 11694178
total_train_sample_count: 8800063
total_episode_count: 28526
total_duration: 2459.629109201028
[2023-06-29 12:08:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1296
train_sample_count: 1296
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2772.9769813798334
avg_train_sample_per_sec: 2772.9769813798334
avg_episode_per_sec: 12.837856395277006
collect_time: 0.46736774546001114
reward_mean: 1727.672541098843
reward_std: 1244.5251678862433
reward_max: 3478.5377261146455
reward_min: 681.9429216887287
total_envstep_count: 11698482
total_train_sample_count: 8803359
total_episode_count: 28532
total_duration: 2460.0964769464877
[2023-06-29 12:08:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1739
train_sample_count: 1739
avg_envstep_per_episode: 289.8333333333333
avg_sample_per_episode: 289.8333333333333
avg_envstep_per_sec: 2621.1858355360287
avg_train_sample_per_sec: 2621.1858355360287
avg_episode_per_sec: 9.043769415305448
collect_time: 0.6634401790304109
reward_mean: 3131.7585580964683
reward_std: 702.3256824043967
reward_max: 3594.7013317879055
reward_min: 1579.0912231206178
total_envstep_count: 11703282
total_train_sample_count: 8806698
total_episode_count: 28538
total_duration: 2460.759917125518
[2023-06-29 12:08:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 289.57142857142856
avg_sample_per_episode: 289.57142857142856
avg_envstep_per_sec: 2657.5920138158003
avg_train_sample_per_sec: 2657.5920138158003
avg_episode_per_sec: 9.177673456689986
collect_time: 0.7627205340256915
reward_mean: 2480.8461867218616
reward_std: 1104.662987837342
reward_max: 3446.5653846351406
reward_min: 927.9689291675131
total_envstep_count: 11707810
total_train_sample_count: 8809925
total_episode_count: 28545
total_duration: 2461.5226376595438
[2023-06-29 12:08:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1374
train_sample_count: 1374
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 2792.832720834
avg_train_sample_per_sec: 2792.832720834
avg_episode_per_sec: 12.195776073510919
collect_time: 0.4919736115057023
reward_mean: 1992.7275714992472
reward_std: 936.6786487161643
reward_max: 3256.7393244654127
reward_min: 709.3040880851557
total_envstep_count: 11712490
total_train_sample_count: 8813299
total_episode_count: 28551
total_duration: 2462.0146112710495
[2023-06-29 12:08:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 2727.698079315263
avg_train_sample_per_sec: 2727.698079315263
avg_episode_per_sec: 16.045282819501544
collect_time: 0.49858890553656965
reward_mean: 2054.3994464499847
reward_std: 1161.9851130338427
reward_max: 3495.615229230512
reward_min: 700.5020474380013
total_envstep_count: 11716434
total_train_sample_count: 8816659
total_episode_count: 28559
total_duration: 2462.513200176586
[2023-06-29 12:08:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1608
train_sample_count: 1608
avg_envstep_per_episode: 229.71428571428572
avg_sample_per_episode: 229.71428571428572
avg_envstep_per_sec: 2746.8330300573166
avg_train_sample_per_sec: 2746.8330300573166
avg_episode_per_sec: 11.95760647413011
collect_time: 0.5854014359097928
reward_mean: 2433.0336935724886
reward_std: 1353.1384884390707
reward_max: 3640.5787090346475
reward_min: 160.64253210697586
total_envstep_count: 11720618
total_train_sample_count: 8819867
total_episode_count: 28566
total_duration: 2463.0986016124957
[2023-06-29 12:08:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2480
train_sample_count: 2480
avg_envstep_per_episode: 206.66666666666666
avg_sample_per_episode: 206.66666666666666
avg_envstep_per_sec: 2567.1956080886844
avg_train_sample_per_sec: 2567.1956080886844
avg_episode_per_sec: 12.421914232687183
collect_time: 0.9660346847688779
reward_mean: 1324.7937964827581
reward_std: 1103.4418544755877
reward_max: 3571.9043252175484
reward_min: 58.540096613726405
total_envstep_count: 11724578
total_train_sample_count: 8823147
total_episode_count: 28578
total_duration: 2464.0646362972648
[2023-06-29 12:08:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 287
train_sample_count: 287
avg_envstep_per_episode: 95.66666666666667
avg_sample_per_episode: 95.66666666666667
avg_envstep_per_sec: 2758.3561866878285
avg_train_sample_per_sec: 2758.3561866878285
avg_episode_per_sec: 28.832991498479043
collect_time: 0.10404747631400826
reward_mean: 2697.417226538557
reward_std: 1213.8690582776064
reward_max: 3631.18281527328
reward_min: 983.0255123887289
total_envstep_count: 11728922
total_train_sample_count: 8826634
total_episode_count: 28581
total_duration: 2464.168683773579
[2023-06-29 12:08:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2701
train_sample_count: 2701
avg_envstep_per_episode: 300.1111111111111
avg_sample_per_episode: 300.1111111111111
avg_envstep_per_sec: 2701.227098383159
avg_train_sample_per_sec: 2701.227098383159
avg_episode_per_sec: 9.000756714345957
collect_time: 0.9999159276969734
reward_mean: 2724.879909442122
reward_std: 1072.2376382109644
reward_max: 3506.0264663695075
reward_min: 54.553627683404045
total_envstep_count: 11733234
total_train_sample_count: 8830135
total_episode_count: 28590
total_duration: 2465.1685997012755
[2023-06-29 12:08:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2473
train_sample_count: 2473
avg_envstep_per_episode: 247.3
avg_sample_per_episode: 247.3
avg_envstep_per_sec: 2745.812864012027
avg_train_sample_per_sec: 2745.812864012027
avg_episode_per_sec: 11.103165645014263
collect_time: 0.900644043304026
reward_mean: 1330.5604918076297
reward_std: 421.4204784314517
reward_max: 2007.4890056360184
reward_min: 634.4466919507548
total_envstep_count: 11737058
total_train_sample_count: 8833408
total_episode_count: 28600
total_duration: 2466.0692437445796
[2023-06-29 12:08:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 2739.3714643425837
avg_train_sample_per_sec: 2739.3714643425837
avg_episode_per_sec: 10.65903293518515
collect_time: 0.375268565574661
reward_mean: 2219.8596257698623
reward_std: 1333.4564669726979
reward_max: 3591.623351700159
reward_min: 859.7536514155544
total_envstep_count: 11741714
total_train_sample_count: 8836836
total_episode_count: 28604
total_duration: 2466.444512310154
[2023-06-29 12:08:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2821
train_sample_count: 2821
avg_envstep_per_episode: 352.625
avg_sample_per_episode: 352.625
avg_envstep_per_sec: 2590.0998368659643
avg_train_sample_per_sec: 2590.0998368659643
avg_episode_per_sec: 7.345196276117587
collect_time: 1.0891472057746725
reward_mean: 2830.0892785262117
reward_std: 687.1207852836269
reward_max: 3509.772297138144
reward_min: 1293.520635779923
total_envstep_count: 11746290
total_train_sample_count: 8840057
total_episode_count: 28612
total_duration: 2467.533659515929
[2023-06-29 12:08:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1401
train_sample_count: 1401
avg_envstep_per_episode: 280.2
avg_sample_per_episode: 280.2
avg_envstep_per_sec: 2729.7948212627966
avg_train_sample_per_sec: 2729.7948212627966
avg_episode_per_sec: 9.742308427062087
collect_time: 0.5132253856910391
reward_mean: 2055.3378987032474
reward_std: 934.4097092827075
reward_max: 3518.35393004455
reward_min: 1002.9420584432661
total_envstep_count: 11750474
total_train_sample_count: 8843458
total_episode_count: 28617
total_duration: 2468.0468849016197
[2023-06-29 12:08:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1267
train_sample_count: 1267
avg_envstep_per_episode: 253.4
avg_sample_per_episode: 253.4
avg_envstep_per_sec: 2780.1847372240845
avg_train_sample_per_sec: 2780.1847372240845
avg_episode_per_sec: 10.971526192675945
collect_time: 0.4557251117294653
reward_mean: 2759.408897947533
reward_std: 653.3096038063885
reward_max: 3521.6111145288646
reward_min: 1841.9251787971568
total_envstep_count: 11754466
total_train_sample_count: 8846725
total_episode_count: 28622
total_duration: 2468.502610013349
[2023-06-29 12:08:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2955
train_sample_count: 2955
avg_envstep_per_episode: 246.25
avg_sample_per_episode: 246.25
avg_envstep_per_sec: 2592.579370547545
avg_train_sample_per_sec: 2592.579370547545
avg_episode_per_sec: 10.528241098670232
collect_time: 1.1397915271446108
reward_mean: 1899.3095805165012
reward_std: 1111.0468044025579
reward_max: 3500.187755819883
reward_min: 645.258045519458
total_envstep_count: 11758922
total_train_sample_count: 8850080
total_episode_count: 28634
total_duration: 2469.6424015404937
[2023-06-29 12:08:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2571
train_sample_count: 2571
avg_envstep_per_episode: 257.1
avg_sample_per_episode: 257.1
avg_envstep_per_sec: 2776.8242366647946
avg_train_sample_per_sec: 2776.8242366647946
avg_episode_per_sec: 10.800561013865401
collect_time: 0.9258778305277228
reward_mean: 1451.301207327512
reward_std: 740.5533868010957
reward_max: 2821.926644798897
reward_min: 665.6156578577691
total_envstep_count: 11763274
total_train_sample_count: 8853451
total_episode_count: 28644
total_duration: 2470.568279371021
[2023-06-29 12:08:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2541
train_sample_count: 2541
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 2766.7479088017885
avg_train_sample_per_sec: 2766.7479088017885
avg_episode_per_sec: 11.977263674466617
collect_time: 0.9184067662674933
reward_mean: 1406.2084591399084
reward_std: 660.9234799477496
reward_max: 2889.402991060058
reward_min: 679.1491620450745
total_envstep_count: 11767674
total_train_sample_count: 8856792
total_episode_count: 28655
total_duration: 2471.486686137289
[2023-06-29 12:08:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2743
train_sample_count: 2743
avg_envstep_per_episode: 228.58333333333334
avg_sample_per_episode: 228.58333333333334
avg_envstep_per_sec: 2742.762651784071
avg_train_sample_per_sec: 2742.762651784071
avg_episode_per_sec: 11.998961655635746
collect_time: 1.0000865361848845
reward_mean: 1413.3479819138656
reward_std: 550.9921217426761
reward_max: 2332.767349368601
reward_min: 707.711014170382
total_envstep_count: 11772034
total_train_sample_count: 8860335
total_episode_count: 28667
total_duration: 2472.4867726734738
[2023-06-29 12:08:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2090
train_sample_count: 2090
avg_envstep_per_episode: 209.0
avg_sample_per_episode: 209.0
avg_envstep_per_sec: 2533.212691404838
avg_train_sample_per_sec: 2533.212691404838
avg_episode_per_sec: 12.120634887104488
collect_time: 0.8250392898675055
reward_mean: 1331.7842546004258
reward_std: 914.236674200487
reward_max: 2964.8737264636543
reward_min: 55.21623207878532
total_envstep_count: 11776514
total_train_sample_count: 8863625
total_episode_count: 28677
total_duration: 2473.3118119633414
[2023-06-29 12:08:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3199
train_sample_count: 3199
avg_envstep_per_episode: 266.5833333333333
avg_sample_per_episode: 266.5833333333333
avg_envstep_per_sec: 2622.38375293587
avg_train_sample_per_sec: 2622.38375293587
avg_episode_per_sec: 9.837013140115797
collect_time: 1.2198824815088882
reward_mean: 1689.5938434938755
reward_std: 854.756592073003
reward_max: 3025.8315066086043
reward_min: 375.95936274690985
total_envstep_count: 11781554
total_train_sample_count: 8867224
total_episode_count: 28689
total_duration: 2474.5316944448505
[2023-06-29 12:09:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2745
train_sample_count: 2745
avg_envstep_per_episode: 228.75
avg_sample_per_episode: 228.75
avg_envstep_per_sec: 2770.5610449957903
avg_train_sample_per_sec: 2770.5610449957903
avg_episode_per_sec: 12.111742273205639
collect_time: 0.9907740545757118
reward_mean: 1346.6971812847812
reward_std: 525.3321531471556
reward_max: 2096.3368279922943
reward_min: 50.15864944215485
total_envstep_count: 11786402
total_train_sample_count: 8870769
total_episode_count: 28701
total_duration: 2475.5224684994264
[2023-06-29 12:09:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2041
train_sample_count: 2041
avg_envstep_per_episode: 204.1
avg_sample_per_episode: 204.1
avg_envstep_per_sec: 2697.7800190919393
avg_train_sample_per_sec: 2697.7800190919393
avg_episode_per_sec: 13.217932479627336
collect_time: 0.7565479711303487
reward_mean: 1440.6268799383283
reward_std: 514.2843946384622
reward_max: 2542.1513239628716
reward_min: 827.1655459247177
total_envstep_count: 11790594
total_train_sample_count: 8874010
total_episode_count: 28711
total_duration: 2476.2790164705566
[2023-06-29 12:09:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2346
train_sample_count: 2346
avg_envstep_per_episode: 195.5
avg_sample_per_episode: 195.5
avg_envstep_per_sec: 2702.1398743206387
avg_train_sample_per_sec: 2702.1398743206387
avg_episode_per_sec: 13.82168733667846
collect_time: 0.8682007997790351
reward_mean: 1388.3314394030451
reward_std: 752.460875377778
reward_max: 2740.0384582597576
reward_min: 62.42416590779142
total_envstep_count: 11795242
total_train_sample_count: 8877556
total_episode_count: 28723
total_duration: 2477.1472172703357
[2023-06-29 12:09:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2075
train_sample_count: 2075
avg_envstep_per_episode: 207.5
avg_sample_per_episode: 207.5
avg_envstep_per_sec: 2592.6585051281404
avg_train_sample_per_sec: 2592.6585051281404
avg_episode_per_sec: 12.494739783750074
collect_time: 0.8003367955693974
reward_mean: 1475.1061447179088
reward_std: 574.0684900662799
reward_max: 2527.864450148757
reward_min: 668.4516130685867
total_envstep_count: 11799266
total_train_sample_count: 8880831
total_episode_count: 28733
total_duration: 2477.947554065905
[2023-06-29 12:09:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2614
train_sample_count: 2614
avg_envstep_per_episode: 186.71428571428572
avg_sample_per_episode: 186.71428571428572
avg_envstep_per_sec: 2765.005648528165
avg_train_sample_per_sec: 2765.005648528165
avg_episode_per_sec: 14.808752516983287
collect_time: 0.9453868571268393
reward_mean: 1232.2232918995228
reward_std: 700.1625270316774
reward_max: 3160.556111574774
reward_min: 182.9359869471293
total_envstep_count: 11803962
total_train_sample_count: 8884245
total_episode_count: 28747
total_duration: 2478.892940923032
[2023-06-29 12:09:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1692
train_sample_count: 1692
avg_envstep_per_episode: 241.71428571428572
avg_sample_per_episode: 241.71428571428572
avg_envstep_per_sec: 2752.6886500023134
avg_train_sample_per_sec: 2752.6886500023134
avg_episode_per_sec: 11.388191814430375
collect_time: 0.6146717682722955
reward_mean: 1610.0577017861306
reward_std: 964.7216598529163
reward_max: 3250.041880183134
reward_min: 183.96954750372694
total_envstep_count: 11807650
total_train_sample_count: 8887537
total_episode_count: 28754
total_duration: 2479.507612691304
[2023-06-29 12:09:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3169
train_sample_count: 3169
avg_envstep_per_episode: 264.0833333333333
avg_sample_per_episode: 264.0833333333333
avg_envstep_per_sec: 2737.1058492931834
avg_train_sample_per_sec: 2737.1058492931834
avg_episode_per_sec: 10.364553547339288
collect_time: 1.1577922720154745
reward_mean: 1735.467042276665
reward_std: 1066.7404636957128
reward_max: 3463.6550603931764
reward_min: 594.1027544263619
total_envstep_count: 11812250
total_train_sample_count: 8891106
total_episode_count: 28766
total_duration: 2480.6654049633194
[2023-06-29 12:09:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2042
train_sample_count: 2042
avg_envstep_per_episode: 204.2
avg_sample_per_episode: 204.2
avg_envstep_per_sec: 2605.760173897816
avg_train_sample_per_sec: 2605.760173897816
avg_episode_per_sec: 12.760823574426132
collect_time: 0.7836484801843764
reward_mean: 1201.4581912331953
reward_std: 472.418011891607
reward_max: 1949.539673915432
reward_min: 641.7754021721236
total_envstep_count: 11816162
total_train_sample_count: 8894348
total_episode_count: 28776
total_duration: 2481.4490534435035
[2023-06-29 12:09:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2301
train_sample_count: 2301
avg_envstep_per_episode: 191.75
avg_sample_per_episode: 191.75
avg_envstep_per_sec: 2687.5326819669594
avg_train_sample_per_sec: 2687.5326819669594
avg_episode_per_sec: 14.01581581208323
collect_time: 0.8561756347892808
reward_mean: 1283.971389765486
reward_std: 643.9833412039966
reward_max: 2468.7911298814515
reward_min: 644.7940922336139
total_envstep_count: 11820618
total_train_sample_count: 8897849
total_episode_count: 28788
total_duration: 2482.305229078293
[2023-06-29 12:09:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3478
train_sample_count: 3478
avg_envstep_per_episode: 248.42857142857142
avg_sample_per_episode: 248.42857142857142
avg_envstep_per_sec: 2620.282493141275
avg_train_sample_per_sec: 2620.282493141275
avg_episode_per_sec: 10.547428092000532
collect_time: 1.3273378000669183
reward_mean: 1466.6242448487321
reward_std: 666.771790977205
reward_max: 3256.3556621451294
reward_min: 722.4625653704957
total_envstep_count: 11825026
total_train_sample_count: 8901327
total_episode_count: 28802
total_duration: 2483.6325668783597
[2023-06-29 12:09:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3337
train_sample_count: 3337
avg_envstep_per_episode: 222.46666666666667
avg_sample_per_episode: 222.46666666666667
avg_envstep_per_sec: 2689.7553817732196
avg_train_sample_per_sec: 2689.7553817732196
avg_episode_per_sec: 12.090599558465176
collect_time: 1.240633264501579
reward_mean: 1012.6036042393494
reward_std: 405.00234871247767
reward_max: 2413.7117187566964
reward_min: 664.4576677937667
total_envstep_count: 11829866
total_train_sample_count: 8904664
total_episode_count: 28817
total_duration: 2484.873200142861
[2023-06-29 12:09:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1451
train_sample_count: 1451
avg_envstep_per_episode: 181.375
avg_sample_per_episode: 181.375
avg_envstep_per_sec: 2428.8393841076568
avg_train_sample_per_sec: 2428.8393841076568
avg_episode_per_sec: 13.391257803488113
collect_time: 0.597404673810117
reward_mean: 1294.3001683260904
reward_std: 346.8865673577408
reward_max: 1684.2199952799233
reward_min: 848.6056907481048
total_envstep_count: 11834242
total_train_sample_count: 8908115
total_episode_count: 28825
total_duration: 2485.4706048166713
[2023-06-29 12:09:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2718
train_sample_count: 2718
avg_envstep_per_episode: 226.5
avg_sample_per_episode: 226.5
avg_envstep_per_sec: 2532.810364230749
avg_train_sample_per_sec: 2532.810364230749
avg_episode_per_sec: 11.182385714043043
collect_time: 1.0731162657830862
reward_mean: 1761.359509456585
reward_std: 881.8443631051766
reward_max: 3153.734828194585
reward_min: 52.08046033479694
total_envstep_count: 11838634
total_train_sample_count: 8911633
total_episode_count: 28837
total_duration: 2486.5437210824543
[2023-06-29 12:09:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3349
train_sample_count: 3349
avg_envstep_per_episode: 257.61538461538464
avg_sample_per_episode: 257.61538461538464
avg_envstep_per_sec: 2686.9469279887153
avg_train_sample_per_sec: 2686.9469279887153
avg_episode_per_sec: 10.430071682249418
collect_time: 1.2463960360046475
reward_mean: 1391.6295919248073
reward_std: 899.753499737805
reward_max: 3688.01901561083
reward_min: 166.6068042238321
total_envstep_count: 11843290
total_train_sample_count: 8914982
total_episode_count: 28850
total_duration: 2487.790117118459
[2023-06-29 12:09:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2767.2819722438608
avg_train_sample_per_sec: 2767.2819722438608
avg_episode_per_sec: 10.9378734080785
collect_time: 1.1885308519294484
reward_mean: 1286.2848970520138
reward_std: 404.2930466324448
reward_max: 1944.9797984625286
reward_min: 690.6921975496058
total_envstep_count: 11847530
total_train_sample_count: 8918271
total_episode_count: 28863
total_duration: 2488.9786479703885
[2023-06-29 12:09:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2179
train_sample_count: 2179
avg_envstep_per_episode: 242.11111111111111
avg_sample_per_episode: 242.11111111111111
avg_envstep_per_sec: 2624.0944247410566
avg_train_sample_per_sec: 2624.0944247410566
avg_episode_per_sec: 10.838389087962144
collect_time: 0.8303817040482534
reward_mean: 1103.0925765683492
reward_std: 359.0905592009192
reward_max: 1735.0340931775072
reward_min: 710.6947387389603
total_envstep_count: 11851426
total_train_sample_count: 8921650
total_episode_count: 28872
total_duration: 2489.8090296744367
[2023-06-29 12:09:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2274
train_sample_count: 2274
avg_envstep_per_episode: 252.66666666666666
avg_sample_per_episode: 252.66666666666666
avg_envstep_per_sec: 2759.353934934154
avg_train_sample_per_sec: 2759.353934934154
avg_episode_per_sec: 10.92092586385549
collect_time: 0.8241059514731168
reward_mean: 1722.0062466055203
reward_std: 783.7434211326755
reward_max: 3213.018014182228
reward_min: 768.1257472445036
total_envstep_count: 11856458
total_train_sample_count: 8925124
total_episode_count: 28881
total_duration: 2490.6331356259097
[2023-06-29 12:09:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2324
train_sample_count: 2324
avg_envstep_per_episode: 258.22222222222223
avg_sample_per_episode: 258.22222222222223
avg_envstep_per_sec: 2804.8296137483276
avg_train_sample_per_sec: 2804.8296137483276
avg_episode_per_sec: 10.862076817441888
collect_time: 0.8285708296177909
reward_mean: 2042.1289899750534
reward_std: 1062.5814518221534
reward_max: 3597.2197629854904
reward_min: 798.6368078083514
total_envstep_count: 11861266
total_train_sample_count: 8928648
total_episode_count: 28890
total_duration: 2491.4617064555277
[2023-06-29 12:09:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2267
train_sample_count: 2267
avg_envstep_per_episode: 323.85714285714283
avg_sample_per_episode: 323.85714285714283
avg_envstep_per_sec: 2763.3479867312008
avg_train_sample_per_sec: 2763.3479867312008
avg_episode_per_sec: 8.53261398637777
collect_time: 0.8203816569196061
reward_mean: 2265.990593230916
reward_std: 992.5220760429145
reward_max: 3558.1467986534863
reward_min: 822.0377580266662
total_envstep_count: 11866010
total_train_sample_count: 8932115
total_episode_count: 28897
total_duration: 2492.282088112447
[2023-06-29 12:10:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2543
train_sample_count: 2543
avg_envstep_per_episode: 231.1818181818182
avg_sample_per_episode: 231.1818181818182
avg_envstep_per_sec: 2575.634780095332
avg_train_sample_per_sec: 2575.634780095332
avg_episode_per_sec: 11.141164994513824
collect_time: 0.9873294224990531
reward_mean: 1842.8660099580206
reward_std: 955.4725736256424
reward_max: 3520.2192720597345
reward_min: 685.4044769065985
total_envstep_count: 11870138
total_train_sample_count: 8935458
total_episode_count: 28908
total_duration: 2493.269417534946
[2023-06-29 12:10:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 269.6666666666667
avg_sample_per_episode: 269.6666666666667
avg_envstep_per_sec: 2685.9465771879704
avg_train_sample_per_sec: 2685.9465771879704
avg_episode_per_sec: 9.960246886976405
collect_time: 0.903592059727758
reward_mean: 1432.9780507842331
reward_std: 756.064477826237
reward_max: 2824.2880055765513
reward_min: 838.8227525419255
total_envstep_count: 11874258
total_train_sample_count: 8938685
total_episode_count: 28917
total_duration: 2494.1730095946737
[2023-06-29 12:10:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3424
train_sample_count: 3424
avg_envstep_per_episode: 285.3333333333333
avg_sample_per_episode: 285.3333333333333
avg_envstep_per_sec: 2623.2256016249853
avg_train_sample_per_sec: 2623.2256016249853
avg_episode_per_sec: 9.193547669246444
collect_time: 1.305263259812258
reward_mean: 1694.7681267462488
reward_std: 876.6725758139733
reward_max: 3581.4832638319626
reward_min: 650.2170156242033
total_envstep_count: 11878946
total_train_sample_count: 8942109
total_episode_count: 28929
total_duration: 2495.478272854486
[2023-06-29 12:10:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2800
train_sample_count: 2800
avg_envstep_per_episode: 233.33333333333334
avg_sample_per_episode: 233.33333333333334
avg_envstep_per_sec: 2747.692738812584
avg_train_sample_per_sec: 2747.692738812584
avg_episode_per_sec: 11.775826023482503
collect_time: 1.0190367941977458
reward_mean: 1194.6909071901268
reward_std: 469.3748984896641
reward_max: 1949.9216541646492
reward_min: 677.0138246256915
total_envstep_count: 11883746
total_train_sample_count: 8945309
total_episode_count: 28941
total_duration: 2496.4973096486838
[2023-06-29 12:10:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2643
train_sample_count: 2643
avg_envstep_per_episode: 264.3
avg_sample_per_episode: 264.3
avg_envstep_per_sec: 2604.376421099446
avg_train_sample_per_sec: 2604.376421099446
avg_episode_per_sec: 9.853864627693705
collect_time: 1.0148302597841248
reward_mean: 1740.8847801966226
reward_std: 804.6732587767101
reward_max: 3480.769509927012
reward_min: 908.7067745959795
total_envstep_count: 11887818
total_train_sample_count: 8948752
total_episode_count: 28951
total_duration: 2497.512139908468
[2023-06-29 12:10:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2516
train_sample_count: 2516
avg_envstep_per_episode: 251.6
avg_sample_per_episode: 251.6
avg_envstep_per_sec: 2477.182655870579
avg_train_sample_per_sec: 2477.182655870579
avg_episode_per_sec: 9.84571802810246
collect_time: 1.0156699563665317
reward_mean: 1419.4307193366444
reward_std: 344.56315589321025
reward_max: 1966.2108146148573
reward_min: 900.5102443122726
total_envstep_count: 11892458
total_train_sample_count: 8952068
total_episode_count: 28961
total_duration: 2498.527809864834
[2023-06-29 12:10:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2902
train_sample_count: 2902
avg_envstep_per_episode: 322.44444444444446
avg_sample_per_episode: 322.44444444444446
avg_envstep_per_sec: 2657.7227742732216
avg_train_sample_per_sec: 2657.7227742732216
avg_episode_per_sec: 8.242420733445552
collect_time: 1.0919122295565904
reward_mean: 1922.21601598724
reward_std: 436.0390817370271
reward_max: 2429.299153211937
reward_min: 949.050476010441
total_envstep_count: 11896930
total_train_sample_count: 8955370
total_episode_count: 28970
total_duration: 2499.619722094391
[2023-06-29 12:10:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2485
train_sample_count: 2485
avg_envstep_per_episode: 225.9090909090909
avg_sample_per_episode: 225.9090909090909
avg_envstep_per_sec: 2753.946000521537
avg_train_sample_per_sec: 2753.946000521537
avg_episode_per_sec: 12.190505434904187
collect_time: 0.9023415853213519
reward_mean: 1354.1014768989369
reward_std: 857.8807989410552
reward_max: 3608.9936142588435
reward_min: 37.60687105150718
total_envstep_count: 11901058
total_train_sample_count: 8958655
total_episode_count: 28981
total_duration: 2500.522063679712
[2023-06-29 12:10:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1844
train_sample_count: 1844
avg_envstep_per_episode: 204.88888888888889
avg_sample_per_episode: 204.88888888888889
avg_envstep_per_sec: 2657.1339951897776
avg_train_sample_per_sec: 2657.1339951897776
avg_episode_per_sec: 12.968658327932754
collect_time: 0.6939808091493324
reward_mean: 1399.9142411595801
reward_std: 646.5867500060009
reward_max: 2547.679738928853
reward_min: 648.639148987895
total_envstep_count: 11905330
total_train_sample_count: 8962099
total_episode_count: 28990
total_duration: 2501.2160444888614
[2023-06-29 12:10:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2319
train_sample_count: 2319
avg_envstep_per_episode: 257.6666666666667
avg_sample_per_episode: 257.6666666666667
avg_envstep_per_sec: 2563.8085439854462
avg_train_sample_per_sec: 2563.8085439854462
avg_episode_per_sec: 9.950097842116868
collect_time: 0.9045137186395007
reward_mean: 1821.1377644379145
reward_std: 621.1745317554057
reward_max: 2899.1299699344395
reward_min: 867.3323769267304
total_envstep_count: 11909802
total_train_sample_count: 8965618
total_episode_count: 28999
total_duration: 2502.120558207501
[2023-06-29 12:10:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 293.7
avg_sample_per_episode: 293.7
avg_envstep_per_sec: 2549.0070292927694
avg_train_sample_per_sec: 2549.0070292927694
avg_episode_per_sec: 8.678948005763601
collect_time: 1.1522133780913426
reward_mean: 1969.5850579107987
reward_std: 784.329613336835
reward_max: 3327.641174452107
reward_min: 931.4370292265501
total_envstep_count: 11914690
total_train_sample_count: 8968955
total_episode_count: 29009
total_duration: 2503.272771585592
[2023-06-29 12:10:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1989
train_sample_count: 1989
avg_envstep_per_episode: 198.9
avg_sample_per_episode: 198.9
avg_envstep_per_sec: 2731.328811671911
avg_train_sample_per_sec: 2731.328811671911
avg_episode_per_sec: 13.732170998853247
collect_time: 0.7282169731818141
reward_mean: 1468.1806599172587
reward_std: 816.3664951188837
reward_max: 2734.3980746791276
reward_min: 46.10211575560229
total_envstep_count: 11919338
total_train_sample_count: 8972544
total_episode_count: 29019
total_duration: 2504.0009885587738
[2023-06-29 12:10:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 326.3333333333333
avg_sample_per_episode: 326.3333333333333
avg_envstep_per_sec: 2613.0951430671366
avg_train_sample_per_sec: 2613.0951430671366
avg_episode_per_sec: 8.007441705006547
collect_time: 1.1239544827872887
reward_mean: 2271.5201739234262
reward_std: 893.5939475024247
reward_max: 3601.352411599159
reward_min: 1059.0716275118898
total_envstep_count: 11923962
total_train_sample_count: 8975881
total_episode_count: 29028
total_duration: 2505.124943041561
[2023-06-29 12:10:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1954
train_sample_count: 1954
avg_envstep_per_episode: 279.14285714285717
avg_sample_per_episode: 279.14285714285717
avg_envstep_per_sec: 2482.3160452976863
avg_train_sample_per_sec: 2482.3160452976863
avg_episode_per_sec: 8.892636805058242
collect_time: 0.7871680979952216
reward_mean: 1718.1641578102845
reward_std: 665.4334686093125
reward_max: 3024.3773598748508
reward_min: 976.4709112231911
total_envstep_count: 11928250
total_train_sample_count: 8979435
total_episode_count: 29035
total_duration: 2505.912111139556
[2023-06-29 12:10:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1797
train_sample_count: 1797
avg_envstep_per_episode: 256.7142857142857
avg_sample_per_episode: 256.7142857142857
avg_envstep_per_sec: 2714.037802837601
avg_train_sample_per_sec: 2714.037802837601
avg_episode_per_sec: 10.572211808493714
collect_time: 0.6621131062069907
reward_mean: 2347.681133256772
reward_std: 752.2329772774314
reward_max: 3532.5107170302326
reward_min: 1377.664569984071
total_envstep_count: 11933266
total_train_sample_count: 8982832
total_episode_count: 29042
total_duration: 2506.574224245763
[2023-06-29 12:10:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2132
train_sample_count: 2132
avg_envstep_per_episode: 236.88888888888889
avg_sample_per_episode: 236.88888888888889
avg_envstep_per_sec: 2779.6124755569144
avg_train_sample_per_sec: 2779.6124755569144
avg_episode_per_sec: 11.733823771112677
collect_time: 0.76701339440234
reward_mean: 2203.142202579692
reward_std: 1048.4544873815948
reward_max: 3661.5608903720054
reward_min: 771.405056234204
total_envstep_count: 11937674
total_train_sample_count: 8986164
total_episode_count: 29051
total_duration: 2507.3412376401657
[2023-06-29 12:10:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2057
train_sample_count: 2057
avg_envstep_per_episode: 342.8333333333333
avg_sample_per_episode: 342.8333333333333
avg_envstep_per_sec: 2523.512825734476
avg_train_sample_per_sec: 2523.512825734476
avg_episode_per_sec: 7.360756905399541
collect_time: 0.8151335626365616
reward_mean: 2368.6058570609907
reward_std: 536.3508536374003
reward_max: 2947.287291187279
reward_min: 1530.5032550264148
total_envstep_count: 11942378
total_train_sample_count: 8989421
total_episode_count: 29057
total_duration: 2508.1563712028023
[2023-06-29 12:10:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 122.625
avg_sample_per_episode: 122.625
avg_envstep_per_sec: 2613.0267947592033
avg_train_sample_per_sec: 2613.0267947592033
avg_episode_per_sec: 21.3090870112881
collect_time: 0.3754266898324713
reward_mean: 1753.1161754670195
reward_std: 1033.888534525903
reward_max: 3563.135474628728
reward_min: 54.236286121049055
total_envstep_count: 11946602
total_train_sample_count: 8992802
total_episode_count: 29065
total_duration: 2508.531797892635
[2023-06-29 12:10:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2303
train_sample_count: 2303
avg_envstep_per_episode: 230.3
avg_sample_per_episode: 230.3
avg_envstep_per_sec: 2437.36145510547
avg_train_sample_per_sec: 2437.36145510547
avg_episode_per_sec: 10.5834192579482
collect_time: 0.9448742184611038
reward_mean: 2104.8740602694743
reward_std: 519.4819063540237
reward_max: 3210.592200066651
reward_min: 1384.5758154461482
total_envstep_count: 11951426
total_train_sample_count: 8996305
total_episode_count: 29075
total_duration: 2509.476672111096
[2023-06-29 12:10:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2566
train_sample_count: 2566
avg_envstep_per_episode: 320.75
avg_sample_per_episode: 320.75
avg_envstep_per_sec: 2726.422061120813
avg_train_sample_per_sec: 2726.422061120813
avg_episode_per_sec: 8.500146722122565
collect_time: 0.9411602248204871
reward_mean: 2233.1422810796457
reward_std: 796.3847093235546
reward_max: 3650.5415530947917
reward_min: 1167.9193546490703
total_envstep_count: 11955306
total_train_sample_count: 8999671
total_episode_count: 29083
total_duration: 2510.4178323359165
[2023-06-29 12:11:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2550
train_sample_count: 2550
avg_envstep_per_episode: 283.3333333333333
avg_sample_per_episode: 283.3333333333333
avg_envstep_per_sec: 2598.8380912031666
avg_train_sample_per_sec: 2598.8380912031666
avg_episode_per_sec: 9.172369733658236
collect_time: 0.9812077207239346
reward_mean: 1638.277102569493
reward_std: 1018.1477109998682
reward_max: 3626.403391516784
reward_min: 520.2585266713537
total_envstep_count: 11960106
total_train_sample_count: 9003021
total_episode_count: 29092
total_duration: 2511.3990400566404
[2023-06-29 12:11:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2382
train_sample_count: 2382
avg_envstep_per_episode: 340.2857142857143
avg_sample_per_episode: 340.2857142857143
avg_envstep_per_sec: 2625.713915089382
avg_train_sample_per_sec: 2625.713915089382
avg_episode_per_sec: 7.716203780699276
collect_time: 0.9071818473106252
reward_mean: 2256.39069710525
reward_std: 917.8111910533852
reward_max: 3539.8598600953997
reward_min: 1202.9804658728126
total_envstep_count: 11964714
total_train_sample_count: 9006603
total_episode_count: 29099
total_duration: 2512.306221903951
[2023-06-29 12:11:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2315
train_sample_count: 2315
avg_envstep_per_episode: 289.375
avg_sample_per_episode: 289.375
avg_envstep_per_sec: 2457.7211561153445
avg_train_sample_per_sec: 2457.7211561153445
avg_episode_per_sec: 8.4932048591459
collect_time: 0.9419294757014142
reward_mean: 2236.472716132079
reward_std: 618.516477344981
reward_max: 3160.746635838295
reward_min: 1345.5025221236422
total_envstep_count: 11969274
total_train_sample_count: 9010118
total_episode_count: 29107
total_duration: 2513.2481513796524
[2023-06-29 12:11:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2037
train_sample_count: 2037
avg_envstep_per_episode: 254.625
avg_sample_per_episode: 254.625
avg_envstep_per_sec: 2751.3993342394247
avg_train_sample_per_sec: 2751.3993342394247
avg_episode_per_sec: 10.805692034322728
collect_time: 0.7403505462296306
reward_mean: 1882.1572295751682
reward_std: 820.1016981567926
reward_max: 3559.1186265065658
reward_min: 972.902041688547
total_envstep_count: 11973386
total_train_sample_count: 9013355
total_episode_count: 29115
total_duration: 2513.9885019258822
[2023-06-29 12:11:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2625
train_sample_count: 2625
avg_envstep_per_episode: 291.6666666666667
avg_sample_per_episode: 291.6666666666667
avg_envstep_per_sec: 2754.314143822633
avg_train_sample_per_sec: 2754.314143822633
avg_episode_per_sec: 9.443362778820456
collect_time: 0.9530503286588937
reward_mean: 1933.3128767991855
reward_std: 850.0092932379476
reward_max: 3285.734617112253
reward_min: 391.1255296127193
total_envstep_count: 11977890
total_train_sample_count: 9016780
total_episode_count: 29124
total_duration: 2514.941552254541
[2023-06-29 12:11:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 387.6666666666667
avg_sample_per_episode: 387.6666666666667
avg_envstep_per_sec: 2617.245475073356
avg_train_sample_per_sec: 2617.245475073356
avg_episode_per_sec: 6.751278095632045
collect_time: 0.8887206118619069
reward_mean: 2144.429029482691
reward_std: 771.8208016402843
reward_max: 3176.7289913569202
reward_min: 1112.7953586647186
total_envstep_count: 11982946
total_train_sample_count: 9020306
total_episode_count: 29130
total_duration: 2515.830272866403
[2023-06-29 12:11:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1358
train_sample_count: 1358
avg_envstep_per_episode: 226.33333333333334
avg_sample_per_episode: 226.33333333333334
avg_envstep_per_sec: 2616.921325141025
avg_train_sample_per_sec: 2616.921325141025
avg_episode_per_sec: 11.562244440976546
collect_time: 0.5189303885269909
reward_mean: 2555.816197789019
reward_std: 1043.1312930582171
reward_max: 3678.2911664558324
reward_min: 1036.9733650509752
total_envstep_count: 11986778
total_train_sample_count: 9023664
total_episode_count: 29136
total_duration: 2516.3492032549298
[2023-06-29 12:11:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 291.2857142857143
avg_sample_per_episode: 291.2857142857143
avg_envstep_per_sec: 2407.8142315162913
avg_train_sample_per_sec: 2407.8142315162913
avg_episode_per_sec: 8.266159696230526
collect_time: 0.8468261269126085
reward_mean: 2558.1935386199443
reward_std: 1074.4248098121477
reward_max: 3733.9202773386246
reward_min: 981.2434698576063
total_envstep_count: 11990946
total_train_sample_count: 9026903
total_episode_count: 29143
total_duration: 2517.1960293818424
[2023-06-29 12:11:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2104
train_sample_count: 2104
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2821.728051763387
avg_train_sample_per_sec: 2821.728051763387
avg_episode_per_sec: 10.72900399910033
collect_time: 0.7456423728307708
reward_mean: 2016.630670728367
reward_std: 918.6782635332511
reward_max: 3480.634751134657
reward_min: 928.3096234324202
total_envstep_count: 11995658
total_train_sample_count: 9030207
total_episode_count: 29151
total_duration: 2517.9416717546733
[2023-06-29 12:11:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2242
train_sample_count: 2242
avg_envstep_per_episode: 224.2
avg_sample_per_episode: 224.2
avg_envstep_per_sec: 2828.644287932898
avg_train_sample_per_sec: 2828.644287932898
avg_episode_per_sec: 12.61661145375958
collect_time: 0.7926058463994415
reward_mean: 1752.9098047290122
reward_std: 417.8200744105106
reward_max: 2359.605175757389
reward_min: 1038.1815903831025
total_envstep_count: 12000362
total_train_sample_count: 9033649
total_episode_count: 29161
total_duration: 2518.734277601073
[2023-06-29 12:11:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2081
train_sample_count: 2081
avg_envstep_per_episode: 231.22222222222223
avg_sample_per_episode: 231.22222222222223
avg_envstep_per_sec: 2584.595552835695
avg_train_sample_per_sec: 2584.595552835695
avg_episode_per_sec: 11.177972117021266
collect_time: 0.8051549874860793
reward_mean: 1691.338820811593
reward_std: 933.274154708102
reward_max: 3326.8359159992656
reward_min: 565.4847740250901
total_envstep_count: 12004594
total_train_sample_count: 9036930
total_episode_count: 29170
total_duration: 2519.539432588559
[2023-06-29 12:11:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 266.09090909090907
avg_sample_per_episode: 266.09090909090907
avg_envstep_per_sec: 2594.794960565861
avg_train_sample_per_sec: 2594.794960565861
avg_episode_per_sec: 9.75153555388605
collect_time: 1.1280274721058088
reward_mean: 1768.6069241877628
reward_std: 1034.3195678667237
reward_max: 3619.198537946115
reward_min: 540.6606351600514
total_envstep_count: 12009026
total_train_sample_count: 9040257
total_episode_count: 29181
total_duration: 2520.667460060665
[2023-06-29 12:11:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2923
train_sample_count: 2923
avg_envstep_per_episode: 292.3
avg_sample_per_episode: 292.3
avg_envstep_per_sec: 2525.8281801952508
avg_train_sample_per_sec: 2525.8281801952508
avg_episode_per_sec: 8.641218543261207
collect_time: 1.157244195356965
reward_mean: 1713.6009621945045
reward_std: 870.8348248565622
reward_max: 3620.395761551341
reward_min: 865.6154516350284
total_envstep_count: 12013394
total_train_sample_count: 9043580
total_episode_count: 29191
total_duration: 2521.824704256022
[2023-06-29 12:11:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 245.4
avg_sample_per_episode: 245.4
avg_envstep_per_sec: 2784.1460336031446
avg_train_sample_per_sec: 2784.1460336031446
avg_episode_per_sec: 11.345338360241012
collect_time: 0.8814192827465013
reward_mean: 1303.6044537896855
reward_std: 646.6032299486097
reward_max: 2981.2804561411454
reward_min: 515.1297130688592
total_envstep_count: 12017682
total_train_sample_count: 9046834
total_episode_count: 29201
total_duration: 2522.7061235387687
[2023-06-29 12:11:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 286.14285714285717
avg_sample_per_episode: 286.14285714285717
avg_envstep_per_sec: 2788.281362671002
avg_train_sample_per_sec: 2788.281362671002
avg_episode_per_sec: 9.744368217022974
collect_time: 0.7183636582791807
reward_mean: 1870.4523975967163
reward_std: 820.9422329612011
reward_max: 3564.037903776406
reward_min: 1158.634438050142
total_envstep_count: 12022042
total_train_sample_count: 9050037
total_episode_count: 29208
total_duration: 2523.4244871970477
[2023-06-29 12:11:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2184
train_sample_count: 2184
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2539.08841778156
avg_train_sample_per_sec: 2539.08841778156
avg_episode_per_sec: 9.300690175024029
collect_time: 0.860151219904423
reward_mean: 2318.6152270897164
reward_std: 1090.6646455347575
reward_max: 3713.159556908841
reward_min: 1091.657752337274
total_envstep_count: 12027250
total_train_sample_count: 9053421
total_episode_count: 29216
total_duration: 2524.284638416952
[2023-06-29 12:11:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3033
train_sample_count: 3033
avg_envstep_per_episode: 303.3
avg_sample_per_episode: 303.3
avg_envstep_per_sec: 2547.593029667492
avg_train_sample_per_sec: 2547.593029667492
avg_episode_per_sec: 8.399581370482993
collect_time: 1.1905355230132117
reward_mean: 2213.515304613443
reward_std: 974.5884737180859
reward_max: 3688.497814987024
reward_min: 694.5229562364226
total_envstep_count: 12031938
total_train_sample_count: 9056854
total_episode_count: 29226
total_duration: 2525.4751739399653
[2023-06-29 12:11:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 208.5
avg_sample_per_episode: 208.5
avg_envstep_per_sec: 2832.723753717962
avg_train_sample_per_sec: 2832.723753717962
avg_episode_per_sec: 13.586205053803177
collect_time: 0.44162442538142205
reward_mean: 1142.1469308154751
reward_std: 308.81567683701564
reward_max: 1700.5111232865054
reward_min: 687.6034709446246
total_envstep_count: 12036090
total_train_sample_count: 9060105
total_episode_count: 29232
total_duration: 2525.916798365347
[2023-06-29 12:11:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2605
train_sample_count: 2605
avg_envstep_per_episode: 217.08333333333334
avg_sample_per_episode: 217.08333333333334
avg_envstep_per_sec: 2763.7686062452017
avg_train_sample_per_sec: 2763.7686062452017
avg_episode_per_sec: 12.731371698634327
collect_time: 0.9425535821318626
reward_mean: 1961.7331803262832
reward_std: 1115.8029566477494
reward_max: 3753.689848429606
reward_min: 561.453296302737
total_envstep_count: 12040634
total_train_sample_count: 9063510
total_episode_count: 29244
total_duration: 2526.859351947479
[2023-06-29 12:12:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1987
train_sample_count: 1987
avg_envstep_per_episode: 283.85714285714283
avg_sample_per_episode: 283.85714285714283
avg_envstep_per_sec: 2757.538357193855
avg_train_sample_per_sec: 2757.538357193855
avg_episode_per_sec: 9.714528686641664
collect_time: 0.7205702124927192
reward_mean: 2035.653173139652
reward_std: 826.5714297543914
reward_max: 3617.7729572156327
reward_min: 1006.4583021293386
total_envstep_count: 12045122
total_train_sample_count: 9067097
total_episode_count: 29251
total_duration: 2527.579922159972
[2023-06-29 12:12:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2853
train_sample_count: 2853
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2596.467580032051
avg_train_sample_per_sec: 2596.467580032051
avg_episode_per_sec: 8.190749463823504
collect_time: 1.0988005480756984
reward_mean: 2200.4599630200128
reward_std: 1051.7143665124593
reward_max: 3590.946255676363
reward_min: 52.108119164445455
total_envstep_count: 12049122
total_train_sample_count: 9070350
total_episode_count: 29260
total_duration: 2528.6787227080476
[2023-06-29 12:12:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1508
train_sample_count: 1508
avg_envstep_per_episode: 167.55555555555554
avg_sample_per_episode: 167.55555555555554
avg_envstep_per_sec: 2763.418422144627
avg_train_sample_per_sec: 2763.418422144627
avg_episode_per_sec: 16.49255026478889
collect_time: 0.5457009289348498
reward_mean: 818.1145167492778
reward_std: 229.7010364849327
reward_max: 1191.1448245525717
reward_min: 532.1726215173522
total_envstep_count: 12053546
total_train_sample_count: 9073858
total_episode_count: 29269
total_duration: 2529.2244236369825
[2023-06-29 12:12:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2247
train_sample_count: 2247
avg_envstep_per_episode: 280.875
avg_sample_per_episode: 280.875
avg_envstep_per_sec: 2788.3873843956985
avg_train_sample_per_sec: 2788.3873843956985
avg_episode_per_sec: 9.927502926197414
collect_time: 0.8058421195615083
reward_mean: 2372.5922623206047
reward_std: 1058.55057311324
reward_max: 3599.0002397606413
reward_min: 982.8976628214012
total_envstep_count: 12058010
total_train_sample_count: 9077305
total_episode_count: 29277
total_duration: 2530.030265756544
[2023-06-29 12:12:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1936
train_sample_count: 1936
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2812.209730487013
avg_train_sample_per_sec: 2812.209730487013
avg_episode_per_sec: 11.620701365648815
collect_time: 0.6884266059575603
reward_mean: 1908.4865753305958
reward_std: 1162.0776176357774
reward_max: 3584.177975613814
reward_min: 975.7080194420656
total_envstep_count: 12062682
total_train_sample_count: 9080841
total_episode_count: 29285
total_duration: 2530.7186923625013
[2023-06-29 12:12:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1045
train_sample_count: 1045
avg_envstep_per_episode: 209.0
avg_sample_per_episode: 209.0
avg_envstep_per_sec: 2696.122793826107
avg_train_sample_per_sec: 2696.122793826107
avg_episode_per_sec: 12.900109061368934
collect_time: 0.38759362236503525
reward_mean: 2326.05242459804
reward_std: 1498.2869011403016
reward_max: 3551.35780576447
reward_min: 49.35748269823603
total_envstep_count: 12067458
total_train_sample_count: 9084286
total_episode_count: 29290
total_duration: 2531.106285984866
[2023-06-29 12:12:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1791
train_sample_count: 1791
avg_envstep_per_episode: 255.85714285714286
avg_sample_per_episode: 255.85714285714286
avg_envstep_per_sec: 2419.118914950738
avg_train_sample_per_sec: 2419.118914950738
avg_episode_per_sec: 9.4549594665858
collect_time: 0.7403521955581382
reward_mean: 3126.6085337451564
reward_std: 662.9185592801254
reward_max: 3614.3563074442586
reward_min: 1680.7958605615343
total_envstep_count: 12071386
total_train_sample_count: 9087677
total_episode_count: 29297
total_duration: 2531.846638180424
[2023-06-29 12:12:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1649
train_sample_count: 1649
avg_envstep_per_episode: 206.125
avg_sample_per_episode: 206.125
avg_envstep_per_sec: 2753.2304202701607
avg_train_sample_per_sec: 2753.2304202701607
avg_episode_per_sec: 13.357091183845535
collect_time: 0.5989327983083202
reward_mean: 1762.1343672565042
reward_std: 1031.5787951867976
reward_max: 3651.172369351506
reward_min: 496.39479152459506
total_envstep_count: 12075522
total_train_sample_count: 9090926
total_episode_count: 29305
total_duration: 2532.4455709787326
[2023-06-29 12:12:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2213
train_sample_count: 2213
avg_envstep_per_episode: 201.1818181818182
avg_sample_per_episode: 201.1818181818182
avg_envstep_per_sec: 2734.185646062044
avg_train_sample_per_sec: 2734.185646062044
avg_episode_per_sec: 13.59062002109466
collect_time: 0.8093817635197192
reward_mean: 1511.5521356337592
reward_std: 1031.048519791036
reward_max: 3316.327126834336
reward_min: 257.833321147753
total_envstep_count: 12080202
total_train_sample_count: 9094339
total_episode_count: 29316
total_duration: 2533.2549527422525
[2023-06-29 12:12:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 194.0
avg_sample_per_episode: 194.0
avg_envstep_per_sec: 2620.9058809584785
avg_train_sample_per_sec: 2620.9058809584785
avg_episode_per_sec: 13.50982412865195
collect_time: 1.110303128831089
reward_mean: 1243.7644732585402
reward_std: 928.1044070193616
reward_max: 3311.8335723316827
reward_min: 239.3568846236197
total_envstep_count: 12084050
total_train_sample_count: 9097649
total_episode_count: 29331
total_duration: 2534.3652558710837
[2023-06-29 12:12:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2799
train_sample_count: 2799
avg_envstep_per_episode: 311.0
avg_sample_per_episode: 311.0
avg_envstep_per_sec: 2761.4048572761276
avg_train_sample_per_sec: 2761.4048572761276
avg_episode_per_sec: 8.879115296707806
collect_time: 1.0136144986581057
reward_mean: 1583.9104446801712
reward_std: 862.6724957043376
reward_max: 3543.1166837759765
reward_min: 500.45875388285793
total_envstep_count: 12088418
total_train_sample_count: 9101248
total_episode_count: 29340
total_duration: 2535.378870369742
[2023-06-29 12:12:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 244.4
avg_sample_per_episode: 244.4
avg_envstep_per_sec: 2837.6228944075942
avg_train_sample_per_sec: 2837.6228944075942
avg_episode_per_sec: 11.610568307723382
collect_time: 0.4306421414939686
reward_mean: 1637.8096518822417
reward_std: 608.7061666296827
reward_max: 2788.1265071829175
reward_min: 993.3684144695413
total_envstep_count: 12092106
total_train_sample_count: 9104470
total_episode_count: 29345
total_duration: 2535.809512511236
[2023-06-29 12:12:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2434
train_sample_count: 2434
avg_envstep_per_episode: 304.25
avg_sample_per_episode: 304.25
avg_envstep_per_sec: 2516.179318374483
avg_train_sample_per_sec: 2516.179318374483
avg_episode_per_sec: 8.270104579702492
collect_time: 0.9673396415850151
reward_mean: 2550.310645061005
reward_std: 1103.621251181395
reward_max: 3578.6648271867116
reward_min: 672.3107305365181
total_envstep_count: 12096418
total_train_sample_count: 9107704
total_episode_count: 29353
total_duration: 2536.776852152821
[2023-06-29 12:12:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1875
train_sample_count: 1875
avg_envstep_per_episode: 208.33333333333334
avg_sample_per_episode: 208.33333333333334
avg_envstep_per_sec: 2639.296835237129
avg_train_sample_per_sec: 2639.296835237129
avg_episode_per_sec: 12.66862480913822
collect_time: 0.7104164923653006
reward_mean: 1318.8891200574178
reward_std: 918.2306017685302
reward_max: 3313.39081337898
reward_min: 513.7695505115712
total_envstep_count: 12101138
total_train_sample_count: 9111179
total_episode_count: 29362
total_duration: 2537.4872686451863
[2023-06-29 12:12:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2803
train_sample_count: 2803
avg_envstep_per_episode: 254.8181818181818
avg_sample_per_episode: 254.8181818181818
avg_envstep_per_sec: 2501.989400875359
avg_train_sample_per_sec: 2501.989400875359
avg_episode_per_sec: 9.818724013424527
collect_time: 1.1203085029134527
reward_mean: 2042.1334297014232
reward_std: 888.5753227506545
reward_max: 3570.4126065565374
reward_min: 1017.5815627328031
total_envstep_count: 12105490
total_train_sample_count: 9114382
total_episode_count: 29373
total_duration: 2538.6075771480996
[2023-06-29 12:12:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 956
train_sample_count: 956
avg_envstep_per_episode: 318.6666666666667
avg_sample_per_episode: 318.6666666666667
avg_envstep_per_sec: 2734.328483459279
avg_train_sample_per_sec: 2734.328483459279
avg_episode_per_sec: 8.580528713784348
collect_time: 0.34962880494538695
reward_mean: 1903.4136985550347
reward_std: 1243.5787518614477
reward_max: 3537.8202535225196
reward_min: 523.8328095579933
total_envstep_count: 12109482
total_train_sample_count: 9117738
total_episode_count: 29376
total_duration: 2538.957205953045
[2023-06-29 12:12:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1907
train_sample_count: 1907
avg_envstep_per_episode: 272.42857142857144
avg_sample_per_episode: 272.42857142857144
avg_envstep_per_sec: 2587.777178639037
avg_train_sample_per_sec: 2587.777178639037
avg_episode_per_sec: 9.498919900615238
collect_time: 0.7369258898105473
reward_mean: 2983.410583594199
reward_std: 788.6762037131922
reward_max: 3617.9827071491204
reward_min: 1447.6691937989676
total_envstep_count: 12114018
total_train_sample_count: 9121245
total_episode_count: 29383
total_duration: 2539.6941318428558
[2023-06-29 12:12:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1704
train_sample_count: 1704
avg_envstep_per_episode: 340.8
avg_sample_per_episode: 340.8
avg_envstep_per_sec: 2506.1675958231613
avg_train_sample_per_sec: 2506.1675958231613
avg_episode_per_sec: 7.353778156758103
collect_time: 0.6799226048728453
reward_mean: 2760.340805725242
reward_std: 1038.1545550768376
reward_max: 3662.0063591317344
reward_min: 1036.6430614902738
total_envstep_count: 12118506
total_train_sample_count: 9124549
total_episode_count: 29388
total_duration: 2540.3740544477287
[2023-06-29 12:12:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1948
train_sample_count: 1948
avg_envstep_per_episode: 278.2857142857143
avg_sample_per_episode: 278.2857142857143
avg_envstep_per_sec: 2482.0088015273054
avg_train_sample_per_sec: 2482.0088015273054
avg_episode_per_sec: 8.918922798096068
collect_time: 0.7848481434881686
reward_mean: 2580.2597022380573
reward_std: 891.9655512948164
reward_max: 3678.5172684046356
reward_min: 1626.1970957364322
total_envstep_count: 12123210
total_train_sample_count: 9128097
total_episode_count: 29395
total_duration: 2541.1589025912167
[2023-06-29 12:12:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2106
train_sample_count: 2106
avg_envstep_per_episode: 351.0
avg_sample_per_episode: 351.0
avg_envstep_per_sec: 2692.3901616556245
avg_train_sample_per_sec: 2692.3901616556245
avg_episode_per_sec: 7.670627241184116
collect_time: 0.7822046113498509
reward_mean: 2579.4697127640306
reward_std: 766.0214867573143
reward_max: 3565.925854344187
reward_min: 1681.441502336053
total_envstep_count: 12127810
total_train_sample_count: 9131403
total_episode_count: 29401
total_duration: 2541.9411072025664
[2023-06-29 12:13:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 464
train_sample_count: 464
avg_envstep_per_episode: 154.66666666666666
avg_sample_per_episode: 154.66666666666666
avg_envstep_per_sec: 2688.305885452384
avg_train_sample_per_sec: 2688.305885452384
avg_episode_per_sec: 17.38128805249386
collect_time: 0.17259940638113763
reward_mean: 3246.4388173304487
reward_std: 230.81864907601062
reward_max: 3432.824750276184
reward_min: 2921.1659375908944
total_envstep_count: 12131706
total_train_sample_count: 9134667
total_episode_count: 29404
total_duration: 2542.1137066089477
[2023-06-29 12:13:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 307.125
avg_sample_per_episode: 307.125
avg_envstep_per_sec: 2712.4178102895507
avg_train_sample_per_sec: 2712.4178102895507
avg_episode_per_sec: 8.831641221944
collect_time: 0.9058338987007739
reward_mean: 2864.006835171106
reward_std: 780.0880806949407
reward_max: 3563.8378420172585
reward_min: 1004.8126668293692
total_envstep_count: 12136426
total_train_sample_count: 9137924
total_episode_count: 29412
total_duration: 2543.0195405076483
[2023-06-29 12:13:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2771.268851400762
avg_train_sample_per_sec: 2771.268851400762
avg_episode_per_sec: 9.655989029270946
collect_time: 0.7249386861128734
reward_mean: 2055.1525890691532
reward_std: 908.9627862725665
reward_max: 3666.248843611768
reward_min: 673.61008368129
total_envstep_count: 12140906
total_train_sample_count: 9141133
total_episode_count: 29419
total_duration: 2543.7444791937614
[2023-06-29 12:13:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1287
train_sample_count: 1287
avg_envstep_per_episode: 257.4
avg_sample_per_episode: 257.4
avg_envstep_per_sec: 2697.0430456241206
avg_train_sample_per_sec: 2697.0430456241206
avg_episode_per_sec: 10.47802271027242
collect_time: 0.4771892692213877
reward_mean: 2486.937019472317
reward_std: 876.1232682500786
reward_max: 3571.446009725022
reward_min: 1677.6524097295114
total_envstep_count: 12145122
total_train_sample_count: 9144420
total_episode_count: 29424
total_duration: 2544.221668462983
[2023-06-29 12:13:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2280
train_sample_count: 2280
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2550.6279762575846
avg_train_sample_per_sec: 2550.6279762575846
avg_episode_per_sec: 11.186964808147302
collect_time: 0.8938975112102925
reward_mean: 2177.009549780187
reward_std: 1017.6441314666895
reward_max: 3634.845870004953
reward_min: 965.4701227731043
total_envstep_count: 12149402
total_train_sample_count: 9147900
total_episode_count: 29434
total_duration: 2545.115565974193
[2023-06-29 12:13:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 420.6666666666667
avg_sample_per_episode: 420.6666666666667
avg_envstep_per_sec: 2772.2266829811238
avg_train_sample_per_sec: 2772.2266829811238
avg_episode_per_sec: 6.5900792780850805
collect_time: 0.45522972841560844
reward_mean: 2858.1994788409484
reward_std: 669.1376395070002
reward_max: 3544.7008424099004
reward_min: 1950.8967788250177
total_envstep_count: 12153482
total_train_sample_count: 9151162
total_episode_count: 29437
total_duration: 2545.570795702609
[2023-06-29 12:13:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 250.75
avg_sample_per_episode: 250.75
avg_envstep_per_sec: 2660.5717436048967
avg_train_sample_per_sec: 2660.5717436048967
avg_episode_per_sec: 10.610455607596796
collect_time: 0.7539732784209774
reward_mean: 2510.4878587773696
reward_std: 1170.4988742949718
reward_max: 3599.804062494798
reward_min: 197.1917314603813
total_envstep_count: 12157954
total_train_sample_count: 9154368
total_episode_count: 29445
total_duration: 2546.32476898103
[2023-06-29 12:13:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 956
train_sample_count: 956
avg_envstep_per_episode: 318.6666666666667
avg_sample_per_episode: 318.6666666666667
avg_envstep_per_sec: 2717.933950127615
avg_train_sample_per_sec: 2717.933950127615
avg_episode_per_sec: 8.52908143345486
collect_time: 0.3517377602038905
reward_mean: 2859.158856128913
reward_std: 877.2099899240783
reward_max: 3562.9955491168557
reward_min: 1622.5335062509118
total_envstep_count: 12162138
total_train_sample_count: 9157724
total_episode_count: 29448
total_duration: 2546.676506741234
[2023-06-29 12:13:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2087
train_sample_count: 2087
avg_envstep_per_episode: 260.875
avg_sample_per_episode: 260.875
avg_envstep_per_sec: 2738.5506433224136
avg_train_sample_per_sec: 2738.5506433224136
avg_episode_per_sec: 10.497558766928273
collect_time: 0.7620819447282701
reward_mean: 2799.6292915482977
reward_std: 862.2483916683353
reward_max: 3617.2053004687095
reward_min: 1276.307608746307
total_envstep_count: 12166418
total_train_sample_count: 9161011
total_episode_count: 29456
total_duration: 2547.4385886859623
[2023-06-29 12:13:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2507
train_sample_count: 2507
avg_envstep_per_episode: 358.14285714285717
avg_sample_per_episode: 358.14285714285717
avg_envstep_per_sec: 2591.812691573826
avg_train_sample_per_sec: 2591.812691573826
avg_episode_per_sec: 7.236812461514472
collect_time: 0.9672766894577072
reward_mean: 2398.6422417817926
reward_std: 1043.4271172863014
reward_max: 3537.102933749664
reward_min: 547.8260646762155
total_envstep_count: 12171218
total_train_sample_count: 9164318
total_episode_count: 29463
total_duration: 2548.40586537542
[2023-06-29 12:13:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 822
train_sample_count: 822
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 2778.656985165494
avg_train_sample_per_sec: 2778.656985165494
avg_episode_per_sec: 13.521445183287076
collect_time: 0.29582636661827566
reward_mean: 2399.9968199944624
reward_std: 1201.702021664684
reward_max: 3647.6862195258063
reward_min: 1070.2603564538224
total_envstep_count: 12175298
total_train_sample_count: 9167540
total_episode_count: 29467
total_duration: 2548.7016917420383
[2023-06-29 12:13:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2951
train_sample_count: 2951
avg_envstep_per_episode: 327.8888888888889
avg_sample_per_episode: 327.8888888888889
avg_envstep_per_sec: 2774.8503412716295
avg_train_sample_per_sec: 2774.8503412716295
avg_episode_per_sec: 8.46277637121134
collect_time: 1.0634807780832052
reward_mean: 2631.6936405751994
reward_std: 918.9383749587639
reward_max: 3584.4160734391558
reward_min: 677.1929012542098
total_envstep_count: 12180154
total_train_sample_count: 9170891
total_episode_count: 29476
total_duration: 2549.7651725201217
[2023-06-29 12:13:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1108
train_sample_count: 1108
avg_envstep_per_episode: 277.0
avg_sample_per_episode: 277.0
avg_envstep_per_sec: 2781.300217982204
avg_train_sample_per_sec: 2781.300217982204
avg_episode_per_sec: 10.040795010766079
collect_time: 0.3983748294543475
reward_mean: 1880.4065027272295
reward_std: 1049.461955324147
reward_max: 3556.6214099786966
reward_min: 732.4987639886541
total_envstep_count: 12185258
total_train_sample_count: 9174399
total_episode_count: 29480
total_duration: 2550.163547349576
[2023-06-29 12:13:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 144.8
avg_sample_per_episode: 144.8
avg_envstep_per_sec: 2614.2468407413553
avg_train_sample_per_sec: 2614.2468407413553
avg_episode_per_sec: 18.054190889097757
collect_time: 0.5538880175482481
reward_mean: 2330.7964135410953
reward_std: 1106.0042198386316
reward_max: 3613.292671026747
reward_min: 703.4374452375181
total_envstep_count: 12189722
total_train_sample_count: 9177847
total_episode_count: 29490
total_duration: 2550.7174353671244
[2023-06-29 12:13:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 175.66666666666666
avg_sample_per_episode: 175.66666666666666
avg_envstep_per_sec: 2805.6339499297223
avg_train_sample_per_sec: 2805.6339499297223
avg_episode_per_sec: 15.971350758613221
collect_time: 0.37567267106473434
reward_mean: 2123.763993448808
reward_std: 657.7570867829717
reward_max: 2937.743495972442
reward_min: 849.1720013799874
total_envstep_count: 12194218
total_train_sample_count: 9181301
total_episode_count: 29496
total_duration: 2551.0931080381893
[2023-06-29 12:13:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 270.125
avg_sample_per_episode: 270.125
avg_envstep_per_sec: 2733.6576861474364
avg_train_sample_per_sec: 2733.6576861474364
avg_episode_per_sec: 10.119972924192268
collect_time: 0.7905159489978106
reward_mean: 2835.8736541371172
reward_std: 659.6798059019759
reward_max: 3655.787041407392
reward_min: 1748.1506502182353
total_envstep_count: 12198746
total_train_sample_count: 9184662
total_episode_count: 29504
total_duration: 2551.883623987187
[2023-06-29 12:13:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1501
train_sample_count: 1501
avg_envstep_per_episode: 250.16666666666666
avg_sample_per_episode: 250.16666666666666
avg_envstep_per_sec: 2788.596400808334
avg_train_sample_per_sec: 2788.596400808334
avg_episode_per_sec: 11.146954300366424
collect_time: 0.538263622360304
reward_mean: 2233.306350691451
reward_std: 937.4667939793472
reward_max: 3457.18250978978
reward_min: 744.3093199265354
total_envstep_count: 12203658
total_train_sample_count: 9188163
total_episode_count: 29510
total_duration: 2552.4218876095474
[2023-06-29 12:13:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 310.5
avg_sample_per_episode: 310.5
avg_envstep_per_sec: 2689.286737033651
avg_train_sample_per_sec: 2689.286737033651
avg_episode_per_sec: 8.661148911541549
collect_time: 0.923664987371303
reward_mean: 2760.4926983977784
reward_std: 830.1359309967182
reward_max: 3648.6302894118744
reward_min: 1344.4131081459539
total_envstep_count: 12208586
total_train_sample_count: 9191447
total_episode_count: 29518
total_duration: 2553.345552596919
[2023-06-29 12:13:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1208
train_sample_count: 1208
avg_envstep_per_episode: 241.6
avg_sample_per_episode: 241.6
avg_envstep_per_sec: 2399.7555607412646
avg_train_sample_per_sec: 2399.7555607412646
avg_episode_per_sec: 9.932763082538347
collect_time: 0.5033846028996631
reward_mean: 1758.3484527454293
reward_std: 1024.5000240628945
reward_max: 3169.4260805820145
reward_min: 43.10358854432523
total_envstep_count: 12213322
total_train_sample_count: 9194655
total_episode_count: 29523
total_duration: 2553.8489371998185
[2023-06-29 12:13:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2116
train_sample_count: 2116
avg_envstep_per_episode: 235.11111111111111
avg_sample_per_episode: 235.11111111111111
avg_envstep_per_sec: 2507.056464724528
avg_train_sample_per_sec: 2507.056464724528
avg_episode_per_sec: 10.66328364013268
collect_time: 0.8440176875842736
reward_mean: 2767.72777329623
reward_std: 995.4849780505713
reward_max: 3663.006391017438
reward_min: 1029.5921968763298
total_envstep_count: 12217706
total_train_sample_count: 9197971
total_episode_count: 29532
total_duration: 2554.6929548874027
[2023-06-29 12:14:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1405
train_sample_count: 1405
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2796.9372349522378
avg_train_sample_per_sec: 2796.9372349522378
avg_episode_per_sec: 9.953513291644976
collect_time: 0.5023351909518243
reward_mean: 2069.1483774560775
reward_std: 804.4062074814115
reward_max: 3609.0605348963036
reward_min: 1315.9567693507581
total_envstep_count: 12221658
total_train_sample_count: 9201376
total_episode_count: 29537
total_duration: 2555.1952900783544
[2023-06-29 12:14:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1327
train_sample_count: 1327
avg_envstep_per_episode: 265.4
avg_sample_per_episode: 265.4
avg_envstep_per_sec: 2670.582971430553
avg_train_sample_per_sec: 2670.582971430553
avg_episode_per_sec: 10.06248293681444
collect_time: 0.4968952525332569
reward_mean: 3256.188275046245
reward_std: 664.8113606233992
reward_max: 3602.713681774288
reward_min: 1926.7999029046712
total_envstep_count: 12225938
total_train_sample_count: 9204703
total_episode_count: 29542
total_duration: 2555.6921853308877
[2023-06-29 12:14:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1832
train_sample_count: 1832
avg_envstep_per_episode: 305.3333333333333
avg_sample_per_episode: 305.3333333333333
avg_envstep_per_sec: 2645.3666988331915
avg_train_sample_per_sec: 2645.3666988331915
avg_episode_per_sec: 8.663864734169842
collect_time: 0.6925315877031535
reward_mean: 2678.8107924023034
reward_std: 1240.5812623379272
reward_max: 3632.532272407405
reward_min: 197.75654596401367
total_envstep_count: 12230290
total_train_sample_count: 9208135
total_episode_count: 29548
total_duration: 2556.384716918591
[2023-06-29 12:14:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 209.0
avg_sample_per_episode: 209.0
avg_envstep_per_sec: 2677.8766751496855
avg_train_sample_per_sec: 2677.8766751496855
avg_episode_per_sec: 12.812807058132465
collect_time: 0.31218764021433887
reward_mean: 2870.0228640782684
reward_std: 917.1647017440284
reward_max: 3584.3998078203836
reward_min: 1337.6657340006818
total_envstep_count: 12234834
total_train_sample_count: 9211371
total_episode_count: 29552
total_duration: 2556.6969045588053
[2023-06-29 12:14:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2781.9810947869328
avg_train_sample_per_sec: 2781.9810947869328
avg_episode_per_sec: 10.952681475539107
collect_time: 0.7304147407067938
reward_mean: 2537.967247339548
reward_std: 1011.8410987142137
reward_max: 3572.609341014103
reward_min: 878.9855863173563
total_envstep_count: 12239546
total_train_sample_count: 9214603
total_episode_count: 29560
total_duration: 2557.427319299512
[2023-06-29 12:14:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2178
train_sample_count: 2178
avg_envstep_per_episode: 272.25
avg_sample_per_episode: 272.25
avg_envstep_per_sec: 2735.8070930021972
avg_train_sample_per_sec: 2735.8070930021972
avg_episode_per_sec: 10.04887821121101
collect_time: 0.7961087627746167
reward_mean: 2308.305637407191
reward_std: 1302.110042477774
reward_max: 3608.1827723436663
reward_min: 600.277431789287
total_envstep_count: 12244474
total_train_sample_count: 9217981
total_episode_count: 29568
total_duration: 2558.2234280622865
[2023-06-29 12:14:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1370
train_sample_count: 1370
avg_envstep_per_episode: 342.5
avg_sample_per_episode: 342.5
avg_envstep_per_sec: 2624.4490540626384
avg_train_sample_per_sec: 2624.4490540626384
avg_episode_per_sec: 7.662624975365367
collect_time: 0.5220143244462089
reward_mean: 3193.9861755002357
reward_std: 574.3826900322662
reward_max: 3576.8748392169364
reward_min: 2201.2152062766604
total_envstep_count: 12249362
total_train_sample_count: 9221351
total_episode_count: 29572
total_duration: 2558.7454423867325
[2023-06-29 12:14:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1734
train_sample_count: 1734
avg_envstep_per_episode: 289.0
avg_sample_per_episode: 289.0
avg_envstep_per_sec: 2683.0921952450317
avg_train_sample_per_sec: 2683.0921952450317
avg_episode_per_sec: 9.284056038910144
collect_time: 0.6462692571924997
reward_mean: 3443.1469304032976
reward_std: 246.04694843051954
reward_max: 3631.0080755226313
reward_min: 2902.7313045506994
total_envstep_count: 12254218
total_train_sample_count: 9224685
total_episode_count: 29578
total_duration: 2559.391711643925
[2023-06-29 12:14:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 253.8
avg_sample_per_episode: 253.8
avg_envstep_per_sec: 2732.32941802783
avg_train_sample_per_sec: 2732.32941802783
avg_episode_per_sec: 10.76567934605134
collect_time: 0.4644388746200129
reward_mean: 2818.979596045134
reward_std: 942.2802363815557
reward_max: 3611.940229187525
reward_min: 1012.1274910468446
total_envstep_count: 12259258
total_train_sample_count: 9227954
total_episode_count: 29583
total_duration: 2559.8561505185453
[2023-06-29 12:14:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1696
train_sample_count: 1696
avg_envstep_per_episode: 282.6666666666667
avg_sample_per_episode: 282.6666666666667
avg_envstep_per_sec: 2390.13431763805
avg_train_sample_per_sec: 2390.13431763805
avg_episode_per_sec: 8.455663859568574
collect_time: 0.7095835524741558
reward_mean: 3241.0516714253413
reward_std: 610.0534788366019
reward_max: 3594.05531744025
reward_min: 1884.3122544242685
total_envstep_count: 12263530
total_train_sample_count: 9231250
total_episode_count: 29589
total_duration: 2560.5657340710195
[2023-06-29 12:14:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1413
train_sample_count: 1413
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 2728.227362605121
avg_train_sample_per_sec: 2728.227362605121
avg_episode_per_sec: 11.584829565202211
collect_time: 0.5179187113828956
reward_mean: 2494.628130203902
reward_std: 946.7253271995752
reward_max: 3719.9670571753823
reward_min: 1352.996214147131
total_envstep_count: 12267610
total_train_sample_count: 9234663
total_episode_count: 29595
total_duration: 2561.0836527824026
[2023-06-29 12:14:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 660
train_sample_count: 660
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 2092.8589303859226
avg_train_sample_per_sec: 2092.8589303859226
avg_episode_per_sec: 9.51299513811783
collect_time: 0.3153580924244599
reward_mean: 3573.8034752871827
reward_std: 29.780016301099824
reward_max: 3600.991036717173
reward_min: 3532.3546872313423
total_envstep_count: 12271674
total_train_sample_count: 9238123
total_episode_count: 29598
total_duration: 2561.399010874827
[2023-06-29 12:14:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1875
train_sample_count: 1875
avg_envstep_per_episode: 234.375
avg_sample_per_episode: 234.375
avg_envstep_per_sec: 2674.530226256772
avg_train_sample_per_sec: 2674.530226256772
avg_episode_per_sec: 11.411328965362227
collect_time: 0.7010576966349036
reward_mean: 2909.918593180797
reward_std: 786.6471002497444
reward_max: 3596.088350863713
reward_min: 1293.809808969878
total_envstep_count: 12276226
total_train_sample_count: 9241598
total_episode_count: 29606
total_duration: 2562.100068571462
[2023-06-29 12:14:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1477
train_sample_count: 1477
avg_envstep_per_episode: 246.16666666666666
avg_sample_per_episode: 246.16666666666666
avg_envstep_per_sec: 2719.7942657442145
avg_train_sample_per_sec: 2719.7942657442145
avg_episode_per_sec: 11.048588757254764
collect_time: 0.5430557813150805
reward_mean: 2494.9810314849847
reward_std: 619.399805463674
reward_max: 3761.080068971994
reward_min: 1771.2430038587283
total_envstep_count: 12281082
total_train_sample_count: 9245075
total_episode_count: 29612
total_duration: 2562.6431243527772
[2023-06-29 12:14:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2075
train_sample_count: 2075
avg_envstep_per_episode: 230.55555555555554
avg_sample_per_episode: 230.55555555555554
avg_envstep_per_sec: 2718.6066987639115
avg_train_sample_per_sec: 2718.6066987639115
avg_episode_per_sec: 11.791547127168773
collect_time: 0.7632586210221048
reward_mean: 2326.7277769682005
reward_std: 767.0022918600907
reward_max: 3622.252877226471
reward_min: 1280.3166537500636
total_envstep_count: 12285666
total_train_sample_count: 9248350
total_episode_count: 29621
total_duration: 2563.4063829737993
[2023-06-29 12:14:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2490
train_sample_count: 2490
avg_envstep_per_episode: 276.6666666666667
avg_sample_per_episode: 276.6666666666667
avg_envstep_per_sec: 2783.8671553510185
avg_train_sample_per_sec: 2783.8671553510185
avg_episode_per_sec: 10.062170441027778
collect_time: 0.8944392318483442
reward_mean: 2048.5282980947813
reward_std: 771.8990075242436
reward_max: 3125.570925125517
reward_min: 848.5749710862264
total_envstep_count: 12290450
total_train_sample_count: 9251640
total_episode_count: 29630
total_duration: 2564.300822205648
[2023-06-29 12:14:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 947
train_sample_count: 947
avg_envstep_per_episode: 157.83333333333334
avg_sample_per_episode: 157.83333333333334
avg_envstep_per_sec: 2806.175449087665
avg_train_sample_per_sec: 2806.175449087665
avg_episode_per_sec: 17.779358705940854
collect_time: 0.33746998973563314
reward_mean: 1804.2819611808764
reward_std: 262.246580237314
reward_max: 2203.5131967736106
reward_min: 1432.4561577654406
total_envstep_count: 12294954
total_train_sample_count: 9254987
total_episode_count: 29636
total_duration: 2564.6382921953837
[2023-06-29 12:14:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 271.0
avg_sample_per_episode: 271.0
avg_envstep_per_sec: 2468.552629629011
avg_train_sample_per_sec: 2468.552629629011
avg_episode_per_sec: 9.109050293833988
collect_time: 0.6586855716519057
reward_mean: 2986.1116836573833
reward_std: 731.1973919171166
reward_max: 3590.4728028093155
reward_min: 1920.8995195823516
total_envstep_count: 12299274
total_train_sample_count: 9258213
total_episode_count: 29642
total_duration: 2565.2969777670355
[2023-06-29 12:14:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1737
train_sample_count: 1737
avg_envstep_per_episode: 347.4
avg_sample_per_episode: 347.4
avg_envstep_per_sec: 2447.024247440731
avg_train_sample_per_sec: 2447.024247440731
avg_episode_per_sec: 7.04382339505104
collect_time: 0.7098417605860162
reward_mean: 3139.1910454013487
reward_std: 892.9663771631693
reward_max: 3634.562448894035
reward_min: 1354.056369465191
total_envstep_count: 12304074
total_train_sample_count: 9261550
total_episode_count: 29647
total_duration: 2566.0068195276217
[2023-06-29 12:15:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2277
train_sample_count: 2277
avg_envstep_per_episode: 325.2857142857143
avg_sample_per_episode: 325.2857142857143
avg_envstep_per_sec: 2812.4539242529845
avg_train_sample_per_sec: 2812.4539242529845
avg_episode_per_sec: 8.646103412284099
collect_time: 0.8096132634794341
reward_mean: 2914.1011926796104
reward_std: 730.5331843000451
reward_max: 3553.4876291246405
reward_min: 1920.8424464473542
total_envstep_count: 12308930
total_train_sample_count: 9265027
total_episode_count: 29654
total_duration: 2566.8164327911013
[2023-06-29 12:15:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 340.0
avg_sample_per_episode: 340.0
avg_envstep_per_sec: 2793.5656286807666
avg_train_sample_per_sec: 2793.5656286807666
avg_episode_per_sec: 8.216369496119901
collect_time: 0.4868330230144786
reward_mean: 3272.906584031967
reward_std: 352.5711907178281
reward_max: 3548.1488353544532
reward_min: 2681.9467736830634
total_envstep_count: 12313730
total_train_sample_count: 9268387
total_episode_count: 29658
total_duration: 2567.303265814116
[2023-06-29 12:15:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1827
train_sample_count: 1827
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2517.5448185190053
avg_train_sample_per_sec: 2517.5448185190053
avg_episode_per_sec: 9.645765588195422
collect_time: 0.7257070406693964
reward_mean: 3014.812362979996
reward_std: 743.2569063884739
reward_max: 3719.684991051263
reward_min: 1556.7778154913651
total_envstep_count: 12318298
total_train_sample_count: 9271814
total_episode_count: 29665
total_duration: 2568.0289728547855
[2023-06-29 12:15:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1667
train_sample_count: 1667
avg_envstep_per_episode: 208.375
avg_sample_per_episode: 208.375
avg_envstep_per_sec: 2692.827057177296
avg_train_sample_per_sec: 2692.827057177296
avg_episode_per_sec: 12.922985277395542
collect_time: 0.6190520091354847
reward_mean: 3201.6997165816983
reward_std: 654.7682162866365
reward_max: 3642.7896874538465
reward_min: 1760.7008721664897
total_envstep_count: 12325586
total_train_sample_count: 9278281
total_episode_count: 29673
total_duration: 2568.648024863921
[2023-06-29 12:15:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 1
envstep_count: 18
train_sample_count: 18
avg_envstep_per_episode: 18.0
avg_sample_per_episode: 18.0
avg_envstep_per_sec: 2636.2007756546705
avg_train_sample_per_sec: 2636.2007756546705
avg_episode_per_sec: 146.45559864748168
collect_time: 0.006828008005395532
reward_mean: 3474.46747876474
reward_std: 0.0
reward_max: 3474.46747876474
reward_min: 3474.46747876474
total_envstep_count: 12328930
total_train_sample_count: 9281499
total_episode_count: 29674
total_duration: 2568.6548528719263
[2023-06-29 12:15:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1638
train_sample_count: 1638
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 2803.4410480673305
avg_train_sample_per_sec: 2803.4410480673305
avg_episode_per_sec: 11.980517299433036
collect_time: 0.5842819491885602
reward_mean: 3344.565434808105
reward_std: 343.5999917384745
reward_max: 3691.5716854772063
reward_min: 2550.566418148322
total_envstep_count: 12333546
total_train_sample_count: 9284737
total_episode_count: 29681
total_duration: 2569.239134821115
[2023-06-29 12:15:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1267
train_sample_count: 1267
avg_envstep_per_episode: 211.16666666666666
avg_sample_per_episode: 211.16666666666666
avg_envstep_per_sec: 2783.9780414373668
avg_train_sample_per_sec: 2783.9780414373668
avg_episode_per_sec: 13.183794987075139
collect_time: 0.455104164307937
reward_mean: 2399.8924841115036
reward_std: 639.0550589571089
reward_max: 3522.8878158791827
reward_min: 1550.769554186082
total_envstep_count: 12338090
total_train_sample_count: 9288004
total_episode_count: 29687
total_duration: 2569.694238985423
[2023-06-29 12:15:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1522
train_sample_count: 1522
avg_envstep_per_episode: 217.42857142857142
avg_sample_per_episode: 217.42857142857142
avg_envstep_per_sec: 2782.338901593869
avg_train_sample_per_sec: 2782.338901593869
avg_episode_per_sec: 12.796565250431724
collect_time: 0.5470217877225951
reward_mean: 2561.1757026524606
reward_std: 830.2824041201135
reward_max: 3551.0305876588986
reward_min: 1486.3127801727915
total_envstep_count: 12342298
total_train_sample_count: 9291526
total_episode_count: 29694
total_duration: 2570.2412607731458
[2023-06-29 12:15:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 367.75
avg_sample_per_episode: 367.75
avg_envstep_per_sec: 2636.275064456417
avg_train_sample_per_sec: 2636.275064456417
avg_episode_per_sec: 7.168660950255383
collect_time: 1.1159685268299655
reward_mean: 2714.8729263123246
reward_std: 895.5006910805287
reward_max: 3550.265377711066
reward_min: 548.4292502644995
total_envstep_count: 12347010
total_train_sample_count: 9294868
total_episode_count: 29702
total_duration: 2571.3572292999756
[2023-06-29 12:15:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1722
train_sample_count: 1722
avg_envstep_per_episode: 344.4
avg_sample_per_episode: 344.4
avg_envstep_per_sec: 2677.093134868328
avg_train_sample_per_sec: 2677.093134868328
avg_episode_per_sec: 7.773208870117096
collect_time: 0.6432349990261718
reward_mean: 2216.69130231691
reward_std: 917.8227624269197
reward_max: 3540.581766408439
reward_min: 840.3263456839936
total_envstep_count: 12351442
total_train_sample_count: 9298190
total_episode_count: 29707
total_duration: 2572.000464299002
[2023-06-29 12:15:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1900
train_sample_count: 1900
avg_envstep_per_episode: 316.6666666666667
avg_sample_per_episode: 316.6666666666667
avg_envstep_per_sec: 2759.0966542169326
avg_train_sample_per_sec: 2759.0966542169326
avg_episode_per_sec: 8.712936802790313
collect_time: 0.6886311855353413
reward_mean: 2783.3336538533126
reward_std: 817.1263447310045
reward_max: 3510.5865533787733
reward_min: 1463.388384617211
total_envstep_count: 12355954
total_train_sample_count: 9301690
total_episode_count: 29713
total_duration: 2572.6890954845376
[2023-06-29 12:15:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 251.11111111111111
avg_sample_per_episode: 251.11111111111111
avg_envstep_per_sec: 2762.676485434531
avg_train_sample_per_sec: 2762.676485434531
avg_episode_per_sec: 11.00180901279238
collect_time: 0.8180472856359557
reward_mean: 1944.7696371623101
reward_std: 1102.1403250025633
reward_max: 3700.4055589572386
reward_min: 527.073272233975
total_envstep_count: 12360426
total_train_sample_count: 9305150
total_episode_count: 29722
total_duration: 2573.5071427701737
[2023-06-29 12:15:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1863
train_sample_count: 1863
avg_envstep_per_episode: 266.14285714285717
avg_sample_per_episode: 266.14285714285717
avg_envstep_per_sec: 2645.0868668537814
avg_train_sample_per_sec: 2645.0868668537814
avg_episode_per_sec: 9.938597996766758
collect_time: 0.7043246947182341
reward_mean: 2080.697176702142
reward_std: 758.8490152710375
reward_max: 3568.8047046435013
reward_min: 1018.7268665153207
total_envstep_count: 12365378
total_train_sample_count: 9308613
total_episode_count: 29729
total_duration: 2574.211467464892
[2023-06-29 12:15:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1478
train_sample_count: 1478
avg_envstep_per_episode: 211.14285714285714
avg_sample_per_episode: 211.14285714285714
avg_envstep_per_sec: 2431.066070439026
avg_train_sample_per_sec: 2431.066070439026
avg_episode_per_sec: 11.51384471791149
collect_time: 0.6079637316204607
reward_mean: 2367.3787894229245
reward_std: 1167.0777211028499
reward_max: 3657.4949255511433
reward_min: 520.8953974481916
total_envstep_count: 12369978
total_train_sample_count: 9312091
total_episode_count: 29736
total_duration: 2574.8194311965126
[2023-06-29 12:15:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2818
train_sample_count: 2818
avg_envstep_per_episode: 256.1818181818182
avg_sample_per_episode: 256.1818181818182
avg_envstep_per_sec: 2608.202208521914
avg_train_sample_per_sec: 2608.202208521914
avg_episode_per_sec: 10.181059011263681
collect_time: 1.0804377017980442
reward_mean: 2156.1352207296045
reward_std: 887.7429021132667
reward_max: 3575.845455238437
reward_min: 1000.768928596012
total_envstep_count: 12374690
total_train_sample_count: 9315309
total_episode_count: 29747
total_duration: 2575.8998688983106
[2023-06-29 12:15:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 343.1666666666667
avg_sample_per_episode: 343.1666666666667
avg_envstep_per_sec: 2730.6237184592187
avg_train_sample_per_sec: 2730.6237184592187
avg_episode_per_sec: 7.957135653596558
collect_time: 0.7540401799343525
reward_mean: 2093.2697918164795
reward_std: 257.47236555579065
reward_max: 2604.876059007401
reward_min: 1743.3398362397968
total_envstep_count: 12379618
total_train_sample_count: 9318568
total_episode_count: 29753
total_duration: 2576.653909078245
[2023-06-29 12:15:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2876
train_sample_count: 2876
avg_envstep_per_episode: 287.6
avg_sample_per_episode: 287.6
avg_envstep_per_sec: 2734.745519078448
avg_train_sample_per_sec: 2734.745519078448
avg_episode_per_sec: 9.508850900829096
collect_time: 1.0516517825648186
reward_mean: 2313.0605073484853
reward_std: 1004.2211960436041
reward_max: 3625.6164417851887
reward_min: 760.8159536734936
total_envstep_count: 12383778
total_train_sample_count: 9321844
total_episode_count: 29763
total_duration: 2577.70556086081
[2023-06-29 12:15:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 244.8
avg_sample_per_episode: 244.8
avg_envstep_per_sec: 2583.363341308945
avg_train_sample_per_sec: 2583.363341308945
avg_episode_per_sec: 10.552954825608436
collect_time: 0.9476018958911296
reward_mean: 1329.2154402971876
reward_std: 395.25221388917794
reward_max: 1986.8542034889215
reward_min: 853.5693323498089
total_envstep_count: 12388058
total_train_sample_count: 9325092
total_episode_count: 29773
total_duration: 2578.653162756701
[2023-06-29 12:15:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 248.2
avg_sample_per_episode: 248.2
avg_envstep_per_sec: 2796.1057012438923
avg_train_sample_per_sec: 2796.1057012438923
avg_episode_per_sec: 11.265534654487883
collect_time: 0.8876631519673389
reward_mean: 1616.2497785063754
reward_std: 656.0643631635835
reward_max: 2530.7982488734906
reward_min: 590.6064554010147
total_envstep_count: 12392090
total_train_sample_count: 9328374
total_episode_count: 29783
total_duration: 2579.5408259086685
[2023-06-29 12:16:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2493
train_sample_count: 2493
avg_envstep_per_episode: 311.625
avg_sample_per_episode: 311.625
avg_envstep_per_sec: 2573.7778917769083
avg_train_sample_per_sec: 2573.7778917769083
avg_episode_per_sec: 8.259215055842466
collect_time: 0.9686150494823234
reward_mean: 1804.9666187826062
reward_std: 405.23868594763985
reward_max: 2319.0381772225037
reward_min: 1151.8696309010386
total_envstep_count: 12396682
total_train_sample_count: 9331667
total_episode_count: 29791
total_duration: 2580.5094409581507
[2023-06-29 12:16:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2408
train_sample_count: 2408
avg_envstep_per_episode: 344.0
avg_sample_per_episode: 344.0
avg_envstep_per_sec: 2773.4658880793954
avg_train_sample_per_sec: 2773.4658880793954
avg_episode_per_sec: 8.062400837440103
collect_time: 0.8682277327980846
reward_mean: 2380.598760533064
reward_std: 886.5477267263892
reward_max: 3589.49805634855
reward_min: 1020.3036332864258
total_envstep_count: 12401002
total_train_sample_count: 9334875
total_episode_count: 29798
total_duration: 2581.3776686909487
[2023-06-29 12:16:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1506
train_sample_count: 1506
avg_envstep_per_episode: 167.33333333333334
avg_sample_per_episode: 167.33333333333334
avg_envstep_per_sec: 2805.037106066936
avg_train_sample_per_sec: 2805.037106066936
avg_episode_per_sec: 16.763169956575315
collect_time: 0.5368912934316323
reward_mean: 2668.2481325924755
reward_std: 881.6192543613895
reward_max: 3532.24551315437
reward_min: 898.6925716324731
total_envstep_count: 12408762
total_train_sample_count: 9341581
total_episode_count: 29807
total_duration: 2581.9145599843805
[2023-06-29 12:16:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2934
train_sample_count: 2934
avg_envstep_per_episode: 326.0
avg_sample_per_episode: 326.0
avg_envstep_per_sec: 2765.4082407698297
avg_train_sample_per_sec: 2765.4082407698297
avg_episode_per_sec: 8.48284736432463
collect_time: 1.060964510318823
reward_mean: 2310.9738380410067
reward_std: 1173.5002304908512
reward_max: 3557.4695097193794
reward_min: 44.993309318118726
total_envstep_count: 12413354
total_train_sample_count: 9344915
total_episode_count: 29816
total_duration: 2582.975524494699
[2023-06-29 12:16:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1223
train_sample_count: 1223
avg_envstep_per_episode: 244.6
avg_sample_per_episode: 244.6
avg_envstep_per_sec: 2636.6373351256307
avg_train_sample_per_sec: 2636.6373351256307
avg_episode_per_sec: 10.779384035673061
collect_time: 0.46384839648101484
reward_mean: 1857.5586745395717
reward_std: 626.0493493626086
reward_max: 2971.6415753708384
reward_min: 1284.5727878652929
total_envstep_count: 12417930
total_train_sample_count: 9348138
total_episode_count: 29821
total_duration: 2583.43937289118
[2023-06-29 12:16:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2486
train_sample_count: 2486
avg_envstep_per_episode: 310.75
avg_sample_per_episode: 310.75
avg_envstep_per_sec: 2453.7152376456706
avg_train_sample_per_sec: 2453.7152376456706
avg_episode_per_sec: 7.896106959439004
collect_time: 1.0131575016770513
reward_mean: 2809.4362740212027
reward_std: 1069.5396212069047
reward_max: 3617.153620645801
reward_min: 887.5749660306963
total_envstep_count: 12422234
total_train_sample_count: 9351424
total_episode_count: 29829
total_duration: 2584.452530392857
[2023-06-29 12:16:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2403
train_sample_count: 2403
avg_envstep_per_episode: 300.375
avg_sample_per_episode: 300.375
avg_envstep_per_sec: 2774.764936928303
avg_train_sample_per_sec: 2774.764936928303
avg_episode_per_sec: 9.237669369715533
collect_time: 0.8660193042010069
reward_mean: 1904.3212343880546
reward_std: 1052.1334931250958
reward_max: 3636.6309301166143
reward_min: 835.7031751204763
total_envstep_count: 12426618
total_train_sample_count: 9355027
total_episode_count: 29837
total_duration: 2585.318549697058
[2023-06-29 12:16:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2015
train_sample_count: 2015
avg_envstep_per_episode: 335.8333333333333
avg_sample_per_episode: 335.8333333333333
avg_envstep_per_sec: 2789.274487635085
avg_train_sample_per_sec: 2789.274487635085
avg_episode_per_sec: 8.305531973106953
collect_time: 0.7224100779369471
reward_mean: 2485.86629716554
reward_std: 985.6156561830882
reward_max: 3576.2684089108634
reward_min: 1179.371611200155
total_envstep_count: 12430538
total_train_sample_count: 9358242
total_episode_count: 29843
total_duration: 2586.040959774995
[2023-06-29 12:16:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1779
train_sample_count: 1779
avg_envstep_per_episode: 296.5
avg_sample_per_episode: 296.5
avg_envstep_per_sec: 2494.8668011293144
avg_train_sample_per_sec: 2494.8668011293144
avg_episode_per_sec: 8.414390560301229
collect_time: 0.7130641199741511
reward_mean: 2157.0013886641914
reward_std: 1051.0274264648483
reward_max: 3653.708066765152
reward_min: 996.1025811299102
total_envstep_count: 12434706
total_train_sample_count: 9361621
total_episode_count: 29849
total_duration: 2586.754023894969
[2023-06-29 12:16:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2939
train_sample_count: 2939
avg_envstep_per_episode: 367.375
avg_sample_per_episode: 367.375
avg_envstep_per_sec: 2573.891627485226
avg_train_sample_per_sec: 2573.891627485226
avg_episode_per_sec: 7.006169792406195
collect_time: 1.1418507168740033
reward_mean: 2555.195151579529
reward_std: 746.3047687344194
reward_max: 3652.1420611849007
reward_min: 1375.9651883269257
total_envstep_count: 12439402
total_train_sample_count: 9364960
total_episode_count: 29857
total_duration: 2587.8958746118433
[2023-06-29 12:16:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 279.875
avg_sample_per_episode: 279.875
avg_envstep_per_sec: 2709.0706491686906
avg_train_sample_per_sec: 2709.0706491686906
avg_episode_per_sec: 9.679573556654544
collect_time: 0.8264826909136027
reward_mean: 1750.341198825638
reward_std: 955.0616914649403
reward_max: 3621.3862287809748
reward_min: 587.7488817769155
total_envstep_count: 12444690
total_train_sample_count: 9368399
total_episode_count: 29865
total_duration: 2588.722357302757
[2023-06-29 12:16:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1721
train_sample_count: 1721
avg_envstep_per_episode: 215.125
avg_sample_per_episode: 215.125
avg_envstep_per_sec: 2785.929418197579
avg_train_sample_per_sec: 2785.929418197579
avg_episode_per_sec: 12.950282013701703
collect_time: 0.6177471650065853
reward_mean: 2249.22973056292
reward_std: 886.1830037910132
reward_max: 3600.1136615736395
reward_min: 1037.0807226563938
total_envstep_count: 12448842
total_train_sample_count: 9371720
total_episode_count: 29873
total_duration: 2589.3401044677635
[2023-06-29 12:16:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2343
train_sample_count: 2343
avg_envstep_per_episode: 260.3333333333333
avg_sample_per_episode: 260.3333333333333
avg_envstep_per_sec: 2510.830248872965
avg_train_sample_per_sec: 2510.830248872965
avg_episode_per_sec: 9.644674451496664
collect_time: 0.9331574689494446
reward_mean: 1967.9492332450116
reward_std: 761.8743724939817
reward_max: 3335.064365040963
reward_min: 1182.6307940504212
total_envstep_count: 12453474
total_train_sample_count: 9375263
total_episode_count: 29882
total_duration: 2590.273261936713
[2023-06-29 12:16:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2451
train_sample_count: 2451
avg_envstep_per_episode: 204.25
avg_sample_per_episode: 204.25
avg_envstep_per_sec: 2710.9123039888314
avg_train_sample_per_sec: 2710.9123039888314
avg_episode_per_sec: 13.272520460165635
collect_time: 0.9041236768867821
reward_mean: 1442.4937395010165
reward_std: 355.75199347778977
reward_max: 2327.2454293336878
reward_min: 1045.6249999912857
total_envstep_count: 12458226
total_train_sample_count: 9378514
total_episode_count: 29894
total_duration: 2591.1773856135997
[2023-06-29 12:16:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3001
train_sample_count: 3001
avg_envstep_per_episode: 230.84615384615384
avg_sample_per_episode: 230.84615384615384
avg_envstep_per_sec: 2507.1312878103727
avg_train_sample_per_sec: 2507.1312878103727
avg_episode_per_sec: 10.860615375386486
collect_time: 1.196985580528155
reward_mean: 1538.2723605443875
reward_std: 695.1579792382515
reward_max: 3693.4069209388713
reward_min: 940.2754759763725
total_envstep_count: 12462914
total_train_sample_count: 9381915
total_episode_count: 29907
total_duration: 2592.374371194128
[2023-06-29 12:16:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2837
train_sample_count: 2837
avg_envstep_per_episode: 218.23076923076923
avg_sample_per_episode: 218.23076923076923
avg_envstep_per_sec: 2738.6190350512675
avg_train_sample_per_sec: 2738.6190350512675
avg_episode_per_sec: 12.549188387615958
collect_time: 1.0359235672028735
reward_mean: 1289.0503387454696
reward_std: 271.8133902238201
reward_max: 1751.36971191592
reward_min: 671.5076602434184
total_envstep_count: 12467586
total_train_sample_count: 9385152
total_episode_count: 29920
total_duration: 2593.410294761331
[2023-06-29 12:16:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2894
train_sample_count: 2894
avg_envstep_per_episode: 241.16666666666666
avg_sample_per_episode: 241.16666666666666
avg_envstep_per_sec: 2593.6866322558726
avg_train_sample_per_sec: 2593.6866322558726
avg_episode_per_sec: 10.754747611289035
collect_time: 1.11578629584983
reward_mean: 1456.3312942908353
reward_std: 456.96880077097745
reward_max: 2392.3255334811643
reward_min: 946.1676167940572
total_envstep_count: 12472314
total_train_sample_count: 9388446
total_episode_count: 29932
total_duration: 2594.526081057181
[2023-06-29 12:16:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2991
train_sample_count: 2991
avg_envstep_per_episode: 249.25
avg_sample_per_episode: 249.25
avg_envstep_per_sec: 2577.606783294296
avg_train_sample_per_sec: 2577.606783294296
avg_episode_per_sec: 10.341451487640104
collect_time: 1.1603786967759953
reward_mean: 1480.0767835026702
reward_std: 714.3349220919449
reward_max: 3259.817951122617
reward_min: 510.6946722915123
total_envstep_count: 12476786
total_train_sample_count: 9391837
total_episode_count: 29944
total_duration: 2595.686459753957
[2023-06-29 12:17:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3402
train_sample_count: 3402
avg_envstep_per_episode: 309.27272727272725
avg_sample_per_episode: 309.27272727272725
avg_envstep_per_sec: 2535.0022040115496
avg_train_sample_per_sec: 2535.0022040115496
avg_episode_per_sec: 8.196656156415946
collect_time: 1.3420106675317511
reward_mean: 1639.2684996883281
reward_std: 623.4142088934735
reward_max: 2632.426600946826
reward_min: 506.85110101105766
total_envstep_count: 12481650
total_train_sample_count: 9395239
total_episode_count: 29955
total_duration: 2597.0284704214887
[2023-06-29 12:17:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3074
train_sample_count: 3074
avg_envstep_per_episode: 236.46153846153845
avg_sample_per_episode: 236.46153846153845
avg_envstep_per_sec: 2787.663908544022
avg_train_sample_per_sec: 2787.663908544022
avg_episode_per_sec: 11.789079639255785
collect_time: 1.10271542798914
reward_mean: 1261.681828837728
reward_std: 359.06098250272566
reward_max: 1914.253914988211
reward_min: 554.0105470512292
total_envstep_count: 12486474
total_train_sample_count: 9398713
total_episode_count: 29968
total_duration: 2598.131185849478
[2023-06-29 12:17:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2853
train_sample_count: 2853
avg_envstep_per_episode: 285.3
avg_sample_per_episode: 285.3
avg_envstep_per_sec: 2781.1163475937956
avg_train_sample_per_sec: 2781.1163475937956
avg_episode_per_sec: 9.74804187730037
collect_time: 1.0258470496814698
reward_mean: 1668.208417063571
reward_std: 609.9683733423997
reward_max: 2880.3653746822006
reward_min: 491.4749634887463
total_envstep_count: 12491442
total_train_sample_count: 9401966
total_episode_count: 29978
total_duration: 2599.1570328991593
[2023-06-29 12:17:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2999
train_sample_count: 2999
avg_envstep_per_episode: 272.6363636363636
avg_sample_per_episode: 272.6363636363636
avg_envstep_per_sec: 2602.373787781671
avg_train_sample_per_sec: 2602.373787781671
avg_episode_per_sec: 9.545218961519966
collect_time: 1.1524093941003084
reward_mean: 1657.719068745079
reward_std: 698.5358081936257
reward_max: 3104.2542614019444
reward_min: 882.5384907674132
total_envstep_count: 12495946
total_train_sample_count: 9405365
total_episode_count: 29989
total_duration: 2600.3094422932595
[2023-06-29 12:17:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2859
train_sample_count: 2859
avg_envstep_per_episode: 259.90909090909093
avg_sample_per_episode: 259.90909090909093
avg_envstep_per_sec: 2589.7666346219507
avg_train_sample_per_sec: 2589.7666346219507
avg_episode_per_sec: 9.964124862134124
collect_time: 1.1039604734182358
reward_mean: 1548.6895326740223
reward_std: 775.3940061526133
reward_max: 3659.0182568183045
reward_min: 824.0292993818439
total_envstep_count: 12500034
total_train_sample_count: 9408624
total_episode_count: 30000
total_duration: 2601.413402766678
[2023-06-29 12:17:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2894
train_sample_count: 2894
avg_envstep_per_episode: 263.09090909090907
avg_sample_per_episode: 263.09090909090907
avg_envstep_per_sec: 2655.2912560171562
avg_train_sample_per_sec: 2655.2912560171562
avg_episode_per_sec: 10.092675817618769
collect_time: 1.0898992694085463
reward_mean: 1379.7214167748061
reward_std: 372.2069279027181
reward_max: 2184.7301529995457
reward_min: 916.7852120680925
total_envstep_count: 12504498
total_train_sample_count: 9411918
total_episode_count: 30011
total_duration: 2602.5033020360866
[2023-06-29 12:17:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 2737.222172777176
avg_train_sample_per_sec: 2737.222172777176
avg_episode_per_sec: 12.219741842755251
collect_time: 1.0638522619614377
reward_mean: 1243.3045350702866
reward_std: 356.67605409334783
reward_max: 1747.3468785234893
reward_min: 527.4591950300156
total_envstep_count: 12508954
total_train_sample_count: 9415230
total_episode_count: 30024
total_duration: 2603.567154298048
[2023-06-29 12:17:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 267.5
avg_sample_per_episode: 267.5
avg_envstep_per_sec: 2564.004988411839
avg_train_sample_per_sec: 2564.004988411839
avg_episode_per_sec: 9.58506537724052
collect_time: 1.251947642265819
reward_mean: 1470.1268995369164
reward_std: 578.059815782323
reward_max: 2188.3683795549887
reward_min: 238.6510512862824
total_envstep_count: 12514034
total_train_sample_count: 9418440
total_episode_count: 30036
total_duration: 2604.819101940314
[2023-06-29 12:17:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2292
train_sample_count: 2292
avg_envstep_per_episode: 254.66666666666666
avg_sample_per_episode: 254.66666666666666
avg_envstep_per_sec: 2576.3064727806286
avg_train_sample_per_sec: 2576.3064727806286
avg_episode_per_sec: 10.116386673222364
collect_time: 0.8896457095518708
reward_mean: 1620.4658763505477
reward_std: 472.5112975521251
reward_max: 2707.3696975147323
reward_min: 932.8615317823533
total_envstep_count: 12519122
total_train_sample_count: 9421932
total_episode_count: 30045
total_duration: 2605.708747649866
[2023-06-29 12:17:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1892
train_sample_count: 1892
avg_envstep_per_episode: 236.5
avg_sample_per_episode: 236.5
avg_envstep_per_sec: 2452.5923911195764
avg_train_sample_per_sec: 2452.5923911195764
avg_episode_per_sec: 10.370369518476009
collect_time: 0.7714286347990857
reward_mean: 2228.690328362569
reward_std: 664.1005006747083
reward_max: 3540.1557307996572
reward_min: 1465.7457920334411
total_envstep_count: 12523986
total_train_sample_count: 9425424
total_episode_count: 30053
total_duration: 2606.480176284665
[2023-06-29 12:17:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1300
train_sample_count: 1300
avg_envstep_per_episode: 185.71428571428572
avg_sample_per_episode: 185.71428571428572
avg_envstep_per_sec: 2579.1663752371705
avg_train_sample_per_sec: 2579.1663752371705
avg_episode_per_sec: 13.887818943584763
collect_time: 0.5040388291664422
reward_mean: 2304.3654271058567
reward_std: 688.7712504598909
reward_max: 3675.4211477201484
reward_min: 1424.5635207760668
total_envstep_count: 12528250
total_train_sample_count: 9428724
total_episode_count: 30060
total_duration: 2606.9842151138314
[2023-06-29 12:17:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2016
train_sample_count: 2016
avg_envstep_per_episode: 201.6
avg_sample_per_episode: 201.6
avg_envstep_per_sec: 2723.6833593330243
avg_train_sample_per_sec: 2723.6833593330243
avg_episode_per_sec: 13.510334123675715
collect_time: 0.7401741443593055
reward_mean: 1719.1617444724975
reward_std: 542.8653983287049
reward_max: 2606.290209916162
reward_min: 772.8074388336386
total_envstep_count: 12532794
total_train_sample_count: 9431940
total_episode_count: 30070
total_duration: 2607.7243892581905
[2023-06-29 12:17:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1659
train_sample_count: 1659
avg_envstep_per_episode: 184.33333333333334
avg_sample_per_episode: 184.33333333333334
avg_envstep_per_sec: 2589.966032762222
avg_train_sample_per_sec: 2589.966032762222
avg_episode_per_sec: 14.050448640663049
collect_time: 0.6405489411884918
reward_mean: 1875.7243226163018
reward_std: 718.3456105558822
reward_max: 3602.690206820079
reward_min: 880.1759982070068
total_envstep_count: 12536562
total_train_sample_count: 9435199
total_episode_count: 30079
total_duration: 2608.364938199379
[2023-06-29 12:17:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 295.14285714285717
avg_sample_per_episode: 295.14285714285717
avg_envstep_per_sec: 2648.7505880254134
avg_train_sample_per_sec: 2648.7505880254134
avg_episode_per_sec: 8.974469562525602
collect_time: 0.7799903884269295
reward_mean: 2183.683130916213
reward_std: 581.3825567930875
reward_max: 3499.8553888930064
reward_min: 1554.2156773921045
total_envstep_count: 12541026
total_train_sample_count: 9438465
total_episode_count: 30086
total_duration: 2609.144928587806
[2023-06-29 12:17:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2130
train_sample_count: 2130
avg_envstep_per_episode: 426.0
avg_sample_per_episode: 426.0
avg_envstep_per_sec: 2464.100590810713
avg_train_sample_per_sec: 2464.100590810713
avg_episode_per_sec: 5.784273687349092
collect_time: 0.864412762994878
reward_mean: 3021.7839942999963
reward_std: 590.0575395282801
reward_max: 3563.5694908850655
reward_min: 2215.8986922196555
total_envstep_count: 12545562
total_train_sample_count: 9441795
total_episode_count: 30091
total_duration: 2610.009341350801
[2023-06-29 12:17:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1906
train_sample_count: 1906
avg_envstep_per_episode: 211.77777777777777
avg_sample_per_episode: 211.77777777777777
avg_envstep_per_sec: 2789.6623693067995
avg_train_sample_per_sec: 2789.6623693067995
avg_episode_per_sec: 13.17259250984323
collect_time: 0.6832368034822867
reward_mean: 1710.1800274261016
reward_std: 1101.20999271312
reward_max: 3691.303291803047
reward_min: 629.9495325704809
total_envstep_count: 12550034
total_train_sample_count: 9445301
total_episode_count: 30100
total_duration: 2610.6925781542836
[2023-06-29 12:17:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2402
train_sample_count: 2402
avg_envstep_per_episode: 240.2
avg_sample_per_episode: 240.2
avg_envstep_per_sec: 2762.7791083039324
avg_train_sample_per_sec: 2762.7791083039324
avg_episode_per_sec: 11.501994622414372
collect_time: 0.8694144214354458
reward_mean: 1946.5758158401914
reward_std: 747.2901369256042
reward_max: 3692.433406519222
reward_min: 854.0449955087577
total_envstep_count: 12554338
total_train_sample_count: 9448503
total_episode_count: 30110
total_duration: 2611.561992575719
[2023-06-29 12:17:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2353
train_sample_count: 2353
avg_envstep_per_episode: 261.44444444444446
avg_sample_per_episode: 261.44444444444446
avg_envstep_per_sec: 2519.8802750943105
avg_train_sample_per_sec: 2519.8802750943105
avg_episode_per_sec: 9.63830109470837
collect_time: 0.9337745222486554
reward_mean: 1760.557719252685
reward_std: 436.8987760966994
reward_max: 2694.4987663062348
reward_min: 1160.7155559293676
total_envstep_count: 12558826
total_train_sample_count: 9452056
total_episode_count: 30119
total_duration: 2612.495767097968
[2023-06-29 12:17:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2709.7883219112105
avg_train_sample_per_sec: 2709.7883219112105
avg_episode_per_sec: 9.925964549125313
collect_time: 0.9067128897607326
reward_mean: 1824.4903249538006
reward_std: 732.2802799344649
reward_max: 3202.8651656232864
reward_min: 643.9353948900483
total_envstep_count: 12563106
total_train_sample_count: 9455313
total_episode_count: 30128
total_duration: 2613.402479987729
[2023-06-29 12:17:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1541
train_sample_count: 1541
avg_envstep_per_episode: 192.625
avg_sample_per_episode: 192.625
avg_envstep_per_sec: 2769.0682355445624
avg_train_sample_per_sec: 2769.0682355445624
avg_episode_per_sec: 14.37543535649351
collect_time: 0.5565048850076273
reward_mean: 1481.7499682477296
reward_std: 707.4845857973833
reward_max: 3228.5447579815227
reward_min: 821.278413164116
total_envstep_count: 12568034
total_train_sample_count: 9458854
total_episode_count: 30136
total_duration: 2613.9589848727364
[2023-06-29 12:18:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1658
train_sample_count: 1658
avg_envstep_per_episode: 207.25
avg_sample_per_episode: 207.25
avg_envstep_per_sec: 2816.904321787981
avg_train_sample_per_sec: 2816.904321787981
avg_episode_per_sec: 13.591818199218245
collect_time: 0.5885893912604079
reward_mean: 2376.254692892175
reward_std: 869.9796729072948
reward_max: 3621.2860385837616
reward_min: 1370.9196482814712
total_envstep_count: 12572034
total_train_sample_count: 9462112
total_episode_count: 30144
total_duration: 2614.547574263997
[2023-06-29 12:18:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 241.8
avg_sample_per_episode: 241.8
avg_envstep_per_sec: 2592.3629293308013
avg_train_sample_per_sec: 2592.3629293308013
avg_episode_per_sec: 10.72110392609926
collect_time: 0.46636988452542566
reward_mean: 2077.7540401909755
reward_std: 825.3091909139278
reward_max: 3560.311119375357
reward_min: 1142.0522364081623
total_envstep_count: 12576050
total_train_sample_count: 9465321
total_episode_count: 30149
total_duration: 2615.0139441485226
[2023-06-29 12:18:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2561
train_sample_count: 2561
avg_envstep_per_episode: 320.125
avg_sample_per_episode: 320.125
avg_envstep_per_sec: 2569.4806767229975
avg_train_sample_per_sec: 2569.4806767229975
avg_episode_per_sec: 8.026491766413113
collect_time: 0.9966994588440286
reward_mean: 2718.0768495508096
reward_std: 797.6923861425512
reward_max: 3646.331373410906
reward_min: 1699.499027062051
total_envstep_count: 12580594
total_train_sample_count: 9468682
total_episode_count: 30157
total_duration: 2616.0106436073665
[2023-06-29 12:18:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 242.2
avg_sample_per_episode: 242.2
avg_envstep_per_sec: 2734.6165030379084
avg_train_sample_per_sec: 2734.6165030379084
avg_episode_per_sec: 11.290737006762628
collect_time: 0.44284088780079034
reward_mean: 2213.4579641048404
reward_std: 942.1101633018495
reward_max: 3587.652207726439
reward_min: 901.0853357633949
total_envstep_count: 12585106
total_train_sample_count: 9471893
total_episode_count: 30162
total_duration: 2616.4534844951672
[2023-06-29 12:18:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2383
train_sample_count: 2383
avg_envstep_per_episode: 198.58333333333334
avg_sample_per_episode: 198.58333333333334
avg_envstep_per_sec: 2810.391307736096
avg_train_sample_per_sec: 2810.391307736096
avg_episode_per_sec: 14.152201297873752
collect_time: 0.8479246265245604
reward_mean: 1837.813505711644
reward_std: 825.6524867727551
reward_max: 3612.1981126347855
reward_min: 548.6129135720557
total_envstep_count: 12590258
total_train_sample_count: 9475476
total_episode_count: 30174
total_duration: 2617.301409121692
[2023-06-29 12:18:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1526
train_sample_count: 1526
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 2751.716429611411
avg_train_sample_per_sec: 2751.716429611411
avg_episode_per_sec: 10.819330653780122
collect_time: 0.5545629569888119
reward_mean: 2293.0921841833956
reward_std: 864.1640232139081
reward_max: 3532.771439431634
reward_min: 1360.975278234141
total_envstep_count: 12594642
total_train_sample_count: 9479002
total_episode_count: 30180
total_duration: 2617.8559720786807
[2023-06-29 12:18:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1641
train_sample_count: 1641
avg_envstep_per_episode: 273.5
avg_sample_per_episode: 273.5
avg_envstep_per_sec: 2459.254351988869
avg_train_sample_per_sec: 2459.254351988869
avg_episode_per_sec: 8.991789221165883
collect_time: 0.6672754278844222
reward_mean: 2818.989989383704
reward_std: 737.0060634261192
reward_max: 3551.6517593107424
reward_min: 1802.099054561442
total_envstep_count: 12598946
total_train_sample_count: 9482243
total_episode_count: 30186
total_duration: 2618.523247506565
[2023-06-29 12:18:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1930
train_sample_count: 1930
avg_envstep_per_episode: 321.6666666666667
avg_sample_per_episode: 321.6666666666667
avg_envstep_per_sec: 2426.9753312141233
avg_train_sample_per_sec: 2426.9753312141233
avg_episode_per_sec: 7.545001029681212
collect_time: 0.7952285197041927
reward_mean: 2529.3044546175583
reward_std: 826.4311250915646
reward_max: 3562.6252790147632
reward_min: 1552.9930372050335
total_envstep_count: 12603450
total_train_sample_count: 9485773
total_episode_count: 30192
total_duration: 2619.3184760262693
[2023-06-29 12:18:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2088
train_sample_count: 2088
avg_envstep_per_episode: 232.0
avg_sample_per_episode: 232.0
avg_envstep_per_sec: 2671.913715552175
avg_train_sample_per_sec: 2671.913715552175
avg_episode_per_sec: 11.51686946358696
collect_time: 0.7814623607965185
reward_mean: 2116.6747047803237
reward_std: 950.6113418083538
reward_max: 3582.9308020979365
reward_min: 829.8713932585084
total_envstep_count: 12607674
total_train_sample_count: 9489061
total_episode_count: 30201
total_duration: 2620.099938387066
[2023-06-29 12:18:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3047
train_sample_count: 3047
avg_envstep_per_episode: 277.0
avg_sample_per_episode: 277.0
avg_envstep_per_sec: 2821.6090769018597
avg_train_sample_per_sec: 2821.6090769018597
avg_episode_per_sec: 10.186314357046424
collect_time: 1.07988027999457
reward_mean: 1699.1230141103465
reward_std: 765.5308526740384
reward_max: 3355.3345726221874
reward_min: 798.5476064454249
total_envstep_count: 12612698
total_train_sample_count: 9492508
total_episode_count: 30212
total_duration: 2621.1798186670603
[2023-06-29 12:18:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2291
train_sample_count: 2291
avg_envstep_per_episode: 254.55555555555554
avg_sample_per_episode: 254.55555555555554
avg_envstep_per_sec: 2787.392881788638
avg_train_sample_per_sec: 2787.392881788638
avg_episode_per_sec: 10.950037510300193
collect_time: 0.821914992668666
reward_mean: 1504.6680544041153
reward_std: 497.6585333561232
reward_max: 2330.5169301228743
reward_min: 803.5180322092568
total_envstep_count: 12617034
total_train_sample_count: 9495999
total_episode_count: 30221
total_duration: 2622.001733659729
[2023-06-29 12:18:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2100
train_sample_count: 2100
avg_envstep_per_episode: 233.33333333333334
avg_sample_per_episode: 233.33333333333334
avg_envstep_per_sec: 2572.282835616296
avg_train_sample_per_sec: 2572.282835616296
avg_episode_per_sec: 11.024069295498412
collect_time: 0.8163954487908631
reward_mean: 1610.746301746825
reward_std: 940.2625496182579
reward_max: 3581.4695139293594
reward_min: 505.6228461858688
total_envstep_count: 12621602
total_train_sample_count: 9499299
total_episode_count: 30230
total_duration: 2622.8181291085198
[2023-06-29 12:18:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1936
train_sample_count: 1936
avg_envstep_per_episode: 176.0
avg_sample_per_episode: 176.0
avg_envstep_per_sec: 2706.1952978840877
avg_train_sample_per_sec: 2706.1952978840877
avg_episode_per_sec: 15.37610964706868
collect_time: 0.7153955228263511
reward_mean: 1493.0107239907047
reward_std: 894.848707789222
reward_max: 3565.3650059498923
reward_min: 51.405130177076344
total_envstep_count: 12626650
total_train_sample_count: 9502835
total_episode_count: 30241
total_duration: 2623.533524631346
[2023-06-29 12:18:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2060
train_sample_count: 2060
avg_envstep_per_episode: 343.3333333333333
avg_sample_per_episode: 343.3333333333333
avg_envstep_per_sec: 2805.0339512133264
avg_train_sample_per_sec: 2805.0339512133264
avg_episode_per_sec: 8.170001799650466
collect_time: 0.7343939630780371
reward_mean: 2722.086254485776
reward_std: 631.3910884474486
reward_max: 3571.9920476015845
reward_min: 1782.8978071810884
total_envstep_count: 12631594
total_train_sample_count: 9506095
total_episode_count: 30247
total_duration: 2624.2679185944244
[2023-06-29 12:18:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 292.42857142857144
avg_sample_per_episode: 292.42857142857144
avg_envstep_per_sec: 2804.6063860978634
avg_train_sample_per_sec: 2804.6063860978634
avg_episode_per_sec: 9.590739962230113
collect_time: 0.7298706906419247
reward_mean: 2524.0419173310543
reward_std: 932.8185990041621
reward_max: 3574.4575413729176
reward_min: 1205.5345792249702
total_envstep_count: 12636098
total_train_sample_count: 9509342
total_episode_count: 30254
total_duration: 2624.997789285066
[2023-06-29 12:18:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1419
train_sample_count: 1419
avg_envstep_per_episode: 236.5
avg_sample_per_episode: 236.5
avg_envstep_per_sec: 2752.985058981314
avg_train_sample_per_sec: 2752.985058981314
avg_episode_per_sec: 11.640528790618664
collect_time: 0.5154405017094688
reward_mean: 2397.480569543541
reward_std: 1123.6759354231167
reward_max: 3564.111444880957
reward_min: 1015.1884144377356
total_envstep_count: 12640410
total_train_sample_count: 9512761
total_episode_count: 30260
total_duration: 2625.513229786776
[2023-06-29 12:18:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1839
train_sample_count: 1839
avg_envstep_per_episode: 306.5
avg_sample_per_episode: 306.5
avg_envstep_per_sec: 2620.0935065519398
avg_train_sample_per_sec: 2620.0935065519398
avg_episode_per_sec: 8.54842905889703
collect_time: 0.7018833470642565
reward_mean: 3009.842949498436
reward_std: 549.5061466244397
reward_max: 3596.9612378295956
reward_min: 1999.8532419131063
total_envstep_count: 12644922
total_train_sample_count: 9516200
total_episode_count: 30266
total_duration: 2626.21511313384
[2023-06-29 12:18:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 180.83333333333334
avg_sample_per_episode: 180.83333333333334
avg_envstep_per_sec: 2252.817327924072
avg_train_sample_per_sec: 2252.817327924072
avg_episode_per_sec: 12.457976006953393
collect_time: 0.4816191648347302
reward_mean: 2072.681742944909
reward_std: 696.4397673995429
reward_max: 3095.9098350561694
reward_min: 1183.0779119769704
total_envstep_count: 12649578
total_train_sample_count: 9519685
total_episode_count: 30272
total_duration: 2626.6967322986748
[2023-06-29 12:18:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3376
train_sample_count: 3376
avg_envstep_per_episode: 375.1111111111111
avg_sample_per_episode: 375.1111111111111
avg_envstep_per_sec: 2752.271413601127
avg_train_sample_per_sec: 2752.271413601127
avg_episode_per_sec: 7.337216446211534
collect_time: 1.2266232114015145
reward_mean: 3000.647660972344
reward_std: 813.5415273389008
reward_max: 3649.616949551883
reward_min: 1760.1013259188487
total_envstep_count: 12654378
total_train_sample_count: 9523061
total_episode_count: 30281
total_duration: 2627.9233555100764
[2023-06-29 12:18:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1783
train_sample_count: 1783
avg_envstep_per_episode: 297.1666666666667
avg_sample_per_episode: 297.1666666666667
avg_envstep_per_sec: 2778.7218983055336
avg_train_sample_per_sec: 2778.7218983055336
avg_episode_per_sec: 9.350718670686035
collect_time: 0.6416619097748769
reward_mean: 1640.0819115300053
reward_std: 694.7605176810803
reward_max: 2654.9108164473378
reward_min: 806.8075330934963
total_envstep_count: 12659410
total_train_sample_count: 9526444
total_episode_count: 30287
total_duration: 2628.5650174198513
[2023-06-29 12:19:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 922
train_sample_count: 922
avg_envstep_per_episode: 184.4
avg_sample_per_episode: 184.4
avg_envstep_per_sec: 2383.3242925185227
avg_train_sample_per_sec: 2383.3242925185227
avg_episode_per_sec: 12.924752128625393
collect_time: 0.3868546143276616
reward_mean: 2882.1826881575735
reward_std: 831.2316782477526
reward_max: 3628.6198166339236
reward_min: 1399.5681483963033
total_envstep_count: 12663770
total_train_sample_count: 9529766
total_episode_count: 30292
total_duration: 2628.951872034179
[2023-06-29 12:19:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2846
train_sample_count: 2846
avg_envstep_per_episode: 258.72727272727275
avg_sample_per_episode: 258.72727272727275
avg_envstep_per_sec: 2621.499285858544
avg_train_sample_per_sec: 2621.499285858544
avg_episode_per_sec: 10.132288174435693
collect_time: 1.0856382892616092
reward_mean: 2276.7407938296715
reward_std: 1020.0430175522392
reward_max: 3648.8556095916374
reward_min: 714.7628779067419
total_envstep_count: 12668354
total_train_sample_count: 9533012
total_episode_count: 30303
total_duration: 2630.0375103234405
[2023-06-29 12:19:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2004
train_sample_count: 2004
avg_envstep_per_episode: 334.0
avg_sample_per_episode: 334.0
avg_envstep_per_sec: 2531.556134533241
avg_train_sample_per_sec: 2531.556134533241
avg_episode_per_sec: 7.579509384830063
collect_time: 0.7916079650232564
reward_mean: 2175.058961498496
reward_std: 628.0332151518378
reward_max: 2975.4506564434564
reward_min: 1319.0908029096584
total_envstep_count: 12672650
total_train_sample_count: 9536216
total_episode_count: 30309
total_duration: 2630.8291182884636
[2023-06-29 12:19:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2788
train_sample_count: 2788
avg_envstep_per_episode: 309.77777777777777
avg_sample_per_episode: 309.77777777777777
avg_envstep_per_sec: 2619.540821033874
avg_train_sample_per_sec: 2619.540821033874
avg_episode_per_sec: 8.456193468186823
collect_time: 1.0643086672341449
reward_mean: 2095.832378564722
reward_std: 929.8306239518157
reward_max: 3557.1018404755746
reward_min: 842.4669248817718
total_envstep_count: 12677146
total_train_sample_count: 9539804
total_episode_count: 30318
total_duration: 2631.8934269556976
[2023-06-29 12:19:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 261.3333333333333
avg_sample_per_episode: 261.3333333333333
avg_envstep_per_sec: 2743.4542022375235
avg_train_sample_per_sec: 2743.4542022375235
avg_episode_per_sec: 10.49791148815379
collect_time: 0.5715422545494511
reward_mean: 1938.4246037853873
reward_std: 598.6480222269145
reward_max: 3041.9036159342404
reward_min: 1138.6795087691278
total_envstep_count: 12681890
total_train_sample_count: 9543372
total_episode_count: 30324
total_duration: 2632.464969210247
[2023-06-29 12:19:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2554
train_sample_count: 2554
avg_envstep_per_episode: 319.25
avg_sample_per_episode: 319.25
avg_envstep_per_sec: 2655.1772231012114
avg_train_sample_per_sec: 2655.1772231012114
avg_episode_per_sec: 8.31692160720818
collect_time: 0.9618943616189063
reward_mean: 2515.0060575042053
reward_std: 878.5205872319387
reward_max: 3736.264381147066
reward_min: 1575.3723941564242
total_envstep_count: 12686570
total_train_sample_count: 9546726
total_episode_count: 30332
total_duration: 2633.426863571866
[2023-06-29 12:19:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2442
train_sample_count: 2442
avg_envstep_per_episode: 271.3333333333333
avg_sample_per_episode: 271.3333333333333
avg_envstep_per_sec: 2579.371887817651
avg_train_sample_per_sec: 2579.371887817651
avg_episode_per_sec: 9.506284598836551
collect_time: 0.9467421163786203
reward_mean: 1910.305965056212
reward_std: 970.8993545467035
reward_max: 3675.2691034320587
reward_min: 818.8335356863338
total_envstep_count: 12690778
total_train_sample_count: 9549968
total_episode_count: 30341
total_duration: 2634.3736056882444
[2023-06-29 12:19:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2133
train_sample_count: 2133
avg_envstep_per_episode: 304.7142857142857
avg_sample_per_episode: 304.7142857142857
avg_envstep_per_sec: 2713.7441990777584
avg_train_sample_per_sec: 2713.7441990777584
avg_episode_per_sec: 8.905864694582423
collect_time: 0.7859989164508877
reward_mean: 1999.2958268013888
reward_std: 728.6155626580285
reward_max: 3535.5041178096913
reward_min: 1248.054857901706
total_envstep_count: 12695226
total_train_sample_count: 9553301
total_episode_count: 30348
total_duration: 2635.1596046046952
[2023-06-29 12:19:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1284
train_sample_count: 1284
avg_envstep_per_episode: 428.0
avg_sample_per_episode: 428.0
avg_envstep_per_sec: 2786.516299103205
avg_train_sample_per_sec: 2786.516299103205
avg_episode_per_sec: 6.510552100708422
collect_time: 0.4607904143296182
reward_mean: 2860.4166988329816
reward_std: 983.3266589753149
reward_max: 3567.0701337699593
reward_min: 1469.8447502131703
total_envstep_count: 12699218
total_train_sample_count: 9556585
total_episode_count: 30351
total_duration: 2635.6203950190247
[2023-06-29 12:19:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1553
train_sample_count: 1553
avg_envstep_per_episode: 258.8333333333333
avg_sample_per_episode: 258.8333333333333
avg_envstep_per_sec: 2772.0269306254677
avg_train_sample_per_sec: 2772.0269306254677
avg_episode_per_sec: 10.70969837975068
collect_time: 0.5602398673845452
reward_mean: 3181.4473189830132
reward_std: 565.7310324435988
reward_max: 3589.9816105794594
reward_min: 2249.980904413576
total_envstep_count: 12703994
total_train_sample_count: 9560138
total_episode_count: 30357
total_duration: 2636.1806348864093
[2023-06-29 12:19:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3063
train_sample_count: 3063
avg_envstep_per_episode: 340.3333333333333
avg_sample_per_episode: 340.3333333333333
avg_envstep_per_sec: 2647.791767354891
avg_train_sample_per_sec: 2647.791767354891
avg_episode_per_sec: 7.7799953986921375
collect_time: 1.1568130235029384
reward_mean: 2546.845092592675
reward_std: 782.0086127517073
reward_max: 3572.2066169668237
reward_min: 1651.4772242127112
total_envstep_count: 12709194
total_train_sample_count: 9563601
total_episode_count: 30366
total_duration: 2637.337447909912
[2023-06-29 12:19:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 306.0
avg_sample_per_episode: 306.0
avg_envstep_per_sec: 2684.1882049935816
avg_train_sample_per_sec: 2684.1882049935816
avg_episode_per_sec: 8.771856879063993
collect_time: 0.9120075840605423
reward_mean: 1810.1587715728065
reward_std: 615.8675110750519
reward_max: 2902.551073342003
reward_min: 841.7909388122885
total_envstep_count: 12713618
total_train_sample_count: 9566849
total_episode_count: 30374
total_duration: 2638.2494554939726
[2023-06-29 12:19:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2601
train_sample_count: 2601
avg_envstep_per_episode: 325.125
avg_sample_per_episode: 325.125
avg_envstep_per_sec: 2541.839190553177
avg_train_sample_per_sec: 2541.839190553177
avg_episode_per_sec: 7.818036726038223
collect_time: 1.023274804191664
reward_mean: 2318.529273167003
reward_std: 678.1404525841103
reward_max: 3550.653988793881
reward_min: 1213.569467824005
total_envstep_count: 12718130
total_train_sample_count: 9570250
total_episode_count: 30382
total_duration: 2639.2727302981643
[2023-06-29 12:19:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1334
train_sample_count: 1334
avg_envstep_per_episode: 333.5
avg_sample_per_episode: 333.5
avg_envstep_per_sec: 2796.594346924894
avg_train_sample_per_sec: 2796.594346924894
avg_episode_per_sec: 8.385590245651857
collect_time: 0.47700875941012055
reward_mean: 2274.8050657468552
reward_std: 903.4349449948536
reward_max: 3555.9216527153208
reward_min: 1123.057205329838
total_envstep_count: 12722050
total_train_sample_count: 9573584
total_episode_count: 30386
total_duration: 2639.7497390575745
[2023-06-29 12:19:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1553
train_sample_count: 1553
avg_envstep_per_episode: 194.125
avg_sample_per_episode: 194.125
avg_envstep_per_sec: 2753.520317056149
avg_train_sample_per_sec: 2753.520317056149
avg_episode_per_sec: 14.184264350579003
collect_time: 0.5640052809417246
reward_mean: 2147.1603375988325
reward_std: 746.617506805921
reward_max: 3458.484839169974
reward_min: 1027.8785727766387
total_envstep_count: 12726418
total_train_sample_count: 9577137
total_episode_count: 30394
total_duration: 2640.3137443385162
[2023-06-29 12:19:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2976
train_sample_count: 2976
avg_envstep_per_episode: 372.0
avg_sample_per_episode: 372.0
avg_envstep_per_sec: 2620.383263154121
avg_train_sample_per_sec: 2620.383263154121
avg_episode_per_sec: 7.0440410299841965
collect_time: 1.1357117265425622
reward_mean: 2535.8488200016186
reward_std: 827.8407136421587
reward_max: 3660.9188345738808
reward_min: 1163.883273265639
total_envstep_count: 12730570
total_train_sample_count: 9580513
total_episode_count: 30402
total_duration: 2641.4494560650587
[2023-06-29 12:19:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2116
train_sample_count: 2116
avg_envstep_per_episode: 352.6666666666667
avg_sample_per_episode: 352.6666666666667
avg_envstep_per_sec: 2814.8786189763055
avg_train_sample_per_sec: 2814.8786189763055
avg_episode_per_sec: 7.981697407305213
collect_time: 0.7517198026711118
reward_mean: 1869.36560197219
reward_std: 843.1651293983813
reward_max: 3595.2394886219936
reward_min: 1045.059676013355
total_envstep_count: 12734898
total_train_sample_count: 9583829
total_episode_count: 30408
total_duration: 2642.20117586773
[2023-06-29 12:19:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2277
train_sample_count: 2277
avg_envstep_per_episode: 325.2857142857143
avg_sample_per_episode: 325.2857142857143
avg_envstep_per_sec: 2693.7714114460714
avg_train_sample_per_sec: 2693.7714114460714
avg_episode_per_sec: 8.281247202513175
collect_time: 0.8452833044128492
reward_mean: 2402.205816039717
reward_std: 572.9243414076684
reward_max: 3499.1773144216327
reward_min: 1655.869566171375
total_envstep_count: 12739474
total_train_sample_count: 9587306
total_episode_count: 30415
total_duration: 2643.046459172143
[2023-06-29 12:19:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 339.3333333333333
avg_sample_per_episode: 339.3333333333333
avg_envstep_per_sec: 2711.40481024883
avg_train_sample_per_sec: 2711.40481024883
avg_episode_per_sec: 7.9903874565289685
collect_time: 0.750902260077186
reward_mean: 2148.91597886153
reward_std: 654.5258275801433
reward_max: 3437.907244140251
reward_min: 1487.9504714106158
total_envstep_count: 12743938
total_train_sample_count: 9590542
total_episode_count: 30421
total_duration: 2643.79736143222
[2023-06-29 12:19:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2253
train_sample_count: 2253
avg_envstep_per_episode: 281.625
avg_sample_per_episode: 281.625
avg_envstep_per_sec: 2653.9826605501394
avg_train_sample_per_sec: 2653.9826605501394
avg_episode_per_sec: 9.423817702796766
collect_time: 0.8489128559464588
reward_mean: 2556.1489893448406
reward_std: 770.7339429072032
reward_max: 3662.2685576955105
reward_min: 1430.5671203791783
total_envstep_count: 12748610
total_train_sample_count: 9593995
total_episode_count: 30429
total_duration: 2644.6462742881663
[2023-06-29 12:20:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 712
train_sample_count: 712
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 2705.089264763492
avg_train_sample_per_sec: 2705.089264763492
avg_episode_per_sec: 15.197130700918494
collect_time: 0.26320758034661407
reward_mean: 2201.118097999064
reward_std: 725.3497952253555
reward_max: 3407.818278272512
reward_min: 1472.646239988595
total_envstep_count: 12752842
total_train_sample_count: 9597507
total_episode_count: 30433
total_duration: 2644.909481868513
[2023-06-29 12:20:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1632
train_sample_count: 1632
avg_envstep_per_episode: 326.4
avg_sample_per_episode: 326.4
avg_envstep_per_sec: 2422.4529916897095
avg_train_sample_per_sec: 2422.4529916897095
avg_episode_per_sec: 7.421730979441512
collect_time: 0.6736972835380584
reward_mean: 3530.50493542205
reward_std: 68.78716206399588
reward_max: 3575.7448937886593
reward_min: 3394.357313105057
total_envstep_count: 12757218
total_train_sample_count: 9600739
total_episode_count: 30438
total_duration: 2645.583179152051
[2023-06-29 12:20:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1680
train_sample_count: 1680
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 2716.885114328576
avg_train_sample_per_sec: 2716.885114328576
avg_episode_per_sec: 9.703161122602056
collect_time: 0.6183551859222353
reward_mean: 2625.2455341204
reward_std: 984.987778507019
reward_max: 3619.761417725416
reward_min: 1274.8765109170427
total_envstep_count: 12761250
total_train_sample_count: 9604019
total_episode_count: 30444
total_duration: 2646.201534337973
[2023-06-29 12:20:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2155
train_sample_count: 2155
avg_envstep_per_episode: 307.85714285714283
avg_sample_per_episode: 307.85714285714283
avg_envstep_per_sec: 2523.9107007880893
avg_train_sample_per_sec: 2523.9107007880893
avg_episode_per_sec: 8.19831782158544
collect_time: 0.8538336951965466
reward_mean: 2716.5609274531917
reward_std: 997.4886779650492
reward_max: 3561.557428644961
reward_min: 1030.3373215862428
total_envstep_count: 12765522
total_train_sample_count: 9607374
total_episode_count: 30451
total_duration: 2647.0553680331695
[2023-06-29 12:20:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2382
train_sample_count: 2382
avg_envstep_per_episode: 297.75
avg_sample_per_episode: 297.75
avg_envstep_per_sec: 2771.85970631211
avg_train_sample_per_sec: 2771.85970631211
avg_episode_per_sec: 9.309352498109522
collect_time: 0.8593508519120512
reward_mean: 3408.552593152527
reward_std: 199.7736207076271
reward_max: 3554.690185221485
reward_min: 2914.929857264922
total_envstep_count: 12773522
total_train_sample_count: 9614156
total_episode_count: 30459
total_duration: 2647.9147188850816
[2023-06-29 12:20:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 403.0
avg_sample_per_episode: 403.0
avg_envstep_per_sec: 2777.2557898813293
avg_train_sample_per_sec: 2777.2557898813293
avg_episode_per_sec: 6.891453572906524
collect_time: 0.43532180377654733
reward_mean: 2746.2865133969535
reward_std: 1000.2338726389503
reward_max: 3558.5972012330444
reward_min: 1337.2277794248562
total_envstep_count: 12777250
total_train_sample_count: 9617365
total_episode_count: 30462
total_duration: 2648.350040688858
[2023-06-29 12:20:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2777.3443515045788
avg_train_sample_per_sec: 2777.3443515045788
avg_episode_per_sec: 12.510560141912517
collect_time: 0.47959483284037563
reward_mean: 2927.3328690612793
reward_std: 859.3651140871867
reward_max: 3543.379198289413
reward_min: 1330.566337569283
total_envstep_count: 12781626
total_train_sample_count: 9620697
total_episode_count: 30468
total_duration: 2648.8296355216985
[2023-06-29 12:20:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 402.5
avg_sample_per_episode: 402.5
avg_envstep_per_sec: 2760.165226704794
avg_train_sample_per_sec: 2760.165226704794
avg_episode_per_sec: 6.857553358272781
collect_time: 0.5832984143206849
reward_mean: 2940.8695498883044
reward_std: 487.4345770140117
reward_max: 3425.7619654491295
reward_min: 2330.484072592247
total_envstep_count: 12785514
total_train_sample_count: 9623907
total_episode_count: 30472
total_duration: 2649.4129339360193
[2023-06-29 12:20:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 903
train_sample_count: 903
avg_envstep_per_episode: 180.6
avg_sample_per_episode: 180.6
avg_envstep_per_sec: 2744.8246020214715
avg_train_sample_per_sec: 2744.8246020214715
avg_episode_per_sec: 15.19836435227836
collect_time: 0.32898276973143226
reward_mean: 3132.391064628435
reward_std: 767.8429346206201
reward_max: 3593.0349743447714
reward_min: 1599.5464955324303
total_envstep_count: 12789626
total_train_sample_count: 9627210
total_episode_count: 30477
total_duration: 2649.7419167057506
[2023-06-29 12:20:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2532
train_sample_count: 2532
avg_envstep_per_episode: 316.5
avg_sample_per_episode: 316.5
avg_envstep_per_sec: 2586.1992421992977
avg_train_sample_per_sec: 2586.1992421992977
avg_episode_per_sec: 8.171245630961446
collect_time: 0.9790428976565599
reward_mean: 2572.361144646002
reward_std: 1048.6011383316875
reward_max: 3557.2438008147415
reward_min: 550.3246894381192
total_envstep_count: 12794066
total_train_sample_count: 9630542
total_episode_count: 30485
total_duration: 2650.720959603407
[2023-06-29 12:20:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1883
train_sample_count: 1883
avg_envstep_per_episode: 376.6
avg_sample_per_episode: 376.6
avg_envstep_per_sec: 2729.841335089
avg_train_sample_per_sec: 2729.841335089
avg_episode_per_sec: 7.248649323125332
collect_time: 0.6897836792916059
reward_mean: 2494.280703571939
reward_std: 817.8002984193026
reward_max: 3461.7629807666945
reward_min: 1485.9894536896786
total_envstep_count: 12799010
total_train_sample_count: 9634025
total_episode_count: 30490
total_duration: 2651.4107432826986
[2023-06-29 12:20:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1291
train_sample_count: 1291
avg_envstep_per_episode: 258.2
avg_sample_per_episode: 258.2
avg_envstep_per_sec: 2753.339424015302
avg_train_sample_per_sec: 2753.339424015302
avg_episode_per_sec: 10.663591882321077
collect_time: 0.4688851613206789
reward_mean: 2722.813230443892
reward_std: 1144.684554315004
reward_max: 3516.3572193148298
reward_min: 524.1423113954269
total_envstep_count: 12802938
total_train_sample_count: 9637316
total_episode_count: 30495
total_duration: 2651.879628444019
[2023-06-29 12:20:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1937
train_sample_count: 1937
avg_envstep_per_episode: 322.8333333333333
avg_sample_per_episode: 322.8333333333333
avg_envstep_per_sec: 2779.0044245107924
avg_train_sample_per_sec: 2779.0044245107924
avg_episode_per_sec: 8.608170648975094
collect_time: 0.697012204412371
reward_mean: 3110.604547772036
reward_std: 616.4818371386662
reward_max: 3589.747280977932
reward_min: 1933.8013416361187
total_envstep_count: 12808138
total_train_sample_count: 9640853
total_episode_count: 30501
total_duration: 2652.5766406484313
[2023-06-29 12:20:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1650
train_sample_count: 1650
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 2513.2393571002635
avg_train_sample_per_sec: 2513.2393571002635
avg_episode_per_sec: 7.615876839697767
collect_time: 0.6565232218485327
reward_mean: 3053.382246273747
reward_std: 649.1823342923194
reward_max: 3546.0924859567212
reward_min: 1846.0405304950123
total_envstep_count: 12813114
total_train_sample_count: 9644103
total_episode_count: 30506
total_duration: 2653.23316387028
[2023-06-29 12:20:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1922
train_sample_count: 1922
avg_envstep_per_episode: 240.25
avg_sample_per_episode: 240.25
avg_envstep_per_sec: 2709.8812088835894
avg_train_sample_per_sec: 2709.8812088835894
avg_episode_per_sec: 11.279422305446783
collect_time: 0.7092561820419505
reward_mean: 2514.3689562534933
reward_std: 1108.6487690057065
reward_max: 3607.076181445911
reward_min: 657.6620235537464
total_envstep_count: 12818066
total_train_sample_count: 9647625
total_episode_count: 30514
total_duration: 2653.9424200523217
[2023-06-29 12:20:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 350.0
avg_sample_per_episode: 350.0
avg_envstep_per_sec: 2706.5844809153036
avg_train_sample_per_sec: 2706.5844809153036
avg_episode_per_sec: 7.733098516900868
collect_time: 0.9051998994583266
reward_mean: 2794.2913596785065
reward_std: 747.2395678822948
reward_max: 3579.235884623563
reward_min: 1875.9436557231254
total_envstep_count: 12822218
total_train_sample_count: 9650875
total_episode_count: 30521
total_duration: 2654.84761995178
[2023-06-29 12:20:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1725
train_sample_count: 1725
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 2647.560561334506
avg_train_sample_per_sec: 2647.560561334506
avg_episode_per_sec: 9.208906300293933
collect_time: 0.6515431696604937
reward_mean: 2259.773065203413
reward_std: 795.029392778487
reward_max: 3563.0828760182117
reward_min: 1070.6116132770023
total_envstep_count: 12826938
total_train_sample_count: 9654200
total_episode_count: 30527
total_duration: 2655.4991631214402
[2023-06-29 12:20:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2903
train_sample_count: 2903
avg_envstep_per_episode: 263.90909090909093
avg_sample_per_episode: 263.90909090909093
avg_envstep_per_sec: 2770.230551668427
avg_train_sample_per_sec: 2770.230551668427
avg_episode_per_sec: 10.496912183380191
collect_time: 1.0479272197224199
reward_mean: 1938.966088343067
reward_std: 932.4096494154187
reward_max: 3474.7296859053163
reward_min: 516.7060041896543
total_envstep_count: 12831530
total_train_sample_count: 9657503
total_episode_count: 30538
total_duration: 2656.547090341163
[2023-06-29 12:20:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2817
train_sample_count: 2817
avg_envstep_per_episode: 402.42857142857144
avg_sample_per_episode: 402.42857142857144
avg_envstep_per_sec: 2593.487064921142
avg_train_sample_per_sec: 2593.487064921142
avg_episode_per_sec: 6.444589795686189
collect_time: 1.0861823982475325
reward_mean: 2278.2059699839206
reward_std: 580.0331486262507
reward_max: 3507.258434831529
reward_min: 1697.7552577757936
total_envstep_count: 12836098
total_train_sample_count: 9660720
total_episode_count: 30545
total_duration: 2657.6332727394106
[2023-06-29 12:21:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 424
train_sample_count: 424
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2676.978042135543
avg_train_sample_per_sec: 2676.978042135543
avg_episode_per_sec: 12.627254915733692
collect_time: 0.15838755242899064
reward_mean: 2611.293383984018
reward_std: 230.92866850776886
reward_max: 2842.222052491787
reward_min: 2380.3647154762493
total_envstep_count: 12839434
total_train_sample_count: 9663944
total_episode_count: 30547
total_duration: 2657.7916602918394
[2023-06-29 12:21:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2534
train_sample_count: 2534
avg_envstep_per_episode: 316.75
avg_sample_per_episode: 316.75
avg_envstep_per_sec: 2493.4426327138804
avg_train_sample_per_sec: 2493.4426327138804
avg_episode_per_sec: 7.871957798623143
collect_time: 1.0162656107479708
reward_mean: 2812.137885144565
reward_std: 773.0620943291046
reward_max: 3587.979349165786
reward_min: 1678.0526958255236
total_envstep_count: 12844234
total_train_sample_count: 9667278
total_episode_count: 30555
total_duration: 2658.8079259025876
[2023-06-29 12:21:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2580
train_sample_count: 2580
avg_envstep_per_episode: 368.57142857142856
avg_sample_per_episode: 368.57142857142856
avg_envstep_per_sec: 2731.838251122289
avg_train_sample_per_sec: 2731.838251122289
avg_episode_per_sec: 7.411964247231017
collect_time: 0.9444190185638146
reward_mean: 2432.1085174221466
reward_std: 561.08907997907
reward_max: 3465.6968727828234
reward_min: 1912.0480080527425
total_envstep_count: 12849082
total_train_sample_count: 9670658
total_episode_count: 30562
total_duration: 2659.7523449211512
[2023-06-29 12:21:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 309.0
avg_sample_per_episode: 309.0
avg_envstep_per_sec: 2668.3335251603803
avg_train_sample_per_sec: 2668.3335251603803
avg_episode_per_sec: 8.63538357657081
collect_time: 0.3474078451059759
reward_mean: 3161.6869661256965
reward_std: 543.826036752169
reward_max: 3582.6087853500308
reward_min: 2393.7865943743523
total_envstep_count: 12854410
total_train_sample_count: 9673985
total_episode_count: 30565
total_duration: 2660.099752766257
[2023-06-29 12:21:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 305.0
avg_sample_per_episode: 305.0
avg_envstep_per_sec: 2814.656168892298
avg_train_sample_per_sec: 2814.656168892298
avg_episode_per_sec: 9.228380881614092
collect_time: 0.7585295936306937
reward_mean: 3534.0931570185244
reward_std: 35.02894641804284
reward_max: 3571.309457877843
reward_min: 3487.241935211324
total_envstep_count: 12859210
total_train_sample_count: 9677320
total_episode_count: 30572
total_duration: 2660.8582823598877
[2023-06-29 12:21:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 257.375
avg_sample_per_episode: 257.375
avg_envstep_per_sec: 2469.6615882535352
avg_train_sample_per_sec: 2469.6615882535352
avg_episode_per_sec: 9.59557683634205
collect_time: 0.8337174654994162
reward_mean: 2206.571389961177
reward_std: 979.966196115432
reward_max: 3567.5329878145744
reward_min: 1027.675802419392
total_envstep_count: 12863434
total_train_sample_count: 9680579
total_episode_count: 30580
total_duration: 2661.691999825387
[2023-06-29 12:21:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 852
train_sample_count: 852
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2744.926957067427
avg_train_sample_per_sec: 2744.926957067427
avg_episode_per_sec: 9.665235764321926
collect_time: 0.3103907729880884
reward_mean: 2748.804755548144
reward_std: 566.729273489276
reward_max: 3548.5230161070604
reward_min: 2302.9985694218753
total_envstep_count: 12867994
total_train_sample_count: 9683831
total_episode_count: 30583
total_duration: 2662.0023905983753
[2023-06-29 12:21:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2217
train_sample_count: 2217
avg_envstep_per_episode: 221.7
avg_sample_per_episode: 221.7
avg_envstep_per_sec: 2573.5913178196097
avg_train_sample_per_sec: 2573.5913178196097
avg_episode_per_sec: 11.608440765988316
collect_time: 0.8614421352175994
reward_mean: 2375.333798760991
reward_std: 899.0314146219062
reward_max: 3575.180910236449
reward_min: 1355.9004230081139
total_envstep_count: 12872170
total_train_sample_count: 9687248
total_episode_count: 30593
total_duration: 2662.863832733593
[2023-06-29 12:21:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1977
train_sample_count: 1977
avg_envstep_per_episode: 329.5
avg_sample_per_episode: 329.5
avg_envstep_per_sec: 2540.638202274718
avg_train_sample_per_sec: 2540.638202274718
avg_episode_per_sec: 7.710586349847399
collect_time: 0.7781509379139171
reward_mean: 2178.7883559320626
reward_std: 765.3239336476929
reward_max: 3515.3229471957206
reward_min: 1372.2908818631154
total_envstep_count: 12877066
total_train_sample_count: 9690825
total_episode_count: 30599
total_duration: 2663.6419836715068
[2023-06-29 12:21:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1735
train_sample_count: 1735
avg_envstep_per_episode: 433.75
avg_sample_per_episode: 433.75
avg_envstep_per_sec: 2768.020556603516
avg_train_sample_per_sec: 2768.020556603516
avg_episode_per_sec: 6.381603588711276
collect_time: 0.6268017034269868
reward_mean: 3520.147543557925
reward_std: 17.56369460884236
reward_max: 3545.955813880993
reward_min: 3502.952507223422
total_envstep_count: 12881866
total_train_sample_count: 9694160
total_episode_count: 30603
total_duration: 2664.268785374934
[2023-06-29 12:21:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 250.375
avg_sample_per_episode: 250.375
avg_envstep_per_sec: 2737.0365480538485
avg_train_sample_per_sec: 2737.0365480538485
avg_episode_per_sec: 10.931748569361352
collect_time: 0.7318133919052779
reward_mean: 2437.816428291201
reward_std: 1131.5569755780389
reward_max: 3567.3192404063643
reward_min: 1035.6862368816398
total_envstep_count: 12886714
total_train_sample_count: 9697363
total_episode_count: 30611
total_duration: 2665.000598766839
[2023-06-29 12:21:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1370
train_sample_count: 1370
avg_envstep_per_episode: 228.33333333333334
avg_sample_per_episode: 228.33333333333334
avg_envstep_per_sec: 2742.3037006410996
avg_train_sample_per_sec: 2742.3037006410996
avg_episode_per_sec: 12.010089199888029
collect_time: 0.4995799698187037
reward_mean: 2222.8736531519476
reward_std: 833.3646560377227
reward_max: 3549.7151328026257
reward_min: 1007.295123080408
total_envstep_count: 12891410
total_train_sample_count: 9700733
total_episode_count: 30617
total_duration: 2665.5001787366577
[2023-06-29 12:21:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 293.2857142857143
avg_sample_per_episode: 293.2857142857143
avg_envstep_per_sec: 2626.603409764232
avg_train_sample_per_sec: 2626.603409764232
avg_episode_per_sec: 8.955783666999329
collect_time: 0.7816178081426768
reward_mean: 3029.142694036777
reward_std: 773.2102421402842
reward_max: 3563.5079969503895
reward_min: 1730.0528681664487
total_envstep_count: 12895306
total_train_sample_count: 9703986
total_episode_count: 30624
total_duration: 2666.2817965448003
[2023-06-29 12:21:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1668
train_sample_count: 1668
avg_envstep_per_episode: 333.6
avg_sample_per_episode: 333.6
avg_envstep_per_sec: 2436.942772863748
avg_train_sample_per_sec: 2436.942772863748
avg_episode_per_sec: 7.3049843311263425
collect_time: 0.684464164925739
reward_mean: 2337.4562278978497
reward_std: 759.5973834018974
reward_max: 3282.2087561812737
reward_min: 1119.2400988753925
total_envstep_count: 12900410
total_train_sample_count: 9707254
total_episode_count: 30629
total_duration: 2666.966260709726
[2023-06-29 12:21:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2437
train_sample_count: 2437
avg_envstep_per_episode: 304.625
avg_sample_per_episode: 304.625
avg_envstep_per_sec: 2677.142227200783
avg_train_sample_per_sec: 2677.142227200783
avg_episode_per_sec: 8.788320811492106
collect_time: 0.9102990402374418
reward_mean: 2796.940892907556
reward_std: 968.2996309850009
reward_max: 3565.8541300160437
reward_min: 1233.4052159758319
total_envstep_count: 12905226
total_train_sample_count: 9710491
total_episode_count: 30637
total_duration: 2667.8765597499637
[2023-06-29 12:21:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2075
train_sample_count: 2075
avg_envstep_per_episode: 345.8333333333333
avg_sample_per_episode: 345.8333333333333
avg_envstep_per_sec: 2794.342694963429
avg_train_sample_per_sec: 2794.342694963429
avg_episode_per_sec: 8.08002706977377
collect_time: 0.7425717696473004
reward_mean: 2482.4407650932717
reward_std: 813.0935686726914
reward_max: 3612.677559705701
reward_min: 1597.053707474775
total_envstep_count: 12909314
total_train_sample_count: 9713766
total_episode_count: 30643
total_duration: 2668.619131519611
[2023-06-29 12:21:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 269.6666666666667
avg_sample_per_episode: 269.6666666666667
avg_envstep_per_sec: 2256.4496519549366
avg_train_sample_per_sec: 2256.4496519549366
avg_episode_per_sec: 8.3675512433434
collect_time: 0.3585278312321752
reward_mean: 2584.4724121062595
reward_std: 815.8985298356995
reward_max: 3324.038982239046
reward_min: 1447.6711463258523
total_envstep_count: 12913506
total_train_sample_count: 9716975
total_episode_count: 30646
total_duration: 2668.977659350843
[2023-06-29 12:21:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1272
train_sample_count: 1272
avg_envstep_per_episode: 181.71428571428572
avg_sample_per_episode: 181.71428571428572
avg_envstep_per_sec: 2792.4358828569602
avg_train_sample_per_sec: 2792.4358828569602
avg_episode_per_sec: 15.367178600627927
collect_time: 0.45551627803128214
reward_mean: 2563.0635402219605
reward_std: 1153.574389438655
reward_max: 3527.7441160191647
reward_min: 652.1167411639655
total_envstep_count: 12918034
total_train_sample_count: 9720247
total_episode_count: 30653
total_duration: 2669.4331756288743
[2023-06-29 12:21:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2243
train_sample_count: 2243
avg_envstep_per_episode: 249.22222222222223
avg_sample_per_episode: 249.22222222222223
avg_envstep_per_sec: 2693.7877697282674
avg_train_sample_per_sec: 2693.7877697282674
avg_episode_per_sec: 10.80877838945805
collect_time: 0.8326565385758878
reward_mean: 2025.635912021341
reward_std: 773.3081038788506
reward_max: 3509.6159501010175
reward_min: 1046.8665376652916
total_envstep_count: 12922410
total_train_sample_count: 9723690
total_episode_count: 30662
total_duration: 2670.2658321674503
[2023-06-29 12:22:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1302
train_sample_count: 1302
avg_envstep_per_episode: 260.4
avg_sample_per_episode: 260.4
avg_envstep_per_sec: 2766.0433890851705
avg_train_sample_per_sec: 2766.0433890851705
avg_episode_per_sec: 10.622286440419241
collect_time: 0.47070845133438705
reward_mean: 2750.785408965302
reward_std: 625.6653285993256
reward_max: 3519.295357629926
reward_min: 1662.799418899627
total_envstep_count: 12926226
total_train_sample_count: 9726992
total_episode_count: 30667
total_duration: 2670.7365406187846
[2023-06-29 12:22:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2580
train_sample_count: 2580
avg_envstep_per_episode: 286.6666666666667
avg_sample_per_episode: 286.6666666666667
avg_envstep_per_sec: 2593.845073515755
avg_train_sample_per_sec: 2593.845073515755
avg_episode_per_sec: 9.048296768078215
collect_time: 0.9946623359825462
reward_mean: 2049.4556667486772
reward_std: 837.9795985193052
reward_max: 3521.239527558601
reward_min: 1127.4458664049241
total_envstep_count: 12930746
total_train_sample_count: 9730372
total_episode_count: 30676
total_duration: 2671.731202954767
[2023-06-29 12:22:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1633
train_sample_count: 1633
avg_envstep_per_episode: 272.1666666666667
avg_sample_per_episode: 272.1666666666667
avg_envstep_per_sec: 2747.0213487381297
avg_train_sample_per_sec: 2747.0213487381297
avg_episode_per_sec: 10.093158660397291
collect_time: 0.5944620709810406
reward_mean: 2061.2723235076587
reward_std: 605.206112088724
reward_max: 2998.7894074329233
reward_min: 1336.353995418905
total_envstep_count: 12934778
total_train_sample_count: 9733605
total_episode_count: 30682
total_duration: 2672.325665025748
[2023-06-29 12:22:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2918
train_sample_count: 2918
avg_envstep_per_episode: 265.27272727272725
avg_sample_per_episode: 265.27272727272725
avg_envstep_per_sec: 2806.523868908286
avg_train_sample_per_sec: 2806.523868908286
avg_episode_per_sec: 10.579767840298542
collect_time: 1.039720357388258
reward_mean: 1787.3109342828284
reward_std: 508.78304789856105
reward_max: 2944.658843869774
reward_min: 1005.2842244791433
total_envstep_count: 12939010
total_train_sample_count: 9736923
total_episode_count: 30693
total_duration: 2673.3653853831365
[2023-06-29 12:22:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2746
train_sample_count: 2746
avg_envstep_per_episode: 343.25
avg_sample_per_episode: 343.25
avg_envstep_per_sec: 2812.167220247472
avg_train_sample_per_sec: 2812.167220247472
avg_episode_per_sec: 8.19276684704289
collect_time: 0.9764710932653395
reward_mean: 1788.1104487985813
reward_std: 436.2137049230772
reward_max: 2321.6566821860083
reward_min: 1067.169055339399
total_envstep_count: 12943594
total_train_sample_count: 9740469
total_episode_count: 30701
total_duration: 2674.341856476402
[2023-06-29 12:22:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2836
train_sample_count: 2836
avg_envstep_per_episode: 257.8181818181818
avg_sample_per_episode: 257.8181818181818
avg_envstep_per_sec: 2679.0806014902714
avg_train_sample_per_sec: 2679.0806014902714
avg_episode_per_sec: 10.391356352747879
collect_time: 1.0585721080666406
reward_mean: 1523.7979204771152
reward_std: 599.6054038929851
reward_max: 2931.2201661518984
reward_min: 472.4650827898337
total_envstep_count: 12948370
total_train_sample_count: 9743705
total_episode_count: 30712
total_duration: 2675.4004285844685
[2023-06-29 12:22:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2971
train_sample_count: 2971
avg_envstep_per_episode: 270.09090909090907
avg_sample_per_episode: 270.09090909090907
avg_envstep_per_sec: 2572.0150285521318
avg_train_sample_per_sec: 2572.0150285521318
avg_episode_per_sec: 9.52277526559187
collect_time: 1.1551254432881248
reward_mean: 1622.612041848547
reward_std: 462.4732888373861
reward_max: 2521.259986216057
reward_min: 797.35157659885
total_envstep_count: 12953386
total_train_sample_count: 9747076
total_episode_count: 30723
total_duration: 2676.5555540277564
[2023-06-29 12:22:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2807
train_sample_count: 2807
avg_envstep_per_episode: 233.91666666666666
avg_sample_per_episode: 233.91666666666666
avg_envstep_per_sec: 2758.1966781153546
avg_train_sample_per_sec: 2758.1966781153546
avg_episode_per_sec: 11.791364494971235
collect_time: 1.017693923813291
reward_mean: 1460.31917185389
reward_std: 645.2571413540006
reward_max: 3370.0647216768807
reward_min: 794.0887942920893
total_envstep_count: 12957826
total_train_sample_count: 9750283
total_episode_count: 30735
total_duration: 2677.5732479515696
[2023-06-29 12:22:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2488
train_sample_count: 2488
avg_envstep_per_episode: 276.44444444444446
avg_sample_per_episode: 276.44444444444446
avg_envstep_per_sec: 2721.126484619083
avg_train_sample_per_sec: 2721.126484619083
avg_episode_per_sec: 9.843303199988645
collect_time: 0.9143272148733956
reward_mean: 1669.5479389859197
reward_std: 411.81686385909154
reward_max: 2195.213483610159
reward_min: 1123.3082247592204
total_envstep_count: 12962410
total_train_sample_count: 9753571
total_episode_count: 30744
total_duration: 2678.487575166443
[2023-06-29 12:22:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2157
train_sample_count: 2157
avg_envstep_per_episode: 215.7
avg_sample_per_episode: 215.7
avg_envstep_per_sec: 2522.6724850469946
avg_train_sample_per_sec: 2522.6724850469946
avg_episode_per_sec: 11.695282730862283
collect_time: 0.8550455965986474
reward_mean: 1523.0819274357923
reward_std: 435.221708359602
reward_max: 2616.566705184399
reward_min: 1088.1040231576194
total_envstep_count: 12966722
total_train_sample_count: 9756928
total_episode_count: 30754
total_duration: 2679.342620763042
[2023-06-29 12:22:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 230.4
avg_sample_per_episode: 230.4
avg_envstep_per_sec: 2751.644633837124
avg_train_sample_per_sec: 2751.644633837124
avg_episode_per_sec: 11.942902056584739
collect_time: 0.4186587126236409
reward_mean: 2003.241293938599
reward_std: 628.5471792553485
reward_max: 2758.0855399541356
reward_min: 1197.8291980356653
total_envstep_count: 12971698
total_train_sample_count: 9760480
total_episode_count: 30759
total_duration: 2679.7612794756656
[2023-06-29 12:22:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2802.9426021993313
avg_train_sample_per_sec: 2802.9426021993313
avg_episode_per_sec: 10.267189019045171
collect_time: 0.8765787776289506
reward_mean: 2764.355078867534
reward_std: 861.6570888050275
reward_max: 3637.9513457048706
reward_min: 1469.8143458879806
total_envstep_count: 12976082
total_train_sample_count: 9763737
total_episode_count: 30768
total_duration: 2680.6378582532943
[2023-06-29 12:22:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 414.4
avg_sample_per_episode: 414.4
avg_envstep_per_sec: 2637.9867565881304
avg_train_sample_per_sec: 2637.9867565881304
avg_episode_per_sec: 6.36579815778989
collect_time: 0.7854474609568716
reward_mean: 2585.5387744791983
reward_std: 685.9098683400739
reward_max: 3413.5512767151386
reward_min: 1702.8178438816649
total_envstep_count: 12980090
total_train_sample_count: 9767009
total_episode_count: 30773
total_duration: 2681.423305714251
[2023-06-29 12:22:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 449
train_sample_count: 449
avg_envstep_per_episode: 149.66666666666666
avg_sample_per_episode: 149.66666666666666
avg_envstep_per_sec: 2735.026518997725
avg_train_sample_per_sec: 2735.026518997725
avg_episode_per_sec: 18.274119280608407
collect_time: 0.16416659834235908
reward_mean: 2876.4861725425
reward_std: 718.5381357238981
reward_max: 3538.3783822559185
reward_min: 1877.8053855141372
total_envstep_count: 12984194
total_train_sample_count: 9770258
total_episode_count: 30776
total_duration: 2681.5874723125935
[2023-06-29 12:22:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2390
train_sample_count: 2390
avg_envstep_per_episode: 265.55555555555554
avg_sample_per_episode: 265.55555555555554
avg_envstep_per_sec: 2737.9533620001052
avg_train_sample_per_sec: 2737.9533620001052
avg_episode_per_sec: 10.310284626778639
collect_time: 0.872914795836434
reward_mean: 2557.194083928607
reward_std: 835.9901071151037
reward_max: 3521.04126171999
reward_min: 1099.9735920777146
total_envstep_count: 12988546
total_train_sample_count: 9773848
total_episode_count: 30785
total_duration: 2682.46038710843
[2023-06-29 12:22:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 343.5
avg_sample_per_episode: 343.5
avg_envstep_per_sec: 2764.807371820112
avg_train_sample_per_sec: 2764.807371820112
avg_episode_per_sec: 8.048929757846032
collect_time: 0.248480240251869
reward_mean: 2804.57852931849
reward_std: 694.7341161835704
reward_max: 3499.31264550206
reward_min: 2109.8444131349193
total_envstep_count: 12992970
total_train_sample_count: 9777335
total_episode_count: 30787
total_duration: 2682.708867348682
[2023-06-29 12:22:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1622
train_sample_count: 1622
avg_envstep_per_episode: 162.2
avg_sample_per_episode: 162.2
avg_envstep_per_sec: 2629.512382555658
avg_train_sample_per_sec: 2629.512382555658
avg_episode_per_sec: 16.211543665571256
collect_time: 0.6168444045977668
reward_mean: 2280.3593907854674
reward_std: 1116.813168564655
reward_max: 3715.6307896930984
reward_min: 87.65715682635562
total_envstep_count: 12997178
total_train_sample_count: 9780557
total_episode_count: 30797
total_duration: 2683.32571175328
[2023-06-29 12:22:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2434
train_sample_count: 2434
avg_envstep_per_episode: 304.25
avg_sample_per_episode: 304.25
avg_envstep_per_sec: 2678.4774887476624
avg_train_sample_per_sec: 2678.4774887476624
avg_episode_per_sec: 8.803541458496836
collect_time: 0.9087252031145615
reward_mean: 2079.59151957873
reward_std: 887.0907752819435
reward_max: 3537.5817533469917
reward_min: 1039.9421754231787
total_envstep_count: 13001778
total_train_sample_count: 9783791
total_episode_count: 30805
total_duration: 2684.2344369563943
[2023-06-29 12:22:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 904
train_sample_count: 904
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 2691.035424573273
avg_train_sample_per_sec: 2691.035424573273
avg_episode_per_sec: 11.907236391917136
collect_time: 0.3359301745882258
reward_mean: 2436.1428403851532
reward_std: 757.5224267391451
reward_max: 3534.692264292984
reward_min: 1468.114932924416
total_envstep_count: 13006266
total_train_sample_count: 9787095
total_episode_count: 30809
total_duration: 2684.5703671309825
[2023-06-29 12:22:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1625
train_sample_count: 1625
avg_envstep_per_episode: 232.14285714285714
avg_sample_per_episode: 232.14285714285714
avg_envstep_per_sec: 2760.9303789302594
avg_train_sample_per_sec: 2760.9303789302594
avg_episode_per_sec: 11.893238555391887
collect_time: 0.5885697127319874
reward_mean: 2733.7456027002177
reward_std: 733.0025466962561
reward_max: 3609.641486655565
reward_min: 1302.040721417955
total_envstep_count: 13010106
total_train_sample_count: 9790320
total_episode_count: 30816
total_duration: 2685.1589368437144
[2023-06-29 12:23:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2041
train_sample_count: 2041
avg_envstep_per_episode: 340.1666666666667
avg_sample_per_episode: 340.1666666666667
avg_envstep_per_sec: 2528.2675277697076
avg_train_sample_per_sec: 2528.2675277697076
avg_episode_per_sec: 7.4324376122578375
collect_time: 0.8072721646670251
reward_mean: 2817.9319529408335
reward_std: 880.811100246012
reward_max: 3614.286046831789
reward_min: 1041.8691361509484
total_envstep_count: 13015234
total_train_sample_count: 9793561
total_episode_count: 30822
total_duration: 2685.9662090083816
[2023-06-29 12:23:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2462
train_sample_count: 2462
avg_envstep_per_episode: 307.75
avg_sample_per_episode: 307.75
avg_envstep_per_sec: 2495.25235542549
avg_train_sample_per_sec: 2495.25235542549
avg_episode_per_sec: 8.108049895777384
collect_time: 0.9866737505113707
reward_mean: 2577.301300951279
reward_std: 774.2826921175614
reward_max: 3507.7996881147574
reward_min: 1521.3876171842571
total_envstep_count: 13020578
total_train_sample_count: 9796823
total_episode_count: 30830
total_duration: 2686.952882758893
[2023-06-29 12:23:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1787
train_sample_count: 1787
avg_envstep_per_episode: 255.28571428571428
avg_sample_per_episode: 255.28571428571428
avg_envstep_per_sec: 2675.483081451813
avg_train_sample_per_sec: 2675.483081451813
avg_episode_per_sec: 10.480347828854333
collect_time: 0.6679167632898316
reward_mean: 2309.535557226351
reward_std: 775.9895423891163
reward_max: 3568.7109800815856
reward_min: 1311.9007128345843
total_envstep_count: 13025138
total_train_sample_count: 9800210
total_episode_count: 30837
total_duration: 2687.6207995221826
[2023-06-29 12:23:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1957
train_sample_count: 1957
avg_envstep_per_episode: 279.57142857142856
avg_sample_per_episode: 279.57142857142856
avg_envstep_per_sec: 2807.90375756088
avg_train_sample_per_sec: 2807.90375756088
avg_episode_per_sec: 10.043600563580052
collect_time: 0.6969612098457292
reward_mean: 2479.5881372340004
reward_std: 759.3412765501891
reward_max: 3554.158159807728
reward_min: 1449.0059919855466
total_envstep_count: 13029882
total_train_sample_count: 9803767
total_episode_count: 30844
total_duration: 2688.317760732028
[2023-06-29 12:23:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 290.6
avg_sample_per_episode: 290.6
avg_envstep_per_sec: 2471.932983584516
avg_train_sample_per_sec: 2471.932983584516
avg_episode_per_sec: 8.506307582878582
collect_time: 0.5877991068726405
reward_mean: 2366.9065411528086
reward_std: 901.7972330247621
reward_max: 3300.2879213436327
reward_min: 912.6016856766274
total_envstep_count: 13034498
total_train_sample_count: 9807220
total_episode_count: 30849
total_duration: 2688.905559838901
[2023-06-29 12:23:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2045
train_sample_count: 2045
avg_envstep_per_episode: 255.625
avg_sample_per_episode: 255.625
avg_envstep_per_sec: 2648.148475784138
avg_train_sample_per_sec: 2648.148475784138
avg_episode_per_sec: 10.359505039742348
collect_time: 0.7722376666944474
reward_mean: 2690.265038088064
reward_std: 854.5250782048979
reward_max: 3553.123449123779
reward_min: 1387.960377403545
total_envstep_count: 13039530
total_train_sample_count: 9810465
total_episode_count: 30857
total_duration: 2689.677797505595
[2023-06-29 12:23:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1737
train_sample_count: 1737
avg_envstep_per_episode: 347.4
avg_sample_per_episode: 347.4
avg_envstep_per_sec: 2496.818752221474
avg_train_sample_per_sec: 2496.818752221474
avg_episode_per_sec: 7.187158181408963
collect_time: 0.6956852588737382
reward_mean: 3057.1476324664764
reward_std: 778.3814711128026
reward_max: 3557.008723511895
reward_min: 1537.027059004405
total_envstep_count: 13043538
total_train_sample_count: 9813802
total_episode_count: 30862
total_duration: 2690.373482764469
[2023-06-29 12:23:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1838
train_sample_count: 1838
avg_envstep_per_episode: 306.3333333333333
avg_sample_per_episode: 306.3333333333333
avg_envstep_per_sec: 2745.64227399278
avg_train_sample_per_sec: 2745.64227399278
avg_episode_per_sec: 8.96292363653791
collect_time: 0.6694244248094038
reward_mean: 2835.265908651348
reward_std: 924.7138890054986
reward_max: 3632.3656237660675
reward_min: 1039.9630229225393
total_envstep_count: 13048250
total_train_sample_count: 9817240
total_episode_count: 30868
total_duration: 2691.042907189278
[2023-06-29 12:23:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1515
train_sample_count: 1515
avg_envstep_per_episode: 303.0
avg_sample_per_episode: 303.0
avg_envstep_per_sec: 2820.980038219931
avg_train_sample_per_sec: 2820.980038219931
avg_episode_per_sec: 9.310165142640036
collect_time: 0.5370474017802627
reward_mean: 2984.1312208145673
reward_std: 467.64005152908913
reward_max: 3554.8133308492997
reward_min: 2350.2947641987444
total_envstep_count: 13052674
total_train_sample_count: 9820755
total_episode_count: 30873
total_duration: 2691.5799545910586
[2023-06-29 12:23:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 265.75
avg_sample_per_episode: 265.75
avg_envstep_per_sec: 2327.013054386109
avg_train_sample_per_sec: 2327.013054386109
avg_episode_per_sec: 8.756399075770872
collect_time: 0.4568087823987007
reward_mean: 3140.8054899801587
reward_std: 578.6134054798655
reward_max: 3573.4936805402135
reward_min: 2154.9401734662274
total_envstep_count: 13057274
total_train_sample_count: 9824218
total_episode_count: 30877
total_duration: 2692.0367633734572
[2023-06-29 12:23:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 957
train_sample_count: 957
avg_envstep_per_episode: 159.5
avg_sample_per_episode: 159.5
avg_envstep_per_sec: 2248.8689753344947
avg_train_sample_per_sec: 2248.8689753344947
avg_episode_per_sec: 14.099492008366736
collect_time: 0.42554724641423664
reward_mean: 2832.7053871462354
reward_std: 564.9173264985799
reward_max: 3517.0282813644794
reward_min: 2036.532574042026
total_envstep_count: 13061826
total_train_sample_count: 9827575
total_episode_count: 30883
total_duration: 2692.4623106198715
[2023-06-29 12:23:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2464
train_sample_count: 2464
avg_envstep_per_episode: 352.0
avg_sample_per_episode: 352.0
avg_envstep_per_sec: 2521.5153788779844
avg_train_sample_per_sec: 2521.5153788779844
avg_episode_per_sec: 7.163395962721546
collect_time: 0.9771901534451171
reward_mean: 3021.093168948607
reward_std: 762.4961950091619
reward_max: 3583.567511817155
reward_min: 1312.4513909186282
total_envstep_count: 13065770
total_train_sample_count: 9830839
total_episode_count: 30890
total_duration: 2693.4395007733165
[2023-06-29 12:23:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 323.6666666666667
avg_sample_per_episode: 323.6666666666667
avg_envstep_per_sec: 2323.2296304318756
avg_train_sample_per_sec: 2323.2296304318756
avg_episode_per_sec: 7.177846437997556
collect_time: 0.41795265835151063
reward_mean: 3221.082945510398
reward_std: 427.98064237127795
reward_max: 3554.608657990413
reward_min: 2616.916848881363
total_envstep_count: 13070426
total_train_sample_count: 9834210
total_episode_count: 30893
total_duration: 2693.857453431668
[2023-06-29 12:23:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1778
train_sample_count: 1778
avg_envstep_per_episode: 296.3333333333333
avg_sample_per_episode: 296.3333333333333
avg_envstep_per_sec: 2751.24420261011
avg_train_sample_per_sec: 2751.24420261011
avg_episode_per_sec: 9.284288647728154
collect_time: 0.6462530655451117
reward_mean: 3353.6559228927144
reward_std: 293.1352043731696
reward_max: 3575.5071540380595
reward_min: 2834.9219884648487
total_envstep_count: 13075450
total_train_sample_count: 9837588
total_episode_count: 30899
total_duration: 2694.503706497213
[2023-06-29 12:23:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1762
train_sample_count: 1762
avg_envstep_per_episode: 251.71428571428572
avg_sample_per_episode: 251.71428571428572
avg_envstep_per_sec: 2590.546301059471
avg_train_sample_per_sec: 2590.546301059471
avg_episode_per_sec: 10.29161413587758
collect_time: 0.6801654150243849
reward_mean: 2547.6890548690544
reward_std: 800.3101223326007
reward_max: 3533.445692428718
reward_min: 1229.106602411588
total_envstep_count: 13079818
total_train_sample_count: 9840950
total_episode_count: 30906
total_duration: 2695.1838719122375
[2023-06-29 12:23:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 305.0
avg_sample_per_episode: 305.0
avg_envstep_per_sec: 2503.0972984793198
avg_train_sample_per_sec: 2503.0972984793198
avg_episode_per_sec: 8.206876388456786
collect_time: 0.8529432720402256
reward_mean: 2518.9508461701553
reward_std: 776.3941939204843
reward_max: 3562.908572298593
reward_min: 1592.8469455714903
total_envstep_count: 13084058
total_train_sample_count: 9844285
total_episode_count: 30913
total_duration: 2696.0368151842777
[2023-06-29 12:23:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 791
train_sample_count: 791
avg_envstep_per_episode: 263.6666666666667
avg_sample_per_episode: 263.6666666666667
avg_envstep_per_sec: 2633.6184629353584
avg_train_sample_per_sec: 2633.6184629353584
avg_episode_per_sec: 9.988439176745986
collect_time: 0.3003472261196002
reward_mean: 2643.122451838582
reward_std: 618.7971729049372
reward_max: 3477.3784261584474
reward_min: 1997.1328497747454
total_envstep_count: 13088346
total_train_sample_count: 9847876
total_episode_count: 30916
total_duration: 2696.3371624103975
[2023-06-29 12:23:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2147
train_sample_count: 2147
avg_envstep_per_episode: 357.8333333333333
avg_sample_per_episode: 357.8333333333333
avg_envstep_per_sec: 2770.1167266803095
avg_train_sample_per_sec: 2770.1167266803095
avg_episode_per_sec: 7.741360204975249
collect_time: 0.7750575920939444
reward_mean: 3494.5024879907564
reward_std: 75.48038465468812
reward_max: 3588.79547876331
reward_min: 3382.5515014043226
total_envstep_count: 13093010
total_train_sample_count: 9851223
total_episode_count: 30922
total_duration: 2697.1122200024915
[2023-06-29 12:23:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1676
train_sample_count: 1676
avg_envstep_per_episode: 279.3333333333333
avg_sample_per_episode: 279.3333333333333
avg_envstep_per_sec: 2617.9897249698793
avg_train_sample_per_sec: 2617.9897249698793
avg_episode_per_sec: 9.372278251682145
collect_time: 0.6401858586436137
reward_mean: 2389.414667403988
reward_std: 960.3627218871909
reward_max: 3593.969479519405
reward_min: 834.893865963513
total_envstep_count: 13096634
total_train_sample_count: 9854499
total_episode_count: 30928
total_duration: 2697.7524058611352
[2023-06-29 12:23:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1930
train_sample_count: 1930
avg_envstep_per_episode: 321.6666666666667
avg_sample_per_episode: 321.6666666666667
avg_envstep_per_sec: 2717.5451933042805
avg_train_sample_per_sec: 2717.5451933042805
avg_episode_per_sec: 8.448327025816416
collect_time: 0.7101997805796564
reward_mean: 2699.410948753473
reward_std: 856.4425087238069
reward_max: 3616.893874015976
reward_min: 1371.5162011570321
total_envstep_count: 13101434
total_train_sample_count: 9858029
total_episode_count: 30934
total_duration: 2698.462605641715
[2023-06-29 12:24:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1282
train_sample_count: 1282
avg_envstep_per_episode: 213.66666666666666
avg_sample_per_episode: 213.66666666666666
avg_envstep_per_sec: 2778.0351958684037
avg_train_sample_per_sec: 2778.0351958684037
avg_episode_per_sec: 13.001724785655556
collect_time: 0.46147723466809837
reward_mean: 2309.599510164548
reward_std: 699.7677530407741
reward_max: 3689.208183062038
reward_min: 1614.278368520506
total_envstep_count: 13105562
total_train_sample_count: 9861311
total_episode_count: 30940
total_duration: 2698.924082876383
[2023-06-29 12:24:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1703
train_sample_count: 1703
avg_envstep_per_episode: 212.875
avg_sample_per_episode: 212.875
avg_envstep_per_sec: 2747.5735019799563
avg_train_sample_per_sec: 2747.5735019799563
avg_episode_per_sec: 12.906980631732033
collect_time: 0.6198196331318467
reward_mean: 2163.5948587188095
reward_std: 654.0503911319207
reward_max: 3253.3745722053654
reward_min: 1024.623156732014
total_envstep_count: 13110490
total_train_sample_count: 9864614
total_episode_count: 30948
total_duration: 2699.543902509515
[2023-06-29 12:24:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1885
train_sample_count: 1885
avg_envstep_per_episode: 314.1666666666667
avg_sample_per_episode: 314.1666666666667
avg_envstep_per_sec: 2802.679074821802
avg_train_sample_per_sec: 2802.679074821802
avg_episode_per_sec: 8.920994402615815
collect_time: 0.6725707616452129
reward_mean: 2937.9936007053852
reward_std: 618.8383803657339
reward_max: 3581.6025215275063
reward_min: 2254.593513818708
total_envstep_count: 13115626
total_train_sample_count: 9868099
total_episode_count: 30954
total_duration: 2700.2164732711603
[2023-06-29 12:24:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1658
train_sample_count: 1658
avg_envstep_per_episode: 236.85714285714286
avg_sample_per_episode: 236.85714285714286
avg_envstep_per_sec: 2732.2230316281966
avg_train_sample_per_sec: 2732.2230316281966
avg_episode_per_sec: 11.535320398912772
collect_time: 0.6068318657763303
reward_mean: 2690.5343057940086
reward_std: 827.4696620096039
reward_max: 3604.277623073605
reward_min: 1642.7012992049235
total_envstep_count: 13119986
total_train_sample_count: 9871357
total_episode_count: 30961
total_duration: 2700.8233051369366
[2023-06-29 12:24:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 179.16666666666666
avg_sample_per_episode: 179.16666666666666
avg_envstep_per_sec: 2335.3146960380195
avg_train_sample_per_sec: 2335.3146960380195
avg_episode_per_sec: 13.034314582537782
collect_time: 0.46032339959312224
reward_mean: 2183.4235256966294
reward_std: 684.2254516551125
reward_max: 3587.9413365928785
reward_min: 1580.5867629169632
total_envstep_count: 13124762
total_train_sample_count: 9874832
total_episode_count: 30967
total_duration: 2701.2836285365297
[2023-06-29 12:24:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3331
train_sample_count: 3331
avg_envstep_per_episode: 333.1
avg_sample_per_episode: 333.1
avg_envstep_per_sec: 2716.9029256762115
avg_train_sample_per_sec: 2716.9029256762115
avg_episode_per_sec: 8.156418269817507
collect_time: 1.2260283459229393
reward_mean: 2746.2704080823814
reward_std: 632.2329963603612
reward_max: 3620.8813395492075
reward_min: 1752.0475484809422
total_envstep_count: 13129346
total_train_sample_count: 9878163
total_episode_count: 30977
total_duration: 2702.5096568824524
[2023-06-29 12:24:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2088
train_sample_count: 2088
avg_envstep_per_episode: 348.0
avg_sample_per_episode: 348.0
avg_envstep_per_sec: 2741.847626413796
avg_train_sample_per_sec: 2741.847626413796
avg_episode_per_sec: 7.8788724896948175
collect_time: 0.7615302834063769
reward_mean: 1792.2634143643306
reward_std: 386.4191604729323
reward_max: 2268.159946521147
reward_min: 1031.2520585590282
total_envstep_count: 13133634
total_train_sample_count: 9881451
total_episode_count: 30983
total_duration: 2703.271187165859
[2023-06-29 12:24:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1100
train_sample_count: 1100
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 2276.6269217172135
avg_train_sample_per_sec: 2276.6269217172135
avg_episode_per_sec: 10.348304189623697
collect_time: 0.483170953267254
reward_mean: 2377.782724039042
reward_std: 1091.96826518265
reward_max: 3604.552560388655
reward_min: 720.2432182200814
total_envstep_count: 13137578
total_train_sample_count: 9884951
total_episode_count: 30988
total_duration: 2703.754358119126
[2023-06-29 12:24:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2011
train_sample_count: 2011
avg_envstep_per_episode: 335.1666666666667
avg_sample_per_episode: 335.1666666666667
avg_envstep_per_sec: 2761.7419644307256
avg_train_sample_per_sec: 2761.7419644307256
avg_episode_per_sec: 8.239906408047913
collect_time: 0.7281636104676872
reward_mean: 2678.118656298467
reward_std: 777.7156006179349
reward_max: 3565.343208556356
reward_min: 1621.100456823675
total_envstep_count: 13141418
total_train_sample_count: 9888162
total_episode_count: 30994
total_duration: 2704.482521729594
[2023-06-29 12:24:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2616
train_sample_count: 2616
avg_envstep_per_episode: 327.0
avg_sample_per_episode: 327.0
avg_envstep_per_sec: 2736.814734942747
avg_train_sample_per_sec: 2736.814734942747
avg_episode_per_sec: 8.369464021231641
collect_time: 0.955855713066645
reward_mean: 2474.4336533296528
reward_std: 807.5053326286474
reward_max: 3613.372133359356
reward_min: 1333.1307472639262
total_envstep_count: 13146482
total_train_sample_count: 9891578
total_episode_count: 31002
total_duration: 2705.4383774426606
[2023-06-29 12:24:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 244.0909090909091
avg_sample_per_episode: 244.0909090909091
avg_envstep_per_sec: 2523.9413046683794
avg_train_sample_per_sec: 2523.9413046683794
avg_episode_per_sec: 10.340169218380696
collect_time: 1.0638123775040729
reward_mean: 1747.0408606282456
reward_std: 305.1411436040827
reward_max: 2297.7687503135226
reward_min: 1239.3838221700967
total_envstep_count: 13150938
total_train_sample_count: 9895063
total_episode_count: 31013
total_duration: 2706.502189820165
[2023-06-29 12:24:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 250.375
avg_sample_per_episode: 250.375
avg_envstep_per_sec: 2442.058483996615
avg_train_sample_per_sec: 2442.058483996615
avg_episode_per_sec: 9.753603530690423
collect_time: 0.8202096768468615
reward_mean: 1544.280349841016
reward_std: 212.66032805385785
reward_max: 1845.3130392874893
reward_min: 1170.7775365618993
total_envstep_count: 13154634
total_train_sample_count: 9898266
total_episode_count: 31021
total_duration: 2707.3223994970117
[2023-06-29 12:24:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2158
train_sample_count: 2158
avg_envstep_per_episode: 269.75
avg_sample_per_episode: 269.75
avg_envstep_per_sec: 2814.7692294276035
avg_train_sample_per_sec: 2814.7692294276035
avg_episode_per_sec: 10.43473300992624
collect_time: 0.7666703108157963
reward_mean: 1774.9165633978541
reward_std: 878.9621578594433
reward_max: 3624.2243483673005
reward_min: 918.5925234898953
total_envstep_count: 13159010
total_train_sample_count: 9901624
total_episode_count: 31029
total_duration: 2708.0890698078274
[2023-06-29 12:24:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 275.8888888888889
avg_sample_per_episode: 275.8888888888889
avg_envstep_per_sec: 2791.5757700518816
avg_train_sample_per_sec: 2791.5757700518816
avg_episode_per_sec: 10.118478425480037
collect_time: 0.8894617966804653
reward_mean: 2129.5759856382156
reward_std: 723.2677812589062
reward_max: 3582.1688664853164
reward_min: 1369.7234462079998
total_envstep_count: 13163186
total_train_sample_count: 9904907
total_episode_count: 31038
total_duration: 2708.9785316045077
[2023-06-29 12:24:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3085
train_sample_count: 3085
avg_envstep_per_episode: 308.5
avg_sample_per_episode: 308.5
avg_envstep_per_sec: 2764.489453304678
avg_train_sample_per_sec: 2764.489453304678
avg_episode_per_sec: 8.961067919950334
collect_time: 1.1159384226668627
reward_mean: 1790.0732380921286
reward_std: 439.6134464812235
reward_max: 2650.031228140144
reward_min: 1021.5299652815048
total_envstep_count: 13167730
total_train_sample_count: 9908392
total_episode_count: 31048
total_duration: 2710.0944700271743
[2023-06-29 12:24:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1997
train_sample_count: 1997
avg_envstep_per_episode: 249.625
avg_sample_per_episode: 249.625
avg_envstep_per_sec: 2557.90232732179
avg_train_sample_per_sec: 2557.90232732179
avg_episode_per_sec: 10.246979778955593
collect_time: 0.7807178478511048
reward_mean: 1488.9799871784776
reward_std: 560.7913156580479
reward_max: 2830.657334922165
reward_min: 982.4050961738842
total_envstep_count: 13172858
total_train_sample_count: 9911989
total_episode_count: 31056
total_duration: 2710.8751878750254
[2023-06-29 12:24:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2466
train_sample_count: 2466
avg_envstep_per_episode: 308.25
avg_sample_per_episode: 308.25
avg_envstep_per_sec: 2542.619617237984
avg_train_sample_per_sec: 2542.619617237984
avg_episode_per_sec: 8.248563235159722
collect_time: 0.9698658750532196
reward_mean: 2590.8128736215804
reward_std: 823.9816436193115
reward_max: 3660.396541049318
reward_min: 1418.952666947603
total_envstep_count: 13177658
total_train_sample_count: 9915255
total_episode_count: 31064
total_duration: 2711.8450537500785
[2023-06-29 12:24:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 286.57142857142856
avg_sample_per_episode: 286.57142857142856
avg_envstep_per_sec: 2559.2876503076754
avg_train_sample_per_sec: 2559.2876503076754
avg_episode_per_sec: 8.930714632180322
collect_time: 0.7838118547396735
reward_mean: 2216.0218194892373
reward_std: 1098.8899272495144
reward_max: 3559.9353580359525
reward_min: 157.3242417470711
total_envstep_count: 13182178
total_train_sample_count: 9918461
total_episode_count: 31071
total_duration: 2712.628865604818
[2023-06-29 12:24:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2347
train_sample_count: 2347
avg_envstep_per_episode: 195.58333333333334
avg_sample_per_episode: 195.58333333333334
avg_envstep_per_sec: 2680.5445905743472
avg_train_sample_per_sec: 2680.5445905743472
avg_episode_per_sec: 13.705383505280004
collect_time: 0.8755683484068137
reward_mean: 1460.9820164915818
reward_std: 1248.04423357725
reward_max: 3612.8492458320266
reward_min: 72.64550484436165
total_envstep_count: 13186866
total_train_sample_count: 9922008
total_episode_count: 31083
total_duration: 2713.504433953225
[2023-06-29 12:25:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2969
train_sample_count: 2969
avg_envstep_per_episode: 247.41666666666666
avg_sample_per_episode: 247.41666666666666
avg_envstep_per_sec: 2773.8857749942667
avg_train_sample_per_sec: 2773.8857749942667
avg_episode_per_sec: 11.211394173099091
collect_time: 1.0703396753985432
reward_mean: 1733.0507131286022
reward_std: 1034.733996521159
reward_max: 3626.116515813366
reward_min: 85.80355056314497
total_envstep_count: 13191242
total_train_sample_count: 9925377
total_episode_count: 31095
total_duration: 2714.5747736286235
[2023-06-29 12:25:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 293.45454545454544
avg_sample_per_episode: 293.45454545454544
avg_envstep_per_sec: 2604.0451590329812
avg_train_sample_per_sec: 2604.0451590329812
avg_episode_per_sec: 8.87375983561425
collect_time: 1.2396098388703543
reward_mean: 1546.158106918048
reward_std: 475.1510148196586
reward_max: 2779.8202313872043
reward_min: 993.4492854149178
total_envstep_count: 13195674
total_train_sample_count: 9928605
total_episode_count: 31106
total_duration: 2715.814383467494
[2023-06-29 12:25:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1131
train_sample_count: 1131
avg_envstep_per_episode: 188.5
avg_sample_per_episode: 188.5
avg_envstep_per_sec: 2660.10124062938
avg_train_sample_per_sec: 2660.10124062938
avg_episode_per_sec: 14.111942921110769
collect_time: 0.42517178772203623
reward_mean: 1231.6085371589015
reward_std: 212.17177104684208
reward_max: 1457.5445416899372
reward_min: 835.6972690426156
total_envstep_count: 13200146
total_train_sample_count: 9932136
total_episode_count: 31112
total_duration: 2716.2395552552157
[2023-06-29 12:25:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2140
train_sample_count: 2140
avg_envstep_per_episode: 267.5
avg_sample_per_episode: 267.5
avg_envstep_per_sec: 2518.0294901016887
avg_train_sample_per_sec: 2518.0294901016887
avg_episode_per_sec: 9.413194355520332
collect_time: 0.8498709043767306
reward_mean: 2544.3243839013503
reward_std: 991.4007178730313
reward_max: 3648.1984634072264
reward_min: 1340.083082175662
total_envstep_count: 13203818
total_train_sample_count: 9935476
total_episode_count: 31120
total_duration: 2717.089426159592
[2023-06-29 12:25:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2665
train_sample_count: 2665
avg_envstep_per_episode: 242.27272727272728
avg_sample_per_episode: 242.27272727272728
avg_envstep_per_sec: 2748.5041257922207
avg_train_sample_per_sec: 2748.5041257922207
avg_episode_per_sec: 11.344669937603912
collect_time: 0.9696183371134102
reward_mean: 1480.0538125490004
reward_std: 754.2952518163198
reward_max: 3399.399808763175
reward_min: 532.3563397698789
total_envstep_count: 13208794
total_train_sample_count: 9938941
total_episode_count: 31131
total_duration: 2718.0590444967056
[2023-06-29 12:25:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2463
train_sample_count: 2463
avg_envstep_per_episode: 307.875
avg_sample_per_episode: 307.875
avg_envstep_per_sec: 2810.4244637566185
avg_train_sample_per_sec: 2810.4244637566185
avg_episode_per_sec: 9.128459484390154
collect_time: 0.8763800741713493
reward_mean: 2056.7248672529013
reward_std: 1022.4959476007388
reward_max: 3718.1142560519725
reward_min: 981.2839703389275
total_envstep_count: 13213594
total_train_sample_count: 9942204
total_episode_count: 31139
total_duration: 2718.935424570877
[2023-06-29 12:25:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2713
train_sample_count: 2713
avg_envstep_per_episode: 226.08333333333334
avg_sample_per_episode: 226.08333333333334
avg_envstep_per_sec: 2650.965400671246
avg_train_sample_per_sec: 2650.965400671246
avg_episode_per_sec: 11.725611798029838
collect_time: 1.0234007578194142
reward_mean: 1659.4275695232363
reward_std: 752.2345995608053
reward_max: 3203.0421788278686
reward_min: 992.8513607397874
total_envstep_count: 13218522
total_train_sample_count: 9945717
total_episode_count: 31151
total_duration: 2719.958825328696
[2023-06-29 12:25:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 400
train_sample_count: 400
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 2743.5295899843627
avg_train_sample_per_sec: 2743.5295899843627
avg_episode_per_sec: 13.717647949921814
collect_time: 0.14579758915677665
reward_mean: 1895.525142240115
reward_std: 488.7865851400154
reward_max: 2384.3117273801304
reward_min: 1406.7385571000996
total_envstep_count: 13221722
total_train_sample_count: 9948917
total_episode_count: 31153
total_duration: 2720.104622917853
[2023-06-29 12:25:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2638
train_sample_count: 2638
avg_envstep_per_episode: 263.8
avg_sample_per_episode: 263.8
avg_envstep_per_sec: 2664.1477175867763
avg_train_sample_per_sec: 2664.1477175867763
avg_episode_per_sec: 10.099119475309992
collect_time: 0.9901853349143639
reward_mean: 2550.7858702362014
reward_std: 1078.730780701386
reward_max: 3658.247128377592
reward_min: 826.6467412905363
total_envstep_count: 13226082
total_train_sample_count: 9952355
total_episode_count: 31163
total_duration: 2721.094808252767
[2023-06-29 12:25:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1254
train_sample_count: 1254
avg_envstep_per_episode: 418.0
avg_sample_per_episode: 418.0
avg_envstep_per_sec: 2859.1302303447833
avg_train_sample_per_sec: 2859.1302303447833
avg_episode_per_sec: 6.84002447450905
collect_time: 0.43859492187201976
reward_mean: 2994.6110613589285
reward_std: 871.3059706595799
reward_max: 3614.33744754991
reward_min: 1762.405444618863
total_envstep_count: 13230522
total_train_sample_count: 9955609
total_episode_count: 31166
total_duration: 2721.5334031746393
[2023-06-29 12:25:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2094
train_sample_count: 2094
avg_envstep_per_episode: 261.75
avg_sample_per_episode: 261.75
avg_envstep_per_sec: 2541.296829289972
avg_train_sample_per_sec: 2541.296829289972
avg_episode_per_sec: 9.70887040798461
collect_time: 0.8239887508871032
reward_mean: 2541.607434657999
reward_std: 1155.1663149446356
reward_max: 3547.41010875367
reward_min: 237.43483510433992
total_envstep_count: 13234882
total_train_sample_count: 9958903
total_episode_count: 31174
total_duration: 2722.3573919255264
[2023-06-29 12:25:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2860
train_sample_count: 2860
avg_envstep_per_episode: 317.77777777777777
avg_sample_per_episode: 317.77777777777777
avg_envstep_per_sec: 2642.816633718705
avg_train_sample_per_sec: 2642.816633718705
avg_episode_per_sec: 8.316555840373548
collect_time: 1.0821787495622412
reward_mean: 1991.5629009569561
reward_std: 1222.9740210015855
reward_max: 3594.314329182075
reward_min: 112.07631281059687
total_envstep_count: 13239274
total_train_sample_count: 9962163
total_episode_count: 31183
total_duration: 2723.439570675089
[2023-06-29 12:25:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1993
train_sample_count: 1993
avg_envstep_per_episode: 398.6
avg_sample_per_episode: 398.6
avg_envstep_per_sec: 2671.515843160946
avg_train_sample_per_sec: 2671.515843160946
avg_episode_per_sec: 6.702247474061581
collect_time: 0.7460184093993154
reward_mean: 2632.5606416544806
reward_std: 925.2890772815537
reward_max: 3564.42610401673
reward_min: 1340.7602488731447
total_envstep_count: 13244546
total_train_sample_count: 9965756
total_episode_count: 31188
total_duration: 2724.185589084488
[2023-06-29 12:25:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 261.3333333333333
avg_sample_per_episode: 261.3333333333333
avg_envstep_per_sec: 2733.093744265409
avg_train_sample_per_sec: 2733.093744265409
avg_episode_per_sec: 10.458266878566615
collect_time: 0.5737088247667997
reward_mean: 2782.652569470532
reward_std: 660.3437208593203
reward_max: 3571.498911289831
reward_min: 1512.9848194352792
total_envstep_count: 13249090
total_train_sample_count: 9969324
total_episode_count: 31194
total_duration: 2724.759297909255
[2023-06-29 12:25:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1544
train_sample_count: 1544
avg_envstep_per_episode: 193.0
avg_sample_per_episode: 193.0
avg_envstep_per_sec: 2428.9740048602334
avg_train_sample_per_sec: 2428.9740048602334
avg_episode_per_sec: 12.585357538135924
collect_time: 0.6356593347275629
reward_mean: 2171.8625316498546
reward_std: 1128.0074467055567
reward_max: 3578.4268334667895
reward_min: 497.14484901106783
total_envstep_count: 13253954
total_train_sample_count: 9972868
total_episode_count: 31202
total_duration: 2725.394957243983
[2023-06-29 12:25:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2564
train_sample_count: 2564
avg_envstep_per_episode: 284.8888888888889
avg_sample_per_episode: 284.8888888888889
avg_envstep_per_sec: 2552.7734098117053
avg_train_sample_per_sec: 2552.7734098117053
avg_episode_per_sec: 8.960593092162773
collect_time: 1.0043978012874721
reward_mean: 2273.4631530964793
reward_std: 1062.6332822465488
reward_max: 3533.5307583447484
reward_min: 234.51121584415623
total_envstep_count: 13258882
total_train_sample_count: 9976232
total_episode_count: 31211
total_duration: 2726.39935504527
[2023-06-29 12:25:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2475
train_sample_count: 2475
avg_envstep_per_episode: 247.5
avg_sample_per_episode: 247.5
avg_envstep_per_sec: 2622.3611566632985
avg_train_sample_per_sec: 2622.3611566632985
avg_episode_per_sec: 10.595398612781004
collect_time: 0.9438059260873124
reward_mean: 1662.9322934421198
reward_std: 918.8672968222771
reward_max: 3555.370520394376
reward_min: 237.07070231611957
total_envstep_count: 13263602
total_train_sample_count: 9979507
total_episode_count: 31221
total_duration: 2727.3431609713575
[2023-06-29 12:25:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1977
train_sample_count: 1977
avg_envstep_per_episode: 219.66666666666666
avg_sample_per_episode: 219.66666666666666
avg_envstep_per_sec: 2662.7830779226715
avg_train_sample_per_sec: 2662.7830779226715
avg_episode_per_sec: 12.121925999647974
collect_time: 0.7424562730593607
reward_mean: 1919.8645185378857
reward_std: 941.0182340404036
reward_max: 3591.070394001991
reward_min: 1063.643057751926
total_envstep_count: 13268962
total_train_sample_count: 9983084
total_episode_count: 31230
total_duration: 2728.085617244417
[2023-06-29 12:25:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1713
train_sample_count: 1713
avg_envstep_per_episode: 285.5
avg_sample_per_episode: 285.5
avg_envstep_per_sec: 2746.280413037702
avg_train_sample_per_sec: 2746.280413037702
avg_episode_per_sec: 9.619195842513843
collect_time: 0.6237527646003289
reward_mean: 2458.414161515776
reward_std: 860.3648030668165
reward_max: 3590.7618105089296
reward_min: 1305.39060046484
total_envstep_count: 13273514
total_train_sample_count: 9986397
total_episode_count: 31236
total_duration: 2728.709370009017
[2023-06-29 12:25:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 275.8888888888889
avg_sample_per_episode: 275.8888888888889
avg_envstep_per_sec: 2741.5483852978714
avg_train_sample_per_sec: 2741.5483852978714
avg_episode_per_sec: 9.937146785211777
collect_time: 0.9056925689568744
reward_mean: 2462.0185519977745
reward_std: 1024.6479000196698
reward_max: 3603.6821070105375
reward_min: 1045.3103571516403
total_envstep_count: 13277634
total_train_sample_count: 9989680
total_episode_count: 31245
total_duration: 2729.615062577974
[2023-06-29 12:26:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 434.3333333333333
avg_sample_per_episode: 434.3333333333333
avg_envstep_per_sec: 2690.602022187242
avg_train_sample_per_sec: 2690.602022187242
avg_episode_per_sec: 6.194785929824809
collect_time: 0.484278235597536
reward_mean: 3427.647042939787
reward_std: 202.59640313897356
reward_max: 3611.701798835498
reward_min: 3145.459629833642
total_envstep_count: 13281778
total_train_sample_count: 9992983
total_episode_count: 31248
total_duration: 2730.099340813572
[2023-06-29 12:26:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2385
train_sample_count: 2385
avg_envstep_per_episode: 340.7142857142857
avg_sample_per_episode: 340.7142857142857
avg_envstep_per_sec: 2574.1266864930735
avg_train_sample_per_sec: 2574.1266864930735
avg_episode_per_sec: 7.555088807317197
collect_time: 0.9265278249569235
reward_mean: 2668.8336134435035
reward_std: 1246.038664445664
reward_max: 3616.3703462821973
reward_min: 239.927170561347
total_envstep_count: 13287770
total_train_sample_count: 9996568
total_episode_count: 31255
total_duration: 2731.0258686385287
[2023-06-29 12:26:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 223.77777777777777
avg_sample_per_episode: 223.77777777777777
avg_envstep_per_sec: 2539.9664525826115
avg_train_sample_per_sec: 2539.9664525826115
avg_episode_per_sec: 11.350396262782276
collect_time: 0.792923858483322
reward_mean: 2220.826727489063
reward_std: 1022.5891623548249
reward_max: 3565.36986365597
reward_min: 690.4422845841046
total_envstep_count: 13292762
total_train_sample_count: 9999782
total_episode_count: 31264
total_duration: 2731.818792497012
[2023-06-29 12:26:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 713
train_sample_count: 713
avg_envstep_per_episode: 142.6
avg_sample_per_episode: 142.6
avg_envstep_per_sec: 2795.717905017313
avg_train_sample_per_sec: 2795.717905017313
avg_episode_per_sec: 19.60531490194469
collect_time: 0.2550328839402646
reward_mean: 1868.7329357283804
reward_std: 1079.1820134964596
reward_max: 3566.6361041429273
reward_min: 248.8282176955104
total_envstep_count: 13297506
total_train_sample_count: 10003295
total_episode_count: 31269
total_duration: 2732.0738253809523
[2023-06-29 12:26:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 941
train_sample_count: 941
avg_envstep_per_episode: 134.42857142857142
avg_sample_per_episode: 134.42857142857142
avg_envstep_per_sec: 2809.795772744605
avg_train_sample_per_sec: 2809.795772744605
avg_episode_per_sec: 20.90177514262724
collect_time: 0.3348997849337756
reward_mean: 3265.9045247247036
reward_std: 652.4038048311315
reward_max: 3590.3824270903983
reward_min: 1688.868919242427
total_envstep_count: 13301562
total_train_sample_count: 10006636
total_episode_count: 31276
total_duration: 2732.408725165886
[2023-06-29 12:26:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 228.77777777777777
avg_sample_per_episode: 228.77777777777777
avg_envstep_per_sec: 2682.790065204229
avg_train_sample_per_sec: 2682.790065204229
avg_episode_per_sec: 11.72662000332106
collect_time: 0.7674845776064321
reward_mean: 2066.7204470532906
reward_std: 823.0002792677145
reward_max: 3581.424618046382
reward_min: 842.0713553603051
total_envstep_count: 13305738
total_train_sample_count: 10009895
total_episode_count: 31285
total_duration: 2733.1762097434926
[2023-06-29 12:26:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2060
train_sample_count: 2060
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 2619.2427908337186
avg_train_sample_per_sec: 2619.2427908337186
avg_episode_per_sec: 12.714770829289897
collect_time: 0.7864868454383686
reward_mean: 1520.286330526219
reward_std: 737.7386401017469
reward_max: 2996.8974898786437
reward_min: 424.2209481958057
total_envstep_count: 13310290
total_train_sample_count: 10013155
total_episode_count: 31295
total_duration: 2733.962696588931
[2023-06-29 12:26:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1656
train_sample_count: 1656
avg_envstep_per_episode: 276.0
avg_sample_per_episode: 276.0
avg_envstep_per_sec: 2794.135416700191
avg_train_sample_per_sec: 2794.135416700191
avg_episode_per_sec: 10.123679046015186
collect_time: 0.5926699150307101
reward_mean: 2317.484228691609
reward_std: 514.5629139691085
reward_max: 3006.5381761087547
reward_min: 1609.9883963779462
total_envstep_count: 13314298
total_train_sample_count: 10016411
total_episode_count: 31301
total_duration: 2734.555366503962
[2023-06-29 12:26:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2105
train_sample_count: 2105
avg_envstep_per_episode: 300.7142857142857
avg_sample_per_episode: 300.7142857142857
avg_envstep_per_sec: 2800.9051567792285
avg_train_sample_per_sec: 2800.9051567792285
avg_episode_per_sec: 9.31417391803069
collect_time: 0.7515427628476172
reward_mean: 2317.2120118568423
reward_std: 713.5185337314126
reward_max: 3612.36344714338
reward_min: 1621.0314910891136
total_envstep_count: 13318346
total_train_sample_count: 10019716
total_episode_count: 31308
total_duration: 2735.3069092668097
[2023-06-29 12:26:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2886
train_sample_count: 2886
avg_envstep_per_episode: 360.75
avg_sample_per_episode: 360.75
avg_envstep_per_sec: 2678.3852878614507
avg_train_sample_per_sec: 2678.3852878614507
avg_episode_per_sec: 7.424491442443384
collect_time: 1.0775148792369296
reward_mean: 2429.478358415736
reward_std: 1049.4411203486682
reward_max: 3684.0475279865664
reward_min: 1006.3854478770558
total_envstep_count: 13323090
total_train_sample_count: 10023002
total_episode_count: 31316
total_duration: 2736.3844241460465
[2023-06-29 12:26:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2346
train_sample_count: 2346
avg_envstep_per_episode: 293.25
avg_sample_per_episode: 293.25
avg_envstep_per_sec: 2520.593433056885
avg_train_sample_per_sec: 2520.593433056885
avg_episode_per_sec: 8.595374025769429
collect_time: 0.930733203234151
reward_mean: 1921.6272627638846
reward_std: 543.8672547062223
reward_max: 2986.8998204106547
reward_min: 1263.0415636562996
total_envstep_count: 13328026
total_train_sample_count: 10026548
total_episode_count: 31324
total_duration: 2737.3151573492805
[2023-06-29 12:26:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2477
train_sample_count: 2477
avg_envstep_per_episode: 275.22222222222223
avg_sample_per_episode: 275.22222222222223
avg_envstep_per_sec: 2744.6401793278173
avg_train_sample_per_sec: 2744.6401793278173
avg_episode_per_sec: 9.972451196588759
collect_time: 0.9024862416051329
reward_mean: 1982.5957752327756
reward_std: 987.5991310090443
reward_max: 3589.9116298934373
reward_min: 736.3780254824172
total_envstep_count: 13332634
total_train_sample_count: 10029825
total_episode_count: 31333
total_duration: 2738.2176435908855
[2023-06-29 12:26:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2720
train_sample_count: 2720
avg_envstep_per_episode: 247.27272727272728
avg_sample_per_episode: 247.27272727272728
avg_envstep_per_sec: 2795.3557978160584
avg_train_sample_per_sec: 2795.3557978160584
avg_episode_per_sec: 11.304747711756118
collect_time: 0.9730425021834673
reward_mean: 1641.7201748683174
reward_std: 775.0333741835191
reward_max: 3162.3599421855097
reward_min: 233.51961455086675
total_envstep_count: 13337322
total_train_sample_count: 10033345
total_episode_count: 31344
total_duration: 2739.190686093069
[2023-06-29 12:26:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2130
train_sample_count: 2130
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2538.6182045122855
avg_train_sample_per_sec: 2538.6182045122855
avg_episode_per_sec: 11.918395326348758
collect_time: 0.839039126172662
reward_mean: 1510.336196125028
reward_std: 681.5495455104376
reward_max: 2930.1869226553395
reward_min: 168.74004817382158
total_envstep_count: 13341682
total_train_sample_count: 10036675
total_episode_count: 31354
total_duration: 2740.0297252192418
[2023-06-29 12:26:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 200.9
avg_sample_per_episode: 200.9
avg_envstep_per_sec: 2807.7108096643897
avg_train_sample_per_sec: 2807.7108096643897
avg_episode_per_sec: 13.975663562291636
collect_time: 0.7155295314192771
reward_mean: 1622.3584152382027
reward_std: 633.5515637296685
reward_max: 2761.128932306274
reward_min: 859.6448498683911
total_envstep_count: 13345754
total_train_sample_count: 10039884
total_episode_count: 31364
total_duration: 2740.745254750661
[2023-06-29 12:26:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3439
train_sample_count: 3439
avg_envstep_per_episode: 229.26666666666668
avg_sample_per_episode: 229.26666666666668
avg_envstep_per_sec: 2542.164126704656
avg_train_sample_per_sec: 2542.164126704656
avg_episode_per_sec: 11.088241320316907
collect_time: 1.3527844106815754
reward_mean: 1353.0175017167207
reward_std: 443.4915563612851
reward_max: 2768.0758777304527
reward_min: 991.4779522182992
total_envstep_count: 13350658
total_train_sample_count: 10043323
total_episode_count: 31379
total_duration: 2742.0980391613425
[2023-06-29 12:26:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1789
train_sample_count: 1789
avg_envstep_per_episode: 198.77777777777777
avg_sample_per_episode: 198.77777777777777
avg_envstep_per_sec: 2698.2621763300344
avg_train_sample_per_sec: 2698.2621763300344
avg_episode_per_sec: 13.5742647216156
collect_time: 0.6630193372955545
reward_mean: 1267.3057801456498
reward_std: 281.39945201351077
reward_max: 1833.6575014656614
reward_min: 998.1927654174972
total_envstep_count: 13355330
total_train_sample_count: 10046712
total_episode_count: 31388
total_duration: 2742.7610584986382
[2023-06-29 12:26:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 223.22222222222223
avg_sample_per_episode: 223.22222222222223
avg_envstep_per_sec: 2475.364222424295
avg_train_sample_per_sec: 2475.364222424295
avg_episode_per_sec: 11.089237432463243
collect_time: 0.811597736527212
reward_mean: 2082.589762117556
reward_std: 663.4779667907383
reward_max: 3567.6160047563408
reward_min: 1072.465147441559
total_envstep_count: 13359242
total_train_sample_count: 10049921
total_episode_count: 31397
total_duration: 2743.5726562351656
[2023-06-29 12:26:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1667
train_sample_count: 1667
avg_envstep_per_episode: 277.8333333333333
avg_sample_per_episode: 277.8333333333333
avg_envstep_per_sec: 2725.8434305118944
avg_train_sample_per_sec: 2725.8434305118944
avg_episode_per_sec: 9.811074135015817
collect_time: 0.6115538337016477
reward_mean: 1920.4608929597089
reward_std: 504.0471930335123
reward_max: 2658.72915892903
reward_min: 1245.2782750125582
total_envstep_count: 13363610
total_train_sample_count: 10053188
total_episode_count: 31403
total_duration: 2744.1842100688673
[2023-06-29 12:27:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2692
train_sample_count: 2692
avg_envstep_per_episode: 224.33333333333334
avg_sample_per_episode: 224.33333333333334
avg_envstep_per_sec: 2693.4926725170903
avg_train_sample_per_sec: 2693.4926725170903
avg_episode_per_sec: 12.006653815083613
collect_time: 0.9994458226924763
reward_mean: 1769.244045282534
reward_std: 870.535692892545
reward_max: 3630.5122701066857
reward_min: 233.64348535672957
total_envstep_count: 13368338
total_train_sample_count: 10056680
total_episode_count: 31415
total_duration: 2745.1836558915597
[2023-06-29 12:27:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 343.0
avg_sample_per_episode: 343.0
avg_envstep_per_sec: 2729.9565546880985
avg_train_sample_per_sec: 2729.9565546880985
avg_episode_per_sec: 7.959057010752474
collect_time: 0.6282151256417856
reward_mean: 2206.385901375631
reward_std: 844.0096651219487
reward_max: 3162.558964212248
reward_min: 995.2275554708331
total_envstep_count: 13373066
total_train_sample_count: 10059995
total_episode_count: 31420
total_duration: 2745.8118710172016
[2023-06-29 12:27:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1619
train_sample_count: 1619
avg_envstep_per_episode: 269.8333333333333
avg_sample_per_episode: 269.8333333333333
avg_envstep_per_sec: 2557.417972901502
avg_train_sample_per_sec: 2557.417972901502
avg_episode_per_sec: 9.477768892778883
collect_time: 0.6330603824462742
reward_mean: 2671.5245516289892
reward_std: 1062.1087594065675
reward_max: 3627.8891159564005
reward_min: 964.1193866653391
total_envstep_count: 13377410
total_train_sample_count: 10063214
total_episode_count: 31426
total_duration: 2746.444931399648
[2023-06-29 12:27:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2507
train_sample_count: 2507
avg_envstep_per_episode: 250.7
avg_sample_per_episode: 250.7
avg_envstep_per_sec: 2533.3692533617996
avg_train_sample_per_sec: 2533.3692533617996
avg_episode_per_sec: 10.105182502440364
collect_time: 0.9895912317847834
reward_mean: 2176.733777746512
reward_std: 1188.9993923706443
reward_max: 3646.6738533624884
reward_min: 808.7879182436247
total_envstep_count: 13381930
total_train_sample_count: 10066521
total_episode_count: 31436
total_duration: 2747.4345226314326
[2023-06-29 12:27:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2550
train_sample_count: 2550
avg_envstep_per_episode: 231.8181818181818
avg_sample_per_episode: 231.8181818181818
avg_envstep_per_sec: 2667.9526086289184
avg_train_sample_per_sec: 2667.9526086289184
avg_episode_per_sec: 11.508815174477686
collect_time: 0.9557890915125606
reward_mean: 1554.8459535012223
reward_std: 931.422288747557
reward_max: 3700.2477990008933
reward_min: 513.8632836966842
total_envstep_count: 13386402
total_train_sample_count: 10069871
total_episode_count: 31447
total_duration: 2748.390311722945
[2023-06-29 12:27:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2174
train_sample_count: 2174
avg_envstep_per_episode: 217.4
avg_sample_per_episode: 217.4
avg_envstep_per_sec: 2744.4288779293233
avg_train_sample_per_sec: 2744.4288779293233
avg_episode_per_sec: 12.623867883759537
collect_time: 0.7921502420715989
reward_mean: 1519.1189319783014
reward_std: 895.9577974326635
reward_max: 3614.7171272404435
reward_min: 108.37352818962742
total_envstep_count: 13391002
total_train_sample_count: 10073245
total_episode_count: 31457
total_duration: 2749.182461965017
[2023-06-29 12:27:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2618
train_sample_count: 2618
avg_envstep_per_episode: 261.8
avg_sample_per_episode: 261.8
avg_envstep_per_sec: 2640.670457542524
avg_train_sample_per_sec: 2640.670457542524
avg_episode_per_sec: 10.08659456662538
collect_time: 0.9914148857621476
reward_mean: 1768.6279386573817
reward_std: 883.0273939108141
reward_max: 3593.1022987808615
reward_min: 662.6477176467213
total_envstep_count: 13395930
total_train_sample_count: 10076663
total_episode_count: 31467
total_duration: 2750.173876850779
[2023-06-29 12:27:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2050
train_sample_count: 2050
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2534.9370547181747
avg_train_sample_per_sec: 2534.9370547181747
avg_episode_per_sec: 12.36554660838134
collect_time: 0.8086985813649372
reward_mean: 1538.1146495982478
reward_std: 739.1220118283727
reward_max: 3650.879896714365
reward_min: 843.7829552476912
total_envstep_count: 13399970
total_train_sample_count: 10079913
total_episode_count: 31477
total_duration: 2750.9825754321437
[2023-06-29 12:27:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2266
train_sample_count: 2266
avg_envstep_per_episode: 283.25
avg_sample_per_episode: 283.25
avg_envstep_per_sec: 2584.157962102766
avg_train_sample_per_sec: 2584.157962102766
avg_episode_per_sec: 9.12324081942724
collect_time: 0.8768813800206408
reward_mean: 2146.914130010953
reward_std: 1039.3457347571086
reward_max: 3624.4136231943253
reward_min: 789.2839624250795
total_envstep_count: 13404762
total_train_sample_count: 10083379
total_episode_count: 31485
total_duration: 2751.8594568121644
[2023-06-29 12:27:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2259
train_sample_count: 2259
avg_envstep_per_episode: 225.9
avg_sample_per_episode: 225.9
avg_envstep_per_sec: 2755.3477206441808
avg_train_sample_per_sec: 2755.3477206441808
avg_episode_per_sec: 12.197201065268617
collect_time: 0.819860224201344
reward_mean: 1589.225648538166
reward_std: 1048.5381431151234
reward_max: 3613.291590307958
reward_min: 265.43069741363155
total_envstep_count: 13409130
total_train_sample_count: 10086838
total_episode_count: 31495
total_duration: 2752.679317036366
[2023-06-29 12:27:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1826
train_sample_count: 1826
avg_envstep_per_episode: 228.25
avg_sample_per_episode: 228.25
avg_envstep_per_sec: 2606.920781813248
avg_train_sample_per_sec: 2606.920781813248
avg_episode_per_sec: 11.421339679357057
collect_time: 0.7004432251024991
reward_mean: 1882.8156499514735
reward_std: 767.2099866293928
reward_max: 3320.0093693634785
reward_min: 965.5690211362588
total_envstep_count: 13413474
total_train_sample_count: 10090264
total_episode_count: 31503
total_duration: 2753.379760261468
[2023-06-29 12:27:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3041
train_sample_count: 3041
avg_envstep_per_episode: 304.1
avg_sample_per_episode: 304.1
avg_envstep_per_sec: 2588.784016605271
avg_train_sample_per_sec: 2588.784016605271
avg_episode_per_sec: 8.512936588639498
collect_time: 1.1746827778965236
reward_mean: 2139.6472503589307
reward_std: 1177.076342747774
reward_max: 3667.2595599583183
reward_min: 254.84717813134077
total_envstep_count: 13418794
total_train_sample_count: 10093705
total_episode_count: 31513
total_duration: 2754.5544430393647
[2023-06-29 12:27:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2662
train_sample_count: 2662
avg_envstep_per_episode: 295.77777777777777
avg_sample_per_episode: 295.77777777777777
avg_envstep_per_sec: 2707.4699831454855
avg_train_sample_per_sec: 2707.4699831454855
avg_episode_per_sec: 9.15373022100277
collect_time: 0.9832057295450938
reward_mean: 1883.0002198769917
reward_std: 645.9982421460485
reward_max: 3179.32354009464
reward_min: 1078.7768031038759
total_envstep_count: 13423218
total_train_sample_count: 10097167
total_episode_count: 31522
total_duration: 2755.53764876891
[2023-06-29 12:27:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2570
train_sample_count: 2570
avg_envstep_per_episode: 214.16666666666666
avg_sample_per_episode: 214.16666666666666
avg_envstep_per_sec: 2522.7167658325434
avg_train_sample_per_sec: 2522.7167658325434
avg_episode_per_sec: 11.779222252914598
collect_time: 1.0187429816965015
reward_mean: 1421.324392893427
reward_std: 789.8880204677343
reward_max: 3623.767730040444
reward_min: 252.8125916433271
total_envstep_count: 13427594
total_train_sample_count: 10100537
total_episode_count: 31534
total_duration: 2756.5563917506065
[2023-06-29 12:27:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3141
train_sample_count: 3141
avg_envstep_per_episode: 392.625
avg_sample_per_episode: 392.625
avg_envstep_per_sec: 2769.833806141435
avg_train_sample_per_sec: 2769.833806141435
avg_episode_per_sec: 7.0546547115986895
collect_time: 1.1340030557196585
reward_mean: 2261.0243621317322
reward_std: 954.8491874875042
reward_max: 3569.837961752364
reward_min: 1104.9146527356804
total_envstep_count: 13432962
total_train_sample_count: 10104078
total_episode_count: 31542
total_duration: 2757.6903948063264
[2023-06-29 12:27:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2411
train_sample_count: 2411
avg_envstep_per_episode: 267.8888888888889
avg_sample_per_episode: 267.8888888888889
avg_envstep_per_sec: 2807.7860343490174
avg_train_sample_per_sec: 2807.7860343490174
avg_episode_per_sec: 10.48115898346792
collect_time: 0.8586836641058329
reward_mean: 1833.9472486536886
reward_std: 334.80087373035303
reward_max: 2304.5712061559234
reward_min: 1372.9126967251175
total_envstep_count: 13437818
total_train_sample_count: 10107289
total_episode_count: 31551
total_duration: 2758.549078470432
[2023-06-29 12:27:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2431
train_sample_count: 2431
avg_envstep_per_episode: 270.1111111111111
avg_sample_per_episode: 270.1111111111111
avg_envstep_per_sec: 2543.121270521472
avg_train_sample_per_sec: 2543.121270521472
avg_episode_per_sec: 9.415093144670196
collect_time: 0.9559119449704885
reward_mean: 2073.4555415544396
reward_std: 921.2117671312511
reward_max: 3595.3900085053306
reward_min: 974.4019685500194
total_envstep_count: 13442850
total_train_sample_count: 10110520
total_episode_count: 31560
total_duration: 2759.5049904154025
[2023-06-29 12:27:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 2762.729831419912
avg_train_sample_per_sec: 2762.729831419912
avg_episode_per_sec: 13.81364915709956
collect_time: 0.7239216724177822
reward_mean: 1487.7706425870033
reward_std: 551.6343867259927
reward_max: 2946.0158159196444
reward_min: 878.4494280355533
total_envstep_count: 13447186
total_train_sample_count: 10113720
total_episode_count: 31570
total_duration: 2760.2289120878204
[2023-06-29 12:27:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1284
train_sample_count: 1284
avg_envstep_per_episode: 183.42857142857142
avg_sample_per_episode: 183.42857142857142
avg_envstep_per_sec: 2751.4351334092694
avg_train_sample_per_sec: 2751.4351334092694
avg_episode_per_sec: 15.000035774038073
collect_time: 0.4666655536992476
reward_mean: 2001.2074784227705
reward_std: 932.0077269843437
reward_max: 3531.313903749398
reward_min: 985.9032662311376
total_envstep_count: 13451610
total_train_sample_count: 10117004
total_episode_count: 31577
total_duration: 2760.69557764152
[2023-06-29 12:27:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2242
train_sample_count: 2242
avg_envstep_per_episode: 224.2
avg_sample_per_episode: 224.2
avg_envstep_per_sec: 2749.1970922440687
avg_train_sample_per_sec: 2749.1970922440687
avg_episode_per_sec: 12.26225286460334
collect_time: 0.815510829079896
reward_mean: 1957.4855336791413
reward_std: 981.9167431862029
reward_max: 3624.65989395265
reward_min: 880.9679400134954
total_envstep_count: 13456250
total_train_sample_count: 10120446
total_episode_count: 31587
total_duration: 2761.5110884705996
[2023-06-29 12:28:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3502
train_sample_count: 3502
avg_envstep_per_episode: 233.46666666666667
avg_sample_per_episode: 233.46666666666667
avg_envstep_per_sec: 2660.539760589645
avg_train_sample_per_sec: 2660.539760589645
avg_episode_per_sec: 11.395801373170952
collect_time: 1.3162742582820357
reward_mean: 1538.874603381936
reward_std: 715.6426425283934
reward_max: 3734.1843679025633
reward_min: 892.1912334560618
total_envstep_count: 13461002
total_train_sample_count: 10123948
total_episode_count: 31602
total_duration: 2762.827362728882
[2023-06-29 12:28:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3015
train_sample_count: 3015
avg_envstep_per_episode: 231.92307692307693
avg_sample_per_episode: 231.92307692307693
avg_envstep_per_sec: 2592.963621576832
avg_train_sample_per_sec: 2592.963621576832
avg_episode_per_sec: 11.180274321890154
collect_time: 1.1627621671631936
reward_mean: 1207.0304323164457
reward_std: 378.7649341683242
reward_max: 2364.975914701281
reward_min: 793.8017428565558
total_envstep_count: 13465978
total_train_sample_count: 10127363
total_episode_count: 31615
total_duration: 2763.990124896045
[2023-06-29 12:28:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2441
train_sample_count: 2441
avg_envstep_per_episode: 203.41666666666666
avg_sample_per_episode: 203.41666666666666
avg_envstep_per_sec: 2713.631646710491
avg_train_sample_per_sec: 2713.631646710491
avg_episode_per_sec: 13.340262089523103
collect_time: 0.89953255186975
reward_mean: 1299.2393194596416
reward_std: 524.4487620025594
reward_max: 2374.0486991856783
reward_min: 193.1460401136759
total_envstep_count: 13470122
total_train_sample_count: 10130604
total_episode_count: 31627
total_duration: 2764.889657447915
[2023-06-29 12:28:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2268
train_sample_count: 2268
avg_envstep_per_episode: 226.8
avg_sample_per_episode: 226.8
avg_envstep_per_sec: 2776.6378654973514
avg_train_sample_per_sec: 2776.6378654973514
avg_episode_per_sec: 12.24267136462677
collect_time: 0.8168151951618494
reward_mean: 1493.8939996334168
reward_std: 585.3947024676406
reward_max: 2693.9549205487965
reward_min: 531.6160785210834
total_envstep_count: 13475066
total_train_sample_count: 10134072
total_episode_count: 31637
total_duration: 2765.7064726430767
[2023-06-29 12:28:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2666
train_sample_count: 2666
avg_envstep_per_episode: 266.6
avg_sample_per_episode: 266.6
avg_envstep_per_sec: 2536.3024619613825
avg_train_sample_per_sec: 2536.3024619613825
avg_episode_per_sec: 9.51351261050781
collect_time: 1.0511364634083584
reward_mean: 1955.2013744168016
reward_std: 1003.2798915298182
reward_max: 3769.8844363230173
reward_min: 917.3340042167158
total_envstep_count: 13479418
total_train_sample_count: 10137538
total_episode_count: 31647
total_duration: 2766.7576091064852
[2023-06-29 12:28:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2150
train_sample_count: 2150
avg_envstep_per_episode: 268.75
avg_sample_per_episode: 268.75
avg_envstep_per_sec: 2521.167147054017
avg_train_sample_per_sec: 2521.167147054017
avg_episode_per_sec: 9.381087058805644
collect_time: 0.8527796352226287
reward_mean: 1608.3648508264287
reward_std: 801.5900425270958
reward_max: 3348.1250984161175
reward_min: 733.227622742582
total_envstep_count: 13483642
total_train_sample_count: 10140888
total_episode_count: 31655
total_duration: 2767.610388741708
[2023-06-29 12:28:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2057
train_sample_count: 2057
avg_envstep_per_episode: 228.55555555555554
avg_sample_per_episode: 228.55555555555554
avg_envstep_per_sec: 2451.3062148983613
avg_train_sample_per_sec: 2451.3062148983613
avg_episode_per_sec: 10.725209496395358
collect_time: 0.8391444477634507
reward_mean: 1701.82257368765
reward_std: 901.0741360598331
reward_max: 3590.8163740895607
reward_min: 966.070125806972
total_envstep_count: 13487954
total_train_sample_count: 10144145
total_episode_count: 31664
total_duration: 2768.4495331894714
[2023-06-29 12:28:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2119
train_sample_count: 2119
avg_envstep_per_episode: 264.875
avg_sample_per_episode: 264.875
avg_envstep_per_sec: 2705.86248330235
avg_train_sample_per_sec: 2705.86248330235
avg_episode_per_sec: 10.21562051270354
collect_time: 0.7831144461613149
reward_mean: 1932.8088043032253
reward_std: 832.2652734466809
reward_max: 3649.612863712254
reward_min: 1025.578904540566
total_envstep_count: 13491970
total_train_sample_count: 10147464
total_episode_count: 31672
total_duration: 2769.2326476356325
[2023-06-29 12:28:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2254
train_sample_count: 2254
avg_envstep_per_episode: 225.4
avg_sample_per_episode: 225.4
avg_envstep_per_sec: 2518.625247359025
avg_train_sample_per_sec: 2518.625247359025
avg_episode_per_sec: 11.17402505483152
collect_time: 0.8949326631119477
reward_mean: 1677.1202850585723
reward_std: 913.7305491336093
reward_max: 3706.433916954146
reward_min: 81.01051878199547
total_envstep_count: 13496570
total_train_sample_count: 10150918
total_episode_count: 31682
total_duration: 2770.1275802987443
[2023-06-29 12:28:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1671
train_sample_count: 1671
avg_envstep_per_episode: 167.1
avg_sample_per_episode: 167.1
avg_envstep_per_sec: 2799.690966615284
avg_train_sample_per_sec: 2799.690966615284
avg_episode_per_sec: 16.754583881599547
collect_time: 0.5968515882380308
reward_mean: 1390.427824691786
reward_std: 670.3683888349374
reward_max: 2427.521937424101
reward_min: 434.40250388282914
total_envstep_count: 13501002
total_train_sample_count: 10154189
total_episode_count: 31692
total_duration: 2770.7244318869825
[2023-06-29 12:28:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2558
train_sample_count: 2558
avg_envstep_per_episode: 255.8
avg_sample_per_episode: 255.8
avg_envstep_per_sec: 2799.3225449234683
avg_train_sample_per_sec: 2799.3225449234683
avg_episode_per_sec: 10.943403224876734
collect_time: 0.9137925190646203
reward_mean: 2015.7907669402146
reward_std: 883.7004489335125
reward_max: 3648.292285217338
reward_min: 1043.8378526815393
total_envstep_count: 13506450
total_train_sample_count: 10157547
total_episode_count: 31702
total_duration: 2771.6382244060474
[2023-06-29 12:28:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3037
train_sample_count: 3037
avg_envstep_per_episode: 276.09090909090907
avg_sample_per_episode: 276.09090909090907
avg_envstep_per_sec: 2717.916116130527
avg_train_sample_per_sec: 2717.916116130527
avg_episode_per_sec: 9.844279643541585
collect_time: 1.1174001956777644
reward_mean: 2018.0500431263208
reward_std: 800.9235407357519
reward_max: 3621.177235949835
reward_min: 994.1983737718538
total_envstep_count: 13511306
total_train_sample_count: 10160984
total_episode_count: 31713
total_duration: 2772.7556246017252
[2023-06-29 12:28:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3360
train_sample_count: 3360
avg_envstep_per_episode: 258.46153846153845
avg_sample_per_episode: 258.46153846153845
avg_envstep_per_sec: 2612.1896973577163
avg_train_sample_per_sec: 2612.1896973577163
avg_episode_per_sec: 10.106686329062594
collect_time: 1.286277180940844
reward_mean: 1471.5939180534297
reward_std: 435.7653837837878
reward_max: 2403.726974028794
reward_min: 968.7086758954496
total_envstep_count: 13515522
total_train_sample_count: 10164344
total_episode_count: 31726
total_duration: 2774.041901782666
[2023-06-29 12:28:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2935
train_sample_count: 2935
avg_envstep_per_episode: 244.58333333333334
avg_sample_per_episode: 244.58333333333334
avg_envstep_per_sec: 2797.2039800311163
avg_train_sample_per_sec: 2797.2039800311163
avg_episode_per_sec: 11.43660911767407
collect_time: 1.0492620563078674
reward_mean: 1147.9958295421914
reward_std: 454.83481938294943
reward_max: 2076.9763309682303
reward_min: 67.05626542876519
total_envstep_count: 13519770
total_train_sample_count: 10167679
total_episode_count: 31738
total_duration: 2775.091163838974
[2023-06-29 12:28:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1423
train_sample_count: 1423
avg_envstep_per_episode: 203.28571428571428
avg_sample_per_episode: 203.28571428571428
avg_envstep_per_sec: 2715.0015752052063
avg_train_sample_per_sec: 2715.0015752052063
avg_episode_per_sec: 13.355594537200593
collect_time: 0.5241249261125921
reward_mean: 1370.869523074402
reward_std: 541.6805531727002
reward_max: 2348.2783301042223
reward_min: 679.7465198108001
total_envstep_count: 13524330
total_train_sample_count: 10171102
total_episode_count: 31745
total_duration: 2775.6152887650865
[2023-06-29 12:28:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1207
train_sample_count: 1207
avg_envstep_per_episode: 241.4
avg_sample_per_episode: 241.4
avg_envstep_per_sec: 2699.2912151714845
avg_train_sample_per_sec: 2699.2912151714845
avg_episode_per_sec: 11.1818194497576
collect_time: 0.44715442084055385
reward_mean: 1985.1247134193704
reward_std: 994.8600543345091
reward_max: 3528.775750382648
reward_min: 980.75984038973
total_envstep_count: 13527682
total_train_sample_count: 10174309
total_episode_count: 31750
total_duration: 2776.062443185927
[2023-06-29 12:28:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2071
train_sample_count: 2071
avg_envstep_per_episode: 258.875
avg_sample_per_episode: 258.875
avg_envstep_per_sec: 2498.3224169265472
avg_train_sample_per_sec: 2498.3224169265472
avg_episode_per_sec: 9.650690166785312
collect_time: 0.8289562571942807
reward_mean: 2768.0081658638674
reward_std: 980.0662689622121
reward_max: 3777.503872245009
reward_min: 1291.4255482590047
total_envstep_count: 13532530
total_train_sample_count: 10177580
total_episode_count: 31758
total_duration: 2776.8913994431214
[2023-06-29 12:28:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2232
train_sample_count: 2232
avg_envstep_per_episode: 318.85714285714283
avg_sample_per_episode: 318.85714285714283
avg_envstep_per_sec: 2692.8180651367056
avg_train_sample_per_sec: 2692.8180651367056
avg_episode_per_sec: 8.445217946217268
collect_time: 0.8288714447133243
reward_mean: 2290.7732639162464
reward_std: 858.1106498150688
reward_max: 3593.075680151445
reward_min: 1318.6446438072467
total_envstep_count: 13537130
total_train_sample_count: 10181012
total_episode_count: 31765
total_duration: 2777.720270887835
[2023-06-29 12:28:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1255
train_sample_count: 1255
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2715.8970784068338
avg_train_sample_per_sec: 2715.8970784068338
avg_episode_per_sec: 10.82030708528619
collect_time: 0.4620940940575674
reward_mean: 2871.983306346959
reward_std: 941.1528422634033
reward_max: 3606.3974971214084
reward_min: 1239.2255341996654
total_envstep_count: 13541482
total_train_sample_count: 10184267
total_episode_count: 31770
total_duration: 2778.1823649818925
[2023-06-29 12:29:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2423
train_sample_count: 2423
avg_envstep_per_episode: 346.14285714285717
avg_sample_per_episode: 346.14285714285717
avg_envstep_per_sec: 2765.480388041427
avg_train_sample_per_sec: 2765.480388041427
avg_episode_per_sec: 7.989419197808497
collect_time: 0.8761588078793142
reward_mean: 2843.0158202783746
reward_std: 945.7341396562983
reward_max: 3598.7968627626287
reward_min: 1220.722825084498
total_envstep_count: 13546282
total_train_sample_count: 10187490
total_episode_count: 31777
total_duration: 2779.0585237897717
[2023-06-29 12:29:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1954
train_sample_count: 1954
avg_envstep_per_episode: 279.14285714285717
avg_sample_per_episode: 279.14285714285717
avg_envstep_per_sec: 2648.438040379732
avg_train_sample_per_sec: 2648.438040379732
avg_episode_per_sec: 9.487751424082969
collect_time: 0.7377933597872036
reward_mean: 2143.9078341109894
reward_std: 936.9299861842823
reward_max: 3549.3029896102125
reward_min: 883.643121581953
total_envstep_count: 13550906
total_train_sample_count: 10191044
total_episode_count: 31784
total_duration: 2779.796317149559
[2023-06-29 12:29:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2383
train_sample_count: 2383
avg_envstep_per_episode: 297.875
avg_sample_per_episode: 297.875
avg_envstep_per_sec: 2761.706295617881
avg_train_sample_per_sec: 2761.706295617881
avg_episode_per_sec: 9.271359783861959
collect_time: 0.8628723495258019
reward_mean: 2599.7139432530375
reward_std: 872.708547303254
reward_max: 3619.233204915227
reward_min: 1594.010464484775
total_envstep_count: 13555858
total_train_sample_count: 10194627
total_episode_count: 31792
total_duration: 2780.6591894990847
[2023-06-29 12:29:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1735
train_sample_count: 1735
avg_envstep_per_episode: 247.85714285714286
avg_sample_per_episode: 247.85714285714286
avg_envstep_per_sec: 2754.6048432355583
avg_train_sample_per_sec: 2754.6048432355583
avg_episode_per_sec: 11.11367948279476
collect_time: 0.6298544069798663
reward_mean: 1973.8599761395174
reward_std: 849.0112961873643
reward_max: 3563.855799733004
reward_min: 1089.1915471421896
total_envstep_count: 13560706
total_train_sample_count: 10197962
total_episode_count: 31799
total_duration: 2781.2890439060648
[2023-06-29 12:29:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1485
train_sample_count: 1485
avg_envstep_per_episode: 212.14285714285714
avg_sample_per_episode: 212.14285714285714
avg_envstep_per_sec: 2746.9295630038455
avg_train_sample_per_sec: 2746.9295630038455
avg_episode_per_sec: 12.948489522577049
collect_time: 0.5406035961024462
reward_mean: 2262.7260589976936
reward_std: 886.461269959698
reward_max: 3738.2373729756823
reward_min: 1363.2173010633794
total_envstep_count: 13564770
total_train_sample_count: 10201447
total_episode_count: 31806
total_duration: 2781.829647502167
[2023-06-29 12:29:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 276
train_sample_count: 276
avg_envstep_per_episode: 69.0
avg_sample_per_episode: 69.0
avg_envstep_per_sec: 2652.55436212607
avg_train_sample_per_sec: 2652.55436212607
avg_episode_per_sec: 38.44281684240681
collect_time: 0.10405064791161567
reward_mean: 2946.825686080664
reward_std: 747.8016833622413
reward_max: 3754.141723293485
reward_min: 2077.125277194433
total_envstep_count: 13568706
total_train_sample_count: 10204923
total_episode_count: 31810
total_duration: 2781.9336981500787
[2023-06-29 12:29:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2317
train_sample_count: 2317
avg_envstep_per_episode: 289.625
avg_sample_per_episode: 289.625
avg_envstep_per_sec: 2803.9184478607644
avg_train_sample_per_sec: 2803.9184478607644
avg_episode_per_sec: 9.681203100080326
collect_time: 0.8263435770636424
reward_mean: 2400.8565646101633
reward_std: 961.7125660869043
reward_max: 3596.8813281981506
reward_min: 1051.082737851715
total_envstep_count: 13572874
total_train_sample_count: 10208440
total_episode_count: 31818
total_duration: 2782.7600417271424
[2023-06-29 12:29:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1333
train_sample_count: 1333
avg_envstep_per_episode: 222.16666666666666
avg_sample_per_episode: 222.16666666666666
avg_envstep_per_sec: 2732.0352132501735
avg_train_sample_per_sec: 2732.0352132501735
avg_episode_per_sec: 12.297232767817736
collect_time: 0.4879146482208744
reward_mean: 2642.785902523085
reward_std: 990.9653299350881
reward_max: 3639.4981856213344
reward_min: 1379.0676302851932
total_envstep_count: 13577218
total_train_sample_count: 10211773
total_episode_count: 31824
total_duration: 2783.247956375363
[2023-06-29 12:29:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1880
train_sample_count: 1880
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2791.9774197025863
avg_train_sample_per_sec: 2791.9774197025863
avg_episode_per_sec: 11.880754977457814
collect_time: 0.6733578813113273
reward_mean: 2214.1330240134166
reward_std: 984.9044137879418
reward_max: 3553.0765664092623
reward_min: 1183.0612494636832
total_envstep_count: 13582602
total_train_sample_count: 10215253
total_episode_count: 31832
total_duration: 2783.9213142566746
[2023-06-29 12:29:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1484
train_sample_count: 1484
avg_envstep_per_episode: 296.8
avg_sample_per_episode: 296.8
avg_envstep_per_sec: 2550.1715420308587
avg_train_sample_per_sec: 2550.1715420308587
avg_episode_per_sec: 8.592222176653836
collect_time: 0.5819216376394034
reward_mean: 2956.111654482439
reward_std: 798.2772128298436
reward_max: 3625.5106372232176
reward_min: 1718.33014114639
total_envstep_count: 13587338
total_train_sample_count: 10218737
total_episode_count: 31837
total_duration: 2784.503235894314
[2023-06-29 12:29:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1752
train_sample_count: 1752
avg_envstep_per_episode: 250.28571428571428
avg_sample_per_episode: 250.28571428571428
avg_envstep_per_sec: 2443.869861295317
avg_train_sample_per_sec: 2443.869861295317
avg_episode_per_sec: 9.764320222070332
collect_time: 0.7168957839151846
reward_mean: 3044.0909730035187
reward_std: 671.0942026912907
reward_max: 3632.4643124041263
reward_min: 1717.7603069985469
total_envstep_count: 13591842
total_train_sample_count: 10222089
total_episode_count: 31844
total_duration: 2785.2201316782293
[2023-06-29 12:29:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2578
train_sample_count: 2578
avg_envstep_per_episode: 368.2857142857143
avg_sample_per_episode: 368.2857142857143
avg_envstep_per_sec: 2789.634355274406
avg_train_sample_per_sec: 2789.634355274406
avg_episode_per_sec: 7.574647202063942
collect_time: 0.9241354499114676
reward_mean: 2596.3019081612133
reward_std: 1004.0356864307519
reward_max: 3639.048819328884
reward_min: 1047.0352373753512
total_envstep_count: 13595970
total_train_sample_count: 10225467
total_episode_count: 31851
total_duration: 2786.1442671281407
[2023-06-29 12:29:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1271
train_sample_count: 1271
avg_envstep_per_episode: 317.75
avg_sample_per_episode: 317.75
avg_envstep_per_sec: 2807.3257786273157
avg_train_sample_per_sec: 2807.3257786273157
avg_episode_per_sec: 8.83501425217094
collect_time: 0.4527440347950905
reward_mean: 2736.9661383224397
reward_std: 950.5846976371713
reward_max: 3758.7040903660145
reward_min: 1637.368553877916
total_envstep_count: 13600042
total_train_sample_count: 10228738
total_episode_count: 31855
total_duration: 2786.597011162936
[2023-06-29 12:29:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 250.3
avg_sample_per_episode: 250.3
avg_envstep_per_sec: 2743.846603360116
avg_train_sample_per_sec: 2743.846603360116
avg_episode_per_sec: 10.962231735358035
collect_time: 0.9122230072682724
reward_mean: 2092.566099888161
reward_std: 724.2873592551119
reward_max: 3545.2195713278015
reward_min: 1130.5163140458742
total_envstep_count: 13604618
total_train_sample_count: 10232041
total_episode_count: 31865
total_duration: 2787.5092341702043
[2023-06-29 12:29:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2134
train_sample_count: 2134
avg_envstep_per_episode: 304.85714285714283
avg_sample_per_episode: 304.85714285714283
avg_envstep_per_sec: 2648.5748325138757
avg_train_sample_per_sec: 2648.5748325138757
avg_episode_per_sec: 8.687921193813088
collect_time: 0.8057163323471322
reward_mean: 2208.244050484993
reward_std: 672.1614929015707
reward_max: 3624.967494110483
reward_min: 1524.8798262937867
total_envstep_count: 13609090
total_train_sample_count: 10235375
total_episode_count: 31872
total_duration: 2788.3149505025513
[2023-06-29 12:29:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2797.0839584534306
avg_train_sample_per_sec: 2797.0839584534306
avg_episode_per_sec: 12.54297739216785
collect_time: 0.47835532285552473
reward_mean: 1966.477418922778
reward_std: 929.1415347099955
reward_max: 3603.73312158841
reward_min: 733.103403373059
total_envstep_count: 13614018
total_train_sample_count: 10238713
total_episode_count: 31878
total_duration: 2788.7933058254066
[2023-06-29 12:29:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2051
train_sample_count: 2051
avg_envstep_per_episode: 227.88888888888889
avg_sample_per_episode: 227.88888888888889
avg_envstep_per_sec: 2801.437116284408
avg_train_sample_per_sec: 2801.437116284408
avg_episode_per_sec: 12.292995634597597
collect_time: 0.7321242329794913
reward_mean: 2451.5833856991367
reward_std: 1053.5175852635718
reward_max: 3701.3336248631867
reward_min: 1129.260035495438
total_envstep_count: 13618426
total_train_sample_count: 10241964
total_episode_count: 31887
total_duration: 2789.525430058386
[2023-06-29 12:29:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2002
train_sample_count: 2002
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2818.640476430909
avg_train_sample_per_sec: 2818.640476430909
avg_episode_per_sec: 9.855386281226954
collect_time: 0.7102715002996848
reward_mean: 1912.871094680595
reward_std: 773.815631271813
reward_max: 3707.3721459228864
reward_min: 1059.927151119402
total_envstep_count: 13622986
total_train_sample_count: 10245166
total_episode_count: 31894
total_duration: 2790.235701558686
[2023-06-29 12:29:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2947
train_sample_count: 2947
avg_envstep_per_episode: 294.7
avg_sample_per_episode: 294.7
avg_envstep_per_sec: 2596.2632661100065
avg_train_sample_per_sec: 2596.2632661100065
avg_episode_per_sec: 8.809851598608775
collect_time: 1.1350929000414909
reward_mean: 2167.4756452630927
reward_std: 1116.3663504924575
reward_max: 3677.28030785783
reward_min: 423.01843044058546
total_envstep_count: 13627914
total_train_sample_count: 10248913
total_episode_count: 31904
total_duration: 2791.3707944587272
[2023-06-29 12:29:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2943
train_sample_count: 2943
avg_envstep_per_episode: 294.3
avg_sample_per_episode: 294.3
avg_envstep_per_sec: 2589.5770438625145
avg_train_sample_per_sec: 2589.5770438625145
avg_episode_per_sec: 8.799106503100628
collect_time: 1.1364790273280818
reward_mean: 1850.5941921638405
reward_std: 1013.9692824101809
reward_max: 3677.848852193313
reward_min: 193.33211608024527
total_envstep_count: 13632714
total_train_sample_count: 10252256
total_episode_count: 31914
total_duration: 2792.5072734860555
[2023-06-29 12:30:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2311
train_sample_count: 2311
avg_envstep_per_episode: 256.77777777777777
avg_sample_per_episode: 256.77777777777777
avg_envstep_per_sec: 2738.2899281017926
avg_train_sample_per_sec: 2738.2899281017926
avg_episode_per_sec: 10.664045587588115
collect_time: 0.8439573824098334
reward_mean: 1734.861459956751
reward_std: 276.5260184249029
reward_max: 2103.441761761405
reward_min: 1245.3493883337114
total_envstep_count: 13637386
total_train_sample_count: 10255767
total_episode_count: 31923
total_duration: 2793.3512308684653
[2023-06-29 12:30:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2883
train_sample_count: 2883
avg_envstep_per_episode: 320.3333333333333
avg_sample_per_episode: 320.3333333333333
avg_envstep_per_sec: 2829.9317656793864
avg_train_sample_per_sec: 2829.9317656793864
avg_episode_per_sec: 8.83433433614793
collect_time: 1.0187524784039708
reward_mean: 2044.5841461291752
reward_std: 878.6286359744131
reward_max: 3584.3066963124675
reward_min: 447.6603371893042
total_envstep_count: 13641746
total_train_sample_count: 10259050
total_episode_count: 31932
total_duration: 2794.3699833468695
[2023-06-29 12:30:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1205
train_sample_count: 1205
avg_envstep_per_episode: 301.25
avg_sample_per_episode: 301.25
avg_envstep_per_sec: 2787.016918487648
avg_train_sample_per_sec: 2787.016918487648
avg_episode_per_sec: 9.251508443112524
collect_time: 0.4323619250413031
reward_mean: 2327.8224564181687
reward_std: 838.468900626094
reward_max: 3618.465140792399
reward_min: 1576.7376977824458
total_envstep_count: 13646258
total_train_sample_count: 10262255
total_episode_count: 31936
total_duration: 2794.802345271911
[2023-06-29 12:30:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1457
train_sample_count: 1457
avg_envstep_per_episode: 208.14285714285714
avg_sample_per_episode: 208.14285714285714
avg_envstep_per_sec: 2386.042108487615
avg_train_sample_per_sec: 2386.042108487615
avg_episode_per_sec: 11.46348301950124
collect_time: 0.6106346551124006
reward_mean: 2255.517177706773
reward_std: 1308.762303341891
reward_max: 3658.207298690013
reward_min: 193.30558261454584
total_envstep_count: 13650282
total_train_sample_count: 10265712
total_episode_count: 31943
total_duration: 2795.412979927023
[2023-06-29 12:30:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1889
train_sample_count: 1889
avg_envstep_per_episode: 269.85714285714283
avg_sample_per_episode: 269.85714285714283
avg_envstep_per_sec: 2789.4609205376414
avg_train_sample_per_sec: 2789.4609205376414
avg_episode_per_sec: 10.33680595223054
collect_time: 0.6771917778421193
reward_mean: 2616.4958913010983
reward_std: 953.4623133807476
reward_max: 3697.6431828295863
reward_min: 1162.9895578640167
total_envstep_count: 13654962
total_train_sample_count: 10269201
total_episode_count: 31950
total_duration: 2796.090171704865
[2023-06-29 12:30:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1865
train_sample_count: 1865
avg_envstep_per_episode: 233.125
avg_sample_per_episode: 233.125
avg_envstep_per_sec: 2800.237319634988
avg_train_sample_per_sec: 2800.237319634988
avg_episode_per_sec: 12.011741853662148
collect_time: 0.66601497913152
reward_mean: 2247.882656583495
reward_std: 771.6111188401576
reward_max: 3645.649208531318
reward_min: 1267.4761674235094
total_envstep_count: 13659450
total_train_sample_count: 10272666
total_episode_count: 31958
total_duration: 2796.7561866839965
[2023-06-29 12:30:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2310
train_sample_count: 2310
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 2827.355306534238
avg_train_sample_per_sec: 2827.355306534238
avg_episode_per_sec: 8.567743353134054
collect_time: 0.8170179371023552
reward_mean: 2501.5974585859617
reward_std: 702.5256326556446
reward_max: 3699.4208823900035
reward_min: 1425.6353267782777
total_envstep_count: 13664362
total_train_sample_count: 10276176
total_episode_count: 31965
total_duration: 2797.5732046210987
[2023-06-29 12:30:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2346
train_sample_count: 2346
avg_envstep_per_episode: 293.25
avg_sample_per_episode: 293.25
avg_envstep_per_sec: 2633.632389636181
avg_train_sample_per_sec: 2633.632389636181
avg_episode_per_sec: 8.980843613422612
collect_time: 0.8907849133508281
reward_mean: 2359.187536785801
reward_std: 579.6504051253312
reward_max: 3543.4158034568813
reward_min: 1676.3607635159929
total_envstep_count: 13668658
total_train_sample_count: 10279722
total_episode_count: 31973
total_duration: 2798.4639895344494
[2023-06-29 12:30:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1913
train_sample_count: 1913
avg_envstep_per_episode: 273.2857142857143
avg_sample_per_episode: 273.2857142857143
avg_envstep_per_sec: 2437.0906288671254
avg_train_sample_per_sec: 2437.0906288671254
avg_episode_per_sec: 8.917738840601087
collect_time: 0.7849523433148863
reward_mean: 1941.941597720053
reward_std: 765.6614965297085
reward_max: 3637.0963493431723
reward_min: 1060.2854561180845
total_envstep_count: 13673226
total_train_sample_count: 10283235
total_episode_count: 31980
total_duration: 2799.248941877764
[2023-06-29 12:30:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2013
train_sample_count: 2013
avg_envstep_per_episode: 335.5
avg_sample_per_episode: 335.5
avg_envstep_per_sec: 2739.5942350846058
avg_train_sample_per_sec: 2739.5942350846058
avg_episode_per_sec: 8.165705618732058
collect_time: 0.7347803460163995
reward_mean: 2637.638100130627
reward_std: 969.4232217155919
reward_max: 3697.5951618939316
reward_min: 1339.7979201361463
total_envstep_count: 13677514
total_train_sample_count: 10286448
total_episode_count: 31986
total_duration: 2799.9837222237807
[2023-06-29 12:30:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 143.4
avg_sample_per_episode: 143.4
avg_envstep_per_sec: 2718.693109075114
avg_train_sample_per_sec: 2718.693109075114
avg_episode_per_sec: 18.958808292016137
collect_time: 0.2637296565789729
reward_mean: 2230.507421168794
reward_std: 1254.3743675927255
reward_max: 3544.301073558663
reward_min: 587.112663963144
total_envstep_count: 13682554
total_train_sample_count: 10289965
total_episode_count: 31991
total_duration: 2800.2474518803597
[2023-06-29 12:30:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2765
train_sample_count: 2765
avg_envstep_per_episode: 251.36363636363637
avg_sample_per_episode: 251.36363636363637
avg_envstep_per_sec: 2747.9311594774563
avg_train_sample_per_sec: 2747.9311594774563
avg_episode_per_sec: 10.932095028662575
collect_time: 1.0062115240637213
reward_mean: 2406.6604402156913
reward_std: 1503.0970635695614
reward_max: 3692.804339187172
reward_min: 73.88747780774355
total_envstep_count: 13687506
total_train_sample_count: 10293530
total_episode_count: 32002
total_duration: 2801.2536634044236
[2023-06-29 12:30:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2220
train_sample_count: 2220
avg_envstep_per_episode: 317.14285714285717
avg_sample_per_episode: 317.14285714285717
avg_envstep_per_sec: 2461.02949562308
avg_train_sample_per_sec: 2461.02949562308
avg_episode_per_sec: 7.760002914126829
collect_time: 0.9020615169173108
reward_mean: 1978.597406974484
reward_std: 381.9305287370994
reward_max: 2630.8385457258464
reward_min: 1452.1675135795583
total_envstep_count: 13691786
total_train_sample_count: 10296950
total_episode_count: 32009
total_duration: 2802.155724921341
[2023-06-29 12:30:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 287.42857142857144
avg_sample_per_episode: 287.42857142857144
avg_envstep_per_sec: 2775.8334792987257
avg_train_sample_per_sec: 2775.8334792987257
avg_episode_per_sec: 9.657472343484631
collect_time: 0.724827341050841
reward_mean: 2442.0251963208184
reward_std: 788.0036595076194
reward_max: 3720.006549356386
reward_min: 1643.2182777554847
total_envstep_count: 13696618
total_train_sample_count: 10300162
total_episode_count: 32016
total_duration: 2802.880552262392
[2023-06-29 12:30:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 426.0
avg_sample_per_episode: 426.0
avg_envstep_per_sec: 2692.9881787056047
avg_train_sample_per_sec: 2692.9881787056047
avg_episode_per_sec: 6.3215684946140955
collect_time: 0.9491315335920083
reward_mean: 3295.73903890095
reward_std: 231.56075637065075
reward_max: 3616.259352815812
reward_min: 2972.401104228124
total_envstep_count: 13701354
total_train_sample_count: 10303518
total_episode_count: 32022
total_duration: 2803.8296837959842
[2023-06-29 12:30:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 712
train_sample_count: 712
avg_envstep_per_episode: 237.33333333333334
avg_sample_per_episode: 237.33333333333334
avg_envstep_per_sec: 2798.8287882441477
avg_train_sample_per_sec: 2798.8287882441477
avg_episode_per_sec: 11.792817927995005
collect_time: 0.2543921239450574
reward_mean: 2919.7522478686788
reward_std: 702.2049651392273
reward_max: 3622.5559966754345
reward_min: 1960.7420394238288
total_envstep_count: 13706050
total_train_sample_count: 10307030
total_episode_count: 32025
total_duration: 2804.084075919929
[2023-06-29 12:30:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2349
train_sample_count: 2349
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2533.680242908649
avg_train_sample_per_sec: 2533.680242908649
avg_episode_per_sec: 9.70758713758103
collect_time: 0.9271098855407907
reward_mean: 2835.796832266798
reward_std: 613.498428618383
reward_max: 3507.1504408508963
reward_min: 1720.4774778490212
total_envstep_count: 13710682
total_train_sample_count: 10310579
total_episode_count: 32034
total_duration: 2805.0111858054697
[2023-06-29 12:30:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2773
train_sample_count: 2773
avg_envstep_per_episode: 252.0909090909091
avg_sample_per_episode: 252.0909090909091
avg_envstep_per_sec: 2498.3581781072935
avg_train_sample_per_sec: 2498.3581781072935
avg_episode_per_sec: 9.91054452188252
collect_time: 1.1099289222415538
reward_mean: 1697.0827679855577
reward_std: 840.2233885816901
reward_max: 3724.865136670225
reward_min: 78.97789745943015
total_envstep_count: 13715602
total_train_sample_count: 10314152
total_episode_count: 32045
total_duration: 2806.1211147277113
[2023-06-29 12:30:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1756
train_sample_count: 1756
avg_envstep_per_episode: 250.85714285714286
avg_sample_per_episode: 250.85714285714286
avg_envstep_per_sec: 2770.3831838129267
avg_train_sample_per_sec: 2770.3831838129267
avg_episode_per_sec: 11.043668728183649
collect_time: 0.6338473357260228
reward_mean: 1896.2182669702183
reward_std: 567.0400833982766
reward_max: 2987.4741519678405
reward_min: 1199.607853303031
total_envstep_count: 13720114
total_train_sample_count: 10317508
total_episode_count: 32052
total_duration: 2806.7549620634372
[2023-06-29 12:31:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2631
train_sample_count: 2631
avg_envstep_per_episode: 263.1
avg_sample_per_episode: 263.1
avg_envstep_per_sec: 2712.547081989808
avg_train_sample_per_sec: 2712.547081989808
avg_episode_per_sec: 10.309947099923253
collect_time: 0.9699370814496653
reward_mean: 1899.1077945456575
reward_std: 1044.3791097249234
reward_max: 3497.5566842086832
reward_min: 52.97882253395165
total_envstep_count: 13724562
total_train_sample_count: 10320939
total_episode_count: 32062
total_duration: 2807.724899144887
[2023-06-29 12:31:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2962
train_sample_count: 2962
avg_envstep_per_episode: 269.27272727272725
avg_sample_per_episode: 269.27272727272725
avg_envstep_per_sec: 2729.1399769274663
avg_train_sample_per_sec: 2729.1399769274663
avg_episode_per_sec: 10.135226112829889
collect_time: 1.0853235909631478
reward_mean: 1623.4654900996932
reward_std: 788.60617682418
reward_max: 3527.7751162781265
reward_min: 922.2622600199929
total_envstep_count: 13729562
total_train_sample_count: 10324301
total_episode_count: 32073
total_duration: 2808.81022273585
[2023-06-29 12:31:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2183
train_sample_count: 2183
avg_envstep_per_episode: 242.55555555555554
avg_sample_per_episode: 242.55555555555554
avg_envstep_per_sec: 2419.797737852188
avg_train_sample_per_sec: 2419.797737852188
avg_episode_per_sec: 9.976261860132704
collect_time: 0.902141516149044
reward_mean: 1726.5048485529721
reward_std: 766.0964598602679
reward_max: 3674.0423250960507
reward_min: 858.8720680107117
total_envstep_count: 13733986
total_train_sample_count: 10327684
total_episode_count: 32082
total_duration: 2809.712364251999
[2023-06-29 12:31:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2125
train_sample_count: 2125
avg_envstep_per_episode: 236.11111111111111
avg_sample_per_episode: 236.11111111111111
avg_envstep_per_sec: 2513.499013352867
avg_train_sample_per_sec: 2513.499013352867
avg_episode_per_sec: 10.645407585965085
collect_time: 0.8454349847408011
reward_mean: 1880.4796430008776
reward_std: 673.8824402251443
reward_max: 2853.629666426055
reward_min: 1078.285746837991
total_envstep_count: 13738298
total_train_sample_count: 10331009
total_episode_count: 32091
total_duration: 2810.55779923674
[2023-06-29 12:31:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2005
train_sample_count: 2005
avg_envstep_per_episode: 250.625
avg_sample_per_episode: 250.625
avg_envstep_per_sec: 2517.638846842308
avg_train_sample_per_sec: 2517.638846842308
avg_episode_per_sec: 10.045441782911952
collect_time: 0.7963811022834852
reward_mean: 1860.934503585469
reward_std: 649.2110561506269
reward_max: 3157.3326026564355
reward_min: 1082.8614051530556
total_envstep_count: 13742682
total_train_sample_count: 10334214
total_episode_count: 32099
total_duration: 2811.3541803390235
[2023-06-29 12:31:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1650
train_sample_count: 1650
avg_envstep_per_episode: 206.25
avg_sample_per_episode: 206.25
avg_envstep_per_sec: 2817.2222345346495
avg_train_sample_per_sec: 2817.2222345346495
avg_episode_per_sec: 13.659259318955876
collect_time: 0.585683294620365
reward_mean: 1938.9455003697926
reward_std: 774.7016067664256
reward_max: 3378.4492271718304
reward_min: 965.3365812444695
total_envstep_count: 13746754
total_train_sample_count: 10337464
total_episode_count: 32107
total_duration: 2811.9398636336437
[2023-06-29 12:31:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2811
train_sample_count: 2811
avg_envstep_per_episode: 216.23076923076923
avg_sample_per_episode: 216.23076923076923
avg_envstep_per_sec: 2640.84017007464
avg_train_sample_per_sec: 2640.84017007464
avg_episode_per_sec: 12.213063753457957
collect_time: 1.0644339751619845
reward_mean: 1483.2035836154564
reward_std: 545.0580303521645
reward_max: 2317.703382569011
reward_min: 101.19151811778565
total_envstep_count: 13751274
total_train_sample_count: 10340675
total_episode_count: 32120
total_duration: 2813.0042976088057
[2023-06-29 12:31:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3016
train_sample_count: 3016
avg_envstep_per_episode: 251.33333333333334
avg_sample_per_episode: 251.33333333333334
avg_envstep_per_sec: 2561.097874709045
avg_train_sample_per_sec: 2561.097874709045
avg_episode_per_sec: 10.19004459433307
collect_time: 1.1776199690699578
reward_mean: 1416.2013909458747
reward_std: 473.37361979792377
reward_max: 2408.0584324983533
reward_min: 573.7192244858088
total_envstep_count: 13756186
total_train_sample_count: 10344091
total_episode_count: 32132
total_duration: 2814.1819175778755
[2023-06-29 12:31:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2676
train_sample_count: 2676
avg_envstep_per_episode: 243.27272727272728
avg_sample_per_episode: 243.27272727272728
avg_envstep_per_sec: 2758.033439696012
avg_train_sample_per_sec: 2758.033439696012
avg_episode_per_sec: 11.337207711754907
collect_time: 0.9702565463799984
reward_mean: 1536.679026946514
reward_std: 541.5201596443453
reward_max: 2351.5801131904336
reward_min: 202.04931108316035
total_envstep_count: 13760746
total_train_sample_count: 10347567
total_episode_count: 32143
total_duration: 2815.1521741242555
[2023-06-29 12:31:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2654
train_sample_count: 2654
avg_envstep_per_episode: 221.16666666666666
avg_sample_per_episode: 221.16666666666666
avg_envstep_per_sec: 2773.149717745209
avg_train_sample_per_sec: 2773.149717745209
avg_episode_per_sec: 12.538732710227018
collect_time: 0.9570345167508348
reward_mean: 1365.4506818122363
reward_std: 643.279912368922
reward_max: 2157.947178691321
reward_min: 67.48130011585923
total_envstep_count: 13765034
total_train_sample_count: 10351021
total_episode_count: 32155
total_duration: 2816.1092086410063
[2023-06-29 12:31:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 237.27272727272728
avg_sample_per_episode: 237.27272727272728
avg_envstep_per_sec: 2593.931950038457
avg_train_sample_per_sec: 2593.931950038457
avg_episode_per_sec: 10.932280249204226
collect_time: 1.0061944762896746
reward_mean: 1426.253001462945
reward_std: 283.20939111384837
reward_max: 1828.960603113638
reward_min: 993.9751609016106
total_envstep_count: 13770130
total_train_sample_count: 10354431
total_episode_count: 32166
total_duration: 2817.115403117296
[2023-06-29 12:31:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3568
train_sample_count: 3568
avg_envstep_per_episode: 297.3333333333333
avg_sample_per_episode: 297.3333333333333
avg_envstep_per_sec: 2545.717453010093
avg_train_sample_per_sec: 2545.717453010093
avg_episode_per_sec: 8.561829998912868
collect_time: 1.4015695244502275
reward_mean: 1856.1387386443312
reward_std: 955.0808466736294
reward_max: 3148.419974140232
reward_min: 88.33094572018187
total_envstep_count: 13775050
total_train_sample_count: 10357999
total_episode_count: 32178
total_duration: 2818.516972641746
[2023-06-29 12:31:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2792
train_sample_count: 2792
avg_envstep_per_episode: 310.22222222222223
avg_sample_per_episode: 310.22222222222223
avg_envstep_per_sec: 2560.307924524682
avg_train_sample_per_sec: 2560.307924524682
avg_episode_per_sec: 8.253141590516526
collect_time: 1.0904938321113586
reward_mean: 1713.4354892602944
reward_std: 375.2605045830175
reward_max: 2541.438321863197
reward_min: 1318.0687673173204
total_envstep_count: 13779706
total_train_sample_count: 10361591
total_episode_count: 32187
total_duration: 2819.6074664738576
[2023-06-29 12:31:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2599
train_sample_count: 2599
avg_envstep_per_episode: 216.58333333333334
avg_sample_per_episode: 216.58333333333334
avg_envstep_per_sec: 2732.4830116691655
avg_train_sample_per_sec: 2732.4830116691655
avg_episode_per_sec: 12.616312481735278
collect_time: 0.951149554782547
reward_mean: 1361.664328405736
reward_std: 309.9805161025396
reward_max: 2085.018268283018
reward_min: 1022.9533300552522
total_envstep_count: 13784138
total_train_sample_count: 10364990
total_episode_count: 32199
total_duration: 2820.5586160286402
[2023-06-29 12:31:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2855
train_sample_count: 2855
avg_envstep_per_episode: 259.54545454545456
avg_sample_per_episode: 259.54545454545456
avg_envstep_per_sec: 2747.3928198925964
avg_train_sample_per_sec: 2747.3928198925964
avg_episode_per_sec: 10.585401407642228
collect_time: 1.039167016572319
reward_mean: 1577.3328751025547
reward_std: 413.9294203157709
reward_max: 2523.262006995068
reward_min: 907.9213143803188
total_envstep_count: 13788362
total_train_sample_count: 10368245
total_episode_count: 32210
total_duration: 2821.5977830452125
[2023-06-29 12:31:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3335
train_sample_count: 3335
avg_envstep_per_episode: 256.53846153846155
avg_sample_per_episode: 256.53846153846155
avg_envstep_per_sec: 2559.533290493122
avg_train_sample_per_sec: 2559.533290493122
avg_episode_per_sec: 9.977191237304522
collect_time: 1.3029719177270307
reward_mean: 1328.6523749632152
reward_std: 349.70531115852543
reward_max: 2095.3027983788866
reward_min: 932.7118549549749
total_envstep_count: 13793434
total_train_sample_count: 10371580
total_episode_count: 32223
total_duration: 2822.9007549629396
[2023-06-29 12:31:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3521
train_sample_count: 3521
avg_envstep_per_episode: 234.73333333333332
avg_sample_per_episode: 234.73333333333332
avg_envstep_per_sec: 2589.0898962004344
avg_train_sample_per_sec: 2589.0898962004344
avg_episode_per_sec: 11.029920034935108
collect_time: 1.3599373297803106
reward_mean: 1286.6136198550605
reward_std: 357.8604660522591
reward_max: 1936.9244869162571
reward_min: 586.741205412117
total_envstep_count: 13798378
total_train_sample_count: 10375101
total_episode_count: 32238
total_duration: 2824.26069229272
[2023-06-29 12:31:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3517
train_sample_count: 3517
avg_envstep_per_episode: 251.21428571428572
avg_sample_per_episode: 251.21428571428572
avg_envstep_per_sec: 2499.539450799562
avg_train_sample_per_sec: 2499.539450799562
avg_episode_per_sec: 9.949830057206105
collect_time: 1.4070592079972848
reward_mean: 1311.7300740115122
reward_std: 233.7412124933223
reward_max: 1927.7546678866545
reward_min: 994.0513186343716
total_envstep_count: 13803610
total_train_sample_count: 10379018
total_episode_count: 32252
total_duration: 2825.6677515007173
[2023-06-29 12:31:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 242.83333333333334
avg_sample_per_episode: 242.83333333333334
avg_envstep_per_sec: 2692.769470400535
avg_train_sample_per_sec: 2692.769470400535
avg_episode_per_sec: 11.0889614429672
collect_time: 1.0821572481533512
reward_mean: 1429.0364482256311
reward_std: 521.3770632738347
reward_max: 3036.7387506721507
reward_min: 997.2816218653173
total_envstep_count: 13808010
total_train_sample_count: 10382332
total_episode_count: 32264
total_duration: 2826.7499087488704
[2023-06-29 12:31:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1871
train_sample_count: 1871
avg_envstep_per_episode: 233.875
avg_sample_per_episode: 233.875
avg_envstep_per_sec: 2578.193357116647
avg_train_sample_per_sec: 2578.193357116647
avg_episode_per_sec: 11.023809116479518
collect_time: 0.7257019706591964
reward_mean: 1403.5495405009096
reward_std: 854.2637542385129
reward_max: 2778.8116047513186
reward_min: 187.5901678312286
total_envstep_count: 13813386
total_train_sample_count: 10385803
total_episode_count: 32272
total_duration: 2827.4756107195294
[2023-06-29 12:32:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2753
train_sample_count: 2753
avg_envstep_per_episode: 229.41666666666666
avg_sample_per_episode: 229.41666666666666
avg_envstep_per_sec: 2619.686111978796
avg_train_sample_per_sec: 2619.686111978796
avg_episode_per_sec: 11.4189005970743
collect_time: 1.0508892601337283
reward_mean: 2003.0568323099044
reward_std: 864.7225984455728
reward_max: 3734.6901836837455
reward_min: 1166.9430638310318
total_envstep_count: 13817842
total_train_sample_count: 10389356
total_episode_count: 32284
total_duration: 2828.526499979663
[2023-06-29 12:32:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1614
train_sample_count: 1614
avg_envstep_per_episode: 322.8
avg_sample_per_episode: 322.8
avg_envstep_per_sec: 2635.8160789541485
avg_train_sample_per_sec: 2635.8160789541485
avg_episode_per_sec: 8.165477320180138
collect_time: 0.6123340747812763
reward_mean: 1920.3247130940003
reward_std: 632.7193177206441
reward_max: 2822.5151010324757
reward_min: 1074.7378828592296
total_envstep_count: 13822890
total_train_sample_count: 10392570
total_episode_count: 32289
total_duration: 2829.1388340544445
[2023-06-29 12:32:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1846
train_sample_count: 1846
avg_envstep_per_episode: 230.75
avg_sample_per_episode: 230.75
avg_envstep_per_sec: 2733.888965306583
avg_train_sample_per_sec: 2733.888965306583
avg_episode_per_sec: 11.847839502953773
collect_time: 0.6752285931967198
reward_mean: 2601.109484381902
reward_std: 1005.6399868411278
reward_max: 3586.9180293909726
reward_min: 1225.4390892574568
total_envstep_count: 13827834
total_train_sample_count: 10396016
total_episode_count: 32297
total_duration: 2829.814062647641
[2023-06-29 12:32:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1963
train_sample_count: 1963
avg_envstep_per_episode: 245.375
avg_sample_per_episode: 245.375
avg_envstep_per_sec: 2792.4159678383767
avg_train_sample_per_sec: 2792.4159678383767
avg_episode_per_sec: 11.380197525576675
collect_time: 0.7029754959894347
reward_mean: 2013.2046111451637
reward_std: 1050.0797630005347
reward_max: 3538.1019547208457
reward_min: 600.4192896122987
total_envstep_count: 13832418
total_train_sample_count: 10399579
total_episode_count: 32305
total_duration: 2830.5170381436305
[2023-06-29 12:32:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1638
train_sample_count: 1638
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2687.5025432159255
avg_train_sample_per_sec: 2687.5025432159255
avg_episode_per_sec: 9.844331660131596
collect_time: 0.6094877953268586
reward_mean: 2847.2668394183297
reward_std: 796.6430638120253
reward_max: 3540.714567658293
reward_min: 1147.760411498201
total_envstep_count: 13836498
total_train_sample_count: 10402817
total_episode_count: 32311
total_duration: 2831.1265259389575
[2023-06-29 12:32:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1765
train_sample_count: 1765
avg_envstep_per_episode: 252.14285714285714
avg_sample_per_episode: 252.14285714285714
avg_envstep_per_sec: 2477.593268917966
avg_train_sample_per_sec: 2477.593268917966
avg_episode_per_sec: 9.826148941884282
collect_time: 0.7123848866326735
reward_mean: 2071.720157804619
reward_std: 1151.7755185177014
reward_max: 3618.063473162874
reward_min: 437.70606110625874
total_envstep_count: 13841138
total_train_sample_count: 10406182
total_episode_count: 32318
total_duration: 2831.83891082559
[2023-06-29 12:32:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2296
train_sample_count: 2296
avg_envstep_per_episode: 229.6
avg_sample_per_episode: 229.6
avg_envstep_per_sec: 2808.7851443386057
avg_train_sample_per_sec: 2808.7851443386057
avg_episode_per_sec: 12.233384774993928
collect_time: 0.817435254749842
reward_mean: 1806.5051427331805
reward_std: 1089.2073646391182
reward_max: 3682.157501688008
reward_min: 576.9395497524923
total_envstep_count: 13845794
total_train_sample_count: 10409678
total_episode_count: 32328
total_duration: 2832.65634608034
[2023-06-29 12:32:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2334
train_sample_count: 2334
avg_envstep_per_episode: 259.3333333333333
avg_sample_per_episode: 259.3333333333333
avg_envstep_per_sec: 2793.0774934353853
avg_train_sample_per_sec: 2793.0774934353853
avg_episode_per_sec: 10.770221697051614
collect_time: 0.8356373947681858
reward_mean: 2107.223705242113
reward_std: 1122.2562139745808
reward_max: 3587.1118328964285
reward_min: 173.3257021869613
total_envstep_count: 13850802
total_train_sample_count: 10413212
total_episode_count: 32337
total_duration: 2833.491983475108
[2023-06-29 12:32:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2267
train_sample_count: 2267
avg_envstep_per_episode: 283.375
avg_sample_per_episode: 283.375
avg_envstep_per_sec: 2780.4849755434725
avg_train_sample_per_sec: 2780.4849755434725
avg_episode_per_sec: 9.81203343817723
collect_time: 0.8153253910522905
reward_mean: 1938.470349902379
reward_std: 1062.8288469482222
reward_max: 3611.417556016759
reward_min: 1019.6435313928621
total_envstep_count: 13855466
total_train_sample_count: 10416679
total_episode_count: 32345
total_duration: 2834.3073088661604
[2023-06-29 12:32:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 148.71428571428572
avg_sample_per_episode: 148.71428571428572
avg_envstep_per_sec: 2601.627118374001
avg_train_sample_per_sec: 2601.627118374001
avg_episode_per_sec: 17.494130478979834
collect_time: 0.40013420549314455
reward_mean: 1947.0864385757034
reward_std: 1097.3095743506315
reward_max: 3569.5683329405274
reward_min: 558.037208871904
total_envstep_count: 13859498
total_train_sample_count: 10420120
total_episode_count: 32352
total_duration: 2834.7074430716534
[2023-06-29 12:32:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1219
train_sample_count: 1219
avg_envstep_per_episode: 243.8
avg_sample_per_episode: 243.8
avg_envstep_per_sec: 2378.110023009885
avg_train_sample_per_sec: 2378.110023009885
avg_episode_per_sec: 9.754347920467126
collect_time: 0.5125919272890315
reward_mean: 2852.8084510674335
reward_std: 785.0672870017997
reward_max: 3544.4280886090096
reward_min: 1592.2166009700065
total_envstep_count: 13863218
total_train_sample_count: 10423339
total_episode_count: 32357
total_duration: 2835.2200349989425
[2023-06-29 12:32:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1361
train_sample_count: 1361
avg_envstep_per_episode: 272.2
avg_sample_per_episode: 272.2
avg_envstep_per_sec: 2782.858079395957
avg_train_sample_per_sec: 2782.858079395957
avg_episode_per_sec: 10.223578542968248
collect_time: 0.4890655438294635
reward_mean: 2795.8527208950295
reward_std: 714.0617704239098
reward_max: 3652.3662055024456
reward_min: 1786.616323925627
total_envstep_count: 13867498
total_train_sample_count: 10426700
total_episode_count: 32362
total_duration: 2835.709100542772
[2023-06-29 12:32:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 291.2
avg_sample_per_episode: 291.2
avg_envstep_per_sec: 2599.815458234975
avg_train_sample_per_sec: 2599.815458234975
avg_episode_per_sec: 8.927937699982744
collect_time: 1.1200795005569235
reward_mean: 2264.7875569810176
reward_std: 1125.836734116861
reward_max: 3590.3014393603817
reward_min: 997.5451380926982
total_envstep_count: 13871858
total_train_sample_count: 10430012
total_episode_count: 32372
total_duration: 2836.829180043329
[2023-06-29 12:32:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3042
train_sample_count: 3042
avg_envstep_per_episode: 276.54545454545456
avg_sample_per_episode: 276.54545454545456
avg_envstep_per_sec: 2577.3240078564754
avg_train_sample_per_sec: 2577.3240078564754
avg_episode_per_sec: 9.31971205996753
collect_time: 1.1802939757388087
reward_mean: 1435.686151791457
reward_std: 449.3300207752281
reward_max: 2559.069560919406
reward_min: 1038.2319523631177
total_envstep_count: 13876554
total_train_sample_count: 10433454
total_episode_count: 32383
total_duration: 2838.009474019068
[2023-06-29 12:32:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2077
train_sample_count: 2077
avg_envstep_per_episode: 230.77777777777777
avg_sample_per_episode: 230.77777777777777
avg_envstep_per_sec: 2764.124930182386
avg_train_sample_per_sec: 2764.124930182386
avg_episode_per_sec: 11.977431088898157
collect_time: 0.7514132148372009
reward_mean: 1656.8287709144302
reward_std: 860.4251681883106
reward_max: 3744.8425009894563
reward_min: 840.9471178867734
total_envstep_count: 13881298
total_train_sample_count: 10436731
total_episode_count: 32392
total_duration: 2838.760887233905
[2023-06-29 12:32:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2405
train_sample_count: 2405
avg_envstep_per_episode: 218.63636363636363
avg_sample_per_episode: 218.63636363636363
avg_envstep_per_sec: 2764.396300117435
avg_train_sample_per_sec: 2764.396300117435
avg_episode_per_sec: 12.643808441285568
collect_time: 0.8699910356188193
reward_mean: 1679.347384023197
reward_std: 940.226249863958
reward_max: 3577.3775302281465
reward_min: 717.8141196792824
total_envstep_count: 13885186
total_train_sample_count: 10439936
total_episode_count: 32403
total_duration: 2839.630878269524
[2023-06-29 12:32:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1647
train_sample_count: 1647
avg_envstep_per_episode: 274.5
avg_sample_per_episode: 274.5
avg_envstep_per_sec: 2596.4144529494174
avg_train_sample_per_sec: 2596.4144529494174
avg_episode_per_sec: 9.458704746628115
collect_time: 0.6343363241292534
reward_mean: 1664.26356150471
reward_std: 868.6192135468976
reward_max: 3434.3940238739997
reward_min: 983.3617066661735
total_envstep_count: 13888898
total_train_sample_count: 10443183
total_episode_count: 32409
total_duration: 2840.2652145936536
[2023-06-29 12:32:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2813
train_sample_count: 2813
avg_envstep_per_episode: 312.55555555555554
avg_sample_per_episode: 312.55555555555554
avg_envstep_per_sec: 2684.529495052682
avg_train_sample_per_sec: 2684.529495052682
avg_episode_per_sec: 8.588967456620738
collect_time: 1.047855873881839
reward_mean: 2127.671557172671
reward_std: 1166.2095751443399
reward_max: 3639.4495033770636
reward_min: 824.8726393277008
total_envstep_count: 13893386
total_train_sample_count: 10446396
total_episode_count: 32418
total_duration: 2841.3130704675355
[2023-06-29 12:32:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 271.8888888888889
avg_sample_per_episode: 271.8888888888889
avg_envstep_per_sec: 2730.024343405649
avg_train_sample_per_sec: 2730.024343405649
avg_episode_per_sec: 10.040955901369367
collect_time: 0.8963290037726983
reward_mean: 1640.2705448802635
reward_std: 530.9862054823526
reward_max: 2505.4421309731374
reward_min: 893.9513601732094
total_envstep_count: 13897450
total_train_sample_count: 10449643
total_episode_count: 32427
total_duration: 2842.209399471308
[2023-06-29 12:33:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 621
train_sample_count: 621
avg_envstep_per_episode: 124.2
avg_sample_per_episode: 124.2
avg_envstep_per_sec: 2794.2145351469885
avg_train_sample_per_sec: 2794.2145351469885
avg_episode_per_sec: 22.49770157123179
collect_time: 0.22224492507241667
reward_mean: 1688.685638111116
reward_std: 735.3957033286753
reward_max: 2623.513485629672
reward_min: 798.3329038979762
total_envstep_count: 13901874
total_train_sample_count: 10453064
total_episode_count: 32432
total_duration: 2842.4316443963808
[2023-06-29 12:33:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2974
train_sample_count: 2974
avg_envstep_per_episode: 270.3636363636364
avg_sample_per_episode: 270.3636363636364
avg_envstep_per_sec: 2655.923768752847
avg_train_sample_per_sec: 2655.923768752847
avg_episode_per_sec: 9.823524363241868
collect_time: 1.1197610545111818
reward_mean: 2258.901238069459
reward_std: 858.420765227861
reward_max: 3585.2823768172
reward_min: 1298.9350662461484
total_envstep_count: 13906034
total_train_sample_count: 10456438
total_episode_count: 32443
total_duration: 2843.551405450892
[2023-06-29 12:33:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 322.0
avg_sample_per_episode: 322.0
avg_envstep_per_sec: 2467.9492317598383
avg_train_sample_per_sec: 2467.9492317598383
avg_episode_per_sec: 7.664438607949808
collect_time: 0.6523635005457328
reward_mean: 1601.4149543314547
reward_std: 763.7407760066218
reward_max: 2897.2060424612014
reward_min: 754.9462864539503
total_envstep_count: 13909714
total_train_sample_count: 10459648
total_episode_count: 32448
total_duration: 2844.2037689514377
[2023-06-29 12:33:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2828
train_sample_count: 2828
avg_envstep_per_episode: 282.8
avg_sample_per_episode: 282.8
avg_envstep_per_sec: 2798.51888574274
avg_train_sample_per_sec: 2798.51888574274
avg_episode_per_sec: 9.895752778439675
collect_time: 1.0105345418276266
reward_mean: 2014.6100741484668
reward_std: 986.58588808203
reward_max: 3594.527321807058
reward_min: 915.7679128322577
total_envstep_count: 13913658
total_train_sample_count: 10462876
total_episode_count: 32458
total_duration: 2845.2143034932656
[2023-06-29 12:33:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 380.6666666666667
avg_sample_per_episode: 380.6666666666667
avg_envstep_per_sec: 2797.770634597178
avg_train_sample_per_sec: 2797.770634597178
avg_episode_per_sec: 7.349660160938296
collect_time: 0.4081821382632479
reward_mean: 2316.9441881249463
reward_std: 134.16633265093128
reward_max: 2472.926576079405
reward_min: 2145.3953744071578
total_envstep_count: 13917858
total_train_sample_count: 10466418
total_episode_count: 32461
total_duration: 2845.622485631529
[2023-06-29 12:33:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 408.0
avg_sample_per_episode: 408.0
avg_envstep_per_sec: 2611.927524814608
avg_train_sample_per_sec: 2611.927524814608
avg_episode_per_sec: 6.401783149055412
collect_time: 0.9372388692805542
reward_mean: 3511.147780932322
reward_std: 67.93716735493943
reward_max: 3557.7635429298543
reward_min: 3361.6542031590175
total_envstep_count: 13921946
total_train_sample_count: 10469666
total_episode_count: 32467
total_duration: 2846.5597245008094
[2023-06-29 12:33:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1729
train_sample_count: 1729
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 2761.1056730795867
avg_train_sample_per_sec: 2761.1056730795867
avg_episode_per_sec: 11.178565478055006
collect_time: 0.6261984164016322
reward_mean: 1754.041135367504
reward_std: 707.8968742626441
reward_max: 2847.6346476906365
reward_min: 935.0141446652366
total_envstep_count: 13926698
total_train_sample_count: 10472995
total_episode_count: 32474
total_duration: 2847.185922917211
[2023-06-29 12:33:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1475
train_sample_count: 1475
avg_envstep_per_episode: 245.83333333333334
avg_sample_per_episode: 245.83333333333334
avg_envstep_per_sec: 2680.1290556344698
avg_train_sample_per_sec: 2680.1290556344698
avg_episode_per_sec: 10.902219887326657
collect_time: 0.5503466323381289
reward_mean: 2464.117129696846
reward_std: 636.6812451262978
reward_max: 3579.127327036899
reward_min: 1746.781472963197
total_envstep_count: 13931530
total_train_sample_count: 10476470
total_episode_count: 32480
total_duration: 2847.736269549549
[2023-06-29 12:33:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2175
train_sample_count: 2175
avg_envstep_per_episode: 271.875
avg_sample_per_episode: 271.875
avg_envstep_per_sec: 2736.1647718903187
avg_train_sample_per_sec: 2736.1647718903187
avg_episode_per_sec: 10.064054333389677
collect_time: 0.7949082680782306
reward_mean: 2494.271806093543
reward_std: 853.6526673462945
reward_max: 3671.296729295344
reward_min: 1219.796269345352
total_envstep_count: 13935586
total_train_sample_count: 10479845
total_episode_count: 32488
total_duration: 2848.5311778176274
[2023-06-29 12:33:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 435
train_sample_count: 435
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 2732.1796602611903
avg_train_sample_per_sec: 2732.1796602611903
avg_episode_per_sec: 18.842618346628896
collect_time: 0.15921354160085321
reward_mean: 2651.636507143376
reward_std: 1024.7614554688153
reward_max: 3586.0142999958407
reward_min: 1225.0688189513655
total_envstep_count: 13939770
total_train_sample_count: 10483080
total_episode_count: 32491
total_duration: 2848.690391359228
[2023-06-29 12:33:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2392
train_sample_count: 2392
avg_envstep_per_episode: 217.45454545454547
avg_sample_per_episode: 217.45454545454547
avg_envstep_per_sec: 2519.6861965545463
avg_train_sample_per_sec: 2519.6861965545463
avg_episode_per_sec: 11.58718568649666
collect_time: 0.9493245640154928
reward_mean: 2285.2135417758604
reward_std: 829.8473565014767
reward_max: 3546.2564514335877
reward_min: 991.4560052131134
total_envstep_count: 13945186
total_train_sample_count: 10486672
total_episode_count: 32502
total_duration: 2849.639715923244
[2023-06-29 12:33:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1225
train_sample_count: 1225
avg_envstep_per_episode: 306.25
avg_sample_per_episode: 306.25
avg_envstep_per_sec: 2310.1543442417496
avg_train_sample_per_sec: 2310.1543442417496
avg_episode_per_sec: 7.543361124054693
collect_time: 0.530267600107938
reward_mean: 2709.881820440294
reward_std: 702.6393293601939
reward_max: 3503.4433753784538
reward_min: 1576.4274641132088
total_envstep_count: 13949386
total_train_sample_count: 10489897
total_episode_count: 32506
total_duration: 2850.1699835233517
[2023-06-29 12:33:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2157
train_sample_count: 2157
avg_envstep_per_episode: 269.625
avg_sample_per_episode: 269.625
avg_envstep_per_sec: 2778.2076177829044
avg_train_sample_per_sec: 2778.2076177829044
avg_episode_per_sec: 10.303968911573126
collect_time: 0.7763998580211773
reward_mean: 2875.708280671972
reward_std: 865.0489810602485
reward_max: 3595.601211686837
reward_min: 1438.8608376593759
total_envstep_count: 13954186
total_train_sample_count: 10493254
total_episode_count: 32514
total_duration: 2850.946383381373
[2023-06-29 12:33:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2153
train_sample_count: 2153
avg_envstep_per_episode: 239.22222222222223
avg_sample_per_episode: 239.22222222222223
avg_envstep_per_sec: 2799.7538900351083
avg_train_sample_per_sec: 2799.7538900351083
avg_episode_per_sec: 11.70356944278494
collect_time: 0.7689961634352803
reward_mean: 1907.0293733271537
reward_std: 599.7735461007422
reward_max: 2973.4030215071157
reward_min: 1302.4944228170805
total_envstep_count: 13958410
total_train_sample_count: 10496607
total_episode_count: 32523
total_duration: 2851.715379544808
[2023-06-29 12:33:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2898
train_sample_count: 2898
avg_envstep_per_episode: 322.0
avg_sample_per_episode: 322.0
avg_envstep_per_sec: 2806.0056727527
avg_train_sample_per_sec: 2806.0056727527
avg_episode_per_sec: 8.714303331530123
collect_time: 1.0327847973154856
reward_mean: 2158.5823240338186
reward_std: 759.2068117807577
reward_max: 3621.130997930862
reward_min: 1199.1688299749235
total_envstep_count: 13963026
total_train_sample_count: 10499905
total_episode_count: 32532
total_duration: 2852.7481643421233
[2023-06-29 12:33:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1736
train_sample_count: 1736
avg_envstep_per_episode: 347.2
avg_sample_per_episode: 347.2
avg_envstep_per_sec: 2695.423383778907
avg_train_sample_per_sec: 2695.423383778907
avg_episode_per_sec: 7.7633161975198925
collect_time: 0.6440546633405612
reward_mean: 2227.0675922575533
reward_std: 434.8737816741612
reward_max: 2836.091635272426
reward_min: 1740.497960616628
total_envstep_count: 13968322
total_train_sample_count: 10503241
total_episode_count: 32537
total_duration: 2853.392219005464
[2023-06-29 12:33:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2765
train_sample_count: 2765
avg_envstep_per_episode: 230.41666666666666
avg_sample_per_episode: 230.41666666666666
avg_envstep_per_sec: 2747.378426383823
avg_train_sample_per_sec: 2747.378426383823
avg_episode_per_sec: 11.92352300781406
collect_time: 1.0064139593755823
reward_mean: 2055.5875619637873
reward_std: 1060.836472256331
reward_max: 3647.2817909987893
reward_min: 961.1928241907905
total_envstep_count: 13973146
total_train_sample_count: 10506806
total_episode_count: 32549
total_duration: 2854.3986329648396
[2023-06-29 12:33:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 295.14285714285717
avg_sample_per_episode: 295.14285714285717
avg_envstep_per_sec: 2728.169355986409
avg_train_sample_per_sec: 2728.169355986409
avg_episode_per_sec: 9.243555417185314
collect_time: 0.7572843656009061
reward_mean: 2057.191333014112
reward_std: 496.76186179800277
reward_max: 2778.8104988971004
reward_min: 1241.7819806849002
total_envstep_count: 13977482
total_train_sample_count: 10510072
total_episode_count: 32556
total_duration: 2855.1559173304404
[2023-06-29 12:33:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2940
train_sample_count: 2940
avg_envstep_per_episode: 326.6666666666667
avg_sample_per_episode: 326.6666666666667
avg_envstep_per_sec: 2773.3906953279497
avg_train_sample_per_sec: 2773.3906953279497
avg_episode_per_sec: 8.48997151631005
collect_time: 1.0600742278946562
reward_mean: 2243.774680005931
reward_std: 646.7315647655391
reward_max: 3573.712081909079
reward_min: 1127.2686294575565
total_envstep_count: 13981458
total_train_sample_count: 10513412
total_episode_count: 32565
total_duration: 2856.215991558335
[2023-06-29 12:33:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2046
train_sample_count: 2046
avg_envstep_per_episode: 341.0
avg_sample_per_episode: 341.0
avg_envstep_per_sec: 2661.4532817379054
avg_train_sample_per_sec: 2661.4532817379054
avg_episode_per_sec: 7.804848333542244
collect_time: 0.7687529268460351
reward_mean: 1872.0344412161132
reward_std: 413.08040315643484
reward_max: 2295.0027486913905
reward_min: 1289.504144960482
total_envstep_count: 13986130
total_train_sample_count: 10516658
total_episode_count: 32571
total_duration: 2856.984744485181
[2023-06-29 12:34:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2870
train_sample_count: 2870
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2571.6163413748604
avg_train_sample_per_sec: 2571.6163413748604
avg_episode_per_sec: 8.960335684232964
collect_time: 1.1160296167917547
reward_mean: 1966.5178112361675
reward_std: 457.33183775530676
reward_max: 2578.101541014141
reward_min: 1315.2072458725384
total_envstep_count: 13990650
total_train_sample_count: 10519928
total_episode_count: 32581
total_duration: 2858.100774101973
[2023-06-29 12:34:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1287
train_sample_count: 1287
avg_envstep_per_episode: 183.85714285714286
avg_sample_per_episode: 183.85714285714286
avg_envstep_per_sec: 2800.2390635271427
avg_train_sample_per_sec: 2800.2390635271427
avg_episode_per_sec: 15.230515497039626
collect_time: 0.4596036162637173
reward_mean: 1612.470602089659
reward_std: 663.1091165562478
reward_max: 3177.9820402645078
reward_min: 1151.8725260288022
total_envstep_count: 13994834
total_train_sample_count: 10523215
total_episode_count: 32588
total_duration: 2858.560377718237
[2023-06-29 12:34:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1249
train_sample_count: 1249
avg_envstep_per_episode: 178.42857142857142
avg_sample_per_episode: 178.42857142857142
avg_envstep_per_sec: 2763.975240517301
avg_train_sample_per_sec: 2763.975240517301
avg_episode_per_sec: 15.49065386999288
collect_time: 0.45188537932280437
reward_mean: 2020.3631475025109
reward_std: 274.5912370255467
reward_max: 2491.2552667065233
reward_min: 1700.71179149794
total_envstep_count: 13998802
total_train_sample_count: 10526464
total_episode_count: 32595
total_duration: 2859.0122630975598
[2023-06-29 12:34:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 153.625
avg_sample_per_episode: 153.625
avg_envstep_per_sec: 2391.868192203424
avg_train_sample_per_sec: 2391.868192203424
avg_episode_per_sec: 15.56952444070577
collect_time: 0.51382430018764
reward_mean: 2058.9415031285057
reward_std: 875.4240123816371
reward_max: 3649.114061208334
reward_min: 1410.978022398202
total_envstep_count: 14002298
total_train_sample_count: 10529693
total_episode_count: 32603
total_duration: 2859.5260873977472
[2023-06-29 12:34:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2809
train_sample_count: 2809
avg_envstep_per_episode: 255.36363636363637
avg_sample_per_episode: 255.36363636363637
avg_envstep_per_sec: 2584.681522377247
avg_train_sample_per_sec: 2584.681522377247
avg_episode_per_sec: 10.121572355339877
collect_time: 1.086787666364573
reward_mean: 1731.466075651103
reward_std: 631.2325750670794
reward_max: 3299.107677240547
reward_min: 1175.8881529418647
total_envstep_count: 14006258
total_train_sample_count: 10532902
total_episode_count: 32614
total_duration: 2860.612875064112
[2023-06-29 12:34:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2600
train_sample_count: 2600
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 2756.721081463647
avg_train_sample_per_sec: 2756.721081463647
avg_episode_per_sec: 10.602773390244796
collect_time: 0.9431494602346793
reward_mean: 1415.8142771879996
reward_std: 291.47403770422
reward_max: 2002.1900045491084
reward_min: 1018.074990445081
total_envstep_count: 14010874
total_train_sample_count: 10536302
total_episode_count: 32624
total_duration: 2861.5560245243464
[2023-06-29 12:34:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2041
train_sample_count: 2041
avg_envstep_per_episode: 255.125
avg_sample_per_episode: 255.125
avg_envstep_per_sec: 2587.765915751268
avg_train_sample_per_sec: 2587.765915751268
avg_episode_per_sec: 10.143129508089242
collect_time: 0.7887112151747568
reward_mean: 1886.8169357190236
reward_std: 480.22042765352046
reward_max: 2679.4633826545733
reward_min: 962.8112560091068
total_envstep_count: 14015162
total_train_sample_count: 10539543
total_episode_count: 32632
total_duration: 2862.344735739521
[2023-06-29 12:34:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 323.0
avg_sample_per_episode: 323.0
avg_envstep_per_sec: 2605.5607987594212
avg_train_sample_per_sec: 2605.5607987594212
avg_episode_per_sec: 8.066751698945577
collect_time: 1.2396563540324568
reward_mean: 2034.8654893345883
reward_std: 821.9471705988776
reward_max: 3324.0183835663297
reward_min: 900.9017217441697
total_envstep_count: 14019466
total_train_sample_count: 10542773
total_episode_count: 32642
total_duration: 2863.5843920935536
[2023-06-29 12:34:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 306.5
avg_sample_per_episode: 306.5
avg_envstep_per_sec: 2771.9655019699007
avg_train_sample_per_sec: 2771.9655019699007
avg_episode_per_sec: 9.0439331222509
collect_time: 0.8845708932010456
reward_mean: 1620.273219168887
reward_std: 450.4032931332516
reward_max: 2380.7656680787745
reward_min: 963.7198358118071
total_envstep_count: 14024074
total_train_sample_count: 10546025
total_episode_count: 32650
total_duration: 2864.468962986755
[2023-06-29 12:34:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1614
train_sample_count: 1614
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2745.432227502848
avg_train_sample_per_sec: 2745.432227502848
avg_episode_per_sec: 10.206067760233637
collect_time: 0.587885573656298
reward_mean: 2061.033363553639
reward_std: 554.5336675670035
reward_max: 2632.9584553168256
reward_min: 1289.6178095977396
total_envstep_count: 14027802
total_train_sample_count: 10549239
total_episode_count: 32656
total_duration: 2865.0568485604113
[2023-06-29 12:34:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 370.375
avg_sample_per_episode: 370.375
avg_envstep_per_sec: 2638.8390250700327
avg_train_sample_per_sec: 2638.8390250700327
avg_episode_per_sec: 7.124776307985239
collect_time: 1.1228422695929186
reward_mean: 2594.9281703500587
reward_std: 876.9431452140961
reward_max: 3742.7964111865335
reward_min: 1397.4586422448456
total_envstep_count: 14032258
total_train_sample_count: 10552602
total_episode_count: 32664
total_duration: 2866.1796908300043
[2023-06-29 12:34:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 268.5
avg_sample_per_episode: 268.5
avg_envstep_per_sec: 2802.537080093248
avg_train_sample_per_sec: 2802.537080093248
avg_episode_per_sec: 10.437754488243009
collect_time: 0.9580604728022591
reward_mean: 1515.3707984640027
reward_std: 499.07849675049704
reward_max: 2346.1556246107757
reward_min: 947.1910183052535
total_envstep_count: 14037234
total_train_sample_count: 10556087
total_episode_count: 32674
total_duration: 2867.1377513028065
[2023-06-29 12:34:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3570
train_sample_count: 3570
avg_envstep_per_episode: 274.61538461538464
avg_sample_per_episode: 274.61538461538464
avg_envstep_per_sec: 2732.8134808864893
avg_train_sample_per_sec: 2732.8134808864893
avg_episode_per_sec: 9.951421639082454
collect_time: 1.306346014819108
reward_mean: 1710.1694099080019
reward_std: 896.6905241711779
reward_max: 3308.9386090941234
reward_min: 532.6614486065769
total_envstep_count: 14042506
total_train_sample_count: 10559657
total_episode_count: 32687
total_duration: 2868.4440973176256
[2023-06-29 12:34:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 253.75
avg_sample_per_episode: 253.75
avg_envstep_per_sec: 2746.4320709821573
avg_train_sample_per_sec: 2746.4320709821573
avg_episode_per_sec: 10.823377619634117
collect_time: 0.7391408006949349
reward_mean: 1719.7542730702107
reward_std: 488.8470601004533
reward_max: 2840.6473363769883
reward_min: 1240.634818160844
total_envstep_count: 14046738
total_train_sample_count: 10562887
total_episode_count: 32695
total_duration: 2869.1832381183203
[2023-06-29 12:34:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 269.1666666666667
avg_sample_per_episode: 269.1666666666667
avg_envstep_per_sec: 2592.5768388782053
avg_train_sample_per_sec: 2592.5768388782053
avg_episode_per_sec: 9.631864416884973
collect_time: 1.2458647132702168
reward_mean: 1692.8935217528972
reward_std: 754.5417088735105
reward_max: 3599.8996053894857
reward_min: 564.4404749605783
total_envstep_count: 14050834
total_train_sample_count: 10566117
total_episode_count: 32707
total_duration: 2870.4291028315906
[2023-06-29 12:34:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3087
train_sample_count: 3087
avg_envstep_per_episode: 257.25
avg_sample_per_episode: 257.25
avg_envstep_per_sec: 2584.384031449632
avg_train_sample_per_sec: 2584.384031449632
avg_episode_per_sec: 10.04619642934745
collect_time: 1.1944819200374184
reward_mean: 1226.7264021470903
reward_std: 137.7335295443264
reward_max: 1513.2591011918814
reward_min: 1044.6686176853045
total_envstep_count: 14055666
total_train_sample_count: 10569604
total_episode_count: 32719
total_duration: 2871.623584751628
[2023-06-29 12:34:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3327
train_sample_count: 3327
avg_envstep_per_episode: 237.64285714285714
avg_sample_per_episode: 237.64285714285714
avg_envstep_per_sec: 2750.1144308778375
avg_train_sample_per_sec: 2750.1144308778375
avg_episode_per_sec: 11.572468299455885
collect_time: 1.2097678418923172
reward_mean: 1304.1993726951682
reward_std: 740.9726352699787
reward_max: 3599.2106997563897
reward_min: 564.3731207463422
total_envstep_count: 14060610
total_train_sample_count: 10572931
total_episode_count: 32733
total_duration: 2872.8333525935204
[2023-06-29 12:34:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 225.0909090909091
avg_sample_per_episode: 225.0909090909091
avg_envstep_per_sec: 2784.720800041101
avg_train_sample_per_sec: 2784.720800041101
avg_episode_per_sec: 12.371538287743178
collect_time: 0.8891376111973077
reward_mean: 1385.5554497036378
reward_std: 405.76959441242025
reward_max: 1939.2443331339236
reward_min: 567.1272480453954
total_envstep_count: 14065098
total_train_sample_count: 10576207
total_episode_count: 32744
total_duration: 2873.722490204718
[2023-06-29 12:34:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2163
train_sample_count: 2163
avg_envstep_per_episode: 216.3
avg_sample_per_episode: 216.3
avg_envstep_per_sec: 2573.795588164544
avg_train_sample_per_sec: 2573.795588164544
avg_episode_per_sec: 11.89919365771865
collect_time: 0.8403930793674662
reward_mean: 1563.5241148185762
reward_std: 387.21308320479216
reward_max: 2125.284114813146
reward_min: 1082.1555705980695
total_envstep_count: 14069314
total_train_sample_count: 10579570
total_episode_count: 32754
total_duration: 2874.5628832840853
[2023-06-29 12:34:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1906
train_sample_count: 1906
avg_envstep_per_episode: 211.77777777777777
avg_sample_per_episode: 211.77777777777777
avg_envstep_per_sec: 2494.029724715913
avg_train_sample_per_sec: 2494.029724715913
avg_episode_per_sec: 11.77663563611921
collect_time: 0.7642250535795465
reward_mean: 1532.7351586489638
reward_std: 397.06471952404956
reward_max: 2238.94355085642
reward_min: 988.144572390011
total_envstep_count: 14073602
total_train_sample_count: 10583076
total_episode_count: 32763
total_duration: 2875.327108337665
[2023-06-29 12:35:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 237.41666666666666
avg_sample_per_episode: 237.41666666666666
avg_envstep_per_sec: 2744.1170474101104
avg_train_sample_per_sec: 2744.1170474101104
avg_episode_per_sec: 11.558232561923948
collect_time: 1.0382210200140252
reward_mean: 1598.0475099628768
reward_std: 744.4733299181846
reward_max: 3595.177441356184
reward_min: 548.5945824419025
total_envstep_count: 14077914
total_train_sample_count: 10586325
total_episode_count: 32775
total_duration: 2876.365329357679
[2023-06-29 12:35:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2188
train_sample_count: 2188
avg_envstep_per_episode: 243.11111111111111
avg_sample_per_episode: 243.11111111111111
avg_envstep_per_sec: 2782.1305050502783
avg_train_sample_per_sec: 2782.1305050502783
avg_episode_per_sec: 11.44386405185215
collect_time: 0.7864476508302614
reward_mean: 1571.3897221497177
reward_std: 751.2020691897754
reward_max: 3626.955633649618
reward_min: 1015.8251887804589
total_envstep_count: 14082762
total_train_sample_count: 10589713
total_episode_count: 32784
total_duration: 2877.1517770085093
[2023-06-29 12:35:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2104
train_sample_count: 2104
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2778.1614562015416
avg_train_sample_per_sec: 2778.1614562015416
avg_episode_per_sec: 10.563351544492553
collect_time: 0.7573353936299682
reward_mean: 2021.2820798585915
reward_std: 938.7476737342411
reward_max: 3644.1472964461323
reward_min: 1178.7254926058085
total_envstep_count: 14086834
total_train_sample_count: 10593017
total_episode_count: 32792
total_duration: 2877.9091124021393
[2023-06-29 12:35:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3412
train_sample_count: 3412
avg_envstep_per_episode: 262.46153846153845
avg_sample_per_episode: 262.46153846153845
avg_envstep_per_sec: 2580.6260053377828
avg_train_sample_per_sec: 2580.6260053377828
avg_episode_per_sec: 9.832396855038445
collect_time: 1.322159814301878
reward_mean: 1624.6154228862506
reward_std: 893.1319412710297
reward_max: 3587.494135289361
reward_min: 538.5078044591193
total_envstep_count: 14091402
total_train_sample_count: 10596429
total_episode_count: 32805
total_duration: 2879.231272216441
[2023-06-29 12:35:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2544
train_sample_count: 2544
avg_envstep_per_episode: 282.6666666666667
avg_sample_per_episode: 282.6666666666667
avg_envstep_per_sec: 2703.8117284724863
avg_train_sample_per_sec: 2703.8117284724863
avg_episode_per_sec: 9.565371680916815
collect_time: 0.9408939140290025
reward_mean: 1531.582842292838
reward_std: 347.0772322615276
reward_max: 2218.979790405429
reward_min: 1081.323582974883
total_envstep_count: 14095858
total_train_sample_count: 10599773
total_episode_count: 32814
total_duration: 2880.17216613047
[2023-06-29 12:35:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2921
train_sample_count: 2921
avg_envstep_per_episode: 243.41666666666666
avg_sample_per_episode: 243.41666666666666
avg_envstep_per_sec: 2752.4818601155926
avg_train_sample_per_sec: 2752.4818601155926
avg_episode_per_sec: 11.307696789245846
collect_time: 1.06122406920325
reward_mean: 1483.634250214144
reward_std: 359.10148936767615
reward_max: 2129.3573322832644
reward_min: 936.9111432183008
total_envstep_count: 14100562
total_train_sample_count: 10603094
total_episode_count: 32826
total_duration: 2881.233390199673
[2023-06-29 12:35:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2811
train_sample_count: 2811
avg_envstep_per_episode: 255.54545454545453
avg_sample_per_episode: 255.54545454545453
avg_envstep_per_sec: 2518.0640514449665
avg_train_sample_per_sec: 2518.0640514449665
avg_episode_per_sec: 9.853683588009474
collect_time: 1.1163337955549364
reward_mean: 1545.0132087221523
reward_std: 689.9045831191319
reward_max: 3490.344557295362
reward_min: 803.1711351757945
total_envstep_count: 14104866
total_train_sample_count: 10606305
total_episode_count: 32837
total_duration: 2882.349723995228
[2023-06-29 12:35:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2618
train_sample_count: 2618
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 2517.1782070954523
avg_train_sample_per_sec: 2517.1782070954523
avg_episode_per_sec: 10.576379021409464
collect_time: 1.0400534982467073
reward_mean: 1314.226345801924
reward_std: 645.3200675431963
reward_max: 3172.2776962471407
reward_min: 885.705156501954
total_envstep_count: 14109410
total_train_sample_count: 10609723
total_episode_count: 32848
total_duration: 2883.389777493475
[2023-06-29 12:35:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2869
train_sample_count: 2869
avg_envstep_per_episode: 239.08333333333334
avg_sample_per_episode: 239.08333333333334
avg_envstep_per_sec: 2625.839880673568
avg_train_sample_per_sec: 2625.839880673568
avg_episode_per_sec: 10.982948263535315
collect_time: 1.0926027977243067
reward_mean: 1483.4513623235905
reward_std: 788.1443244200066
reward_max: 3611.267350205345
reward_min: 873.6039006910615
total_envstep_count: 14113306
total_train_sample_count: 10612992
total_episode_count: 32860
total_duration: 2884.482380291199
[2023-06-29 12:35:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2048
train_sample_count: 2048
avg_envstep_per_episode: 256.0
avg_sample_per_episode: 256.0
avg_envstep_per_sec: 2740.1360022299523
avg_train_sample_per_sec: 2740.1360022299523
avg_episode_per_sec: 10.703656258710751
collect_time: 0.7474081572350115
reward_mean: 1390.9437408877964
reward_std: 375.5255311285554
reward_max: 2293.7659381385815
reward_min: 1004.3590448688279
total_envstep_count: 14117874
total_train_sample_count: 10616240
total_episode_count: 32868
total_duration: 2885.229788448434
[2023-06-29 12:35:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2881
train_sample_count: 2881
avg_envstep_per_episode: 240.08333333333334
avg_sample_per_episode: 240.08333333333334
avg_envstep_per_sec: 2722.136487286251
avg_train_sample_per_sec: 2722.136487286251
avg_episode_per_sec: 11.338298454507118
collect_time: 1.05835986309126
reward_mean: 1562.016205531684
reward_std: 710.6688535627874
reward_max: 2675.939717975265
reward_min: 430.3833874041562
total_envstep_count: 14122802
total_train_sample_count: 10619521
total_episode_count: 32880
total_duration: 2886.2881483115257
[2023-06-29 12:35:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2996
train_sample_count: 2996
avg_envstep_per_episode: 299.6
avg_sample_per_episode: 299.6
avg_envstep_per_sec: 2565.5694224513168
avg_train_sample_per_sec: 2565.5694224513168
avg_episode_per_sec: 8.563315829276759
collect_time: 1.1677719471482557
reward_mean: 1963.723273720782
reward_std: 848.0903610960795
reward_max: 3675.8031383813154
reward_min: 969.6590897466568
total_envstep_count: 14128314
total_train_sample_count: 10622917
total_episode_count: 32890
total_duration: 2887.455920258674
[2023-06-29 12:35:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 228.30769230769232
avg_sample_per_episode: 228.30769230769232
avg_envstep_per_sec: 2609.396434686582
avg_train_sample_per_sec: 2609.396434686582
avg_episode_per_sec: 11.42929705219864
collect_time: 1.1374277823586014
reward_mean: 1463.2288544062746
reward_std: 549.089912674883
reward_max: 2807.9663955633887
reward_min: 863.3316742706396
total_envstep_count: 14132682
total_train_sample_count: 10626285
total_episode_count: 32903
total_duration: 2888.5933480410326
[2023-06-29 12:35:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2078
train_sample_count: 2078
avg_envstep_per_episode: 259.75
avg_sample_per_episode: 259.75
avg_envstep_per_sec: 2740.343585751954
avg_train_sample_per_sec: 2740.343585751954
avg_episode_per_sec: 10.549927182875665
collect_time: 0.758299072716385
reward_mean: 1742.1246664341597
reward_std: 835.2395950458191
reward_max: 3395.4236231795444
reward_min: 993.8167583738721
total_envstep_count: 14136994
total_train_sample_count: 10629563
total_episode_count: 32911
total_duration: 2889.351647113749
[2023-06-29 12:35:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3067
train_sample_count: 3067
avg_envstep_per_episode: 278.8181818181818
avg_sample_per_episode: 278.8181818181818
avg_envstep_per_sec: 2786.825304053058
avg_train_sample_per_sec: 2786.825304053058
avg_episode_per_sec: 9.995134771628184
collect_time: 1.100535435622558
reward_mean: 1770.4043318980528
reward_std: 578.930351294559
reward_max: 2640.5097791011613
reward_min: 1007.8050181228999
total_envstep_count: 14141818
total_train_sample_count: 10633030
total_episode_count: 32922
total_duration: 2890.4521825493716
[2023-06-29 12:35:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2086
train_sample_count: 2086
avg_envstep_per_episode: 260.75
avg_sample_per_episode: 260.75
avg_envstep_per_sec: 2640.4413546043475
avg_train_sample_per_sec: 2640.4413546043475
avg_episode_per_sec: 10.126333095318687
collect_time: 0.7900194398798049
reward_mean: 1618.4414520910482
reward_std: 500.7949597156488
reward_max: 2255.5040456766474
reward_min: 992.2339411073879
total_envstep_count: 14146002
total_train_sample_count: 10636316
total_episode_count: 32930
total_duration: 2891.2422019892515
[2023-06-29 12:35:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1589
train_sample_count: 1589
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 2704.2938021981663
avg_train_sample_per_sec: 2704.2938021981663
avg_episode_per_sec: 11.91318855593906
collect_time: 0.5875840852456166
reward_mean: 2037.5778797085857
reward_std: 976.623984142035
reward_max: 3589.5488323271584
reward_min: 1067.7998324279115
total_envstep_count: 14150234
total_train_sample_count: 10639905
total_episode_count: 32937
total_duration: 2891.829786074497
[2023-06-29 12:35:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 266.875
avg_sample_per_episode: 266.875
avg_envstep_per_sec: 2759.9227623836427
avg_train_sample_per_sec: 2759.9227623836427
avg_episode_per_sec: 10.341630959751356
collect_time: 0.7735723727848383
reward_mean: 2227.445621566454
reward_std: 796.8598839659757
reward_max: 3025.6568745245336
reward_min: 832.2478273218617
total_envstep_count: 14154962
total_train_sample_count: 10643240
total_episode_count: 32945
total_duration: 2892.6033584472816
[2023-06-29 12:35:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2429
train_sample_count: 2429
avg_envstep_per_episode: 220.8181818181818
avg_sample_per_episode: 220.8181818181818
avg_envstep_per_sec: 2712.215527279523
avg_train_sample_per_sec: 2712.215527279523
avg_episode_per_sec: 12.282573404724065
collect_time: 0.8955777944521978
reward_mean: 1581.9769502427314
reward_std: 539.1306574661666
reward_max: 2473.462991168432
reward_min: 798.9269565977821
total_envstep_count: 14159698
total_train_sample_count: 10646469
total_episode_count: 32956
total_duration: 2893.4989362417336
[2023-06-29 12:35:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3246
train_sample_count: 3246
avg_envstep_per_episode: 249.69230769230768
avg_sample_per_episode: 249.69230769230768
avg_envstep_per_sec: 2608.512013427186
avg_train_sample_per_sec: 2608.512013427186
avg_episode_per_sec: 10.44690578390432
collect_time: 1.2443875984819606
reward_mean: 1667.857812911066
reward_std: 893.9523426169739
reward_max: 3684.6666455618597
reward_min: 815.7151392513975
total_envstep_count: 14164066
total_train_sample_count: 10649715
total_episode_count: 32969
total_duration: 2894.7433238402155
[2023-06-29 12:36:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2297
train_sample_count: 2297
avg_envstep_per_episode: 255.22222222222223
avg_sample_per_episode: 255.22222222222223
avg_envstep_per_sec: 2703.6294737616017
avg_train_sample_per_sec: 2703.6294737616017
avg_episode_per_sec: 10.593236945517813
collect_time: 0.8495986681208014
reward_mean: 1259.6904683569535
reward_std: 355.1625170395978
reward_max: 1983.6902236751882
reward_min: 876.4601535212103
total_envstep_count: 14168842
total_train_sample_count: 10653212
total_episode_count: 32978
total_duration: 2895.5929225083364
[2023-06-29 12:36:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2995
train_sample_count: 2995
avg_envstep_per_episode: 230.3846153846154
avg_sample_per_episode: 230.3846153846154
avg_envstep_per_sec: 2795.747201197138
avg_train_sample_per_sec: 2795.747201197138
avg_episode_per_sec: 12.135129754778898
collect_time: 1.0712699627196414
reward_mean: 1610.2266039498247
reward_std: 808.8906804211997
reward_max: 3609.0488311753306
reward_min: 899.738469553058
total_envstep_count: 14173826
total_train_sample_count: 10656607
total_episode_count: 32991
total_duration: 2896.664192471056
[2023-06-29 12:36:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2903
train_sample_count: 2903
avg_envstep_per_episode: 207.35714285714286
avg_sample_per_episode: 207.35714285714286
avg_envstep_per_sec: 2732.8159144576275
avg_train_sample_per_sec: 2732.8159144576275
avg_episode_per_sec: 13.179270686326829
collect_time: 1.0622742588119582
reward_mean: 1246.8757655234754
reward_std: 528.1150396120858
reward_max: 2294.422563689566
reward_min: 555.6202974579337
total_envstep_count: 14178274
total_train_sample_count: 10659910
total_episode_count: 33005
total_duration: 2897.726466729868
[2023-06-29 12:36:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2664
train_sample_count: 2664
avg_envstep_per_episode: 242.1818181818182
avg_sample_per_episode: 242.1818181818182
avg_envstep_per_sec: 2555.1978973528367
avg_train_sample_per_sec: 2555.1978973528367
avg_episode_per_sec: 10.5507420686491
collect_time: 1.0425806951234116
reward_mean: 1355.8722163865423
reward_std: 371.986766261613
reward_max: 2017.9332414878845
reward_min: 921.6985151553354
total_envstep_count: 14182850
total_train_sample_count: 10663374
total_episode_count: 33016
total_duration: 2898.7690474249916
[2023-06-29 12:36:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3435
train_sample_count: 3435
avg_envstep_per_episode: 245.35714285714286
avg_sample_per_episode: 245.35714285714286
avg_envstep_per_sec: 2637.8701898509817
avg_train_sample_per_sec: 2637.8701898509817
avg_episode_per_sec: 10.75114487857751
collect_time: 1.302186898057349
reward_mean: 1424.9146676837245
reward_std: 735.4725235319721
reward_max: 2868.657013271978
reward_min: 751.4658064448117
total_envstep_count: 14187450
total_train_sample_count: 10666809
total_episode_count: 33030
total_duration: 2900.071234323049
[2023-06-29 12:36:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3081
train_sample_count: 3081
avg_envstep_per_episode: 256.75
avg_sample_per_episode: 256.75
avg_envstep_per_sec: 2543.121253334814
avg_train_sample_per_sec: 2543.121253334814
avg_episode_per_sec: 9.905048698480288
collect_time: 1.211503382294439
reward_mean: 1289.5896928285772
reward_std: 389.85835179787745
reward_max: 2213.7471255750374
reward_min: 911.8014321254562
total_envstep_count: 14192050
total_train_sample_count: 10670290
total_episode_count: 33042
total_duration: 2901.282737705343
[2023-06-29 12:36:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 351.0
avg_sample_per_episode: 351.0
avg_envstep_per_sec: 2797.546705970078
avg_train_sample_per_sec: 2797.546705970078
avg_episode_per_sec: 7.970218535527288
collect_time: 0.8782695190599186
reward_mean: 1881.1554058390304
reward_std: 720.1796282660366
reward_max: 3323.5532459041037
reward_min: 1176.7033284295994
total_envstep_count: 14196314
total_train_sample_count: 10673547
total_episode_count: 33049
total_duration: 2902.161007224403
[2023-06-29 12:36:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 241.25
avg_sample_per_episode: 241.25
avg_envstep_per_sec: 2633.9918852398914
avg_train_sample_per_sec: 2633.9918852398914
avg_episode_per_sec: 10.918101078714576
collect_time: 1.0990922243241221
reward_mean: 1578.9374546993859
reward_std: 810.8364135155952
reward_max: 3405.151635383268
reward_min: 489.7232375193049
total_envstep_count: 14200866
total_train_sample_count: 10676842
total_episode_count: 33061
total_duration: 2903.260099448727
[2023-06-29 12:36:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2152
train_sample_count: 2152
avg_envstep_per_episode: 239.11111111111111
avg_sample_per_episode: 239.11111111111111
avg_envstep_per_sec: 2545.752209097617
avg_train_sample_per_sec: 2545.752209097617
avg_episode_per_sec: 10.646733216486316
collect_time: 0.8453297191727907
reward_mean: 1516.1840675703731
reward_std: 478.9507021444143
reward_max: 2502.610297649908
reward_min: 1032.1887351670846
total_envstep_count: 14204858
total_train_sample_count: 10680194
total_episode_count: 33070
total_duration: 2904.1054291678997
[2023-06-29 12:36:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2935
train_sample_count: 2935
avg_envstep_per_episode: 266.8181818181818
avg_sample_per_episode: 266.8181818181818
avg_envstep_per_sec: 2689.8754259164566
avg_train_sample_per_sec: 2689.8754259164566
avg_episode_per_sec: 10.08130483307701
collect_time: 1.091128597154282
reward_mean: 1640.1149521797897
reward_std: 806.1594898335987
reward_max: 3668.8681840358677
reward_min: 644.5935903882331
total_envstep_count: 14209546
total_train_sample_count: 10683529
total_episode_count: 33081
total_duration: 2905.196557765054
[2023-06-29 12:36:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 253.375
avg_sample_per_episode: 253.375
avg_envstep_per_sec: 2779.236313164624
avg_train_sample_per_sec: 2779.236313164624
avg_episode_per_sec: 10.968865567497282
collect_time: 0.7293370449999348
reward_mean: 1676.4309603321103
reward_std: 458.7658306777194
reward_max: 2271.000609249958
reward_min: 941.6300373188419
total_envstep_count: 14213506
total_train_sample_count: 10686756
total_episode_count: 33089
total_duration: 2905.9258948100537
[2023-06-29 12:36:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1983
train_sample_count: 1983
avg_envstep_per_episode: 220.33333333333334
avg_sample_per_episode: 220.33333333333334
avg_envstep_per_sec: 2761.647373086186
avg_train_sample_per_sec: 2761.647373086186
avg_episode_per_sec: 12.533951768923686
collect_time: 0.7180496754674242
reward_mean: 1669.8908048925673
reward_std: 645.3376341511814
reward_max: 3127.5922046932874
reward_min: 654.7773932789739
total_envstep_count: 14218010
total_train_sample_count: 10690339
total_episode_count: 33098
total_duration: 2906.643944485521
[2023-06-29 12:36:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2882
train_sample_count: 2882
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 2610.1570103092713
avg_train_sample_per_sec: 2610.1570103092713
avg_episode_per_sec: 9.962431337058288
collect_time: 1.1041481369193644
reward_mean: 1866.6665536181638
reward_std: 844.8189339473296
reward_max: 3718.8373029252866
reward_min: 574.55460089758
total_envstep_count: 14222802
total_train_sample_count: 10693621
total_episode_count: 33109
total_duration: 2907.7480926224403
[2023-06-29 12:36:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2873
train_sample_count: 2873
avg_envstep_per_episode: 221.0
avg_sample_per_episode: 221.0
avg_envstep_per_sec: 2556.1794681650454
avg_train_sample_per_sec: 2556.1794681650454
avg_episode_per_sec: 11.56642293287351
collect_time: 1.123942992180586
reward_mean: 1333.0148807792614
reward_std: 694.0238495559307
reward_max: 3370.465513622813
reward_min: 445.1474943661117
total_envstep_count: 14227314
total_train_sample_count: 10696894
total_episode_count: 33122
total_duration: 2908.872035614621
[2023-06-29 12:36:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1670
train_sample_count: 1670
avg_envstep_per_episode: 238.57142857142858
avg_sample_per_episode: 238.57142857142858
avg_envstep_per_sec: 2463.2037143041916
avg_train_sample_per_sec: 2463.2037143041916
avg_episode_per_sec: 10.324805988101403
collect_time: 0.677978841255419
reward_mean: 1596.4815218193976
reward_std: 849.1575673652658
reward_max: 3576.959297250527
reward_min: 927.4398055268881
total_envstep_count: 14231490
total_train_sample_count: 10700164
total_episode_count: 33129
total_duration: 2909.5500144558764
[2023-06-29 12:36:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2213
train_sample_count: 2213
avg_envstep_per_episode: 221.3
avg_sample_per_episode: 221.3
avg_envstep_per_sec: 2748.773345251892
avg_train_sample_per_sec: 2748.773345251892
avg_episode_per_sec: 12.421027316999059
collect_time: 0.8050863865595311
reward_mean: 1776.6236166878764
reward_std: 696.3919833489148
reward_max: 3243.63403781859
reward_min: 963.1549246712875
total_envstep_count: 14235914
total_train_sample_count: 10703577
total_episode_count: 33139
total_duration: 2910.355100842436
[2023-06-29 12:36:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 246.9
avg_sample_per_episode: 246.9
avg_envstep_per_sec: 2764.7588779317603
avg_train_sample_per_sec: 2764.7588779317603
avg_episode_per_sec: 11.197889339537305
collect_time: 0.8930254351319745
reward_mean: 1826.4014780749178
reward_std: 824.1307827535029
reward_max: 3741.7364788241152
reward_min: 1015.3330081570991
total_envstep_count: 14240378
total_train_sample_count: 10706846
total_episode_count: 33149
total_duration: 2911.248126277568
[2023-06-29 12:36:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2630
train_sample_count: 2630
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2612.4214279628795
avg_train_sample_per_sec: 2612.4214279628795
avg_episode_per_sec: 9.933161323052774
collect_time: 1.0067288423869758
reward_mean: 1714.963812305233
reward_std: 495.557614553164
reward_max: 2530.4616883886615
reward_min: 1002.9406918968284
total_envstep_count: 14245058
total_train_sample_count: 10710276
total_episode_count: 33159
total_duration: 2912.254855119955
[2023-06-29 12:36:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1700
train_sample_count: 1700
avg_envstep_per_episode: 242.85714285714286
avg_sample_per_episode: 242.85714285714286
avg_envstep_per_sec: 2389.5341881304435
avg_train_sample_per_sec: 2389.5341881304435
avg_episode_per_sec: 9.83925842171359
collect_time: 0.7114357302123681
reward_mean: 1881.9169660476186
reward_std: 875.8275193783039
reward_max: 3579.2248841501855
reward_min: 940.6469149301537
total_envstep_count: 14249130
total_train_sample_count: 10713576
total_episode_count: 33166
total_duration: 2912.9662908501678
[2023-06-29 12:37:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2520
train_sample_count: 2520
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 2520.9739704547464
avg_train_sample_per_sec: 2520.9739704547464
avg_episode_per_sec: 10.003864962122009
collect_time: 0.9996136531094089
reward_mean: 1896.0015172169012
reward_std: 517.3274026060504
reward_max: 2877.701332656885
reward_min: 1146.7159790359115
total_envstep_count: 14253610
total_train_sample_count: 10716896
total_episode_count: 33176
total_duration: 2913.965904503277
[2023-06-29 12:37:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 350.42857142857144
avg_sample_per_episode: 350.42857142857144
avg_envstep_per_sec: 2806.0217361716473
avg_train_sample_per_sec: 2806.0217361716473
avg_episode_per_sec: 8.007399980921946
collect_time: 0.8741913750628008
reward_mean: 2198.7149621502367
reward_std: 1049.2633864976883
reward_max: 3640.6173785159335
reward_min: 915.5343810909727
total_envstep_count: 14258098
total_train_sample_count: 10720149
total_episode_count: 33183
total_duration: 2914.84009587834
[2023-06-29 12:37:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2412
train_sample_count: 2412
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2539.2312031795336
avg_train_sample_per_sec: 2539.2312031795336
avg_episode_per_sec: 9.47474329544602
collect_time: 0.9498938091890887
reward_mean: 1944.5151871418905
reward_std: 709.9927068958254
reward_max: 3596.1458682952853
reward_min: 1130.674325099315
total_envstep_count: 14262650
total_train_sample_count: 10723361
total_episode_count: 33192
total_duration: 2915.789989687529
[2023-06-29 12:37:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3026
train_sample_count: 3026
avg_envstep_per_episode: 275.09090909090907
avg_sample_per_episode: 275.09090909090907
avg_envstep_per_sec: 2519.814760298704
avg_train_sample_per_sec: 2519.814760298704
avg_episode_per_sec: 9.159934687140035
collect_time: 1.200881925003603
reward_mean: 1733.344208123123
reward_std: 560.9697618330315
reward_max: 2845.6875907325702
reward_min: 1171.2577532059343
total_envstep_count: 14267130
total_train_sample_count: 10726787
total_episode_count: 33203
total_duration: 2916.990871612533
[2023-06-29 12:37:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 245.3
avg_sample_per_episode: 245.3
avg_envstep_per_sec: 2520.6632291204164
avg_train_sample_per_sec: 2520.6632291204164
avg_episode_per_sec: 10.2758386837359
collect_time: 0.9731565770711753
reward_mean: 1448.0921331541697
reward_std: 501.2067784190419
reward_max: 2630.048204325901
reward_min: 935.2271119233477
total_envstep_count: 14271106
total_train_sample_count: 10730040
total_episode_count: 33213
total_duration: 2917.964028189604
[2023-06-29 12:37:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2611
train_sample_count: 2611
avg_envstep_per_episode: 290.1111111111111
avg_sample_per_episode: 290.1111111111111
avg_envstep_per_sec: 2790.7847863955126
avg_train_sample_per_sec: 2790.7847863955126
avg_episode_per_sec: 9.619710102473999
collect_time: 0.9355791291138158
reward_mean: 1790.0353047096103
reward_std: 380.98534100914895
reward_max: 2358.960815593424
reward_min: 1241.100503588282
total_envstep_count: 14275810
total_train_sample_count: 10733451
total_episode_count: 33222
total_duration: 2918.8996073187177
[2023-06-29 12:37:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2536
train_sample_count: 2536
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2594.6003940764654
avg_train_sample_per_sec: 2594.6003940764654
avg_episode_per_sec: 8.184859287307463
collect_time: 0.9774144819332289
reward_mean: 2122.0718438552353
reward_std: 734.8771441128183
reward_max: 3346.036018311061
reward_min: 1049.28665787099
total_envstep_count: 14280650
total_train_sample_count: 10736787
total_episode_count: 33230
total_duration: 2919.8770218006507
[2023-06-29 12:37:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1605
train_sample_count: 1605
avg_envstep_per_episode: 267.5
avg_sample_per_episode: 267.5
avg_envstep_per_sec: 2411.3068068297307
avg_train_sample_per_sec: 2411.3068068297307
avg_episode_per_sec: 9.014231053569087
collect_time: 0.6656141787739471
reward_mean: 2255.6988570819053
reward_std: 662.6715072976605
reward_max: 2895.144099072339
reward_min: 1105.8766004010467
total_envstep_count: 14284810
total_train_sample_count: 10739992
total_episode_count: 33236
total_duration: 2920.5426359794246
[2023-06-29 12:37:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2403
train_sample_count: 2403
avg_envstep_per_episode: 300.375
avg_sample_per_episode: 300.375
avg_envstep_per_sec: 2512.3961140375472
avg_train_sample_per_sec: 2512.3961140375472
avg_episode_per_sec: 8.36419846537677
collect_time: 0.9564574577128515
reward_mean: 2300.7566806233144
reward_std: 1119.6210425913373
reward_max: 3600.8865706635343
reward_min: 1019.3046023350155
total_envstep_count: 14288618
total_train_sample_count: 10743195
total_episode_count: 33244
total_duration: 2921.4990934371376
[2023-06-29 12:37:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2057
train_sample_count: 2057
avg_envstep_per_episode: 342.8333333333333
avg_sample_per_episode: 342.8333333333333
avg_envstep_per_sec: 2754.134125196048
avg_train_sample_per_sec: 2754.134125196048
avg_episode_per_sec: 8.033449076896591
collect_time: 0.7468772058635947
reward_mean: 2234.868977959112
reward_std: 864.459418650681
reward_max: 3636.1137206114827
reward_min: 1068.7969690815432
total_envstep_count: 14293026
total_train_sample_count: 10746452
total_episode_count: 33250
total_duration: 2922.2459706430013
[2023-06-29 12:37:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2969
train_sample_count: 2969
avg_envstep_per_episode: 296.9
avg_sample_per_episode: 296.9
avg_envstep_per_sec: 2743.58586601941
avg_train_sample_per_sec: 2743.58586601941
avg_episode_per_sec: 9.240774220341564
collect_time: 1.082160407943651
reward_mean: 2035.9468504284046
reward_std: 600.3609509047742
reward_max: 3298.679423744769
reward_min: 1227.2160849599297
total_envstep_count: 14297890
total_train_sample_count: 10749821
total_episode_count: 33260
total_duration: 2923.328131050945
[2023-06-29 12:37:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1714
train_sample_count: 1714
avg_envstep_per_episode: 244.85714285714286
avg_sample_per_episode: 244.85714285714286
avg_envstep_per_sec: 2592.5029050445282
avg_train_sample_per_sec: 2592.5029050445282
avg_episode_per_sec: 10.587818165292706
collect_time: 0.6611371569400655
reward_mean: 1487.563451099882
reward_std: 442.2915939024969
reward_max: 2262.4484412613797
reward_min: 1048.212485247004
total_envstep_count: 14301938
total_train_sample_count: 10753135
total_episode_count: 33267
total_duration: 2923.9892682078853
[2023-06-29 12:37:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 271.44444444444446
avg_sample_per_episode: 271.44444444444446
avg_envstep_per_sec: 2473.267544761311
avg_train_sample_per_sec: 2473.267544761311
avg_episode_per_sec: 9.111505486226688
collect_time: 0.9877621226925403
reward_mean: 2304.773165195742
reward_std: 793.0650064664422
reward_max: 3502.8045295153306
reward_min: 1093.1806100038077
total_envstep_count: 14306234
total_train_sample_count: 10756378
total_episode_count: 33276
total_duration: 2924.9770303305777
[2023-06-29 12:37:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2267
train_sample_count: 2267
avg_envstep_per_episode: 251.88888888888889
avg_sample_per_episode: 251.88888888888889
avg_envstep_per_sec: 2781.6738824070862
avg_train_sample_per_sec: 2781.6738824070862
avg_episode_per_sec: 11.043257583442337
collect_time: 0.8149769152803348
reward_mean: 1731.6168372426896
reward_std: 624.8860687230882
reward_max: 3172.7838404806275
reward_min: 1060.4868888234519
total_envstep_count: 14310978
total_train_sample_count: 10759845
total_episode_count: 33285
total_duration: 2925.792007245858
[2023-06-29 12:37:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3189
train_sample_count: 3189
avg_envstep_per_episode: 289.90909090909093
avg_sample_per_episode: 289.90909090909093
avg_envstep_per_sec: 2779.4364132805626
avg_train_sample_per_sec: 2779.4364132805626
avg_episode_per_sec: 9.58726890752154
collect_time: 1.147354904311709
reward_mean: 1917.8011608048828
reward_std: 709.4858321951249
reward_max: 3036.971261517173
reward_min: 1200.6478112763634
total_envstep_count: 14316082
total_train_sample_count: 10763434
total_episode_count: 33296
total_duration: 2926.9393621501695
[2023-06-29 12:37:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1395
train_sample_count: 1395
avg_envstep_per_episode: 232.5
avg_sample_per_episode: 232.5
avg_envstep_per_sec: 2811.47430974479
avg_train_sample_per_sec: 2811.47430974479
avg_episode_per_sec: 12.092362622558237
collect_time: 0.49618095216620717
reward_mean: 1516.1270383442486
reward_std: 378.86392450247183
reward_max: 1999.585004784145
reward_min: 957.6167655953136
total_envstep_count: 14320458
total_train_sample_count: 10766829
total_episode_count: 33302
total_duration: 2927.4355431023355
[2023-06-29 12:37:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 292.7
avg_sample_per_episode: 292.7
avg_envstep_per_sec: 2551.2261146451106
avg_train_sample_per_sec: 2551.2261146451106
avg_episode_per_sec: 8.71618078115856
collect_time: 1.1472914859242735
reward_mean: 2472.2741465905315
reward_std: 1025.923547701812
reward_max: 3644.877201255185
reward_min: 919.6626523896663
total_envstep_count: 14324738
total_train_sample_count: 10770156
total_episode_count: 33312
total_duration: 2928.5828345882596
[2023-06-29 12:37:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2551
train_sample_count: 2551
avg_envstep_per_episode: 364.42857142857144
avg_sample_per_episode: 364.42857142857144
avg_envstep_per_sec: 2708.1609396041445
avg_train_sample_per_sec: 2708.1609396041445
avg_episode_per_sec: 7.431253068298319
collect_time: 0.9419676514398303
reward_mean: 1963.225909383327
reward_std: 875.9273040028021
reward_max: 3577.113960240172
reward_min: 1162.2326659522503
total_envstep_count: 14329546
total_train_sample_count: 10773507
total_episode_count: 33319
total_duration: 2929.5248022396995
[2023-06-29 12:37:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2076
train_sample_count: 2076
avg_envstep_per_episode: 296.57142857142856
avg_sample_per_episode: 296.57142857142856
avg_envstep_per_sec: 2775.830857351246
avg_train_sample_per_sec: 2775.830857351246
avg_episode_per_sec: 9.359737958313449
collect_time: 0.7478841855591163
reward_mean: 2301.236461222779
reward_std: 1062.1040751437822
reward_max: 3626.1932009427733
reward_min: 1086.0950789153753
total_envstep_count: 14333642
total_train_sample_count: 10776783
total_episode_count: 33326
total_duration: 2930.2726864252586
[2023-06-29 12:37:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3470
train_sample_count: 3470
avg_envstep_per_episode: 315.45454545454544
avg_sample_per_episode: 315.45454545454544
avg_envstep_per_sec: 2811.8764928093456
avg_train_sample_per_sec: 2811.8764928093456
avg_episode_per_sec: 8.913729516110317
collect_time: 1.2340513564068822
reward_mean: 1915.1006661893828
reward_std: 674.9134062043643
reward_max: 3041.6511143002417
reward_min: 848.2984359639439
total_envstep_count: 14338682
total_train_sample_count: 10780253
total_episode_count: 33337
total_duration: 2931.5067377816654
[2023-06-29 12:38:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2217
train_sample_count: 2217
avg_envstep_per_episode: 277.125
avg_sample_per_episode: 277.125
avg_envstep_per_sec: 2662.4502374889657
avg_train_sample_per_sec: 2662.4502374889657
avg_episode_per_sec: 9.607398240826218
collect_time: 0.8326916194651275
reward_mean: 1600.6193297095765
reward_std: 389.8395706463322
reward_max: 2403.119742421835
reward_min: 1029.5450150632316
total_envstep_count: 14343418
total_train_sample_count: 10783670
total_episode_count: 33345
total_duration: 2932.3394294011305
[2023-06-29 12:38:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 306.25
avg_sample_per_episode: 306.25
avg_envstep_per_sec: 2625.976148191595
avg_train_sample_per_sec: 2625.976148191595
avg_episode_per_sec: 8.574615994095003
collect_time: 0.9329863874381409
reward_mean: 2441.162426136725
reward_std: 709.7388399719273
reward_max: 3649.7129442533987
reward_min: 1176.3321033244895
total_envstep_count: 14348162
total_train_sample_count: 10786920
total_episode_count: 33353
total_duration: 2933.2724157885687
[2023-06-29 12:38:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 816
train_sample_count: 816
avg_envstep_per_episode: 163.2
avg_sample_per_episode: 163.2
avg_envstep_per_sec: 2818.616915206954
avg_train_sample_per_sec: 2818.616915206954
avg_episode_per_sec: 17.27093698043477
collect_time: 0.2895036908341572
reward_mean: 2216.597804760445
reward_std: 1170.6364843614845
reward_max: 3645.14570384175
reward_min: 1021.9436202671661
total_envstep_count: 14351778
total_train_sample_count: 10790136
total_episode_count: 33358
total_duration: 2933.5619194794026
[2023-06-29 12:38:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2459
train_sample_count: 2459
avg_envstep_per_episode: 307.375
avg_sample_per_episode: 307.375
avg_envstep_per_sec: 2754.0190008198456
avg_train_sample_per_sec: 2754.0190008198456
avg_episode_per_sec: 8.959801548010885
collect_time: 0.8928769188839941
reward_mean: 2311.0783164999175
reward_std: 857.5898254152609
reward_max: 3642.394336445661
reward_min: 1337.4845097778464
total_envstep_count: 14355578
total_train_sample_count: 10793395
total_episode_count: 33366
total_duration: 2934.454796398287
[2023-06-29 12:38:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 232.57142857142858
avg_sample_per_episode: 232.57142857142858
avg_envstep_per_sec: 2501.300943832284
avg_train_sample_per_sec: 2501.300943832284
avg_episode_per_sec: 10.754979488222352
collect_time: 0.6508613063991071
reward_mean: 1773.861209315249
reward_std: 909.3248702155039
reward_max: 3671.1142798186297
reward_min: 996.0848142787065
total_envstep_count: 14360218
total_train_sample_count: 10796623
total_episode_count: 33373
total_duration: 2935.105657704686
[2023-06-29 12:38:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 206.6
avg_sample_per_episode: 206.6
avg_envstep_per_sec: 2478.4597509460236
avg_train_sample_per_sec: 2478.4597509460236
avg_episode_per_sec: 11.996416993930415
collect_time: 0.8335822275150571
reward_mean: 1898.5572178588318
reward_std: 589.1513513293083
reward_max: 2753.672228955855
reward_min: 986.8551070882522
total_envstep_count: 14364194
total_train_sample_count: 10799889
total_episode_count: 33383
total_duration: 2935.939239932201
[2023-06-29 12:38:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2094
train_sample_count: 2094
avg_envstep_per_episode: 299.14285714285717
avg_sample_per_episode: 299.14285714285717
avg_envstep_per_sec: 2723.9918215501953
avg_train_sample_per_sec: 2723.9918215501953
avg_episode_per_sec: 9.10598985236455
collect_time: 0.7687247749548405
reward_mean: 1901.854243448806
reward_std: 892.3458468174769
reward_max: 3593.200816927631
reward_min: 931.3947806907497
total_envstep_count: 14369074
total_train_sample_count: 10803183
total_episode_count: 33390
total_duration: 2936.707964707156
[2023-06-29 12:38:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3101
train_sample_count: 3101
avg_envstep_per_episode: 310.1
avg_sample_per_episode: 310.1
avg_envstep_per_sec: 2772.7779552326856
avg_train_sample_per_sec: 2772.7779552326856
avg_episode_per_sec: 8.941560642478832
collect_time: 1.1183729999540373
reward_mean: 2262.717192878623
reward_std: 899.7273233767249
reward_max: 3690.6473662418803
reward_min: 1104.9722416291233
total_envstep_count: 14374706
total_train_sample_count: 10806684
total_episode_count: 33400
total_duration: 2937.82633770711
[2023-06-29 12:38:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2488
train_sample_count: 2488
avg_envstep_per_episode: 276.44444444444446
avg_sample_per_episode: 276.44444444444446
avg_envstep_per_sec: 2579.104901512094
avg_train_sample_per_sec: 2579.104901512094
avg_episode_per_sec: 9.329559531193265
collect_time: 0.9646757673723623
reward_mean: 1859.3712861350589
reward_std: 716.6815258341552
reward_max: 3552.2821660319614
reward_min: 1168.4831489543699
total_envstep_count: 14379514
total_train_sample_count: 10809972
total_episode_count: 33409
total_duration: 2938.791013474482
[2023-06-29 12:38:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2449
train_sample_count: 2449
avg_envstep_per_episode: 272.1111111111111
avg_sample_per_episode: 272.1111111111111
avg_envstep_per_sec: 2529.63317637732
avg_train_sample_per_sec: 2529.63317637732
avg_episode_per_sec: 9.296324453816203
collect_time: 0.9681245576906946
reward_mean: 2085.3496395113607
reward_std: 777.7635177908425
reward_max: 3548.798787700735
reward_min: 945.8272606277658
total_envstep_count: 14384314
total_train_sample_count: 10813221
total_episode_count: 33418
total_duration: 2939.759138032173
[2023-06-29 12:38:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 345.3333333333333
avg_sample_per_episode: 345.3333333333333
avg_envstep_per_sec: 2476.370626255256
avg_train_sample_per_sec: 2476.370626255256
avg_episode_per_sec: 7.170957411936069
collect_time: 0.8367083578007298
reward_mean: 2148.5105589144555
reward_std: 795.0297440570728
reward_max: 3682.6692105352527
reward_min: 1132.9099699053595
total_envstep_count: 14388794
total_train_sample_count: 10816493
total_episode_count: 33424
total_duration: 2940.5958463899738
[2023-06-29 12:38:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1578
train_sample_count: 1578
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2740.898720977962
avg_train_sample_per_sec: 2740.898720977962
avg_episode_per_sec: 10.421668140600616
collect_time: 0.5757235712222757
reward_mean: 2653.2630465836924
reward_std: 735.4825206093705
reward_max: 3511.1723092479633
reward_min: 1700.878900375344
total_envstep_count: 14393258
total_train_sample_count: 10820071
total_episode_count: 33430
total_duration: 2941.171569961196
[2023-06-29 12:38:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3054
train_sample_count: 3054
avg_envstep_per_episode: 339.3333333333333
avg_sample_per_episode: 339.3333333333333
avg_envstep_per_sec: 2823.3068220464484
avg_train_sample_per_sec: 2823.3068220464484
avg_episode_per_sec: 8.320157628820576
collect_time: 1.081710275394842
reward_mean: 2592.1746804565864
reward_std: 949.0574227903363
reward_max: 3629.787293822893
reward_min: 1041.861079402188
total_envstep_count: 14397858
total_train_sample_count: 10823525
total_episode_count: 33439
total_duration: 2942.253280236591
[2023-06-29 12:38:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 573
train_sample_count: 573
avg_envstep_per_episode: 95.5
avg_sample_per_episode: 95.5
avg_envstep_per_sec: 2610.202220457116
avg_train_sample_per_sec: 2610.202220457116
avg_episode_per_sec: 27.33196042363472
collect_time: 0.21952322142291814
reward_mean: 741.776311067007
reward_std: 552.1586358886426
reward_max: 1540.9881619252567
reward_min: 68.57024367191781
total_envstep_count: 14402090
total_train_sample_count: 10826898
total_episode_count: 33445
total_duration: 2942.472803458014
[2023-06-29 12:38:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2174
train_sample_count: 2174
avg_envstep_per_episode: 181.16666666666666
avg_sample_per_episode: 181.16666666666666
avg_envstep_per_sec: 2570.152323417215
avg_train_sample_per_sec: 2570.152323417215
avg_episode_per_sec: 14.186673358328694
collect_time: 0.8458642626712101
reward_mean: 1869.949535369619
reward_std: 1291.7919071684469
reward_max: 3583.9934366471857
reward_min: 67.21085619951572
total_envstep_count: 14406730
total_train_sample_count: 10830272
total_episode_count: 33457
total_duration: 2943.318667720685
[2023-06-29 12:38:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1819
train_sample_count: 1819
avg_envstep_per_episode: 202.11111111111111
avg_sample_per_episode: 202.11111111111111
avg_envstep_per_sec: 2764.5540024586644
avg_train_sample_per_sec: 2764.5540024586644
avg_episode_per_sec: 13.678387038003287
collect_time: 0.6579723161067814
reward_mean: 1928.7916907816423
reward_std: 960.3984115481737
reward_max: 3587.5106948111547
reward_min: 611.6202489776175
total_envstep_count: 14410546
total_train_sample_count: 10833691
total_episode_count: 33466
total_duration: 2943.9766400367917
[2023-06-29 12:38:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2061
train_sample_count: 2061
avg_envstep_per_episode: 294.42857142857144
avg_sample_per_episode: 294.42857142857144
avg_envstep_per_sec: 2807.318369921793
avg_train_sample_per_sec: 2807.318369921793
avg_episode_per_sec: 9.534802809050243
collect_time: 0.734152571394108
reward_mean: 1959.0599728400373
reward_std: 836.3030137450157
reward_max: 3583.3650923057066
reward_min: 1017.8396613873597
total_envstep_count: 14414914
total_train_sample_count: 10836952
total_episode_count: 33473
total_duration: 2944.710792608186
[2023-06-29 12:38:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2675
train_sample_count: 2675
avg_envstep_per_episode: 297.22222222222223
avg_sample_per_episode: 297.22222222222223
avg_envstep_per_sec: 2562.6731917329516
avg_train_sample_per_sec: 2562.6731917329516
avg_episode_per_sec: 8.622078028260399
collect_time: 1.0438318895399572
reward_mean: 2070.8044190833853
reward_std: 1082.0901800365264
reward_max: 3610.4879656459675
reward_min: 1028.1551269383767
total_envstep_count: 14419602
total_train_sample_count: 10840427
total_episode_count: 33482
total_duration: 2945.7546244977257
[2023-06-29 12:38:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 886
train_sample_count: 886
avg_envstep_per_episode: 177.2
avg_sample_per_episode: 177.2
avg_envstep_per_sec: 2721.635627641364
avg_train_sample_per_sec: 2721.635627641364
avg_episode_per_sec: 15.359117537479479
collect_time: 0.32553953622654086
reward_mean: 2070.3768549116126
reward_std: 909.2536662610789
reward_max: 3586.32450338831
reward_min: 1191.69984522657
total_envstep_count: 14423602
total_train_sample_count: 10843713
total_episode_count: 33487
total_duration: 2946.0801640339523
[2023-06-29 12:39:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1844
train_sample_count: 1844
avg_envstep_per_episode: 184.4
avg_sample_per_episode: 184.4
avg_envstep_per_sec: 2724.3009614781586
avg_train_sample_per_sec: 2724.3009614781586
avg_episode_per_sec: 14.773866385456392
collect_time: 0.6768708839714528
reward_mean: 1976.7303638396763
reward_std: 1060.3682605937681
reward_max: 3644.8118737325804
reward_min: 70.50038985157835
total_envstep_count: 14428610
total_train_sample_count: 10847157
total_episode_count: 33497
total_duration: 2946.7570349179236
[2023-06-29 12:39:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2485
train_sample_count: 2485
avg_envstep_per_episode: 414.1666666666667
avg_sample_per_episode: 414.1666666666667
avg_envstep_per_sec: 2750.630071880856
avg_train_sample_per_sec: 2750.630071880856
avg_episode_per_sec: 6.641360334521182
collect_time: 0.9034293725658207
reward_mean: 3053.8162993133064
reward_std: 477.36856185987824
reward_max: 3648.700349869307
reward_min: 2259.115009991507
total_envstep_count: 14432858
total_train_sample_count: 10850442
total_episode_count: 33503
total_duration: 2947.6604642904895
[2023-06-29 12:39:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2441
train_sample_count: 2441
avg_envstep_per_episode: 244.1
avg_sample_per_episode: 244.1
avg_envstep_per_sec: 2685.6339391355473
avg_train_sample_per_sec: 2685.6339391355473
avg_episode_per_sec: 11.002187378679015
collect_time: 0.9089101699339225
reward_mean: 1755.646381332696
reward_std: 965.9030513304493
reward_max: 3672.7797482721517
reward_min: 994.4668680192653
total_envstep_count: 14437498
total_train_sample_count: 10854083
total_episode_count: 33513
total_duration: 2948.569374460423
[2023-06-29 12:39:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1329
train_sample_count: 1329
avg_envstep_per_episode: 221.5
avg_sample_per_episode: 221.5
avg_envstep_per_sec: 2373.6838643168235
avg_train_sample_per_sec: 2373.6838643168235
avg_episode_per_sec: 10.716405707976628
collect_time: 0.5598892169166357
reward_mean: 2136.5199309841378
reward_std: 545.5694773312638
reward_max: 3223.3525122116125
reward_min: 1599.4127691629237
total_envstep_count: 14442314
total_train_sample_count: 10857412
total_episode_count: 33519
total_duration: 2949.1292636773396
[2023-06-29 12:39:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3294
train_sample_count: 3294
avg_envstep_per_episode: 219.6
avg_sample_per_episode: 219.6
avg_envstep_per_sec: 2515.6703619695695
avg_train_sample_per_sec: 2515.6703619695695
avg_episode_per_sec: 11.455693815890573
collect_time: 1.309392537987791
reward_mean: 1686.5175643532227
reward_std: 699.8388319471036
reward_max: 3086.7477355962365
reward_min: 879.336534267405
total_envstep_count: 14446738
total_train_sample_count: 10860706
total_episode_count: 33534
total_duration: 2950.4386562153272
[2023-06-29 12:39:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2138
train_sample_count: 2138
avg_envstep_per_episode: 267.25
avg_sample_per_episode: 267.25
avg_envstep_per_sec: 2777.4925644775462
avg_train_sample_per_sec: 2777.4925644775462
avg_episode_per_sec: 10.392862729569865
collect_time: 0.7697590363854542
reward_mean: 1472.074858931411
reward_std: 539.0522192552974
reward_max: 2384.2860971123646
reward_min: 721.8461725436794
total_envstep_count: 14451482
total_train_sample_count: 10864044
total_episode_count: 33542
total_duration: 2951.2084152517127
[2023-06-29 12:39:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2247
train_sample_count: 2247
avg_envstep_per_episode: 280.875
avg_sample_per_episode: 280.875
avg_envstep_per_sec: 2582.9960883949684
avg_train_sample_per_sec: 2582.9960883949684
avg_episode_per_sec: 9.196247755745325
collect_time: 0.8699200165634975
reward_mean: 2136.0311677039476
reward_std: 984.2649966621032
reward_max: 3590.4654075129815
reward_min: 887.1948909910674
total_envstep_count: 14456290
total_train_sample_count: 10867491
total_episode_count: 33550
total_duration: 2952.078335268276
[2023-06-29 12:39:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 2650.284412239139
avg_train_sample_per_sec: 2650.284412239139
avg_episode_per_sec: 10.817487396894444
collect_time: 0.9244290871899574
reward_mean: 1829.0976317343132
reward_std: 919.1432816306212
reward_max: 3568.4283625655157
reward_min: 981.4348819835438
total_envstep_count: 14461026
total_train_sample_count: 10870741
total_episode_count: 33560
total_duration: 2953.002764355466
[2023-06-29 12:39:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1672
train_sample_count: 1672
avg_envstep_per_episode: 185.77777777777777
avg_sample_per_episode: 185.77777777777777
avg_envstep_per_sec: 2338.9009666055467
avg_train_sample_per_sec: 2338.9009666055467
avg_episode_per_sec: 12.589777930293014
collect_time: 0.714865667196922
reward_mean: 1439.7421233031837
reward_std: 732.7537443764056
reward_max: 3235.5362205634174
reward_min: 805.7704214998718
total_envstep_count: 14465042
total_train_sample_count: 10874013
total_episode_count: 33569
total_duration: 2953.717630022663
[2023-06-29 12:39:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 236.9090909090909
avg_sample_per_episode: 236.9090909090909
avg_envstep_per_sec: 2739.749449486174
avg_train_sample_per_sec: 2739.749449486174
avg_episode_per_sec: 11.56456022423174
collect_time: 0.9511818682868034
reward_mean: 1819.2526433020794
reward_std: 1053.0039601781714
reward_max: 3596.0235789221124
reward_min: 770.4879195369793
total_envstep_count: 14469578
total_train_sample_count: 10877419
total_episode_count: 33580
total_duration: 2954.6688118909497
[2023-06-29 12:39:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2091
train_sample_count: 2091
avg_envstep_per_episode: 190.0909090909091
avg_sample_per_episode: 190.0909090909091
avg_envstep_per_sec: 2554.176790071315
avg_train_sample_per_sec: 2554.176790071315
avg_episode_per_sec: 13.43660673877784
collect_time: 0.8186590717323124
reward_mean: 1228.1926901950121
reward_std: 554.0042626640774
reward_max: 2861.594664133333
reward_min: 719.7132367911203
total_envstep_count: 14473810
total_train_sample_count: 10880710
total_episode_count: 33591
total_duration: 2955.487470962682
[2023-06-29 12:39:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2522
train_sample_count: 2522
avg_envstep_per_episode: 229.27272727272728
avg_sample_per_episode: 229.27272727272728
avg_envstep_per_sec: 2558.1960338534277
avg_train_sample_per_sec: 2558.1960338534277
avg_episode_per_sec: 11.157873264229858
collect_time: 0.9858509538071227
reward_mean: 1665.933503884045
reward_std: 678.1383001890456
reward_max: 3604.3972873782527
reward_min: 933.2840255702672
total_envstep_count: 14478938
total_train_sample_count: 10884032
total_episode_count: 33602
total_duration: 2956.473321916489
[2023-06-29 12:39:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1988
train_sample_count: 1988
avg_envstep_per_episode: 220.88888888888889
avg_sample_per_episode: 220.88888888888889
avg_envstep_per_sec: 2495.3917439765073
avg_train_sample_per_sec: 2495.3917439765073
avg_episode_per_sec: 11.297045118605917
collect_time: 0.7966685009673239
reward_mean: 1694.9218733983992
reward_std: 942.3889847640564
reward_max: 3499.9177747098083
reward_min: 552.7881950825808
total_envstep_count: 14483794
total_train_sample_count: 10887620
total_episode_count: 33611
total_duration: 2957.2699904174565
[2023-06-29 12:39:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 173.84615384615384
avg_sample_per_episode: 173.84615384615384
avg_envstep_per_sec: 2714.58065499125
avg_train_sample_per_sec: 2714.58065499125
avg_episode_per_sec: 15.614844475613385
collect_time: 0.8325411130608992
reward_mean: 1402.652074937359
reward_std: 818.5815523859183
reward_max: 3588.644957710518
reward_min: 555.1783739161613
total_envstep_count: 14488362
total_train_sample_count: 10891080
total_episode_count: 33624
total_duration: 2958.1025315305174
[2023-06-29 12:39:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2446
train_sample_count: 2446
avg_envstep_per_episode: 271.77777777777777
avg_sample_per_episode: 271.77777777777777
avg_envstep_per_sec: 2785.510598266705
avg_train_sample_per_sec: 2785.510598266705
avg_episode_per_sec: 10.249221334587222
collect_time: 0.8781154886009169
reward_mean: 2106.6437795997913
reward_std: 661.6889889270082
reward_max: 3546.2484402961545
reward_min: 1046.7511662722577
total_envstep_count: 14492922
total_train_sample_count: 10894326
total_episode_count: 33633
total_duration: 2958.9806470191184
[2023-06-29 12:39:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 269.6666666666667
avg_sample_per_episode: 269.6666666666667
avg_envstep_per_sec: 2573.34414721885
avg_train_sample_per_sec: 2573.34414721885
avg_episode_per_sec: 9.542685341973487
collect_time: 0.9431307517196983
reward_mean: 1811.9931411776754
reward_std: 662.0375686923485
reward_max: 2775.664965176221
reward_min: 841.8021616623588
total_envstep_count: 14497562
total_train_sample_count: 10897553
total_episode_count: 33642
total_duration: 2959.923777770838
[2023-06-29 12:39:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2297
train_sample_count: 2297
avg_envstep_per_episode: 255.22222222222223
avg_sample_per_episode: 255.22222222222223
avg_envstep_per_sec: 2545.549024006138
avg_train_sample_per_sec: 2545.549024006138
avg_episode_per_sec: 9.973853380955699
collect_time: 0.9023593646548688
reward_mean: 1814.7832406054683
reward_std: 743.6079945231594
reward_max: 2909.310819440499
reward_min: 843.4202982547401
total_envstep_count: 14501914
total_train_sample_count: 10901050
total_episode_count: 33651
total_duration: 2960.826137135493
[2023-06-29 12:39:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1643
train_sample_count: 1643
avg_envstep_per_episode: 205.375
avg_sample_per_episode: 205.375
avg_envstep_per_sec: 2717.6388069621585
avg_train_sample_per_sec: 2717.6388069621585
avg_episode_per_sec: 13.232568749663585
collect_time: 0.6045689352797344
reward_mean: 1584.212740618608
reward_std: 551.2204746787121
reward_max: 2586.1286254143197
reward_min: 908.6627815439921
total_envstep_count: 14506858
total_train_sample_count: 10904293
total_episode_count: 33659
total_duration: 2961.4307060707724
[2023-06-29 12:39:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2203
train_sample_count: 2203
avg_envstep_per_episode: 244.77777777777777
avg_sample_per_episode: 244.77777777777777
avg_envstep_per_sec: 2747.529175588398
avg_train_sample_per_sec: 2747.529175588398
avg_episode_per_sec: 11.22458582854997
collect_time: 0.801811321813613
reward_mean: 2334.106180455956
reward_std: 838.7446794346093
reward_max: 3319.814606840888
reward_min: 1043.1382820886795
total_envstep_count: 14511362
total_train_sample_count: 10907696
total_episode_count: 33668
total_duration: 2962.232517392586
[2023-06-29 12:40:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2543
train_sample_count: 2543
avg_envstep_per_episode: 231.1818181818182
avg_sample_per_episode: 231.1818181818182
avg_envstep_per_sec: 2655.1173010651673
avg_train_sample_per_sec: 2655.1173010651673
avg_episode_per_sec: 11.484974562216612
collect_time: 0.9577731270026417
reward_mean: 1523.8110628139787
reward_std: 613.039611518171
reward_max: 2950.7230509275387
reward_min: 966.2493161423645
total_envstep_count: 14516034
total_train_sample_count: 10911039
total_episode_count: 33679
total_duration: 2963.190290519589
[2023-06-29 12:40:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1521
train_sample_count: 1521
avg_envstep_per_episode: 217.28571428571428
avg_sample_per_episode: 217.28571428571428
avg_envstep_per_sec: 2698.1569755156447
avg_train_sample_per_sec: 2698.1569755156447
avg_episode_per_sec: 12.417553470486201
collect_time: 0.5637181282639502
reward_mean: 1988.5397865444954
reward_std: 1042.091787133822
reward_max: 3595.6984733554527
reward_min: 982.5641583114685
total_envstep_count: 14520834
total_train_sample_count: 10914560
total_episode_count: 33686
total_duration: 2963.754008647853
[2023-06-29 12:40:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 250.3
avg_sample_per_episode: 250.3
avg_envstep_per_sec: 2527.7130611592756
avg_train_sample_per_sec: 2527.7130611592756
avg_episode_per_sec: 10.098733764120158
collect_time: 0.9902231540679931
reward_mean: 2183.357051868271
reward_std: 953.7586751841908
reward_max: 3548.6666627166805
reward_min: 907.0652400562049
total_envstep_count: 14525450
total_train_sample_count: 10917863
total_episode_count: 33696
total_duration: 2964.744231801921
[2023-06-29 12:40:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2588
train_sample_count: 2588
avg_envstep_per_episode: 258.8
avg_sample_per_episode: 258.8
avg_envstep_per_sec: 2578.2077512314486
avg_train_sample_per_sec: 2578.2077512314486
avg_episode_per_sec: 9.962162871837128
collect_time: 1.0037980836741625
reward_mean: 1528.712876180587
reward_std: 638.4701386123567
reward_max: 3023.4257507720354
reward_min: 937.5211767885208
total_envstep_count: 14529826
total_train_sample_count: 10921251
total_episode_count: 33706
total_duration: 2965.7480298855953
[2023-06-29 12:40:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1712
train_sample_count: 1712
avg_envstep_per_episode: 285.3333333333333
avg_sample_per_episode: 285.3333333333333
avg_envstep_per_sec: 2754.825362935381
avg_train_sample_per_sec: 2754.825362935381
avg_episode_per_sec: 9.654761785988484
collect_time: 0.621455001479946
reward_mean: 2387.545433150798
reward_std: 955.4421752673243
reward_max: 3588.5242592627837
reward_min: 979.4978516541365
total_envstep_count: 14534066
total_train_sample_count: 10924563
total_episode_count: 33712
total_duration: 2966.3694848870755
[2023-06-29 12:40:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 306.625
avg_sample_per_episode: 306.625
avg_envstep_per_sec: 2691.5985796304108
avg_train_sample_per_sec: 2691.5985796304108
avg_episode_per_sec: 8.778144572785685
collect_time: 0.911354322507046
reward_mean: 2311.6394576730677
reward_std: 953.0175140142583
reward_max: 3704.169691813302
reward_min: 1003.9339046216458
total_envstep_count: 14538442
total_train_sample_count: 10927816
total_episode_count: 33720
total_duration: 2967.2808392095826
[2023-06-29 12:40:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2497
train_sample_count: 2497
avg_envstep_per_episode: 356.7142857142857
avg_sample_per_episode: 356.7142857142857
avg_envstep_per_sec: 2565.283917830523
avg_train_sample_per_sec: 2565.283917830523
avg_episode_per_sec: 7.191424679540914
collect_time: 0.9733815359165892
reward_mean: 2341.9735507655532
reward_std: 663.4124612519582
reward_max: 3551.8892451550128
reward_min: 1501.4091210393105
total_envstep_count: 14543098
total_train_sample_count: 10931113
total_episode_count: 33727
total_duration: 2968.2542207454994
[2023-06-29 12:40:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1365
train_sample_count: 1365
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2743.3556842640846
avg_train_sample_per_sec: 2743.3556842640846
avg_episode_per_sec: 10.048921920381263
collect_time: 0.4975658124936746
reward_mean: 2008.3717212675233
reward_std: 894.5703294222856
reward_max: 3552.916009705531
reward_min: 999.215324166834
total_envstep_count: 14547066
total_train_sample_count: 10934478
total_episode_count: 33732
total_duration: 2968.751786557993
[2023-06-29 12:40:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1700
train_sample_count: 1700
avg_envstep_per_episode: 283.3333333333333
avg_sample_per_episode: 283.3333333333333
avg_envstep_per_sec: 2641.767426586617
avg_train_sample_per_sec: 2641.767426586617
avg_episode_per_sec: 9.323885035011589
collect_time: 0.6435085779661313
reward_mean: 2936.758143435098
reward_std: 976.2491233715353
reward_max: 3661.0076980916515
reward_min: 1009.0805444842468
total_envstep_count: 14551346
total_train_sample_count: 10937778
total_episode_count: 33738
total_duration: 2969.3952951359593
[2023-06-29 12:40:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3455
train_sample_count: 3455
avg_envstep_per_episode: 265.7692307692308
avg_sample_per_episode: 265.7692307692308
avg_envstep_per_sec: 2596.7532248208495
avg_train_sample_per_sec: 2596.7532248208495
avg_episode_per_sec: 9.77070677935486
collect_time: 1.3305076381443066
reward_mean: 1754.854716594731
reward_std: 1043.987234044173
reward_max: 3673.5798800187663
reward_min: 695.9708675670788
total_envstep_count: 14555874
total_train_sample_count: 10941233
total_episode_count: 33751
total_duration: 2970.7258027741036
[2023-06-29 12:40:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3089
train_sample_count: 3089
avg_envstep_per_episode: 308.9
avg_sample_per_episode: 308.9
avg_envstep_per_sec: 2598.690452821634
avg_train_sample_per_sec: 2598.690452821634
avg_episode_per_sec: 8.412724029853138
collect_time: 1.1886756256967783
reward_mean: 1533.0900967111313
reward_std: 453.66110583010635
reward_max: 2270.1581326915484
reward_min: 858.9696473808298
total_envstep_count: 14560098
total_train_sample_count: 10944722
total_episode_count: 33761
total_duration: 2971.9144783998004
[2023-06-29 12:40:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2961
train_sample_count: 2961
avg_envstep_per_episode: 329.0
avg_sample_per_episode: 329.0
avg_envstep_per_sec: 2721.7316009562232
avg_train_sample_per_sec: 2721.7316009562232
avg_episode_per_sec: 8.272740428438368
collect_time: 1.08791035786178
reward_mean: 1510.8950042953134
reward_std: 388.2022202911986
reward_max: 2247.4098167381894
reward_min: 1027.9207793674525
total_envstep_count: 14564850
total_train_sample_count: 10948083
total_episode_count: 33770
total_duration: 2973.002388757662
[2023-06-29 12:40:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2305
train_sample_count: 2305
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 2607.096025213844
avg_train_sample_per_sec: 2607.096025213844
avg_episode_per_sec: 11.310611823053552
collect_time: 0.8841254705265162
reward_mean: 1646.3020353340921
reward_std: 891.4547411570933
reward_max: 3537.6207677478315
reward_min: 996.781967150243
total_envstep_count: 14569810
total_train_sample_count: 10951588
total_episode_count: 33780
total_duration: 2973.886514228189
[2023-06-29 12:40:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3048
train_sample_count: 3048
avg_envstep_per_episode: 234.46153846153845
avg_sample_per_episode: 234.46153846153845
avg_envstep_per_sec: 2614.3944245603075
avg_train_sample_per_sec: 2614.3944245603075
avg_episode_per_sec: 11.150632388216534
collect_time: 1.165853159479797
reward_mean: 1588.4470266958535
reward_std: 923.2440541523166
reward_max: 3586.491941870068
reward_min: 647.6026451057539
total_envstep_count: 14575418
total_train_sample_count: 10955036
total_episode_count: 33793
total_duration: 2975.0523673876687
[2023-06-29 12:40:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2055
train_sample_count: 2055
avg_envstep_per_episode: 186.8181818181818
avg_sample_per_episode: 186.8181818181818
avg_envstep_per_sec: 2522.6180064226282
avg_train_sample_per_sec: 2522.6180064226282
avg_episode_per_sec: 13.50306475457368
collect_time: 0.8146298784706741
reward_mean: 1560.9527677342492
reward_std: 611.8288009889561
reward_max: 2942.271488364361
reward_min: 810.0828114359849
total_envstep_count: 14579210
total_train_sample_count: 10958291
total_episode_count: 33804
total_duration: 2975.8669972661396
[2023-06-29 12:40:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2612
train_sample_count: 2612
avg_envstep_per_episode: 326.5
avg_sample_per_episode: 326.5
avg_envstep_per_sec: 2661.2803374582786
avg_train_sample_per_sec: 2661.2803374582786
avg_episode_per_sec: 8.150935183639444
collect_time: 0.9814824703866617
reward_mean: 1988.1703272812342
reward_std: 805.9046940113623
reward_max: 3288.6302147009123
reward_min: 986.0250080037948
total_envstep_count: 14583194
total_train_sample_count: 10961703
total_episode_count: 33812
total_duration: 2976.8484797365263
[2023-06-29 12:40:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2921
train_sample_count: 2921
avg_envstep_per_episode: 292.1
avg_sample_per_episode: 292.1
avg_envstep_per_sec: 2800.253742712954
avg_train_sample_per_sec: 2800.253742712954
avg_episode_per_sec: 9.586626986350408
collect_time: 1.0431197557011616
reward_mean: 1573.4249070613896
reward_std: 828.2505878396381
reward_max: 3557.583347682706
reward_min: 538.624577139922
total_envstep_count: 14587698
total_train_sample_count: 10965024
total_episode_count: 33822
total_duration: 2977.8915994922277
[2023-06-29 12:40:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1673
train_sample_count: 1673
avg_envstep_per_episode: 334.6
avg_sample_per_episode: 334.6
avg_envstep_per_sec: 2518.0985806094645
avg_train_sample_per_sec: 2518.0985806094645
avg_episode_per_sec: 7.525698089089853
collect_time: 0.6643901922199875
reward_mean: 1863.2279343223513
reward_std: 949.4596257354297
reward_max: 3582.386481090214
reward_min: 1052.4966138309146
total_envstep_count: 14591522
total_train_sample_count: 10968297
total_episode_count: 33827
total_duration: 2978.5559896844475
[2023-06-29 12:40:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1528
train_sample_count: 1528
avg_envstep_per_episode: 218.28571428571428
avg_sample_per_episode: 218.28571428571428
avg_envstep_per_sec: 2691.2078117366054
avg_train_sample_per_sec: 2691.2078117366054
avg_episode_per_sec: 12.32883159826979
collect_time: 0.5677748085213825
reward_mean: 2292.966919005109
reward_std: 765.3241950379155
reward_max: 3612.7424232015924
reward_min: 1390.702293442565
total_envstep_count: 14596274
total_train_sample_count: 10971825
total_episode_count: 33834
total_duration: 2979.123764492969
[2023-06-29 12:40:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2662
train_sample_count: 2662
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2749.4382611126684
avg_train_sample_per_sec: 2749.4382611126684
avg_episode_per_sec: 11.361315128564746
collect_time: 0.9681977724870668
reward_mean: 2002.571575047486
reward_std: 778.9574503844225
reward_max: 3694.6417672262082
reward_min: 1021.1684563820681
total_envstep_count: 14600986
total_train_sample_count: 10975287
total_episode_count: 33845
total_duration: 2980.091962265456
[2023-06-29 12:41:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2042
train_sample_count: 2042
avg_envstep_per_episode: 226.88888888888889
avg_sample_per_episode: 226.88888888888889
avg_envstep_per_sec: 2670.39245867626
avg_train_sample_per_sec: 2670.39245867626
avg_episode_per_sec: 11.769604372226414
collect_time: 0.7646816082652659
reward_mean: 1664.6361647596048
reward_std: 626.1213246584445
reward_max: 3098.9279257068183
reward_min: 977.4838216740822
total_envstep_count: 14605274
total_train_sample_count: 10978529
total_episode_count: 33854
total_duration: 2980.856643873721
[2023-06-29 12:41:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2576
train_sample_count: 2576
avg_envstep_per_episode: 286.22222222222223
avg_sample_per_episode: 286.22222222222223
avg_envstep_per_sec: 2609.1395928094403
avg_train_sample_per_sec: 2609.1395928094403
avg_episode_per_sec: 9.115782738852857
collect_time: 0.9872986509036273
reward_mean: 1876.2121506547753
reward_std: 850.3429029914707
reward_max: 3513.1404196885837
reward_min: 1016.73961426843
total_envstep_count: 14609730
total_train_sample_count: 10981905
total_episode_count: 33863
total_duration: 2981.8439425246247
[2023-06-29 12:41:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3357
train_sample_count: 3357
avg_envstep_per_episode: 239.78571428571428
avg_sample_per_episode: 239.78571428571428
avg_envstep_per_sec: 2594.711473946134
avg_train_sample_per_sec: 2594.711473946134
avg_episode_per_sec: 10.820959378982984
collect_time: 1.2937854685224592
reward_mean: 1412.451138697665
reward_std: 877.8588423931209
reward_max: 3598.9651588863926
reward_min: 524.6102101668514
total_envstep_count: 14614674
total_train_sample_count: 10985262
total_episode_count: 33877
total_duration: 2983.137727993147
[2023-06-29 12:41:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1668
train_sample_count: 1668
avg_envstep_per_episode: 238.28571428571428
avg_sample_per_episode: 238.28571428571428
avg_envstep_per_sec: 2665.2619408707706
avg_train_sample_per_sec: 2665.2619408707706
avg_episode_per_sec: 11.18515203003321
collect_time: 0.6258296696553007
reward_mean: 1651.4382418256944
reward_std: 390.6978995218283
reward_max: 2032.3549020707856
reward_min: 1040.8912589282393
total_envstep_count: 14619122
total_train_sample_count: 10988530
total_episode_count: 33884
total_duration: 2983.763557662802
[2023-06-29 12:41:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1653
train_sample_count: 1653
avg_envstep_per_episode: 236.14285714285714
avg_sample_per_episode: 236.14285714285714
avg_envstep_per_sec: 2714.4240640508615
avg_train_sample_per_sec: 2714.4240640508615
avg_episode_per_sec: 11.49483874673686
collect_time: 0.6089689602637662
reward_mean: 2386.3945284488095
reward_std: 836.9330387606359
reward_max: 3570.023233884767
reward_min: 1232.9079982900096
total_envstep_count: 14623962
total_train_sample_count: 10991783
total_episode_count: 33891
total_duration: 2984.372526623066
[2023-06-29 12:41:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2613
train_sample_count: 2613
avg_envstep_per_episode: 261.3
avg_sample_per_episode: 261.3
avg_envstep_per_sec: 2622.9534563032203
avg_train_sample_per_sec: 2622.9534563032203
avg_episode_per_sec: 10.038092063923537
collect_time: 0.9962052485989406
reward_mean: 1949.7290392304944
reward_std: 919.9566348233916
reward_max: 3539.486318243356
reward_min: 789.8214031776347
total_envstep_count: 14628194
total_train_sample_count: 10995196
total_episode_count: 33901
total_duration: 2985.3687318716647
[2023-06-29 12:41:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 201.2
avg_sample_per_episode: 201.2
avg_envstep_per_sec: 2505.7225669904306
avg_train_sample_per_sec: 2505.7225669904306
avg_episode_per_sec: 12.453889497964367
collect_time: 0.802961998469196
reward_mean: 1445.8025596598532
reward_std: 916.0726804428537
reward_max: 3573.762224829131
reward_min: 686.1673856236433
total_envstep_count: 14632842
total_train_sample_count: 10998408
total_episode_count: 33911
total_duration: 2986.171693870134
[2023-06-29 12:41:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2383
train_sample_count: 2383
avg_envstep_per_episode: 264.77777777777777
avg_sample_per_episode: 264.77777777777777
avg_envstep_per_sec: 2562.005112222724
avg_train_sample_per_sec: 2562.005112222724
avg_episode_per_sec: 9.676057914395516
collect_time: 0.9301308528352529
reward_mean: 2091.976657486257
reward_std: 876.8551363889306
reward_max: 3602.9818946763758
reward_min: 1053.964407792823
total_envstep_count: 14638090
total_train_sample_count: 11001991
total_episode_count: 33920
total_duration: 2987.101824722969
[2023-06-29 12:41:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 303.375
avg_sample_per_episode: 303.375
avg_envstep_per_sec: 2811.9007907991245
avg_train_sample_per_sec: 2811.9007907991245
avg_episode_per_sec: 9.268729429910588
collect_time: 0.8631172223221509
reward_mean: 2325.7497835139447
reward_std: 722.5239504387996
reward_max: 3678.374733617317
reward_min: 1161.7041424286151
total_envstep_count: 14642914
total_train_sample_count: 11005218
total_episode_count: 33928
total_duration: 2987.9649419452912
[2023-06-29 12:41:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 285.7142857142857
avg_sample_per_episode: 285.7142857142857
avg_envstep_per_sec: 2774.4480767666946
avg_train_sample_per_sec: 2774.4480767666946
avg_episode_per_sec: 9.710568268683431
collect_time: 0.7208640942852943
reward_mean: 1921.9281255883354
reward_std: 887.9784992253365
reward_max: 3568.1387344244044
reward_min: 1006.9221704291757
total_envstep_count: 14647450
total_train_sample_count: 11008418
total_episode_count: 33935
total_duration: 2988.6858060395766
[2023-06-29 12:41:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2121
train_sample_count: 2121
avg_envstep_per_episode: 303.0
avg_sample_per_episode: 303.0
avg_envstep_per_sec: 2498.0000610277266
avg_train_sample_per_sec: 2498.0000610277266
avg_episode_per_sec: 8.244224623853883
collect_time: 0.8490792426671834
reward_mean: 2710.3687049800906
reward_std: 827.9693625956916
reward_max: 3618.697504726001
reward_min: 1216.063576963222
total_envstep_count: 14651922
total_train_sample_count: 11011739
total_episode_count: 33942
total_duration: 2989.534885282244
[2023-06-29 12:41:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 271.0
avg_sample_per_episode: 271.0
avg_envstep_per_sec: 2658.9788512097725
avg_train_sample_per_sec: 2658.9788512097725
avg_episode_per_sec: 9.811730078264844
collect_time: 0.9172694242717698
reward_mean: 2033.0701077705655
reward_std: 801.7140592019887
reward_max: 3603.9138006834864
reward_min: 880.7641375048255
total_envstep_count: 14656738
total_train_sample_count: 11014978
total_episode_count: 33951
total_duration: 2990.4521547065156
[2023-06-29 12:41:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1985
train_sample_count: 1985
avg_envstep_per_episode: 248.125
avg_sample_per_episode: 248.125
avg_envstep_per_sec: 2535.006019016493
avg_train_sample_per_sec: 2535.006019016493
avg_episode_per_sec: 10.21664894313952
collect_time: 0.7830356161324307
reward_mean: 1970.1844067656407
reward_std: 963.6416802789878
reward_max: 3741.7214144418353
reward_min: 974.7886155868287
total_envstep_count: 14661042
total_train_sample_count: 11018563
total_episode_count: 33959
total_duration: 2991.235190322648
[2023-06-29 12:41:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 289.6
avg_sample_per_episode: 289.6
avg_envstep_per_sec: 2686.1268785491684
avg_train_sample_per_sec: 2686.1268785491684
avg_episode_per_sec: 9.275299994990222
collect_time: 0.5390661221416667
reward_mean: 2505.468024724555
reward_std: 732.1392005144925
reward_max: 3583.438688564193
reward_min: 1484.439762081504
total_envstep_count: 14665250
total_train_sample_count: 11022011
total_episode_count: 33964
total_duration: 2991.77425644479
[2023-06-29 12:41:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2706
train_sample_count: 2706
avg_envstep_per_episode: 300.6666666666667
avg_sample_per_episode: 300.6666666666667
avg_envstep_per_sec: 2622.772982010556
avg_train_sample_per_sec: 2622.772982010556
avg_episode_per_sec: 8.723191736177014
collect_time: 1.0317324520880355
reward_mean: 2479.68298800322
reward_std: 1121.620529971383
reward_max: 3597.6429380938985
reward_min: 291.01893929481776
total_envstep_count: 14669994
total_train_sample_count: 11025517
total_episode_count: 33973
total_duration: 2992.805988896878
[2023-06-29 12:41:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2052
train_sample_count: 2052
avg_envstep_per_episode: 342.0
avg_sample_per_episode: 342.0
avg_envstep_per_sec: 2557.557205304225
avg_train_sample_per_sec: 2557.557205304225
avg_episode_per_sec: 7.478237442410015
collect_time: 0.802328094849363
reward_mean: 2148.6052167164303
reward_std: 1052.2136620564693
reward_max: 3594.7206427460865
reward_min: 1022.0244490386868
total_envstep_count: 14674170
total_train_sample_count: 11028769
total_episode_count: 33979
total_duration: 2993.608316991727
[2023-06-29 12:41:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1998
train_sample_count: 1998
avg_envstep_per_episode: 199.8
avg_sample_per_episode: 199.8
avg_envstep_per_sec: 2738.7615470877545
avg_train_sample_per_sec: 2738.7615470877545
avg_episode_per_sec: 13.707515250689461
collect_time: 0.7295268192021176
reward_mean: 1681.5989204674993
reward_std: 1045.9178491360362
reward_max: 3614.3745606888283
reward_min: 619.2742336845796
total_envstep_count: 14678690
total_train_sample_count: 11032367
total_episode_count: 33989
total_duration: 2994.337843810929
[2023-06-29 12:41:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2699
train_sample_count: 2699
avg_envstep_per_episode: 269.9
avg_sample_per_episode: 269.9
avg_envstep_per_sec: 2713.7132292647584
avg_train_sample_per_sec: 2713.7132292647584
avg_episode_per_sec: 10.054513631955384
collect_time: 0.9945781930433583
reward_mean: 1955.6266054433413
reward_std: 832.7964262279029
reward_max: 3511.5639819398434
reward_min: 1044.1638426157074
total_envstep_count: 14682986
total_train_sample_count: 11035866
total_episode_count: 33999
total_duration: 2995.332422003972
[2023-06-29 12:41:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1666
train_sample_count: 1666
avg_envstep_per_episode: 277.6666666666667
avg_sample_per_episode: 277.6666666666667
avg_envstep_per_sec: 2472.412820620219
avg_train_sample_per_sec: 2472.412820620219
avg_episode_per_sec: 8.90424785337414
collect_time: 0.673835690425709
reward_mean: 2005.4118279537252
reward_std: 345.5485619547457
reward_max: 2544.8283219507916
reward_min: 1437.9167175335226
total_envstep_count: 14686762
total_train_sample_count: 11039132
total_episode_count: 34005
total_duration: 2996.006257694398
[2023-06-29 12:41:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2214
train_sample_count: 2214
avg_envstep_per_episode: 221.4
avg_sample_per_episode: 221.4
avg_envstep_per_sec: 2539.61342032182
avg_train_sample_per_sec: 2539.61342032182
avg_episode_per_sec: 11.470701988806775
collect_time: 0.8717862263144923
reward_mean: 1588.0191588451685
reward_std: 827.9088997560003
reward_max: 2676.704440037001
reward_min: 162.6207306706428
total_envstep_count: 14691066
total_train_sample_count: 11042546
total_episode_count: 34015
total_duration: 2996.878043920712
[2023-06-29 12:42:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2087
train_sample_count: 2087
avg_envstep_per_episode: 231.88888888888889
avg_sample_per_episode: 231.88888888888889
avg_envstep_per_sec: 2554.706035021926
avg_train_sample_per_sec: 2554.706035021926
avg_episode_per_sec: 11.016940256443378
collect_time: 0.8169237365825099
reward_mean: 1680.7782748416198
reward_std: 544.1545378207936
reward_max: 2692.8584132027313
reward_min: 844.5147232773463
total_envstep_count: 14695794
total_train_sample_count: 11045833
total_episode_count: 34024
total_duration: 2997.6949676572945
[2023-06-29 12:42:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2501
train_sample_count: 2501
avg_envstep_per_episode: 357.2857142857143
avg_sample_per_episode: 357.2857142857143
avg_envstep_per_sec: 2812.693325939232
avg_train_sample_per_sec: 2812.693325939232
avg_episode_per_sec: 7.872392355687576
collect_time: 0.8891833236617968
reward_mean: 2552.6224780438392
reward_std: 903.176137073742
reward_max: 3599.466138011947
reward_min: 1540.0331252858919
total_envstep_count: 14700506
total_train_sample_count: 11049134
total_episode_count: 34031
total_duration: 2998.584150980956
[2023-06-29 12:42:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2317
train_sample_count: 2317
avg_envstep_per_episode: 331.0
avg_sample_per_episode: 331.0
avg_envstep_per_sec: 2718.40244753025
avg_train_sample_per_sec: 2718.40244753025
avg_episode_per_sec: 8.212696216103474
collect_time: 0.8523388441270217
reward_mean: 2357.9349661916713
reward_std: 944.8050137654787
reward_max: 3634.1838668226524
reward_min: 969.5751008245182
total_envstep_count: 14706082
total_train_sample_count: 11052651
total_episode_count: 34038
total_duration: 2999.4364898250833
[2023-06-29 12:42:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1560
train_sample_count: 1560
avg_envstep_per_episode: 222.85714285714286
avg_sample_per_episode: 222.85714285714286
avg_envstep_per_sec: 2780.849215082461
avg_train_sample_per_sec: 2780.849215082461
avg_episode_per_sec: 12.478169554857196
collect_time: 0.5609797149514779
reward_mean: 2218.3611404455078
reward_std: 960.1040115361114
reward_max: 3758.0973614465815
reward_min: 1262.9188950633024
total_envstep_count: 14710818
total_train_sample_count: 11056211
total_episode_count: 34045
total_duration: 2999.9974695400347
[2023-06-29 12:42:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1669
train_sample_count: 1669
avg_envstep_per_episode: 238.42857142857142
avg_sample_per_episode: 238.42857142857142
avg_envstep_per_sec: 2650.0654466141
avg_train_sample_per_sec: 2650.0654466141
avg_episode_per_sec: 11.114714275793109
collect_time: 0.62979576679226
reward_mean: 2808.7004328702037
reward_std: 1057.6009240703956
reward_max: 3633.344685919964
reward_min: 1126.4756137249576
total_envstep_count: 14714994
total_train_sample_count: 11059480
total_episode_count: 34052
total_duration: 3000.6272653068268
[2023-06-29 12:42:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 367.25
avg_sample_per_episode: 367.25
avg_envstep_per_sec: 2829.1499674450984
avg_train_sample_per_sec: 2829.1499674450984
avg_episode_per_sec: 7.703607807883182
collect_time: 0.5192372327037156
reward_mean: 3156.975294363082
reward_std: 592.7833412155863
reward_max: 3637.9727274739425
reward_min: 2159.0816677731937
total_envstep_count: 14719482
total_train_sample_count: 11062949
total_episode_count: 34056
total_duration: 3001.1465025395305
[2023-06-29 12:42:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2350
train_sample_count: 2350
avg_envstep_per_episode: 293.75
avg_sample_per_episode: 293.75
avg_envstep_per_sec: 2792.885858546548
avg_train_sample_per_sec: 2792.885858546548
avg_episode_per_sec: 9.50769653973293
collect_time: 0.8414235736876725
reward_mean: 2860.064424341591
reward_std: 743.071650334825
reward_max: 3599.4074633871487
reward_min: 1757.1205038749108
total_envstep_count: 14723914
total_train_sample_count: 11066499
total_episode_count: 34064
total_duration: 3001.9879261132182
[2023-06-29 12:42:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 436
train_sample_count: 436
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2722.2867501988894
avg_train_sample_per_sec: 2722.2867501988894
avg_episode_per_sec: 12.487553899994905
collect_time: 0.16015946886129684
reward_mean: 1786.5706577718688
reward_std: 581.9483077628289
reward_max: 2368.5189655346976
reward_min: 1204.6223500090398
total_envstep_count: 14727402
total_train_sample_count: 11069735
total_episode_count: 34066
total_duration: 3002.1480855820796
[2023-06-29 12:42:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2333
train_sample_count: 2333
avg_envstep_per_episode: 212.0909090909091
avg_sample_per_episode: 212.0909090909091
avg_envstep_per_sec: 2614.9878157361254
avg_train_sample_per_sec: 2614.9878157361254
avg_episode_per_sec: 12.329561068622967
collect_time: 0.8921647687843068
reward_mean: 2328.1823664880753
reward_std: 1029.3216433700666
reward_max: 3682.7306574861805
reward_min: 701.5616123393451
total_envstep_count: 14732010
total_train_sample_count: 11073268
total_episode_count: 34077
total_duration: 3003.040250350864
[2023-06-29 12:42:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2300
train_sample_count: 2300
avg_envstep_per_episode: 255.55555555555554
avg_sample_per_episode: 255.55555555555554
avg_envstep_per_sec: 2694.062633505566
avg_train_sample_per_sec: 2694.062633505566
avg_episode_per_sec: 10.541984218065258
collect_time: 0.85372922343947
reward_mean: 1788.9426030536238
reward_std: 448.1668917853267
reward_max: 2378.705579622981
reward_min: 980.3779443109968
total_envstep_count: 14736514
total_train_sample_count: 11076768
total_episode_count: 34086
total_duration: 3003.8939795743036
[2023-06-29 12:42:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2785
train_sample_count: 2785
avg_envstep_per_episode: 232.08333333333334
avg_sample_per_episode: 232.08333333333334
avg_envstep_per_sec: 2700.5254287509765
avg_train_sample_per_sec: 2700.5254287509765
avg_episode_per_sec: 11.636016210058068
collect_time: 1.0312807908970862
reward_mean: 1577.616475674674
reward_std: 872.5434514318217
reward_max: 3702.58159492912
reward_min: 813.0705270496265
total_envstep_count: 14741298
total_train_sample_count: 11080353
total_episode_count: 34098
total_duration: 3004.9252603652008
[2023-06-29 12:42:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3244
train_sample_count: 3244
avg_envstep_per_episode: 270.3333333333333
avg_sample_per_episode: 270.3333333333333
avg_envstep_per_sec: 2712.7884465210986
avg_train_sample_per_sec: 2712.7884465210986
avg_episode_per_sec: 10.034975757784583
collect_time: 1.1958175375452262
reward_mean: 1589.2206370279628
reward_std: 701.9697148638884
reward_max: 2931.4929796176907
reward_min: 683.8265163825015
total_envstep_count: 14745922
total_train_sample_count: 11083597
total_episode_count: 34110
total_duration: 3006.121077902746
[2023-06-29 12:42:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1885
train_sample_count: 1885
avg_envstep_per_episode: 235.625
avg_sample_per_episode: 235.625
avg_envstep_per_sec: 2492.460869972225
avg_train_sample_per_sec: 2492.460869972225
avg_episode_per_sec: 10.578083267786631
collect_time: 0.7562806793516504
reward_mean: 1483.2333459328315
reward_std: 862.4238845177255
reward_max: 3337.8047807880475
reward_min: 692.5974528157259
total_envstep_count: 14750234
total_train_sample_count: 11087082
total_episode_count: 34118
total_duration: 3006.8773585820977
[2023-06-29 12:42:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3123
train_sample_count: 3123
avg_envstep_per_episode: 260.25
avg_sample_per_episode: 260.25
avg_envstep_per_sec: 2625.6990887537827
avg_train_sample_per_sec: 2625.6990887537827
avg_episode_per_sec: 10.089141551407426
collect_time: 1.189397525929846
reward_mean: 1741.829430451466
reward_std: 805.1230419131568
reward_max: 3152.977879681631
reward_min: 891.9743541590418
total_envstep_count: 14755298
total_train_sample_count: 11090605
total_episode_count: 34130
total_duration: 3008.0667561080277
[2023-06-29 12:42:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3196
train_sample_count: 3196
avg_envstep_per_episode: 319.6
avg_sample_per_episode: 319.6
avg_envstep_per_sec: 2555.1965716804507
avg_train_sample_per_sec: 2555.1965716804507
avg_episode_per_sec: 7.994983015270496
collect_time: 1.250784395776689
reward_mean: 1932.3981591937725
reward_std: 600.5726573570868
reward_max: 2998.704933304388
reward_min: 1253.8945043736667
total_envstep_count: 14760746
total_train_sample_count: 11094201
total_episode_count: 34140
total_duration: 3009.317540503804
[2023-06-29 12:42:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2805
train_sample_count: 2805
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2718.2420582915247
avg_train_sample_per_sec: 2718.2420582915247
avg_episode_per_sec: 10.659772777613822
collect_time: 1.0319169300775974
reward_mean: 1628.7856360144526
reward_std: 702.329776497731
reward_max: 3144.3430838639256
reward_min: 539.213041763452
total_envstep_count: 14765042
total_train_sample_count: 11097406
total_episode_count: 34151
total_duration: 3010.3494574338815
[2023-06-29 12:42:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2749
train_sample_count: 2749
avg_envstep_per_episode: 343.625
avg_sample_per_episode: 343.625
avg_envstep_per_sec: 2733.9829204817797
avg_train_sample_per_sec: 2733.9829204817797
avg_episode_per_sec: 7.956298058877497
collect_time: 1.0054927481096239
reward_mean: 1902.3450872182525
reward_std: 966.7485269648218
reward_max: 3554.867098336515
reward_min: 881.2319306110252
total_envstep_count: 14769586
total_train_sample_count: 11100955
total_episode_count: 34159
total_duration: 3011.354950181991
[2023-06-29 12:42:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2031
train_sample_count: 2031
avg_envstep_per_episode: 253.875
avg_sample_per_episode: 253.875
avg_envstep_per_sec: 2756.6026173021046
avg_train_sample_per_sec: 2756.6026173021046
avg_episode_per_sec: 10.858109767807404
collect_time: 0.7367764897458255
reward_mean: 1722.821956640014
reward_std: 812.4469154032814
reward_max: 3694.352558589719
reward_min: 830.4475833689476
total_envstep_count: 14774186
total_train_sample_count: 11104186
total_episode_count: 34167
total_duration: 3012.091726671737
[2023-06-29 12:42:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2049
train_sample_count: 2049
avg_envstep_per_episode: 227.66666666666666
avg_sample_per_episode: 227.66666666666666
avg_envstep_per_sec: 2470.000963697715
avg_train_sample_per_sec: 2470.000963697715
avg_episode_per_sec: 10.849198962069028
collect_time: 0.8295543322106823
reward_mean: 2043.8458661750094
reward_std: 773.6556949197446
reward_max: 3602.8524805067855
reward_min: 999.9873058223652
total_envstep_count: 14778162
total_train_sample_count: 11107435
total_episode_count: 34176
total_duration: 3012.9212810039476
[2023-06-29 12:43:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 2794.745608538391
avg_train_sample_per_sec: 2794.745608538391
avg_episode_per_sec: 14.632175960933985
collect_time: 0.3417126757735386
reward_mean: 1727.2322115527234
reward_std: 496.461993350615
reward_max: 2584.9480714697743
reward_min: 1233.2240521665071
total_envstep_count: 14782586
total_train_sample_count: 11110790
total_episode_count: 34181
total_duration: 3013.262993679721
[2023-06-29 12:43:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2917
train_sample_count: 2917
avg_envstep_per_episode: 265.1818181818182
avg_sample_per_episode: 265.1818181818182
avg_envstep_per_sec: 2801.2129708843277
avg_train_sample_per_sec: 2801.2129708843277
avg_episode_per_sec: 10.563367391061913
collect_time: 1.0413346040872855
reward_mean: 2357.9627595151114
reward_std: 1140.2292432022873
reward_max: 3662.4164846559606
reward_min: 919.4243712272607
total_envstep_count: 14787386
total_train_sample_count: 11114107
total_episode_count: 34192
total_duration: 3014.3043282838084
[2023-06-29 12:43:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2328
train_sample_count: 2328
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 2741.2049930722787
avg_train_sample_per_sec: 2741.2049930722787
avg_episode_per_sec: 9.419948429801646
collect_time: 0.8492615495314824
reward_mean: 1804.3694153459492
reward_std: 880.4040835033607
reward_max: 3590.075423731617
reward_min: 992.5875844615636
total_envstep_count: 14792378
total_train_sample_count: 11117635
total_episode_count: 34200
total_duration: 3015.15358983334
[2023-06-29 12:43:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2998
train_sample_count: 2998
avg_envstep_per_episode: 230.6153846153846
avg_sample_per_episode: 230.6153846153846
avg_envstep_per_sec: 2606.6795346864897
avg_train_sample_per_sec: 2606.6795346864897
avg_episode_per_sec: 11.303146748140215
collect_time: 1.1501221995670348
reward_mean: 1658.9708651379226
reward_std: 957.0626492731358
reward_max: 3615.4639845689194
reward_min: 695.2570807022246
total_envstep_count: 14796946
total_train_sample_count: 11121033
total_episode_count: 34213
total_duration: 3016.3037120329072
[2023-06-29 12:43:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2893
train_sample_count: 2893
avg_envstep_per_episode: 222.53846153846155
avg_sample_per_episode: 222.53846153846155
avg_envstep_per_sec: 2611.9329416257474
avg_train_sample_per_sec: 2611.9329416257474
avg_episode_per_sec: 11.736995589745842
collect_time: 1.1076088340152055
reward_mean: 1258.8340290369968
reward_std: 289.4184324636275
reward_max: 1818.921926100421
reward_min: 851.7274620904932
total_envstep_count: 14801554
total_train_sample_count: 11124326
total_episode_count: 34226
total_duration: 3017.4113208669223
[2023-06-29 12:43:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1712
train_sample_count: 1712
avg_envstep_per_episode: 244.57142857142858
avg_sample_per_episode: 244.57142857142858
avg_envstep_per_sec: 2766.385726839882
avg_train_sample_per_sec: 2766.385726839882
avg_episode_per_sec: 11.311156593387368
collect_time: 0.6188580223610626
reward_mean: 1565.0832019676948
reward_std: 875.079456780564
reward_max: 3609.7658695241234
reward_min: 907.2686775488457
total_envstep_count: 14806178
total_train_sample_count: 11127638
total_episode_count: 34233
total_duration: 3018.0301788892834
[2023-06-29 12:43:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2793
train_sample_count: 2793
avg_envstep_per_episode: 214.84615384615384
avg_sample_per_episode: 214.84615384615384
avg_envstep_per_sec: 2744.472437336465
avg_train_sample_per_sec: 2744.472437336465
avg_episode_per_sec: 12.774128781014698
collect_time: 1.0176819275002926
reward_mean: 1729.0608903763437
reward_std: 873.820776829973
reward_max: 3578.5516700185617
reward_min: 1006.2228621226894
total_envstep_count: 14811050
total_train_sample_count: 11131231
total_episode_count: 34246
total_duration: 3019.0478608167837
[2023-06-29 12:43:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1020
train_sample_count: 1020
avg_envstep_per_episode: 340.0
avg_sample_per_episode: 340.0
avg_envstep_per_sec: 2787.3029726964032
avg_train_sample_per_sec: 2787.3029726964032
avg_episode_per_sec: 8.197949919695304
collect_time: 0.3659451484074816
reward_mean: 2347.540489071566
reward_std: 1057.549156096256
reward_max: 3672.6252950906955
reward_min: 1084.391709986298
total_envstep_count: 14815090
total_train_sample_count: 11134651
total_episode_count: 34249
total_duration: 3019.413805965191
[2023-06-29 12:43:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2194
train_sample_count: 2194
avg_envstep_per_episode: 219.4
avg_sample_per_episode: 219.4
avg_envstep_per_sec: 2677.34526024862
avg_train_sample_per_sec: 2677.34526024862
avg_episode_per_sec: 12.203032179802278
collect_time: 0.8194684610068795
reward_mean: 2369.5476623881978
reward_std: 983.4937884029522
reward_max: 3614.0231925751978
reward_min: 998.2199493370757
total_envstep_count: 14819410
total_train_sample_count: 11138045
total_episode_count: 34259
total_duration: 3020.233274426198
[2023-06-29 12:43:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3545
train_sample_count: 3545
avg_envstep_per_episode: 322.27272727272725
avg_sample_per_episode: 322.27272727272725
avg_envstep_per_sec: 2656.4046963131627
avg_train_sample_per_sec: 2656.4046963131627
avg_episode_per_sec: 8.242722611973143
collect_time: 1.334510515253991
reward_mean: 1919.2730596768
reward_std: 845.6814946741622
reward_max: 3616.7513181289087
reward_min: 950.538209668072
total_envstep_count: 14824050
total_train_sample_count: 11141590
total_episode_count: 34270
total_duration: 3021.567784941452
[2023-06-29 12:43:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3052
train_sample_count: 3052
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 2805.007262863847
avg_train_sample_per_sec: 2805.007262863847
avg_episode_per_sec: 11.028862108245795
collect_time: 1.0880542237469928
reward_mean: 1261.6109827956507
reward_std: 323.0210810765689
reward_max: 1729.789799658522
reward_min: 545.048158710968
total_envstep_count: 14829114
total_train_sample_count: 11145042
total_episode_count: 34282
total_duration: 3022.655839165199
[2023-06-29 12:43:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2183
train_sample_count: 2183
avg_envstep_per_episode: 198.45454545454547
avg_sample_per_episode: 198.45454545454547
avg_envstep_per_sec: 2720.694394348532
avg_train_sample_per_sec: 2720.694394348532
avg_episode_per_sec: 13.709408308673318
collect_time: 0.8023686910718679
reward_mean: 1267.262951305489
reward_std: 292.4920230505551
reward_max: 1749.695890347032
reward_min: 820.4588715677986
total_envstep_count: 14833682
total_train_sample_count: 11148425
total_episode_count: 34293
total_duration: 3023.4582078562707
[2023-06-29 12:43:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3347
train_sample_count: 3347
avg_envstep_per_episode: 278.9166666666667
avg_sample_per_episode: 278.9166666666667
avg_envstep_per_sec: 2652.2582354120855
avg_train_sample_per_sec: 2652.2582354120855
avg_episode_per_sec: 9.509142164608614
collect_time: 1.2619434847300874
reward_mean: 1860.2379919877642
reward_std: 891.4859891850043
reward_max: 3663.9379532172184
reward_min: 902.2055332239323
total_envstep_count: 14838138
total_train_sample_count: 11151772
total_episode_count: 34305
total_duration: 3024.720151341001
[2023-06-29 12:43:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2659
train_sample_count: 2659
avg_envstep_per_episode: 241.72727272727272
avg_sample_per_episode: 241.72727272727272
avg_envstep_per_sec: 2545.1016362532346
avg_train_sample_per_sec: 2545.1016362532346
avg_episode_per_sec: 10.528814591495141
collect_time: 1.0447519903033973
reward_mean: 1218.3003961495947
reward_std: 227.85130810379366
reward_max: 1590.0847504101064
reward_min: 944.8762103117199
total_envstep_count: 14842634
total_train_sample_count: 11155231
total_episode_count: 34316
total_duration: 3025.764903331304
[2023-06-29 12:43:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3155
train_sample_count: 3155
avg_envstep_per_episode: 286.8181818181818
avg_sample_per_episode: 286.8181818181818
avg_envstep_per_sec: 2728.3174326981934
avg_train_sample_per_sec: 2728.3174326981934
avg_episode_per_sec: 9.512358719391484
collect_time: 1.1563903679931535
reward_mean: 1717.749496511308
reward_std: 764.1524640755016
reward_max: 3261.616764767841
reward_min: 851.0739383815527
total_envstep_count: 14847810
total_train_sample_count: 11158786
total_episode_count: 34327
total_duration: 3026.921293699297
[2023-06-29 12:43:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2719
train_sample_count: 2719
avg_envstep_per_episode: 226.58333333333334
avg_sample_per_episode: 226.58333333333334
avg_envstep_per_sec: 2741.5625491324267
avg_train_sample_per_sec: 2741.5625491324267
avg_episode_per_sec: 12.099577267226598
collect_time: 0.991770186261274
reward_mean: 1391.1309409454536
reward_std: 346.697456505144
reward_max: 2013.5672467786321
reward_min: 989.4956483495613
total_envstep_count: 14852194
total_train_sample_count: 11162305
total_episode_count: 34339
total_duration: 3027.9130638855586
[2023-06-29 12:43:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2727
train_sample_count: 2727
avg_envstep_per_episode: 227.25
avg_sample_per_episode: 227.25
avg_envstep_per_sec: 2616.984606251362
avg_train_sample_per_sec: 2616.984606251362
avg_episode_per_sec: 11.515883855891582
collect_time: 1.0420389915499835
reward_mean: 1383.5708691007123
reward_std: 770.4693829191499
reward_max: 3576.005077297837
reward_min: 520.065824207207
total_envstep_count: 14857258
total_train_sample_count: 11165832
total_episode_count: 34351
total_duration: 3028.9551028771084
[2023-06-29 12:43:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3470
train_sample_count: 3470
avg_envstep_per_episode: 247.85714285714286
avg_sample_per_episode: 247.85714285714286
avg_envstep_per_sec: 2591.7918375886065
avg_train_sample_per_sec: 2591.7918375886065
avg_episode_per_sec: 10.45679703926239
collect_time: 1.3388420897368343
reward_mean: 1518.051226432977
reward_std: 559.2473799809987
reward_max: 2403.3608468332286
reward_min: 744.5433838803815
total_envstep_count: 14861418
total_train_sample_count: 11169302
total_episode_count: 34365
total_duration: 3030.293944966845
[2023-06-29 12:43:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 264.72727272727275
avg_sample_per_episode: 264.72727272727275
avg_envstep_per_sec: 2743.3968390385244
avg_train_sample_per_sec: 2743.3968390385244
avg_episode_per_sec: 10.363106191422997
collect_time: 1.0614578097350895
reward_mean: 1193.0985544263146
reward_std: 313.3870900792785
reward_max: 1951.4578476565919
reward_min: 835.1818916912869
total_envstep_count: 14866106
total_train_sample_count: 11172614
total_episode_count: 34376
total_duration: 3031.3554027765804
[2023-06-29 12:43:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3067
train_sample_count: 3067
avg_envstep_per_episode: 219.07142857142858
avg_sample_per_episode: 219.07142857142858
avg_envstep_per_sec: 2801.455179037234
avg_train_sample_per_sec: 2801.455179037234
avg_episode_per_sec: 12.787861919309186
collect_time: 1.0947881739996372
reward_mean: 1257.9415173598136
reward_std: 517.9620240649883
reward_max: 2846.8105386076577
reward_min: 524.9972948898286
total_envstep_count: 14870666
total_train_sample_count: 11176081
total_episode_count: 34390
total_duration: 3032.4501909505802
[2023-06-29 12:44:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3008
train_sample_count: 3008
avg_envstep_per_episode: 250.66666666666666
avg_sample_per_episode: 250.66666666666666
avg_envstep_per_sec: 2633.8986331057185
avg_train_sample_per_sec: 2633.8986331057185
avg_episode_per_sec: 10.507574334198345
collect_time: 1.1420333198066799
reward_mean: 1324.8548278093492
reward_std: 392.771007049541
reward_max: 2246.625527686619
reward_min: 958.951190548796
total_envstep_count: 14874962
total_train_sample_count: 11179489
total_episode_count: 34402
total_duration: 3033.592224270387
[2023-06-29 12:44:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2603
train_sample_count: 2603
avg_envstep_per_episode: 236.63636363636363
avg_sample_per_episode: 236.63636363636363
avg_envstep_per_sec: 2673.717549422429
avg_train_sample_per_sec: 2673.717549422429
avg_episode_per_sec: 11.298844811235773
collect_time: 0.9735508526554328
reward_mean: 1296.3553140714923
reward_std: 648.1899902883573
reward_max: 3331.794505663297
reward_min: 1007.5012084222797
total_envstep_count: 14879330
total_train_sample_count: 11182892
total_episode_count: 34413
total_duration: 3034.5657751230424
[2023-06-29 12:44:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3349
train_sample_count: 3349
avg_envstep_per_episode: 239.21428571428572
avg_sample_per_episode: 239.21428571428572
avg_envstep_per_sec: 2628.654093577184
avg_train_sample_per_sec: 2628.654093577184
avg_episode_per_sec: 10.988700301606622
collect_time: 1.2740360202519223
reward_mean: 1377.0296393096073
reward_std: 533.3517192308692
reward_max: 2717.6122915548262
reward_min: 888.6797883003084
total_envstep_count: 14883810
total_train_sample_count: 11186241
total_episode_count: 34427
total_duration: 3035.8398111432944
[2023-06-29 12:44:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 225.36363636363637
avg_sample_per_episode: 225.36363636363637
avg_envstep_per_sec: 2819.201813198435
avg_train_sample_per_sec: 2819.201813198435
avg_episode_per_sec: 12.509568352231863
collect_time: 0.87932690323703
reward_mean: 1206.2269151080652
reward_std: 329.09411053278774
reward_max: 1851.396112626725
reward_min: 891.7078380549407
total_envstep_count: 14888162
total_train_sample_count: 11189520
total_episode_count: 34438
total_duration: 3036.7191380465315
[2023-06-29 12:44:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3582
train_sample_count: 3582
avg_envstep_per_episode: 223.875
avg_sample_per_episode: 223.875
avg_envstep_per_sec: 2640.6629661542124
avg_train_sample_per_sec: 2640.6629661542124
avg_episode_per_sec: 11.795256130225404
collect_time: 1.3564775383723902
reward_mean: 1242.860860910624
reward_std: 513.0939332615391
reward_max: 2943.54533776287
reward_min: 870.8709178595599
total_envstep_count: 14892570
total_train_sample_count: 11193102
total_episode_count: 34454
total_duration: 3038.075615584904
[2023-06-29 12:44:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2854
train_sample_count: 2854
avg_envstep_per_episode: 285.4
avg_sample_per_episode: 285.4
avg_envstep_per_sec: 2567.810957009207
avg_train_sample_per_sec: 2567.810957009207
avg_episode_per_sec: 8.997235308371433
collect_time: 1.1114525359468534
reward_mean: 1341.7339997370714
reward_std: 561.8538138891973
reward_max: 2683.570402267967
reward_min: 934.0853156280342
total_envstep_count: 14897018
total_train_sample_count: 11196356
total_episode_count: 34464
total_duration: 3039.1870681208507
[2023-06-29 12:44:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2851
train_sample_count: 2851
avg_envstep_per_episode: 237.58333333333334
avg_sample_per_episode: 237.58333333333334
avg_envstep_per_sec: 2557.697855082279
avg_train_sample_per_sec: 2557.697855082279
avg_episode_per_sec: 10.765476766393318
collect_time: 1.1146742741074416
reward_mean: 1295.805214768244
reward_std: 354.32893392226725
reward_max: 2027.8672291925257
reward_min: 928.6386198756911
total_envstep_count: 14901202
total_train_sample_count: 11199607
total_episode_count: 34476
total_duration: 3040.301742394958
[2023-06-29 12:44:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2905
train_sample_count: 2905
avg_envstep_per_episode: 223.46153846153845
avg_sample_per_episode: 223.46153846153845
avg_envstep_per_sec: 2721.10686649034
avg_train_sample_per_sec: 2721.10686649034
avg_episode_per_sec: 12.177070314758836
collect_time: 1.0675802688142284
reward_mean: 1216.3293845322637
reward_std: 614.1379130525411
reward_max: 3281.584473912731
reward_min: 846.3784290103684
total_envstep_count: 14905786
total_train_sample_count: 11202912
total_episode_count: 34489
total_duration: 3041.3693226637724
[2023-06-29 12:44:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 223.06666666666666
avg_sample_per_episode: 223.06666666666666
avg_envstep_per_sec: 2722.084900178966
avg_train_sample_per_sec: 2722.084900178966
avg_episode_per_sec: 12.203010610485503
collect_time: 1.2292048641759903
reward_mean: 1245.2325943190174
reward_std: 539.2997539036066
reward_max: 2958.9880699259957
reward_min: 782.8101186109226
total_envstep_count: 14909842
total_train_sample_count: 11206258
total_episode_count: 34504
total_duration: 3042.5985275279486
[2023-06-29 12:44:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3069
train_sample_count: 3069
avg_envstep_per_episode: 306.9
avg_sample_per_episode: 306.9
avg_envstep_per_sec: 2553.593492305679
avg_train_sample_per_sec: 2553.593492305679
avg_episode_per_sec: 8.32060440633978
collect_time: 1.201835769572295
reward_mean: 1382.7455400118088
reward_std: 516.9134145681173
reward_max: 2259.8547286433086
reward_min: 814.5138126327705
total_envstep_count: 14914306
total_train_sample_count: 11209727
total_episode_count: 34514
total_duration: 3043.800363297521
[2023-06-29 12:44:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3143
train_sample_count: 3143
avg_envstep_per_episode: 241.76923076923077
avg_sample_per_episode: 241.76923076923077
avg_envstep_per_sec: 2592.79322050958
avg_train_sample_per_sec: 2592.79322050958
avg_episode_per_sec: 10.724248128101985
collect_time: 1.2122061933586374
reward_mean: 1289.8532569844206
reward_std: 290.914489936429
reward_max: 1952.536386794571
reward_min: 869.2675393436268
total_envstep_count: 14918890
total_train_sample_count: 11213270
total_episode_count: 34527
total_duration: 3045.0125694908797
[2023-06-29 12:44:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 235.21428571428572
avg_sample_per_episode: 235.21428571428572
avg_envstep_per_sec: 2755.452067040419
avg_train_sample_per_sec: 2755.452067040419
avg_episode_per_sec: 11.714645896922523
collect_time: 1.1950852055782453
reward_mean: 1234.825644296688
reward_std: 369.21999749812943
reward_max: 1945.9173694764745
reward_min: 804.6951393875662
total_envstep_count: 14923346
total_train_sample_count: 11216563
total_episode_count: 34541
total_duration: 3046.207654696458
[2023-06-29 12:44:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2817
train_sample_count: 2817
avg_envstep_per_episode: 234.75
avg_sample_per_episode: 234.75
avg_envstep_per_sec: 2575.9008309992073
avg_train_sample_per_sec: 2575.9008309992073
avg_episode_per_sec: 10.97295348668459
collect_time: 1.093598001172766
reward_mean: 1213.6204736403017
reward_std: 310.2010021898301
reward_max: 1866.7383029979926
reward_min: 942.2886916465503
total_envstep_count: 14927890
total_train_sample_count: 11219780
total_episode_count: 34553
total_duration: 3047.301252697631
[2023-06-29 12:44:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3350
train_sample_count: 3350
avg_envstep_per_episode: 239.28571428571428
avg_sample_per_episode: 239.28571428571428
avg_envstep_per_sec: 2578.9253549496248
avg_train_sample_per_sec: 2578.9253549496248
avg_episode_per_sec: 10.777598498296939
collect_time: 1.298990679807961
reward_mean: 1310.0112751240342
reward_std: 622.7486461281212
reward_max: 3313.3514840460007
reward_min: 771.6860174725504
total_envstep_count: 14933018
total_train_sample_count: 11223130
total_episode_count: 34567
total_duration: 3048.600243377439
[2023-06-29 12:44:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3532
train_sample_count: 3532
avg_envstep_per_episode: 235.46666666666667
avg_sample_per_episode: 235.46666666666667
avg_envstep_per_sec: 2592.959396712482
avg_train_sample_per_sec: 2592.959396712482
avg_episode_per_sec: 11.012001967918241
collect_time: 1.3621501379767431
reward_mean: 1296.0005066348779
reward_std: 336.5419127041093
reward_max: 2056.610624549077
reward_min: 651.0786896163036
total_envstep_count: 14937890
total_train_sample_count: 11226662
total_episode_count: 34582
total_duration: 3049.9623935154154
[2023-06-29 12:44:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2873
train_sample_count: 2873
avg_envstep_per_episode: 261.1818181818182
avg_sample_per_episode: 261.1818181818182
avg_envstep_per_sec: 2717.6891194421523
avg_train_sample_per_sec: 2717.6891194421523
avg_episode_per_sec: 10.405353398490663
collect_time: 1.0571481408402326
reward_mean: 1404.5793657012844
reward_std: 438.8864514524083
reward_max: 2251.849201052262
reward_min: 973.3305075709842
total_envstep_count: 14942322
total_train_sample_count: 11229935
total_episode_count: 34593
total_duration: 3051.0195416562556
[2023-06-29 12:44:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3396
train_sample_count: 3396
avg_envstep_per_episode: 283.0
avg_sample_per_episode: 283.0
avg_envstep_per_sec: 2780.702205546554
avg_train_sample_per_sec: 2780.702205546554
avg_episode_per_sec: 9.825802846454254
collect_time: 1.2212742498014122
reward_mean: 1523.622599872586
reward_std: 566.8958649742445
reward_max: 3068.385724390844
reward_min: 789.660825885249
total_envstep_count: 14946850
total_train_sample_count: 11233331
total_episode_count: 34605
total_duration: 3052.240815906057
[2023-06-29 12:44:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2515
train_sample_count: 2515
avg_envstep_per_episode: 279.44444444444446
avg_sample_per_episode: 279.44444444444446
avg_envstep_per_sec: 2575.0648930141865
avg_train_sample_per_sec: 2575.0648930141865
avg_episode_per_sec: 9.214943951144205
collect_time: 0.9766744157876819
reward_mean: 1437.0932162680551
reward_std: 385.42520532368985
reward_max: 1916.9828185742097
reward_min: 720.5340446181395
total_envstep_count: 14951410
total_train_sample_count: 11236646
total_episode_count: 34614
total_duration: 3053.2174903218447
[2023-06-29 12:44:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3505
train_sample_count: 3505
avg_envstep_per_episode: 318.6363636363636
avg_sample_per_episode: 318.6363636363636
avg_envstep_per_sec: 2637.4983033053973
avg_train_sample_per_sec: 2637.4983033053973
avg_episode_per_sec: 8.277455445466297
collect_time: 1.3289108074903486
reward_mean: 1886.4990422567148
reward_std: 563.9936390755244
reward_max: 2967.2420965371634
reward_min: 981.5164946776143
total_envstep_count: 14956106
total_train_sample_count: 11240151
total_episode_count: 34625
total_duration: 3054.546401129335
[2023-06-29 12:45:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2863
train_sample_count: 2863
avg_envstep_per_episode: 286.3
avg_sample_per_episode: 286.3
avg_envstep_per_sec: 2625.5968717804076
avg_train_sample_per_sec: 2625.5968717804076
avg_episode_per_sec: 9.170788933916898
collect_time: 1.090418727555312
reward_mean: 1460.0880404786976
reward_std: 732.7378583417499
reward_max: 3283.8766674389412
reward_min: 701.3365310664776
total_envstep_count: 14960746
total_train_sample_count: 11243414
total_episode_count: 34635
total_duration: 3055.6368198568907
[2023-06-29 12:45:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3062
train_sample_count: 3062
avg_envstep_per_episode: 278.3636363636364
avg_sample_per_episode: 278.3636363636364
avg_envstep_per_sec: 2600.9797181024055
avg_train_sample_per_sec: 2600.9797181024055
avg_episode_per_sec: 9.343820019309751
collect_time: 1.1772487031286583
reward_mean: 1637.3465766400861
reward_std: 469.58326555499735
reward_max: 2545.998464873889
reward_min: 1103.852738762749
total_envstep_count: 14965250
total_train_sample_count: 11246876
total_episode_count: 34646
total_duration: 3056.814068560019
[2023-06-29 12:45:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2767
train_sample_count: 2767
avg_envstep_per_episode: 251.54545454545453
avg_sample_per_episode: 251.54545454545453
avg_envstep_per_sec: 2764.491832391183
avg_train_sample_per_sec: 2764.491832391183
avg_episode_per_sec: 10.990028968667515
collect_time: 1.0009072798043492
reward_mean: 1329.2732729225627
reward_std: 326.92490727465196
reward_max: 1941.752530237399
reward_min: 852.8520799775628
total_envstep_count: 14969986
total_train_sample_count: 11250443
total_episode_count: 34657
total_duration: 3057.8149758398235
[2023-06-29 12:45:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2911
train_sample_count: 2911
avg_envstep_per_episode: 223.92307692307693
avg_sample_per_episode: 223.92307692307693
avg_envstep_per_sec: 2615.2497124938645
avg_train_sample_per_sec: 2615.2497124938645
avg_episode_per_sec: 11.679232656276277
collect_time: 1.1130868253586814
reward_mean: 1426.6520129140422
reward_std: 558.6386549231406
reward_max: 2821.957774381673
reward_min: 907.9331346697885
total_envstep_count: 14974570
total_train_sample_count: 11253754
total_episode_count: 34670
total_duration: 3058.928062665182
[2023-06-29 12:45:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3502
train_sample_count: 3502
avg_envstep_per_episode: 233.46666666666667
avg_sample_per_episode: 233.46666666666667
avg_envstep_per_sec: 2646.7885293751237
avg_train_sample_per_sec: 2646.7885293751237
avg_episode_per_sec: 11.33690118236061
collect_time: 1.323112882322632
reward_mean: 1232.6089274406015
reward_std: 548.7848348310869
reward_max: 2794.2277875484824
reward_min: 426.8513673275497
total_envstep_count: 14979258
total_train_sample_count: 11257256
total_episode_count: 34685
total_duration: 3060.2511755475048
[2023-06-29 12:45:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2828
train_sample_count: 2828
avg_envstep_per_episode: 235.66666666666666
avg_sample_per_episode: 235.66666666666666
avg_envstep_per_sec: 2568.8062243928207
avg_train_sample_per_sec: 2568.8062243928207
avg_episode_per_sec: 10.900167854566424
collect_time: 1.1009004778740927
reward_mean: 1175.529726761253
reward_std: 458.49145321235716
reward_max: 2310.2734945854118
reward_min: 441.6154395511764
total_envstep_count: 14983370
total_train_sample_count: 11260484
total_episode_count: 34697
total_duration: 3061.3520760253787
[2023-06-29 12:45:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3376
train_sample_count: 3376
avg_envstep_per_episode: 259.6923076923077
avg_sample_per_episode: 259.6923076923077
avg_envstep_per_sec: 2594.543735429921
avg_train_sample_per_sec: 2594.543735429921
avg_episode_per_sec: 9.990837843776356
collect_time: 1.301192172596231
reward_mean: 1311.4903800623385
reward_std: 451.10937667003765
reward_max: 2356.6062743271386
reward_min: 713.567325202016
total_envstep_count: 14987938
total_train_sample_count: 11263860
total_episode_count: 34710
total_duration: 3062.6532681979747
[2023-06-29 12:45:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 236.91666666666666
avg_sample_per_episode: 236.91666666666666
avg_envstep_per_sec: 2717.24469053636
avg_train_sample_per_sec: 2717.24469053636
avg_episode_per_sec: 11.469200241447878
collect_time: 1.0462804508926347
reward_mean: 1229.466396132087
reward_std: 503.75563717305783
reward_max: 2542.9528462388216
reward_min: 413.2160711981346
total_envstep_count: 14992610
total_train_sample_count: 11267103
total_episode_count: 34722
total_duration: 3063.699548648867
[2023-06-29 12:45:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 204.0
avg_sample_per_episode: 204.0
avg_envstep_per_sec: 2529.288331975359
avg_train_sample_per_sec: 2529.288331975359
avg_episode_per_sec: 12.398472215565485
collect_time: 0.9678611841332169
reward_mean: 1327.8396963883852
reward_std: 364.1625995363949
reward_max: 2408.871090184832
reward_min: 985.9315210045021
total_envstep_count: 14997090
total_train_sample_count: 11270351
total_episode_count: 34734
total_duration: 3064.6674098330004
[2023-06-29 12:45:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2472
train_sample_count: 2472
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 2702.0446097568765
avg_train_sample_per_sec: 2702.0446097568765
avg_episode_per_sec: 13.11672140658678
collect_time: 0.9148627639506013
reward_mean: 1386.2258247711861
reward_std: 437.96879799445725
reward_max: 2187.8275686221846
reward_min: 786.077176352788
total_envstep_count: 15001642
total_train_sample_count: 11273623
total_episode_count: 34746
total_duration: 3065.582272596951
[2023-06-29 12:45:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3272
train_sample_count: 3272
avg_envstep_per_episode: 251.69230769230768
avg_sample_per_episode: 251.69230769230768
avg_envstep_per_sec: 2782.503513901226
avg_train_sample_per_sec: 2782.503513901226
avg_episode_per_sec: 11.05517899777382
collect_time: 1.175919449392706
reward_mean: 1517.6606126503998
reward_std: 535.133561432335
reward_max: 2309.8382702056006
reward_min: 682.3987553973351
total_envstep_count: 15006138
total_train_sample_count: 11276895
total_episode_count: 34759
total_duration: 3066.7581920463435
[2023-06-29 12:45:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 284.9
avg_sample_per_episode: 284.9
avg_envstep_per_sec: 2668.043406687215
avg_train_sample_per_sec: 2668.043406687215
avg_episode_per_sec: 9.364841722313846
collect_time: 1.067823706638068
reward_mean: 1521.2044966721448
reward_std: 384.1059001620323
reward_max: 2399.3993720041244
reward_min: 1199.2263426446834
total_envstep_count: 15010618
total_train_sample_count: 11280144
total_episode_count: 34769
total_duration: 3067.8260157529817
[2023-06-29 12:45:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1698
train_sample_count: 1698
avg_envstep_per_episode: 212.25
avg_sample_per_episode: 212.25
avg_envstep_per_sec: 2469.002690623631
avg_train_sample_per_sec: 2469.002690623631
avg_episode_per_sec: 11.632521510594257
collect_time: 0.6877270755711943
reward_mean: 1405.028520546481
reward_std: 320.069242444646
reward_max: 1830.5708986205987
reward_min: 987.9755628019358
total_envstep_count: 15014810
total_train_sample_count: 11283442
total_episode_count: 34777
total_duration: 3068.513742828553
[2023-06-29 12:45:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2702
train_sample_count: 2702
avg_envstep_per_episode: 245.63636363636363
avg_sample_per_episode: 245.63636363636363
avg_envstep_per_sec: 2751.1581486047717
avg_train_sample_per_sec: 2751.1581486047717
avg_episode_per_sec: 11.200125697502772
collect_time: 0.9821318346858025
reward_mean: 1840.7489913888787
reward_std: 719.1289323365177
reward_max: 3583.2281350596463
reward_min: 1054.4716748502426
total_envstep_count: 15019666
total_train_sample_count: 11286944
total_episode_count: 34788
total_duration: 3069.4958746632387
[2023-06-29 12:45:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 253.66666666666666
avg_sample_per_episode: 253.66666666666666
avg_envstep_per_sec: 2823.2332168809507
avg_train_sample_per_sec: 2823.2332168809507
avg_episode_per_sec: 11.12969730702083
collect_time: 1.0781964386785403
reward_mean: 1603.0875700349586
reward_std: 413.6859044715061
reward_max: 2247.259139681978
reward_min: 970.0123813783254
total_envstep_count: 15024922
total_train_sample_count: 11290388
total_episode_count: 34800
total_duration: 3070.574071101917
[2023-06-29 12:45:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1569
train_sample_count: 1569
avg_envstep_per_episode: 224.14285714285714
avg_sample_per_episode: 224.14285714285714
avg_envstep_per_sec: 2800.8030260291844
avg_train_sample_per_sec: 2800.8030260291844
avg_episode_per_sec: 12.495615794903946
collect_time: 0.5601964813014491
reward_mean: 1643.5822396762248
reward_std: 375.15540376031726
reward_max: 2322.440760960702
reward_min: 1146.4338668933212
total_envstep_count: 15029370
total_train_sample_count: 11293957
total_episode_count: 34807
total_duration: 3071.1342675832184
[2023-06-29 12:45:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2048
train_sample_count: 2048
avg_envstep_per_episode: 227.55555555555554
avg_sample_per_episode: 227.55555555555554
avg_envstep_per_sec: 2428.7111255751915
avg_train_sample_per_sec: 2428.7111255751915
avg_episode_per_sec: 10.673046938562853
collect_time: 0.8432456122236325
reward_mean: 2300.5039831502936
reward_std: 901.6161221243457
reward_max: 3640.2320979716947
reward_min: 1053.1887523626185
total_envstep_count: 15033234
total_train_sample_count: 11297205
total_episode_count: 34816
total_duration: 3071.977513195442
[2023-06-29 12:45:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3136
train_sample_count: 3136
avg_envstep_per_episode: 285.09090909090907
avg_sample_per_episode: 285.09090909090907
avg_envstep_per_sec: 2585.15207267221
avg_train_sample_per_sec: 2585.15207267221
avg_episode_per_sec: 9.067816581439512
collect_time: 1.213081440411508
reward_mean: 1682.7641669325865
reward_std: 371.3088213674497
reward_max: 2291.456015780114
reward_min: 1015.1403401183454
total_envstep_count: 15038842
total_train_sample_count: 11300741
total_episode_count: 34827
total_duration: 3073.1905946358534
[2023-06-29 12:45:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2429
train_sample_count: 2429
avg_envstep_per_episode: 242.9
avg_sample_per_episode: 242.9
avg_envstep_per_sec: 2516.906101744012
avg_train_sample_per_sec: 2516.906101744012
avg_episode_per_sec: 10.36190243616308
collect_time: 0.9650737460236993
reward_mean: 1824.9822534725395
reward_std: 615.7313071110431
reward_max: 2876.7682301602454
reward_min: 1003.9471627948634
total_envstep_count: 15043034
total_train_sample_count: 11303970
total_episode_count: 34837
total_duration: 3074.155668381877
[2023-06-29 12:45:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 232.0
avg_sample_per_episode: 232.0
avg_envstep_per_sec: 2726.1818800616306
avg_train_sample_per_sec: 2726.1818800616306
avg_episode_per_sec: 11.750783965782892
collect_time: 0.5106042301068082
reward_mean: 1754.3372404166264
reward_std: 534.0062858448473
reward_max: 2320.341688968841
reward_min: 854.8458395363964
total_envstep_count: 15047290
total_train_sample_count: 11307362
total_episode_count: 34843
total_duration: 3074.666272611984
[2023-06-29 12:46:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 228.30769230769232
avg_sample_per_episode: 228.30769230769232
avg_envstep_per_sec: 2563.743104658074
avg_train_sample_per_sec: 2563.743104658074
avg_episode_per_sec: 11.229333005577818
collect_time: 1.157682294535451
reward_mean: 1703.4216683533368
reward_std: 968.96270585983
reward_max: 3598.5419420299972
reward_min: 588.4951195920456
total_envstep_count: 15052130
total_train_sample_count: 11310730
total_episode_count: 34856
total_duration: 3075.8239549065192
[2023-06-29 12:46:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3557
train_sample_count: 3557
avg_envstep_per_episode: 237.13333333333333
avg_sample_per_episode: 237.13333333333333
avg_envstep_per_sec: 2605.850197531856
avg_train_sample_per_sec: 2605.850197531856
avg_episode_per_sec: 10.988966253297114
collect_time: 1.3650055568693207
reward_mean: 1335.9263086046726
reward_std: 370.22887422861254
reward_max: 1962.4181730799828
reward_min: 832.0076858825341
total_envstep_count: 15056794
total_train_sample_count: 11314287
total_episode_count: 34871
total_duration: 3077.1889604633884
[2023-06-29 12:46:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 276.72727272727275
avg_sample_per_episode: 276.72727272727275
avg_envstep_per_sec: 2627.653485930022
avg_train_sample_per_sec: 2627.653485930022
avg_episode_per_sec: 9.495462662690617
collect_time: 1.1584480283642187
reward_mean: 1407.877129991937
reward_std: 474.97138525818315
reward_max: 2255.189959903242
reward_min: 865.2242680383422
total_envstep_count: 15061578
total_train_sample_count: 11317731
total_episode_count: 34882
total_duration: 3078.3474084917525
[2023-06-29 12:46:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1740
train_sample_count: 1740
avg_envstep_per_episode: 217.5
avg_sample_per_episode: 217.5
avg_envstep_per_sec: 2769.999345538669
avg_train_sample_per_sec: 2769.999345538669
avg_episode_per_sec: 12.735629174890432
collect_time: 0.6281589931789786
reward_mean: 1386.4273695589893
reward_std: 731.0363454171454
reward_max: 3190.3472024402254
reward_min: 844.0404606028379
total_envstep_count: 15065738
total_train_sample_count: 11321071
total_episode_count: 34890
total_duration: 3078.9755674849316
[2023-06-29 12:46:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3133
train_sample_count: 3133
avg_envstep_per_episode: 313.3
avg_sample_per_episode: 313.3
avg_envstep_per_sec: 2597.7207570973565
avg_train_sample_per_sec: 2597.7207570973565
avg_episode_per_sec: 8.291480233314255
collect_time: 1.2060572682572528
reward_mean: 2207.3722722244556
reward_std: 1012.6691243073009
reward_max: 3700.28293849305
reward_min: 796.3049330817944
total_envstep_count: 15070794
total_train_sample_count: 11324604
total_episode_count: 34900
total_duration: 3080.1816247531888
[2023-06-29 12:46:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3038
train_sample_count: 3038
avg_envstep_per_episode: 303.8
avg_sample_per_episode: 303.8
avg_envstep_per_sec: 2527.799535360321
avg_train_sample_per_sec: 2527.799535360321
avg_episode_per_sec: 8.320604132193287
collect_time: 1.2018358091702686
reward_mean: 1841.292351842043
reward_std: 588.955221030347
reward_max: 2952.524129957875
reward_min: 962.6276123194021
total_envstep_count: 15075002
total_train_sample_count: 11328042
total_episode_count: 34910
total_duration: 3081.3834605623592
[2023-06-29 12:46:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1886
train_sample_count: 1886
avg_envstep_per_episode: 235.75
avg_sample_per_episode: 235.75
avg_envstep_per_sec: 2654.6407648584586
avg_train_sample_per_sec: 2654.6407648584586
avg_episode_per_sec: 11.260406213609581
collect_time: 0.7104539435114712
reward_mean: 1158.5947831967342
reward_std: 486.35321406191997
reward_max: 2318.1879566958305
reward_min: 504.1835114872747
total_envstep_count: 15079290
total_train_sample_count: 11331528
total_episode_count: 34918
total_duration: 3082.0939145058705
[2023-06-29 12:46:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 266.6666666666667
avg_sample_per_episode: 266.6666666666667
avg_envstep_per_sec: 2544.074266794346
avg_train_sample_per_sec: 2544.074266794346
avg_episode_per_sec: 9.540278500478797
collect_time: 0.943368686726317
reward_mean: 1994.4857201116433
reward_std: 1058.3429212202918
reward_max: 3716.898773472281
reward_min: 797.1381312890478
total_envstep_count: 15083354
total_train_sample_count: 11334728
total_episode_count: 34927
total_duration: 3083.037283192597
[2023-06-29 12:46:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1602
train_sample_count: 1602
avg_envstep_per_episode: 200.25
avg_sample_per_episode: 200.25
avg_envstep_per_sec: 2790.056915302874
avg_train_sample_per_sec: 2790.056915302874
avg_episode_per_sec: 13.932868490900743
collect_time: 0.5741818352211268
reward_mean: 1580.7969237333448
reward_std: 925.3804762206098
reward_max: 3734.581283831497
reward_min: 779.2109379613652
total_envstep_count: 15087274
total_train_sample_count: 11337930
total_episode_count: 34935
total_duration: 3083.611465027818
[2023-06-29 12:46:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2481
train_sample_count: 2481
avg_envstep_per_episode: 275.6666666666667
avg_sample_per_episode: 275.6666666666667
avg_envstep_per_sec: 2565.250132203224
avg_train_sample_per_sec: 2565.250132203224
avg_episode_per_sec: 9.305623212345433
collect_time: 0.9671571473106741
reward_mean: 2048.573717579812
reward_std: 796.8708612380326
reward_max: 3539.477286812925
reward_min: 1040.9209717402907
total_envstep_count: 15091746
total_train_sample_count: 11341211
total_episode_count: 34944
total_duration: 3084.578622175129
[2023-06-29 12:46:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2466
train_sample_count: 2466
avg_envstep_per_episode: 246.6
avg_sample_per_episode: 246.6
avg_envstep_per_sec: 2631.755075137383
avg_train_sample_per_sec: 2631.755075137383
avg_episode_per_sec: 10.672161699664976
collect_time: 0.9370172867896036
reward_mean: 1656.7124747538514
reward_std: 629.4196958389126
reward_max: 3234.8624937191394
reward_min: 1083.589962724998
total_envstep_count: 15096098
total_train_sample_count: 11344477
total_episode_count: 34954
total_duration: 3085.515639461919
[2023-06-29 12:46:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2267
train_sample_count: 2267
avg_envstep_per_episode: 283.375
avg_sample_per_episode: 283.375
avg_envstep_per_sec: 2785.925933553844
avg_train_sample_per_sec: 2785.925933553844
avg_episode_per_sec: 9.831233995778893
collect_time: 0.8137330474928024
reward_mean: 1840.733855081639
reward_std: 711.2799073209537
reward_max: 3289.6085167381057
reward_min: 1019.4058436332537
total_envstep_count: 15100762
total_train_sample_count: 11347944
total_episode_count: 34962
total_duration: 3086.3293725094118
[2023-06-29 12:46:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2978
train_sample_count: 2978
avg_envstep_per_episode: 248.16666666666666
avg_sample_per_episode: 248.16666666666666
avg_envstep_per_sec: 2766.8804847101533
avg_train_sample_per_sec: 2766.8804847101533
avg_episode_per_sec: 11.149283350074493
collect_time: 1.0763023616150023
reward_mean: 1730.8485997829996
reward_std: 898.5942291917181
reward_max: 3501.849466185606
reward_min: 791.4122093020253
total_envstep_count: 15104810
total_train_sample_count: 11351322
total_episode_count: 34974
total_duration: 3087.405674871027
[2023-06-29 12:46:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2583
train_sample_count: 2583
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2529.8437114749727
avg_train_sample_per_sec: 2529.8437114749727
avg_episode_per_sec: 8.81478645113231
collect_time: 1.0210116886999456
reward_mean: 1542.8787937415368
reward_std: 778.4322775013854
reward_max: 3557.5992023571616
reward_min: 850.0957066774034
total_envstep_count: 15109498
total_train_sample_count: 11354705
total_episode_count: 34983
total_duration: 3088.426686559727
[2023-06-29 12:46:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3266
train_sample_count: 3266
avg_envstep_per_episode: 251.23076923076923
avg_sample_per_episode: 251.23076923076923
avg_envstep_per_sec: 2640.052849854116
avg_train_sample_per_sec: 2640.052849854116
avg_episode_per_sec: 10.50847735704333
collect_time: 1.2370964468307792
reward_mean: 1527.9867497914174
reward_std: 675.8421740215452
reward_max: 2852.759233632173
reward_min: 796.9144255936749
total_envstep_count: 15114106
total_train_sample_count: 11357971
total_episode_count: 34996
total_duration: 3089.663783006558
[2023-06-29 12:46:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3120
train_sample_count: 3120
avg_envstep_per_episode: 283.6363636363636
avg_sample_per_episode: 283.6363636363636
avg_envstep_per_sec: 2796.875162140028
avg_train_sample_per_sec: 2796.875162140028
avg_episode_per_sec: 9.860777815237277
collect_time: 1.115530661587603
reward_mean: 1513.0654510043685
reward_std: 490.34073413532127
reward_max: 2777.919122221994
reward_min: 860.7182096390881
total_envstep_count: 15118874
total_train_sample_count: 11361491
total_episode_count: 35007
total_duration: 3090.7793136681453
[2023-06-29 12:46:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3438
train_sample_count: 3438
avg_envstep_per_episode: 343.8
avg_sample_per_episode: 343.8
avg_envstep_per_sec: 2626.6124703475652
avg_train_sample_per_sec: 2626.6124703475652
avg_episode_per_sec: 7.639943194728229
collect_time: 1.308910255628638
reward_mean: 1900.91941512956
reward_std: 695.5804564033613
reward_max: 3350.4831979577316
reward_min: 1009.4458150017721
total_envstep_count: 15123770
total_train_sample_count: 11364929
total_episode_count: 35017
total_duration: 3092.088223923774
[2023-06-29 12:46:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2272
train_sample_count: 2272
avg_envstep_per_episode: 324.57142857142856
avg_sample_per_episode: 324.57142857142856
avg_envstep_per_sec: 2652.8414284672835
avg_train_sample_per_sec: 2652.8414284672835
avg_episode_per_sec: 8.173367077143919
collect_time: 0.8564401835780588
reward_mean: 1876.0495529664888
reward_std: 596.326194356563
reward_max: 2766.2062150841725
reward_min: 896.503303409776
total_envstep_count: 15128146
total_train_sample_count: 11368401
total_episode_count: 35024
total_duration: 3092.944664107352
[2023-06-29 12:46:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2813
train_sample_count: 2813
avg_envstep_per_episode: 281.3
avg_sample_per_episode: 281.3
avg_envstep_per_sec: 2583.169754855731
avg_train_sample_per_sec: 2583.169754855731
avg_episode_per_sec: 9.182971044634664
collect_time: 1.088972180288285
reward_mean: 1881.8558931783093
reward_std: 1044.389153331351
reward_max: 3765.843221517166
reward_min: 930.3622106358647
total_envstep_count: 15132490
total_train_sample_count: 11371614
total_episode_count: 35034
total_duration: 3094.03363628764
[2023-06-29 12:47:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2871
train_sample_count: 2871
avg_envstep_per_episode: 319.0
avg_sample_per_episode: 319.0
avg_envstep_per_sec: 2624.662587464557
avg_train_sample_per_sec: 2624.662587464557
avg_episode_per_sec: 8.227782405845007
collect_time: 1.0938548877527936
reward_mean: 1809.552591227139
reward_std: 833.6811279689662
reward_max: 3583.107252986789
reward_min: 962.7801812057054
total_envstep_count: 15137066
total_train_sample_count: 11374885
total_episode_count: 35043
total_duration: 3095.127491175393
[2023-06-29 12:47:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1886
train_sample_count: 1886
avg_envstep_per_episode: 235.75
avg_sample_per_episode: 235.75
avg_envstep_per_sec: 2729.566529385248
avg_train_sample_per_sec: 2729.566529385248
avg_episode_per_sec: 11.57822493906786
collect_time: 0.6909522005403416
reward_mean: 1518.6994087324329
reward_std: 627.9644536954353
reward_max: 2559.8921542977428
reward_min: 912.4732953817122
total_envstep_count: 15141650
total_train_sample_count: 11378371
total_episode_count: 35051
total_duration: 3095.8184433759334
[2023-06-29 12:47:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1978
train_sample_count: 1978
avg_envstep_per_episode: 247.25
avg_sample_per_episode: 247.25
avg_envstep_per_sec: 2795.806988311415
avg_train_sample_per_sec: 2795.806988311415
avg_episode_per_sec: 11.307611681744852
collect_time: 0.7074880377184599
reward_mean: 2247.4322356363887
reward_std: 1146.1971259093732
reward_max: 3667.0069758464124
reward_min: 779.3879050358532
total_envstep_count: 15146386
total_train_sample_count: 11381949
total_episode_count: 35059
total_duration: 3096.525931413652
[2023-06-29 12:47:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3045
train_sample_count: 3045
avg_envstep_per_episode: 304.5
avg_sample_per_episode: 304.5
avg_envstep_per_sec: 2696.5358064002285
avg_train_sample_per_sec: 2696.5358064002285
avg_episode_per_sec: 8.855618411823409
collect_time: 1.1292266146708276
reward_mean: 2050.729779109152
reward_std: 832.9939080788454
reward_max: 3570.1823519163845
reward_min: 912.850680822606
total_envstep_count: 15151562
total_train_sample_count: 11385794
total_episode_count: 35069
total_duration: 3097.6551580283226
[2023-06-29 12:47:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3384
train_sample_count: 3384
avg_envstep_per_episode: 241.71428571428572
avg_sample_per_episode: 241.71428571428572
avg_envstep_per_sec: 2588.9439301619327
avg_train_sample_per_sec: 2588.9439301619327
avg_episode_per_sec: 10.710760940386246
collect_time: 1.307096673889086
reward_mean: 1525.6271853767787
reward_std: 673.4027059966355
reward_max: 3563.702114647015
reward_min: 922.5586771646783
total_envstep_count: 15156362
total_train_sample_count: 11389178
total_episode_count: 35083
total_duration: 3098.962254702212
[2023-06-29 12:47:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2998
train_sample_count: 2998
avg_envstep_per_episode: 230.6153846153846
avg_sample_per_episode: 230.6153846153846
avg_envstep_per_sec: 2611.4950400280895
avg_train_sample_per_sec: 2611.4950400280895
avg_episode_per_sec: 11.324027858694183
collect_time: 1.1480014145337045
reward_mean: 1210.5572612821654
reward_std: 496.8623635237892
reward_max: 2285.4579828680776
reward_min: 710.6282248843028
total_envstep_count: 15160458
total_train_sample_count: 11392576
total_episode_count: 35096
total_duration: 3100.1102561167454
[2023-06-29 12:47:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2651
train_sample_count: 2651
avg_envstep_per_episode: 265.1
avg_sample_per_episode: 265.1
avg_envstep_per_sec: 2536.3907959322105
avg_train_sample_per_sec: 2536.3907959322105
avg_episode_per_sec: 9.56767557877107
collect_time: 1.045185940688476
reward_mean: 1393.013542331804
reward_std: 739.5126808968535
reward_max: 3490.0946430451645
reward_min: 940.0098771250553
total_envstep_count: 15165506
total_train_sample_count: 11396027
total_episode_count: 35106
total_duration: 3101.155442057434
[2023-06-29 12:47:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2481
train_sample_count: 2481
avg_envstep_per_episode: 190.84615384615384
avg_sample_per_episode: 190.84615384615384
avg_envstep_per_sec: 2731.470124438233
avg_train_sample_per_sec: 2731.470124438233
avg_episode_per_sec: 14.312419031719884
collect_time: 0.9083020816529171
reward_mean: 1398.8979639389868
reward_std: 597.4872173664576
reward_max: 2582.305491089468
reward_min: 651.3335329813553
total_envstep_count: 15169338
total_train_sample_count: 11399308
total_episode_count: 35119
total_duration: 3102.063744139087
[2023-06-29 12:47:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2551
train_sample_count: 2551
avg_envstep_per_episode: 255.1
avg_sample_per_episode: 255.1
avg_envstep_per_sec: 2570.209236983121
avg_train_sample_per_sec: 2570.209236983121
avg_episode_per_sec: 10.075300811380327
collect_time: 0.9925261972034352
reward_mean: 1433.8806965392432
reward_std: 774.2308726434349
reward_max: 3561.346886923216
reward_min: 808.5281037060452
total_envstep_count: 15174386
total_train_sample_count: 11402659
total_episode_count: 35129
total_duration: 3103.0562703362903
[2023-06-29 12:47:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2986
train_sample_count: 2986
avg_envstep_per_episode: 229.69230769230768
avg_sample_per_episode: 229.69230769230768
avg_envstep_per_sec: 2582.9387558012777
avg_train_sample_per_sec: 2582.9387558012777
avg_episode_per_sec: 11.245212265712194
collect_time: 1.1560475420849399
reward_mean: 1558.8410902306036
reward_std: 683.8602306767152
reward_max: 3161.3707289099993
reward_min: 709.5448142679061
total_envstep_count: 15178946
total_train_sample_count: 11406045
total_episode_count: 35142
total_duration: 3104.2123178783754
[2023-06-29 12:47:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1869
train_sample_count: 1869
avg_envstep_per_episode: 233.625
avg_sample_per_episode: 233.625
avg_envstep_per_sec: 2742.968595460164
avg_train_sample_per_sec: 2742.968595460164
avg_episode_per_sec: 11.740903565372559
collect_time: 0.6813785630259664
reward_mean: 1420.7446228026552
reward_std: 595.3381508413188
reward_max: 2385.2603076122855
reward_min: 832.6265732861051
total_envstep_count: 15183322
total_train_sample_count: 11409514
total_episode_count: 35150
total_duration: 3104.8936964414015
[2023-06-29 12:47:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2504
train_sample_count: 2504
avg_envstep_per_episode: 227.63636363636363
avg_sample_per_episode: 227.63636363636363
avg_envstep_per_sec: 2787.882406744907
avg_train_sample_per_sec: 2787.882406744907
avg_episode_per_sec: 12.247087250077465
collect_time: 0.8981727471509948
reward_mean: 1794.7418482719006
reward_std: 915.3462822413437
reward_max: 3632.858329116243
reward_min: 667.6756968413862
total_envstep_count: 15187754
total_train_sample_count: 11412818
total_episode_count: 35161
total_duration: 3105.7918691885525
[2023-06-29 12:47:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2902
train_sample_count: 2902
avg_envstep_per_episode: 241.83333333333334
avg_sample_per_episode: 241.83333333333334
avg_envstep_per_sec: 2811.1395370619634
avg_train_sample_per_sec: 2811.1395370619634
avg_episode_per_sec: 11.624284784542922
collect_time: 1.0323215769762175
reward_mean: 1460.2886779659177
reward_std: 634.8483943207503
reward_max: 3123.4312149440652
reward_min: 770.5809122172216
total_envstep_count: 15192386
total_train_sample_count: 11416120
total_episode_count: 35173
total_duration: 3106.824190765529
[2023-06-29 12:47:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2104
train_sample_count: 2104
avg_envstep_per_episode: 350.6666666666667
avg_sample_per_episode: 350.6666666666667
avg_envstep_per_sec: 2603.3148843892127
avg_train_sample_per_sec: 2603.3148843892127
avg_episode_per_sec: 7.423901761566196
collect_time: 0.8082003497220578
reward_mean: 2084.225612211167
reward_std: 790.3567274319468
reward_max: 3474.7024917011363
reward_min: 1265.1390270753748
total_envstep_count: 15196922
total_train_sample_count: 11419424
total_episode_count: 35179
total_duration: 3107.632391115251
[2023-06-29 12:47:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1727
train_sample_count: 1727
avg_envstep_per_episode: 215.875
avg_sample_per_episode: 215.875
avg_envstep_per_sec: 2513.7108571510316
avg_train_sample_per_sec: 2513.7108571510316
avg_episode_per_sec: 11.644288857677044
collect_time: 0.6870320805143566
reward_mean: 1993.8344726635019
reward_std: 1087.150387979779
reward_max: 3638.832083593742
reward_min: 785.6949048491948
total_envstep_count: 15201250
total_train_sample_count: 11422751
total_episode_count: 35187
total_duration: 3108.319423195765
[2023-06-29 12:47:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2139
train_sample_count: 2139
avg_envstep_per_episode: 213.9
avg_sample_per_episode: 213.9
avg_envstep_per_sec: 2768.3730318697717
avg_train_sample_per_sec: 2768.3730318697717
avg_episode_per_sec: 12.942370415473453
collect_time: 0.7726559879668058
reward_mean: 1747.6717970157847
reward_std: 820.0037422484296
reward_max: 3200.980960971912
reward_min: 820.7410582825785
total_envstep_count: 15205354
total_train_sample_count: 11426090
total_episode_count: 35197
total_duration: 3109.092079183732
[2023-06-29 12:47:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2119
train_sample_count: 2119
avg_envstep_per_episode: 235.44444444444446
avg_sample_per_episode: 235.44444444444446
avg_envstep_per_sec: 2770.2222142282117
avg_train_sample_per_sec: 2770.2222142282117
avg_episode_per_sec: 11.76592729025668
collect_time: 0.7649205861957744
reward_mean: 1759.0129340639885
reward_std: 717.6135611238228
reward_max: 3168.792576401988
reward_min: 740.2709048146378
total_envstep_count: 15209578
total_train_sample_count: 11429409
total_episode_count: 35206
total_duration: 3109.856999769928
[2023-06-29 12:47:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2577
train_sample_count: 2577
avg_envstep_per_episode: 234.27272727272728
avg_sample_per_episode: 234.27272727272728
avg_envstep_per_sec: 2733.4587958052657
avg_train_sample_per_sec: 2733.4587958052657
avg_episode_per_sec: 11.667848953767141
collect_time: 0.9427616044385357
reward_mean: 1438.2276987406915
reward_std: 614.9943965209226
reward_max: 3068.5690604362003
reward_min: 836.4484874410798
total_envstep_count: 15213714
total_train_sample_count: 11432786
total_episode_count: 35217
total_duration: 3110.7997613743664
[2023-06-29 12:47:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1980
train_sample_count: 1980
avg_envstep_per_episode: 247.5
avg_sample_per_episode: 247.5
avg_envstep_per_sec: 2450.5809183260544
avg_train_sample_per_sec: 2450.5809183260544
avg_episode_per_sec: 9.901337043741634
collect_time: 0.807971687526442
reward_mean: 1713.9227696923708
reward_std: 791.3936711739749
reward_max: 3572.6002961967442
reward_min: 866.1338237986504
total_envstep_count: 15218202
total_train_sample_count: 11436366
total_episode_count: 35225
total_duration: 3111.6077330618928
[2023-06-29 12:47:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2524
train_sample_count: 2524
avg_envstep_per_episode: 280.44444444444446
avg_sample_per_episode: 280.44444444444446
avg_envstep_per_sec: 2504.11597815441
avg_train_sample_per_sec: 2504.11597815441
avg_episode_per_sec: 8.929098178839022
collect_time: 1.0079405355099587
reward_mean: 2081.4349393953576
reward_std: 1081.332910810016
reward_max: 3607.4173142439886
reward_min: 880.5142109293078
total_envstep_count: 15223010
total_train_sample_count: 11439690
total_episode_count: 35234
total_duration: 3112.6156735974027
[2023-06-29 12:48:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1698
train_sample_count: 1698
avg_envstep_per_episode: 242.57142857142858
avg_sample_per_episode: 242.57142857142858
avg_envstep_per_sec: 2779.4980680116846
avg_train_sample_per_sec: 2779.4980680116846
avg_episode_per_sec: 11.458472600754884
collect_time: 0.6109016658589244
reward_mean: 1895.0912270960973
reward_std: 1102.990565348389
reward_max: 3529.294485871486
reward_min: 809.9529507853229
total_envstep_count: 15228042
total_train_sample_count: 11442988
total_episode_count: 35241
total_duration: 3113.2265752632616
[2023-06-29 12:48:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2711
train_sample_count: 2711
avg_envstep_per_episode: 387.2857142857143
avg_sample_per_episode: 387.2857142857143
avg_envstep_per_sec: 2823.4750966022457
avg_train_sample_per_sec: 2823.4750966022457
avg_episode_per_sec: 7.290418914133427
collect_time: 0.9601643036492167
reward_mean: 3187.480504927658
reward_std: 826.3912409739678
reward_max: 3595.819477896918
reward_min: 1167.868047329872
total_envstep_count: 15232762
total_train_sample_count: 11446499
total_episode_count: 35248
total_duration: 3114.186739566911
[2023-06-29 12:48:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1403
train_sample_count: 1403
avg_envstep_per_episode: 233.83333333333334
avg_sample_per_episode: 233.83333333333334
avg_envstep_per_sec: 2566.2222808280185
avg_train_sample_per_sec: 2566.2222808280185
avg_episode_per_sec: 10.97457853525881
collect_time: 0.5467180339293553
reward_mean: 2128.696138859686
reward_std: 966.4139365804673
reward_max: 3624.222147659487
reward_min: 922.9567841438984
total_envstep_count: 15237266
total_train_sample_count: 11449902
total_episode_count: 35254
total_duration: 3114.73345760084
[2023-06-29 12:48:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2688
train_sample_count: 2688
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 2533.3338538914813
avg_train_sample_per_sec: 2533.3338538914813
avg_episode_per_sec: 11.309526133444113
collect_time: 1.0610524135502055
reward_mean: 1861.5772516608652
reward_std: 859.5610506044222
reward_max: 3607.8023768543194
reward_min: 947.9817451183874
total_envstep_count: 15242074
total_train_sample_count: 11453390
total_episode_count: 35266
total_duration: 3115.79451001439
[2023-06-29 12:48:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2022
train_sample_count: 2022
avg_envstep_per_episode: 202.2
avg_sample_per_episode: 202.2
avg_envstep_per_sec: 2804.1238827779807
avg_train_sample_per_sec: 2804.1238827779807
avg_episode_per_sec: 13.868070636884177
collect_time: 0.7210808382676914
reward_mean: 1512.1193427309613
reward_std: 479.0708796372678
reward_max: 2298.662906674474
reward_min: 868.1381119614734
total_envstep_count: 15246298
total_train_sample_count: 11456612
total_episode_count: 35276
total_duration: 3116.515590852658
[2023-06-29 12:48:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1764
train_sample_count: 1764
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 2774.144739395893
avg_train_sample_per_sec: 2774.144739395893
avg_episode_per_sec: 14.153799690795372
collect_time: 0.6358716526031495
reward_mean: 1417.4361438003625
reward_std: 491.52674442839424
reward_max: 2160.3465771782467
reward_min: 579.0035598681519
total_envstep_count: 15250530
total_train_sample_count: 11459976
total_episode_count: 35285
total_duration: 3117.1514625052614
[2023-06-29 12:48:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2168
train_sample_count: 2168
avg_envstep_per_episode: 216.8
avg_sample_per_episode: 216.8
avg_envstep_per_sec: 2551.735458817395
avg_train_sample_per_sec: 2551.735458817395
avg_episode_per_sec: 11.769997503770272
collect_time: 0.8496178522380068
reward_mean: 1783.9314605215175
reward_std: 774.7434562325714
reward_max: 3583.844629935563
reward_min: 977.2807031190798
total_envstep_count: 15255490
total_train_sample_count: 11463344
total_episode_count: 35295
total_duration: 3118.0010803574996
[2023-06-29 12:48:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2444
train_sample_count: 2444
avg_envstep_per_episode: 222.1818181818182
avg_sample_per_episode: 222.1818181818182
avg_envstep_per_sec: 2511.8699187292355
avg_train_sample_per_sec: 2511.8699187292355
avg_episode_per_sec: 11.305470174313252
collect_time: 0.9729803210655228
reward_mean: 1833.7015170960165
reward_std: 875.2982144337634
reward_max: 3670.5350716275693
reward_min: 827.5594218562949
total_envstep_count: 15259650
total_train_sample_count: 11466588
total_episode_count: 35306
total_duration: 3118.9740606785654
[2023-06-29 12:48:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2535
train_sample_count: 2535
avg_envstep_per_episode: 316.875
avg_sample_per_episode: 316.875
avg_envstep_per_sec: 2757.9620534716187
avg_train_sample_per_sec: 2757.9620534716187
avg_episode_per_sec: 8.703627782158954
collect_time: 0.9191569538852203
reward_mean: 1803.3399077380122
reward_std: 945.0394711360896
reward_max: 3586.4783978727146
reward_min: 829.219254230941
total_envstep_count: 15264018
total_train_sample_count: 11469923
total_episode_count: 35314
total_duration: 3119.8932176324506
[2023-06-29 12:48:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2196
train_sample_count: 2196
avg_envstep_per_episode: 219.6
avg_sample_per_episode: 219.6
avg_envstep_per_sec: 2534.307246322584
avg_train_sample_per_sec: 2534.307246322584
avg_episode_per_sec: 11.54056123097716
collect_time: 0.8665089851226657
reward_mean: 1426.9433936908001
reward_std: 751.834498705693
reward_max: 2864.7183465360586
reward_min: 568.4610014008044
total_envstep_count: 15268730
total_train_sample_count: 11473719
total_episode_count: 35324
total_duration: 3120.7597266175735
[2023-06-29 12:48:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 223.22222222222223
avg_sample_per_episode: 223.22222222222223
avg_envstep_per_sec: 2797.6899439952495
avg_train_sample_per_sec: 2797.6899439952495
avg_episode_per_sec: 12.53320532402053
collect_time: 0.7180924406265841
reward_mean: 1964.964155814127
reward_std: 865.5672590231559
reward_max: 3356.187735702459
reward_min: 828.8015935438654
total_envstep_count: 15273026
total_train_sample_count: 11476928
total_episode_count: 35333
total_duration: 3121.4778190582
[2023-06-29 12:48:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 201.875
avg_sample_per_episode: 201.875
avg_envstep_per_sec: 2681.5174968758
avg_train_sample_per_sec: 2681.5174968758
avg_episode_per_sec: 13.283058808053498
collect_time: 0.602270916330628
reward_mean: 1721.3025915375601
reward_std: 719.5014752309646
reward_max: 2755.5611645715035
reward_min: 855.3206095378837
total_envstep_count: 15277074
total_train_sample_count: 11480143
total_episode_count: 35341
total_duration: 3122.080089974531
[2023-06-29 12:48:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2930
train_sample_count: 2930
avg_envstep_per_episode: 266.3636363636364
avg_sample_per_episode: 266.3636363636364
avg_envstep_per_sec: 2506.1872417835402
avg_train_sample_per_sec: 2506.1872417835402
avg_episode_per_sec: 9.40889408178121
collect_time: 1.1691065819626674
reward_mean: 1862.5762629076323
reward_std: 815.8037753654332
reward_max: 3566.983065196401
reward_min: 541.3771642817081
total_envstep_count: 15281330
total_train_sample_count: 11483873
total_episode_count: 35352
total_duration: 3123.2491965564936
[2023-06-29 12:48:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 272.6666666666667
avg_sample_per_episode: 272.6666666666667
avg_envstep_per_sec: 2691.682583896836
avg_train_sample_per_sec: 2691.682583896836
avg_episode_per_sec: 9.871696517959057
collect_time: 0.9116973950350656
reward_mean: 1559.3446280081243
reward_std: 441.99426044383085
reward_max: 2462.9073592135323
reward_min: 1068.3724886643454
total_envstep_count: 15285618
total_train_sample_count: 11487127
total_episode_count: 35361
total_duration: 3124.1608939515286
[2023-06-29 12:48:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2491
train_sample_count: 2491
avg_envstep_per_episode: 355.85714285714283
avg_sample_per_episode: 355.85714285714283
avg_envstep_per_sec: 2802.695498953521
avg_train_sample_per_sec: 2802.695498953521
avg_episode_per_sec: 7.875900639371597
collect_time: 0.8887872410435229
reward_mean: 2099.4024241919783
reward_std: 437.0299527502367
reward_max: 2727.9293119496047
reward_min: 1404.6810293690098
total_envstep_count: 15290082
total_train_sample_count: 11490418
total_episode_count: 35368
total_duration: 3125.0496811925723
[2023-06-29 12:48:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1011
train_sample_count: 1011
avg_envstep_per_episode: 252.75
avg_sample_per_episode: 252.75
avg_envstep_per_sec: 2801.2009137811897
avg_train_sample_per_sec: 2801.2009137811897
avg_episode_per_sec: 11.082891844831611
collect_time: 0.3609166322294625
reward_mean: 2540.8969193402413
reward_std: 885.4881839318646
reward_max: 3554.978539812428
reward_min: 1625.5883136750012
total_envstep_count: 15294978
total_train_sample_count: 11493829
total_episode_count: 35372
total_duration: 3125.4105978248017
[2023-06-29 12:48:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2406
train_sample_count: 2406
avg_envstep_per_episode: 240.6
avg_sample_per_episode: 240.6
avg_envstep_per_sec: 2656.9037823591866
avg_train_sample_per_sec: 2656.9037823591866
avg_episode_per_sec: 11.04282536308889
collect_time: 0.9055653486493975
reward_mean: 2524.5438692152716
reward_std: 926.1066467212427
reward_max: 3745.658294257946
reward_min: 1323.0779855989783
total_envstep_count: 15299506
total_train_sample_count: 11497035
total_episode_count: 35382
total_duration: 3126.316163173451
[2023-06-29 12:48:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1677
train_sample_count: 1677
avg_envstep_per_episode: 335.4
avg_sample_per_episode: 335.4
avg_envstep_per_sec: 2826.5583724376293
avg_train_sample_per_sec: 2826.5583724376293
avg_episode_per_sec: 8.427425081805692
collect_time: 0.5933010322209451
reward_mean: 2176.278323697914
reward_std: 1149.933548227854
reward_max: 3577.103474527024
reward_min: 1029.524700441109
total_envstep_count: 15303466
total_train_sample_count: 11500312
total_episode_count: 35387
total_duration: 3126.909464205672
[2023-06-29 12:48:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2347
train_sample_count: 2347
avg_envstep_per_episode: 335.2857142857143
avg_sample_per_episode: 335.2857142857143
avg_envstep_per_sec: 2730.6800321720084
avg_train_sample_per_sec: 2730.6800321720084
avg_episode_per_sec: 8.144337548020477
collect_time: 0.8594928634436801
reward_mean: 2721.405168277507
reward_std: 973.3441143622994
reward_max: 3734.6983334329343
reward_min: 1358.582572957689
total_envstep_count: 15308170
total_train_sample_count: 11503859
total_episode_count: 35394
total_duration: 3127.768957069116
[2023-06-29 12:48:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 284.3
avg_sample_per_episode: 284.3
avg_envstep_per_sec: 2743.3642563923777
avg_train_sample_per_sec: 2743.3642563923777
avg_episode_per_sec: 9.649540120972134
collect_time: 1.0363188167139885
reward_mean: 1996.4040622843143
reward_std: 993.6673937199752
reward_max: 3725.011894311527
reward_min: 876.3442446826145
total_envstep_count: 15312970
total_train_sample_count: 11507102
total_episode_count: 35404
total_duration: 3128.80527588583
[2023-06-29 12:49:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2056
train_sample_count: 2056
avg_envstep_per_episode: 228.44444444444446
avg_sample_per_episode: 228.44444444444446
avg_envstep_per_sec: 2506.583127174734
avg_train_sample_per_sec: 2506.583127174734
avg_episode_per_sec: 10.972396957476947
collect_time: 0.8202401020377874
reward_mean: 1570.9380284900153
reward_std: 746.7156416310062
reward_max: 3573.5284839280516
reward_min: 1011.0089499979844
total_envstep_count: 15317002
total_train_sample_count: 11510358
total_episode_count: 35413
total_duration: 3129.6255159878674
[2023-06-29 12:49:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2985
train_sample_count: 2985
avg_envstep_per_episode: 426.42857142857144
avg_sample_per_episode: 426.42857142857144
avg_envstep_per_sec: 2556.4303432826105
avg_train_sample_per_sec: 2556.4303432826105
avg_episode_per_sec: 5.994979029473458
collect_time: 1.1676437841709704
reward_mean: 2592.45312729908
reward_std: 857.2935267690176
reward_max: 3572.882088363305
reward_min: 1301.5012819086623
total_envstep_count: 15321698
total_train_sample_count: 11513743
total_episode_count: 35420
total_duration: 3130.7931597720385
[2023-06-29 12:49:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 191.33333333333334
avg_sample_per_episode: 191.33333333333334
avg_envstep_per_sec: 2815.7813148581445
avg_train_sample_per_sec: 2815.7813148581445
avg_episode_per_sec: 14.716627081140128
collect_time: 0.4077021159073338
reward_mean: 1700.3843639467225
reward_std: 898.2952059861174
reward_max: 3582.34329531146
reward_min: 928.0015643556901
total_envstep_count: 15326778
total_train_sample_count: 11517291
total_episode_count: 35426
total_duration: 3131.200861887946
[2023-06-29 12:49:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1947
train_sample_count: 1947
avg_envstep_per_episode: 216.33333333333334
avg_sample_per_episode: 216.33333333333334
avg_envstep_per_sec: 2777.319504544773
avg_train_sample_per_sec: 2777.319504544773
avg_episode_per_sec: 12.838148711300953
collect_time: 0.7010356557155027
reward_mean: 2406.187279468022
reward_std: 1043.7010508508417
reward_max: 3576.6955193552944
reward_min: 891.4641122584209
total_envstep_count: 15331482
total_train_sample_count: 11520838
total_episode_count: 35435
total_duration: 3131.9018975436616
[2023-06-29 12:49:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 290.75
avg_sample_per_episode: 290.75
avg_envstep_per_sec: 2553.5464700112498
avg_train_sample_per_sec: 2553.5464700112498
avg_episode_per_sec: 8.782618985421323
collect_time: 0.9108900219034404
reward_mean: 2316.2423811759327
reward_std: 1006.6138823625967
reward_max: 3567.9968336904753
reward_min: 533.1162594394729
total_envstep_count: 15336050
total_train_sample_count: 11524364
total_episode_count: 35443
total_duration: 3132.812787565565
[2023-06-29 12:49:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2622
train_sample_count: 2622
avg_envstep_per_episode: 327.75
avg_sample_per_episode: 327.75
avg_envstep_per_sec: 2542.895841761587
avg_train_sample_per_sec: 2542.895841761587
avg_episode_per_sec: 7.758644826122309
collect_time: 1.0311079034144057
reward_mean: 1961.6088466936453
reward_std: 1110.4531316543284
reward_max: 3581.6645131952214
reward_min: 815.3545461942671
total_envstep_count: 15340370
total_train_sample_count: 11527786
total_episode_count: 35451
total_duration: 3133.8438954689796
[2023-06-29 12:49:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1207
train_sample_count: 1207
avg_envstep_per_episode: 201.16666666666666
avg_sample_per_episode: 201.16666666666666
avg_envstep_per_sec: 2722.1233008175277
avg_train_sample_per_sec: 2722.1233008175277
avg_episode_per_sec: 13.531681694204776
collect_time: 0.44340386772248896
reward_mean: 1967.9620021958597
reward_std: 1143.1184269596417
reward_max: 3585.631481099559
reward_min: 903.6978134393446
total_envstep_count: 15344610
total_train_sample_count: 11530993
total_episode_count: 35457
total_duration: 3134.287299336702
[2023-06-29 12:49:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2855
train_sample_count: 2855
avg_envstep_per_episode: 259.54545454545456
avg_sample_per_episode: 259.54545454545456
avg_envstep_per_sec: 2758.547948235831
avg_train_sample_per_sec: 2758.547948235831
avg_episode_per_sec: 10.62838088637273
collect_time: 1.0349647907428445
reward_mean: 2094.4562791043545
reward_std: 1174.470969192676
reward_max: 3656.933327554718
reward_min: 530.8093415309886
total_envstep_count: 15349050
total_train_sample_count: 11534248
total_episode_count: 35468
total_duration: 3135.3222641274447
[2023-06-29 12:49:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1820
train_sample_count: 1820
avg_envstep_per_episode: 227.5
avg_sample_per_episode: 227.5
avg_envstep_per_sec: 2735.9285862285406
avg_train_sample_per_sec: 2735.9285862285406
avg_episode_per_sec: 12.026059719685893
collect_time: 0.6652220416720956
reward_mean: 1437.3429919022255
reward_std: 790.6752600129876
reward_max: 3459.492738396759
reward_min: 873.070650476637
total_envstep_count: 15353946
total_train_sample_count: 11538068
total_episode_count: 35476
total_duration: 3135.987486169117
[2023-06-29 12:49:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 290.75
avg_sample_per_episode: 290.75
avg_envstep_per_sec: 2452.7755354687133
avg_train_sample_per_sec: 2452.7755354687133
avg_episode_per_sec: 8.436029356728163
collect_time: 0.9483134377216922
reward_mean: 2636.4415643425737
reward_std: 624.4776098039122
reward_max: 3678.719058043679
reward_min: 1943.1564606695715
total_envstep_count: 15358866
total_train_sample_count: 11541594
total_episode_count: 35484
total_duration: 3136.9357996068384
[2023-06-29 12:49:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1694
train_sample_count: 1694
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2747.78995601229
avg_train_sample_per_sec: 2747.78995601229
avg_episode_per_sec: 11.354503950464009
collect_time: 0.6164954480212181
reward_mean: 1844.5632546419401
reward_std: 913.2392005490321
reward_max: 3631.4165063028086
reward_min: 834.2932164506882
total_envstep_count: 15363282
total_train_sample_count: 11544888
total_episode_count: 35491
total_duration: 3137.5522950548598
[2023-06-29 12:49:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2540
train_sample_count: 2540
avg_envstep_per_episode: 230.9090909090909
avg_sample_per_episode: 230.9090909090909
avg_envstep_per_sec: 2745.786272136579
avg_train_sample_per_sec: 2745.786272136579
avg_episode_per_sec: 11.891200391142664
collect_time: 0.9250537908850238
reward_mean: 2011.7465119849214
reward_std: 992.5305824214571
reward_max: 3584.95008100882
reward_min: 1023.5912182922751
total_envstep_count: 15368346
total_train_sample_count: 11548228
total_episode_count: 35502
total_duration: 3138.477348845745
[2023-06-29 12:49:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2672
train_sample_count: 2672
avg_envstep_per_episode: 222.66666666666666
avg_sample_per_episode: 222.66666666666666
avg_envstep_per_sec: 2770.218670549583
avg_train_sample_per_sec: 2770.218670549583
avg_episode_per_sec: 12.441101813845432
collect_time: 0.964544795111753
reward_mean: 1582.4072136904342
reward_std: 684.2322595713448
reward_max: 2864.211512986796
reward_min: 587.918670177417
total_envstep_count: 15373082
total_train_sample_count: 11551700
total_episode_count: 35514
total_duration: 3139.4418936408565
[2023-06-29 12:49:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2510
train_sample_count: 2510
avg_envstep_per_episode: 278.8888888888889
avg_sample_per_episode: 278.8888888888889
avg_envstep_per_sec: 2783.2142071409207
avg_train_sample_per_sec: 2783.2142071409207
avg_episode_per_sec: 9.979652535565053
collect_time: 0.9018350055702029
reward_mean: 1782.2328665515442
reward_std: 767.1232984231868
reward_max: 2881.7669404784597
reward_min: 532.733018802561
total_envstep_count: 15377730
total_train_sample_count: 11555010
total_episode_count: 35523
total_duration: 3140.343728646427
[2023-06-29 12:49:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2124
train_sample_count: 2124
avg_envstep_per_episode: 265.5
avg_sample_per_episode: 265.5
avg_envstep_per_sec: 2531.9367083648576
avg_train_sample_per_sec: 2531.9367083648576
avg_episode_per_sec: 9.536484777268766
collect_time: 0.8388835285585373
reward_mean: 1942.4616892230688
reward_std: 832.1326417055361
reward_max: 3570.64903863019
reward_min: 814.9429377686108
total_envstep_count: 15382474
total_train_sample_count: 11558334
total_episode_count: 35531
total_duration: 3141.1826121749855
[2023-06-29 12:49:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1865
train_sample_count: 1865
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 2798.145650338782
avg_train_sample_per_sec: 2798.145650338782
avg_episode_per_sec: 15.003461932111433
collect_time: 0.6665128385201097
reward_mean: 1553.802126558132
reward_std: 926.6827816506459
reward_max: 3334.4897505558642
reward_min: 805.0160495666104
total_envstep_count: 15387162
total_train_sample_count: 11561799
total_episode_count: 35541
total_duration: 3141.8491250135057
[2023-06-29 12:49:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1824
train_sample_count: 1824
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 2449.670417758745
avg_train_sample_per_sec: 2449.670417758745
avg_episode_per_sec: 8.058126374206397
collect_time: 0.744589960664511
reward_mean: 2840.6214056265894
reward_std: 958.4140691287259
reward_max: 3691.5226956507368
reward_min: 993.07768293766
total_envstep_count: 15391962
total_train_sample_count: 11565223
total_episode_count: 35547
total_duration: 3142.5937149741703
[2023-06-29 12:49:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2673
train_sample_count: 2673
avg_envstep_per_episode: 267.3
avg_sample_per_episode: 267.3
avg_envstep_per_sec: 2759.5860887899075
avg_train_sample_per_sec: 2759.5860887899075
avg_episode_per_sec: 10.32392850276808
collect_time: 0.9686235232371837
reward_mean: 2258.5914622998653
reward_std: 837.3892129319713
reward_max: 3741.8261809501073
reward_min: 1175.158631763504
total_envstep_count: 15396594
total_train_sample_count: 11568696
total_episode_count: 35557
total_duration: 3143.5623384974074
[2023-06-29 12:49:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2822
train_sample_count: 2822
avg_envstep_per_episode: 313.55555555555554
avg_sample_per_episode: 313.55555555555554
avg_envstep_per_sec: 2559.1632017415036
avg_train_sample_per_sec: 2559.1632017415036
avg_episode_per_sec: 8.161753655447743
collect_time: 1.1027041956838222
reward_mean: 1778.4668539819343
reward_std: 1025.1474466739733
reward_max: 3633.8291947575754
reward_min: 829.5760498414514
total_envstep_count: 15400738
total_train_sample_count: 11571918
total_episode_count: 35566
total_duration: 3144.665042693091
[2023-06-29 12:50:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2613
train_sample_count: 2613
avg_envstep_per_episode: 261.3
avg_sample_per_episode: 261.3
avg_envstep_per_sec: 2540.557211389373
avg_train_sample_per_sec: 2540.557211389373
avg_episode_per_sec: 9.72276008951157
collect_time: 1.0285145275555552
reward_mean: 1460.6735162297323
reward_std: 818.0983068993331
reward_max: 3674.859853089878
reward_min: 850.4125638162377
total_envstep_count: 15405354
total_train_sample_count: 11575331
total_episode_count: 35576
total_duration: 3145.6935572206467
[2023-06-29 12:50:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3086
train_sample_count: 3086
avg_envstep_per_episode: 237.3846153846154
avg_sample_per_episode: 237.3846153846154
avg_envstep_per_sec: 2656.0849222288944
avg_train_sample_per_sec: 2656.0849222288944
avg_episode_per_sec: 11.188951389817118
collect_time: 1.1618604413485152
reward_mean: 1520.597870059184
reward_std: 692.2307303338774
reward_max: 3062.6579291887624
reward_min: 825.4211977682122
total_envstep_count: 15410122
total_train_sample_count: 11578817
total_episode_count: 35589
total_duration: 3146.855417661995
[2023-06-29 12:50:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2121
train_sample_count: 2121
avg_envstep_per_episode: 265.125
avg_sample_per_episode: 265.125
avg_envstep_per_sec: 2720.3858090096305
avg_train_sample_per_sec: 2720.3858090096305
avg_episode_per_sec: 10.260766842091957
collect_time: 0.7796688223322854
reward_mean: 1472.1580052630648
reward_std: 519.3821215396533
reward_max: 2713.414452632135
reward_min: 870.5290221494049
total_envstep_count: 15414906
total_train_sample_count: 11582138
total_episode_count: 35597
total_duration: 3147.6350864843275
[2023-06-29 12:50:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 214.6
avg_sample_per_episode: 214.6
avg_envstep_per_sec: 2740.6844174034595
avg_train_sample_per_sec: 2740.6844174034595
avg_episode_per_sec: 12.771129624433641
collect_time: 0.7830160912992431
reward_mean: 1912.3087481130756
reward_std: 1038.806786699396
reward_max: 3611.1261167832363
reward_min: 1119.0249353936447
total_envstep_count: 15419522
total_train_sample_count: 11585484
total_episode_count: 35607
total_duration: 3148.4181025756266
[2023-06-29 12:50:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3377
train_sample_count: 3377
avg_envstep_per_episode: 225.13333333333333
avg_sample_per_episode: 225.13333333333333
avg_envstep_per_sec: 2619.548823393981
avg_train_sample_per_sec: 2619.548823393981
avg_episode_per_sec: 11.635544077853039
collect_time: 1.2891532961102203
reward_mean: 1474.2571253281699
reward_std: 634.7584869422317
reward_max: 2904.9999707971
reward_min: 826.099042634105
total_envstep_count: 15424114
total_train_sample_count: 11588861
total_episode_count: 35622
total_duration: 3149.707255871737
[2023-06-29 12:50:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2216
train_sample_count: 2216
avg_envstep_per_episode: 246.22222222222223
avg_sample_per_episode: 246.22222222222223
avg_envstep_per_sec: 2508.5610994711687
avg_train_sample_per_sec: 2508.5610994711687
avg_episode_per_sec: 10.188199411209622
collect_time: 0.8833749357219787
reward_mean: 1405.3445462283353
reward_std: 585.0076765009726
reward_max: 2976.1063736579417
reward_min: 955.0959373363106
total_envstep_count: 15428754
total_train_sample_count: 11592277
total_episode_count: 35631
total_duration: 3150.5906308074586
[2023-06-29 12:50:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2216
train_sample_count: 2216
avg_envstep_per_episode: 246.22222222222223
avg_sample_per_episode: 246.22222222222223
avg_envstep_per_sec: 2737.612986598735
avg_train_sample_per_sec: 2737.612986598735
avg_episode_per_sec: 11.118464295752984
collect_time: 0.8094643073538319
reward_mean: 1898.1348112544495
reward_std: 857.0142397917944
reward_max: 3585.6285984552305
reward_min: 533.1216977121032
total_envstep_count: 15432666
total_train_sample_count: 11595693
total_episode_count: 35640
total_duration: 3151.4000951148123
[2023-06-29 12:50:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2207
train_sample_count: 2207
avg_envstep_per_episode: 275.875
avg_sample_per_episode: 275.875
avg_envstep_per_sec: 2745.0181532929687
avg_train_sample_per_sec: 2745.0181532929687
avg_episode_per_sec: 9.95022438891878
collect_time: 0.8040019689314064
reward_mean: 1769.2782948292797
reward_std: 660.4240262720905
reward_max: 3031.9151608114225
reward_min: 831.2725079346155
total_envstep_count: 15437490
total_train_sample_count: 11599100
total_episode_count: 35648
total_duration: 3152.204097083744
[2023-06-29 12:50:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2838
train_sample_count: 2838
avg_envstep_per_episode: 354.75
avg_sample_per_episode: 354.75
avg_envstep_per_sec: 2582.628717934704
avg_train_sample_per_sec: 2582.628717934704
avg_episode_per_sec: 7.280137330330385
collect_time: 1.098880369559862
reward_mean: 2576.887941322667
reward_std: 689.6757708372479
reward_max: 3607.76648028656
reward_min: 1349.583215654436
total_envstep_count: 15442506
total_train_sample_count: 11602338
total_episode_count: 35656
total_duration: 3153.302977453304
[2023-06-29 12:50:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1373
train_sample_count: 1373
avg_envstep_per_episode: 274.6
avg_sample_per_episode: 274.6
avg_envstep_per_sec: 2426.7750302190284
avg_train_sample_per_sec: 2426.7750302190284
avg_episode_per_sec: 8.837491005895952
collect_time: 0.5657714385977014
reward_mean: 2051.5878532866445
reward_std: 609.79558347186
reward_max: 3203.299103316015
reward_min: 1476.6345910795385
total_envstep_count: 15446898
total_train_sample_count: 11605711
total_episode_count: 35661
total_duration: 3153.8687488919013
[2023-06-29 12:50:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2089
train_sample_count: 2089
avg_envstep_per_episode: 261.125
avg_sample_per_episode: 261.125
avg_envstep_per_sec: 2809.3958569774186
avg_train_sample_per_sec: 2809.3958569774186
avg_episode_per_sec: 10.758816110971445
collect_time: 0.7435762371513994
reward_mean: 2665.0556068846004
reward_std: 948.5398291820968
reward_max: 3603.551199741766
reward_min: 1076.5817492022716
total_envstep_count: 15451842
total_train_sample_count: 11609000
total_episode_count: 35669
total_duration: 3154.612325129053
[2023-06-29 12:50:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1796
train_sample_count: 1796
avg_envstep_per_episode: 256.57142857142856
avg_sample_per_episode: 256.57142857142856
avg_envstep_per_sec: 2820.4462435518026
avg_train_sample_per_sec: 2820.4462435518026
avg_episode_per_sec: 10.992830570636201
collect_time: 0.6367786672431976
reward_mean: 2154.9352513771464
reward_std: 1035.6478036938688
reward_max: 3612.853048553158
reward_min: 1028.6656801915672
total_envstep_count: 15456066
total_train_sample_count: 11612396
total_episode_count: 35676
total_duration: 3155.249103796296
[2023-06-29 12:50:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1295
train_sample_count: 1295
avg_envstep_per_episode: 215.83333333333334
avg_sample_per_episode: 215.83333333333334
avg_envstep_per_sec: 2490.8157641326384
avg_train_sample_per_sec: 2490.8157641326384
avg_episode_per_sec: 11.540459138838479
collect_time: 0.5199099903926254
reward_mean: 2700.3740529493853
reward_std: 829.1423561351604
reward_max: 3617.4887794256106
reward_min: 1489.1045666292825
total_envstep_count: 15460562
total_train_sample_count: 11615691
total_episode_count: 35682
total_duration: 3155.7690137866884
[2023-06-29 12:50:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2327
train_sample_count: 2327
avg_envstep_per_episode: 211.54545454545453
avg_sample_per_episode: 211.54545454545453
avg_envstep_per_sec: 2594.7709901858807
avg_train_sample_per_sec: 2594.7709901858807
avg_episode_per_sec: 12.2657846549397
collect_time: 0.8968036134215073
reward_mean: 1842.8120328119394
reward_std: 892.2348793973067
reward_max: 3236.555601748895
reward_min: 530.6905014918532
total_envstep_count: 15465754
total_train_sample_count: 11619218
total_episode_count: 35693
total_duration: 3156.66581740011
[2023-06-29 12:50:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2967
train_sample_count: 2967
avg_envstep_per_episode: 197.8
avg_sample_per_episode: 197.8
avg_envstep_per_sec: 2590.5308864155536
avg_train_sample_per_sec: 2590.5308864155536
avg_episode_per_sec: 13.096718333749008
collect_time: 1.1453250820357352
reward_mean: 1408.2821906392687
reward_std: 431.55920018334575
reward_max: 2175.6428170633408
reward_min: 854.3137210961328
total_envstep_count: 15470618
total_train_sample_count: 11622585
total_episode_count: 35708
total_duration: 3157.811142482146
[2023-06-29 12:50:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2210
train_sample_count: 2210
avg_envstep_per_episode: 184.16666666666666
avg_sample_per_episode: 184.16666666666666
avg_envstep_per_sec: 2541.6863105215534
avg_train_sample_per_sec: 2541.6863105215534
avg_episode_per_sec: 13.801011640841013
collect_time: 0.8695014765793457
reward_mean: 1195.1300790918037
reward_std: 480.0014024178972
reward_max: 2666.651770096428
reward_min: 817.8086883824498
total_envstep_count: 15474930
total_train_sample_count: 11625995
total_episode_count: 35720
total_duration: 3158.6806439587253
[2023-06-29 12:50:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2068
train_sample_count: 2068
avg_envstep_per_episode: 206.8
avg_sample_per_episode: 206.8
avg_envstep_per_sec: 2687.8765882509197
avg_train_sample_per_sec: 2687.8765882509197
avg_episode_per_sec: 12.997468995410637
collect_time: 0.7693805619794875
reward_mean: 1598.4088189781319
reward_std: 908.7378927905365
reward_max: 3424.662843052599
reward_min: 468.6545626726005
total_envstep_count: 15479042
total_train_sample_count: 11629263
total_episode_count: 35730
total_duration: 3159.450024520705
[2023-06-29 12:50:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3122
train_sample_count: 3122
avg_envstep_per_episode: 283.8181818181818
avg_sample_per_episode: 283.8181818181818
avg_envstep_per_sec: 2596.095901677615
avg_train_sample_per_sec: 2596.095901677615
avg_episode_per_sec: 9.147038731087049
collect_time: 1.2025749888448043
reward_mean: 1747.3030242225216
reward_std: 771.2548915213334
reward_max: 3586.3127452525864
reward_min: 962.1091318055833
total_envstep_count: 15483666
total_train_sample_count: 11632785
total_episode_count: 35741
total_duration: 3160.65259950955
[2023-06-29 12:50:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2079
train_sample_count: 2079
avg_envstep_per_episode: 259.875
avg_sample_per_episode: 259.875
avg_envstep_per_sec: 2681.9969551304403
avg_train_sample_per_sec: 2681.9969551304403
avg_episode_per_sec: 10.320334603676539
collect_time: 0.7751686652824282
reward_mean: 1432.9389188124367
reward_std: 491.70278510377364
reward_max: 2498.0779612029323
reward_min: 992.1463616386493
total_envstep_count: 15488090
total_train_sample_count: 11636064
total_episode_count: 35749
total_duration: 3161.427768174832
[2023-06-29 12:51:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2915
train_sample_count: 2915
avg_envstep_per_episode: 323.8888888888889
avg_sample_per_episode: 323.8888888888889
avg_envstep_per_sec: 2621.861464399486
avg_train_sample_per_sec: 2621.861464399486
avg_episode_per_sec: 8.094941056464966
collect_time: 1.111805501389317
reward_mean: 2360.8210516517865
reward_std: 682.6931979956242
reward_max: 3417.3252908200575
reward_min: 1047.7634160846317
total_envstep_count: 15492218
total_train_sample_count: 11639379
total_episode_count: 35758
total_duration: 3162.5395736762216
[2023-06-29 12:51:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2486
train_sample_count: 2486
avg_envstep_per_episode: 310.75
avg_sample_per_episode: 310.75
avg_envstep_per_sec: 2804.3925150249834
avg_train_sample_per_sec: 2804.3925150249834
avg_episode_per_sec: 9.024593773209922
collect_time: 0.8864664937881754
reward_mean: 1656.469615868659
reward_std: 426.722921200738
reward_max: 2537.9069310611353
reward_min: 1265.426219265448
total_envstep_count: 15497186
total_train_sample_count: 11642665
total_episode_count: 35766
total_duration: 3163.42604017001
[2023-06-29 12:51:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 453
train_sample_count: 453
avg_envstep_per_episode: 113.25
avg_sample_per_episode: 113.25
avg_envstep_per_sec: 2586.5655982022085
avg_train_sample_per_sec: 2586.5655982022085
avg_episode_per_sec: 22.839431330703828
collect_time: 0.17513570903241638
reward_mean: 1906.2903523895602
reward_std: 820.3401599541811
reward_max: 2898.120169203887
reward_min: 1033.415155886527
total_envstep_count: 15500826
total_train_sample_count: 11645918
total_episode_count: 35770
total_duration: 3163.6011758790423
[2023-06-29 12:51:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2543
train_sample_count: 2543
avg_envstep_per_episode: 317.875
avg_sample_per_episode: 317.875
avg_envstep_per_sec: 2622.8003761252107
avg_train_sample_per_sec: 2622.8003761252107
avg_episode_per_sec: 8.251043259536644
collect_time: 0.9695743614910168
reward_mean: 2985.364623007481
reward_std: 762.5396189676703
reward_max: 3558.8289519008886
reward_min: 1337.9932849858722
total_envstep_count: 15505514
total_train_sample_count: 11649261
total_episode_count: 35778
total_duration: 3164.5707502405335
[2023-06-29 12:51:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2221
train_sample_count: 2221
avg_envstep_per_episode: 246.77777777777777
avg_sample_per_episode: 246.77777777777777
avg_envstep_per_sec: 2748.4245238742933
avg_train_sample_per_sec: 2748.4245238742933
avg_episode_per_sec: 11.137244806334373
collect_time: 0.808099324069917
reward_mean: 1849.5189346390098
reward_std: 729.1206548284853
reward_max: 3128.0066699460353
reward_min: 1020.4120079305779
total_envstep_count: 15509722
total_train_sample_count: 11652682
total_episode_count: 35787
total_duration: 3165.3788495646036
[2023-06-29 12:51:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3256
train_sample_count: 3256
avg_envstep_per_episode: 232.57142857142858
avg_sample_per_episode: 232.57142857142858
avg_envstep_per_sec: 2740.614074380191
avg_train_sample_per_sec: 2740.614074380191
avg_episode_per_sec: 11.783967150283377
collect_time: 1.1880549072697757
reward_mean: 1371.756997054355
reward_std: 808.1279971695319
reward_max: 3471.989453715931
reward_min: 716.8664040242267
total_envstep_count: 15514106
total_train_sample_count: 11655938
total_episode_count: 35801
total_duration: 3166.5669044718734
[2023-06-29 12:51:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2727
train_sample_count: 2727
avg_envstep_per_episode: 247.9090909090909
avg_sample_per_episode: 247.9090909090909
avg_envstep_per_sec: 2725.4244261552017
avg_train_sample_per_sec: 2725.4244261552017
avg_episode_per_sec: 10.993644549947641
collect_time: 1.0005781021956353
reward_mean: 1239.3405288408712
reward_std: 472.2058476134941
reward_max: 2233.4118362474424
reward_min: 532.6164668611091
total_envstep_count: 15518722
total_train_sample_count: 11659465
total_episode_count: 35812
total_duration: 3167.567482574069
[2023-06-29 12:51:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2657
train_sample_count: 2657
avg_envstep_per_episode: 241.54545454545453
avg_sample_per_episode: 241.54545454545453
avg_envstep_per_sec: 2632.723227858723
avg_train_sample_per_sec: 2632.723227858723
avg_episode_per_sec: 10.899493980596896
collect_time: 1.0092211638065054
reward_mean: 1546.5471166760283
reward_std: 777.278570125554
reward_max: 3550.363206603282
reward_min: 556.9913763341335
total_envstep_count: 15523394
total_train_sample_count: 11662922
total_episode_count: 35823
total_duration: 3168.5767037378755
[2023-06-29 12:51:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3432
train_sample_count: 3432
avg_envstep_per_episode: 264.0
avg_sample_per_episode: 264.0
avg_envstep_per_sec: 2632.07305651421
avg_train_sample_per_sec: 2632.07305651421
avg_episode_per_sec: 9.96997369891746
collect_time: 1.303915174962953
reward_mean: 1530.5978451546505
reward_std: 708.174880444385
reward_max: 3589.500110723089
reward_min: 811.9293194614866
total_envstep_count: 15527626
total_train_sample_count: 11666354
total_episode_count: 35836
total_duration: 3169.8806189128386
[2023-06-29 12:51:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3031
train_sample_count: 3031
avg_envstep_per_episode: 233.15384615384616
avg_sample_per_episode: 233.15384615384616
avg_envstep_per_sec: 2707.83245357382
avg_train_sample_per_sec: 2707.83245357382
avg_episode_per_sec: 11.613930021926645
collect_time: 1.1193454735353587
reward_mean: 1065.8780873567605
reward_std: 275.18801463695354
reward_max: 1722.7131390260136
reward_min: 690.1617235377281
total_envstep_count: 15531850
total_train_sample_count: 11669785
total_episode_count: 35849
total_duration: 3170.999964386374
[2023-06-29 12:51:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3065
train_sample_count: 3065
avg_envstep_per_episode: 218.92857142857142
avg_sample_per_episode: 218.92857142857142
avg_envstep_per_sec: 2558.9675530527275
avg_train_sample_per_sec: 2558.9675530527275
avg_episode_per_sec: 11.688595674629097
collect_time: 1.197748676548712
reward_mean: 1097.6664349376078
reward_std: 473.8367672463057
reward_max: 2184.210278608265
reward_min: 558.2353014114751
total_envstep_count: 15536458
total_train_sample_count: 11673250
total_episode_count: 35863
total_duration: 3172.1977130629225
[2023-06-29 12:51:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 2537.291245244256
avg_train_sample_per_sec: 2537.291245244256
avg_episode_per_sec: 10.068616052556571
collect_time: 1.2911407021721826
reward_mean: 1345.4193539732528
reward_std: 615.1169954982286
reward_max: 2470.0154173129285
reward_min: 659.2346959505613
total_envstep_count: 15540858
total_train_sample_count: 11676526
total_episode_count: 35876
total_duration: 3173.4888537650945
[2023-06-29 12:51:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3182
train_sample_count: 3182
avg_envstep_per_episode: 227.28571428571428
avg_sample_per_episode: 227.28571428571428
avg_envstep_per_sec: 2573.786593862347
avg_train_sample_per_sec: 2573.786593862347
avg_episode_per_sec: 11.324013926484243
collect_time: 1.2363107367129995
reward_mean: 1120.2053094192217
reward_std: 361.8170100860242
reward_max: 2074.0671632246376
reward_min: 687.3894686390206
total_envstep_count: 15545690
total_train_sample_count: 11680108
total_episode_count: 35890
total_duration: 3174.7251645018077
[2023-06-29 12:51:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 2823
train_sample_count: 2823
avg_envstep_per_episode: 176.4375
avg_sample_per_episode: 176.4375
avg_envstep_per_sec: 2775.4926766982326
avg_train_sample_per_sec: 2775.4926766982326
avg_episode_per_sec: 15.730741348626186
collect_time: 1.017116717223078
reward_mean: 1016.1105536797804
reward_std: 259.5476794674667
reward_max: 1857.8988471349967
reward_min: 692.8494170225702
total_envstep_count: 15550066
total_train_sample_count: 11683331
total_episode_count: 35906
total_duration: 3175.7422812190307
[2023-06-29 12:51:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3270
train_sample_count: 3270
avg_envstep_per_episode: 233.57142857142858
avg_sample_per_episode: 233.57142857142858
avg_envstep_per_sec: 2763.9914109617366
avg_train_sample_per_sec: 2763.9914109617366
avg_episode_per_sec: 11.833602371090004
collect_time: 1.1830716937221584
reward_mean: 1245.7780938032415
reward_std: 564.4549678963209
reward_max: 2403.9399712930913
reward_min: 556.7347830328976
total_envstep_count: 15554226
total_train_sample_count: 11686601
total_episode_count: 35920
total_duration: 3176.9253529127527
[2023-06-29 12:51:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 235.21428571428572
avg_sample_per_episode: 235.21428571428572
avg_envstep_per_sec: 2563.5807559067807
avg_train_sample_per_sec: 2563.5807559067807
avg_episode_per_sec: 10.898916059123879
collect_time: 1.284531408816576
reward_mean: 1081.0461442306103
reward_std: 237.6920659708383
reward_max: 1759.5760342617223
reward_min: 828.8928817898285
total_envstep_count: 15558530
total_train_sample_count: 11689894
total_episode_count: 35934
total_duration: 3178.2098843215695
[2023-06-29 12:51:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 214.53333333333333
avg_sample_per_episode: 214.53333333333333
avg_envstep_per_sec: 2597.17426253196
avg_train_sample_per_sec: 2597.17426253196
avg_episode_per_sec: 12.106157221249035
collect_time: 1.2390389225799594
reward_mean: 1004.7433534930157
reward_std: 304.66288877981697
reward_max: 1948.5315761053157
reward_min: 544.8387706973375
total_envstep_count: 15562954
total_train_sample_count: 11693112
total_episode_count: 35949
total_duration: 3179.4489232441492
[2023-06-29 12:51:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1687
train_sample_count: 1687
avg_envstep_per_episode: 281.1666666666667
avg_sample_per_episode: 281.1666666666667
avg_envstep_per_sec: 2790.2535761517124
avg_train_sample_per_sec: 2790.2535761517124
avg_episode_per_sec: 9.923842001725118
collect_time: 0.6046045472063124
reward_mean: 1436.969588971813
reward_std: 643.4756459007667
reward_max: 2814.9149638146346
reward_min: 959.1695726620854
total_envstep_count: 15567322
total_train_sample_count: 11696399
total_episode_count: 35955
total_duration: 3180.0535277913555
[2023-06-29 12:51:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2525
train_sample_count: 2525
avg_envstep_per_episode: 210.41666666666666
avg_sample_per_episode: 210.41666666666666
avg_envstep_per_sec: 2775.690764415917
avg_train_sample_per_sec: 2775.690764415917
avg_episode_per_sec: 13.191401652669704
collect_time: 0.9096834677588196
reward_mean: 1645.4250663708383
reward_std: 1039.3629625379801
reward_max: 3548.445014597732
reward_min: 545.2386505317197
total_envstep_count: 15571426
total_train_sample_count: 11699724
total_episode_count: 35967
total_duration: 3180.9632112591144
[2023-06-29 12:51:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3358
train_sample_count: 3358
avg_envstep_per_episode: 223.86666666666667
avg_sample_per_episode: 223.86666666666667
avg_envstep_per_sec: 2531.170209228206
avg_train_sample_per_sec: 2531.170209228206
avg_episode_per_sec: 11.306597122818074
collect_time: 1.32665910327062
reward_mean: 1266.053978103625
reward_std: 667.1872905633217
reward_max: 3060.5955594342577
reward_min: 691.0318297043736
total_envstep_count: 15576178
total_train_sample_count: 11703082
total_episode_count: 35982
total_duration: 3182.289870362385
[2023-06-29 12:52:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3322
train_sample_count: 3322
avg_envstep_per_episode: 207.625
avg_sample_per_episode: 207.625
avg_envstep_per_sec: 2612.3340623064973
avg_train_sample_per_sec: 2612.3340623064973
avg_episode_per_sec: 12.58198223868271
collect_time: 1.2716597191505132
reward_mean: 1052.5400513428556
reward_std: 357.2564216379943
reward_max: 2312.897025096412
reward_min: 660.002132777832
total_envstep_count: 15580570
total_train_sample_count: 11706404
total_episode_count: 35998
total_duration: 3183.5615300815357
[2023-06-29 12:52:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3302
train_sample_count: 3302
avg_envstep_per_episode: 220.13333333333333
avg_sample_per_episode: 220.13333333333333
avg_envstep_per_sec: 2763.390134536337
avg_train_sample_per_sec: 2763.390134536337
avg_episode_per_sec: 12.553256213823458
collect_time: 1.194909093266353
reward_mean: 1054.9462308480408
reward_std: 142.7518741663933
reward_max: 1295.021130383587
reward_min: 863.175955756618
total_envstep_count: 15584842
total_train_sample_count: 11709706
total_episode_count: 36013
total_duration: 3184.756439174802
[2023-06-29 12:52:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2858
train_sample_count: 2858
avg_envstep_per_episode: 219.84615384615384
avg_sample_per_episode: 219.84615384615384
avg_envstep_per_sec: 2755.8552851006143
avg_train_sample_per_sec: 2755.8552851006143
avg_episode_per_sec: 12.535380932927916
collect_time: 1.0370646149134266
reward_mean: 1058.722467438644
reward_std: 244.4396376827727
reward_max: 1891.8784484619325
reward_min: 893.0798070374924
total_envstep_count: 15589178
total_train_sample_count: 11712964
total_episode_count: 36026
total_duration: 3185.7935037897155
[2023-06-29 12:52:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3173
train_sample_count: 3173
avg_envstep_per_episode: 244.07692307692307
avg_sample_per_episode: 244.07692307692307
avg_envstep_per_sec: 2576.0290995860237
avg_train_sample_per_sec: 2576.0290995860237
avg_episode_per_sec: 10.554169018158937
collect_time: 1.2317407441204415
reward_mean: 1292.5187961903127
reward_std: 479.0661073124566
reward_max: 2748.702839695816
reward_min: 823.10442056278
total_envstep_count: 15593442
total_train_sample_count: 11716537
total_episode_count: 36039
total_duration: 3187.025244533836
[2023-06-29 12:52:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2989
train_sample_count: 2989
avg_envstep_per_episode: 249.08333333333334
avg_sample_per_episode: 249.08333333333334
avg_envstep_per_sec: 2554.7157753591655
avg_train_sample_per_sec: 2554.7157753591655
avg_episode_per_sec: 10.256470158685175
collect_time: 1.1699931666878984
reward_mean: 1222.8927112294305
reward_std: 276.9441586815701
reward_max: 1814.7397380018292
reward_min: 785.7955705137739
total_envstep_count: 15597946
total_train_sample_count: 11719926
total_episode_count: 36051
total_duration: 3188.195237700524
[2023-06-29 12:52:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2930
train_sample_count: 2930
avg_envstep_per_episode: 244.16666666666666
avg_sample_per_episode: 244.16666666666666
avg_envstep_per_sec: 2603.5101145071653
avg_train_sample_per_sec: 2603.5101145071653
avg_episode_per_sec: 10.66284005941501
collect_time: 1.1254037323202941
reward_mean: 1352.0639089986523
reward_std: 573.3607942050671
reward_max: 2546.7757959519713
reward_min: 525.9419915281787
total_envstep_count: 15602242
total_train_sample_count: 11723256
total_episode_count: 36063
total_duration: 3189.3206414328442
[2023-06-29 12:52:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3265
train_sample_count: 3265
avg_envstep_per_episode: 272.0833333333333
avg_sample_per_episode: 272.0833333333333
avg_envstep_per_sec: 2747.1881194087823
avg_train_sample_per_sec: 2747.1881194087823
avg_episode_per_sec: 10.096862919726
collect_time: 1.1884879586268213
reward_mean: 1396.447439276673
reward_std: 562.6045288007737
reward_max: 2642.3450295516936
reward_min: 676.1355888434083
total_envstep_count: 15606618
total_train_sample_count: 11726521
total_episode_count: 36075
total_duration: 3190.509129391471
[2023-06-29 12:52:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 2633.2713032163015
avg_train_sample_per_sec: 2633.2713032163015
avg_episode_per_sec: 15.221221405874575
collect_time: 0.32848875045403836
reward_mean: 1271.9744601332302
reward_std: 327.28368166932086
reward_max: 1683.5635415816703
reward_min: 819.5595768756541
total_envstep_count: 15611250
total_train_sample_count: 11729786
total_episode_count: 36080
total_duration: 3190.8376181419253
[2023-06-29 12:52:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2860
train_sample_count: 2860
avg_envstep_per_episode: 317.77777777777777
avg_sample_per_episode: 317.77777777777777
avg_envstep_per_sec: 2557.831852281692
avg_train_sample_per_sec: 2557.831852281692
avg_episode_per_sec: 8.049121213473857
collect_time: 1.118134484660812
reward_mean: 2744.4594955046314
reward_std: 884.8853684278515
reward_max: 3557.688306586004
reward_min: 827.5759093649212
total_envstep_count: 15616234
total_train_sample_count: 11733046
total_episode_count: 36089
total_duration: 3191.955752626586
[2023-06-29 12:52:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1498
train_sample_count: 1498
avg_envstep_per_episode: 299.6
avg_sample_per_episode: 299.6
avg_envstep_per_sec: 2436.3467819429743
avg_train_sample_per_sec: 2436.3467819429743
avg_episode_per_sec: 8.13199860461607
collect_time: 0.6148549997489899
reward_mean: 1897.2700112378723
reward_std: 857.9381850674359
reward_max: 2763.3833972858133
reward_min: 433.93627980263204
total_envstep_count: 15620570
total_train_sample_count: 11736544
total_episode_count: 36094
total_duration: 3192.570607626335
[2023-06-29 12:52:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 905
train_sample_count: 905
avg_envstep_per_episode: 150.83333333333334
avg_sample_per_episode: 150.83333333333334
avg_envstep_per_sec: 2728.1818375847697
avg_train_sample_per_sec: 2728.1818375847697
avg_episode_per_sec: 18.087393398352063
collect_time: 0.3317227567210794
reward_mean: 2724.65225920914
reward_std: 849.1403002182017
reward_max: 3572.910182211574
reward_min: 1025.1307087587845
total_envstep_count: 15624770
total_train_sample_count: 11739849
total_episode_count: 36100
total_duration: 3192.902330383056
[2023-06-29 12:52:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1602
train_sample_count: 1602
avg_envstep_per_episode: 267.0
avg_sample_per_episode: 267.0
avg_envstep_per_sec: 2626.402247021943
avg_train_sample_per_sec: 2626.402247021943
avg_episode_per_sec: 9.836712535662707
collect_time: 0.6099598802188413
reward_mean: 2425.8347209228946
reward_std: 938.3046690158582
reward_max: 3513.923751488454
reward_min: 812.1181783517817
total_envstep_count: 15628586
total_train_sample_count: 11743051
total_episode_count: 36106
total_duration: 3193.5122902632747
[2023-06-29 12:52:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 305.0
avg_sample_per_episode: 305.0
avg_envstep_per_sec: 2507.3619062443854
avg_train_sample_per_sec: 2507.3619062443854
avg_episode_per_sec: 8.220858708997985
collect_time: 0.8514925566520541
reward_mean: 2669.136959008119
reward_std: 1056.4903490116274
reward_max: 3541.904098905774
reward_min: 994.1650738057426
total_envstep_count: 15633378
total_train_sample_count: 11746386
total_episode_count: 36113
total_duration: 3194.3637828199267
[2023-06-29 12:52:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1665
train_sample_count: 1665
avg_envstep_per_episode: 333.0
avg_sample_per_episode: 333.0
avg_envstep_per_sec: 2710.6424012612197
avg_train_sample_per_sec: 2710.6424012612197
avg_episode_per_sec: 8.140067271054713
collect_time: 0.6142455379674211
reward_mean: 2716.391440272663
reward_std: 1000.40776072383
reward_max: 3552.5193105562935
reward_min: 1351.414973424908
total_envstep_count: 15638522
total_train_sample_count: 11749651
total_episode_count: 36118
total_duration: 3194.978028357894
[2023-06-29 12:52:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1774
train_sample_count: 1774
avg_envstep_per_episode: 221.75
avg_sample_per_episode: 221.75
avg_envstep_per_sec: 2738.018824562476
avg_train_sample_per_sec: 2738.018824562476
avg_episode_per_sec: 12.347322771420409
collect_time: 0.6479137338595464
reward_mean: 2451.954310097549
reward_std: 1106.8577512403774
reward_max: 3525.245866749546
reward_min: 829.0500597174517
total_envstep_count: 15643074
total_train_sample_count: 11753025
total_episode_count: 36126
total_duration: 3195.6259420917536
[2023-06-29 12:52:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 253.625
avg_sample_per_episode: 253.625
avg_envstep_per_sec: 2512.0347793800483
avg_train_sample_per_sec: 2512.0347793800483
avg_episode_per_sec: 9.904523526387573
collect_time: 0.8077117469292134
reward_mean: 2110.002860921911
reward_std: 1028.7600068997162
reward_max: 3525.6293443287473
reward_min: 982.244442491494
total_envstep_count: 15647514
total_train_sample_count: 11756254
total_episode_count: 36134
total_duration: 3196.433653838683
[2023-06-29 12:52:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1476
train_sample_count: 1476
avg_envstep_per_episode: 295.2
avg_sample_per_episode: 295.2
avg_envstep_per_sec: 2748.800931318584
avg_train_sample_per_sec: 2748.800931318584
avg_episode_per_sec: 9.311656271404418
collect_time: 0.5369614013088868
reward_mean: 2852.580439992364
reward_std: 844.619817129342
reward_max: 3526.675150823203
reward_min: 1527.6549846014793
total_envstep_count: 15652250
total_train_sample_count: 11759730
total_episode_count: 36139
total_duration: 3196.9706152399917
[2023-06-29 12:52:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1633
train_sample_count: 1633
avg_envstep_per_episode: 272.1666666666667
avg_sample_per_episode: 272.1666666666667
avg_envstep_per_sec: 2664.8855872162303
avg_train_sample_per_sec: 2664.8855872162303
avg_episode_per_sec: 9.791373866073107
collect_time: 0.6127842815592883
reward_mean: 2836.8805157678994
reward_std: 735.8917852771723
reward_max: 3546.0820322609493
reward_min: 1729.8481914010315
total_envstep_count: 15656778
total_train_sample_count: 11762963
total_episode_count: 36145
total_duration: 3197.583399521551
[2023-06-29 12:52:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1511
train_sample_count: 1511
avg_envstep_per_episode: 215.85714285714286
avg_sample_per_episode: 215.85714285714286
avg_envstep_per_sec: 2700.682769954941
avg_train_sample_per_sec: 2700.682769954941
avg_episode_per_sec: 12.511435731095029
collect_time: 0.5594881475195289
reward_mean: 1908.9644248144791
reward_std: 1062.7213693411927
reward_max: 3518.6244986492416
reward_min: 950.6887701143011
total_envstep_count: 15661378
total_train_sample_count: 11766474
total_episode_count: 36152
total_duration: 3198.1428876690707
[2023-06-29 12:53:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 201.4
avg_sample_per_episode: 201.4
avg_envstep_per_sec: 2479.7403406011113
avg_train_sample_per_sec: 2479.7403406011113
avg_episode_per_sec: 12.312514104275627
collect_time: 0.8121818107422443
reward_mean: 2251.796966500815
reward_std: 1309.8833837189554
reward_max: 3559.311808807336
reward_min: 679.5443179030945
total_envstep_count: 15665658
total_train_sample_count: 11769688
total_episode_count: 36162
total_duration: 3198.955069479813
[2023-06-29 12:53:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 819
train_sample_count: 819
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2725.081805774597
avg_train_sample_per_sec: 2725.081805774597
avg_episode_per_sec: 9.981984636536984
collect_time: 0.30054143632110214
reward_mean: 1306.9566802557313
reward_std: 834.321844900635
reward_max: 2461.7597041716085
reward_min: 519.884251660176
total_envstep_count: 15669114
total_train_sample_count: 11772907
total_episode_count: 36165
total_duration: 3199.255610916134
[2023-06-29 12:53:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1323
train_sample_count: 1323
avg_envstep_per_episode: 165.375
avg_sample_per_episode: 165.375
avg_envstep_per_sec: 2733.7303044901732
avg_train_sample_per_sec: 2733.7303044901732
avg_episode_per_sec: 16.530493148844585
collect_time: 0.48395410396810623
reward_mean: 2694.5485847164628
reward_std: 884.4204645140973
reward_max: 3605.546648557197
reward_min: 997.5184638323655
total_envstep_count: 15673250
total_train_sample_count: 11776230
total_episode_count: 36173
total_duration: 3199.7395650201024
[2023-06-29 12:53:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2559
train_sample_count: 2559
avg_envstep_per_episode: 426.5
avg_sample_per_episode: 426.5
avg_envstep_per_sec: 2608.208010075447
avg_train_sample_per_sec: 2608.208010075447
avg_episode_per_sec: 6.115376342498117
collect_time: 0.9811334027480333
reward_mean: 2974.677673533439
reward_std: 749.3344546988671
reward_max: 3573.2747684795386
reward_min: 1439.5877596991959
total_envstep_count: 15677778
total_train_sample_count: 11779589
total_episode_count: 36179
total_duration: 3200.7206984228505
[2023-06-29 12:53:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 164.42857142857142
avg_sample_per_episode: 164.42857142857142
avg_envstep_per_sec: 2352.602545296425
avg_train_sample_per_sec: 2352.602545296425
avg_episode_per_sec: 14.307747886251065
collect_time: 0.48924541134294125
reward_mean: 1845.3425923251502
reward_std: 1056.0573001224259
reward_max: 3544.0512286883068
reward_min: 659.771559654522
total_envstep_count: 15682906
total_train_sample_count: 11783140
total_episode_count: 36186
total_duration: 3201.2099438341934
[2023-06-29 12:53:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2599
train_sample_count: 2599
avg_envstep_per_episode: 259.9
avg_sample_per_episode: 259.9
avg_envstep_per_sec: 2556.0287124349666
avg_train_sample_per_sec: 2556.0287124349666
avg_episode_per_sec: 9.834662225605873
collect_time: 1.016811738990247
reward_mean: 2393.8189640711053
reward_std: 1007.6238758610126
reward_max: 3646.413382637068
reward_min: 654.9411180463786
total_envstep_count: 15687706
total_train_sample_count: 11786539
total_episode_count: 36196
total_duration: 3202.2267555731837
[2023-06-29 12:53:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2103
train_sample_count: 2103
avg_envstep_per_episode: 262.875
avg_sample_per_episode: 262.875
avg_envstep_per_sec: 2710.0483332510057
avg_train_sample_per_sec: 2710.0483332510057
avg_episode_per_sec: 10.30926612744082
collect_time: 0.7760009200563655
reward_mean: 1863.7261980312187
reward_std: 813.4752651822839
reward_max: 3552.527368051648
reward_min: 992.3720102630871
total_envstep_count: 15692138
total_train_sample_count: 11789842
total_episode_count: 36204
total_duration: 3203.00275649324
[2023-06-29 12:53:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2020
train_sample_count: 2020
avg_envstep_per_episode: 288.57142857142856
avg_sample_per_episode: 288.57142857142856
avg_envstep_per_sec: 2763.696623409091
avg_train_sample_per_sec: 2763.696623409091
avg_episode_per_sec: 9.577166516764176
collect_time: 0.7309051155941559
reward_mean: 2229.188828466969
reward_std: 1133.2162472289615
reward_max: 3610.362677449448
reward_min: 960.274318948625
total_envstep_count: 15696442
total_train_sample_count: 11793062
total_episode_count: 36211
total_duration: 3203.733661608834
[2023-06-29 12:53:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 258.25
avg_sample_per_episode: 258.25
avg_envstep_per_sec: 2742.8647973123325
avg_train_sample_per_sec: 2742.8647973123325
avg_episode_per_sec: 10.620967269360435
collect_time: 0.7532270646458491
reward_mean: 2061.5148728813724
reward_std: 966.3751780886229
reward_max: 3561.9902047324554
reward_min: 1142.0106189514445
total_envstep_count: 15700570
total_train_sample_count: 11796328
total_episode_count: 36219
total_duration: 3204.48688867348
[2023-06-29 12:53:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 272.75
avg_sample_per_episode: 272.75
avg_envstep_per_sec: 2753.5204277330836
avg_train_sample_per_sec: 2753.5204277330836
avg_episode_per_sec: 10.095400284997556
collect_time: 0.39622004943620404
reward_mean: 2269.506922278469
reward_std: 1276.2007625118442
reward_max: 3554.4675201252367
reward_min: 961.7852041294179
total_envstep_count: 15704786
total_train_sample_count: 11799819
total_episode_count: 36223
total_duration: 3204.883108722916
[2023-06-29 12:53:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2015
train_sample_count: 2015
avg_envstep_per_episode: 335.8333333333333
avg_sample_per_episode: 335.8333333333333
avg_envstep_per_sec: 2496.1123459513665
avg_train_sample_per_sec: 2496.1123459513665
avg_episode_per_sec: 7.432592593403573
collect_time: 0.8072553317835557
reward_mean: 3101.1094002084496
reward_std: 944.7241445566017
reward_max: 3545.1058152506844
reward_min: 988.7845382624954
total_envstep_count: 15708594
total_train_sample_count: 11803034
total_episode_count: 36229
total_duration: 3205.6903640546993
[2023-06-29 12:53:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2817
train_sample_count: 2817
avg_envstep_per_episode: 313.0
avg_sample_per_episode: 313.0
avg_envstep_per_sec: 2778.0017282541007
avg_train_sample_per_sec: 2778.0017282541007
avg_episode_per_sec: 8.87540488260096
collect_time: 1.0140382460346447
reward_mean: 2025.4769539280137
reward_std: 1115.7199615680142
reward_max: 3497.61775263948
reward_min: 795.9703017241627
total_envstep_count: 15712890
total_train_sample_count: 11806251
total_episode_count: 36238
total_duration: 3206.704402300734
[2023-06-29 12:53:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1948
train_sample_count: 1948
avg_envstep_per_episode: 278.2857142857143
avg_sample_per_episode: 278.2857142857143
avg_envstep_per_sec: 2786.6708164318056
avg_train_sample_per_sec: 2786.6708164318056
avg_episode_per_sec: 10.01370416582271
collect_time: 0.6990420212224125
reward_mean: 1613.4323672099838
reward_std: 812.6299375843093
reward_max: 3497.433694108096
reward_min: 999.2989551616363
total_envstep_count: 15717458
total_train_sample_count: 11809799
total_episode_count: 36245
total_duration: 3207.403444321956
[2023-06-29 12:53:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1843
train_sample_count: 1843
avg_envstep_per_episode: 368.6
avg_sample_per_episode: 368.6
avg_envstep_per_sec: 2573.198559645125
avg_train_sample_per_sec: 2573.198559645125
avg_episode_per_sec: 6.98100531645449
collect_time: 0.7162292210571468
reward_mean: 3134.9836356859837
reward_std: 799.2834325269934
reward_max: 3570.3332139266868
reward_min: 1536.8569224877124
total_envstep_count: 15721890
total_train_sample_count: 11813242
total_episode_count: 36250
total_duration: 3208.1196735430135
[2023-06-29 12:53:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 265.6
avg_sample_per_episode: 265.6
avg_envstep_per_sec: 2689.914737548215
avg_train_sample_per_sec: 2689.914737548215
avg_episode_per_sec: 10.127691029925508
collect_time: 0.49369594562333097
reward_mean: 2578.342967788549
reward_std: 1173.3182090217763
reward_max: 3585.0302235864287
reward_min: 1129.3006224663677
total_envstep_count: 15726386
total_train_sample_count: 11816570
total_episode_count: 36255
total_duration: 3208.6133694886366
[2023-06-29 12:53:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 820
train_sample_count: 820
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2648.2847871458043
avg_train_sample_per_sec: 2648.2847871458043
avg_episode_per_sec: 12.918462376320997
collect_time: 0.3096343731535599
reward_mean: 2877.680778596908
reward_std: 1107.5897116896836
reward_max: 3544.9457187559697
reward_min: 959.5249186077959
total_envstep_count: 15730474
total_train_sample_count: 11819790
total_episode_count: 36259
total_duration: 3208.92300386179
[2023-06-29 12:53:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 2819.4376586722065
avg_train_sample_per_sec: 2819.4376586722065
avg_episode_per_sec: 11.507908810906965
collect_time: 0.8689676086520777
reward_mean: 2465.5420145737185
reward_std: 1288.1867582958218
reward_max: 3529.54690820757
reward_min: 562.5027091859198
total_envstep_count: 15735274
total_train_sample_count: 11823040
total_episode_count: 36269
total_duration: 3209.791971470442
[2023-06-29 12:53:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1708
train_sample_count: 1708
avg_envstep_per_episode: 284.6666666666667
avg_sample_per_episode: 284.6666666666667
avg_envstep_per_sec: 2744.48091809129
avg_train_sample_per_sec: 2744.48091809129
avg_episode_per_sec: 9.641033670109918
collect_time: 0.6223399072447793
reward_mean: 1939.9407453206547
reward_std: 1124.9244102711332
reward_max: 3529.4788820443805
reward_min: 912.8334781243448
total_envstep_count: 15739802
total_train_sample_count: 11826348
total_episode_count: 36275
total_duration: 3210.4143113776868
[2023-06-29 12:53:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1889
train_sample_count: 1889
avg_envstep_per_episode: 209.88888888888889
avg_sample_per_episode: 209.88888888888889
avg_envstep_per_sec: 2596.72954236986
avg_train_sample_per_sec: 2596.72954236986
avg_episode_per_sec: 12.371924765129032
collect_time: 0.7274535022526978
reward_mean: 2167.079492690058
reward_std: 1027.0111951057547
reward_max: 3504.155604894985
reward_min: 907.2117842165284
total_envstep_count: 15744698
total_train_sample_count: 11829837
total_episode_count: 36284
total_duration: 3211.1417648799393
[2023-06-29 12:53:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 314.6666666666667
avg_sample_per_episode: 314.6666666666667
avg_envstep_per_sec: 2658.9383047226165
avg_train_sample_per_sec: 2658.9383047226165
avg_episode_per_sec: 8.45001579890662
collect_time: 0.35502892200369396
reward_mean: 2973.9775205926635
reward_std: 770.0150616780287
reward_max: 3527.720224253427
reward_min: 1885.0645710449119
total_envstep_count: 15748738
total_train_sample_count: 11833181
total_episode_count: 36287
total_duration: 3211.496793801943
[2023-06-29 12:54:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1796
train_sample_count: 1796
avg_envstep_per_episode: 224.5
avg_sample_per_episode: 224.5
avg_envstep_per_sec: 2758.1629511334904
avg_train_sample_per_sec: 2758.1629511334904
avg_episode_per_sec: 12.285803791240491
collect_time: 0.6511580467941238
reward_mean: 2727.703123343583
reward_std: 1114.1416096099183
reward_max: 3536.0119232439333
reward_min: 800.869558827136
total_envstep_count: 15752818
total_train_sample_count: 11836577
total_episode_count: 36295
total_duration: 3212.147951848737
[2023-06-29 12:54:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2131
train_sample_count: 2131
avg_envstep_per_episode: 304.42857142857144
avg_sample_per_episode: 304.42857142857144
avg_envstep_per_sec: 2470.065470784572
avg_train_sample_per_sec: 2470.065470784572
avg_episode_per_sec: 8.113776769353358
collect_time: 0.8627301685744897
reward_mean: 1777.2762685341188
reward_std: 859.366686320572
reward_max: 3486.491416789719
reward_min: 1013.5497941751747
total_envstep_count: 15757122
total_train_sample_count: 11839908
total_episode_count: 36302
total_duration: 3213.010682017312
[2023-06-29 12:54:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 180.28571428571428
avg_sample_per_episode: 180.28571428571428
avg_envstep_per_sec: 2740.1983930192223
avg_train_sample_per_sec: 2740.1983930192223
avg_episode_per_sec: 15.199198693450521
collect_time: 0.46055059488210826
reward_mean: 2046.424002408726
reward_std: 1266.3600023833887
reward_max: 3533.84918299387
reward_min: 796.1682726807072
total_envstep_count: 15761962
total_train_sample_count: 11843170
total_episode_count: 36309
total_duration: 3213.471232612194
[2023-06-29 12:54:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2283
train_sample_count: 2283
avg_envstep_per_episode: 228.3
avg_sample_per_episode: 228.3
avg_envstep_per_sec: 2524.7933441479004
avg_train_sample_per_sec: 2524.7933441479004
avg_episode_per_sec: 11.059103566131846
collect_time: 0.9042324217511339
reward_mean: 2166.5893964552947
reward_std: 937.1974337653154
reward_max: 3526.427563327753
reward_min: 999.2106043383172
total_envstep_count: 15766826
total_train_sample_count: 11846653
total_episode_count: 36319
total_duration: 3214.375465033945
[2023-06-29 12:54:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1674
train_sample_count: 1674
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2777.9239496963523
avg_train_sample_per_sec: 2777.9239496963523
avg_episode_per_sec: 9.956716665578323
collect_time: 0.602608289612457
reward_mean: 2461.703474225951
reward_std: 1102.2490567724894
reward_max: 3522.6131019329096
reward_min: 982.8445331552708
total_envstep_count: 15771050
total_train_sample_count: 11849927
total_episode_count: 36325
total_duration: 3214.9780733235575
[2023-06-29 12:54:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3459
train_sample_count: 3459
avg_envstep_per_episode: 288.25
avg_sample_per_episode: 288.25
avg_envstep_per_sec: 2650.1287938726337
avg_train_sample_per_sec: 2650.1287938726337
avg_episode_per_sec: 9.19385531265441
collect_time: 1.3052195832887663
reward_mean: 1889.0066520589287
reward_std: 1031.9696616346955
reward_max: 3511.7452234922207
reward_min: 818.3323076207104
total_envstep_count: 15775562
total_train_sample_count: 11853386
total_episode_count: 36337
total_duration: 3216.2832929068463
[2023-06-29 12:54:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2577
train_sample_count: 2577
avg_envstep_per_episode: 257.7
avg_sample_per_episode: 257.7
avg_envstep_per_sec: 2690.8900289649564
avg_train_sample_per_sec: 2690.8900289649564
avg_episode_per_sec: 10.44194811395016
collect_time: 0.9576757029313592
reward_mean: 1208.7207346216765
reward_std: 308.0383774113511
reward_max: 1934.8151276775113
reward_min: 886.4517628725476
total_envstep_count: 15779874
total_train_sample_count: 11856763
total_episode_count: 36347
total_duration: 3217.2409686097776
[2023-06-29 12:54:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1814
train_sample_count: 1814
avg_envstep_per_episode: 201.55555555555554
avg_sample_per_episode: 201.55555555555554
avg_envstep_per_sec: 2629.110755191542
avg_train_sample_per_sec: 2629.110755191542
avg_episode_per_sec: 13.04409966743323
collect_time: 0.6899671291587874
reward_mean: 1416.3586187943079
reward_std: 796.6978001134984
reward_max: 3484.1651883724335
reward_min: 679.6948157377235
total_envstep_count: 15784490
total_train_sample_count: 11860177
total_episode_count: 36356
total_duration: 3217.9309357389366
[2023-06-29 12:54:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2536
train_sample_count: 2536
avg_envstep_per_episode: 253.6
avg_sample_per_episode: 253.6
avg_envstep_per_sec: 2715.519319067028
avg_train_sample_per_sec: 2715.519319067028
avg_episode_per_sec: 10.707883750264306
collect_time: 0.9338913489561527
reward_mean: 1923.9759388124726
reward_std: 1186.6509326592352
reward_max: 3604.2173178740227
reward_min: 819.3110371201803
total_envstep_count: 15788714
total_train_sample_count: 11863513
total_episode_count: 36366
total_duration: 3218.8648270878925
[2023-06-29 12:54:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 344.0
avg_sample_per_episode: 344.0
avg_envstep_per_sec: 2776.2329486039384
avg_train_sample_per_sec: 2776.2329486039384
avg_episode_per_sec: 8.070444618034704
collect_time: 0.4956356420638037
reward_mean: 2359.1100416523705
reward_std: 1134.2699378032112
reward_max: 3509.9542125962867
reward_min: 1112.0353439460655
total_envstep_count: 15793074
total_train_sample_count: 11866889
total_episode_count: 36370
total_duration: 3219.3604627299565
[2023-06-29 12:54:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3190
train_sample_count: 3190
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 2568.769983145137
avg_train_sample_per_sec: 2568.769983145137
avg_episode_per_sec: 8.857827528086679
collect_time: 1.241839487743564
reward_mean: 2186.6867472042986
reward_std: 1079.0655611612403
reward_max: 3637.524309389751
reward_min: 1000.9373376280333
total_envstep_count: 15798538
total_train_sample_count: 11870479
total_episode_count: 36381
total_duration: 3220.6023022177
[2023-06-29 12:54:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2513
train_sample_count: 2513
avg_envstep_per_episode: 209.41666666666666
avg_sample_per_episode: 209.41666666666666
avg_envstep_per_sec: 2645.78008933816
avg_train_sample_per_sec: 2645.78008933816
avg_episode_per_sec: 12.63404738243451
collect_time: 0.9498143893843517
reward_mean: 1320.6623691486573
reward_std: 446.44555477394
reward_max: 2225.96601734585
reward_min: 916.0487610699938
total_envstep_count: 15802946
total_train_sample_count: 11873792
total_episode_count: 36393
total_duration: 3221.5521166070844
[2023-06-29 12:54:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3265
train_sample_count: 3265
avg_envstep_per_episode: 233.21428571428572
avg_sample_per_episode: 233.21428571428572
avg_envstep_per_sec: 2594.3891886605784
avg_train_sample_per_sec: 2594.3891886605784
avg_episode_per_sec: 11.124486566997886
collect_time: 1.2584850469892845
reward_mean: 1425.5413777567478
reward_std: 852.4182690473758
reward_max: 3459.4251540082614
reward_min: 558.4385919194063
total_envstep_count: 15807522
total_train_sample_count: 11877057
total_episode_count: 36407
total_duration: 3222.8106016540737
[2023-06-29 12:54:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2604
train_sample_count: 2604
avg_envstep_per_episode: 260.4
avg_sample_per_episode: 260.4
avg_envstep_per_sec: 2730.953270800189
avg_train_sample_per_sec: 2730.953270800189
avg_episode_per_sec: 10.487531761905487
collect_time: 0.9535132028227672
reward_mean: 1414.1143958294117
reward_std: 706.4216414272427
reward_max: 2977.229012388746
reward_min: 789.0138367130498
total_envstep_count: 15812442
total_train_sample_count: 11880461
total_episode_count: 36417
total_duration: 3223.7641148568964
[2023-06-29 12:54:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3531
train_sample_count: 3531
avg_envstep_per_episode: 207.7058823529412
avg_sample_per_episode: 207.7058823529412
avg_envstep_per_sec: 2602.5152129910666
avg_train_sample_per_sec: 2602.5152129910666
avg_episode_per_sec: 12.52980986146931
collect_time: 1.3567644032873212
reward_mean: 1237.4758541388155
reward_std: 663.5130784602798
reward_max: 3558.0850931974433
reward_min: 844.0822728616469
total_envstep_count: 15817434
total_train_sample_count: 11883992
total_episode_count: 36434
total_duration: 3225.1208792601838
[2023-06-29 12:54:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3043
train_sample_count: 3043
avg_envstep_per_episode: 234.07692307692307
avg_sample_per_episode: 234.07692307692307
avg_envstep_per_sec: 2725.394588835215
avg_train_sample_per_sec: 2725.394588835215
avg_episode_per_sec: 11.643157954274661
collect_time: 1.1165355697358026
reward_mean: 1173.9415028494143
reward_std: 192.10038447699992
reward_max: 1476.398460847705
reward_min: 903.4041474136903
total_envstep_count: 15822466
total_train_sample_count: 11887435
total_episode_count: 36447
total_duration: 3226.2374148299195
[2023-06-29 12:54:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2585
train_sample_count: 2585
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2628.618567876418
avg_train_sample_per_sec: 2628.618567876418
avg_episode_per_sec: 11.185610927133695
collect_time: 0.9834062771946193
reward_mean: 1565.506435911743
reward_std: 933.2718127167651
reward_max: 3556.7966081224745
reward_min: 898.6314033060056
total_envstep_count: 15827162
total_train_sample_count: 11890820
total_episode_count: 36458
total_duration: 3227.2208211071143
[2023-06-29 12:54:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3238
train_sample_count: 3238
avg_envstep_per_episode: 202.375
avg_sample_per_episode: 202.375
avg_envstep_per_sec: 2620.6434537544687
avg_train_sample_per_sec: 2620.6434537544687
avg_episode_per_sec: 12.949442637452593
collect_time: 1.2355744141237812
reward_mean: 1198.552348290607
reward_std: 731.7578640617932
reward_max: 3555.192855350502
reward_min: 670.4211083343811
total_envstep_count: 15831314
total_train_sample_count: 11894058
total_episode_count: 36474
total_duration: 3228.456395521238
[2023-06-29 12:54:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2941
train_sample_count: 2941
avg_envstep_per_episode: 226.23076923076923
avg_sample_per_episode: 226.23076923076923
avg_envstep_per_sec: 2785.765712493971
avg_train_sample_per_sec: 2785.765712493971
avg_episode_per_sec: 12.31382327862007
collect_time: 1.0557241001315414
reward_mean: 1052.5301537926964
reward_std: 204.2075129661372
reward_max: 1580.7773464100774
reward_min: 755.1082272583592
total_envstep_count: 15835890
total_train_sample_count: 11897399
total_episode_count: 36487
total_duration: 3229.5121196213695
[2023-06-29 12:54:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2378
train_sample_count: 2378
avg_envstep_per_episode: 237.8
avg_sample_per_episode: 237.8
avg_envstep_per_sec: 2758.2188740229826
avg_train_sample_per_sec: 2758.2188740229826
avg_episode_per_sec: 11.598901909264015
collect_time: 0.8621505792727693
reward_mean: 1441.5647134241758
reward_std: 641.1038699272932
reward_max: 2768.112854920001
reward_min: 965.1605637202302
total_envstep_count: 15840682
total_train_sample_count: 11900977
total_episode_count: 36497
total_duration: 3230.374270200642
[2023-06-29 12:55:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3017
train_sample_count: 3017
avg_envstep_per_episode: 232.07692307692307
avg_sample_per_episode: 232.07692307692307
avg_envstep_per_sec: 2824.0109499003797
avg_train_sample_per_sec: 2824.0109499003797
avg_episode_per_sec: 12.168426366822981
collect_time: 1.068338633781299
reward_mean: 1516.5482671070104
reward_std: 699.725670682877
reward_max: 2938.5652131849342
reward_min: 858.0947046886855
total_envstep_count: 15845842
total_train_sample_count: 11904394
total_episode_count: 36510
total_duration: 3231.4426088344235
[2023-06-29 12:55:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1630
train_sample_count: 1630
avg_envstep_per_episode: 232.85714285714286
avg_sample_per_episode: 232.85714285714286
avg_envstep_per_sec: 2629.6967394231265
avg_train_sample_per_sec: 2629.6967394231265
avg_episode_per_sec: 11.29317618157171
collect_time: 0.6198433361398057
reward_mean: 1640.1814825043562
reward_std: 790.9560708857622
reward_max: 3327.7987812578704
reward_min: 968.9609990490259
total_envstep_count: 15850074
total_train_sample_count: 11907624
total_episode_count: 36517
total_duration: 3232.062452170563
[2023-06-29 12:55:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1473
train_sample_count: 1473
avg_envstep_per_episode: 184.125
avg_sample_per_episode: 184.125
avg_envstep_per_sec: 2753.713216375692
avg_train_sample_per_sec: 2753.713216375692
avg_episode_per_sec: 14.955672594029554
collect_time: 0.5349140902692451
reward_mean: 1980.3893735174672
reward_std: 990.9364388234516
reward_max: 3503.3547566003167
reward_min: 958.3191908595618
total_envstep_count: 15854402
total_train_sample_count: 11911497
total_episode_count: 36525
total_duration: 3232.5973662608326
[2023-06-29 12:55:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1632
train_sample_count: 1632
avg_envstep_per_episode: 272.0
avg_sample_per_episode: 272.0
avg_envstep_per_sec: 2755.181992212104
avg_train_sample_per_sec: 2755.181992212104
avg_episode_per_sec: 10.129345559603324
collect_time: 0.5923383662542328
reward_mean: 2042.570577400995
reward_std: 1043.2701165248125
reward_max: 3530.6524594629004
reward_min: 843.8446137615208
total_envstep_count: 15858866
total_train_sample_count: 11914729
total_episode_count: 36531
total_duration: 3233.189704627087
[2023-06-29 12:55:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1218
train_sample_count: 1218
avg_envstep_per_episode: 152.25
avg_sample_per_episode: 152.25
avg_envstep_per_sec: 2687.796668371642
avg_train_sample_per_sec: 2687.796668371642
avg_episode_per_sec: 17.653836902276797
collect_time: 0.4531592788742853
reward_mean: 2067.112846335942
reward_std: 1197.8454236977313
reward_max: 3600.1018746593236
reward_min: 784.0704050299497
total_envstep_count: 15863074
total_train_sample_count: 11917947
total_episode_count: 36539
total_duration: 3233.6428639059613
[2023-06-29 12:55:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2002
train_sample_count: 2002
avg_envstep_per_episode: 222.44444444444446
avg_sample_per_episode: 222.44444444444446
avg_envstep_per_sec: 2577.712289285399
avg_train_sample_per_sec: 2577.712289285399
avg_episode_per_sec: 11.588117184599698
collect_time: 0.7766576620368288
reward_mean: 2081.8877179074575
reward_std: 1031.1136192359052
reward_max: 3645.831161476315
reward_min: 974.7048015083996
total_envstep_count: 15867146
total_train_sample_count: 11921149
total_episode_count: 36548
total_duration: 3234.4195215679983
[2023-06-29 12:55:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 879
train_sample_count: 879
avg_envstep_per_episode: 146.5
avg_sample_per_episode: 146.5
avg_envstep_per_sec: 2793.72126186589
avg_train_sample_per_sec: 2793.72126186589
avg_episode_per_sec: 19.069769705569215
collect_time: 0.31463410899229344
reward_mean: 1915.510534858868
reward_std: 893.3367615973835
reward_max: 3637.501650997435
reward_min: 1022.4543737554154
total_envstep_count: 15871666
total_train_sample_count: 11924428
total_episode_count: 36554
total_duration: 3234.7341556769907
[2023-06-29 12:55:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2599
train_sample_count: 2599
avg_envstep_per_episode: 236.27272727272728
avg_sample_per_episode: 236.27272727272728
avg_envstep_per_sec: 2739.03523703661
avg_train_sample_per_sec: 2739.03523703661
avg_episode_per_sec: 11.592684727742482
collect_time: 0.948874247712083
reward_mean: 2125.8054826551324
reward_std: 1016.2555148729984
reward_max: 3542.6515773219116
reward_min: 810.4578187257384
total_envstep_count: 15876290
total_train_sample_count: 11927827
total_episode_count: 36565
total_duration: 3235.6830299247026
[2023-06-29 12:55:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2407
train_sample_count: 2407
avg_envstep_per_episode: 218.8181818181818
avg_sample_per_episode: 218.8181818181818
avg_envstep_per_sec: 2731.211686773324
avg_train_sample_per_sec: 2731.211686773324
avg_episode_per_sec: 12.481648755507505
collect_time: 0.8812938270792366
reward_mean: 1435.6554164132117
reward_std: 388.0293448050189
reward_max: 2121.3372092366435
reward_min: 914.616156000728
total_envstep_count: 15879826
total_train_sample_count: 11931034
total_episode_count: 36576
total_duration: 3236.564323751782
[2023-06-29 12:55:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2820
train_sample_count: 2820
avg_envstep_per_episode: 256.3636363636364
avg_sample_per_episode: 256.3636363636364
avg_envstep_per_sec: 2620.310286861599
avg_train_sample_per_sec: 2620.310286861599
avg_episode_per_sec: 10.22106849485021
collect_time: 1.0762084223916755
reward_mean: 1175.2021639931568
reward_std: 654.8433239987794
reward_max: 2446.1177843067067
reward_min: 53.418422078659205
total_envstep_count: 15884346
total_train_sample_count: 11934254
total_episode_count: 36587
total_duration: 3237.6405321741736
[2023-06-29 12:55:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1713
train_sample_count: 1713
avg_envstep_per_episode: 190.33333333333334
avg_sample_per_episode: 190.33333333333334
avg_envstep_per_sec: 2673.640897273544
avg_train_sample_per_sec: 2673.640897273544
avg_episode_per_sec: 14.047150073241037
collect_time: 0.6406993556041272
reward_mean: 1461.8013703468841
reward_std: 868.6535276502448
reward_max: 3560.8261748618274
reward_min: 789.1916426723295
total_envstep_count: 15888674
total_train_sample_count: 11937567
total_episode_count: 36596
total_duration: 3238.281231529778
[2023-06-29 12:55:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2538
train_sample_count: 2538
avg_envstep_per_episode: 282.0
avg_sample_per_episode: 282.0
avg_envstep_per_sec: 2692.881086243696
avg_train_sample_per_sec: 2692.881086243696
avg_episode_per_sec: 9.549223710084027
collect_time: 0.9424849886484443
reward_mean: 2002.5563568729651
reward_std: 1066.9434516918081
reward_max: 3603.8592661728876
reward_min: 724.3544209952449
total_envstep_count: 15893274
total_train_sample_count: 11940905
total_episode_count: 36605
total_duration: 3239.2237165184265
[2023-06-29 12:55:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 941
train_sample_count: 941
avg_envstep_per_episode: 156.83333333333334
avg_sample_per_episode: 156.83333333333334
avg_envstep_per_sec: 2702.351730603032
avg_train_sample_per_sec: 2702.351730603032
avg_episode_per_sec: 17.230723043164925
collect_time: 0.3482152191158384
reward_mean: 1450.7834749826397
reward_std: 965.5702805487925
reward_max: 3567.5921635196505
reward_min: 750.8256548529566
total_envstep_count: 15897362
total_train_sample_count: 11944246
total_episode_count: 36611
total_duration: 3239.5719317375424
[2023-06-29 12:55:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2726
train_sample_count: 2726
avg_envstep_per_episode: 302.8888888888889
avg_sample_per_episode: 302.8888888888889
avg_envstep_per_sec: 2601.3888194163906
avg_train_sample_per_sec: 2601.3888194163906
avg_episode_per_sec: 8.588591113260277
collect_time: 1.0479017898645253
reward_mean: 2492.850246055741
reward_std: 1216.9175964333403
reward_max: 3558.892176710606
reward_min: 713.8160519872353
total_envstep_count: 15901994
total_train_sample_count: 11947772
total_episode_count: 36620
total_duration: 3240.619833527407
[2023-06-29 12:55:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1668
train_sample_count: 1668
avg_envstep_per_episode: 238.28571428571428
avg_sample_per_episode: 238.28571428571428
avg_envstep_per_sec: 2458.5420359360414
avg_train_sample_per_sec: 2458.5420359360414
avg_episode_per_sec: 10.317622452969
collect_time: 0.6784508768282832
reward_mean: 1969.251160213489
reward_std: 1192.6958198028688
reward_max: 3575.7866039571895
reward_min: 754.6830999928158
total_envstep_count: 15906074
total_train_sample_count: 11951040
total_episode_count: 36627
total_duration: 3241.2982844042353
[2023-06-29 12:55:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2465
train_sample_count: 2465
avg_envstep_per_episode: 273.8888888888889
avg_sample_per_episode: 273.8888888888889
avg_envstep_per_sec: 2528.15367000005
avg_train_sample_per_sec: 2528.15367000005
avg_episode_per_sec: 9.230581350912964
collect_time: 0.9750198452137409
reward_mean: 1784.0092132846962
reward_std: 995.0451051569372
reward_max: 3545.3684301840053
reward_min: 920.4814829394237
total_envstep_count: 15910122
total_train_sample_count: 11954305
total_episode_count: 36636
total_duration: 3242.273304249449
[2023-06-29 12:55:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3516
train_sample_count: 3516
avg_envstep_per_episode: 270.46153846153845
avg_sample_per_episode: 270.46153846153845
avg_envstep_per_sec: 2775.9547186848304
avg_train_sample_per_sec: 2775.9547186848304
avg_episode_per_sec: 10.26376886885745
collect_time: 1.2665912654604763
reward_mean: 1543.7742935718054
reward_std: 952.0083621967765
reward_max: 3542.3743699970346
reward_min: 590.5656082223014
total_envstep_count: 15914778
total_train_sample_count: 11957821
total_episode_count: 36649
total_duration: 3243.53989551491
[2023-06-29 12:55:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3293
train_sample_count: 3293
avg_envstep_per_episode: 219.53333333333333
avg_sample_per_episode: 219.53333333333333
avg_envstep_per_sec: 2681.702258018297
avg_train_sample_per_sec: 2681.702258018297
avg_episode_per_sec: 12.21546731560111
collect_time: 1.227951384294778
reward_mean: 1064.6261723531088
reward_std: 279.1332452001273
reward_max: 1875.4735265694173
reward_min: 678.0296468324436
total_envstep_count: 15919154
total_train_sample_count: 11961114
total_episode_count: 36664
total_duration: 3244.7678468992044
[2023-06-29 12:55:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2897
train_sample_count: 2897
avg_envstep_per_episode: 222.84615384615384
avg_sample_per_episode: 222.84615384615384
avg_envstep_per_sec: 2581.8636504297215
avg_train_sample_per_sec: 2581.8636504297215
avg_episode_per_sec: 11.585856905621808
collect_time: 1.1220577041385698
reward_mean: 1110.549875281267
reward_std: 168.17001040697525
reward_max: 1466.4865618845747
reward_min: 852.6169842664278
total_envstep_count: 15923866
total_train_sample_count: 11964411
total_episode_count: 36677
total_duration: 3245.889904603343
[2023-06-29 12:55:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3242
train_sample_count: 3242
avg_envstep_per_episode: 190.7058823529412
avg_sample_per_episode: 190.7058823529412
avg_envstep_per_sec: 2728.59655432307
avg_train_sample_per_sec: 2728.59655432307
avg_episode_per_sec: 14.307878292255456
collect_time: 1.188156598256901
reward_mean: 1059.173325987082
reward_std: 391.23009351747737
reward_max: 2459.323024171186
reward_min: 677.2060472149127
total_envstep_count: 15928226
total_train_sample_count: 11967653
total_episode_count: 36694
total_duration: 3247.0780612015997
[2023-06-29 12:56:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2804
train_sample_count: 2804
avg_envstep_per_episode: 215.69230769230768
avg_sample_per_episode: 215.69230769230768
avg_envstep_per_sec: 2761.226851901122
avg_train_sample_per_sec: 2761.226851901122
avg_episode_per_sec: 12.801693678571535
collect_time: 1.0154906316623094
reward_mean: 1077.757275223535
reward_std: 445.2207627591419
reward_max: 2334.6842715348516
reward_min: 636.0448610584248
total_envstep_count: 15932058
total_train_sample_count: 11970857
total_episode_count: 36707
total_duration: 3248.093551833262
[2023-06-29 12:56:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3074
train_sample_count: 3074
avg_envstep_per_episode: 219.57142857142858
avg_sample_per_episode: 219.57142857142858
avg_envstep_per_sec: 2636.023426246463
avg_train_sample_per_sec: 2636.023426246463
avg_episode_per_sec: 12.005311635475108
collect_time: 1.1661504861423744
reward_mean: 1051.1734140686028
reward_std: 290.09440279311355
reward_max: 2027.5143084023941
reward_min: 672.9619785706935
total_envstep_count: 15936578
total_train_sample_count: 11974331
total_episode_count: 36721
total_duration: 3249.2597023194044
[2023-06-29 12:56:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 246.92307692307693
avg_sample_per_episode: 246.92307692307693
avg_envstep_per_sec: 2584.622162316942
avg_train_sample_per_sec: 2584.622162316942
avg_episode_per_sec: 10.46731716826176
collect_time: 1.2419610288888214
reward_mean: 1295.5110288385383
reward_std: 697.5395442423448
reward_max: 3169.576441483105
reward_min: 688.7015805543484
total_envstep_count: 15940578
total_train_sample_count: 11977541
total_episode_count: 36734
total_duration: 3250.5016633482933
[2023-06-29 12:56:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 229.28571428571428
avg_sample_per_episode: 229.28571428571428
avg_envstep_per_sec: 2616.154894340916
avg_train_sample_per_sec: 2616.154894340916
avg_episode_per_sec: 11.410021346035148
collect_time: 1.2269915695525706
reward_mean: 1026.962438693648
reward_std: 235.2517622496679
reward_max: 1581.6475758433048
reward_min: 695.7957563705929
total_envstep_count: 15944858
total_train_sample_count: 11980751
total_episode_count: 36748
total_duration: 3251.7286549178457
[2023-06-29 12:56:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3060
train_sample_count: 3060
avg_envstep_per_episode: 235.3846153846154
avg_sample_per_episode: 235.3846153846154
avg_envstep_per_sec: 2747.9194699640625
avg_train_sample_per_sec: 2747.9194699640625
avg_episode_per_sec: 11.674167682853861
collect_time: 1.1135697510233147
reward_mean: 1090.1279622927286
reward_std: 108.41425520438953
reward_max: 1327.7002879930526
reward_min: 939.6128489418668
total_envstep_count: 15949634
total_train_sample_count: 11984211
total_episode_count: 36761
total_duration: 3252.842224668869
[2023-06-29 12:56:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3113
train_sample_count: 3113
avg_envstep_per_episode: 239.46153846153845
avg_sample_per_episode: 239.46153846153845
avg_envstep_per_sec: 2714.7617928668415
avg_train_sample_per_sec: 2714.7617928668415
avg_episode_per_sec: 11.336942919135542
collect_time: 1.1466936097964644
reward_mean: 1423.665339398194
reward_std: 760.6791252163434
reward_max: 3640.7443694235867
reward_min: 433.9128352242268
total_envstep_count: 15954426
total_train_sample_count: 11987724
total_episode_count: 36774
total_duration: 3253.9889182786656
[2023-06-29 12:56:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2954
train_sample_count: 2954
avg_envstep_per_episode: 227.23076923076923
avg_sample_per_episode: 227.23076923076923
avg_envstep_per_sec: 2541.6245777607373
avg_train_sample_per_sec: 2541.6245777607373
avg_episode_per_sec: 11.185213104566548
collect_time: 1.1622487545358018
reward_mean: 1297.7286216182733
reward_std: 435.66415458363224
reward_max: 2628.2158270199675
reward_min: 893.6462588281393
total_envstep_count: 15959034
total_train_sample_count: 11991078
total_episode_count: 36787
total_duration: 3255.1511670332015
[2023-06-29 12:56:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 207.85714285714286
avg_sample_per_episode: 207.85714285714286
avg_envstep_per_sec: 2590.064915747555
avg_train_sample_per_sec: 2590.064915747555
avg_episode_per_sec: 12.460793409094768
collect_time: 1.1235239635528995
reward_mean: 1190.2216420818816
reward_std: 352.47973354968485
reward_max: 2080.7374148925796
reward_min: 769.1482819908623
total_envstep_count: 15963394
total_train_sample_count: 11994388
total_episode_count: 36801
total_duration: 3256.2746909967545
[2023-06-29 12:56:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2985
train_sample_count: 2985
avg_envstep_per_episode: 229.6153846153846
avg_sample_per_episode: 229.6153846153846
avg_envstep_per_sec: 2667.4428555449535
avg_train_sample_per_sec: 2667.4428555449535
avg_episode_per_sec: 11.617004060999799
collect_time: 1.1190492773987355
reward_mean: 1249.6899856269592
reward_std: 514.8874809887285
reward_max: 2841.973040344564
reward_min: 687.9599218770501
total_envstep_count: 15967546
total_train_sample_count: 11997773
total_episode_count: 36814
total_duration: 3257.393740274153
[2023-06-29 12:56:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1735
train_sample_count: 1735
avg_envstep_per_episode: 247.85714285714286
avg_sample_per_episode: 247.85714285714286
avg_envstep_per_sec: 2752.6331133100516
avg_train_sample_per_sec: 2752.6331133100516
avg_episode_per_sec: 11.105724376467066
collect_time: 0.6303055759994314
reward_mean: 1296.4665151688444
reward_std: 276.7471557067952
reward_max: 1818.2920859493206
reward_min: 907.2062651077081
total_envstep_count: 15971890
total_train_sample_count: 12001108
total_episode_count: 36821
total_duration: 3258.0240458501526
[2023-06-29 12:56:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2738
train_sample_count: 2738
avg_envstep_per_episode: 228.16666666666666
avg_sample_per_episode: 228.16666666666666
avg_envstep_per_sec: 2712.8462186676306
avg_train_sample_per_sec: 2712.8462186676306
avg_episode_per_sec: 11.889756984664562
collect_time: 1.0092720999661835
reward_mean: 1748.3466780113952
reward_std: 1084.7937498597487
reward_max: 3547.5802061132317
reward_min: 257.72658580595186
total_envstep_count: 15976394
total_train_sample_count: 12004646
total_episode_count: 36833
total_duration: 3259.0333179501185
[2023-06-29 12:56:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 199.9090909090909
avg_sample_per_episode: 199.9090909090909
avg_envstep_per_sec: 2621.8653758331516
avg_train_sample_per_sec: 2621.8653758331516
avg_episode_per_sec: 13.115288373881159
collect_time: 0.838715831968002
reward_mean: 1244.90918552191
reward_std: 366.8961795182219
reward_max: 1967.5069415361397
reward_min: 688.4572380398467
total_envstep_count: 15980906
total_train_sample_count: 12008045
total_episode_count: 36844
total_duration: 3259.8720337820864
[2023-06-29 12:56:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3089
train_sample_count: 3089
avg_envstep_per_episode: 280.8181818181818
avg_sample_per_episode: 280.8181818181818
avg_envstep_per_sec: 2579.628987312829
avg_train_sample_per_sec: 2579.628987312829
avg_episode_per_sec: 9.186118116037916
collect_time: 1.1974590203445408
reward_mean: 1837.5854385051045
reward_std: 1003.6798459294456
reward_max: 3554.816309224845
reward_min: 954.4996790286422
total_envstep_count: 15985274
total_train_sample_count: 12011534
total_episode_count: 36855
total_duration: 3261.069492802431
[2023-06-29 12:56:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3061
train_sample_count: 3061
avg_envstep_per_episode: 204.06666666666666
avg_sample_per_episode: 204.06666666666666
avg_envstep_per_sec: 2818.011735345324
avg_train_sample_per_sec: 2818.011735345324
avg_episode_per_sec: 13.809270183005507
collect_time: 1.0862268462572247
reward_mean: 1053.282472546296
reward_std: 181.7704905650157
reward_max: 1430.924366285214
reward_min: 672.5681617887601
total_envstep_count: 15989962
total_train_sample_count: 12014995
total_episode_count: 36870
total_duration: 3262.1557196486883
[2023-06-29 12:56:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3005
train_sample_count: 3005
avg_envstep_per_episode: 214.64285714285714
avg_sample_per_episode: 214.64285714285714
avg_envstep_per_sec: 2807.591797537931
avg_train_sample_per_sec: 2807.591797537931
avg_episode_per_sec: 13.080294564236619
collect_time: 1.0703122877888382
reward_mean: 1198.8870363275332
reward_std: 585.2668784311174
reward_max: 3134.9042396437894
reward_min: 703.2912580522393
total_envstep_count: 15994546
total_train_sample_count: 12018400
total_episode_count: 36884
total_duration: 3263.2260319364773
[2023-06-29 12:56:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2815
train_sample_count: 2815
avg_envstep_per_episode: 234.58333333333334
avg_sample_per_episode: 234.58333333333334
avg_envstep_per_sec: 2563.292550262382
avg_train_sample_per_sec: 2563.292550262382
avg_episode_per_sec: 10.927001990461308
collect_time: 1.0981969263367355
reward_mean: 1286.9472317857685
reward_std: 494.80362056123454
reward_max: 2699.18091447658
reward_min: 836.3458019842387
total_envstep_count: 15998850
total_train_sample_count: 12021615
total_episode_count: 36896
total_duration: 3264.324228862814
[2023-06-29 12:56:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3057
train_sample_count: 3057
avg_envstep_per_episode: 305.7
avg_sample_per_episode: 305.7
avg_envstep_per_sec: 2678.495608653605
avg_train_sample_per_sec: 2678.495608653605
avg_episode_per_sec: 8.761843665860663
collect_time: 1.141312306103297
reward_mean: 1686.344155759895
reward_std: 836.3928021495448
reward_max: 3402.615132739787
reward_min: 834.3259184397754
total_envstep_count: 16003370
total_train_sample_count: 12025072
total_episode_count: 36906
total_duration: 3265.4655411689173
[2023-06-29 12:56:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3357
train_sample_count: 3357
avg_envstep_per_episode: 258.2307692307692
avg_sample_per_episode: 258.2307692307692
avg_envstep_per_sec: 2769.039806990816
avg_train_sample_per_sec: 2769.039806990816
avg_episode_per_sec: 10.72312108754263
collect_time: 1.21233360081166
reward_mean: 1372.51247316749
reward_std: 503.5450598167242
reward_max: 2566.104820147192
reward_min: 974.8976516262488
total_envstep_count: 16007714
total_train_sample_count: 12028429
total_episode_count: 36919
total_duration: 3266.677874769729
[2023-06-29 12:56:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2319
train_sample_count: 2319
avg_envstep_per_episode: 257.6666666666667
avg_sample_per_episode: 257.6666666666667
avg_envstep_per_sec: 2591.3447568578017
avg_train_sample_per_sec: 2591.3447568578017
avg_episode_per_sec: 10.056965421181637
collect_time: 0.8949021521983667
reward_mean: 1296.7708021244625
reward_std: 372.6944638638932
reward_max: 2104.1351477945254
reward_min: 953.0581597006977
total_envstep_count: 16012058
total_train_sample_count: 12031948
total_episode_count: 36928
total_duration: 3267.5727769219275
[2023-06-29 12:57:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1703
train_sample_count: 1703
avg_envstep_per_episode: 243.28571428571428
avg_sample_per_episode: 243.28571428571428
avg_envstep_per_sec: 2590.863473266293
avg_train_sample_per_sec: 2590.863473266293
avg_episode_per_sec: 10.64946818136468
collect_time: 0.6573098187427968
reward_mean: 1650.360708420307
reward_std: 901.2803462762106
reward_max: 3568.0129325078924
reward_min: 1007.9965885007921
total_envstep_count: 16016410
total_train_sample_count: 12035251
total_episode_count: 36935
total_duration: 3268.2300867406702
[2023-06-29 12:57:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3462
train_sample_count: 3462
avg_envstep_per_episode: 266.3076923076923
avg_sample_per_episode: 266.3076923076923
avg_envstep_per_sec: 2561.902850907274
avg_train_sample_per_sec: 2561.902850907274
avg_episode_per_sec: 9.62008580641091
collect_time: 1.3513392979651686
reward_mean: 1890.7721363150652
reward_std: 996.3774133002037
reward_max: 3553.0536490148124
reward_min: 941.1132862910104
total_envstep_count: 16020738
total_train_sample_count: 12038713
total_episode_count: 36948
total_duration: 3269.5814260386355
[2023-06-29 12:57:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2057
train_sample_count: 2057
avg_envstep_per_episode: 228.55555555555554
avg_sample_per_episode: 228.55555555555554
avg_envstep_per_sec: 2493.5816519411346
avg_train_sample_per_sec: 2493.5816519411346
avg_episode_per_sec: 10.910177378449301
collect_time: 0.8249178439369425
reward_mean: 1101.6341964669784
reward_std: 173.8779918663496
reward_max: 1332.3172307332886
reward_min: 767.420387003814
total_envstep_count: 16024946
total_train_sample_count: 12041970
total_episode_count: 36957
total_duration: 3270.4063438825724
[2023-06-29 12:57:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1681
train_sample_count: 1681
avg_envstep_per_episode: 240.14285714285714
avg_sample_per_episode: 240.14285714285714
avg_envstep_per_sec: 2826.401870855072
avg_train_sample_per_sec: 2826.401870855072
avg_episode_per_sec: 11.769668706713565
collect_time: 0.5947491109929979
reward_mean: 2041.0607399633916
reward_std: 981.4985638155705
reward_max: 3544.3264220604133
reward_min: 998.7183715093621
total_envstep_count: 16029002
total_train_sample_count: 12045251
total_episode_count: 36964
total_duration: 3271.001092993565
[2023-06-29 12:57:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3162
train_sample_count: 3162
avg_envstep_per_episode: 351.3333333333333
avg_sample_per_episode: 351.3333333333333
avg_envstep_per_sec: 2611.886595725847
avg_train_sample_per_sec: 2611.886595725847
avg_episode_per_sec: 7.434212321800324
collect_time: 1.2106191766420378
reward_mean: 2273.7235321792514
reward_std: 1131.4916302289034
reward_max: 3625.2611313275834
reward_min: 842.0014543937144
total_envstep_count: 16033850
total_train_sample_count: 12048813
total_episode_count: 36973
total_duration: 3272.211712170207
[2023-06-29 12:57:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2147
train_sample_count: 2147
avg_envstep_per_episode: 238.55555555555554
avg_sample_per_episode: 238.55555555555554
avg_envstep_per_sec: 2653.403653335113
avg_train_sample_per_sec: 2653.403653335113
avg_episode_per_sec: 11.122791280864472
collect_time: 0.8091494097784161
reward_mean: 1455.4643895126305
reward_std: 443.20342139491953
reward_max: 2227.0573651824916
reward_min: 972.2879297638101
total_envstep_count: 16038274
total_train_sample_count: 12052160
total_episode_count: 36982
total_duration: 3273.0208615799856
[2023-06-29 12:57:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2805
train_sample_count: 2805
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2533.3350287823146
avg_train_sample_per_sec: 2533.3350287823146
avg_episode_per_sec: 9.934647171695351
collect_time: 1.1072361010806633
reward_mean: 1569.8701068101655
reward_std: 952.8837311022634
reward_max: 3578.384631163394
reward_min: 737.9894426221216
total_envstep_count: 16042578
total_train_sample_count: 12055365
total_episode_count: 36993
total_duration: 3274.1280976810663
[2023-06-29 12:57:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3051
train_sample_count: 3051
avg_envstep_per_episode: 254.25
avg_sample_per_episode: 254.25
avg_envstep_per_sec: 2739.655412576046
avg_train_sample_per_sec: 2739.655412576046
avg_episode_per_sec: 10.775439184173239
collect_time: 1.1136437035091222
reward_mean: 1466.9316561272872
reward_std: 695.8443458013222
reward_max: 3521.443274451099
reward_min: 931.3468788622323
total_envstep_count: 16047282
total_train_sample_count: 12058816
total_episode_count: 37005
total_duration: 3275.2417413845756
[2023-06-29 12:57:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3115
train_sample_count: 3115
avg_envstep_per_episode: 259.5833333333333
avg_sample_per_episode: 259.5833333333333
avg_envstep_per_sec: 2647.5484642148745
avg_train_sample_per_sec: 2647.5484642148745
avg_episode_per_sec: 10.19922361816324
collect_time: 1.1765601431299002
reward_mean: 1405.0442905489338
reward_std: 689.7408687471548
reward_max: 3546.6585529974186
reward_min: 1003.7857914407366
total_envstep_count: 16052066
total_train_sample_count: 12062331
total_episode_count: 37017
total_duration: 3276.4183015277054
[2023-06-29 12:57:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2670
train_sample_count: 2670
avg_envstep_per_episode: 267.0
avg_sample_per_episode: 267.0
avg_envstep_per_sec: 2549.777616654725
avg_train_sample_per_sec: 2549.777616654725
avg_episode_per_sec: 9.549728901328558
collect_time: 1.0471501446086915
reward_mean: 1438.4066508108222
reward_std: 729.928820457384
reward_max: 3507.943149972202
reward_min: 830.1457435659939
total_envstep_count: 16057034
total_train_sample_count: 12065801
total_episode_count: 37027
total_duration: 3277.465451672314
[2023-06-29 12:57:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1344
train_sample_count: 1344
avg_envstep_per_episode: 268.8
avg_sample_per_episode: 268.8
avg_envstep_per_sec: 2742.2309273967753
avg_train_sample_per_sec: 2742.2309273967753
avg_episode_per_sec: 10.201751962041575
collect_time: 0.4901118963295594
reward_mean: 2399.603287514106
reward_std: 955.5370757446914
reward_max: 3612.348236094526
reward_min: 1314.299807428748
total_envstep_count: 16061394
total_train_sample_count: 12069145
total_episode_count: 37032
total_duration: 3277.9555635686434
[2023-06-29 12:57:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2178
train_sample_count: 2178
avg_envstep_per_episode: 272.25
avg_sample_per_episode: 272.25
avg_envstep_per_sec: 2473.8783075203064
avg_train_sample_per_sec: 2473.8783075203064
avg_episode_per_sec: 9.08678900833905
collect_time: 0.8803990048253909
reward_mean: 2685.0561994232485
reward_std: 1097.8081062476926
reward_max: 3576.849665882293
reward_min: 1197.4036250968347
total_envstep_count: 16065546
total_train_sample_count: 12072523
total_episode_count: 37040
total_duration: 3278.835962573469
[2023-06-29 12:57:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2727
train_sample_count: 2727
avg_envstep_per_episode: 272.7
avg_sample_per_episode: 272.7
avg_envstep_per_sec: 2768.399873924246
avg_train_sample_per_sec: 2768.399873924246
avg_episode_per_sec: 10.151814719194155
collect_time: 0.9850455585140736
reward_mean: 1696.142418856974
reward_std: 774.4912652617345
reward_max: 3517.535686653792
reward_min: 994.1235498956258
total_envstep_count: 16070226
total_train_sample_count: 12076050
total_episode_count: 37050
total_duration: 3279.821008131983
[2023-06-29 12:57:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3241
train_sample_count: 3241
avg_envstep_per_episode: 270.0833333333333
avg_sample_per_episode: 270.0833333333333
avg_envstep_per_sec: 2555.41900656758
avg_train_sample_per_sec: 2555.41900656758
avg_episode_per_sec: 9.461594593894155
collect_time: 1.268285158586688
reward_mean: 1590.2450005048074
reward_std: 892.587468504874
reward_max: 3567.2388446063273
reward_min: 909.3690779557937
total_envstep_count: 16075026
total_train_sample_count: 12079291
total_episode_count: 37062
total_duration: 3281.08929329057
[2023-06-29 12:57:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1736
train_sample_count: 1736
avg_envstep_per_episode: 217.0
avg_sample_per_episode: 217.0
avg_envstep_per_sec: 2361.7483784753285
avg_train_sample_per_sec: 2361.7483784753285
avg_episode_per_sec: 10.883633080531467
collect_time: 0.7350486681060866
reward_mean: 1259.330404697937
reward_std: 270.5556358841975
reward_max: 1679.941156011161
reward_min: 984.8521189969533
total_envstep_count: 16079338
total_train_sample_count: 12082627
total_episode_count: 37070
total_duration: 3281.824341958676
[2023-06-29 12:57:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2656
train_sample_count: 2656
avg_envstep_per_episode: 241.45454545454547
avg_sample_per_episode: 241.45454545454547
avg_envstep_per_sec: 2784.4925730137975
avg_train_sample_per_sec: 2784.4925730137975
avg_episode_per_sec: 11.532160505704734
collect_time: 0.9538542231144386
reward_mean: 1818.4860063694653
reward_std: 1111.4863232565922
reward_max: 3547.526141705288
reward_min: 801.1428216289933
total_envstep_count: 16083578
total_train_sample_count: 12086083
total_episode_count: 37081
total_duration: 3282.7781961817905
[2023-06-29 12:57:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2414
train_sample_count: 2414
avg_envstep_per_episode: 268.22222222222223
avg_sample_per_episode: 268.22222222222223
avg_envstep_per_sec: 2748.816994381711
avg_train_sample_per_sec: 2748.816994381711
avg_episode_per_sec: 10.248282083444655
collect_time: 0.8781959675503894
reward_mean: 1405.2653354959127
reward_std: 785.4186929043764
reward_max: 3517.7193331547537
reward_min: 907.8952959729794
total_envstep_count: 16087826
total_train_sample_count: 12089297
total_episode_count: 37090
total_duration: 3283.6563921493407
[2023-06-29 12:57:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2925
train_sample_count: 2925
avg_envstep_per_episode: 225.0
avg_sample_per_episode: 225.0
avg_envstep_per_sec: 2552.2058340088815
avg_train_sample_per_sec: 2552.2058340088815
avg_episode_per_sec: 11.343137040039473
collect_time: 1.1460674374392255
reward_mean: 1529.5989485253433
reward_std: 878.5754279282918
reward_max: 3560.0871591716545
reward_min: 890.453991972645
total_envstep_count: 16091954
total_train_sample_count: 12092622
total_episode_count: 37103
total_duration: 3284.80245958678
[2023-06-29 12:57:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 271.1111111111111
avg_sample_per_episode: 271.1111111111111
avg_envstep_per_sec: 2763.12145662082
avg_train_sample_per_sec: 2763.12145662082
avg_episode_per_sec: 10.191841438355484
collect_time: 0.8830592640629038
reward_mean: 1363.940993764502
reward_std: 529.5900341346556
reward_max: 2767.494000601035
reward_min: 955.2292889614831
total_envstep_count: 16096410
total_train_sample_count: 12095862
total_episode_count: 37112
total_duration: 3285.685518850843
[2023-06-29 12:57:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2475
train_sample_count: 2475
avg_envstep_per_episode: 247.5
avg_sample_per_episode: 247.5
avg_envstep_per_sec: 2549.286422430178
avg_train_sample_per_sec: 2549.286422430178
avg_episode_per_sec: 10.300147161334053
collect_time: 0.9708599152388053
reward_mean: 1739.0615684417469
reward_std: 971.1692788757389
reward_max: 3606.516175195339
reward_min: 846.1806678049081
total_envstep_count: 16100706
total_train_sample_count: 12099137
total_episode_count: 37122
total_duration: 3286.6563787660816
[2023-06-29 12:58:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2430
train_sample_count: 2430
avg_envstep_per_episode: 243.0
avg_sample_per_episode: 243.0
avg_envstep_per_sec: 2758.7875318781084
avg_train_sample_per_sec: 2758.7875318781084
avg_episode_per_sec: 11.3530351106095
collect_time: 0.8808217276325448
reward_mean: 1577.095703052443
reward_std: 678.0968124534303
reward_max: 3071.5254724058072
reward_min: 966.4719246554997
total_envstep_count: 16104762
total_train_sample_count: 12102367
total_episode_count: 37132
total_duration: 3287.537200493714
[2023-06-29 12:58:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3162
train_sample_count: 3162
avg_envstep_per_episode: 243.23076923076923
avg_sample_per_episode: 243.23076923076923
avg_envstep_per_sec: 2623.232553068439
avg_train_sample_per_sec: 2623.232553068439
avg_episode_per_sec: 10.784953570490101
collect_time: 1.2053830287754534
reward_mean: 1364.683296033611
reward_std: 369.02200062136416
reward_max: 2278.465147156916
reward_min: 871.9968957086996
total_envstep_count: 16109706
total_train_sample_count: 12105929
total_episode_count: 37145
total_duration: 3288.7425835224894
[2023-06-29 12:58:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2191
train_sample_count: 2191
avg_envstep_per_episode: 243.44444444444446
avg_sample_per_episode: 243.44444444444446
avg_envstep_per_sec: 2678.397658377127
avg_train_sample_per_sec: 2678.397658377127
avg_episode_per_sec: 11.002089879230553
collect_time: 0.8180264021465554
reward_mean: 1525.7722447183614
reward_std: 577.4595103567164
reward_max: 2584.8956661326547
reward_min: 992.8270268762388
total_envstep_count: 16114170
total_train_sample_count: 12109320
total_episode_count: 37154
total_duration: 3289.560609924636
[2023-06-29 12:58:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 286.14285714285717
avg_sample_per_episode: 286.14285714285717
avg_envstep_per_sec: 2722.6836510691573
avg_train_sample_per_sec: 2722.6836510691573
avg_episode_per_sec: 9.51512009859416
collect_time: 0.7356712188040838
reward_mean: 2196.795036464625
reward_std: 1064.9723998079482
reward_max: 3578.093345410762
reward_min: 963.1628757109744
total_envstep_count: 16118914
total_train_sample_count: 12112523
total_episode_count: 37161
total_duration: 3290.29628114344
[2023-06-29 12:58:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 222.9090909090909
avg_sample_per_episode: 222.9090909090909
avg_envstep_per_sec: 2722.3800525247266
avg_train_sample_per_sec: 2722.3800525247266
avg_episode_per_sec: 12.212961083920062
collect_time: 0.9006824736781417
reward_mean: 1714.1449858878007
reward_std: 860.288051362209
reward_max: 3674.7128987544543
reward_min: 801.7202335084155
total_envstep_count: 16123250
total_train_sample_count: 12115775
total_episode_count: 37172
total_duration: 3291.196963617118
[2023-06-29 12:58:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2980
train_sample_count: 2980
avg_envstep_per_episode: 270.90909090909093
avg_sample_per_episode: 270.90909090909093
avg_envstep_per_sec: 2769.8745248102546
avg_train_sample_per_sec: 2769.8745248102546
avg_episode_per_sec: 10.224369051313019
collect_time: 1.0758610086152331
reward_mean: 1659.8658076308702
reward_std: 849.6470533231718
reward_max: 3600.1943496529675
reward_min: 846.4653421806989
total_envstep_count: 16128042
total_train_sample_count: 12119155
total_episode_count: 37183
total_duration: 3292.2728246257334
[2023-06-29 12:58:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1550
train_sample_count: 1550
avg_envstep_per_episode: 193.75
avg_sample_per_episode: 193.75
avg_envstep_per_sec: 2440.779772319701
avg_train_sample_per_sec: 2440.779772319701
avg_episode_per_sec: 12.597573018424264
collect_time: 0.6350429553613066
reward_mean: 1412.5765312719159
reward_std: 848.3124222021105
reward_max: 3563.602409416018
reward_min: 740.8569804912071
total_envstep_count: 16132362
total_train_sample_count: 12122705
total_episode_count: 37191
total_duration: 3292.9078675810947
[2023-06-29 12:58:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1874
train_sample_count: 1874
avg_envstep_per_episode: 208.22222222222223
avg_sample_per_episode: 208.22222222222223
avg_envstep_per_sec: 2693.410255999305
avg_train_sample_per_sec: 2693.410255999305
avg_episode_per_sec: 12.935268038417153
collect_time: 0.6957722076782957
reward_mean: 1742.3489029768864
reward_std: 938.2322048179432
reward_max: 3530.4427113072543
reward_min: 1013.5708939211496
total_envstep_count: 16136698
total_train_sample_count: 12126179
total_episode_count: 37200
total_duration: 3293.603639788773
[2023-06-29 12:58:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 184.55555555555554
avg_sample_per_episode: 184.55555555555554
avg_envstep_per_sec: 2442.5867925342777
avg_train_sample_per_sec: 2442.5867925342777
avg_episode_per_sec: 13.234967569421132
collect_time: 0.6800167777361347
reward_mean: 1772.3006843920466
reward_std: 988.4532888103848
reward_max: 3557.6256010254774
reward_min: 848.340038881162
total_envstep_count: 16141242
total_train_sample_count: 12129440
total_episode_count: 37209
total_duration: 3294.283656566509
[2023-06-29 12:58:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3345
train_sample_count: 3345
avg_envstep_per_episode: 257.3076923076923
avg_sample_per_episode: 257.3076923076923
avg_envstep_per_sec: 2750.241054742704
avg_train_sample_per_sec: 2750.241054742704
avg_episode_per_sec: 10.688530257594964
collect_time: 1.2162570238094776
reward_mean: 1929.8323345304657
reward_std: 953.0174780995089
reward_max: 3585.987491591074
reward_min: 1033.5768299835227
total_envstep_count: 16145570
total_train_sample_count: 12132785
total_episode_count: 37222
total_duration: 3295.4999135903186
[2023-06-29 12:58:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3174
train_sample_count: 3174
avg_envstep_per_episode: 244.15384615384616
avg_sample_per_episode: 244.15384615384616
avg_envstep_per_sec: 2645.404538894704
avg_train_sample_per_sec: 2645.404538894704
avg_episode_per_sec: 10.834990234918447
collect_time: 1.1998164943521843
reward_mean: 1165.029885576309
reward_std: 193.41237308703847
reward_max: 1556.131557074669
reward_min: 947.9624645719134
total_envstep_count: 16150242
total_train_sample_count: 12136359
total_episode_count: 37235
total_duration: 3296.6997300846706
[2023-06-29 12:58:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1799
train_sample_count: 1799
avg_envstep_per_episode: 179.9
avg_sample_per_episode: 179.9
avg_envstep_per_sec: 2505.373984375551
avg_train_sample_per_sec: 2505.373984375551
avg_episode_per_sec: 13.926481291692891
collect_time: 0.7180564702991397
reward_mean: 1186.3346722926794
reward_std: 333.1539128068293
reward_max: 1821.5109174563229
reward_min: 536.538127246079
total_envstep_count: 16154450
total_train_sample_count: 12139758
total_episode_count: 37245
total_duration: 3297.4177865549696
[2023-06-29 12:58:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2638
train_sample_count: 2638
avg_envstep_per_episode: 293.1111111111111
avg_sample_per_episode: 293.1111111111111
avg_envstep_per_sec: 2515.971269914644
avg_train_sample_per_sec: 2515.971269914644
avg_episode_per_sec: 8.583677569837677
collect_time: 1.048501638927497
reward_mean: 1867.7269749205395
reward_std: 907.6255956839462
reward_max: 3545.063492485737
reward_min: 1012.350132385684
total_envstep_count: 16158546
total_train_sample_count: 12143196
total_episode_count: 37254
total_duration: 3298.466288193897
[2023-06-29 12:58:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2997
train_sample_count: 2997
avg_envstep_per_episode: 249.75
avg_sample_per_episode: 249.75
avg_envstep_per_sec: 2599.4580819639928
avg_train_sample_per_sec: 2599.4580819639928
avg_episode_per_sec: 10.408240568424395
collect_time: 1.1529326134528965
reward_mean: 1451.592807947617
reward_std: 934.0452026635703
reward_max: 3554.3535208381472
reward_min: 919.1545072849716
total_envstep_count: 16163394
total_train_sample_count: 12146993
total_episode_count: 37266
total_duration: 3299.61922080735
[2023-06-29 12:58:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1917
train_sample_count: 1917
avg_envstep_per_episode: 239.625
avg_sample_per_episode: 239.625
avg_envstep_per_sec: 2730.9702201647556
avg_train_sample_per_sec: 2730.9702201647556
avg_episode_per_sec: 11.396850162398561
collect_time: 0.7019483353737743
reward_mean: 1366.9204436039752
reward_std: 566.8415352996684
reward_max: 2655.425266894042
reward_min: 849.1142660560238
total_envstep_count: 16167962
total_train_sample_count: 12150510
total_episode_count: 37274
total_duration: 3300.3211691427236
[2023-06-29 12:58:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2571
train_sample_count: 2571
avg_envstep_per_episode: 233.72727272727272
avg_sample_per_episode: 233.72727272727272
avg_envstep_per_sec: 2596.930640186448
avg_train_sample_per_sec: 2596.930640186448
avg_episode_per_sec: 11.110944007020974
collect_time: 0.9900148891983553
reward_mean: 1827.1126129723516
reward_std: 1081.229732290846
reward_max: 3592.313855544788
reward_min: 971.0986432356046
total_envstep_count: 16172626
total_train_sample_count: 12153881
total_episode_count: 37285
total_duration: 3301.311184031922
[2023-06-29 12:58:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2614
train_sample_count: 2614
avg_envstep_per_episode: 237.63636363636363
avg_sample_per_episode: 237.63636363636363
avg_envstep_per_sec: 2539.823483486367
avg_train_sample_per_sec: 2539.823483486367
avg_episode_per_sec: 10.687857046040564
collect_time: 1.0292053825771437
reward_mean: 1654.7081015288902
reward_std: 853.078678479241
reward_max: 3564.3711495500893
reward_min: 941.587314599962
total_envstep_count: 16177298
total_train_sample_count: 12157295
total_episode_count: 37296
total_duration: 3302.340389414499
[2023-06-29 12:58:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1920
train_sample_count: 1920
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 2411.8496935191047
avg_train_sample_per_sec: 2411.8496935191047
avg_episode_per_sec: 10.049373722996268
collect_time: 0.7960695084603503
reward_mean: 1748.8916661444464
reward_std: 1039.765614038675
reward_max: 3570.8905748390703
reward_min: 1014.3412775900352
total_envstep_count: 16181690
total_train_sample_count: 12160815
total_episode_count: 37304
total_duration: 3303.1364589229593
[2023-06-29 12:58:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3272
train_sample_count: 3272
avg_envstep_per_episode: 297.45454545454544
avg_sample_per_episode: 297.45454545454544
avg_envstep_per_sec: 2751.8793795151855
avg_train_sample_per_sec: 2751.8793795151855
avg_episode_per_sec: 9.251428231866456
collect_time: 1.1890056026279927
reward_mean: 2000.5333534374854
reward_std: 1103.5075776378198
reward_max: 3574.3955684088805
reward_min: 668.2862530974833
total_envstep_count: 16185898
total_train_sample_count: 12164087
total_episode_count: 37315
total_duration: 3304.3254645255874
[2023-06-29 12:59:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 263.4
avg_sample_per_episode: 263.4
avg_envstep_per_sec: 2674.244920066321
avg_train_sample_per_sec: 2674.244920066321
avg_episode_per_sec: 10.152790129333033
collect_time: 0.49247546106111273
reward_mean: 1006.7716837595156
reward_std: 167.26408345132555
reward_max: 1218.396064328598
reward_min: 703.5882369363212
total_envstep_count: 16189890
total_train_sample_count: 12167404
total_episode_count: 37320
total_duration: 3304.8179399866485
[2023-06-29 12:59:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 315.8888888888889
avg_sample_per_episode: 315.8888888888889
avg_envstep_per_sec: 2560.394197678804
avg_train_sample_per_sec: 2560.394197678804
avg_episode_per_sec: 8.105363270879083
collect_time: 1.1103758954685181
reward_mean: 2449.564599065052
reward_std: 1213.3358350815415
reward_max: 3600.230566129117
reward_min: 923.6641778549503
total_envstep_count: 16194786
total_train_sample_count: 12170647
total_episode_count: 37329
total_duration: 3305.928315882117
[2023-06-29 12:59:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1177
train_sample_count: 1177
avg_envstep_per_episode: 235.4
avg_sample_per_episode: 235.4
avg_envstep_per_sec: 2764.0201672754374
avg_train_sample_per_sec: 2764.0201672754374
avg_episode_per_sec: 11.74180190006558
collect_time: 0.42582902032881975
reward_mean: 1714.8127534606313
reward_std: 922.3054436490711
reward_max: 3549.9339702563525
reward_min: 1167.2276065041706
total_envstep_count: 16199722
total_train_sample_count: 12174224
total_episode_count: 37334
total_duration: 3306.354144902446
[2023-06-29 12:59:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 229.44444444444446
avg_sample_per_episode: 229.44444444444446
avg_envstep_per_sec: 2772.434727314917
avg_train_sample_per_sec: 2772.434727314917
avg_episode_per_sec: 12.083250627522641
collect_time: 0.7448326843027022
reward_mean: 2563.0958343772254
reward_std: 1115.1024554022388
reward_max: 3588.6353400981434
reward_min: 1009.2332668546832
total_envstep_count: 16204386
total_train_sample_count: 12177489
total_episode_count: 37343
total_duration: 3307.098977586749
[2023-06-29 12:59:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1862
train_sample_count: 1862
avg_envstep_per_episode: 232.75
avg_sample_per_episode: 232.75
avg_envstep_per_sec: 2758.653734093194
avg_train_sample_per_sec: 2758.653734093194
avg_episode_per_sec: 11.852432799541113
collect_time: 0.6749669148353858
reward_mean: 1874.160090223279
reward_std: 1053.4932909017389
reward_max: 3604.3309326476583
reward_min: 937.8943768465182
total_envstep_count: 16208658
total_train_sample_count: 12180951
total_episode_count: 37351
total_duration: 3307.773944501584
[2023-06-29 12:59:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1695
train_sample_count: 1695
avg_envstep_per_episode: 242.14285714285714
avg_sample_per_episode: 242.14285714285714
avg_envstep_per_sec: 2458.634923241769
avg_train_sample_per_sec: 2458.634923241769
avg_episode_per_sec: 10.153654550260992
collect_time: 0.6894069485375658
reward_mean: 2421.763450265291
reward_std: 1050.9493078498263
reward_max: 3563.6323889423693
reward_min: 948.9070847151852
total_envstep_count: 16213546
total_train_sample_count: 12184246
total_episode_count: 37358
total_duration: 3308.4633514501215
[2023-06-29 12:59:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1707
train_sample_count: 1707
avg_envstep_per_episode: 341.4
avg_sample_per_episode: 341.4
avg_envstep_per_sec: 2489.110076501376
avg_train_sample_per_sec: 2489.110076501376
avg_episode_per_sec: 7.290890675165132
collect_time: 0.6857872683554886
reward_mean: 3054.190708416139
reward_std: 947.5188632956998
reward_max: 3552.021472497446
reward_min: 1159.6351304743935
total_envstep_count: 16218130
total_train_sample_count: 12187553
total_episode_count: 37363
total_duration: 3309.149138718477
[2023-06-29 12:59:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1421
train_sample_count: 1421
avg_envstep_per_episode: 236.83333333333334
avg_sample_per_episode: 236.83333333333334
avg_envstep_per_sec: 2749.2665007275955
avg_train_sample_per_sec: 2749.2665007275955
avg_episode_per_sec: 11.608444056555646
collect_time: 0.516865134618245
reward_mean: 2805.0969507155082
reward_std: 999.8576959238898
reward_max: 3524.8560635609597
reward_min: 1379.9075906669543
total_envstep_count: 16222498
total_train_sample_count: 12190974
total_episode_count: 37369
total_duration: 3309.6660038530954
[2023-06-29 12:59:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1792
train_sample_count: 1792
avg_envstep_per_episode: 358.4
avg_sample_per_episode: 358.4
avg_envstep_per_sec: 2800.746726652161
avg_train_sample_per_sec: 2800.746726652161
avg_episode_per_sec: 7.814583500703575
collect_time: 0.6398293651286511
reward_mean: 3200.9742304592774
reward_std: 606.1974997006303
reward_max: 3537.769686298969
reward_min: 1989.426472746749
total_envstep_count: 16226722
total_train_sample_count: 12194366
total_episode_count: 37374
total_duration: 3310.305833218224
[2023-06-29 12:59:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1214
train_sample_count: 1214
avg_envstep_per_episode: 303.5
avg_sample_per_episode: 303.5
avg_envstep_per_sec: 2350.4698302945826
avg_train_sample_per_sec: 2350.4698302945826
avg_episode_per_sec: 7.744546393062874
collect_time: 0.516492483482696
reward_mean: 2898.257707598045
reward_std: 1027.1088878021176
reward_max: 3509.05818872158
reward_min: 1119.3875921846848
total_envstep_count: 16231402
total_train_sample_count: 12197580
total_episode_count: 37378
total_duration: 3310.8223257017066
[2023-06-29 12:59:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2165
train_sample_count: 2165
avg_envstep_per_episode: 270.625
avg_sample_per_episode: 270.625
avg_envstep_per_sec: 2479.250230033677
avg_train_sample_per_sec: 2479.250230033677
avg_episode_per_sec: 9.161201773796495
collect_time: 0.8732478770287708
reward_mean: 2629.672797663143
reward_std: 1131.2138753617044
reward_max: 3529.533082864897
reward_min: 841.4968876433226
total_envstep_count: 16236202
total_train_sample_count: 12200945
total_episode_count: 37386
total_duration: 3311.6955735787355
[2023-06-29 12:59:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2099
train_sample_count: 2099
avg_envstep_per_episode: 299.85714285714283
avg_sample_per_episode: 299.85714285714283
avg_envstep_per_sec: 2780.2390320836466
avg_train_sample_per_sec: 2780.2390320836466
avg_episode_per_sec: 9.271878620574334
collect_time: 0.7549710567248986
reward_mean: 2271.289930594861
reward_std: 1093.2228143731274
reward_max: 3519.702180578089
reward_min: 1002.9188346294659
total_envstep_count: 16240538
total_train_sample_count: 12204244
total_episode_count: 37393
total_duration: 3312.4505446354606
[2023-06-29 12:59:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1982
train_sample_count: 1982
avg_envstep_per_episode: 220.22222222222223
avg_sample_per_episode: 220.22222222222223
avg_envstep_per_sec: 2762.502473424793
avg_train_sample_per_sec: 2762.502473424793
avg_episode_per_sec: 12.544158557428425
collect_time: 0.7174654209604487
reward_mean: 1974.159995183923
reward_std: 1015.5665960137412
reward_max: 3526.653636265473
reward_min: 995.0999292588823
total_envstep_count: 16245194
total_train_sample_count: 12207826
total_episode_count: 37402
total_duration: 3313.168010056421
[2023-06-29 12:59:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2158
train_sample_count: 2158
avg_envstep_per_episode: 308.2857142857143
avg_sample_per_episode: 308.2857142857143
avg_envstep_per_sec: 2674.636156874469
avg_train_sample_per_sec: 2674.636156874469
avg_episode_per_sec: 8.675835541298092
collect_time: 0.8068387150354683
reward_mean: 2092.4777481554797
reward_std: 1242.0456989733466
reward_max: 3530.8754866183535
reward_min: 679.2763019195618
total_envstep_count: 16249498
total_train_sample_count: 12211184
total_episode_count: 37409
total_duration: 3313.9748487714564
[2023-06-29 12:59:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 190.14285714285714
avg_sample_per_episode: 190.14285714285714
avg_envstep_per_sec: 2663.353773358987
avg_train_sample_per_sec: 2663.353773358987
avg_episode_per_sec: 14.00711976973171
collect_time: 0.4997458517579361
reward_mean: 2082.183041740048
reward_std: 1200.2930643970262
reward_max: 3530.0671020957857
reward_min: 919.6112322767973
total_envstep_count: 16254018
total_train_sample_count: 12214515
total_episode_count: 37416
total_duration: 3314.474594623214
[2023-06-29 12:59:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2689
train_sample_count: 2689
avg_envstep_per_episode: 298.77777777777777
avg_sample_per_episode: 298.77777777777777
avg_envstep_per_sec: 2674.4959679062945
avg_train_sample_per_sec: 2674.4959679062945
avg_episode_per_sec: 8.951455452270975
collect_time: 1.005423089908436
reward_mean: 2179.8489681378687
reward_std: 1008.0664463605199
reward_max: 3538.157319905621
reward_min: 987.5433239810604
total_envstep_count: 16258722
total_train_sample_count: 12218004
total_episode_count: 37425
total_duration: 3315.480017713123
[2023-06-29 12:59:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 203.2
avg_sample_per_episode: 203.2
avg_envstep_per_sec: 2811.681232890438
avg_train_sample_per_sec: 2811.681232890438
avg_episode_per_sec: 13.83701394138995
collect_time: 0.7226992790754885
reward_mean: 1635.7194259918297
reward_std: 972.851323459395
reward_max: 3551.6928961411577
reward_min: 863.4169593172392
total_envstep_count: 16262834
total_train_sample_count: 12221236
total_episode_count: 37435
total_duration: 3316.2027169921985
[2023-06-29 12:59:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2841
train_sample_count: 2841
avg_envstep_per_episode: 284.1
avg_sample_per_episode: 284.1
avg_envstep_per_sec: 2789.6836388173774
avg_train_sample_per_sec: 2789.6836388173774
avg_episode_per_sec: 9.81937218872713
collect_time: 1.0183950468320404
reward_mean: 1872.9445511950921
reward_std: 1027.3043030186923
reward_max: 3585.554080838864
reward_min: 699.4104558158773
total_envstep_count: 16267354
total_train_sample_count: 12224477
total_episode_count: 37445
total_duration: 3317.2211120390307
[2023-06-29 12:59:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3366
train_sample_count: 3366
avg_envstep_per_episode: 224.4
avg_sample_per_episode: 224.4
avg_envstep_per_sec: 2621.045947261607
avg_train_sample_per_sec: 2621.045947261607
avg_episode_per_sec: 11.680240406691654
collect_time: 1.2842201425414534
reward_mean: 1221.145169644254
reward_std: 389.8877303480853
reward_max: 2150.9950642553736
reward_min: 774.2141759700245
total_envstep_count: 16271954
total_train_sample_count: 12227843
total_episode_count: 37460
total_duration: 3318.505332181572
[2023-06-29 12:59:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 235.6
avg_sample_per_episode: 235.6
avg_envstep_per_sec: 2578.857517978392
avg_train_sample_per_sec: 2578.857517978392
avg_episode_per_sec: 10.945914762217285
collect_time: 0.45679142480250445
reward_mean: 1166.6224220474796
reward_std: 149.00444895266213
reward_max: 1292.3451520577235
reward_min: 964.4019788930495
total_envstep_count: 16276794
total_train_sample_count: 12231421
total_episode_count: 37465
total_duration: 3318.9621236063745
[2023-06-29 13:00:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1800
train_sample_count: 1800
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 2742.1825298669532
avg_train_sample_per_sec: 2742.1825298669532
avg_episode_per_sec: 13.710912649334768
collect_time: 0.6564114461364223
reward_mean: 2515.7746858505507
reward_std: 962.1945455012502
reward_max: 3567.5629960086067
reward_min: 1160.7134763653394
total_envstep_count: 16281170
total_train_sample_count: 12234821
total_episode_count: 37474
total_duration: 3319.618535052511
[2023-06-29 13:00:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 335.3333333333333
avg_sample_per_episode: 335.3333333333333
avg_envstep_per_sec: 2765.10651025139
avg_train_sample_per_sec: 2765.10651025139
avg_episode_per_sec: 8.245844463970348
collect_time: 0.7276392401307821
reward_mean: 2547.161020827832
reward_std: 634.969584505766
reward_max: 3518.7797528305173
reward_min: 1839.8228712963692
total_envstep_count: 16285370
total_train_sample_count: 12238033
total_episode_count: 37480
total_duration: 3320.346174292642
[2023-06-29 13:00:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 229.55555555555554
avg_sample_per_episode: 229.55555555555554
avg_envstep_per_sec: 2633.165310981865
avg_train_sample_per_sec: 2633.165310981865
avg_episode_per_sec: 11.47071045442245
collect_time: 0.7846070246268063
reward_mean: 1841.6861647715907
reward_std: 875.993623751002
reward_max: 3771.4544971110176
reward_min: 885.1222155097995
total_envstep_count: 16290186
total_train_sample_count: 12241299
total_episode_count: 37489
total_duration: 3321.130781317269
[2023-06-29 13:00:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2112
train_sample_count: 2112
avg_envstep_per_episode: 264.0
avg_sample_per_episode: 264.0
avg_envstep_per_sec: 2469.8087958696938
avg_train_sample_per_sec: 2469.8087958696938
avg_episode_per_sec: 9.355336347991264
collect_time: 0.8551269246153532
reward_mean: 2221.4443700537086
reward_std: 981.5003330607094
reward_max: 3540.9438206905647
reward_min: 930.2981709470318
total_envstep_count: 16294090
total_train_sample_count: 12244611
total_episode_count: 37497
total_duration: 3321.9859082418843
[2023-06-29 13:00:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2055
train_sample_count: 2055
avg_envstep_per_episode: 293.57142857142856
avg_sample_per_episode: 293.57142857142856
avg_envstep_per_sec: 2785.414578389908
avg_train_sample_per_sec: 2785.414578389908
avg_episode_per_sec: 9.488030194028884
collect_time: 0.7377716825148091
reward_mean: 2035.3063673828315
reward_std: 841.9231705460435
reward_max: 3233.284273821315
reward_min: 873.7639787001776
total_envstep_count: 16297882
total_train_sample_count: 12247866
total_episode_count: 37504
total_duration: 3322.723679924399
[2023-06-29 13:00:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1612
train_sample_count: 1612
avg_envstep_per_episode: 268.6666666666667
avg_sample_per_episode: 268.6666666666667
avg_envstep_per_sec: 2717.1581616460517
avg_train_sample_per_sec: 2717.1581616460517
avg_episode_per_sec: 10.113491916796718
collect_time: 0.5932669002320616
reward_mean: 2065.0861191261315
reward_std: 497.24442955356716
reward_max: 2845.6239762104997
reward_min: 1279.50627847607
total_envstep_count: 16302522
total_train_sample_count: 12251078
total_episode_count: 37510
total_duration: 3323.3169468246315
[2023-06-29 13:00:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2024
train_sample_count: 2024
avg_envstep_per_episode: 202.4
avg_sample_per_episode: 202.4
avg_envstep_per_sec: 2492.184796183165
avg_train_sample_per_sec: 2492.184796183165
avg_episode_per_sec: 12.313165989047258
collect_time: 0.8121388121377676
reward_mean: 1918.4441675828173
reward_std: 816.8414769824091
reward_max: 3553.992114334076
reward_min: 947.7822813212181
total_envstep_count: 16306330
total_train_sample_count: 12254302
total_episode_count: 37520
total_duration: 3324.129085636769
[2023-06-29 13:00:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3232
train_sample_count: 3232
avg_envstep_per_episode: 323.2
avg_sample_per_episode: 323.2
avg_envstep_per_sec: 2516.8629292369274
avg_train_sample_per_sec: 2516.8629292369274
avg_episode_per_sec: 7.787323419668711
collect_time: 1.2841382669098673
reward_mean: 1843.4843190930164
reward_std: 731.1046668458869
reward_max: 3512.4357040321765
reward_min: 1076.0445052460593
total_envstep_count: 16310986
total_train_sample_count: 12257534
total_episode_count: 37530
total_duration: 3325.413223903679
[2023-06-29 13:00:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 275.77777777777777
avg_sample_per_episode: 275.77777777777777
avg_envstep_per_sec: 2735.5254913865238
avg_train_sample_per_sec: 2735.5254913865238
avg_episode_per_sec: 9.919310806800448
collect_time: 0.9073211007593198
reward_mean: 1589.05351086581
reward_std: 580.4411116819246
reward_max: 2432.126873369811
reward_min: 833.4772764070409
total_envstep_count: 16314994
total_train_sample_count: 12260816
total_episode_count: 37539
total_duration: 3326.3205450044384
[2023-06-29 13:00:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2814
train_sample_count: 2814
avg_envstep_per_episode: 255.8181818181818
avg_sample_per_episode: 255.8181818181818
avg_envstep_per_sec: 2588.302785308604
avg_train_sample_per_sec: 2588.302785308604
avg_episode_per_sec: 10.117743652592269
collect_time: 1.087198922773823
reward_mean: 1455.6554243640232
reward_std: 344.405494966636
reward_max: 2299.6133575170447
reward_min: 1022.6685662568808
total_envstep_count: 16319378
total_train_sample_count: 12264030
total_episode_count: 37550
total_duration: 3327.4077439272123
[2023-06-29 13:00:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2911
train_sample_count: 2911
avg_envstep_per_episode: 242.58333333333334
avg_sample_per_episode: 242.58333333333334
avg_envstep_per_sec: 2596.5781109452973
avg_train_sample_per_sec: 2596.5781109452973
avg_episode_per_sec: 10.703860299327918
collect_time: 1.1210908648306503
reward_mean: 1375.720758129002
reward_std: 543.5466482623527
reward_max: 2786.3388195654443
reward_min: 950.8227829881423
total_envstep_count: 16324042
total_train_sample_count: 12267341
total_episode_count: 37562
total_duration: 3328.528834792043
[2023-06-29 13:00:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3418
train_sample_count: 3418
avg_envstep_per_episode: 213.625
avg_sample_per_episode: 213.625
avg_envstep_per_sec: 2636.3069659482626
avg_train_sample_per_sec: 2636.3069659482626
avg_episode_per_sec: 12.34081669256062
collect_time: 1.2965106279915197
reward_mean: 1177.9804705922656
reward_std: 613.2986519925593
reward_max: 2693.272390226282
reward_min: 46.020269653232596
total_envstep_count: 16328954
total_train_sample_count: 12270759
total_episode_count: 37578
total_duration: 3329.825345420035
[2023-06-29 13:00:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2776
train_sample_count: 2776
avg_envstep_per_episode: 231.33333333333334
avg_sample_per_episode: 231.33333333333334
avg_envstep_per_sec: 2501.3600980782826
avg_train_sample_per_sec: 2501.3600980782826
avg_episode_per_sec: 10.812795813018512
collect_time: 1.1097962273135782
reward_mean: 1267.8555427018075
reward_std: 414.99416292748214
reward_max: 1941.2193672617166
reward_min: 393.27259524393935
total_envstep_count: 16333770
total_train_sample_count: 12274335
total_episode_count: 37590
total_duration: 3330.9351416473482
[2023-06-29 13:00:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3342
train_sample_count: 3342
avg_envstep_per_episode: 278.5
avg_sample_per_episode: 278.5
avg_envstep_per_sec: 2822.7505188675714
avg_train_sample_per_sec: 2822.7505188675714
avg_episode_per_sec: 10.135549439380867
collect_time: 1.1839516024040058
reward_mean: 1695.8532613015448
reward_std: 720.0676975481481
reward_max: 3347.3860604203555
reward_min: 898.9447478297297
total_envstep_count: 16338714
total_train_sample_count: 12277677
total_episode_count: 37602
total_duration: 3332.119093249752
[2023-06-29 13:00:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2804
train_sample_count: 2804
avg_envstep_per_episode: 233.66666666666666
avg_sample_per_episode: 233.66666666666666
avg_envstep_per_sec: 2651.8922919021397
avg_train_sample_per_sec: 2651.8922919021397
avg_episode_per_sec: 11.3490397656297
collect_time: 1.0573581772390752
reward_mean: 1310.668961317883
reward_std: 474.61062044281243
reward_max: 2296.280763583565
reward_min: 613.2378545665812
total_envstep_count: 16343082
total_train_sample_count: 12280881
total_episode_count: 37614
total_duration: 3333.176451426991
[2023-06-29 13:00:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 225.72727272727272
avg_sample_per_episode: 225.72727272727272
avg_envstep_per_sec: 2757.6553101639283
avg_train_sample_per_sec: 2757.6553101639283
avg_episode_per_sec: 12.21675731445961
collect_time: 0.9004025959474966
reward_mean: 1403.371989319574
reward_std: 485.76983192697315
reward_max: 2620.7681844109866
reward_min: 941.095811955368
total_envstep_count: 16347898
total_train_sample_count: 12284164
total_episode_count: 37625
total_duration: 3334.0768540229387
[2023-06-29 13:00:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2599
train_sample_count: 2599
avg_envstep_per_episode: 236.27272727272728
avg_sample_per_episode: 236.27272727272728
avg_envstep_per_sec: 2800.233200964526
avg_train_sample_per_sec: 2800.233200964526
avg_episode_per_sec: 11.851698811315808
collect_time: 0.9281369848428295
reward_mean: 1676.0077016952055
reward_std: 483.1456450436289
reward_max: 2240.2272302784518
reward_min: 787.3149637813265
total_envstep_count: 16352466
total_train_sample_count: 12287563
total_episode_count: 37636
total_duration: 3335.0049910077814
[2023-06-29 13:00:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2070
train_sample_count: 2070
avg_envstep_per_episode: 207.0
avg_sample_per_episode: 207.0
avg_envstep_per_sec: 2655.3625477957685
avg_train_sample_per_sec: 2655.3625477957685
avg_episode_per_sec: 12.827838395148639
collect_time: 0.7795545665575192
reward_mean: 1481.373603712645
reward_std: 812.4386538033257
reward_max: 3685.727726885118
reward_min: 802.6380777373013
total_envstep_count: 16356858
total_train_sample_count: 12290833
total_episode_count: 37646
total_duration: 3335.784545574339
[2023-06-29 13:00:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2831
train_sample_count: 2831
avg_envstep_per_episode: 202.21428571428572
avg_sample_per_episode: 202.21428571428572
avg_envstep_per_sec: 2592.5715367929333
avg_train_sample_per_sec: 2592.5715367929333
avg_episode_per_sec: 12.82091187393185
collect_time: 1.0919660112839191
reward_mean: 1257.8524527693546
reward_std: 469.5710791336101
reward_max: 2357.8743969760108
reward_min: 787.7007359710864
total_envstep_count: 16360834
total_train_sample_count: 12294064
total_episode_count: 37660
total_duration: 3336.876511585623
[2023-06-29 13:00:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3240
train_sample_count: 3240
avg_envstep_per_episode: 231.42857142857142
avg_sample_per_episode: 231.42857142857142
avg_envstep_per_sec: 2621.4551928031124
avg_train_sample_per_sec: 2621.4551928031124
avg_episode_per_sec: 11.327275524457892
collect_time: 1.2359547509700062
reward_mean: 1285.555663925484
reward_std: 739.6470204256898
reward_max: 3636.6733676204244
reward_min: 672.8673211784765
total_envstep_count: 16364986
total_train_sample_count: 12297304
total_episode_count: 37674
total_duration: 3338.112466336593
[2023-06-29 13:01:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3454
train_sample_count: 3454
avg_envstep_per_episode: 265.6923076923077
avg_sample_per_episode: 265.6923076923077
avg_envstep_per_sec: 2592.837692443382
avg_train_sample_per_sec: 2592.837692443382
avg_episode_per_sec: 9.758798495009833
collect_time: 1.33213120515272
reward_mean: 1248.7953045686613
reward_std: 418.5644238882249
reward_max: 2268.7889925344703
reward_min: 868.0390940604609
total_envstep_count: 16370138
total_train_sample_count: 12300758
total_episode_count: 37687
total_duration: 3339.4445975417457
[2023-06-29 13:01:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2822
train_sample_count: 2822
avg_envstep_per_episode: 235.16666666666666
avg_sample_per_episode: 235.16666666666666
avg_envstep_per_sec: 2726.8685696395078
avg_train_sample_per_sec: 2726.8685696395078
avg_episode_per_sec: 11.595472301798049
collect_time: 1.0348866943642496
reward_mean: 1401.6185697698138
reward_std: 474.7759566159773
reward_max: 2249.97370464922
reward_min: 703.2593827832142
total_envstep_count: 16374098
total_train_sample_count: 12303980
total_episode_count: 37699
total_duration: 3340.47948423611
[2023-06-29 13:01:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2541
train_sample_count: 2541
avg_envstep_per_episode: 363.0
avg_sample_per_episode: 363.0
avg_envstep_per_sec: 2667.5666065014284
avg_train_sample_per_sec: 2667.5666065014284
avg_episode_per_sec: 7.3486683374695
collect_time: 0.9525535346735265
reward_mean: 1895.0988325655962
reward_std: 1051.983651095837
reward_max: 3649.389840510135
reward_min: 954.7120507504819
total_envstep_count: 16378826
total_train_sample_count: 12307321
total_episode_count: 37706
total_duration: 3341.432037770783
[2023-06-29 13:01:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1711
train_sample_count: 1711
avg_envstep_per_episode: 244.42857142857142
avg_sample_per_episode: 244.42857142857142
avg_envstep_per_sec: 2802.48841912022
avg_train_sample_per_sec: 2802.48841912022
avg_episode_per_sec: 11.465469861976354
collect_time: 0.6105288387015462
reward_mean: 1896.6932602120846
reward_std: 879.4896516639823
reward_max: 3596.0438559841186
reward_min: 737.9286686075728
total_envstep_count: 16383546
total_train_sample_count: 12310632
total_episode_count: 37713
total_duration: 3342.0425666094848
[2023-06-29 13:01:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2382
train_sample_count: 2382
avg_envstep_per_episode: 238.2
avg_sample_per_episode: 238.2
avg_envstep_per_sec: 2576.8623508446503
avg_train_sample_per_sec: 2576.8623508446503
avg_episode_per_sec: 10.81806192629996
collect_time: 0.9243799922876059
reward_mean: 2021.0553323500073
reward_std: 952.3362834450443
reward_max: 3581.390166508825
reward_min: 988.7360494848406
total_envstep_count: 16388098
total_train_sample_count: 12314214
total_episode_count: 37723
total_duration: 3342.966946601772
[2023-06-29 13:01:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1665
train_sample_count: 1665
avg_envstep_per_episode: 237.85714285714286
avg_sample_per_episode: 237.85714285714286
avg_envstep_per_sec: 2808.6337014640485
avg_train_sample_per_sec: 2808.6337014640485
avg_episode_per_sec: 11.808069615764769
collect_time: 0.5928149331584571
reward_mean: 2013.1235785821102
reward_std: 925.6225214184548
reward_max: 3619.6349622107787
reward_min: 809.7542423611675
total_envstep_count: 16392858
total_train_sample_count: 12317479
total_episode_count: 37730
total_duration: 3343.5597615349307
[2023-06-29 13:01:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1252
train_sample_count: 1252
avg_envstep_per_episode: 208.66666666666666
avg_sample_per_episode: 208.66666666666666
avg_envstep_per_sec: 2381.6739058291346
avg_train_sample_per_sec: 2381.6739058291346
avg_episode_per_sec: 11.41377271164122
collect_time: 0.5256806974858046
reward_mean: 2903.6029167440415
reward_std: 818.8413082903572
reward_max: 3757.131103029035
reward_min: 1685.771769970169
total_envstep_count: 16397482
total_train_sample_count: 12320731
total_episode_count: 37736
total_duration: 3344.0854422324164
[2023-06-29 13:01:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2123
train_sample_count: 2123
avg_envstep_per_episode: 353.8333333333333
avg_sample_per_episode: 353.8333333333333
avg_envstep_per_sec: 2570.779133369222
avg_train_sample_per_sec: 2570.779133369222
avg_episode_per_sec: 7.26550861997896
collect_time: 0.8258196795061231
reward_mean: 2794.069873811952
reward_std: 973.8277289021732
reward_max: 3634.399011434667
reward_min: 882.5905276033409
total_envstep_count: 16402242
total_train_sample_count: 12324054
total_episode_count: 37742
total_duration: 3344.9112619119223
[2023-06-29 13:01:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1608
train_sample_count: 1608
avg_envstep_per_episode: 201.0
avg_sample_per_episode: 201.0
avg_envstep_per_sec: 2679.178147039614
avg_train_sample_per_sec: 2679.178147039614
avg_episode_per_sec: 13.329244512634896
collect_time: 0.600184053373523
reward_mean: 2152.1371290782035
reward_std: 1240.2659268359039
reward_max: 3675.3390464798917
reward_min: 62.96259637562657
total_envstep_count: 16406570
total_train_sample_count: 12327262
total_episode_count: 37750
total_duration: 3345.511445965296
[2023-06-29 13:01:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1354
train_sample_count: 1354
avg_envstep_per_episode: 338.5
avg_sample_per_episode: 338.5
avg_envstep_per_sec: 2737.3253344043424
avg_train_sample_per_sec: 2737.3253344043424
avg_episode_per_sec: 8.08663318878683
collect_time: 0.4946434327634052
reward_mean: 3498.360281067515
reward_std: 131.69642198945076
reward_max: 3624.3763234062967
reward_min: 3279.0228034538573
total_envstep_count: 16410610
total_train_sample_count: 12330616
total_episode_count: 37754
total_duration: 3346.0060893980594
[2023-06-29 13:01:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1398
train_sample_count: 1398
avg_envstep_per_episode: 279.6
avg_sample_per_episode: 279.6
avg_envstep_per_sec: 2625.8273232952474
avg_train_sample_per_sec: 2625.8273232952474
avg_episode_per_sec: 9.391370970297737
collect_time: 0.5324036305043846
reward_mean: 2987.597340641418
reward_std: 816.9052698792697
reward_max: 3605.2577683157897
reward_min: 1500.6891815008964
total_envstep_count: 16415370
total_train_sample_count: 12334014
total_episode_count: 37759
total_duration: 3346.5384930285636
[2023-06-29 13:01:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2456.817607624331
avg_train_sample_per_sec: 2456.817607624331
avg_episode_per_sec: 9.672510266237522
collect_time: 0.8270862247543412
reward_mean: 2745.6648016670524
reward_std: 1110.8814251490173
reward_max: 3711.130145147116
reward_min: 1075.8192172290221
total_envstep_count: 16419682
total_train_sample_count: 12337246
total_episode_count: 37767
total_duration: 3347.365579253318
[2023-06-29 13:01:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2662
train_sample_count: 2662
avg_envstep_per_episode: 380.2857142857143
avg_sample_per_episode: 380.2857142857143
avg_envstep_per_sec: 2668.3018413726186
avg_train_sample_per_sec: 2668.3018413726186
avg_episode_per_sec: 7.016571333436637
collect_time: 0.997638257683255
reward_mean: 2434.9244684402443
reward_std: 782.1914508805196
reward_max: 3580.080982405511
reward_min: 1075.6706736719468
total_envstep_count: 16424618
total_train_sample_count: 12340708
total_episode_count: 37774
total_duration: 3348.3632175110015
[2023-06-29 13:01:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 515
train_sample_count: 515
avg_envstep_per_episode: 103.0
avg_sample_per_episode: 103.0
avg_envstep_per_sec: 2745.6740383079423
avg_train_sample_per_sec: 2745.6740383079423
avg_episode_per_sec: 26.657029498135362
collect_time: 0.18756778583861888
reward_mean: 1943.6692276773658
reward_std: 884.900366174569
reward_max: 3574.63321422117
reward_min: 1041.408440625225
total_envstep_count: 16428818
total_train_sample_count: 12344023
total_episode_count: 37779
total_duration: 3348.5507852968403
[2023-06-29 13:01:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1908
train_sample_count: 1908
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2526.265883605449
avg_train_sample_per_sec: 2526.265883605449
avg_episode_per_sec: 11.916348507572872
collect_time: 0.7552649198099968
reward_mean: 2476.6615319518855
reward_std: 868.261311865958
reward_max: 3613.9117593343094
reward_min: 1522.5920164964573
total_envstep_count: 16433314
total_train_sample_count: 12347531
total_episode_count: 37788
total_duration: 3349.3060502166504
[2023-06-29 13:01:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 400.3333333333333
avg_sample_per_episode: 400.3333333333333
avg_envstep_per_sec: 2779.8021076405166
avg_train_sample_per_sec: 2779.8021076405166
avg_episode_per_sec: 6.943718836737343
collect_time: 0.43204514332115657
reward_mean: 2996.235055189827
reward_std: 900.9065090225566
reward_max: 3690.619941180178
reward_min: 1723.9366563280064
total_envstep_count: 16436898
total_train_sample_count: 12350732
total_episode_count: 37791
total_duration: 3349.738095359972
[2023-06-29 13:01:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1868
train_sample_count: 1868
avg_envstep_per_episode: 233.5
avg_sample_per_episode: 233.5
avg_envstep_per_sec: 2755.231593313694
avg_train_sample_per_sec: 2755.231593313694
avg_episode_per_sec: 11.799707037746012
collect_time: 0.6779829341871665
reward_mean: 2550.922350462279
reward_std: 993.6804014063007
reward_max: 3633.8274685880133
reward_min: 1142.3225129678221
total_envstep_count: 16441514
total_train_sample_count: 12354200
total_episode_count: 37799
total_duration: 3350.416078294159
[2023-06-29 13:01:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1655
train_sample_count: 1655
avg_envstep_per_episode: 236.42857142857142
avg_sample_per_episode: 236.42857142857142
avg_envstep_per_sec: 2670.061482514563
avg_train_sample_per_sec: 2670.061482514563
avg_episode_per_sec: 11.293311406406007
collect_time: 0.6198359142057596
reward_mean: 2027.149686888812
reward_std: 532.9397847372823
reward_max: 2568.5814848297423
reward_min: 971.5967188225577
total_envstep_count: 16445594
total_train_sample_count: 12357455
total_episode_count: 37806
total_duration: 3351.035914208365
[2023-06-29 13:01:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2213
train_sample_count: 2213
avg_envstep_per_episode: 221.3
avg_sample_per_episode: 221.3
avg_envstep_per_sec: 2578.435375481914
avg_train_sample_per_sec: 2578.435375481914
avg_episode_per_sec: 11.651312135028983
collect_time: 0.8582724318178371
reward_mean: 1938.5949837541866
reward_std: 913.5826478517909
reward_max: 3589.9012673152642
reward_min: 699.5034725303198
total_envstep_count: 16450258
total_train_sample_count: 12360868
total_episode_count: 37816
total_duration: 3351.894186640183
[2023-06-29 13:02:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2925
train_sample_count: 2925
avg_envstep_per_episode: 265.90909090909093
avg_sample_per_episode: 265.90909090909093
avg_envstep_per_sec: 2510.103134167921
avg_train_sample_per_sec: 2510.103134167921
avg_episode_per_sec: 9.439704094306713
collect_time: 1.1652907644249502
reward_mean: 1853.0824534798346
reward_std: 738.8905956887027
reward_max: 3523.8977947401568
reward_min: 820.2165747176526
total_envstep_count: 16454874
total_train_sample_count: 12364193
total_episode_count: 37827
total_duration: 3353.0594774046076
[2023-06-29 13:02:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3504
train_sample_count: 3504
avg_envstep_per_episode: 269.53846153846155
avg_sample_per_episode: 269.53846153846155
avg_envstep_per_sec: 2593.8706149109303
avg_train_sample_per_sec: 2593.8706149109303
avg_episode_per_sec: 9.62337842290014
collect_time: 1.350876940375194
reward_mean: 1481.0380506013812
reward_std: 696.8691612987592
reward_max: 2799.904943616279
reward_min: 697.070009076896
total_envstep_count: 16459306
total_train_sample_count: 12367697
total_episode_count: 37840
total_duration: 3354.410354344983
[2023-06-29 13:02:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2526
train_sample_count: 2526
avg_envstep_per_episode: 280.6666666666667
avg_sample_per_episode: 280.6666666666667
avg_envstep_per_sec: 2717.4064149511846
avg_train_sample_per_sec: 2717.4064149511846
avg_episode_per_sec: 9.681970599588544
collect_time: 0.9295628309780732
reward_mean: 1351.9132559282084
reward_std: 861.87257222228
reward_max: 2366.9157384745163
reward_min: 47.28011523562847
total_envstep_count: 16464522
total_train_sample_count: 12371023
total_episode_count: 37849
total_duration: 3355.339917175961
[2023-06-29 13:02:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3072
train_sample_count: 3072
avg_envstep_per_episode: 204.8
avg_sample_per_episode: 204.8
avg_envstep_per_sec: 2623.7737365794555
avg_train_sample_per_sec: 2623.7737365794555
avg_episode_per_sec: 12.811395198141874
collect_time: 1.1708326663887128
reward_mean: 1442.4540374457858
reward_std: 944.5139752459539
reward_max: 3574.319200686548
reward_min: 28.343796950372145
total_envstep_count: 16469170
total_train_sample_count: 12374495
total_episode_count: 37864
total_duration: 3356.51074984235
[2023-06-29 13:02:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2576
train_sample_count: 2576
avg_envstep_per_episode: 234.1818181818182
avg_sample_per_episode: 234.1818181818182
avg_envstep_per_sec: 2560.054442446319
avg_train_sample_per_sec: 2560.054442446319
avg_episode_per_sec: 10.93190949802388
collect_time: 1.0062286009583623
reward_mean: 1360.2262298946264
reward_std: 563.8485102659565
reward_max: 2909.2657792254035
reward_min: 911.2148699988006
total_envstep_count: 16473386
total_train_sample_count: 12377871
total_episode_count: 37875
total_duration: 3357.5169784433083
[2023-06-29 13:02:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3379
train_sample_count: 3379
avg_envstep_per_episode: 259.9230769230769
avg_sample_per_episode: 259.9230769230769
avg_envstep_per_sec: 2526.660644948737
avg_train_sample_per_sec: 2526.660644948737
avg_episode_per_sec: 9.720801534280433
collect_time: 1.3373382795806976
reward_mean: 1438.4699928864748
reward_std: 589.0922800676816
reward_max: 2474.8583565064355
reward_min: 591.2085871817515
total_envstep_count: 16477978
total_train_sample_count: 12381250
total_episode_count: 37888
total_duration: 3358.854316722889
[2023-06-29 13:02:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2129
train_sample_count: 2129
avg_envstep_per_episode: 236.55555555555554
avg_sample_per_episode: 236.55555555555554
avg_envstep_per_sec: 2719.365693038857
avg_train_sample_per_sec: 2719.365693038857
avg_episode_per_sec: 11.495674606552237
collect_time: 0.7829031621050089
reward_mean: 1096.0947632461862
reward_std: 325.06278127723004
reward_max: 1436.3309493147128
reward_min: 435.85386247505375
total_envstep_count: 16482074
total_train_sample_count: 12384579
total_episode_count: 37897
total_duration: 3359.637219884994
[2023-06-29 13:02:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3024
train_sample_count: 3024
avg_envstep_per_episode: 232.6153846153846
avg_sample_per_episode: 232.6153846153846
avg_envstep_per_sec: 2605.0608426934155
avg_train_sample_per_sec: 2605.0608426934155
avg_episode_per_sec: 11.19900494544127
collect_time: 1.1608174175592139
reward_mean: 1603.1960757569516
reward_std: 1001.5510710041458
reward_max: 3742.7588822616053
reward_min: 631.4891142309588
total_envstep_count: 16486234
total_train_sample_count: 12388003
total_episode_count: 37910
total_duration: 3360.7980373025534
[2023-06-29 13:02:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 277.6666666666667
avg_sample_per_episode: 277.6666666666667
avg_envstep_per_sec: 2599.6845981910237
avg_train_sample_per_sec: 2599.6845981910237
avg_episode_per_sec: 9.362609597326616
collect_time: 1.2816939417645332
reward_mean: 1383.6104639128507
reward_std: 571.6850644162373
reward_max: 2543.9680358862156
reward_min: 661.3845897110718
total_envstep_count: 16490626
total_train_sample_count: 12391335
total_episode_count: 37922
total_duration: 3362.079731244318
[2023-06-29 13:02:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3190
train_sample_count: 3190
avg_envstep_per_episode: 212.66666666666666
avg_sample_per_episode: 212.66666666666666
avg_envstep_per_sec: 2589.564918859178
avg_train_sample_per_sec: 2589.564918859178
avg_episode_per_sec: 12.176637549494567
collect_time: 1.2318671668618917
reward_mean: 1041.2407491146917
reward_std: 442.87215268874803
reward_max: 2320.662322351401
reward_min: 415.50076191528996
total_envstep_count: 16495162
total_train_sample_count: 12394925
total_episode_count: 37937
total_duration: 3363.3115984111796
[2023-06-29 13:02:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2933
train_sample_count: 2933
avg_envstep_per_episode: 225.6153846153846
avg_sample_per_episode: 225.6153846153846
avg_envstep_per_sec: 2820.994094387087
avg_train_sample_per_sec: 2820.994094387087
avg_episode_per_sec: 12.503553776690122
collect_time: 1.0397044098163022
reward_mean: 1203.4075056198858
reward_std: 534.6994212799448
reward_max: 2324.4382512269417
reward_min: 237.31289699985822
total_envstep_count: 16499378
total_train_sample_count: 12398258
total_episode_count: 37950
total_duration: 3364.351302820996
[2023-06-29 13:02:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 201.75
avg_sample_per_episode: 201.75
avg_envstep_per_sec: 2784.851663137631
avg_train_sample_per_sec: 2784.851663137631
avg_episode_per_sec: 13.803477884201394
collect_time: 0.8693461242644115
reward_mean: 1150.232921439623
reward_std: 465.7178933891647
reward_max: 2069.2631468150635
reward_min: 399.61948065803097
total_envstep_count: 16503738
total_train_sample_count: 12401479
total_episode_count: 37962
total_duration: 3365.22064894526
[2023-06-29 13:02:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3040
train_sample_count: 3040
avg_envstep_per_episode: 190.0
avg_sample_per_episode: 190.0
avg_envstep_per_sec: 2598.667616993845
avg_train_sample_per_sec: 2598.667616993845
avg_episode_per_sec: 13.677197984178132
collect_time: 1.169830254596658
reward_mean: 1145.500948603216
reward_std: 588.5048574663751
reward_max: 2352.702366661008
reward_min: 240.96936300153203
total_envstep_count: 16508178
total_train_sample_count: 12404919
total_episode_count: 37978
total_duration: 3366.3904791998566
[2023-06-29 13:02:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2502
train_sample_count: 2502
avg_envstep_per_episode: 227.45454545454547
avg_sample_per_episode: 227.45454545454547
avg_envstep_per_sec: 2692.3175393999713
avg_train_sample_per_sec: 2692.3175393999713
avg_episode_per_sec: 11.836727791126972
collect_time: 0.9293108867676928
reward_mean: 1315.371972936006
reward_std: 578.4496349207606
reward_max: 2235.8821289071752
reward_min: 644.2185434361508
total_envstep_count: 16513018
total_train_sample_count: 12408221
total_episode_count: 37989
total_duration: 3367.3197900866244
[2023-06-29 13:02:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2948
train_sample_count: 2948
avg_envstep_per_episode: 226.76923076923077
avg_sample_per_episode: 226.76923076923077
avg_envstep_per_sec: 2812.7094668569403
avg_train_sample_per_sec: 2812.7094668569403
avg_episode_per_sec: 12.40339995561066
collect_time: 1.0480997183453291
reward_mean: 1519.3027177834479
reward_std: 509.80497954588077
reward_max: 2459.394441648947
reward_min: 915.6227553334261
total_envstep_count: 16517386
total_train_sample_count: 12411569
total_episode_count: 38002
total_duration: 3368.3678898049698
[2023-06-29 13:02:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3170
train_sample_count: 3170
avg_envstep_per_episode: 243.84615384615384
avg_sample_per_episode: 243.84615384615384
avg_envstep_per_sec: 2601.4917421292134
avg_train_sample_per_sec: 2601.4917421292134
avg_episode_per_sec: 10.668578122296458
collect_time: 1.2185316403908653
reward_mean: 1302.1665447832297
reward_std: 575.567339050342
reward_max: 2728.435157546364
reward_min: 457.28815731835977
total_envstep_count: 16522170
total_train_sample_count: 12415139
total_episode_count: 38015
total_duration: 3369.5864214453604
[2023-06-29 13:02:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3183
train_sample_count: 3183
avg_envstep_per_episode: 244.84615384615384
avg_sample_per_episode: 244.84615384615384
avg_envstep_per_sec: 2649.2622030250386
avg_train_sample_per_sec: 2649.2622030250386
avg_episode_per_sec: 10.820109531676248
collect_time: 1.2014665805315599
reward_mean: 1357.2243114606206
reward_std: 725.0190407638996
reward_max: 2513.6573269427467
reward_min: 19.50580483406584
total_envstep_count: 16527034
total_train_sample_count: 12418722
total_episode_count: 38028
total_duration: 3370.787888025892
[2023-06-29 13:02:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2841
train_sample_count: 2841
avg_envstep_per_episode: 189.4
avg_sample_per_episode: 189.4
avg_envstep_per_sec: 2673.5155606537587
avg_train_sample_per_sec: 2673.5155606537587
avg_episode_per_sec: 14.115710457517205
collect_time: 1.062645769417286
reward_mean: 1087.6598635544647
reward_std: 545.0991824942258
reward_max: 2522.234248918135
reward_min: 455.75547668737966
total_envstep_count: 16531170
total_train_sample_count: 12421963
total_episode_count: 38043
total_duration: 3371.8505337953093
[2023-06-29 13:02:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2955
train_sample_count: 2955
avg_envstep_per_episode: 197.0
avg_sample_per_episode: 197.0
avg_envstep_per_sec: 2720.3428672742257
avg_train_sample_per_sec: 2720.3428672742257
avg_episode_per_sec: 13.808847042001146
collect_time: 1.086260131231509
reward_mean: 1024.9331782782783
reward_std: 413.1149420808291
reward_max: 2222.5048803445634
reward_min: 631.4665043720674
total_envstep_count: 16535978
total_train_sample_count: 12425318
total_episode_count: 38058
total_duration: 3372.9367939265408
[2023-06-29 13:02:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3348
train_sample_count: 3348
avg_envstep_per_episode: 257.53846153846155
avg_sample_per_episode: 257.53846153846155
avg_envstep_per_sec: 2786.6752516199413
avg_train_sample_per_sec: 2786.6752516199413
avg_episode_per_sec: 10.820423617401206
collect_time: 1.201431705418043
reward_mean: 1481.5675663410307
reward_std: 594.613956540193
reward_max: 2732.6242272626255
reward_min: 763.8562289367069
total_envstep_count: 16540298
total_train_sample_count: 12428666
total_episode_count: 38071
total_duration: 3374.138225631959
[2023-06-29 13:03:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3430
train_sample_count: 3430
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 2637.2407765539883
avg_train_sample_per_sec: 2637.2407765539883
avg_episode_per_sec: 10.764248067567298
collect_time: 1.3006017616949974
reward_mean: 1162.4731832452824
reward_std: 375.4800031757738
reward_max: 1650.0650934531775
reward_min: 617.9601417094783
total_envstep_count: 16544930
total_train_sample_count: 12432096
total_episode_count: 38085
total_duration: 3375.438827393654
[2023-06-29 13:03:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2838
train_sample_count: 2838
avg_envstep_per_episode: 202.71428571428572
avg_sample_per_episode: 202.71428571428572
avg_envstep_per_sec: 2710.0807615088165
avg_train_sample_per_sec: 2710.0807615088165
avg_episode_per_sec: 13.368967815758785
collect_time: 1.0472012643711641
reward_mean: 1055.2159781924936
reward_std: 302.41348061959724
reward_max: 1662.0950934066987
reward_min: 688.1196672758321
total_envstep_count: 16549818
total_train_sample_count: 12435334
total_episode_count: 38099
total_duration: 3376.486028658025
[2023-06-29 13:03:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2848
train_sample_count: 2848
avg_envstep_per_episode: 237.33333333333334
avg_sample_per_episode: 237.33333333333334
avg_envstep_per_sec: 2734.5646116239923
avg_train_sample_per_sec: 2734.5646116239923
avg_episode_per_sec: 11.522041902910079
collect_time: 1.0414820655155927
reward_mean: 1444.8098548316846
reward_std: 698.8988877314648
reward_max: 3395.5569980859636
reward_min: 847.7786385171743
total_envstep_count: 16554474
total_train_sample_count: 12438982
total_episode_count: 38111
total_duration: 3377.5275107235407
[2023-06-29 13:03:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2445
train_sample_count: 2445
avg_envstep_per_episode: 222.27272727272728
avg_sample_per_episode: 222.27272727272728
avg_envstep_per_sec: 2754.7436736340987
avg_train_sample_per_sec: 2754.7436736340987
avg_episode_per_sec: 12.39352982003071
collect_time: 0.8875598929226398
reward_mean: 1471.8279140573195
reward_std: 938.1062197212917
reward_max: 3669.3107335768987
reward_min: 23.116900965090238
total_envstep_count: 16558842
total_train_sample_count: 12442227
total_episode_count: 38122
total_duration: 3378.4150706164633
[2023-06-29 13:03:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1844
train_sample_count: 1844
avg_envstep_per_episode: 167.63636363636363
avg_sample_per_episode: 167.63636363636363
avg_envstep_per_sec: 2506.7418809618616
avg_train_sample_per_sec: 2506.7418809618616
avg_episode_per_sec: 14.953449398362515
collect_time: 0.7356162251904608
reward_mean: 1260.7742309160712
reward_std: 789.7722460364985
reward_max: 2954.9643096436826
reward_min: 28.406381912128836
total_envstep_count: 16563106
total_train_sample_count: 12445671
total_episode_count: 38133
total_duration: 3379.1506868416536
[2023-06-29 13:03:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3094
train_sample_count: 3094
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 2616.6180959718877
avg_train_sample_per_sec: 2616.6180959718877
avg_episode_per_sec: 10.99419368055415
collect_time: 1.1824423307180405
reward_mean: 1642.3809059263613
reward_std: 697.9029017127959
reward_max: 3452.428782163116
reward_min: 818.3207766850288
total_envstep_count: 16567298
total_train_sample_count: 12449165
total_episode_count: 38146
total_duration: 3380.3331291723716
[2023-06-29 13:03:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2085
train_sample_count: 2085
avg_envstep_per_episode: 231.66666666666666
avg_sample_per_episode: 231.66666666666666
avg_envstep_per_sec: 2757.177441287394
avg_train_sample_per_sec: 2757.177441287394
avg_episode_per_sec: 11.90148535807508
collect_time: 0.7562081311047077
reward_mean: 1275.8958023057692
reward_std: 273.088495186218
reward_max: 1723.333974719452
reward_min: 891.6008910837147
total_envstep_count: 16570986
total_train_sample_count: 12452450
total_episode_count: 38155
total_duration: 3381.0893373034764
[2023-06-29 13:03:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2430
train_sample_count: 2430
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 2541.3407934019306
avg_train_sample_per_sec: 2541.3407934019306
avg_episode_per_sec: 12.549831078528053
collect_time: 0.9561881689811126
reward_mean: 1261.4401000561627
reward_std: 496.9106268486994
reward_max: 2061.1195980086936
reward_min: 544.4122974004844
total_envstep_count: 16575490
total_train_sample_count: 12455680
total_episode_count: 38167
total_duration: 3382.0455254724575
[2023-06-29 13:03:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2549
train_sample_count: 2549
avg_envstep_per_episode: 196.07692307692307
avg_sample_per_episode: 196.07692307692307
avg_envstep_per_sec: 2493.453721817048
avg_train_sample_per_sec: 2493.453721817048
avg_episode_per_sec: 12.716711802126962
collect_time: 1.0222768434388563
reward_mean: 1197.3777894218113
reward_std: 434.41358156954345
reward_max: 2247.682406114399
reward_min: 439.06738693079865
total_envstep_count: 16579946
total_train_sample_count: 12459029
total_episode_count: 38180
total_duration: 3383.067802315896
[2023-06-29 13:03:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3007
train_sample_count: 3007
avg_envstep_per_episode: 214.78571428571428
avg_sample_per_episode: 214.78571428571428
avg_envstep_per_sec: 2534.162132670648
avg_train_sample_per_sec: 2534.162132670648
avg_episode_per_sec: 11.798559979178277
collect_time: 1.1865854837121441
reward_mean: 1387.1567000261089
reward_std: 820.9358545096379
reward_max: 3675.8215940301975
reward_min: 512.9330239992433
total_envstep_count: 16584986
total_train_sample_count: 12462436
total_episode_count: 38194
total_duration: 3384.254387799608
[2023-06-29 13:03:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3392
train_sample_count: 3392
avg_envstep_per_episode: 226.13333333333333
avg_sample_per_episode: 226.13333333333333
avg_envstep_per_sec: 2758.33508316954
avg_train_sample_per_sec: 2758.33508316954
avg_episode_per_sec: 12.197826134299264
collect_time: 1.2297273165602236
reward_mean: 1341.2953434942772
reward_std: 553.7001286105788
reward_max: 2816.626060812698
reward_min: 866.3242824549602
total_envstep_count: 16589362
total_train_sample_count: 12465828
total_episode_count: 38209
total_duration: 3385.484115116168
[2023-06-29 13:03:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2857
train_sample_count: 2857
avg_envstep_per_episode: 204.07142857142858
avg_sample_per_episode: 204.07142857142858
avg_envstep_per_sec: 2604.148684178671
avg_train_sample_per_sec: 2604.148684178671
avg_episode_per_sec: 12.760966600805526
collect_time: 1.0970955757470802
reward_mean: 981.240913907505
reward_std: 205.15794354969088
reward_max: 1532.0259508058741
reward_min: 675.8638745971657
total_envstep_count: 16593778
total_train_sample_count: 12469085
total_episode_count: 38223
total_duration: 3386.581210691915
[2023-06-29 13:03:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3401
train_sample_count: 3401
avg_envstep_per_episode: 200.05882352941177
avg_sample_per_episode: 200.05882352941177
avg_envstep_per_sec: 2622.621983188663
avg_train_sample_per_sec: 2622.621983188663
avg_episode_per_sec: 13.109254252927748
collect_time: 1.2967938276277855
reward_mean: 1062.149769492375
reward_std: 283.99713255676625
reward_max: 1721.6092868942578
reward_min: 494.60296911940566
total_envstep_count: 16598474
total_train_sample_count: 12472486
total_episode_count: 38240
total_duration: 3387.878004519543
[2023-06-29 13:03:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3009
train_sample_count: 3009
avg_envstep_per_episode: 214.92857142857142
avg_sample_per_episode: 214.92857142857142
avg_envstep_per_sec: 2615.4416622858
avg_train_sample_per_sec: 2615.4416622858
avg_episode_per_sec: 12.168887760718244
collect_time: 1.1504749057833104
reward_mean: 1120.4431667743208
reward_std: 625.4544160476207
reward_max: 2664.03753788886
reward_min: 19.369200737405194
total_envstep_count: 16603210
total_train_sample_count: 12475895
total_episode_count: 38254
total_duration: 3389.028479425326
[2023-06-29 13:03:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3392
train_sample_count: 3392
avg_envstep_per_episode: 226.13333333333333
avg_sample_per_episode: 226.13333333333333
avg_envstep_per_sec: 2605.0957308495717
avg_train_sample_per_sec: 2605.0957308495717
avg_episode_per_sec: 11.520175696563555
collect_time: 1.3020634749932216
reward_mean: 1251.4129600459953
reward_std: 426.7604441106699
reward_max: 2238.863016366974
reward_min: 657.6331802817319
total_envstep_count: 16607794
total_train_sample_count: 12479287
total_episode_count: 38269
total_duration: 3390.3305429003194
[2023-06-29 13:03:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3333
train_sample_count: 3333
avg_envstep_per_episode: 196.05882352941177
avg_sample_per_episode: 196.05882352941177
avg_envstep_per_sec: 2771.792801122999
avg_train_sample_per_sec: 2771.792801122999
avg_episode_per_sec: 14.13755704143144
collect_time: 1.20247083355207
reward_mean: 964.185639085733
reward_std: 223.12754024151062
reward_max: 1325.087781041671
reward_min: 495.09568434710457
total_envstep_count: 16611802
total_train_sample_count: 12482620
total_episode_count: 38286
total_duration: 3391.5330137338715
[2023-06-29 13:03:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2894
train_sample_count: 2894
avg_envstep_per_episode: 222.6153846153846
avg_sample_per_episode: 222.6153846153846
avg_envstep_per_sec: 2632.6857776029833
avg_train_sample_per_sec: 2632.6857776029833
avg_episode_per_sec: 11.826162788126739
collect_time: 1.099257657187991
reward_mean: 1001.1491077157472
reward_std: 257.16514735655466
reward_max: 1664.346261093852
reward_min: 681.0951395439313
total_envstep_count: 16615954
total_train_sample_count: 12485914
total_episode_count: 38299
total_duration: 3392.6322713910595
[2023-06-29 13:03:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3336
train_sample_count: 3336
avg_envstep_per_episode: 238.28571428571428
avg_sample_per_episode: 238.28571428571428
avg_envstep_per_sec: 2607.4641514289
avg_train_sample_per_sec: 2607.4641514289
avg_episode_per_sec: 10.942595359713609
collect_time: 1.2794039749968795
reward_mean: 1211.5357873578046
reward_std: 478.484490161689
reward_max: 2411.454447467397
reward_min: 484.2136805257549
total_envstep_count: 16620034
total_train_sample_count: 12489250
total_episode_count: 38313
total_duration: 3393.9116753660564
[2023-06-29 13:03:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3507
train_sample_count: 3507
avg_envstep_per_episode: 233.8
avg_sample_per_episode: 233.8
avg_envstep_per_sec: 2584.1043218534014
avg_train_sample_per_sec: 2584.1043218534014
avg_episode_per_sec: 11.052627552837473
collect_time: 1.3571433515055107
reward_mean: 1032.7054776967564
reward_std: 231.65778957105238
reward_max: 1525.3523963779444
reward_min: 561.579012881724
total_envstep_count: 16624498
total_train_sample_count: 12492757
total_episode_count: 38328
total_duration: 3395.2688187175618
[2023-06-29 13:03:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3313
train_sample_count: 3313
avg_envstep_per_episode: 220.86666666666667
avg_sample_per_episode: 220.86666666666667
avg_envstep_per_sec: 2740.459052938462
avg_train_sample_per_sec: 2740.459052938462
avg_episode_per_sec: 12.407753031716549
collect_time: 1.2089215478142723
reward_mean: 1050.8211037824133
reward_std: 315.5624519150328
reward_max: 1494.736670551383
reward_min: 332.35417902752096
total_envstep_count: 16629130
total_train_sample_count: 12496070
total_episode_count: 38343
total_duration: 3396.4777402653763
[2023-06-29 13:04:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3032
train_sample_count: 3032
avg_envstep_per_episode: 216.57142857142858
avg_sample_per_episode: 216.57142857142858
avg_envstep_per_sec: 2768.013426055951
avg_train_sample_per_sec: 2768.013426055951
avg_episode_per_sec: 12.781064632184473
collect_time: 1.0953704094998535
reward_mean: 1139.8210288249068
reward_std: 203.97494606647885
reward_max: 1577.0185820592576
reward_min: 918.2035102412625
total_envstep_count: 16633474
total_train_sample_count: 12499502
total_episode_count: 38357
total_duration: 3397.5731106748763
[2023-06-29 13:04:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3280
train_sample_count: 3280
avg_envstep_per_episode: 218.66666666666666
avg_sample_per_episode: 218.66666666666666
avg_envstep_per_sec: 2605.139857095752
avg_train_sample_per_sec: 2605.139857095752
avg_episode_per_sec: 11.913749346474475
collect_time: 1.2590494867544624
reward_mean: 1141.451632911111
reward_std: 225.3760468856514
reward_max: 1592.1917338588491
reward_min: 801.8943813442982
total_envstep_count: 16638298
total_train_sample_count: 12502782
total_episode_count: 38372
total_duration: 3398.832160161631
[2023-06-29 13:04:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3310
train_sample_count: 3310
avg_envstep_per_episode: 220.66666666666666
avg_sample_per_episode: 220.66666666666666
avg_envstep_per_sec: 2568.917669538283
avg_train_sample_per_sec: 2568.917669538283
avg_episode_per_sec: 11.641620858934818
collect_time: 1.2884803741471844
reward_mean: 1203.1656272183002
reward_std: 328.72793316997246
reward_max: 1898.8442311584538
reward_min: 591.8774825292536
total_envstep_count: 16643106
total_train_sample_count: 12506092
total_episode_count: 38387
total_duration: 3400.120640535778
[2023-06-29 13:04:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 226.30769230769232
avg_sample_per_episode: 226.30769230769232
avg_envstep_per_sec: 2680.231120977479
avg_train_sample_per_sec: 2680.231120977479
avg_episode_per_sec: 11.84330542920028
collect_time: 1.0976665321784094
reward_mean: 1258.7114660186967
reward_std: 405.8803868770747
reward_max: 2403.4710471758744
reward_min: 885.4035363945005
total_envstep_count: 16647570
total_train_sample_count: 12509434
total_episode_count: 38400
total_duration: 3401.218307067956
[2023-06-29 13:04:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2273
train_sample_count: 2273
avg_envstep_per_episode: 189.41666666666666
avg_sample_per_episode: 189.41666666666666
avg_envstep_per_sec: 2775.905663159421
avg_train_sample_per_sec: 2775.905663159421
avg_episode_per_sec: 14.655023298685899
collect_time: 0.8188318609548733
reward_mean: 1176.986965990251
reward_std: 339.95958069804686
reward_max: 2096.4699230363003
reward_min: 823.6900195312709
total_envstep_count: 16652010
total_train_sample_count: 12512907
total_episode_count: 38412
total_duration: 3402.037138928911
[2023-06-29 13:04:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2917
train_sample_count: 2917
avg_envstep_per_episode: 265.1818181818182
avg_sample_per_episode: 265.1818181818182
avg_envstep_per_sec: 2612.3442297455663
avg_train_sample_per_sec: 2612.3442297455663
avg_episode_per_sec: 9.851143821460827
collect_time: 1.1166216024616733
reward_mean: 1735.223105611995
reward_std: 606.6277949932847
reward_max: 3274.8281960977174
reward_min: 1019.0873097697062
total_envstep_count: 16656530
total_train_sample_count: 12516224
total_episode_count: 38423
total_duration: 3403.153760531373
[2023-06-29 13:04:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2339
train_sample_count: 2339
avg_envstep_per_episode: 212.63636363636363
avg_sample_per_episode: 212.63636363636363
avg_envstep_per_sec: 2548.1673004425293
avg_train_sample_per_sec: 2548.1673004425293
avg_episode_per_sec: 11.983685465954606
collect_time: 0.9179146124329418
reward_mean: 1309.3597845198713
reward_std: 335.9779975239897
reward_max: 1946.683455208121
reward_min: 690.4444545066102
total_envstep_count: 16661130
total_train_sample_count: 12519763
total_episode_count: 38434
total_duration: 3404.071675143806
[2023-06-29 13:04:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3182
train_sample_count: 3182
avg_envstep_per_episode: 244.76923076923077
avg_sample_per_episode: 244.76923076923077
avg_envstep_per_sec: 2565.8074334750336
avg_train_sample_per_sec: 2565.8074334750336
avg_episode_per_sec: 10.482557082079017
collect_time: 1.2401554218316448
reward_mean: 1600.2498915409158
reward_std: 607.769384289874
reward_max: 3062.4146113065244
reward_min: 853.3191733961755
total_envstep_count: 16666050
total_train_sample_count: 12523345
total_episode_count: 38447
total_duration: 3405.3118305656376
[2023-06-29 13:04:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1772
train_sample_count: 1772
avg_envstep_per_episode: 177.2
avg_sample_per_episode: 177.2
avg_envstep_per_sec: 2816.8572421083095
avg_train_sample_per_sec: 2816.8572421083095
avg_episode_per_sec: 15.896485564945312
collect_time: 0.6290698632188141
reward_mean: 1294.1254879702967
reward_std: 405.591572011993
reward_max: 2227.02021294822
reward_min: 803.0164597147078
total_envstep_count: 16670330
total_train_sample_count: 12526717
total_episode_count: 38457
total_duration: 3405.9409004288564
[2023-06-29 13:04:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2679
train_sample_count: 2679
avg_envstep_per_episode: 243.54545454545453
avg_sample_per_episode: 243.54545454545453
avg_envstep_per_sec: 2804.4118732671354
avg_train_sample_per_sec: 2804.4118732671354
avg_episode_per_sec: 11.514942368771365
collect_time: 0.9552805083794519
reward_mean: 1772.5361900056087
reward_std: 710.2531066875694
reward_max: 3414.401413197962
reward_min: 742.2216503868849
total_envstep_count: 16675002
total_train_sample_count: 12530196
total_episode_count: 38468
total_duration: 3406.896180937236
[2023-06-29 13:04:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3042
train_sample_count: 3042
avg_envstep_per_episode: 253.5
avg_sample_per_episode: 253.5
avg_envstep_per_sec: 2571.126302904116
avg_train_sample_per_sec: 2571.126302904116
avg_episode_per_sec: 10.142510070627678
collect_time: 1.1831390766622498
reward_mean: 1569.7967405455872
reward_std: 616.872710089889
reward_max: 2992.7757241867653
reward_min: 865.5448198182485
total_envstep_count: 16679426
total_train_sample_count: 12533638
total_episode_count: 38480
total_duration: 3408.0793200138983
[2023-06-29 13:04:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2561
train_sample_count: 2561
avg_envstep_per_episode: 256.1
avg_sample_per_episode: 256.1
avg_envstep_per_sec: 2566.3131756076277
avg_train_sample_per_sec: 2566.3131756076277
avg_episode_per_sec: 10.020746488120373
collect_time: 0.9979296464445071
reward_mean: 1406.5684340383023
reward_std: 234.59244526968774
reward_max: 2075.623037089423
reward_min: 1132.022005707012
total_envstep_count: 16683906
total_train_sample_count: 12536999
total_episode_count: 38490
total_duration: 3409.0772496603427
[2023-06-29 13:04:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1810
train_sample_count: 1810
avg_envstep_per_episode: 258.57142857142856
avg_sample_per_episode: 258.57142857142856
avg_envstep_per_sec: 2678.2445191183638
avg_train_sample_per_sec: 2678.2445191183638
avg_episode_per_sec: 10.357851731396988
collect_time: 0.6758158140825109
reward_mean: 1914.971817366161
reward_std: 1037.0848576873348
reward_max: 3564.4825354185623
reward_min: 895.1276745545074
total_envstep_count: 16688498
total_train_sample_count: 12540409
total_episode_count: 38497
total_duration: 3409.753065474425
[2023-06-29 13:04:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1490
train_sample_count: 1490
avg_envstep_per_episode: 165.55555555555554
avg_sample_per_episode: 165.55555555555554
avg_envstep_per_sec: 2731.206874414335
avg_train_sample_per_sec: 2731.206874414335
avg_episode_per_sec: 16.497222731361752
collect_time: 0.5455463714441285
reward_mean: 1823.4202002367265
reward_std: 976.5269804700993
reward_max: 3386.5900600019745
reward_min: 599.6360420036899
total_envstep_count: 16692986
total_train_sample_count: 12543899
total_episode_count: 38506
total_duration: 3410.2986118458693
[2023-06-29 13:04:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2582
train_sample_count: 2582
avg_envstep_per_episode: 286.8888888888889
avg_sample_per_episode: 286.8888888888889
avg_envstep_per_sec: 2743.0626179966057
avg_train_sample_per_sec: 2743.0626179966057
avg_episode_per_sec: 9.561411139414968
collect_time: 0.9412836524620654
reward_mean: 2384.970893026548
reward_std: 1236.4194948258028
reward_max: 3596.9754849200976
reward_min: 61.76963993623135
total_envstep_count: 16697778
total_train_sample_count: 12547281
total_episode_count: 38515
total_duration: 3411.2398954983314
[2023-06-29 13:04:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 290.57142857142856
avg_sample_per_episode: 290.57142857142856
avg_envstep_per_sec: 2568.3067561112275
avg_train_sample_per_sec: 2568.3067561112275
avg_episode_per_sec: 8.838813811592228
collect_time: 0.7919614723436533
reward_mean: 1998.5220473922927
reward_std: 1016.6707703223063
reward_max: 3578.979559835609
reward_min: 850.3306907463792
total_envstep_count: 16702018
total_train_sample_count: 12550515
total_episode_count: 38522
total_duration: 3412.031856970675
[2023-06-29 13:04:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2108
train_sample_count: 2108
avg_envstep_per_episode: 301.14285714285717
avg_sample_per_episode: 301.14285714285717
avg_envstep_per_sec: 2492.0468292966493
avg_train_sample_per_sec: 2492.0468292966493
avg_episode_per_sec: 8.27529782024504
collect_time: 0.8458910062275828
reward_mean: 2374.55796222665
reward_std: 870.4866102825681
reward_max: 3592.9040771446616
reward_min: 1182.077326794601
total_envstep_count: 16706450
total_train_sample_count: 12553823
total_episode_count: 38529
total_duration: 3412.877747976903
[2023-06-29 13:04:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2200
train_sample_count: 2200
avg_envstep_per_episode: 314.2857142857143
avg_sample_per_episode: 314.2857142857143
avg_envstep_per_sec: 2463.6914426593976
avg_train_sample_per_sec: 2463.6914426593976
avg_episode_per_sec: 7.839018226643538
collect_time: 0.892968965961598
reward_mean: 2307.551214676086
reward_std: 1129.6733952179768
reward_max: 3603.719694339119
reward_min: 817.1623713107019
total_envstep_count: 16710666
total_train_sample_count: 12557223
total_episode_count: 38536
total_duration: 3413.7707169428645
[2023-06-29 13:04:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2917
train_sample_count: 2917
avg_envstep_per_episode: 291.7
avg_sample_per_episode: 291.7
avg_envstep_per_sec: 2806.8339107430543
avg_train_sample_per_sec: 2806.8339107430543
avg_episode_per_sec: 9.622330856164053
collect_time: 1.0392492369553072
reward_mean: 1875.143995910978
reward_std: 876.9922051888125
reward_max: 3485.6765246352475
reward_min: 1160.0733504333884
total_envstep_count: 16715314
total_train_sample_count: 12560540
total_episode_count: 38546
total_duration: 3414.8099661798196
[2023-06-29 13:04:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1967
train_sample_count: 1967
avg_envstep_per_episode: 245.875
avg_sample_per_episode: 245.875
avg_envstep_per_sec: 2638.601545281103
avg_train_sample_per_sec: 2638.601545281103
avg_episode_per_sec: 10.731475527325278
collect_time: 0.7454706465695055
reward_mean: 1687.6419023974768
reward_std: 871.1684143608003
reward_max: 3585.790130098328
reward_min: 855.8309257585946
total_envstep_count: 16720114
total_train_sample_count: 12564107
total_episode_count: 38554
total_duration: 3415.5554368263893
[2023-06-29 13:05:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3158
train_sample_count: 3158
avg_envstep_per_episode: 287.09090909090907
avg_sample_per_episode: 287.09090909090907
avg_envstep_per_sec: 2571.9905872741897
avg_train_sample_per_sec: 2571.9905872741897
avg_episode_per_sec: 8.958801918941129
collect_time: 1.2278427516901866
reward_mean: 2085.5011026760376
reward_std: 938.6501728140485
reward_max: 3621.523147144904
reward_min: 944.9807980428616
total_envstep_count: 16724858
total_train_sample_count: 12567665
total_episode_count: 38565
total_duration: 3416.7832795780796
[2023-06-29 13:05:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1697
train_sample_count: 1697
avg_envstep_per_episode: 242.42857142857142
avg_sample_per_episode: 242.42857142857142
avg_envstep_per_sec: 2728.1851581253827
avg_train_sample_per_sec: 2728.1851581253827
avg_episode_per_sec: 11.253562820788261
collect_time: 0.6220252298293637
reward_mean: 1534.1129657374343
reward_std: 255.68408476025826
reward_max: 1974.8792954033213
reward_min: 1276.8380752705211
total_envstep_count: 16729546
total_train_sample_count: 12570962
total_episode_count: 38572
total_duration: 3417.405304807909
[2023-06-29 13:05:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1667
train_sample_count: 1667
avg_envstep_per_episode: 238.14285714285714
avg_sample_per_episode: 238.14285714285714
avg_envstep_per_sec: 2851.4444078084753
avg_train_sample_per_sec: 2851.4444078084753
avg_episode_per_sec: 11.973671778439908
collect_time: 0.5846159916128965
reward_mean: 2018.315021092612
reward_std: 1036.8487488070584
reward_max: 3626.1575628443
reward_min: 1008.9059239856658
total_envstep_count: 16733330
total_train_sample_count: 12574229
total_episode_count: 38579
total_duration: 3417.9899207995218
[2023-06-29 13:05:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2192
train_sample_count: 2192
avg_envstep_per_episode: 243.55555555555554
avg_sample_per_episode: 243.55555555555554
avg_envstep_per_sec: 2770.9837635619156
avg_train_sample_per_sec: 2770.9837635619156
avg_episode_per_sec: 11.377214357690347
collect_time: 0.7910547975143418
reward_mean: 2279.2867801046114
reward_std: 1205.5356528113614
reward_max: 3683.337647061059
reward_min: 634.2860657008243
total_envstep_count: 16737898
total_train_sample_count: 12577621
total_episode_count: 38588
total_duration: 3418.780975597036
[2023-06-29 13:05:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2270
train_sample_count: 2270
avg_envstep_per_episode: 324.2857142857143
avg_sample_per_episode: 324.2857142857143
avg_envstep_per_sec: 2571.5113945216344
avg_train_sample_per_sec: 2571.5113945216344
avg_episode_per_sec: 7.929770820110767
collect_time: 0.8827493453212082
reward_mean: 2252.137800383374
reward_std: 718.3817142286746
reward_max: 3631.5972913751834
reward_min: 1103.720483794404
total_envstep_count: 16742298
total_train_sample_count: 12581091
total_episode_count: 38595
total_duration: 3419.6637249423575
[2023-06-29 13:05:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1793
train_sample_count: 1793
avg_envstep_per_episode: 256.14285714285717
avg_sample_per_episode: 256.14285714285717
avg_envstep_per_sec: 2741.158979006878
avg_train_sample_per_sec: 2741.158979006878
avg_episode_per_sec: 10.70168034191196
collect_time: 0.654102886308916
reward_mean: 1924.871315973842
reward_std: 1015.6918467343379
reward_max: 3626.1554100973476
reward_min: 736.9078104326297
total_envstep_count: 16746162
total_train_sample_count: 12584484
total_episode_count: 38602
total_duration: 3420.3178278286664
[2023-06-29 13:05:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3288
train_sample_count: 3288
avg_envstep_per_episode: 298.90909090909093
avg_sample_per_episode: 298.90909090909093
avg_envstep_per_sec: 2797.3390712832233
avg_train_sample_per_sec: 2797.3390712832233
avg_episode_per_sec: 9.35849445988913
collect_time: 1.1754027367485687
reward_mean: 2054.4394163157344
reward_std: 1043.9936296656597
reward_max: 3614.296488960293
reward_min: 1024.2454933586225
total_envstep_count: 16750826
total_train_sample_count: 12587772
total_episode_count: 38613
total_duration: 3421.493230565415
[2023-06-29 13:05:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2500
train_sample_count: 2500
avg_envstep_per_episode: 192.30769230769232
avg_sample_per_episode: 192.30769230769232
avg_envstep_per_sec: 2691.8188133145795
avg_train_sample_per_sec: 2691.8188133145795
avg_episode_per_sec: 13.997457829235815
collect_time: 0.9287400725614281
reward_mean: 1031.4101347790065
reward_std: 382.4144202341691
reward_max: 1697.082018157819
reward_min: 50.532491437267446
total_envstep_count: 16755706
total_train_sample_count: 12591072
total_episode_count: 38626
total_duration: 3422.4219706379768
[2023-06-29 13:05:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 173.84615384615384
avg_sample_per_episode: 173.84615384615384
avg_envstep_per_sec: 2617.3834940381616
avg_train_sample_per_sec: 2617.3834940381616
avg_episode_per_sec: 15.055745762166417
collect_time: 0.8634577260641382
reward_mean: 1407.7645885376796
reward_std: 648.8508525377582
reward_max: 3441.684338841218
reward_min: 917.1405270845438
total_envstep_count: 16760090
total_train_sample_count: 12594532
total_episode_count: 38639
total_duration: 3423.285428364041
[2023-06-29 13:05:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3032
train_sample_count: 3032
avg_envstep_per_episode: 252.66666666666666
avg_sample_per_episode: 252.66666666666666
avg_envstep_per_sec: 2602.673013381987
avg_train_sample_per_sec: 2602.673013381987
avg_episode_per_sec: 10.300816675654302
collect_time: 1.1649561755973845
reward_mean: 1620.5412983812357
reward_std: 711.1743919488106
reward_max: 3725.258936883545
reward_min: 1124.6636247832728
total_envstep_count: 16764370
total_train_sample_count: 12597964
total_episode_count: 38651
total_duration: 3424.4503845396384
[2023-06-29 13:05:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2621
train_sample_count: 2621
avg_envstep_per_episode: 218.41666666666666
avg_sample_per_episode: 218.41666666666666
avg_envstep_per_sec: 2741.1715669815844
avg_train_sample_per_sec: 2741.1715669815844
avg_episode_per_sec: 12.550194125821829
collect_time: 0.9561605087295173
reward_mean: 1202.6748992025832
reward_std: 318.10058250412715
reward_max: 1845.0533393464477
reward_min: 851.9798005733596
total_envstep_count: 16769050
total_train_sample_count: 12601385
total_episode_count: 38663
total_duration: 3425.406545048368
[2023-06-29 13:05:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3030
train_sample_count: 3030
avg_envstep_per_episode: 275.45454545454544
avg_sample_per_episode: 275.45454545454544
avg_envstep_per_sec: 2796.14669933395
avg_train_sample_per_sec: 2796.14669933395
avg_episode_per_sec: 10.151027621344372
collect_time: 1.0836341314716265
reward_mean: 1670.9517335008168
reward_std: 796.9566590949167
reward_max: 3765.2830587167664
reward_min: 894.8144900252878
total_envstep_count: 16773754
total_train_sample_count: 12604815
total_episode_count: 38674
total_duration: 3426.4901791798397
[2023-06-29 13:05:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3104
train_sample_count: 3104
avg_envstep_per_episode: 258.6666666666667
avg_sample_per_episode: 258.6666666666667
avg_envstep_per_sec: 2767.6498876789865
avg_train_sample_per_sec: 2767.6498876789865
avg_episode_per_sec: 10.699677400820823
collect_time: 1.1215291405962784
reward_mean: 1521.4227248922437
reward_std: 837.1601827768333
reward_max: 3577.912213126786
reward_min: 58.069487026025925
total_envstep_count: 16778338
total_train_sample_count: 12608319
total_episode_count: 38686
total_duration: 3427.611708320436
[2023-06-29 13:05:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2493
train_sample_count: 2493
avg_envstep_per_episode: 249.3
avg_sample_per_episode: 249.3
avg_envstep_per_sec: 2530.1530275156497
avg_train_sample_per_sec: 2530.1530275156497
avg_episode_per_sec: 10.149029392361209
collect_time: 0.9853158970577641
reward_mean: 1396.4929459504851
reward_std: 546.3049484727532
reward_max: 2511.736299621697
reward_min: 444.22422977212557
total_envstep_count: 16782490
total_train_sample_count: 12611612
total_episode_count: 38696
total_duration: 3428.5970242174935
[2023-06-29 13:05:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3463
train_sample_count: 3463
avg_envstep_per_episode: 230.86666666666667
avg_sample_per_episode: 230.86666666666667
avg_envstep_per_sec: 2631.6972218698547
avg_train_sample_per_sec: 2631.6972218698547
avg_episode_per_sec: 11.399208295711182
collect_time: 1.3158808586420492
reward_mean: 1332.708174180262
reward_std: 767.4376296844669
reward_max: 3061.2854401736204
reward_min: 61.7403852028974
total_envstep_count: 16786954
total_train_sample_count: 12615075
total_episode_count: 38711
total_duration: 3429.9129050761358
[2023-06-29 13:05:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3498
train_sample_count: 3498
avg_envstep_per_episode: 249.85714285714286
avg_sample_per_episode: 249.85714285714286
avg_envstep_per_sec: 2618.4293072607175
avg_train_sample_per_sec: 2618.4293072607175
avg_episode_per_sec: 10.479705632261306
collect_time: 1.3359153864877298
reward_mean: 1189.3689212190131
reward_std: 449.39676168548226
reward_max: 2389.4937463479982
reward_min: 761.0109819781818
total_envstep_count: 16791682
total_train_sample_count: 12618573
total_episode_count: 38725
total_duration: 3431.2488204626234
[2023-06-29 13:05:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3101
train_sample_count: 3101
avg_envstep_per_episode: 238.53846153846155
avg_sample_per_episode: 238.53846153846155
avg_envstep_per_sec: 2778.035102953305
avg_train_sample_per_sec: 2778.035102953305
avg_episode_per_sec: 11.646067829214113
collect_time: 1.1162565932674335
reward_mean: 1248.6303117466198
reward_std: 503.44883664112456
reward_max: 2121.207986621856
reward_min: 64.64109259596891
total_envstep_count: 16796346
total_train_sample_count: 12622074
total_episode_count: 38738
total_duration: 3432.3650770558907
[2023-06-29 13:05:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2625
train_sample_count: 2625
avg_envstep_per_episode: 218.75
avg_sample_per_episode: 218.75
avg_envstep_per_sec: 2653.977618063754
avg_train_sample_per_sec: 2653.977618063754
avg_episode_per_sec: 12.132469111148591
collect_time: 0.9890814384166151
reward_mean: 1280.905386585416
reward_std: 798.2986949152561
reward_max: 3100.3649592557517
reward_min: 51.444745404622836
total_envstep_count: 16800938
total_train_sample_count: 12625499
total_episode_count: 38750
total_duration: 3433.3541584943073
[2023-06-29 13:05:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2518
train_sample_count: 2518
avg_envstep_per_episode: 314.75
avg_sample_per_episode: 314.75
avg_envstep_per_sec: 2526.5271948475806
avg_train_sample_per_sec: 2526.5271948475806
avg_episode_per_sec: 8.027091961390248
collect_time: 0.9966249344693497
reward_mean: 2072.451913135189
reward_std: 923.6578044708829
reward_max: 3616.4312726344183
reward_min: 745.8139657562948
total_envstep_count: 16805082
total_train_sample_count: 12628817
total_episode_count: 38758
total_duration: 3434.3507834287766
[2023-06-29 13:06:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2991
train_sample_count: 2991
avg_envstep_per_episode: 213.64285714285714
avg_sample_per_episode: 213.64285714285714
avg_envstep_per_sec: 2737.331851374456
avg_train_sample_per_sec: 2737.331851374456
avg_episode_per_sec: 12.812653266212768
collect_time: 1.0926698560491206
reward_mean: 1240.3067105747468
reward_std: 670.508657303489
reward_max: 3227.1107933152934
reward_min: 545.7245846185862
total_envstep_count: 16809530
total_train_sample_count: 12632208
total_episode_count: 38772
total_duration: 3435.443453284826
[2023-06-29 13:06:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 244.33333333333334
avg_sample_per_episode: 244.33333333333334
avg_envstep_per_sec: 2722.263254174314
avg_train_sample_per_sec: 2722.263254174314
avg_episode_per_sec: 11.14159585610224
collect_time: 0.8077837426736951
reward_mean: 1406.575997611114
reward_std: 361.79709949262815
reward_max: 2108.2518787266426
reward_min: 893.5619864585144
total_envstep_count: 16813722
total_train_sample_count: 12635607
total_episode_count: 38781
total_duration: 3436.2512370274994
[2023-06-29 13:06:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3274
train_sample_count: 3274
avg_envstep_per_episode: 272.8333333333333
avg_sample_per_episode: 272.8333333333333
avg_envstep_per_sec: 2592.688637208922
avg_train_sample_per_sec: 2592.688637208922
avg_episode_per_sec: 9.502829458310037
collect_time: 1.2627817906914278
reward_mean: 1714.864845324282
reward_std: 807.013218299654
reward_max: 3130.4128733277876
reward_min: 894.6443199463907
total_envstep_count: 16818234
total_train_sample_count: 12638881
total_episode_count: 38793
total_duration: 3437.514018818191
[2023-06-29 13:06:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3310
train_sample_count: 3310
avg_envstep_per_episode: 236.42857142857142
avg_sample_per_episode: 236.42857142857142
avg_envstep_per_sec: 2576.805576302749
avg_train_sample_per_sec: 2576.805576302749
avg_episode_per_sec: 10.898875549316765
collect_time: 1.284536183265038
reward_mean: 1201.2240077792947
reward_std: 339.146404798385
reward_max: 2004.2774992420357
reward_min: 562.7896679814204
total_envstep_count: 16822850
total_train_sample_count: 12642191
total_episode_count: 38807
total_duration: 3438.798555001456
[2023-06-29 13:06:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1934
train_sample_count: 1934
avg_envstep_per_episode: 214.88888888888889
avg_sample_per_episode: 214.88888888888889
avg_envstep_per_sec: 2717.1338762520527
avg_train_sample_per_sec: 2717.1338762520527
avg_episode_per_sec: 12.644366538918549
collect_time: 0.7117794293845071
reward_mean: 1228.2067295547067
reward_std: 662.606579536996
reward_max: 2572.6866587743175
reward_min: 270.3889206330041
total_envstep_count: 16827722
total_train_sample_count: 12645725
total_episode_count: 38816
total_duration: 3439.5103344308404
[2023-06-29 13:06:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2472
train_sample_count: 2472
avg_envstep_per_episode: 224.72727272727272
avg_sample_per_episode: 224.72727272727272
avg_envstep_per_sec: 2727.194749033704
avg_train_sample_per_sec: 2727.194749033704
avg_episode_per_sec: 12.13557533955127
collect_time: 0.9064259165488185
reward_mean: 1796.3814735516078
reward_std: 794.8472057413059
reward_max: 3618.23308556548
reward_min: 1136.8248830530292
total_envstep_count: 16832098
total_train_sample_count: 12648997
total_episode_count: 38827
total_duration: 3440.4167603473893
[2023-06-29 13:06:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2565
train_sample_count: 2565
avg_envstep_per_episode: 197.30769230769232
avg_sample_per_episode: 197.30769230769232
avg_envstep_per_sec: 2757.66093451645
avg_train_sample_per_sec: 2757.66093451645
avg_episode_per_sec: 13.976449180785128
collect_time: 0.9301361048035324
reward_mean: 1354.7168407870379
reward_std: 807.4573761220568
reward_max: 3842.4086514501423
reward_min: 61.64019957764371
total_envstep_count: 16836114
total_train_sample_count: 12652362
total_episode_count: 38840
total_duration: 3441.346896452193
[2023-06-29 13:06:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3045
train_sample_count: 3045
avg_envstep_per_episode: 253.75
avg_sample_per_episode: 253.75
avg_envstep_per_sec: 2560.1774819525635
avg_train_sample_per_sec: 2560.1774819525635
avg_episode_per_sec: 10.089369387005176
collect_time: 1.1893706672545523
reward_mean: 1437.4352318146382
reward_std: 831.140298791752
reward_max: 3250.156563310193
reward_min: 620.2307503498267
total_envstep_count: 16841042
total_train_sample_count: 12655807
total_episode_count: 38852
total_duration: 3442.5362671194475
[2023-06-29 13:06:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 217.42857142857142
avg_sample_per_episode: 217.42857142857142
avg_envstep_per_sec: 2732.574898645598
avg_train_sample_per_sec: 2732.574898645598
avg_episode_per_sec: 12.567690072614443
collect_time: 1.1139676359863953
reward_mean: 1295.6813891097734
reward_std: 499.44754406319663
reward_max: 2366.419031294233
reward_min: 442.0499642719344
total_envstep_count: 16845250
total_train_sample_count: 12659251
total_episode_count: 38866
total_duration: 3443.6502347554338
[2023-06-29 13:06:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2467
train_sample_count: 2467
avg_envstep_per_episode: 352.42857142857144
avg_sample_per_episode: 352.42857142857144
avg_envstep_per_sec: 2814.60081332335
avg_train_sample_per_sec: 2814.60081332335
avg_episode_per_sec: 7.9863014565315975
collect_time: 0.8765008481210097
reward_mean: 1913.1407985044832
reward_std: 818.7655930388916
reward_max: 3556.4325239979567
reward_min: 988.577733609772
total_envstep_count: 16849810
total_train_sample_count: 12662518
total_episode_count: 38873
total_duration: 3444.5267356035547
[2023-06-29 13:06:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3151
train_sample_count: 3151
avg_envstep_per_episode: 350.1111111111111
avg_sample_per_episode: 350.1111111111111
avg_envstep_per_sec: 2782.925168510022
avg_train_sample_per_sec: 2782.925168510022
avg_episode_per_sec: 7.948691373084798
collect_time: 1.132261850104667
reward_mean: 2177.831234617009
reward_std: 1068.8955817016224
reward_max: 3733.895552512596
reward_min: 736.3337956747231
total_envstep_count: 16854578
total_train_sample_count: 12666069
total_episode_count: 38882
total_duration: 3445.658997453659
[2023-06-29 13:06:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2714
train_sample_count: 2714
avg_envstep_per_episode: 271.4
avg_sample_per_episode: 271.4
avg_envstep_per_sec: 2575.0692753946714
avg_train_sample_per_sec: 2575.0692753946714
avg_episode_per_sec: 9.488096077356932
collect_time: 1.0539522279780358
reward_mean: 1530.1268248341412
reward_std: 405.16609399657983
reward_max: 2211.5278013547404
reward_min: 869.9972266317296
total_envstep_count: 16859666
total_train_sample_count: 12669583
total_episode_count: 38892
total_duration: 3446.7129496816374
[2023-06-29 13:06:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2049
train_sample_count: 2049
avg_envstep_per_episode: 227.66666666666666
avg_sample_per_episode: 227.66666666666666
avg_envstep_per_sec: 2530.770659184734
avg_train_sample_per_sec: 2530.770659184734
avg_episode_per_sec: 11.1161229539593
collect_time: 0.809634801384993
reward_mean: 1790.221750835893
reward_std: 962.03383394187
reward_max: 3586.4419426391514
reward_min: 469.2148796879183
total_envstep_count: 16864266
total_train_sample_count: 12672832
total_episode_count: 38901
total_duration: 3447.5225844830225
[2023-06-29 13:06:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2352
train_sample_count: 2352
avg_envstep_per_episode: 180.92307692307693
avg_sample_per_episode: 180.92307692307693
avg_envstep_per_sec: 2741.6125217883277
avg_train_sample_per_sec: 2741.6125217883277
avg_episode_per_sec: 15.153470571108954
collect_time: 0.8578892827881501
reward_mean: 1447.8703633248772
reward_std: 711.8004228772513
reward_max: 2945.862896158816
reward_min: 67.82259840941558
total_envstep_count: 16868930
total_train_sample_count: 12676384
total_episode_count: 38914
total_duration: 3448.3804737658106
[2023-06-29 13:06:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 274.8888888888889
avg_sample_per_episode: 274.8888888888889
avg_envstep_per_sec: 2726.779719318544
avg_train_sample_per_sec: 2726.779719318544
avg_episode_per_sec: 9.91957052298581
collect_time: 0.9072973450962454
reward_mean: 1833.745523639621
reward_std: 952.9544344727091
reward_max: 3503.8274463442885
reward_min: 927.6141226665899
total_envstep_count: 16872834
total_train_sample_count: 12679658
total_episode_count: 38923
total_duration: 3449.2877711109068
[2023-06-29 13:06:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2258
train_sample_count: 2258
avg_envstep_per_episode: 250.88888888888889
avg_sample_per_episode: 250.88888888888889
avg_envstep_per_sec: 2676.910428738495
avg_train_sample_per_sec: 2676.910428738495
avg_episode_per_sec: 10.669704986114462
collect_time: 0.8435097326226533
reward_mean: 1577.964445227679
reward_std: 583.1829163172574
reward_max: 2997.9129913971765
reward_min: 972.572796542845
total_envstep_count: 16877866
total_train_sample_count: 12683116
total_episode_count: 38932
total_duration: 3450.1312808435296
[2023-06-29 13:06:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2846
train_sample_count: 2846
avg_envstep_per_episode: 218.92307692307693
avg_sample_per_episode: 218.92307692307693
avg_envstep_per_sec: 2779.7615954425723
avg_train_sample_per_sec: 2779.7615954425723
avg_episode_per_sec: 12.697435256765088
collect_time: 1.023828807717189
reward_mean: 1502.8446581445605
reward_std: 772.0099749122244
reward_max: 3075.6160943653213
reward_min: 432.13021246949035
total_envstep_count: 16881874
total_train_sample_count: 12686362
total_episode_count: 38945
total_duration: 3451.1551096512467
[2023-06-29 13:06:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2487
train_sample_count: 2487
avg_envstep_per_episode: 226.0909090909091
avg_sample_per_episode: 226.0909090909091
avg_envstep_per_sec: 2808.396615503414
avg_train_sample_per_sec: 2808.396615503414
avg_episode_per_sec: 12.421537101140954
collect_time: 0.8855586800919846
reward_mean: 1341.8529391607738
reward_std: 817.7209773238961
reward_max: 3551.6197196909584
reward_min: 62.43166702174686
total_envstep_count: 16886898
total_train_sample_count: 12689649
total_episode_count: 38956
total_duration: 3452.0406683313386
[2023-06-29 13:06:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2362
train_sample_count: 2362
avg_envstep_per_episode: 214.72727272727272
avg_sample_per_episode: 214.72727272727272
avg_envstep_per_sec: 2802.8799560921952
avg_train_sample_per_sec: 2802.8799560921952
avg_episode_per_sec: 13.053208940310816
collect_time: 0.8427046598503367
reward_mean: 1623.3906130869063
reward_std: 902.7221625476997
reward_max: 3154.581043094855
reward_min: 60.42964744391879
total_envstep_count: 16891562
total_train_sample_count: 12693211
total_episode_count: 38967
total_duration: 3452.883372991189
[2023-06-29 13:06:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3430
train_sample_count: 3430
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 2660.691428970916
avg_train_sample_per_sec: 2660.691428970916
avg_episode_per_sec: 10.85996501620782
collect_time: 1.28913859106414
reward_mean: 1521.251369131538
reward_std: 719.7855385478346
reward_max: 2840.2929107983537
reward_min: 60.35611203603736
total_envstep_count: 16896010
total_train_sample_count: 12696641
total_episode_count: 38981
total_duration: 3454.1725115822533
[2023-06-29 13:07:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3179
train_sample_count: 3179
avg_envstep_per_episode: 244.53846153846155
avg_sample_per_episode: 244.53846153846155
avg_envstep_per_sec: 2661.7853310326936
avg_train_sample_per_sec: 2661.7853310326936
avg_episode_per_sec: 10.884935295195035
collect_time: 1.1943111876593904
reward_mean: 1168.8436628903244
reward_std: 299.8751069149118
reward_max: 1613.886935289195
reward_min: 694.0480066201387
total_envstep_count: 16901282
total_train_sample_count: 12700220
total_episode_count: 38994
total_duration: 3455.3668227699127
[2023-06-29 13:07:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2523
train_sample_count: 2523
avg_envstep_per_episode: 194.07692307692307
avg_sample_per_episode: 194.07692307692307
avg_envstep_per_sec: 2723.263846198749
avg_train_sample_per_sec: 2723.263846198749
avg_episode_per_sec: 14.031878716045872
collect_time: 0.9264618276050314
reward_mean: 1301.8886925693312
reward_std: 343.92720384376594
reward_max: 1963.353698410643
reward_min: 444.9933395544373
total_envstep_count: 16905522
total_train_sample_count: 12703543
total_episode_count: 39007
total_duration: 3456.293284597518
[2023-06-29 13:07:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2273
train_sample_count: 2273
avg_envstep_per_episode: 378.8333333333333
avg_sample_per_episode: 378.8333333333333
avg_envstep_per_sec: 2827.275177102249
avg_train_sample_per_sec: 2827.275177102249
avg_episode_per_sec: 7.463110894242629
collect_time: 0.8039542872970926
reward_mean: 2278.66156604499
reward_std: 856.0894393033628
reward_max: 3562.406358311783
reward_min: 1221.0836885655297
total_envstep_count: 16909914
total_train_sample_count: 12707016
total_episode_count: 39013
total_duration: 3457.097238884815
[2023-06-29 13:07:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2004
train_sample_count: 2004
avg_envstep_per_episode: 222.66666666666666
avg_sample_per_episode: 222.66666666666666
avg_envstep_per_sec: 2532.8420527131125
avg_train_sample_per_sec: 2532.8420527131125
avg_episode_per_sec: 11.375039158891223
collect_time: 0.7912060674503446
reward_mean: 1660.2131655924914
reward_std: 832.6756405427379
reward_max: 3614.8368738542513
reward_min: 996.4990026077343
total_envstep_count: 16913978
total_train_sample_count: 12710220
total_episode_count: 39022
total_duration: 3457.888444952265
[2023-06-29 13:07:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2699
train_sample_count: 2699
avg_envstep_per_episode: 299.8888888888889
avg_sample_per_episode: 299.8888888888889
avg_envstep_per_sec: 2668.939432821195
avg_train_sample_per_sec: 2668.939432821195
avg_episode_per_sec: 8.899760983842443
collect_time: 1.0112631132835523
reward_mean: 2048.7157231160345
reward_std: 899.9794662012501
reward_max: 3453.1685207115215
reward_min: 724.406852551497
total_envstep_count: 16919194
total_train_sample_count: 12713719
total_episode_count: 39031
total_duration: 3458.8997080655486
[2023-06-29 13:07:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3108
train_sample_count: 3108
avg_envstep_per_episode: 239.07692307692307
avg_sample_per_episode: 239.07692307692307
avg_envstep_per_sec: 2670.4672576263097
avg_train_sample_per_sec: 2670.4672576263097
avg_episode_per_sec: 11.169908091744539
collect_time: 1.1638412682740018
reward_mean: 1563.7528660536134
reward_std: 789.9769754407444
reward_max: 3542.9856139880394
reward_min: 406.27887444833976
total_envstep_count: 16924090
total_train_sample_count: 12717227
total_episode_count: 39044
total_duration: 3460.0635493338227
[2023-06-29 13:07:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3167
train_sample_count: 3167
avg_envstep_per_episode: 263.9166666666667
avg_sample_per_episode: 263.9166666666667
avg_envstep_per_sec: 2772.894506736088
avg_train_sample_per_sec: 2772.894506736088
avg_episode_per_sec: 10.506704793442706
collect_time: 1.1421278351219373
reward_mean: 1523.4282338704015
reward_std: 339.02250354419454
reward_max: 2217.778487838255
reward_min: 1099.228707105246
total_envstep_count: 16928618
total_train_sample_count: 12720794
total_episode_count: 39056
total_duration: 3461.2056771689445
[2023-06-29 13:07:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2731
train_sample_count: 2731
avg_envstep_per_episode: 341.375
avg_sample_per_episode: 341.375
avg_envstep_per_sec: 2810.9432653163085
avg_train_sample_per_sec: 2810.9432653163085
avg_episode_per_sec: 8.234180198656341
collect_time: 0.9715599861787632
reward_mean: 1872.2443968201856
reward_std: 552.7357597697211
reward_max: 2796.0141780880545
reward_min: 1253.5769749924577
total_envstep_count: 16933826
total_train_sample_count: 12724325
total_episode_count: 39064
total_duration: 3462.1772371551233
[2023-06-29 13:07:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2717
train_sample_count: 2717
avg_envstep_per_episode: 209.0
avg_sample_per_episode: 209.0
avg_envstep_per_sec: 2588.8728349565117
avg_train_sample_per_sec: 2588.8728349565117
avg_episode_per_sec: 12.386951363428286
collect_time: 1.0494914865316822
reward_mean: 1469.3141937068488
reward_std: 477.68557526027166
reward_max: 2288.486514988311
reward_min: 855.2664347863314
total_envstep_count: 16938914
total_train_sample_count: 12727842
total_episode_count: 39077
total_duration: 3463.226728641655
[2023-06-29 13:07:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2393
train_sample_count: 2393
avg_envstep_per_episode: 217.54545454545453
avg_sample_per_episode: 217.54545454545453
avg_envstep_per_sec: 2456.530069484624
avg_train_sample_per_sec: 2456.530069484624
avg_episode_per_sec: 11.29203124292974
collect_time: 0.9741382895028219
reward_mean: 1588.68150616285
reward_std: 771.9217572371598
reward_max: 3101.737057072466
reward_min: 51.89028585643286
total_envstep_count: 16943634
total_train_sample_count: 12731435
total_episode_count: 39088
total_duration: 3464.2008669311576
[2023-06-29 13:07:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1763
train_sample_count: 1763
avg_envstep_per_episode: 176.3
avg_sample_per_episode: 176.3
avg_envstep_per_sec: 2699.780587114469
avg_train_sample_per_sec: 2699.780587114469
avg_episode_per_sec: 15.313559768091148
collect_time: 0.653016029678285
reward_mean: 1476.5736601857668
reward_std: 318.49475022834764
reward_max: 1982.1346303923667
reward_min: 919.3738955721849
total_envstep_count: 16947994
total_train_sample_count: 12734798
total_episode_count: 39098
total_duration: 3464.853882960836
[2023-06-29 13:07:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2337
train_sample_count: 2337
avg_envstep_per_episode: 212.45454545454547
avg_sample_per_episode: 212.45454545454547
avg_envstep_per_sec: 2735.9116520273296
avg_train_sample_per_sec: 2735.9116520273296
avg_episode_per_sec: 12.877632936371684
collect_time: 0.854194249389693
reward_mean: 1691.555605397689
reward_std: 465.98207721502763
reward_max: 2566.8736903604367
reward_min: 1013.1217760620838
total_envstep_count: 16952522
total_train_sample_count: 12738335
total_episode_count: 39109
total_duration: 3465.708077210226
[2023-06-29 13:07:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2841
train_sample_count: 2841
avg_envstep_per_episode: 236.75
avg_sample_per_episode: 236.75
avg_envstep_per_sec: 2585.53382005431
avg_train_sample_per_sec: 2585.53382005431
avg_episode_per_sec: 10.920945385657065
collect_time: 1.098805971116759
reward_mean: 1553.8795341697805
reward_std: 396.9683374578594
reward_max: 2351.0245080450964
reward_min: 744.3270404741314
total_envstep_count: 16956522
total_train_sample_count: 12741576
total_episode_count: 39121
total_duration: 3466.8068831813425
[2023-06-29 13:07:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2704
train_sample_count: 2704
avg_envstep_per_episode: 245.8181818181818
avg_sample_per_episode: 245.8181818181818
avg_envstep_per_sec: 2607.6714962421215
avg_train_sample_per_sec: 2607.6714962421215
avg_episode_per_sec: 10.608131086783779
collect_time: 1.0369404289983213
reward_mean: 1287.3865101541373
reward_std: 266.53625956403886
reward_max: 1918.570652032181
reward_min: 904.0289387866744
total_envstep_count: 16961250
total_train_sample_count: 12745080
total_episode_count: 39132
total_duration: 3467.8438236103407
[2023-06-29 13:07:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3096
train_sample_count: 3096
avg_envstep_per_episode: 221.14285714285714
avg_sample_per_episode: 221.14285714285714
avg_envstep_per_sec: 2555.4820716082127
avg_train_sample_per_sec: 2555.4820716082127
avg_episode_per_sec: 11.555797481432487
collect_time: 1.2115130974296482
reward_mean: 1340.6970562773392
reward_std: 412.69655169228906
reward_max: 2425.845937838993
reward_min: 745.3200833478032
total_envstep_count: 16965858
total_train_sample_count: 12748576
total_episode_count: 39146
total_duration: 3469.0553367077705
[2023-06-29 13:07:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3245
train_sample_count: 3245
avg_envstep_per_episode: 249.6153846153846
avg_sample_per_episode: 249.6153846153846
avg_envstep_per_sec: 2725.181252182441
avg_train_sample_per_sec: 2725.181252182441
avg_episode_per_sec: 10.917521195183893
collect_time: 1.190746486091986
reward_mean: 1329.2496467996518
reward_std: 414.3175552068118
reward_max: 2130.1220834334563
reward_min: 450.49953372025976
total_envstep_count: 16970050
total_train_sample_count: 12751821
total_episode_count: 39159
total_duration: 3470.2460831938624
[2023-06-29 13:07:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2517
train_sample_count: 2517
avg_envstep_per_episode: 228.8181818181818
avg_sample_per_episode: 228.8181818181818
avg_envstep_per_sec: 2801.518694594845
avg_train_sample_per_sec: 2801.518694594845
avg_episode_per_sec: 12.243426952937345
collect_time: 0.8984412650382145
reward_mean: 1149.4708051974164
reward_std: 310.0322781012541
reward_max: 1574.0740884917445
reward_min: 433.67342248534743
total_envstep_count: 16974746
total_train_sample_count: 12755138
total_episode_count: 39170
total_duration: 3471.144524458901
[2023-06-29 13:07:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3008
train_sample_count: 3008
avg_envstep_per_episode: 214.85714285714286
avg_sample_per_episode: 214.85714285714286
avg_envstep_per_sec: 2590.1449596885805
avg_train_sample_per_sec: 2590.1449596885805
avg_episode_per_sec: 12.055195955997384
collect_time: 1.1613249632027
reward_mean: 1351.4216694918528
reward_std: 443.0296135735852
reward_max: 2547.7612944777757
reward_min: 952.4333172046598
total_envstep_count: 16979322
total_train_sample_count: 12758546
total_episode_count: 39184
total_duration: 3472.3058494221036
[2023-06-29 13:07:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 229.78571428571428
avg_sample_per_episode: 229.78571428571428
avg_envstep_per_sec: 2525.57985570733
avg_train_sample_per_sec: 2525.57985570733
avg_episode_per_sec: 10.991022064004545
collect_time: 1.2737668906925244
reward_mean: 1254.472337446097
reward_std: 222.18883725386766
reward_max: 1751.9936400029171
reward_min: 929.5654874309546
total_envstep_count: 16984010
total_train_sample_count: 12761763
total_episode_count: 39198
total_duration: 3473.579616312796
[2023-06-29 13:08:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2443.299166135889
avg_train_sample_per_sec: 2443.299166135889
avg_episode_per_sec: 9.433587514038182
collect_time: 0.8480336868762969
reward_mean: 1560.6830010464985
reward_std: 387.2375746191537
reward_max: 2005.9213606292196
reward_min: 913.0062177026924
total_envstep_count: 16988554
total_train_sample_count: 12765035
total_episode_count: 39206
total_duration: 3474.427649999672
[2023-06-29 13:08:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2998
train_sample_count: 2998
avg_envstep_per_episode: 272.54545454545456
avg_sample_per_episode: 272.54545454545456
avg_envstep_per_sec: 2749.3761282545406
avg_train_sample_per_sec: 2749.3761282545406
avg_episode_per_sec: 10.087770984256153
collect_time: 1.090429195623845
reward_mean: 1856.4300124097872
reward_std: 741.4759491574373
reward_max: 3495.3521766835265
reward_min: 1009.1346210704793
total_envstep_count: 16993370
total_train_sample_count: 12768433
total_episode_count: 39217
total_duration: 3475.518079195296
[2023-06-29 13:08:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2678
train_sample_count: 2678
avg_envstep_per_episode: 267.8
avg_sample_per_episode: 267.8
avg_envstep_per_sec: 2608.2807792607414
avg_train_sample_per_sec: 2608.2807792607414
avg_episode_per_sec: 9.739659369905683
collect_time: 1.0267299522710966
reward_mean: 1521.7174476252494
reward_std: 460.62361092650843
reward_max: 2530.1416194436906
reward_min: 1051.8502641699856
total_envstep_count: 16997674
total_train_sample_count: 12771911
total_episode_count: 39227
total_duration: 3476.5448091475673
[2023-06-29 13:08:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2700
train_sample_count: 2700
avg_envstep_per_episode: 270.0
avg_sample_per_episode: 270.0
avg_envstep_per_sec: 2612.5886009204364
avg_train_sample_per_sec: 2612.5886009204364
avg_episode_per_sec: 9.6762540774831
collect_time: 1.0334577740440143
reward_mean: 1683.6421797751125
reward_std: 818.2186108057676
reward_max: 3574.820218872382
reward_min: 989.11085250402
total_envstep_count: 17002762
total_train_sample_count: 12775411
total_episode_count: 39237
total_duration: 3477.5782669216114
[2023-06-29 13:08:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1677
train_sample_count: 1677
avg_envstep_per_episode: 209.625
avg_sample_per_episode: 209.625
avg_envstep_per_sec: 2768.384141434474
avg_train_sample_per_sec: 2768.384141434474
avg_episode_per_sec: 13.20636441948467
collect_time: 0.6057685329504311
reward_mean: 1733.2637299368992
reward_std: 495.71559523803694
reward_max: 2619.1100360487912
reward_min: 1092.0636342982646
total_envstep_count: 17007426
total_train_sample_count: 12778688
total_episode_count: 39245
total_duration: 3478.184035454562
[2023-06-29 13:08:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1637
train_sample_count: 1637
avg_envstep_per_episode: 181.88888888888889
avg_sample_per_episode: 181.88888888888889
avg_envstep_per_sec: 2808.762441745411
avg_train_sample_per_sec: 2808.762441745411
avg_episode_per_sec: 15.44218813421423
collect_time: 0.5828189581539482
reward_mean: 1679.615972460488
reward_std: 716.5409706304133
reward_max: 3516.3355240828355
reward_min: 884.8155930762754
total_envstep_count: 17011506
total_train_sample_count: 12781925
total_episode_count: 39254
total_duration: 3478.766854412716
[2023-06-29 13:08:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1826
train_sample_count: 1826
avg_envstep_per_episode: 202.88888888888889
avg_sample_per_episode: 202.88888888888889
avg_envstep_per_sec: 2561.9977579234264
avg_train_sample_per_sec: 2561.9977579234264
avg_episode_per_sec: 12.627590263587534
collect_time: 0.7127250577611848
reward_mean: 2070.3747496161964
reward_std: 984.4156247286292
reward_max: 3535.890687733221
reward_min: 846.6524843827583
total_envstep_count: 17016098
total_train_sample_count: 12785351
total_episode_count: 39263
total_duration: 3479.479579470477
[2023-06-29 13:08:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2693
train_sample_count: 2693
avg_envstep_per_episode: 224.41666666666666
avg_sample_per_episode: 224.41666666666666
avg_envstep_per_sec: 2636.5980661056296
avg_train_sample_per_sec: 2636.5980661056296
avg_episode_per_sec: 11.748673150117918
collect_time: 1.0213919347887859
reward_mean: 1687.7287030426148
reward_std: 444.4335456345274
reward_max: 2433.0153993043236
reward_min: 737.9781405013246
total_envstep_count: 17020562
total_train_sample_count: 12788844
total_episode_count: 39275
total_duration: 3480.500971405266
[2023-06-29 13:08:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2639
train_sample_count: 2639
avg_envstep_per_episode: 263.9
avg_sample_per_episode: 263.9
avg_envstep_per_sec: 2561.5280146116747
avg_train_sample_per_sec: 2561.5280146116747
avg_episode_per_sec: 9.706434310767998
collect_time: 1.030244441968389
reward_mean: 1612.6319860208791
reward_std: 583.6430202845254
reward_max: 2688.071224662283
reward_min: 822.8280963622091
total_envstep_count: 17025274
total_train_sample_count: 12792283
total_episode_count: 39285
total_duration: 3481.5312158472343
[2023-06-29 13:08:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 248.4
avg_sample_per_episode: 248.4
avg_envstep_per_sec: 2543.915881113052
avg_train_sample_per_sec: 2543.915881113052
avg_episode_per_sec: 10.241207250857698
collect_time: 0.9764473811583594
reward_mean: 1690.8845138621668
reward_std: 490.7652446093612
reward_max: 2641.2828160598565
reward_min: 1086.2251935644242
total_envstep_count: 17030090
total_train_sample_count: 12795567
total_episode_count: 39295
total_duration: 3482.5076632283926
[2023-06-29 13:08:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2035
train_sample_count: 2035
avg_envstep_per_episode: 203.5
avg_sample_per_episode: 203.5
avg_envstep_per_sec: 2727.424146358472
avg_train_sample_per_sec: 2727.424146358472
avg_episode_per_sec: 13.402575657781188
collect_time: 0.7461252415459605
reward_mean: 1586.1777976527537
reward_std: 502.90316542896716
reward_max: 2515.920799845112
reward_min: 1051.4519033503893
total_envstep_count: 17034202
total_train_sample_count: 12798802
total_episode_count: 39305
total_duration: 3483.2537884699386
[2023-06-29 13:08:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2305
train_sample_count: 2305
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 2568.5869057620343
avg_train_sample_per_sec: 2568.5869057620343
avg_episode_per_sec: 11.143544059705139
collect_time: 0.8973805771684276
reward_mean: 1554.1842308435773
reward_std: 528.8291857599439
reward_max: 2443.9541794588904
reward_min: 751.4103496704013
total_envstep_count: 17038802
total_train_sample_count: 12802307
total_episode_count: 39315
total_duration: 3484.151169047107
[2023-06-29 13:08:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 268.25
avg_sample_per_episode: 268.25
avg_envstep_per_sec: 2576.29513372043
avg_train_sample_per_sec: 2576.29513372043
avg_episode_per_sec: 9.604082511539348
collect_time: 0.8329790992932395
reward_mean: 2080.8632281290484
reward_std: 734.4582238137904
reward_max: 3294.2428513695386
reward_min: 1095.2689821941872
total_envstep_count: 17043418
total_train_sample_count: 12805653
total_episode_count: 39323
total_duration: 3484.9841481464005
[2023-06-29 13:08:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1701
train_sample_count: 1701
avg_envstep_per_episode: 243.0
avg_sample_per_episode: 243.0
avg_envstep_per_sec: 2418.90686393688
avg_train_sample_per_sec: 2418.90686393688
avg_episode_per_sec: 9.954349234308149
collect_time: 0.7032102084457876
reward_mean: 2298.5924963435464
reward_std: 756.431803793402
reward_max: 3590.9969578105784
reward_min: 1170.6527326311227
total_envstep_count: 17047978
total_train_sample_count: 12808954
total_episode_count: 39330
total_duration: 3485.6873583548463
[2023-06-29 13:08:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1981
train_sample_count: 1981
avg_envstep_per_episode: 220.11111111111111
avg_sample_per_episode: 220.11111111111111
avg_envstep_per_sec: 2746.318388620249
avg_train_sample_per_sec: 2746.318388620249
avg_episode_per_sec: 12.476963905897145
collect_time: 0.7213293288238348
reward_mean: 2010.4472740741699
reward_std: 819.7951977297575
reward_max: 2918.4455879138422
reward_min: 49.372577452021275
total_envstep_count: 17052834
total_train_sample_count: 12812535
total_episode_count: 39339
total_duration: 3486.40868768367
[2023-06-29 13:08:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2635
train_sample_count: 2635
avg_envstep_per_episode: 292.77777777777777
avg_sample_per_episode: 292.77777777777777
avg_envstep_per_sec: 2794.08084956707
avg_train_sample_per_sec: 2794.08084956707
avg_episode_per_sec: 9.543350150323958
collect_time: 0.9430650513954459
reward_mean: 2060.890849736935
reward_std: 933.9537676398918
reward_max: 3627.8614946169364
reward_min: 745.9568982664783
total_envstep_count: 17057482
total_train_sample_count: 12815970
total_episode_count: 39348
total_duration: 3487.3517527350655
[2023-06-29 13:08:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 149.85714285714286
avg_sample_per_episode: 149.85714285714286
avg_envstep_per_sec: 2249.3643623021067
avg_train_sample_per_sec: 2249.3643623021067
avg_episode_per_sec: 15.010057708403
collect_time: 0.4663539698505774
reward_mean: 1454.2813246002454
reward_std: 1373.248704160909
reward_max: 3602.412707048991
reward_min: 20.941852018525804
total_envstep_count: 17061690
total_train_sample_count: 12819419
total_episode_count: 39355
total_duration: 3487.818106704916
[2023-06-29 13:08:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2022
train_sample_count: 2022
avg_envstep_per_episode: 288.85714285714283
avg_sample_per_episode: 288.85714285714283
avg_envstep_per_sec: 2669.759328620415
avg_train_sample_per_sec: 2669.759328620415
avg_episode_per_sec: 9.242490257340705
collect_time: 0.7573716395795341
reward_mean: 2753.4735100000626
reward_std: 935.9757120491539
reward_max: 3609.6439802043983
reward_min: 1489.5887526902677
total_envstep_count: 17066042
total_train_sample_count: 12822641
total_episode_count: 39362
total_duration: 3488.5754783444954
[2023-06-29 13:08:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 818
train_sample_count: 818
avg_envstep_per_episode: 204.5
avg_sample_per_episode: 204.5
avg_envstep_per_sec: 2718.163441233933
avg_train_sample_per_sec: 2718.163441233933
avg_episode_per_sec: 13.291752768870088
collect_time: 0.30093848941940815
reward_mean: 2836.6711505504527
reward_std: 768.284263978957
reward_max: 3602.1706974634153
reward_min: 1976.7733458108366
total_envstep_count: 17070554
total_train_sample_count: 12825859
total_episode_count: 39366
total_duration: 3488.876416833915
[2023-06-29 13:08:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1981
train_sample_count: 1981
avg_envstep_per_episode: 198.1
avg_sample_per_episode: 198.1
avg_envstep_per_sec: 2811.4434194772216
avg_train_sample_per_sec: 2811.4434194772216
avg_episode_per_sec: 14.192041491555889
collect_time: 0.7046202624160796
reward_mean: 2237.094686192213
reward_std: 1254.3364747578094
reward_max: 3593.6672669295895
reward_min: 19.73235529934177
total_envstep_count: 17075378
total_train_sample_count: 12829440
total_episode_count: 39376
total_duration: 3489.581037096331
[2023-06-29 13:09:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 2759.956886764036
avg_train_sample_per_sec: 2759.956886764036
avg_episode_per_sec: 14.45003605635621
collect_time: 0.41522387740761035
reward_mean: 2252.1931699167726
reward_std: 599.1247479980113
reward_max: 2850.844323568725
reward_min: 1207.9035729210552
total_envstep_count: 17079730
total_train_sample_count: 12832986
total_episode_count: 39382
total_duration: 3489.9962609737386
[2023-06-29 13:09:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1509
train_sample_count: 1509
avg_envstep_per_episode: 167.66666666666666
avg_sample_per_episode: 167.66666666666666
avg_envstep_per_sec: 2627.4479123503897
avg_train_sample_per_sec: 2627.4479123503897
avg_episode_per_sec: 15.67066349314348
collect_time: 0.5743215661505238
reward_mean: 1985.685645680255
reward_std: 713.8671038940589
reward_max: 3557.55243875744
reward_min: 737.2844431333092
total_envstep_count: 17084266
total_train_sample_count: 12836495
total_episode_count: 39391
total_duration: 3490.570582539889
[2023-06-29 13:09:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2542
train_sample_count: 2542
avg_envstep_per_episode: 211.83333333333334
avg_sample_per_episode: 211.83333333333334
avg_envstep_per_sec: 2502.2054184023973
avg_train_sample_per_sec: 2502.2054184023973
avg_episode_per_sec: 11.812142022355928
collect_time: 1.0159038028232752
reward_mean: 1735.2324282663355
reward_std: 892.9049869811316
reward_max: 3567.9189587047954
reward_min: 412.9748892002984
total_envstep_count: 17088626
total_train_sample_count: 12839837
total_episode_count: 39403
total_duration: 3491.5864863427123
[2023-06-29 13:09:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2646
train_sample_count: 2646
avg_envstep_per_episode: 264.6
avg_sample_per_episode: 264.6
avg_envstep_per_sec: 2756.1351155847665
avg_train_sample_per_sec: 2756.1351155847665
avg_episode_per_sec: 10.4162324852032
collect_time: 0.9600400158315898
reward_mean: 1622.143844368234
reward_std: 912.4463201726078
reward_max: 3402.558369068529
reward_min: 53.770728799129934
total_envstep_count: 17093618
total_train_sample_count: 12843283
total_episode_count: 39413
total_duration: 3492.546526358544
[2023-06-29 13:09:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2406
train_sample_count: 2406
avg_envstep_per_episode: 267.3333333333333
avg_sample_per_episode: 267.3333333333333
avg_envstep_per_sec: 2769.445913862232
avg_train_sample_per_sec: 2769.445913862232
avg_episode_per_sec: 10.359523368561964
collect_time: 0.868765837945044
reward_mean: 1807.8868347298455
reward_std: 579.0728244977125
reward_max: 3183.401034652224
reward_min: 1098.9268667392257
total_envstep_count: 17097506
total_train_sample_count: 12846489
total_episode_count: 39422
total_duration: 3493.4152921964887
[2023-06-29 13:09:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2220
train_sample_count: 2220
avg_envstep_per_episode: 317.14285714285717
avg_sample_per_episode: 317.14285714285717
avg_envstep_per_sec: 2551.3679416781906
avg_train_sample_per_sec: 2551.3679416781906
avg_episode_per_sec: 8.044853870156457
collect_time: 0.870121460623108
reward_mean: 2092.965150528461
reward_std: 622.3795496118464
reward_max: 3214.435112318648
reward_min: 1341.5901850117855
total_envstep_count: 17101706
total_train_sample_count: 12849909
total_episode_count: 39429
total_duration: 3494.285413657112
[2023-06-29 13:09:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 271.3333333333333
avg_sample_per_episode: 271.3333333333333
avg_envstep_per_sec: 2585.3003420527925
avg_train_sample_per_sec: 2585.3003420527925
avg_episode_per_sec: 9.528133938769505
collect_time: 0.6297140697808935
reward_mean: 2037.9092470344456
reward_std: 316.1573615303895
reward_max: 2529.818106860213
reward_min: 1552.4748462279542
total_envstep_count: 17106378
total_train_sample_count: 12853137
total_episode_count: 39435
total_duration: 3494.9151277268925
[2023-06-29 13:09:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2011
train_sample_count: 2011
avg_envstep_per_episode: 223.44444444444446
avg_sample_per_episode: 223.44444444444446
avg_envstep_per_sec: 2756.884902523484
avg_train_sample_per_sec: 2756.884902523484
avg_episode_per_sec: 12.338122388220466
collect_time: 0.7294464843850584
reward_mean: 2128.989171998056
reward_std: 1094.322472887457
reward_max: 3602.7094174887343
reward_min: 427.74212820147307
total_envstep_count: 17110706
total_train_sample_count: 12856348
total_episode_count: 39444
total_duration: 3495.6445742112774
[2023-06-29 13:09:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2531
train_sample_count: 2531
avg_envstep_per_episode: 281.22222222222223
avg_sample_per_episode: 281.22222222222223
avg_envstep_per_sec: 2801.4501642049695
avg_train_sample_per_sec: 2801.4501642049695
avg_episode_per_sec: 9.961695566118028
collect_time: 0.9034606548920275
reward_mean: 2054.9153433438833
reward_std: 1081.979542769801
reward_max: 3607.4594675955427
reward_min: 56.358815270325074
total_envstep_count: 17115506
total_train_sample_count: 12859679
total_episode_count: 39453
total_duration: 3496.5480348661695
[2023-06-29 13:09:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 350.5
avg_sample_per_episode: 350.5
avg_envstep_per_sec: 2825.922833604629
avg_train_sample_per_sec: 2825.922833604629
avg_episode_per_sec: 8.06254731413589
collect_time: 0.24806055978033686
reward_mean: 2831.1851888182437
reward_std: 920.2299178801273
reward_max: 3751.415106698371
reward_min: 1910.9552709381162
total_envstep_count: 17120098
total_train_sample_count: 12863180
total_episode_count: 39455
total_duration: 3496.7960954259497
[2023-06-29 13:09:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2201
train_sample_count: 2201
avg_envstep_per_episode: 244.55555555555554
avg_sample_per_episode: 244.55555555555554
avg_envstep_per_sec: 2559.015226708694
avg_train_sample_per_sec: 2559.015226708694
avg_episode_per_sec: 10.46394231730043
collect_time: 0.8600964843928813
reward_mean: 3082.3229745621597
reward_std: 922.7883128109861
reward_max: 3723.1322595427814
reward_min: 1158.5043170913787
total_envstep_count: 17124466
total_train_sample_count: 12866581
total_episode_count: 39464
total_duration: 3497.6561919103424
[2023-06-29 13:09:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2646
train_sample_count: 2646
avg_envstep_per_episode: 220.5
avg_sample_per_episode: 220.5
avg_envstep_per_sec: 2527.705428359493
avg_train_sample_per_sec: 2527.705428359493
avg_episode_per_sec: 11.463516681902462
collect_time: 1.0467991919917985
reward_mean: 1445.8740462012063
reward_std: 1001.531975645835
reward_max: 2925.72324280029
reward_min: 54.6170471184226
total_envstep_count: 17129138
total_train_sample_count: 12870027
total_episode_count: 39476
total_duration: 3498.702991102334
[2023-06-29 13:09:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 332.0
avg_sample_per_episode: 332.0
avg_envstep_per_sec: 2718.8535834116383
avg_train_sample_per_sec: 2718.8535834116383
avg_episode_per_sec: 8.189318022324212
collect_time: 0.4884411606797948
reward_mean: 2682.99107832606
reward_std: 893.9061979875438
reward_max: 3575.0359725549765
reward_min: 1643.009572025862
total_envstep_count: 17133370
total_train_sample_count: 12873355
total_episode_count: 39480
total_duration: 3499.191432263014
[2023-06-29 13:09:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 2753.844796889921
avg_train_sample_per_sec: 2753.844796889921
avg_episode_per_sec: 15.918178016704745
collect_time: 0.31410630002710954
reward_mean: 2627.642045421337
reward_std: 772.2994297194767
reward_max: 3570.9574553376833
reward_min: 1749.1900302745555
total_envstep_count: 17137242
total_train_sample_count: 12876620
total_episode_count: 39485
total_duration: 3499.5055385630412
[2023-06-29 13:09:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1696
train_sample_count: 1696
avg_envstep_per_episode: 242.28571428571428
avg_sample_per_episode: 242.28571428571428
avg_envstep_per_sec: 2584.885521394033
avg_train_sample_per_sec: 2584.885521394033
avg_episode_per_sec: 10.66874920386688
collect_time: 0.6561219001626596
reward_mean: 2713.0025912682786
reward_std: 849.1346271616023
reward_max: 3664.003487499991
reward_min: 1449.4806873417751
total_envstep_count: 17141650
total_train_sample_count: 12879916
total_episode_count: 39492
total_duration: 3500.161660463204
[2023-06-29 13:09:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2913
train_sample_count: 2913
avg_envstep_per_episode: 323.6666666666667
avg_sample_per_episode: 323.6666666666667
avg_envstep_per_sec: 2678.9297684856465
avg_train_sample_per_sec: 2678.9297684856465
avg_episode_per_sec: 8.276816998410855
collect_time: 1.0873745307801292
reward_mean: 2385.2803140413885
reward_std: 565.2634719834344
reward_max: 2985.123284461819
reward_min: 1378.4001114622308
total_envstep_count: 17146482
total_train_sample_count: 12883229
total_episode_count: 39501
total_duration: 3501.249034993984
[2023-06-29 13:09:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 568
train_sample_count: 568
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2782.1045872755385
avg_train_sample_per_sec: 2782.1045872755385
avg_episode_per_sec: 9.796142912942036
collect_time: 0.20416198679152875
reward_mean: 2075.839418572161
reward_std: 708.0926151512506
reward_max: 2783.932033723411
reward_min: 1367.74680342091
total_envstep_count: 17151410
total_train_sample_count: 12886597
total_episode_count: 39503
total_duration: 3501.4531969807754
[2023-06-29 13:09:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 104.11111111111111
avg_sample_per_episode: 104.11111111111111
avg_envstep_per_sec: 2706.183590721937
avg_train_sample_per_sec: 2706.183590721937
avg_episode_per_sec: 25.993225524543686
collect_time: 0.34624406238086514
reward_mean: 2578.3304519189073
reward_std: 1270.1719634754538
reward_max: 3620.572872110927
reward_min: 63.57613073024174
total_envstep_count: 17156066
total_train_sample_count: 12889934
total_episode_count: 39512
total_duration: 3501.799441043156
[2023-06-29 13:09:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 2757.1091023350377
avg_train_sample_per_sec: 2757.1091023350377
avg_episode_per_sec: 13.615353591777964
collect_time: 0.4406789702195673
reward_mean: 2694.971180245188
reward_std: 832.815491389879
reward_max: 3575.9457474604337
reward_min: 1188.4707415414834
total_envstep_count: 17160498
total_train_sample_count: 12893149
total_episode_count: 39518
total_duration: 3502.240120013376
[2023-06-29 13:09:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 839
train_sample_count: 839
avg_envstep_per_episode: 209.75
avg_sample_per_episode: 209.75
avg_envstep_per_sec: 2759.4121529211693
avg_train_sample_per_sec: 2759.4121529211693
avg_episode_per_sec: 13.155719441817254
collect_time: 0.30405026632640497
reward_mean: 2929.260569900698
reward_std: 886.9886916368622
reward_max: 3631.4089712069017
reward_min: 1447.4489947048373
total_envstep_count: 17164362
total_train_sample_count: 12896388
total_episode_count: 39522
total_duration: 3502.5441702797025
[2023-06-29 13:10:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1691
train_sample_count: 1691
avg_envstep_per_episode: 153.72727272727272
avg_sample_per_episode: 153.72727272727272
avg_envstep_per_sec: 2683.587892602956
avg_train_sample_per_sec: 2683.587892602956
avg_episode_per_sec: 17.456810655607637
collect_time: 0.6301265573082492
reward_mean: 2009.4502088281433
reward_std: 1314.3840527866482
reward_max: 3602.0085109815136
reward_min: 369.4006338403536
total_envstep_count: 17169210
total_train_sample_count: 12899679
total_episode_count: 39533
total_duration: 3503.174296837011
[2023-06-29 13:10:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 683
train_sample_count: 683
avg_envstep_per_episode: 227.66666666666666
avg_sample_per_episode: 227.66666666666666
avg_envstep_per_sec: 2776.308340794576
avg_train_sample_per_sec: 2776.308340794576
avg_episode_per_sec: 12.194619359273394
collect_time: 0.24601013870257876
reward_mean: 3115.33692269092
reward_std: 411.38603970640395
reward_max: 3610.8710063300414
reward_min: 2603.5770978981677
total_envstep_count: 17173674
total_train_sample_count: 12903162
total_episode_count: 39536
total_duration: 3503.4203069757136
[2023-06-29 13:10:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1554
train_sample_count: 1554
avg_envstep_per_episode: 194.25
avg_sample_per_episode: 194.25
avg_envstep_per_sec: 2635.336643834362
avg_train_sample_per_sec: 2635.336643834362
avg_episode_per_sec: 13.566726609185904
collect_time: 0.5896779842665418
reward_mean: 2890.2139799691604
reward_std: 1140.2395355058554
reward_max: 3679.5638174006663
reward_min: 781.4486763122185
total_envstep_count: 17178170
total_train_sample_count: 12906716
total_episode_count: 39544
total_duration: 3504.00998495998
[2023-06-29 13:10:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 1
envstep_count: 38
train_sample_count: 38
avg_envstep_per_episode: 38.0
avg_sample_per_episode: 38.0
avg_envstep_per_sec: 2731.9898422381207
avg_train_sample_per_sec: 2731.9898422381207
avg_episode_per_sec: 71.89446953258212
collect_time: 0.013909275727346541
reward_mean: 3591.1001425437803
reward_std: 0.0
reward_max: 3591.1001425437803
reward_min: 3591.1001425437803
total_envstep_count: 17181674
total_train_sample_count: 12909954
total_episode_count: 39545
total_duration: 3504.0238942357073
[2023-06-29 13:10:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2559
train_sample_count: 2559
avg_envstep_per_episode: 255.9
avg_sample_per_episode: 255.9
avg_envstep_per_sec: 2532.505081535261
avg_train_sample_per_sec: 2532.505081535261
avg_episode_per_sec: 9.896463780911532
collect_time: 1.0104619408892468
reward_mean: 2823.013726375533
reward_std: 1163.8904477016988
reward_max: 3579.6519474267006
reward_min: 749.597576708633
total_envstep_count: 17186154
total_train_sample_count: 12913313
total_episode_count: 39555
total_duration: 3505.0343561765967
[2023-06-29 13:10:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1769
train_sample_count: 1769
avg_envstep_per_episode: 353.8
avg_sample_per_episode: 353.8
avg_envstep_per_sec: 2806.176799079707
avg_train_sample_per_sec: 2806.176799079707
avg_episode_per_sec: 7.931534197511891
collect_time: 0.6303950629839674
reward_mean: 2394.714200302497
reward_std: 1099.8445371493556
reward_max: 3549.9640224902787
reward_min: 1071.9357059490242
total_envstep_count: 17191074
total_train_sample_count: 12916682
total_episode_count: 39560
total_duration: 3505.6647512395807
[2023-06-29 13:10:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1460
train_sample_count: 1460
avg_envstep_per_episode: 208.57142857142858
avg_sample_per_episode: 208.57142857142858
avg_envstep_per_sec: 2788.243306780609
avg_train_sample_per_sec: 2788.243306780609
avg_episode_per_sec: 13.368289827030317
collect_time: 0.5236271872147917
reward_mean: 2343.0325549123777
reward_std: 1260.1661482639363
reward_max: 3578.360918813789
reward_min: 55.30471031116205
total_envstep_count: 17195514
total_train_sample_count: 12920142
total_episode_count: 39567
total_duration: 3506.1883784267957
[2023-06-29 13:10:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 894
train_sample_count: 894
avg_envstep_per_episode: 223.5
avg_sample_per_episode: 223.5
avg_envstep_per_sec: 2806.3848075395645
avg_train_sample_per_sec: 2806.3848075395645
avg_episode_per_sec: 12.55653157735823
collect_time: 0.31855930719058967
reward_mean: 2904.1088264948958
reward_std: 1044.453010041922
reward_max: 3519.0925941021133
reward_min: 1095.1086289818686
total_envstep_count: 17199922
total_train_sample_count: 12923436
total_episode_count: 39571
total_duration: 3506.5069377339864
[2023-06-29 13:10:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 186.2
avg_sample_per_episode: 186.2
avg_envstep_per_sec: 2733.286229503864
avg_train_sample_per_sec: 2733.286229503864
avg_episode_per_sec: 14.679303058559958
collect_time: 0.34061562596354633
reward_mean: 2957.737129902409
reward_std: 1093.0810227110303
reward_max: 3513.2412179475423
reward_min: 771.6431279709743
total_envstep_count: 17204106
total_train_sample_count: 12926767
total_episode_count: 39576
total_duration: 3506.84755335995
[2023-06-29 13:10:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 598
train_sample_count: 598
avg_envstep_per_episode: 149.5
avg_sample_per_episode: 149.5
avg_envstep_per_sec: 2657.333815042606
avg_train_sample_per_sec: 2657.333815042606
avg_episode_per_sec: 17.77480812737529
collect_time: 0.22503759091719985
reward_mean: 3504.6904901223097
reward_std: 24.499095126915368
reward_max: 3526.0603410652575
reward_min: 3464.745769267297
total_envstep_count: 17208162
total_train_sample_count: 12930165
total_episode_count: 39580
total_duration: 3507.072590950867
[2023-06-29 13:10:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2140
train_sample_count: 2140
avg_envstep_per_episode: 267.5
avg_sample_per_episode: 267.5
avg_envstep_per_sec: 2768.021768092711
avg_train_sample_per_sec: 2768.021768092711
avg_episode_per_sec: 10.347744927449387
collect_time: 0.7731153073534368
reward_mean: 2903.2427892890137
reward_std: 1037.9638827334434
reward_max: 3546.451562854255
reward_min: 461.9104640577524
total_envstep_count: 17212794
total_train_sample_count: 12933505
total_episode_count: 39588
total_duration: 3507.84570625822
[2023-06-29 13:10:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1361
train_sample_count: 1361
avg_envstep_per_episode: 453.6666666666667
avg_sample_per_episode: 453.6666666666667
avg_envstep_per_sec: 2467.563325014003
avg_train_sample_per_sec: 2467.563325014003
avg_episode_per_sec: 5.4391550147259435
collect_time: 0.5515562604628501
reward_mean: 3514.0277376801896
reward_std: 7.17118859502817
reward_max: 3522.6646045989633
reward_min: 3505.1057929338895
total_envstep_count: 17217594
total_train_sample_count: 12936866
total_episode_count: 39591
total_duration: 3508.397262518683
[2023-06-29 13:10:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 1887
train_sample_count: 1887
avg_envstep_per_episode: 157.25
avg_sample_per_episode: 157.25
avg_envstep_per_sec: 2679.351772145381
avg_train_sample_per_sec: 2679.351772145381
avg_episode_per_sec: 17.038803002514346
collect_time: 0.7042748248353602
reward_mean: 1748.3826131813582
reward_std: 1495.0185737831025
reward_max: 3542.5241043787755
reward_min: 55.144315579728236
total_envstep_count: 17222234
total_train_sample_count: 12940353
total_episode_count: 39603
total_duration: 3509.1015373435184
[2023-06-29 13:10:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 858
train_sample_count: 858
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2614.970745176043
avg_train_sample_per_sec: 2614.970745176043
avg_episode_per_sec: 9.143254353762387
collect_time: 0.32811074524745343
reward_mean: 2649.10137940946
reward_std: 1276.7712664356704
reward_max: 3569.568699753643
reward_min: 843.5899656387234
total_envstep_count: 17226090
total_train_sample_count: 12943611
total_episode_count: 39606
total_duration: 3509.429648088766
[2023-06-29 13:10:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 242.16666666666666
avg_sample_per_episode: 242.16666666666666
avg_envstep_per_sec: 2719.0005386914872
avg_train_sample_per_sec: 2719.0005386914872
avg_episode_per_sec: 11.227806766792101
collect_time: 0.5343875366421417
reward_mean: 3541.8226027049027
reward_std: 20.528789202953046
reward_max: 3564.8406899732463
reward_min: 3507.1537740471645
total_envstep_count: 17231410
total_train_sample_count: 12947064
total_episode_count: 39612
total_duration: 3509.964035625408
[2023-06-29 13:10:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2062
train_sample_count: 2062
avg_envstep_per_episode: 294.57142857142856
avg_sample_per_episode: 294.57142857142856
avg_envstep_per_sec: 2792.803732674208
avg_train_sample_per_sec: 2792.803732674208
avg_episode_per_sec: 9.4809050090783
collect_time: 0.738326140099205
reward_mean: 2526.9752229041583
reward_std: 1562.3614559225778
reward_max: 3543.282480857068
reward_min: 54.118038989412476
total_envstep_count: 17236210
total_train_sample_count: 12950326
total_episode_count: 39619
total_duration: 3510.7023617655072
[2023-06-29 13:10:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 229
train_sample_count: 229
avg_envstep_per_episode: 76.33333333333333
avg_sample_per_episode: 76.33333333333333
avg_envstep_per_sec: 2755.0200775547382
avg_train_sample_per_sec: 2755.0200775547382
avg_episode_per_sec: 36.091966081503124
collect_time: 0.08312099133711308
reward_mean: 3524.445708196268
reward_std: 17.409885812626662
reward_max: 3539.772453582818
reward_min: 3500.0947849665913
total_envstep_count: 17240834
total_train_sample_count: 12953755
total_episode_count: 39622
total_duration: 3510.7854827568444
[2023-06-29 13:10:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2067
train_sample_count: 2067
avg_envstep_per_episode: 295.2857142857143
avg_sample_per_episode: 295.2857142857143
avg_envstep_per_sec: 2405.3842902628057
avg_train_sample_per_sec: 2405.3842902628057
avg_episode_per_sec: 8.145955506453623
collect_time: 0.8593221500478684
reward_mean: 3525.9489015515574
reward_std: 21.779665827505635
reward_max: 3567.243338790443
reward_min: 3499.5616633887867
total_envstep_count: 17245290
total_train_sample_count: 12957022
total_episode_count: 39629
total_duration: 3511.644804906892
[2023-06-29 13:10:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 1
envstep_count: 43
train_sample_count: 43
avg_envstep_per_episode: 43.0
avg_sample_per_episode: 43.0
avg_envstep_per_sec: 2786.108027810338
avg_train_sample_per_sec: 2786.108027810338
avg_episode_per_sec: 64.79320994907764
collect_time: 0.015433715983293949
reward_mean: 3521.1834202423356
reward_std: 0.0
reward_max: 3521.1834202423356
reward_min: 3521.1834202423356
total_envstep_count: 17248834
total_train_sample_count: 12960265
total_episode_count: 39630
total_duration: 3511.6602386228756
[2023-06-29 13:11:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2511
train_sample_count: 2511
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2770.548949539773
avg_train_sample_per_sec: 2770.548949539773
avg_episode_per_sec: 9.930282973260834
collect_time: 0.9063185836933553
reward_mean: 3121.3450348950287
reward_std: 1074.72086915921
reward_max: 3692.9713529402434
reward_min: 150.79758675015447
total_envstep_count: 17253634
total_train_sample_count: 12963576
total_episode_count: 39639
total_duration: 3512.566557206569
[2023-06-29 13:11:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1326
train_sample_count: 1326
avg_envstep_per_episode: 331.5
avg_sample_per_episode: 331.5
avg_envstep_per_sec: 2684.0350656076434
avg_train_sample_per_sec: 2684.0350656076434
avg_episode_per_sec: 8.096636698665591
collect_time: 0.4940322937620804
reward_mean: 2217.2474916488673
reward_std: 1427.1064622606848
reward_max: 3637.6641048755164
reward_min: 420.9586241544799
total_envstep_count: 17258090
total_train_sample_count: 12966902
total_episode_count: 39643
total_duration: 3513.0605895003314
[2023-06-29 13:11:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 171.58333333333334
avg_sample_per_episode: 171.58333333333334
avg_envstep_per_sec: 2646.690059674342
avg_train_sample_per_sec: 2646.690059674342
avg_episode_per_sec: 15.425099910680963
collect_time: 0.7779528216663747
reward_mean: 1788.9588342826598
reward_std: 1380.6316634991904
reward_max: 3654.52724589407
reward_min: 53.70143818024704
total_envstep_count: 17262962
total_train_sample_count: 12970161
total_episode_count: 39655
total_duration: 3513.838542321998
[2023-06-29 13:11:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 510
train_sample_count: 510
avg_envstep_per_episode: 102.0
avg_sample_per_episode: 102.0
avg_envstep_per_sec: 2548.384660257024
avg_train_sample_per_sec: 2548.384660257024
avg_episode_per_sec: 24.984163335853175
collect_time: 0.20012677362002432
reward_mean: 1473.7113462132222
reward_std: 1358.5946076168987
reward_max: 3563.648295149539
reward_min: 21.687295353014825
total_envstep_count: 17266514
total_train_sample_count: 12973471
total_episode_count: 39660
total_duration: 3514.038669095618
[2023-06-29 13:11:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 202.66666666666666
avg_sample_per_episode: 202.66666666666666
avg_envstep_per_sec: 2736.665025207609
avg_train_sample_per_sec: 2736.665025207609
avg_episode_per_sec: 13.503281374379648
collect_time: 0.4443364419098943
reward_mean: 3069.1141927370627
reward_std: 1099.2283296409107
reward_max: 3618.3786337346587
reward_min: 615.0767872358567
total_envstep_count: 17270962
total_train_sample_count: 12976687
total_episode_count: 39666
total_duration: 3514.483005537528
[2023-06-29 13:11:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 433
train_sample_count: 433
avg_envstep_per_episode: 144.33333333333334
avg_sample_per_episode: 144.33333333333334
avg_envstep_per_sec: 2633.792037485211
avg_train_sample_per_sec: 2633.792037485211
avg_episode_per_sec: 18.2479817839622
collect_time: 0.1644017423689365
reward_mean: 3546.356068784558
reward_std: 72.14540228677573
reward_max: 3601.732826132855
reward_min: 3444.4551597272457
total_envstep_count: 17274514
total_train_sample_count: 12979920
total_episode_count: 39669
total_duration: 3514.647407279897
[2023-06-29 13:11:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 1980
train_sample_count: 1980
avg_envstep_per_episode: 152.30769230769232
avg_sample_per_episode: 152.30769230769232
avg_envstep_per_sec: 2497.5449937734097
avg_train_sample_per_sec: 2497.5449937734097
avg_episode_per_sec: 16.398022686391077
collect_time: 0.792778510471806
reward_mean: 1860.052266279656
reward_std: 1523.3092750593987
reward_max: 3651.2834206835414
reward_min: 19.33553082732654
total_envstep_count: 17279090
total_train_sample_count: 12983500
total_episode_count: 39682
total_duration: 3515.4401857903686
[2023-06-29 13:11:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2898
train_sample_count: 2898
avg_envstep_per_episode: 193.2
avg_sample_per_episode: 193.2
avg_envstep_per_sec: 2764.4687885118738
avg_train_sample_per_sec: 2764.4687885118738
avg_episode_per_sec: 14.308844661034545
collect_time: 1.0483026656126606
reward_mean: 1260.491993087829
reward_std: 784.9191808080283
reward_max: 2333.3760353434336
reward_min: 19.9609549037605
total_envstep_count: 17284034
total_train_sample_count: 12986798
total_episode_count: 39697
total_duration: 3516.488488455981
[2023-06-29 13:11:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2540
train_sample_count: 2540
avg_envstep_per_episode: 317.5
avg_sample_per_episode: 317.5
avg_envstep_per_sec: 2529.7069620271163
avg_train_sample_per_sec: 2529.7069620271163
avg_episode_per_sec: 7.967580982762572
collect_time: 1.0040688657332213
reward_mean: 1877.7484106392467
reward_std: 1034.0256867526582
reward_max: 3624.898471881649
reward_min: 52.79478141572379
total_envstep_count: 17288458
total_train_sample_count: 12990138
total_episode_count: 39705
total_duration: 3517.4925573217142
[2023-06-29 13:11:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2739.2506432530754
avg_train_sample_per_sec: 2739.2506432530754
avg_episode_per_sec: 11.319217534103617
collect_time: 0.44172664629295477
reward_mean: 2360.108265045871
reward_std: 1309.6498215738397
reward_max: 3591.982983881388
reward_min: 57.21130953369509
total_envstep_count: 17292562
total_train_sample_count: 12993348
total_episode_count: 39710
total_duration: 3517.934283968007
[2023-06-29 13:11:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 214.6
avg_sample_per_episode: 214.6
avg_envstep_per_sec: 2512.0774187371576
avg_train_sample_per_sec: 2512.0774187371576
avg_episode_per_sec: 11.70585936037818
collect_time: 0.8542730347374454
reward_mean: 1856.37527988111
reward_std: 1192.8659668985226
reward_max: 3595.0279741798017
reward_min: 21.313227240822037
total_envstep_count: 17297282
total_train_sample_count: 12996694
total_episode_count: 39720
total_duration: 3518.7885570027447
[2023-06-29 13:11:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1539
train_sample_count: 1539
avg_envstep_per_episode: 219.85714285714286
avg_sample_per_episode: 219.85714285714286
avg_envstep_per_sec: 2818.2322238620723
avg_train_sample_per_sec: 2818.2322238620723
avg_episode_per_sec: 12.818470154018522
collect_time: 0.5460870069433003
reward_mean: 2006.7583827174628
reward_std: 1226.0956899571852
reward_max: 3580.974845255758
reward_min: 20.12791761573032
total_envstep_count: 17301522
total_train_sample_count: 13000233
total_episode_count: 39727
total_duration: 3519.334644009688
[2023-06-29 13:11:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2969
train_sample_count: 2969
avg_envstep_per_episode: 228.3846153846154
avg_sample_per_episode: 228.3846153846154
avg_envstep_per_sec: 2518.521579139312
avg_train_sample_per_sec: 2518.521579139312
avg_episode_per_sec: 11.027544805931646
collect_time: 1.1788662144457924
reward_mean: 1740.8004637876536
reward_std: 1042.4505177324975
reward_max: 3671.8613020470407
reward_min: 20.018521166080784
total_envstep_count: 17306154
total_train_sample_count: 13003602
total_episode_count: 39740
total_duration: 3520.513510224134
[2023-06-29 13:11:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1726
train_sample_count: 1726
avg_envstep_per_episode: 246.57142857142858
avg_sample_per_episode: 246.57142857142858
avg_envstep_per_sec: 2724.9114449390686
avg_train_sample_per_sec: 2724.9114449390686
avg_episode_per_sec: 11.051205164874554
collect_time: 0.6334150796737524
reward_mean: 1752.2565818101446
reward_std: 360.8678869697976
reward_max: 2347.736845286995
reward_min: 1201.99938852989
total_envstep_count: 17310722
total_train_sample_count: 13006928
total_episode_count: 39747
total_duration: 3521.1469253038076
[2023-06-29 13:11:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2984
train_sample_count: 2984
avg_envstep_per_episode: 298.4
avg_sample_per_episode: 298.4
avg_envstep_per_sec: 2599.0203546700313
avg_train_sample_per_sec: 2599.0203546700313
avg_episode_per_sec: 8.709853735489382
collect_time: 1.1481249058470129
reward_mean: 2094.867612157797
reward_std: 1251.0002608661325
reward_max: 3669.937252760102
reward_min: 17.503608441911062
total_envstep_count: 17315522
total_train_sample_count: 13010312
total_episode_count: 39757
total_duration: 3522.2950502096546
[2023-06-29 13:11:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 350.2857142857143
avg_sample_per_episode: 350.2857142857143
avg_envstep_per_sec: 2586.4714133460043
avg_train_sample_per_sec: 2586.4714133460043
avg_episode_per_sec: 7.383890658002459
collect_time: 0.9480097043979913
reward_mean: 2135.4794454392736
reward_std: 627.3182301210044
reward_max: 3156.689051432883
reward_min: 1445.4829870615742
total_envstep_count: 17319602
total_train_sample_count: 13013564
total_episode_count: 39764
total_duration: 3523.2430599140525
[2023-06-29 13:11:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 2743.227467071486
avg_train_sample_per_sec: 2743.227467071486
avg_episode_per_sec: 9.426898512273148
collect_time: 0.4243177111530676
reward_mean: 1983.0740524981545
reward_std: 723.9668370123028
reward_max: 3186.782213430331
reward_min: 1258.4309368777426
total_envstep_count: 17324066
total_train_sample_count: 13017128
total_episode_count: 39768
total_duration: 3523.6673776252055
[2023-06-29 13:11:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 233.71428571428572
avg_sample_per_episode: 233.71428571428572
avg_envstep_per_sec: 2735.242648042634
avg_train_sample_per_sec: 2735.242648042634
avg_episode_per_sec: 11.703360963507603
collect_time: 0.598118781589903
reward_mean: 2789.2592121220923
reward_std: 806.3210052802068
reward_max: 3656.9801494945987
reward_min: 1740.7000582166272
total_envstep_count: 17328354
total_train_sample_count: 13020364
total_episode_count: 39775
total_duration: 3524.2654964067956
[2023-06-29 13:11:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 854
train_sample_count: 854
avg_envstep_per_episode: 284.6666666666667
avg_sample_per_episode: 284.6666666666667
avg_envstep_per_sec: 2661.624297684124
avg_train_sample_per_sec: 2661.624297684124
avg_episode_per_sec: 9.349968258843527
collect_time: 0.3208567042099309
reward_mean: 3403.0331420018592
reward_std: 209.34867327725365
reward_max: 3552.285200187608
reward_min: 3106.972770834617
total_envstep_count: 17332994
total_train_sample_count: 13023618
total_episode_count: 39778
total_duration: 3524.5863531110053
[2023-06-29 13:11:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2220
train_sample_count: 2220
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2795.9647627321756
avg_train_sample_per_sec: 2795.9647627321756
avg_episode_per_sec: 12.594435868162954
collect_time: 0.794001422904432
reward_mean: 2552.794042714732
reward_std: 1441.7564296855137
reward_max: 3606.254624314329
reward_min: 56.69656980413332
total_envstep_count: 17337874
total_train_sample_count: 13027038
total_episode_count: 39788
total_duration: 3525.3803545339097
[2023-06-29 13:12:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 406.8
avg_sample_per_episode: 406.8
avg_envstep_per_sec: 2777.3471217661518
avg_train_sample_per_sec: 2777.3471217661518
avg_episode_per_sec: 6.827303642492999
collect_time: 0.7323535412838682
reward_mean: 2990.789017070477
reward_std: 846.6338074807804
reward_max: 3641.105897147581
reward_min: 1414.5981684294657
total_envstep_count: 17342794
total_train_sample_count: 13030272
total_episode_count: 39793
total_duration: 3526.1127080751935
[2023-06-29 13:12:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 180.28571428571428
avg_sample_per_episode: 180.28571428571428
avg_envstep_per_sec: 2699.0584250647735
avg_train_sample_per_sec: 2699.0584250647735
avg_episode_per_sec: 14.971005527300644
collect_time: 0.467570463936776
reward_mean: 2166.3140202199943
reward_std: 1469.9573756083817
reward_max: 3604.4432570480126
reward_min: 19.920436479193867
total_envstep_count: 17347554
total_train_sample_count: 13033534
total_episode_count: 39800
total_duration: 3526.58027853913
[2023-06-29 13:12:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 422
train_sample_count: 422
avg_envstep_per_episode: 140.66666666666666
avg_sample_per_episode: 140.66666666666666
avg_envstep_per_sec: 2435.3680506237206
avg_train_sample_per_sec: 2435.3680506237206
avg_episode_per_sec: 17.313043013912704
collect_time: 0.17327976356260477
reward_mean: 3239.861645459618
reward_std: 548.6073846204664
reward_max: 3654.9901966089087
reward_min: 2464.6651754089366
total_envstep_count: 17351898
total_train_sample_count: 13036756
total_episode_count: 39803
total_duration: 3526.753558302693
[2023-06-29 13:12:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1766
train_sample_count: 1766
avg_envstep_per_episode: 220.75
avg_sample_per_episode: 220.75
avg_envstep_per_sec: 2477.590637336988
avg_train_sample_per_sec: 2477.590637336988
avg_episode_per_sec: 11.22351364592067
collect_time: 0.712789261222817
reward_mean: 3172.810372590626
reward_std: 808.7923429948694
reward_max: 3688.916716887214
reward_min: 1101.3397304312423
total_envstep_count: 17356546
total_train_sample_count: 13040122
total_episode_count: 39811
total_duration: 3527.466347563916
[2023-06-29 13:12:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 498
train_sample_count: 498
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 2714.031384634504
avg_train_sample_per_sec: 2714.031384634504
avg_episode_per_sec: 10.899724436283147
collect_time: 0.18349087737873201
reward_mean: 3589.315954189767
reward_std: 30.46095821470817
reward_max: 3619.7769124044753
reward_min: 3558.854995975059
total_envstep_count: 17360194
total_train_sample_count: 13043420
total_episode_count: 39813
total_duration: 3527.6498384412944
[2023-06-29 13:12:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1842
train_sample_count: 1842
avg_envstep_per_episode: 167.45454545454547
avg_sample_per_episode: 167.45454545454547
avg_envstep_per_sec: 2741.306252979706
avg_train_sample_per_sec: 2741.306252979706
avg_episode_per_sec: 16.370449936360895
collect_time: 0.671942435471341
reward_mean: 2199.3156605240533
reward_std: 1431.526127229809
reward_max: 3631.567586699124
reward_min: 51.51172276676449
total_envstep_count: 17364626
total_train_sample_count: 13046862
total_episode_count: 39824
total_duration: 3528.321780876766
[2023-06-29 13:12:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 333.0
avg_sample_per_episode: 333.0
avg_envstep_per_sec: 2764.2054786890294
avg_train_sample_per_sec: 2764.2054786890294
avg_episode_per_sec: 8.300917353420509
collect_time: 0.4818744519064202
reward_mean: 2728.795305618672
reward_std: 1110.7181001291551
reward_max: 3620.868341594345
reward_min: 895.7933420458689
total_envstep_count: 17368994
total_train_sample_count: 13050194
total_episode_count: 39828
total_duration: 3528.8036553286724
[2023-06-29 13:12:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2102
train_sample_count: 2102
avg_envstep_per_episode: 262.75
avg_sample_per_episode: 262.75
avg_envstep_per_sec: 2756.524793180614
avg_train_sample_per_sec: 2756.524793180614
avg_episode_per_sec: 10.491055349878645
collect_time: 0.7625543601857501
reward_mean: 2784.060556964263
reward_std: 876.632192821243
reward_max: 3726.5038769076946
reward_min: 1338.7760390447875
total_envstep_count: 17373858
total_train_sample_count: 13053496
total_episode_count: 39836
total_duration: 3529.566209688858
[2023-06-29 13:12:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3057
train_sample_count: 3057
avg_envstep_per_episode: 277.90909090909093
avg_sample_per_episode: 277.90909090909093
avg_envstep_per_sec: 2822.5971591265907
avg_train_sample_per_sec: 2822.5971591265907
avg_episode_per_sec: 10.15654849538518
collect_time: 1.083045092040673
reward_mean: 1882.3075804294763
reward_std: 681.0324122643278
reward_max: 2531.391893709572
reward_min: 413.6296002117984
total_envstep_count: 17378938
total_train_sample_count: 13056953
total_episode_count: 39847
total_duration: 3530.649254780899
[2023-06-29 13:12:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1482
train_sample_count: 1482
avg_envstep_per_episode: 211.71428571428572
avg_sample_per_episode: 211.71428571428572
avg_envstep_per_sec: 2442.9522234816804
avg_train_sample_per_sec: 2442.9522234816804
avg_episode_per_sec: 11.538910637227909
collect_time: 0.60664305497054
reward_mean: 1635.542532787776
reward_std: 828.831833769057
reward_max: 3414.320127259019
reward_min: 903.3587471110928
total_envstep_count: 17383122
total_train_sample_count: 13060435
total_episode_count: 39854
total_duration: 3531.2558978358693
[2023-06-29 13:12:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2106
train_sample_count: 2106
avg_envstep_per_episode: 263.25
avg_sample_per_episode: 263.25
avg_envstep_per_sec: 2757.9966674734223
avg_train_sample_per_sec: 2757.9966674734223
avg_episode_per_sec: 10.476720484229526
collect_time: 0.7635977319469675
reward_mean: 2479.0789047979933
reward_std: 1221.8470387807401
reward_max: 3771.74000652341
reward_min: 469.25258113174255
total_envstep_count: 17387546
total_train_sample_count: 13063741
total_episode_count: 39862
total_duration: 3532.019495567816
[2023-06-29 13:12:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 201.0
avg_sample_per_episode: 201.0
avg_envstep_per_sec: 2601.0835379637488
avg_train_sample_per_sec: 2601.0835379637488
avg_episode_per_sec: 12.940714119222632
collect_time: 0.4636529286345466
reward_mean: 1186.5893756002622
reward_std: 668.660120776503
reward_max: 2072.5298544248294
reward_min: 49.74631394431641
total_envstep_count: 17390930
total_train_sample_count: 13066947
total_episode_count: 39868
total_duration: 3532.4831484964507
[2023-06-29 13:12:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 124.85714285714286
avg_sample_per_episode: 124.85714285714286
avg_envstep_per_sec: 2785.492771451553
avg_train_sample_per_sec: 2785.492771451553
avg_episode_per_sec: 22.309438672952943
collect_time: 0.313768539971672
reward_mean: 2406.161533443402
reward_std: 1316.8111665189977
reward_max: 3586.204552041422
reward_min: 49.49962295833616
total_envstep_count: 17394746
total_train_sample_count: 13070221
total_episode_count: 39875
total_duration: 3532.796917036422
[2023-06-29 13:12:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1221
train_sample_count: 1221
avg_envstep_per_episode: 407.0
avg_sample_per_episode: 407.0
avg_envstep_per_sec: 2789.5710509355986
avg_train_sample_per_sec: 2789.5710509355986
avg_episode_per_sec: 6.853982926131692
collect_time: 0.43770170313119894
reward_mean: 3171.3805503577623
reward_std: 298.9622383381942
reward_max: 3391.7508641565423
reward_min: 2748.7128763067
total_envstep_count: 17398490
total_train_sample_count: 13073442
total_episode_count: 39878
total_duration: 3533.2346187395533
[2023-06-29 13:12:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 566
train_sample_count: 566
avg_envstep_per_episode: 113.2
avg_sample_per_episode: 113.2
avg_envstep_per_sec: 2058.483565230654
avg_train_sample_per_sec: 2058.483565230654
avg_episode_per_sec: 18.184483791790232
collect_time: 0.2749596885591746
reward_mean: 3290.399755709509
reward_std: 414.6234551959521
reward_max: 3573.4699845884647
reward_min: 2497.3233247383764
total_envstep_count: 17402746
total_train_sample_count: 13076808
total_episode_count: 39883
total_duration: 3533.5095784281125
[2023-06-29 13:12:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1739
train_sample_count: 1739
avg_envstep_per_episode: 248.42857142857142
avg_sample_per_episode: 248.42857142857142
avg_envstep_per_sec: 2386.8025103896653
avg_train_sample_per_sec: 2386.8025103896653
avg_episode_per_sec: 9.607600674368982
collect_time: 0.7285898152152076
reward_mean: 2760.9070436234915
reward_std: 450.08671972100154
reward_max: 3271.732502539145
reward_min: 2140.3184246797223
total_envstep_count: 17407498
total_train_sample_count: 13080147
total_episode_count: 39890
total_duration: 3534.238168243328
[2023-06-29 13:12:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 814
train_sample_count: 814
avg_envstep_per_episode: 162.8
avg_sample_per_episode: 162.8
avg_envstep_per_sec: 2608.4467307694613
avg_train_sample_per_sec: 2608.4467307694613
avg_episode_per_sec: 16.02240006615148
collect_time: 0.3120631103552878
reward_mean: 2170.7557600759837
reward_std: 810.6623207607188
reward_max: 3713.847535645454
reward_min: 1564.0250614774482
total_envstep_count: 17411242
total_train_sample_count: 13083361
total_episode_count: 39895
total_duration: 3534.550231353683
[2023-06-29 13:12:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 252.4
avg_sample_per_episode: 252.4
avg_envstep_per_sec: 2775.4351280468186
avg_train_sample_per_sec: 2775.4351280468186
avg_episode_per_sec: 10.996177210962038
collect_time: 0.4547034759512172
reward_mean: 3488.901444075903
reward_std: 268.2404305602054
reward_max: 3684.6665898700917
reward_min: 2957.7432273765753
total_envstep_count: 17415506
total_train_sample_count: 13086623
total_episode_count: 39900
total_duration: 3535.0049348296343
[2023-06-29 13:12:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1342
train_sample_count: 1342
avg_envstep_per_episode: 335.5
avg_sample_per_episode: 335.5
avg_envstep_per_sec: 2765.990541467778
avg_train_sample_per_sec: 2765.990541467778
avg_episode_per_sec: 8.244383134032125
collect_time: 0.4851788102239371
reward_mean: 3594.5027218416385
reward_std: 22.604728072776094
reward_max: 3627.1894440233764
reward_min: 3563.2920841763894
total_envstep_count: 17420298
total_train_sample_count: 13089965
total_episode_count: 39904
total_duration: 3535.490113639858
[2023-06-29 13:12:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 228.5
avg_sample_per_episode: 228.5
avg_envstep_per_sec: 2691.228601810366
avg_train_sample_per_sec: 2691.228601810366
avg_episode_per_sec: 11.777805697200725
collect_time: 0.5094327546451239
reward_mean: 3224.863315665633
reward_std: 594.9564105766738
reward_max: 3602.059645088404
reward_min: 1954.8521766389517
total_envstep_count: 17424858
total_train_sample_count: 13093336
total_episode_count: 39910
total_duration: 3535.9995463945033
[2023-06-29 13:13:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2279
train_sample_count: 2279
avg_envstep_per_episode: 284.875
avg_sample_per_episode: 284.875
avg_envstep_per_sec: 2430.7027921029903
avg_train_sample_per_sec: 2430.7027921029903
avg_episode_per_sec: 8.53252406179198
collect_time: 0.9375889176595957
reward_mean: 2594.5064199946833
reward_std: 963.0922895329517
reward_max: 3708.3259530443343
reward_min: 1038.642030329622
total_envstep_count: 17430138
total_train_sample_count: 13096815
total_episode_count: 39918
total_duration: 3536.937135312163
[2023-06-29 13:13:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2142
train_sample_count: 2142
avg_envstep_per_episode: 194.72727272727272
avg_sample_per_episode: 194.72727272727272
avg_envstep_per_sec: 2521.514317355314
avg_train_sample_per_sec: 2521.514317355314
avg_episode_per_sec: 12.948953076988072
collect_time: 0.8494895251067356
reward_mean: 1759.07369509895
reward_std: 1085.8272493247962
reward_max: 3616.019617689154
reward_min: 50.217413015339744
total_envstep_count: 17434570
total_train_sample_count: 13100157
total_episode_count: 39929
total_duration: 3537.7866248372698
[2023-06-29 13:13:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 252.875
avg_sample_per_episode: 252.875
avg_envstep_per_sec: 2793.15921295829
avg_train_sample_per_sec: 2793.15921295829
avg_episode_per_sec: 11.045612310265112
collect_time: 0.724269490480423
reward_mean: 1857.9036129734359
reward_std: 917.5080010533928
reward_max: 3596.68670703891
reward_min: 953.8364474143084
total_envstep_count: 17438338
total_train_sample_count: 13103380
total_episode_count: 39937
total_duration: 3538.51089432775
[2023-06-29 13:13:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2892
train_sample_count: 2892
avg_envstep_per_episode: 289.2
avg_sample_per_episode: 289.2
avg_envstep_per_sec: 2698.8539820679107
avg_train_sample_per_sec: 2698.8539820679107
avg_episode_per_sec: 9.33213686745474
collect_time: 1.0715659384373575
reward_mean: 1911.0780738796464
reward_std: 943.0528181626584
reward_max: 3656.5702144528777
reward_min: 974.0257223100903
total_envstep_count: 17443250
total_train_sample_count: 13106672
total_episode_count: 39947
total_duration: 3539.5824602661874
[2023-06-29 13:13:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2463
train_sample_count: 2463
avg_envstep_per_episode: 307.875
avg_sample_per_episode: 307.875
avg_envstep_per_sec: 2526.7487572628215
avg_train_sample_per_sec: 2526.7487572628215
avg_episode_per_sec: 8.207060518921061
collect_time: 0.974770440836437
reward_mean: 1951.2534130588424
reward_std: 821.5325121174463
reward_max: 3263.526513361763
reward_min: 688.6418404076999
total_envstep_count: 17447818
total_train_sample_count: 13109935
total_episode_count: 39955
total_duration: 3540.557230707024
[2023-06-29 13:13:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1677
train_sample_count: 1677
avg_envstep_per_episode: 209.625
avg_sample_per_episode: 209.625
avg_envstep_per_sec: 2804.4211037997297
avg_train_sample_per_sec: 2804.4211037997297
avg_episode_per_sec: 13.378275987118567
collect_time: 0.5979843746460975
reward_mean: 1876.707895493295
reward_std: 764.2359538170826
reward_max: 3603.1764537337135
reward_min: 995.7658624487932
total_envstep_count: 17452434
total_train_sample_count: 13113212
total_episode_count: 39963
total_duration: 3541.1552150816697
[2023-06-29 13:13:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 298.3333333333333
avg_sample_per_episode: 298.3333333333333
avg_envstep_per_sec: 2784.031262036421
avg_train_sample_per_sec: 2784.031262036421
avg_episode_per_sec: 9.331948364367893
collect_time: 0.964428825427778
reward_mean: 2209.4862273287017
reward_std: 622.1571783865581
reward_max: 2940.690934758847
reward_min: 1265.4786499796805
total_envstep_count: 17457026
total_train_sample_count: 13116697
total_episode_count: 39972
total_duration: 3542.1196439070973
[2023-06-29 13:13:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2831
train_sample_count: 2831
avg_envstep_per_episode: 283.1
avg_sample_per_episode: 283.1
avg_envstep_per_sec: 2650.8709454917407
avg_train_sample_per_sec: 2650.8709454917407
avg_episode_per_sec: 9.363726405834477
collect_time: 1.067950895464979
reward_mean: 1877.978579041476
reward_std: 677.7321452496736
reward_max: 3576.3963044037314
reward_min: 1004.0242792873719
total_envstep_count: 17461450
total_train_sample_count: 13119928
total_episode_count: 39982
total_duration: 3543.187594802562
[2023-06-29 13:13:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 343.0
avg_sample_per_episode: 343.0
avg_envstep_per_sec: 2750.7009388595634
avg_train_sample_per_sec: 2750.7009388595634
avg_episode_per_sec: 8.019536264896686
collect_time: 0.6234774474287403
reward_mean: 2001.0472173278395
reward_std: 827.0416881280055
reward_max: 3601.9125903881363
reward_min: 1228.5568779876269
total_envstep_count: 17465626
total_train_sample_count: 13123243
total_episode_count: 39987
total_duration: 3543.811072249991
[2023-06-29 13:13:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2532
train_sample_count: 2532
avg_envstep_per_episode: 281.3333333333333
avg_sample_per_episode: 281.3333333333333
avg_envstep_per_sec: 2564.8119456788822
avg_train_sample_per_sec: 2564.8119456788822
avg_episode_per_sec: 9.116630138669011
collect_time: 0.98720688051451
reward_mean: 2219.885286473903
reward_std: 1010.9768255146267
reward_max: 3666.5615751298274
reward_min: 806.6208877609773
total_envstep_count: 17470098
total_train_sample_count: 13126575
total_episode_count: 39996
total_duration: 3544.7982791305053
[2023-06-29 13:13:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3116
train_sample_count: 3116
avg_envstep_per_episode: 283.27272727272725
avg_sample_per_episode: 283.27272727272725
avg_envstep_per_sec: 2825.0080565321473
avg_train_sample_per_sec: 2825.0080565321473
avg_episode_per_sec: 9.972749878643652
collect_time: 1.1030057039288805
reward_mean: 1812.3649820709759
reward_std: 808.9246295457912
reward_max: 3342.4975854086388
reward_min: 834.1368631336858
total_envstep_count: 17475098
total_train_sample_count: 13130091
total_episode_count: 40007
total_duration: 3545.901284834434
[2023-06-29 13:13:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2674
train_sample_count: 2674
avg_envstep_per_episode: 243.0909090909091
avg_sample_per_episode: 243.0909090909091
avg_envstep_per_sec: 2624.780079914827
avg_train_sample_per_sec: 2624.780079914827
avg_episode_per_sec: 10.797524636897194
collect_time: 1.0187520167734472
reward_mean: 1485.6320825421362
reward_std: 194.8783045275369
reward_max: 1748.4907453440803
reward_min: 1208.5702314105888
total_envstep_count: 17479650
total_train_sample_count: 13133565
total_episode_count: 40018
total_duration: 3546.9200368512074
[2023-06-29 13:13:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2525
train_sample_count: 2525
avg_envstep_per_episode: 280.55555555555554
avg_sample_per_episode: 280.55555555555554
avg_envstep_per_sec: 2563.346064920001
avg_train_sample_per_sec: 2563.346064920001
avg_episode_per_sec: 9.13667904327921
collect_time: 0.9850406211456284
reward_mean: 1844.5491078059556
reward_std: 996.913115658741
reward_max: 3702.632860297839
reward_min: 975.3269217069575
total_envstep_count: 17483714
total_train_sample_count: 13136890
total_episode_count: 40027
total_duration: 3547.9050774723532
[2023-06-29 13:13:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3117
train_sample_count: 3117
avg_envstep_per_episode: 346.3333333333333
avg_sample_per_episode: 346.3333333333333
avg_envstep_per_sec: 2632.985098946744
avg_train_sample_per_sec: 2632.985098946744
avg_episode_per_sec: 7.602459380981937
collect_time: 1.183827436489053
reward_mean: 1986.9514846136653
reward_std: 884.1776336224442
reward_max: 3680.0012799826263
reward_min: 1099.1212896610725
total_envstep_count: 17488226
total_train_sample_count: 13140407
total_episode_count: 40036
total_duration: 3549.0889049088423
[2023-06-29 13:13:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3306
train_sample_count: 3306
avg_envstep_per_episode: 220.4
avg_sample_per_episode: 220.4
avg_envstep_per_sec: 2752.5228021121857
avg_train_sample_per_sec: 2752.5228021121857
avg_episode_per_sec: 12.488760445155107
collect_time: 1.2010799683341755
reward_mean: 1155.5189579790438
reward_std: 705.6041441509766
reward_max: 2440.919769572208
reward_min: 21.4298823728045
total_envstep_count: 17492850
total_train_sample_count: 13143713
total_episode_count: 40051
total_duration: 3550.2899848771767
[2023-06-29 13:13:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 269.25
avg_sample_per_episode: 269.25
avg_envstep_per_sec: 2582.1388795964235
avg_train_sample_per_sec: 2582.1388795964235
avg_episode_per_sec: 9.590116544462111
collect_time: 0.8341921563632784
reward_mean: 1470.9262308975171
reward_std: 408.5624916366767
reward_max: 2320.750025042065
reward_min: 1016.2698890847049
total_envstep_count: 17496962
total_train_sample_count: 13147067
total_episode_count: 40059
total_duration: 3551.12417703354
[2023-06-29 13:13:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 171.33333333333334
avg_sample_per_episode: 171.33333333333334
avg_envstep_per_sec: 2324.920293674365
avg_train_sample_per_sec: 2324.920293674365
avg_episode_per_sec: 13.569573698488512
collect_time: 0.44216569608729334
reward_mean: 2028.0844756613722
reward_std: 1094.5340943955996
reward_max: 3583.037363624044
reward_min: 57.07122776012364
total_envstep_count: 17501458
total_train_sample_count: 13150495
total_episode_count: 40065
total_duration: 3551.566342729627
[2023-06-29 13:13:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 148.0
avg_sample_per_episode: 148.0
avg_envstep_per_sec: 2624.6698436002116
avg_train_sample_per_sec: 2624.6698436002116
avg_episode_per_sec: 17.73425570000143
collect_time: 0.39471631166338916
reward_mean: 2062.279444620911
reward_std: 551.5608592439672
reward_max: 2688.8868862970517
reward_min: 1058.111687947997
total_envstep_count: 17505850
total_train_sample_count: 13153931
total_episode_count: 40072
total_duration: 3551.961059041291
[2023-06-29 13:13:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 273.1111111111111
avg_sample_per_episode: 273.1111111111111
avg_envstep_per_sec: 2779.518871867546
avg_train_sample_per_sec: 2779.518871867546
avg_episode_per_sec: 10.177245665910462
collect_time: 0.8843257100638
reward_mean: 2479.0479859492552
reward_std: 966.7336998934817
reward_max: 3615.1208945281596
reward_min: 1139.9598169355306
total_envstep_count: 17510210
total_train_sample_count: 13157189
total_episode_count: 40081
total_duration: 3552.8453847513547
[2023-06-29 13:13:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 346.57142857142856
avg_sample_per_episode: 346.57142857142856
avg_envstep_per_sec: 2618.2544155817736
avg_train_sample_per_sec: 2618.2544155817736
avg_episode_per_sec: 7.554732443970494
collect_time: 0.9265715300859886
reward_mean: 2459.4710092592213
reward_std: 654.1293221850707
reward_max: 3586.224587032908
reward_min: 1870.6856006585228
total_envstep_count: 17514290
total_train_sample_count: 13160415
total_episode_count: 40088
total_duration: 3553.7719562814405
[2023-06-29 13:14:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1474
train_sample_count: 1474
avg_envstep_per_episode: 294.8
avg_sample_per_episode: 294.8
avg_envstep_per_sec: 2787.0567627346154
avg_train_sample_per_sec: 2787.0567627346154
avg_episode_per_sec: 9.454059575083498
collect_time: 0.5288733332268895
reward_mean: 2139.8131512737305
reward_std: 690.6449064094348
reward_max: 3284.1374722326573
reward_min: 1200.3511965009625
total_envstep_count: 17518810
total_train_sample_count: 13163889
total_episode_count: 40093
total_duration: 3554.3008296146672
[2023-06-29 13:14:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 291.1818181818182
avg_sample_per_episode: 291.1818181818182
avg_envstep_per_sec: 2526.7896480153445
avg_train_sample_per_sec: 2526.7896480153445
avg_episode_per_sec: 8.677704067489476
collect_time: 1.267616401118226
reward_mean: 2197.720872446472
reward_std: 1075.3522667519949
reward_max: 3647.36417417731
reward_min: 768.2127594028304
total_envstep_count: 17523194
total_train_sample_count: 13167092
total_episode_count: 40104
total_duration: 3555.5684460157854
[2023-06-29 13:14:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3463
train_sample_count: 3463
avg_envstep_per_episode: 314.8181818181818
avg_sample_per_episode: 314.8181818181818
avg_envstep_per_sec: 2810.444427988704
avg_train_sample_per_sec: 2810.444427988704
avg_episode_per_sec: 8.927198587316125
collect_time: 1.2321894592586902
reward_mean: 1583.3817871273902
reward_std: 556.5875445929345
reward_max: 2423.8319910578166
reward_min: 764.5040652703709
total_envstep_count: 17528002
total_train_sample_count: 13170555
total_episode_count: 40115
total_duration: 3556.800635475044
[2023-06-29 13:14:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1921
train_sample_count: 1921
avg_envstep_per_episode: 240.125
avg_sample_per_episode: 240.125
avg_envstep_per_sec: 2794.0131144523293
avg_train_sample_per_sec: 2794.0131144523293
avg_episode_per_sec: 11.635661070077374
collect_time: 0.6875415115496143
reward_mean: 1518.2443094360954
reward_std: 467.76055879277476
reward_max: 2502.443207758177
reward_min: 1136.3623813113775
total_envstep_count: 17532786
total_train_sample_count: 13174076
total_episode_count: 40123
total_duration: 3557.4881769865938
[2023-06-29 13:14:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2371
train_sample_count: 2371
avg_envstep_per_episode: 237.1
avg_sample_per_episode: 237.1
avg_envstep_per_sec: 2570.4525660561517
avg_train_sample_per_sec: 2570.4525660561517
avg_episode_per_sec: 10.841217064766562
collect_time: 0.9224056616760791
reward_mean: 1897.3637864061798
reward_std: 1087.3710062813616
reward_max: 3740.4938536575833
reward_min: 63.86536464188473
total_envstep_count: 17537490
total_train_sample_count: 13177647
total_episode_count: 40133
total_duration: 3558.41058264827
[2023-06-29 13:14:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2354
train_sample_count: 2354
avg_envstep_per_episode: 336.2857142857143
avg_sample_per_episode: 336.2857142857143
avg_envstep_per_sec: 2561.9473818819224
avg_train_sample_per_sec: 2561.9473818819224
avg_episode_per_sec: 7.618365196760177
collect_time: 0.9188322979025545
reward_mean: 2499.24389614622
reward_std: 849.1879000148517
reward_max: 3636.380005126456
reward_min: 1162.2819855304929
total_envstep_count: 17542258
total_train_sample_count: 13181201
total_episode_count: 40140
total_duration: 3559.3294149461726
[2023-06-29 13:14:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1299
train_sample_count: 1299
avg_envstep_per_episode: 259.8
avg_sample_per_episode: 259.8
avg_envstep_per_sec: 2794.126586439375
avg_train_sample_per_sec: 2794.126586439375
avg_episode_per_sec: 10.754913727634237
collect_time: 0.4649037757646292
reward_mean: 2288.5014865211533
reward_std: 1094.6374077042428
reward_max: 3625.2758567544593
reward_min: 1202.9773240349768
total_envstep_count: 17546410
total_train_sample_count: 13184500
total_episode_count: 40145
total_duration: 3559.794318721937
[2023-06-29 13:14:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 160.16666666666666
avg_sample_per_episode: 160.16666666666666
avg_envstep_per_sec: 2784.014567800743
avg_train_sample_per_sec: 2784.014567800743
avg_episode_per_sec: 17.381984814572796
collect_time: 0.34518497536424547
reward_mean: 2398.127264090645
reward_std: 1007.2625730018173
reward_max: 3709.438552521231
reward_min: 1092.851567412086
total_envstep_count: 17550874
total_train_sample_count: 13187861
total_episode_count: 40151
total_duration: 3560.1395036973013
[2023-06-29 13:14:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1781
train_sample_count: 1781
avg_envstep_per_episode: 222.625
avg_sample_per_episode: 222.625
avg_envstep_per_sec: 2509.2614553398294
avg_train_sample_per_sec: 2509.2614553398294
avg_episode_per_sec: 11.271247413093
collect_time: 0.7097705965274946
reward_mean: 2440.869609777087
reward_std: 995.2765254096496
reward_max: 3652.829241767161
reward_min: 1044.3396193154467
total_envstep_count: 17554978
total_train_sample_count: 13191242
total_episode_count: 40159
total_duration: 3560.849274293829
[2023-06-29 13:14:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2768
train_sample_count: 2768
avg_envstep_per_episode: 307.55555555555554
avg_sample_per_episode: 307.55555555555554
avg_envstep_per_sec: 2609.328895768008
avg_train_sample_per_sec: 2609.328895768008
avg_episode_per_sec: 8.4840896177428
collect_time: 1.0608091622674842
reward_mean: 2226.278001826606
reward_std: 1156.54773701573
reward_max: 3598.7020284940427
reward_min: 799.0168013701858
total_envstep_count: 17560042
total_train_sample_count: 13194810
total_episode_count: 40168
total_duration: 3561.9100834560963
[2023-06-29 13:14:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2404
train_sample_count: 2404
avg_envstep_per_episode: 300.5
avg_sample_per_episode: 300.5
avg_envstep_per_sec: 2729.966108277566
avg_train_sample_per_sec: 2729.966108277566
avg_episode_per_sec: 9.084745784617525
collect_time: 0.8805970128020272
reward_mean: 1962.4291619553014
reward_std: 963.2757862116875
reward_max: 3611.459310828452
reward_min: 948.8085649500497
total_envstep_count: 17564266
total_train_sample_count: 13198014
total_episode_count: 40176
total_duration: 3562.7906804688982
[2023-06-29 13:14:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1793
train_sample_count: 1793
avg_envstep_per_episode: 199.22222222222223
avg_sample_per_episode: 199.22222222222223
avg_envstep_per_sec: 2733.9996564063563
avg_train_sample_per_sec: 2733.9996564063563
avg_episode_per_sec: 13.723366931208703
collect_time: 0.6558157371375709
reward_mean: 1740.8620760398976
reward_std: 987.9616054025877
reward_max: 3635.217875099797
reward_min: 991.744057496946
total_envstep_count: 17568330
total_train_sample_count: 13201407
total_episode_count: 40185
total_duration: 3563.4464962060356
[2023-06-29 13:14:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3433
train_sample_count: 3433
avg_envstep_per_episode: 228.86666666666667
avg_sample_per_episode: 228.86666666666667
avg_envstep_per_sec: 2584.167354423761
avg_train_sample_per_sec: 2584.167354423761
avg_episode_per_sec: 11.29114777639278
collect_time: 1.3284743320215493
reward_mean: 1444.9176776828062
reward_std: 612.486946738234
reward_max: 2572.054411585858
reward_min: 23.369921709285755
total_envstep_count: 17573562
total_train_sample_count: 13204840
total_episode_count: 40200
total_duration: 3564.774970538057
[2023-06-29 13:14:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2473
train_sample_count: 2473
avg_envstep_per_episode: 206.08333333333334
avg_sample_per_episode: 206.08333333333334
avg_envstep_per_sec: 2570.6903475717986
avg_train_sample_per_sec: 2570.6903475717986
avg_episode_per_sec: 12.474033227198376
collect_time: 0.9619983995100483
reward_mean: 1319.9319949563933
reward_std: 374.6587166153248
reward_max: 2028.8446762409383
reward_min: 728.2538506656762
total_envstep_count: 17577882
total_train_sample_count: 13208113
total_episode_count: 40212
total_duration: 3565.736968937567
[2023-06-29 13:14:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3272
train_sample_count: 3272
avg_envstep_per_episode: 251.69230769230768
avg_sample_per_episode: 251.69230769230768
avg_envstep_per_sec: 2593.1864111684467
avg_train_sample_per_sec: 2593.1864111684467
avg_episode_per_sec: 10.30300224486241
collect_time: 1.2617681420464066
reward_mean: 1456.3748278841895
reward_std: 533.8588470228427
reward_max: 2261.730206198122
reward_min: 677.689231086343
total_envstep_count: 17582546
total_train_sample_count: 13211385
total_episode_count: 40225
total_duration: 3566.9987370796134
[2023-06-29 13:14:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2871
train_sample_count: 2871
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2738.2898265915314
avg_train_sample_per_sec: 2738.2898265915314
avg_episode_per_sec: 10.491531902649546
collect_time: 1.048464619091712
reward_mean: 1461.0869318605075
reward_std: 438.86745653852176
reward_max: 2577.3608084001244
reward_min: 959.1035380783572
total_envstep_count: 17586562
total_train_sample_count: 13214656
total_episode_count: 40236
total_duration: 3568.047201698705
[2023-06-29 13:14:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2625
train_sample_count: 2625
avg_envstep_per_episode: 291.6666666666667
avg_sample_per_episode: 291.6666666666667
avg_envstep_per_sec: 2610.649407906082
avg_train_sample_per_sec: 2610.649407906082
avg_episode_per_sec: 8.95079796996371
collect_time: 1.0054969434235246
reward_mean: 1421.2795282089378
reward_std: 791.7417481937753
reward_max: 3249.7937617953044
reward_min: 411.4006788043668
total_envstep_count: 17591362
total_train_sample_count: 13218081
total_episode_count: 40245
total_duration: 3569.0526986421287
[2023-06-29 13:14:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2526
train_sample_count: 2526
avg_envstep_per_episode: 229.63636363636363
avg_sample_per_episode: 229.63636363636363
avg_envstep_per_sec: 2588.5364289746067
avg_train_sample_per_sec: 2588.5364289746067
avg_episode_per_sec: 11.272328075503038
collect_time: 0.9758410087358209
reward_mean: 1694.3161854540035
reward_std: 876.1115951546587
reward_max: 3743.0378334759616
reward_min: 793.7520253493217
total_envstep_count: 17595658
total_train_sample_count: 13221407
total_episode_count: 40256
total_duration: 3570.0285396508643
[2023-06-29 13:14:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2570
train_sample_count: 2570
avg_envstep_per_episode: 214.16666666666666
avg_sample_per_episode: 214.16666666666666
avg_envstep_per_sec: 2577.681898787832
avg_train_sample_per_sec: 2577.681898787832
avg_episode_per_sec: 12.03586878811439
collect_time: 0.9970198422111571
reward_mean: 1347.4621047259984
reward_std: 554.1875039662134
reward_max: 2889.2002474353535
reward_min: 635.2900144131994
total_envstep_count: 17600450
total_train_sample_count: 13224777
total_episode_count: 40268
total_duration: 3571.0255594930754
[2023-06-29 13:15:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 184.9090909090909
avg_sample_per_episode: 184.9090909090909
avg_envstep_per_sec: 2712.027950108095
avg_train_sample_per_sec: 2712.027950108095
avg_episode_per_sec: 14.666817822610149
collect_time: 0.749992270514369
reward_mean: 1388.387045634625
reward_std: 598.5893766351056
reward_max: 2489.756113881924
reward_min: 769.2115472644729
total_envstep_count: 17604794
total_train_sample_count: 13228011
total_episode_count: 40279
total_duration: 3571.7755517635896
[2023-06-29 13:15:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1681
train_sample_count: 1681
avg_envstep_per_episode: 186.77777777777777
avg_sample_per_episode: 186.77777777777777
avg_envstep_per_sec: 2466.64268266944
avg_train_sample_per_sec: 2466.64268266944
avg_episode_per_sec: 13.20629633790896
collect_time: 0.6814931128090247
reward_mean: 1619.0790035252744
reward_std: 752.1604699790807
reward_max: 2724.95598498179
reward_min: 21.541911611306457
total_envstep_count: 17609074
total_train_sample_count: 13231292
total_episode_count: 40288
total_duration: 3572.457044876399
[2023-06-29 13:15:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2459
train_sample_count: 2459
avg_envstep_per_episode: 245.9
avg_sample_per_episode: 245.9
avg_envstep_per_sec: 2568.7266641096744
avg_train_sample_per_sec: 2568.7266641096744
avg_episode_per_sec: 10.446224742210958
collect_time: 0.9572836356461049
reward_mean: 1962.704050358468
reward_std: 812.5205472831391
reward_max: 3149.5959568835387
reward_min: 703.4777775544482
total_envstep_count: 17613530
total_train_sample_count: 13234551
total_episode_count: 40298
total_duration: 3573.414328512045
[2023-06-29 13:15:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2298
train_sample_count: 2298
avg_envstep_per_episode: 229.8
avg_sample_per_episode: 229.8
avg_envstep_per_sec: 2737.2912913712667
avg_train_sample_per_sec: 2737.2912913712667
avg_episode_per_sec: 11.911624418499855
collect_time: 0.8395160599984226
reward_mean: 1552.7046212815571
reward_std: 772.2890877180549
reward_max: 3596.79817483874
reward_min: 386.0621135444242
total_envstep_count: 17618754
total_train_sample_count: 13238049
total_episode_count: 40308
total_duration: 3574.2538445720434
[2023-06-29 13:15:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2980
train_sample_count: 2980
avg_envstep_per_episode: 331.1111111111111
avg_sample_per_episode: 331.1111111111111
avg_envstep_per_sec: 2822.503269668836
avg_train_sample_per_sec: 2822.503269668836
avg_episode_per_sec: 8.52433873389917
collect_time: 1.0558003712603823
reward_mean: 2357.464931249332
reward_std: 1009.0254774360786
reward_max: 3589.409452341264
reward_min: 645.9716206472807
total_envstep_count: 17623650
total_train_sample_count: 13241429
total_episode_count: 40317
total_duration: 3575.3096449433037
[2023-06-29 13:15:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3113
train_sample_count: 3113
avg_envstep_per_episode: 283.0
avg_sample_per_episode: 283.0
avg_envstep_per_sec: 2580.6548320282714
avg_train_sample_per_sec: 2580.6548320282714
avg_episode_per_sec: 9.118921667944422
collect_time: 1.2062829795619474
reward_mean: 1709.0950586698686
reward_std: 904.7597020988504
reward_max: 3616.306742986414
reward_min: 641.8511450572176
total_envstep_count: 17628354
total_train_sample_count: 13244942
total_episode_count: 40328
total_duration: 3576.5159279228656
[2023-06-29 13:15:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2719
train_sample_count: 2719
avg_envstep_per_episode: 247.1818181818182
avg_sample_per_episode: 247.1818181818182
avg_envstep_per_sec: 2742.761919714715
avg_train_sample_per_sec: 2742.761919714715
avg_episode_per_sec: 11.096131341251144
collect_time: 0.9913364993352444
reward_mean: 1458.419419859625
reward_std: 461.2650841882735
reward_max: 2802.525265848
reward_min: 885.3210132823831
total_envstep_count: 17633242
total_train_sample_count: 13248461
total_episode_count: 40339
total_duration: 3577.507264422201
[2023-06-29 13:15:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2700
train_sample_count: 2700
avg_envstep_per_episode: 245.45454545454547
avg_sample_per_episode: 245.45454545454547
avg_envstep_per_sec: 2789.1623497244454
avg_train_sample_per_sec: 2789.1623497244454
avg_episode_per_sec: 11.363254017395889
collect_time: 0.9680325708780436
reward_mean: 1658.6330706617105
reward_std: 543.7688361553187
reward_max: 2750.505409263166
reward_min: 873.0174984949299
total_envstep_count: 17638266
total_train_sample_count: 13251961
total_episode_count: 40350
total_duration: 3578.475296993079
[2023-06-29 13:15:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2144
train_sample_count: 2144
avg_envstep_per_episode: 306.2857142857143
avg_sample_per_episode: 306.2857142857143
avg_envstep_per_sec: 2828.1263499036236
avg_train_sample_per_sec: 2828.1263499036236
avg_episode_per_sec: 9.233621478230114
collect_time: 0.7580990856625139
reward_mean: 2013.5413411820566
reward_std: 795.3384857911527
reward_max: 3128.378439707419
reward_min: 999.2307654732243
total_envstep_count: 17642762
total_train_sample_count: 13255305
total_episode_count: 40357
total_duration: 3579.233396078742
[2023-06-29 13:15:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1617
train_sample_count: 1617
avg_envstep_per_episode: 202.125
avg_sample_per_episode: 202.125
avg_envstep_per_sec: 2510.1188121728114
avg_train_sample_per_sec: 2510.1188121728114
avg_episode_per_sec: 12.418645947670063
collect_time: 0.6441926143728196
reward_mean: 2138.330515533771
reward_std: 902.2814975740217
reward_max: 3761.759598868093
reward_min: 1325.5905590259472
total_envstep_count: 17647074
total_train_sample_count: 13258522
total_episode_count: 40365
total_duration: 3579.877588693115
[2023-06-29 13:15:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2568
train_sample_count: 2568
avg_envstep_per_episode: 256.8
avg_sample_per_episode: 256.8
avg_envstep_per_sec: 2627.4522666735247
avg_train_sample_per_sec: 2627.4522666735247
avg_episode_per_sec: 10.231511941875096
collect_time: 0.9773726558508352
reward_mean: 1954.9402531673136
reward_std: 781.2879898504599
reward_max: 3556.179781994037
reward_min: 940.1030068196094
total_envstep_count: 17651994
total_train_sample_count: 13261890
total_episode_count: 40375
total_duration: 3580.854961348966
[2023-06-29 13:15:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2785
train_sample_count: 2785
avg_envstep_per_episode: 278.5
avg_sample_per_episode: 278.5
avg_envstep_per_sec: 2576.447994701989
avg_train_sample_per_sec: 2576.447994701989
avg_episode_per_sec: 9.251159765536766
collect_time: 1.0809455520650373
reward_mean: 1776.871446987645
reward_std: 622.098778372206
reward_max: 3207.995759146946
reward_min: 1187.8841929830128
total_envstep_count: 17656602
total_train_sample_count: 13265475
total_episode_count: 40385
total_duration: 3581.935906901031
[2023-06-29 13:15:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2861
train_sample_count: 2861
avg_envstep_per_episode: 286.1
avg_sample_per_episode: 286.1
avg_envstep_per_sec: 2632.7444949728683
avg_train_sample_per_sec: 2632.7444949728683
avg_episode_per_sec: 9.20218278564442
collect_time: 1.086698692358099
reward_mean: 1878.6185305972617
reward_std: 804.7580319693253
reward_max: 3672.1982582655014
reward_min: 764.6538897451596
total_envstep_count: 17661170
total_train_sample_count: 13268736
total_episode_count: 40395
total_duration: 3583.022605593389
[2023-06-29 13:15:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 253.6
avg_sample_per_episode: 253.6
avg_envstep_per_sec: 2763.671278250007
avg_train_sample_per_sec: 2763.671278250007
avg_episode_per_sec: 10.897757406348608
collect_time: 0.45880999306216846
reward_mean: 1649.424522837849
reward_std: 706.0974395210267
reward_max: 2614.233165243949
reward_min: 832.8471955345733
total_envstep_count: 17665514
total_train_sample_count: 13272004
total_episode_count: 40400
total_duration: 3583.481415586451
[2023-06-29 13:15:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2022
train_sample_count: 2022
avg_envstep_per_episode: 183.8181818181818
avg_sample_per_episode: 183.8181818181818
avg_envstep_per_sec: 2640.2709562476825
avg_train_sample_per_sec: 2640.2709562476825
avg_episode_per_sec: 14.363491849023001
collect_time: 0.7658304899409412
reward_mean: 1962.0711311572827
reward_std: 795.2706024808259
reward_max: 3650.378561798644
reward_min: 1130.975486392083
total_envstep_count: 17669530
total_train_sample_count: 13275226
total_episode_count: 40411
total_duration: 3584.247246076392
[2023-06-29 13:15:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2098
train_sample_count: 2098
avg_envstep_per_episode: 349.6666666666667
avg_sample_per_episode: 349.6666666666667
avg_envstep_per_sec: 2743.833415707937
avg_train_sample_per_sec: 2743.833415707937
avg_episode_per_sec: 7.846997375713834
collect_time: 0.7646236786786469
reward_mean: 2439.2262850787265
reward_std: 823.6858019732335
reward_max: 3640.2009731653047
reward_min: 1411.5347831290878
total_envstep_count: 17673722
total_train_sample_count: 13278524
total_episode_count: 40417
total_duration: 3585.0118697550706
[2023-06-29 13:15:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2506
train_sample_count: 2506
avg_envstep_per_episode: 358.0
avg_sample_per_episode: 358.0
avg_envstep_per_sec: 2757.1287024335215
avg_train_sample_per_sec: 2757.1287024335215
avg_episode_per_sec: 7.7014768224400045
collect_time: 0.9089165833238513
reward_mean: 2445.959922669431
reward_std: 1057.0265818899065
reward_max: 3634.315612524642
reward_min: 704.9979137376619
total_envstep_count: 17678418
total_train_sample_count: 13281830
total_episode_count: 40424
total_duration: 3585.9207863383945
[2023-06-29 13:15:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2904
train_sample_count: 2904
avg_envstep_per_episode: 363.0
avg_sample_per_episode: 363.0
avg_envstep_per_sec: 2546.6642455934402
avg_train_sample_per_sec: 2546.6642455934402
avg_episode_per_sec: 7.015603982351075
collect_time: 1.1403152202041817
reward_mean: 2224.817928829571
reward_std: 911.2659305630362
reward_max: 3670.2700957984703
reward_min: 1026.945608121543
total_envstep_count: 17683002
total_train_sample_count: 13285134
total_episode_count: 40432
total_duration: 3587.0611015585987
[2023-06-29 13:15:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1867
train_sample_count: 1867
avg_envstep_per_episode: 233.375
avg_sample_per_episode: 233.375
avg_envstep_per_sec: 2627.6624776355957
avg_train_sample_per_sec: 2627.6624776355957
avg_episode_per_sec: 11.259400011293394
collect_time: 0.7105174336088821
reward_mean: 1694.3024559155795
reward_std: 831.4604091540018
reward_max: 3596.4870797406074
reward_min: 895.5908803088661
total_envstep_count: 17687410
total_train_sample_count: 13288601
total_episode_count: 40440
total_duration: 3587.7716189922076
[2023-06-29 13:16:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2357
train_sample_count: 2357
avg_envstep_per_episode: 294.625
avg_sample_per_episode: 294.625
avg_envstep_per_sec: 2556.9020576501002
avg_train_sample_per_sec: 2556.9020576501002
avg_episode_per_sec: 8.678496589393637
collect_time: 0.9218186488403006
reward_mean: 2337.71764161006
reward_std: 977.6784985941399
reward_max: 3761.3743908843485
reward_min: 1121.1952829935897
total_envstep_count: 17692170
total_train_sample_count: 13292158
total_episode_count: 40448
total_duration: 3588.6934376410477
[2023-06-29 13:16:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2042
train_sample_count: 2042
avg_envstep_per_episode: 340.3333333333333
avg_sample_per_episode: 340.3333333333333
avg_envstep_per_sec: 2781.2176869782693
avg_train_sample_per_sec: 2781.2176869782693
avg_episode_per_sec: 8.172040216390606
collect_time: 0.7342107773730532
reward_mean: 2392.129949316835
reward_std: 1023.2563608275077
reward_max: 3579.9462198685196
reward_min: 846.0952556442202
total_envstep_count: 17696482
total_train_sample_count: 13295400
total_episode_count: 40454
total_duration: 3589.4276484184206
[2023-06-29 13:16:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2124
train_sample_count: 2124
avg_envstep_per_episode: 265.5
avg_sample_per_episode: 265.5
avg_envstep_per_sec: 2569.7641820268586
avg_train_sample_per_sec: 2569.7641820268586
avg_episode_per_sec: 9.678961137577621
collect_time: 0.8265349851381034
reward_mean: 2147.1938828915845
reward_std: 890.9772051948261
reward_max: 3597.472634810589
reward_min: 858.0031103327314
total_envstep_count: 17700730
total_train_sample_count: 13298724
total_episode_count: 40462
total_duration: 3590.2541834035587
[2023-06-29 13:16:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1197
train_sample_count: 1197
avg_envstep_per_episode: 199.5
avg_sample_per_episode: 199.5
avg_envstep_per_sec: 2364.5594000481924
avg_train_sample_per_sec: 2364.5594000481924
avg_episode_per_sec: 11.852428070417005
collect_time: 0.5062253881106153
reward_mean: 2077.589883662256
reward_std: 934.6715248772089
reward_max: 3604.820163123767
reward_min: 972.9390344377917
total_envstep_count: 17705338
total_train_sample_count: 13302321
total_episode_count: 40468
total_duration: 3590.7604087916693
[2023-06-29 13:16:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1509
train_sample_count: 1509
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2727.814073064223
avg_train_sample_per_sec: 2727.814073064223
avg_episode_per_sec: 10.84617921695516
collect_time: 0.5531901953658087
reward_mean: 2856.471023134953
reward_std: 839.469802773161
reward_max: 3763.4383352866435
reward_min: 1642.043969997636
total_envstep_count: 17709482
total_train_sample_count: 13305830
total_episode_count: 40474
total_duration: 3591.313598987035
[2023-06-29 13:16:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1959
train_sample_count: 1959
avg_envstep_per_episode: 326.5
avg_sample_per_episode: 326.5
avg_envstep_per_sec: 2668.2059119340283
avg_train_sample_per_sec: 2668.2059119340283
avg_episode_per_sec: 8.172146744055217
collect_time: 0.7342012066002934
reward_mean: 2871.70290724879
reward_std: 930.9271153188299
reward_max: 3677.240298019967
reward_min: 1040.8011964368018
total_envstep_count: 17714826
total_train_sample_count: 13309389
total_episode_count: 40480
total_duration: 3592.0478001936353
[2023-06-29 13:16:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2708.135483915439
avg_train_sample_per_sec: 2708.135483915439
avg_episode_per_sec: 13.21041699470946
collect_time: 0.3784891878888011
reward_mean: 2841.0748643122124
reward_std: 683.576228868782
reward_max: 3625.2554229228626
reward_min: 1971.8358263962427
total_envstep_count: 17719562
total_train_sample_count: 13312814
total_episode_count: 40485
total_duration: 3592.426289381524
[2023-06-29 13:16:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2181
train_sample_count: 2181
avg_envstep_per_episode: 218.1
avg_sample_per_episode: 218.1
avg_envstep_per_sec: 2541.9258396095543
avg_train_sample_per_sec: 2541.9258396095543
avg_episode_per_sec: 11.654864005545871
collect_time: 0.8580108695598321
reward_mean: 2461.6485310922108
reward_std: 1012.0801447836299
reward_max: 3610.776622971433
reward_min: 818.7133168185723
total_envstep_count: 17724570
total_train_sample_count: 13316195
total_episode_count: 40495
total_duration: 3593.2843002510836
[2023-06-29 13:16:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2252
train_sample_count: 2252
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 2550.4886462150066
avg_train_sample_per_sec: 2550.4886462150066
avg_episode_per_sec: 9.06035043060393
collect_time: 0.8829680552948268
reward_mean: 2368.335684402892
reward_std: 667.9083684946371
reward_max: 3394.1867728450397
reward_min: 1318.7668372753312
total_envstep_count: 17729226
total_train_sample_count: 13319647
total_episode_count: 40503
total_duration: 3594.1672683063784
[2023-06-29 13:16:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 166.5
avg_sample_per_episode: 166.5
avg_envstep_per_sec: 2768.4675578866722
avg_train_sample_per_sec: 2768.4675578866722
avg_episode_per_sec: 16.627432780100136
collect_time: 0.481132602116093
reward_mean: 1339.281200209843
reward_std: 595.6778533170767
reward_max: 1973.514627168455
reward_min: 54.14171799793162
total_envstep_count: 17733642
total_train_sample_count: 13322979
total_episode_count: 40511
total_duration: 3594.6484009084948
[2023-06-29 13:16:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1697
train_sample_count: 1697
avg_envstep_per_episode: 188.55555555555554
avg_sample_per_episode: 188.55555555555554
avg_envstep_per_sec: 2782.032512367967
avg_train_sample_per_sec: 2782.032512367967
avg_episode_per_sec: 14.75444467372522
collect_time: 0.6099856822146101
reward_mean: 2273.3368877678568
reward_std: 1149.1559193672924
reward_max: 3756.97144038047
reward_min: 648.7455259656155
total_envstep_count: 17737866
total_train_sample_count: 13326276
total_episode_count: 40520
total_duration: 3595.2583865907095
[2023-06-29 13:16:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2456
train_sample_count: 2456
avg_envstep_per_episode: 272.8888888888889
avg_sample_per_episode: 272.8888888888889
avg_envstep_per_sec: 2740.185608500392
avg_train_sample_per_sec: 2740.185608500392
avg_episode_per_sec: 10.041396773820654
collect_time: 0.8962896500080821
reward_mean: 2061.7774467983563
reward_std: 586.2132988256201
reward_max: 2765.9086068402808
reward_min: 1009.9347569221037
total_envstep_count: 17742322
total_train_sample_count: 13329532
total_episode_count: 40529
total_duration: 3596.1546762407174
[2023-06-29 13:16:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2205
train_sample_count: 2205
avg_envstep_per_episode: 367.5
avg_sample_per_episode: 367.5
avg_envstep_per_sec: 2491.6207192751463
avg_train_sample_per_sec: 2491.6207192751463
avg_episode_per_sec: 6.779920324558221
collect_time: 0.884966151927598
reward_mean: 2332.2110434522388
reward_std: 576.8442510341115
reward_max: 3098.439846720987
reward_min: 1261.4636315670587
total_envstep_count: 17746954
total_train_sample_count: 13332937
total_episode_count: 40535
total_duration: 3597.039642392645
[2023-06-29 13:16:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3022
train_sample_count: 3022
avg_envstep_per_episode: 302.2
avg_sample_per_episode: 302.2
avg_envstep_per_sec: 2602.076581209401
avg_train_sample_per_sec: 2602.076581209401
avg_episode_per_sec: 8.610445338217739
collect_time: 1.1613801153367385
reward_mean: 2166.6821515781107
reward_std: 813.654579967228
reward_max: 3617.678100677491
reward_min: 1251.7448772731875
total_envstep_count: 17752250
total_train_sample_count: 13336359
total_episode_count: 40545
total_duration: 3598.2010225079816
[2023-06-29 13:16:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2301
train_sample_count: 2301
avg_envstep_per_episode: 287.625
avg_sample_per_episode: 287.625
avg_envstep_per_sec: 2460.493839840529
avg_train_sample_per_sec: 2460.493839840529
avg_episode_per_sec: 8.55452008636429
collect_time: 0.9351781186126171
reward_mean: 2011.2858135734896
reward_std: 736.5626582245163
reward_max: 3735.090760408682
reward_min: 1318.69479631128
total_envstep_count: 17757226
total_train_sample_count: 13339860
total_episode_count: 40553
total_duration: 3599.1362006265945
[2023-06-29 13:16:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2105
train_sample_count: 2105
avg_envstep_per_episode: 263.125
avg_sample_per_episode: 263.125
avg_envstep_per_sec: 2684.073082428932
avg_train_sample_per_sec: 2684.073082428932
avg_episode_per_sec: 10.200752807330858
collect_time: 0.784255843769759
reward_mean: 2113.796600828897
reward_std: 788.1472728548738
reward_max: 3518.631622331054
reward_min: 1254.717169767246
total_envstep_count: 17761418
total_train_sample_count: 13343165
total_episode_count: 40561
total_duration: 3599.920456470364
[2023-06-29 13:16:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2019
train_sample_count: 2019
avg_envstep_per_episode: 224.33333333333334
avg_sample_per_episode: 224.33333333333334
avg_envstep_per_sec: 2466.12347415419
avg_train_sample_per_sec: 2466.12347415419
avg_episode_per_sec: 10.9931209843426
collect_time: 0.8186938006794082
reward_mean: 1921.3420770120756
reward_std: 778.6978177806445
reward_max: 3408.50454218637
reward_min: 958.4527942653524
total_envstep_count: 17765626
total_train_sample_count: 13346384
total_episode_count: 40570
total_duration: 3600.7391502710434
[2023-06-29 13:16:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2153
train_sample_count: 2153
avg_envstep_per_episode: 239.22222222222223
avg_sample_per_episode: 239.22222222222223
avg_envstep_per_sec: 2664.3659040878797
avg_train_sample_per_sec: 2664.3659040878797
avg_episode_per_sec: 11.137618735156023
collect_time: 0.8080721933487807
reward_mean: 1811.6834615617745
reward_std: 537.4502830778174
reward_max: 3037.042704120873
reward_min: 1041.2517138029018
total_envstep_count: 17770026
total_train_sample_count: 13349737
total_episode_count: 40579
total_duration: 3601.5472224643922
[2023-06-29 13:16:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 141.85714285714286
avg_sample_per_episode: 141.85714285714286
avg_envstep_per_sec: 2744.219717567344
avg_train_sample_per_sec: 2744.219717567344
avg_episode_per_sec: 19.344952691814107
collect_time: 0.36185149229969826
reward_mean: 1654.2459155218844
reward_std: 384.430519199343
reward_max: 2063.617252617954
reward_min: 890.2315819206109
total_envstep_count: 17774426
total_train_sample_count: 13353130
total_episode_count: 40586
total_duration: 3601.909073956692
[2023-06-29 13:16:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 213.125
avg_sample_per_episode: 213.125
avg_envstep_per_sec: 2714.204855149925
avg_train_sample_per_sec: 2714.204855149925
avg_episode_per_sec: 12.735272047624282
collect_time: 0.6281766082486138
reward_mean: 2213.960646171582
reward_std: 795.0618092144832
reward_max: 3592.338233955859
reward_min: 1185.4400437570425
total_envstep_count: 17779010
total_train_sample_count: 13356835
total_episode_count: 40594
total_duration: 3602.53725056494
[2023-06-29 13:17:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1322
train_sample_count: 1322
avg_envstep_per_episode: 220.33333333333334
avg_sample_per_episode: 220.33333333333334
avg_envstep_per_sec: 2418.2539042139565
avg_train_sample_per_sec: 2418.2539042139565
avg_episode_per_sec: 10.97543375588785
collect_time: 0.5466754329213874
reward_mean: 2694.8427719492815
reward_std: 859.0856635338586
reward_max: 3593.9228057321716
reward_min: 1512.0014870779726
total_envstep_count: 17783330
total_train_sample_count: 13360157
total_episode_count: 40600
total_duration: 3603.0839259978616
[2023-06-29 13:17:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1695
train_sample_count: 1695
avg_envstep_per_episode: 169.5
avg_sample_per_episode: 169.5
avg_envstep_per_sec: 2752.496053067937
avg_train_sample_per_sec: 2752.496053067937
avg_episode_per_sec: 16.23891476736246
collect_time: 0.6158046977436171
reward_mean: 1868.0149379708394
reward_std: 543.6953136400638
reward_max: 3081.6844183806006
reward_min: 1209.4420664081426
total_envstep_count: 17787250
total_train_sample_count: 13363452
total_episode_count: 40610
total_duration: 3603.699730695605
[2023-06-29 13:17:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2495
train_sample_count: 2495
avg_envstep_per_episode: 311.875
avg_sample_per_episode: 311.875
avg_envstep_per_sec: 2810.9771908274665
avg_train_sample_per_sec: 2810.9771908274665
avg_episode_per_sec: 9.013153317282459
collect_time: 0.8875916916513817
reward_mean: 2208.3060029066673
reward_std: 541.7771403476296
reward_max: 3290.967501577878
reward_min: 1565.945872298947
total_envstep_count: 17791402
total_train_sample_count: 13366747
total_episode_count: 40618
total_duration: 3604.5873223872563
[2023-06-29 13:17:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2376
train_sample_count: 2376
avg_envstep_per_episode: 339.42857142857144
avg_sample_per_episode: 339.42857142857144
avg_envstep_per_sec: 2795.5340683777385
avg_train_sample_per_sec: 2795.5340683777385
avg_episode_per_sec: 8.236001043200408
collect_time: 0.8499270414467901
reward_mean: 2072.8436448480907
reward_std: 356.45503201889596
reward_max: 2833.6168106305513
reward_min: 1597.8949139770377
total_envstep_count: 17796066
total_train_sample_count: 13370323
total_episode_count: 40625
total_duration: 3605.437249428703
[2023-06-29 13:17:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2779
train_sample_count: 2779
avg_envstep_per_episode: 252.63636363636363
avg_sample_per_episode: 252.63636363636363
avg_envstep_per_sec: 2520.382512136044
avg_train_sample_per_sec: 2520.382512136044
avg_episode_per_sec: 9.976325164986141
collect_time: 1.1026104119587687
reward_mean: 1729.901141468421
reward_std: 700.1137129624419
reward_max: 3061.2720724526325
reward_min: 61.29547906073618
total_envstep_count: 17800626
total_train_sample_count: 13373902
total_episode_count: 40636
total_duration: 3606.539859840662
[2023-06-29 13:17:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3047
train_sample_count: 3047
avg_envstep_per_episode: 304.7
avg_sample_per_episode: 304.7
avg_envstep_per_sec: 2554.9641846306386
avg_train_sample_per_sec: 2554.9641846306386
avg_episode_per_sec: 8.385179470399207
collect_time: 1.1925803180839865
reward_mean: 1840.2546053697188
reward_std: 699.5923253610537
reward_max: 3137.292387732328
reward_min: 1244.6921736451939
total_envstep_count: 17805346
total_train_sample_count: 13377349
total_episode_count: 40646
total_duration: 3607.7324401587457
[2023-06-29 13:17:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2045
train_sample_count: 2045
avg_envstep_per_episode: 292.14285714285717
avg_sample_per_episode: 292.14285714285717
avg_envstep_per_sec: 2760.179184468496
avg_train_sample_per_sec: 2760.179184468496
avg_episode_per_sec: 9.448046108205121
collect_time: 0.7408939287373795
reward_mean: 1781.5332685423014
reward_std: 473.8939653769789
reward_max: 2481.116129174436
reward_min: 1098.2189727104321
total_envstep_count: 17809698
total_train_sample_count: 13380594
total_episode_count: 40653
total_duration: 3608.473334087483
[2023-06-29 13:17:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1948
train_sample_count: 1948
avg_envstep_per_episode: 243.5
avg_sample_per_episode: 243.5
avg_envstep_per_sec: 2789.5394583323687
avg_train_sample_per_sec: 2789.5394583323687
avg_episode_per_sec: 11.456014202596997
collect_time: 0.6983231565989554
reward_mean: 2150.931698201909
reward_std: 739.7355058551605
reward_max: 3443.6750530852682
reward_min: 1558.5015182057994
total_envstep_count: 17814522
total_train_sample_count: 13384142
total_episode_count: 40661
total_duration: 3609.1716572440823
[2023-06-29 13:17:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2146
train_sample_count: 2146
avg_envstep_per_episode: 268.25
avg_sample_per_episode: 268.25
avg_envstep_per_sec: 2783.191817853186
avg_train_sample_per_sec: 2783.191817853186
avg_episode_per_sec: 10.375365583795661
collect_time: 0.7710571676138788
reward_mean: 2283.749004176434
reward_std: 733.6368665607489
reward_max: 3572.346179180805
reward_min: 1389.0017162488293
total_envstep_count: 17818770
total_train_sample_count: 13387488
total_episode_count: 40669
total_duration: 3609.942714411696
[2023-06-29 13:17:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2449
train_sample_count: 2449
avg_envstep_per_episode: 306.125
avg_sample_per_episode: 306.125
avg_envstep_per_sec: 2660.2290582048126
avg_train_sample_per_sec: 2660.2290582048126
avg_episode_per_sec: 8.69000917339261
collect_time: 0.9205974171459674
reward_mean: 2147.1137860157833
reward_std: 752.3295601585438
reward_max: 3273.676430715005
reward_min: 1180.6720528048652
total_envstep_count: 17823242
total_train_sample_count: 13390737
total_episode_count: 40677
total_duration: 3610.863311828842
[2023-06-29 13:17:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2364
train_sample_count: 2364
avg_envstep_per_episode: 295.5
avg_sample_per_episode: 295.5
avg_envstep_per_sec: 2580.1055377931566
avg_train_sample_per_sec: 2580.1055377931566
avg_episode_per_sec: 8.731321616897315
collect_time: 0.9162415898777543
reward_mean: 1895.8839819534228
reward_std: 679.6246173976491
reward_max: 3229.4749506724775
reward_min: 1039.156188772157
total_envstep_count: 17827714
total_train_sample_count: 13394301
total_episode_count: 40685
total_duration: 3611.77955341872
[2023-06-29 13:17:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2228
train_sample_count: 2228
avg_envstep_per_episode: 278.5
avg_sample_per_episode: 278.5
avg_envstep_per_sec: 2800.1356732212507
avg_train_sample_per_sec: 2800.1356732212507
avg_episode_per_sec: 10.05434712108169
collect_time: 0.7956757314680145
reward_mean: 2214.7470716366824
reward_std: 772.6028529793666
reward_max: 3769.9231493543443
reward_min: 1364.1756474733766
total_envstep_count: 17832826
total_train_sample_count: 13397729
total_episode_count: 40693
total_duration: 3612.575229150188
[2023-06-29 13:17:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2698
train_sample_count: 2698
avg_envstep_per_episode: 299.77777777777777
avg_sample_per_episode: 299.77777777777777
avg_envstep_per_sec: 2823.771063584228
avg_train_sample_per_sec: 2823.771063584228
avg_episode_per_sec: 9.419547654654579
collect_time: 0.9554598936131223
reward_mean: 2358.46870869984
reward_std: 752.0527406804836
reward_max: 3607.387842270066
reward_min: 1430.34079759756
total_envstep_count: 17837770
total_train_sample_count: 13401227
total_episode_count: 40702
total_duration: 3613.530689043801
[2023-06-29 13:17:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1852
train_sample_count: 1852
avg_envstep_per_episode: 308.6666666666667
avg_sample_per_episode: 308.6666666666667
avg_envstep_per_sec: 2443.079580345283
avg_train_sample_per_sec: 2443.079580345283
avg_episode_per_sec: 7.914944644747138
collect_time: 0.7580596288796515
reward_mean: 2250.4425428760374
reward_std: 633.1367853572875
reward_max: 3368.5015110149284
reward_min: 1245.604324559433
total_envstep_count: 17843058
total_train_sample_count: 13404679
total_episode_count: 40708
total_duration: 3614.2887486726804
[2023-06-29 13:17:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1400
train_sample_count: 1400
avg_envstep_per_episode: 175.0
avg_sample_per_episode: 175.0
avg_envstep_per_sec: 2386.8406321890448
avg_train_sample_per_sec: 2386.8406321890448
avg_episode_per_sec: 13.639089326794542
collect_time: 0.586549424842
reward_mean: 2439.920441546547
reward_std: 862.7119165479297
reward_max: 3571.4485582320567
reward_min: 1442.224121008294
total_envstep_count: 17847346
total_train_sample_count: 13408079
total_episode_count: 40716
total_duration: 3614.8752980975223
[2023-06-29 13:17:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2867
train_sample_count: 2867
avg_envstep_per_episode: 358.375
avg_sample_per_episode: 358.375
avg_envstep_per_sec: 2722.5653604228987
avg_train_sample_per_sec: 2722.5653604228987
avg_episode_per_sec: 7.596973450778929
collect_time: 1.0530509355906394
reward_mean: 2650.3206314919335
reward_std: 823.4255551289557
reward_max: 3581.764859936075
reward_min: 1553.1885701637602
total_envstep_count: 17852146
total_train_sample_count: 13411346
total_episode_count: 40724
total_duration: 3615.928349033113
[2023-06-29 13:17:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1841
train_sample_count: 1841
avg_envstep_per_episode: 368.2
avg_sample_per_episode: 368.2
avg_envstep_per_sec: 2795.6270321268853
avg_train_sample_per_sec: 2795.6270321268853
avg_episode_per_sec: 7.592686127449444
collect_time: 0.6585284728053962
reward_mean: 2513.9233709171376
reward_std: 1037.593094869983
reward_max: 3654.7940161588144
reward_min: 1093.5683435561614
total_envstep_count: 17857234
total_train_sample_count: 13414787
total_episode_count: 40729
total_duration: 3616.5868775059184
[2023-06-29 13:17:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 755
train_sample_count: 755
avg_envstep_per_episode: 151.0
avg_sample_per_episode: 151.0
avg_envstep_per_sec: 2697.0463248913
avg_train_sample_per_sec: 2697.0463248913
avg_episode_per_sec: 17.861233939677483
collect_time: 0.2799358665188775
reward_mean: 2845.140118241017
reward_std: 763.433660154503
reward_max: 3613.718632443707
reward_min: 1857.0671180629108
total_envstep_count: 17861594
total_train_sample_count: 13418342
total_episode_count: 40734
total_duration: 3616.8668133724373
[2023-06-29 13:17:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 308.625
avg_sample_per_episode: 308.625
avg_envstep_per_sec: 2719.7350673312294
avg_train_sample_per_sec: 2719.7350673312294
avg_episode_per_sec: 8.812426301599771
collect_time: 0.9078090103911238
reward_mean: 3043.52808761102
reward_std: 704.1084470738755
reward_max: 3646.5224141034637
reward_min: 1613.7385113751982
total_envstep_count: 17866394
total_train_sample_count: 13421611
total_episode_count: 40742
total_duration: 3617.7746223828285
[2023-06-29 13:18:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1909
train_sample_count: 1909
avg_envstep_per_episode: 318.1666666666667
avg_sample_per_episode: 318.1666666666667
avg_envstep_per_sec: 2663.3984103265007
avg_train_sample_per_sec: 2663.3984103265007
avg_episode_per_sec: 8.371079340994763
collect_time: 0.716753450253047
reward_mean: 2354.320593687268
reward_std: 685.2794922922409
reward_max: 3537.8750399792734
reward_min: 1331.4407580402603
total_envstep_count: 17870874
total_train_sample_count: 13425120
total_episode_count: 40748
total_duration: 3618.4913758330817
[2023-06-29 13:18:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2142
train_sample_count: 2142
avg_envstep_per_episode: 306.0
avg_sample_per_episode: 306.0
avg_envstep_per_sec: 2717.3424658066856
avg_train_sample_per_sec: 2717.3424658066856
avg_episode_per_sec: 8.880204136623156
collect_time: 0.7882701672511174
reward_mean: 2686.393255505688
reward_std: 813.1400417635026
reward_max: 3617.050193966086
reward_min: 1330.7286009298903
total_envstep_count: 17875626
total_train_sample_count: 13428462
total_episode_count: 40755
total_duration: 3619.279646000333
[2023-06-29 13:18:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 222.75
avg_sample_per_episode: 222.75
avg_envstep_per_sec: 2737.8490495569213
avg_train_sample_per_sec: 2737.8490495569213
avg_episode_per_sec: 12.291129290940162
collect_time: 0.32543795653898255
reward_mean: 2419.7184588296873
reward_std: 1081.6056093878408
reward_max: 3646.880786628181
reward_min: 993.5316939075581
total_envstep_count: 17879754
total_train_sample_count: 13431753
total_episode_count: 40759
total_duration: 3619.605083956872
[2023-06-29 13:18:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2456
train_sample_count: 2456
avg_envstep_per_episode: 307.0
avg_sample_per_episode: 307.0
avg_envstep_per_sec: 2519.879572069487
avg_train_sample_per_sec: 2519.879572069487
avg_episode_per_sec: 8.2080767819853
collect_time: 0.9746497520050035
reward_mean: 3014.10693914724
reward_std: 716.6968858164281
reward_max: 3598.683967484574
reward_min: 1371.0142906191495
total_envstep_count: 17884554
total_train_sample_count: 13435009
total_episode_count: 40767
total_duration: 3620.579733708877
[2023-06-29 13:18:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 808
train_sample_count: 808
avg_envstep_per_episode: 269.3333333333333
avg_sample_per_episode: 269.3333333333333
avg_envstep_per_sec: 2858.6196251602846
avg_train_sample_per_sec: 2858.6196251602846
avg_episode_per_sec: 10.613686727080264
collect_time: 0.28265390501357623
reward_mean: 2749.4659227891093
reward_std: 589.4780182700272
reward_max: 3563.187238493348
reward_min: 2185.698552805993
total_envstep_count: 17889026
total_train_sample_count: 13438217
total_episode_count: 40770
total_duration: 3620.8623876138904
[2023-06-29 13:18:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1126
train_sample_count: 1126
avg_envstep_per_episode: 187.66666666666666
avg_sample_per_episode: 187.66666666666666
avg_envstep_per_sec: 2810.3421642827066
avg_train_sample_per_sec: 2810.3421642827066
avg_episode_per_sec: 14.975180271488668
collect_time: 0.40066295638680455
reward_mean: 3182.3030616586752
reward_std: 547.0216697304234
reward_max: 3580.986430259313
reward_min: 2190.7373637671385
total_envstep_count: 17893722
total_train_sample_count: 13441743
total_episode_count: 40776
total_duration: 3621.2630505702773
[2023-06-29 13:18:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1282
train_sample_count: 1282
avg_envstep_per_episode: 320.5
avg_sample_per_episode: 320.5
avg_envstep_per_sec: 2779.203846980794
avg_train_sample_per_sec: 2779.203846980794
avg_episode_per_sec: 8.67146286109452
collect_time: 0.4612831841725856
reward_mean: 3363.2158033136448
reward_std: 281.6125651297976
reward_max: 3564.24781458851
reward_min: 2877.544020895608
total_envstep_count: 17897938
total_train_sample_count: 13445025
total_episode_count: 40780
total_duration: 3621.72433375445
[2023-06-29 13:18:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 557
train_sample_count: 557
avg_envstep_per_episode: 111.4
avg_sample_per_episode: 111.4
avg_envstep_per_sec: 2745.124615758622
avg_train_sample_per_sec: 2745.124615758622
avg_episode_per_sec: 24.64205220609176
collect_time: 0.20290517843980344
reward_mean: 3312.56365293278
reward_std: 490.32706572317613
reward_max: 3697.858416674083
reward_min: 2343.279056703182
total_envstep_count: 17902626
total_train_sample_count: 13448382
total_episode_count: 40785
total_duration: 3621.92723893289
[2023-06-29 13:18:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2212
train_sample_count: 2212
avg_envstep_per_episode: 368.6666666666667
avg_sample_per_episode: 368.6666666666667
avg_envstep_per_sec: 2707.1366440461175
avg_train_sample_per_sec: 2707.1366440461175
avg_episode_per_sec: 7.343046954917136
collect_time: 0.8170995006347074
reward_mean: 3555.320098981739
reward_std: 18.46407687048865
reward_max: 3578.0570006339276
reward_min: 3528.132621280004
total_envstep_count: 17906818
total_train_sample_count: 13451794
total_episode_count: 40791
total_duration: 3622.7443384335247
[2023-06-29 13:18:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 190
train_sample_count: 190
avg_envstep_per_episode: 95.0
avg_sample_per_episode: 95.0
avg_envstep_per_sec: 2721.198014711686
avg_train_sample_per_sec: 2721.198014711686
avg_episode_per_sec: 28.644189628544062
collect_time: 0.06982218823209406
reward_mean: 3542.2669387771602
reward_std: 22.03144314468568
reward_max: 3564.2983819218457
reward_min: 3520.2354956324743
total_envstep_count: 17910930
total_train_sample_count: 13455184
total_episode_count: 40793
total_duration: 3622.814160621757
[2023-06-29 13:18:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2113
train_sample_count: 2113
avg_envstep_per_episode: 301.85714285714283
avg_sample_per_episode: 301.85714285714283
avg_envstep_per_sec: 2591.7374528734313
avg_train_sample_per_sec: 2591.7374528734313
avg_episode_per_sec: 8.585973577905357
collect_time: 0.8152831984031946
reward_mean: 3148.86379489899
reward_std: 633.4586193963033
reward_max: 3580.0438447701094
reward_min: 1981.9400803436195
total_envstep_count: 17915298
total_train_sample_count: 13458497
total_episode_count: 40800
total_duration: 3623.62944382016
[2023-06-29 13:18:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 70
train_sample_count: 70
avg_envstep_per_episode: 35.0
avg_sample_per_episode: 35.0
avg_envstep_per_sec: 2643.329641675505
avg_train_sample_per_sec: 2643.329641675505
avg_episode_per_sec: 75.52370404787158
collect_time: 0.026481751990504555
reward_mean: 3545.5075511022587
reward_std: 17.209443977123556
reward_max: 3562.7169950793823
reward_min: 3528.298107125135
total_envstep_count: 17918930
total_train_sample_count: 13461767
total_episode_count: 40802
total_duration: 3623.6559255721504
[2023-06-29 13:18:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 285.8333333333333
avg_sample_per_episode: 285.8333333333333
avg_envstep_per_sec: 2655.93304435647
avg_train_sample_per_sec: 2655.93304435647
avg_episode_per_sec: 9.291894032734005
collect_time: 0.645724109515548
reward_mean: 3358.9895217599446
reward_std: 449.3486407640331
reward_max: 3584.2663722343846
reward_min: 2354.719225379897
total_envstep_count: 17923298
total_train_sample_count: 13465082
total_episode_count: 40808
total_duration: 3624.301649681666
[2023-06-29 13:18:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 70
train_sample_count: 70
avg_envstep_per_episode: 35.0
avg_sample_per_episode: 35.0
avg_envstep_per_sec: 2655.0032582283825
avg_train_sample_per_sec: 2655.0032582283825
avg_episode_per_sec: 75.85723594938236
collect_time: 0.02636531604360789
reward_mean: 3548.2260410442786
reward_std: 1.7855963349957165
reward_max: 3550.0116373792744
reward_min: 3546.440444709283
total_envstep_count: 17926930
total_train_sample_count: 13468352
total_episode_count: 40810
total_duration: 3624.3280149977095
[2023-06-29 13:18:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2316
train_sample_count: 2316
avg_envstep_per_episode: 257.3333333333333
avg_sample_per_episode: 257.3333333333333
avg_envstep_per_sec: 2544.014852448375
avg_train_sample_per_sec: 2544.014852448375
avg_episode_per_sec: 9.886068079462598
collect_time: 0.9103720435323196
reward_mean: 3003.1688266592296
reward_std: 795.0290082080411
reward_max: 3579.412352396377
reward_min: 1101.102726968295
total_envstep_count: 17931794
total_train_sample_count: 13471868
total_episode_count: 40819
total_duration: 3625.238387041242
[2023-06-29 13:18:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 686
train_sample_count: 686
avg_envstep_per_episode: 228.66666666666666
avg_sample_per_episode: 228.66666666666666
avg_envstep_per_sec: 2781.102539746207
avg_train_sample_per_sec: 2781.102539746207
avg_episode_per_sec: 12.162256004721023
collect_time: 0.24666476341523233
reward_mean: 2543.744092310873
reward_std: 536.1924970592218
reward_max: 3258.202400409241
reward_min: 1966.4795198722431
total_envstep_count: 17935954
total_train_sample_count: 13475354
total_episode_count: 40822
total_duration: 3625.485051804657
[2023-06-29 13:18:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1638
train_sample_count: 1638
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 2763.1298206476285
avg_train_sample_per_sec: 2763.1298206476285
avg_episode_per_sec: 11.808247096784736
collect_time: 0.5928060229960828
reward_mean: 3244.5602282867526
reward_std: 687.7582144351188
reward_max: 3598.671096426224
reward_min: 1587.4553867783345
total_envstep_count: 17940754
total_train_sample_count: 13478592
total_episode_count: 40829
total_duration: 3626.077857827653
[2023-06-29 13:18:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 402.8
avg_sample_per_episode: 402.8
avg_envstep_per_sec: 2820.9111934369666
avg_train_sample_per_sec: 2820.9111934369666
avg_episode_per_sec: 7.003255197211933
collect_time: 0.7139537056982517
reward_mean: 3268.679605711956
reward_std: 609.3638457159982
reward_max: 3596.4440815199
reward_min: 2050.537146497716
total_envstep_count: 17944554
total_train_sample_count: 13481806
total_episode_count: 40834
total_duration: 3626.7918115333514
[2023-06-29 13:18:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1609
train_sample_count: 1609
avg_envstep_per_episode: 321.8
avg_sample_per_episode: 321.8
avg_envstep_per_sec: 2673.6688840598113
avg_train_sample_per_sec: 2673.6688840598113
avg_episode_per_sec: 8.308480062336269
collect_time: 0.6017947882749141
reward_mean: 2809.076384462427
reward_std: 835.7667261751188
reward_max: 3572.583242058464
reward_min: 1559.350178035547
total_envstep_count: 17948754
total_train_sample_count: 13485015
total_episode_count: 40839
total_duration: 3627.3936063216265
[2023-06-29 13:18:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2428
train_sample_count: 2428
avg_envstep_per_episode: 346.85714285714283
avg_sample_per_episode: 346.85714285714283
avg_envstep_per_sec: 2574.665554707432
avg_train_sample_per_sec: 2574.665554707432
avg_episode_per_sec: 7.422841385070851
collect_time: 0.943035104330629
reward_mean: 2779.9325440597127
reward_std: 816.4926798990663
reward_max: 3608.5798758004507
reward_min: 1755.7629614572284
total_envstep_count: 17952658
total_train_sample_count: 13488243
total_episode_count: 40846
total_duration: 3628.336641425957
[2023-06-29 13:19:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 406.5
avg_sample_per_episode: 406.5
avg_envstep_per_sec: 2760.275561172674
avg_train_sample_per_sec: 2760.275561172674
avg_episode_per_sec: 6.790345783942618
collect_time: 0.5890716212801634
reward_mean: 2216.8750367851508
reward_std: 960.7574337625215
reward_max: 3632.434993035576
reward_min: 991.3874319959842
total_envstep_count: 17957250
total_train_sample_count: 13491469
total_episode_count: 40850
total_duration: 3628.9257130472374
[2023-06-29 13:19:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 173.57142857142858
avg_sample_per_episode: 173.57142857142858
avg_envstep_per_sec: 2708.666561512244
avg_train_sample_per_sec: 2708.666561512244
avg_episode_per_sec: 15.605486362621981
collect_time: 0.44856019462272523
reward_mean: 2376.899884595779
reward_std: 1218.5730526667367
reward_max: 3697.7515449434472
reward_min: 704.7096285150079
total_envstep_count: 17961194
total_train_sample_count: 13494684
total_episode_count: 40857
total_duration: 3629.37427324186
[2023-06-29 13:19:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2118
train_sample_count: 2118
avg_envstep_per_episode: 302.57142857142856
avg_sample_per_episode: 302.57142857142856
avg_envstep_per_sec: 2537.9529805553193
avg_train_sample_per_sec: 2537.9529805553193
avg_episode_per_sec: 8.387946583516165
collect_time: 0.834530827098526
reward_mean: 2679.335954809473
reward_std: 584.7382256105655
reward_max: 3408.342965944635
reward_min: 1398.238954543339
total_envstep_count: 17966282
total_train_sample_count: 13498002
total_episode_count: 40864
total_duration: 3630.2088040689587
[2023-06-29 13:19:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2406
train_sample_count: 2406
avg_envstep_per_episode: 401.0
avg_sample_per_episode: 401.0
avg_envstep_per_sec: 2774.1340215442115
avg_train_sample_per_sec: 2774.1340215442115
avg_episode_per_sec: 6.9180399539755895
collect_time: 0.8672976796776058
reward_mean: 3089.407629201338
reward_std: 554.5337119553324
reward_max: 3611.7055529431636
reward_min: 2254.408620841702
total_envstep_count: 17971250
total_train_sample_count: 13501208
total_episode_count: 40870
total_duration: 3631.076101748636
[2023-06-29 13:19:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 183.625
avg_sample_per_episode: 183.625
avg_envstep_per_sec: 2763.122542665156
avg_train_sample_per_sec: 2763.122542665156
avg_episode_per_sec: 15.047638081226172
collect_time: 0.5316448971470819
reward_mean: 2033.1407961506636
reward_std: 981.4865614348105
reward_max: 3669.581064464728
reward_min: 1060.3525717952978
total_envstep_count: 17975666
total_train_sample_count: 13504677
total_episode_count: 40878
total_duration: 3631.607746645783
[2023-06-29 13:19:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 366
train_sample_count: 366
avg_envstep_per_episode: 91.5
avg_sample_per_episode: 91.5
avg_envstep_per_sec: 2681.760575865763
avg_train_sample_per_sec: 2681.760575865763
avg_episode_per_sec: 29.308858752631288
collect_time: 0.13647750783339144
reward_mean: 2253.7898222605313
reward_std: 266.3972831135494
reward_max: 2454.469473520475
reward_min: 1796.0800373492705
total_envstep_count: 17980034
total_train_sample_count: 13508243
total_episode_count: 40882
total_duration: 3631.7442241536164
[2023-06-29 13:19:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 254.75
avg_sample_per_episode: 254.75
avg_envstep_per_sec: 2635.831440678966
avg_train_sample_per_sec: 2635.831440678966
avg_episode_per_sec: 10.346737745550406
collect_time: 0.7731905646724625
reward_mean: 2972.992699135426
reward_std: 814.0987706296586
reward_max: 3588.6513974426257
reward_min: 1235.2883619393672
total_envstep_count: 17984042
total_train_sample_count: 13511481
total_episode_count: 40890
total_duration: 3632.517414718289
[2023-06-29 13:19:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 562
train_sample_count: 562
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2719.9988583141912
avg_train_sample_per_sec: 2719.9988583141912
avg_episode_per_sec: 9.679711239552281
collect_time: 0.20661773378402004
reward_mean: 3576.3576744178854
reward_std: 3.366471650694166
reward_max: 3579.7241460685796
reward_min: 3572.991202767191
total_envstep_count: 17988034
total_train_sample_count: 13514843
total_episode_count: 40892
total_duration: 3632.724032452073
[2023-06-29 13:19:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2378
train_sample_count: 2378
avg_envstep_per_episode: 297.25
avg_sample_per_episode: 297.25
avg_envstep_per_sec: 2828.026161798843
avg_train_sample_per_sec: 2828.026161798843
avg_episode_per_sec: 9.513965220517553
collect_time: 0.840869165965356
reward_mean: 3044.4542612491377
reward_std: 757.582016926741
reward_max: 3691.8564840443255
reward_min: 1503.6147715225509
total_envstep_count: 17993026
total_train_sample_count: 13518421
total_episode_count: 40900
total_duration: 3633.564901618038
[2023-06-29 13:19:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1647
train_sample_count: 1647
avg_envstep_per_episode: 329.4
avg_sample_per_episode: 329.4
avg_envstep_per_sec: 2723.8265687183516
avg_train_sample_per_sec: 2723.8265687183516
avg_episode_per_sec: 8.269054549843204
collect_time: 0.6046640483336524
reward_mean: 2630.845289302978
reward_std: 617.3197992628166
reward_max: 3513.1981958023625
reward_min: 1923.904302928433
total_envstep_count: 17997162
total_train_sample_count: 13521668
total_episode_count: 40905
total_duration: 3634.169565666372
[2023-06-29 13:19:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1340
train_sample_count: 1340
avg_envstep_per_episode: 335.0
avg_sample_per_episode: 335.0
avg_envstep_per_sec: 2397.458690625364
avg_train_sample_per_sec: 2397.458690625364
avg_episode_per_sec: 7.15659310634437
collect_time: 0.5589251674031841
reward_mean: 3572.016472603367
reward_std: 12.424470097698782
reward_max: 3588.4138306927907
reward_min: 3558.0506048979037
total_envstep_count: 18001962
total_train_sample_count: 13525008
total_episode_count: 40909
total_duration: 3634.728490833775
[2023-06-29 13:19:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 285.8333333333333
avg_sample_per_episode: 285.8333333333333
avg_envstep_per_sec: 2457.3105596580367
avg_train_sample_per_sec: 2457.3105596580367
avg_episode_per_sec: 8.597004873439197
collect_time: 0.6979174826964737
reward_mean: 3351.085402099658
reward_std: 251.01479410928644
reward_max: 3635.45847031995
reward_min: 2974.1089656489944
total_envstep_count: 18006266
total_train_sample_count: 13528323
total_episode_count: 40915
total_duration: 3635.4264083164717
[2023-06-29 13:19:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 416.3333333333333
avg_sample_per_episode: 416.3333333333333
avg_envstep_per_sec: 2559.9998132197297
avg_train_sample_per_sec: 2559.9998132197297
avg_episode_per_sec: 6.148918686676693
collect_time: 0.9757813211940229
reward_mean: 3017.510854877615
reward_std: 763.0723084710569
reward_max: 3662.3140872421463
reward_min: 1541.2728876252795
total_envstep_count: 18011066
total_train_sample_count: 13531621
total_episode_count: 40921
total_duration: 3636.4021896376657
[2023-06-29 13:19:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 144
train_sample_count: 144
avg_envstep_per_episode: 48.0
avg_sample_per_episode: 48.0
avg_envstep_per_sec: 2693.4821851997426
avg_train_sample_per_sec: 2693.4821851997426
avg_episode_per_sec: 56.11421219166131
collect_time: 0.053462391840294006
reward_mean: 2619.247187483676
reward_std: 783.8234538838199
reward_max: 3589.8865191936893
reward_min: 1670.2861989548862
total_envstep_count: 18014946
total_train_sample_count: 13534965
total_episode_count: 40924
total_duration: 3636.455652029506
[2023-06-29 13:19:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2004
train_sample_count: 2004
avg_envstep_per_episode: 334.0
avg_sample_per_episode: 334.0
avg_envstep_per_sec: 2475.6373647205696
avg_train_sample_per_sec: 2475.6373647205696
avg_episode_per_sec: 7.412087918325059
collect_time: 0.809488509326242
reward_mean: 3369.4696083139206
reward_std: 463.4422483243286
reward_max: 3591.4868904752248
reward_min: 2333.5037030643102
total_envstep_count: 18019346
total_train_sample_count: 13538169
total_episode_count: 40930
total_duration: 3637.2651405388324
[2023-06-29 13:19:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 483
train_sample_count: 483
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 2711.5575055931154
avg_train_sample_per_sec: 2711.5575055931154
avg_episode_per_sec: 16.841972084429287
collect_time: 0.1781264085322618
reward_mean: 3195.9267917288685
reward_std: 533.2325071776954
reward_max: 3603.944624209665
reward_min: 2442.6943814992096
total_envstep_count: 18022946
total_train_sample_count: 13541452
total_episode_count: 40933
total_duration: 3637.4432669473645
[2023-06-29 13:19:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1827
train_sample_count: 1827
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2812.0477128014113
avg_train_sample_per_sec: 2812.0477128014113
avg_episode_per_sec: 10.7741291678215
collect_time: 0.6497044810736552
reward_mean: 3158.089958179841
reward_std: 602.2796166609915
reward_max: 3741.3139210240265
reward_min: 2147.8305560123363
total_envstep_count: 18027682
total_train_sample_count: 13544879
total_episode_count: 40940
total_duration: 3638.092971428438
[2023-06-29 13:19:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1847
train_sample_count: 1847
avg_envstep_per_episode: 307.8333333333333
avg_sample_per_episode: 307.8333333333333
avg_envstep_per_sec: 2611.7131446557005
avg_train_sample_per_sec: 2611.7131446557005
avg_episode_per_sec: 8.484179138026096
collect_time: 0.7071986461374908
reward_mean: 2591.02169091805
reward_std: 797.1418599178706
reward_max: 3597.8960052137154
reward_min: 1433.7340083218367
total_envstep_count: 18032242
total_train_sample_count: 13548326
total_episode_count: 40946
total_duration: 3638.8001700745754
[2023-06-29 13:19:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1149
train_sample_count: 1149
avg_envstep_per_episode: 191.5
avg_sample_per_episode: 191.5
avg_envstep_per_sec: 2627.599906951123
avg_train_sample_per_sec: 2627.599906951123
avg_episode_per_sec: 13.721148339170355
collect_time: 0.4372811846127733
reward_mean: 2640.354272755482
reward_std: 821.2422521776658
reward_max: 3634.9433708519086
reward_min: 1532.9429827118033
total_envstep_count: 18036730
total_train_sample_count: 13551875
total_episode_count: 40952
total_duration: 3639.237451259188
[2023-06-29 13:19:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 312.25
avg_sample_per_episode: 312.25
avg_envstep_per_sec: 2674.6531821115186
avg_train_sample_per_sec: 2674.6531821115186
avg_episode_per_sec: 8.565742776978443
collect_time: 0.9339528641346843
reward_mean: 2819.460939251275
reward_std: 698.7816185491736
reward_max: 3581.4217450197193
reward_min: 1167.14101550304
total_envstep_count: 18041402
total_train_sample_count: 13555173
total_episode_count: 40960
total_duration: 3640.171404123323
[2023-06-29 13:20:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1466
train_sample_count: 1466
avg_envstep_per_episode: 293.2
avg_sample_per_episode: 293.2
avg_envstep_per_sec: 2767.4174935835845
avg_train_sample_per_sec: 2767.4174935835845
avg_episode_per_sec: 9.438668122727096
collect_time: 0.5297357566753136
reward_mean: 2160.152276737762
reward_std: 771.6153118308932
reward_max: 3581.006579990774
reward_min: 1529.4213016991919
total_envstep_count: 18046185
total_train_sample_count: 13558639
total_episode_count: 40965
total_duration: 3640.701139879998
[2023-06-29 13:20:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 215.75
avg_sample_per_episode: 215.75
avg_envstep_per_sec: 2723.605103643053
avg_train_sample_per_sec: 2723.605103643053
avg_episode_per_sec: 12.623893875518206
collect_time: 0.3168594444347546
reward_mean: 3598.7670184343815
reward_std: 57.77241001293409
reward_max: 3695.026855536572
reward_min: 3548.516844582017
total_envstep_count: 18050649
total_train_sample_count: 13561902
total_episode_count: 40969
total_duration: 3641.017999324433
[2023-06-29 13:20:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1401
train_sample_count: 1401
avg_envstep_per_episode: 200.14285714285714
avg_sample_per_episode: 200.14285714285714
avg_envstep_per_sec: 2813.633775910701
avg_train_sample_per_sec: 2813.633775910701
avg_episode_per_sec: 14.05812736001064
collect_time: 0.4979326065797359
reward_mean: 3033.4412017152076
reward_std: 812.5713918676566
reward_max: 3628.309482659198
reward_min: 1704.9075271774163
total_envstep_count: 18055481
total_train_sample_count: 13565303
total_episode_count: 40976
total_duration: 3641.5159319310123
[2023-06-29 13:20:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2409
train_sample_count: 2409
avg_envstep_per_episode: 301.125
avg_sample_per_episode: 301.125
avg_envstep_per_sec: 2562.55012995206
avg_train_sample_per_sec: 2562.55012995206
avg_episode_per_sec: 8.509921560654414
collect_time: 0.9400791702931748
reward_mean: 2730.004983296796
reward_std: 790.8311416268065
reward_max: 3581.529644285087
reward_min: 1280.5144180174582
total_envstep_count: 18060273
total_train_sample_count: 13568512
total_episode_count: 40984
total_duration: 3642.4560111013056
[2023-06-29 13:20:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 310.5
avg_sample_per_episode: 310.5
avg_envstep_per_sec: 2546.2313728426966
avg_train_sample_per_sec: 2546.2313728426966
avg_episode_per_sec: 8.200423100942663
collect_time: 0.9755594194987789
reward_mean: 2283.2412482839554
reward_std: 794.105044435438
reward_max: 3775.0630432407806
reward_min: 1346.00106702719
total_envstep_count: 18065857
total_train_sample_count: 13571796
total_episode_count: 40992
total_duration: 3643.4315705208046
[2023-06-29 13:20:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1908
train_sample_count: 1908
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2761.3485679152323
avg_train_sample_per_sec: 2761.3485679152323
avg_episode_per_sec: 13.025229093939775
collect_time: 0.6909667334901168
reward_mean: 2077.4558035650107
reward_std: 649.5977937383234
reward_max: 3174.5083567448733
reward_min: 1351.6816427703177
total_envstep_count: 18070289
total_train_sample_count: 13575304
total_episode_count: 41001
total_duration: 3644.122537254295
[2023-06-29 13:20:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2891
train_sample_count: 2891
avg_envstep_per_episode: 321.22222222222223
avg_sample_per_episode: 321.22222222222223
avg_envstep_per_sec: 2822.361592875935
avg_train_sample_per_sec: 2822.361592875935
avg_episode_per_sec: 8.786321112377522
collect_time: 1.0243194944607092
reward_mean: 2173.7397344939195
reward_std: 783.2244593311474
reward_max: 3647.4328639608066
reward_min: 1006.1645715999656
total_envstep_count: 18074729
total_train_sample_count: 13578595
total_episode_count: 41010
total_duration: 3645.1468567487555
[2023-06-29 13:20:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1014
train_sample_count: 1014
avg_envstep_per_episode: 202.8
avg_sample_per_episode: 202.8
avg_envstep_per_sec: 2621.6655351734166
avg_train_sample_per_sec: 2621.6655351734166
avg_episode_per_sec: 12.927344847995151
collect_time: 0.386777026434429
reward_mean: 1694.6167389031802
reward_std: 1042.3423295187981
reward_max: 3211.1874929559117
reward_min: 55.51974355055148
total_envstep_count: 18079609
total_train_sample_count: 13582009
total_episode_count: 41015
total_duration: 3645.53363377519
[2023-06-29 13:20:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1913
train_sample_count: 1913
avg_envstep_per_episode: 239.125
avg_sample_per_episode: 239.125
avg_envstep_per_sec: 2446.322048230336
avg_train_sample_per_sec: 2446.322048230336
avg_episode_per_sec: 10.230306526838833
collect_time: 0.7819902540566399
reward_mean: 2841.212086463139
reward_std: 838.3192654108709
reward_max: 3680.7026192771127
reward_min: 1418.4981662494129
total_envstep_count: 18084625
total_train_sample_count: 13585522
total_episode_count: 41023
total_duration: 3646.315624029247
[2023-06-29 13:20:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1957
train_sample_count: 1957
avg_envstep_per_episode: 244.625
avg_sample_per_episode: 244.625
avg_envstep_per_sec: 2474.4284293663904
avg_train_sample_per_sec: 2474.4284293663904
avg_episode_per_sec: 10.115190309111458
collect_time: 0.7908897169036792
reward_mean: 2277.1608410190383
reward_std: 889.0576756890254
reward_max: 3588.8939712228503
reward_min: 737.5733928020953
total_envstep_count: 18089481
total_train_sample_count: 13589079
total_episode_count: 41031
total_duration: 3647.1065137461505
[2023-06-29 13:20:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2355
train_sample_count: 2355
avg_envstep_per_episode: 294.375
avg_sample_per_episode: 294.375
avg_envstep_per_sec: 2596.756921193892
avg_train_sample_per_sec: 2596.756921193892
avg_episode_per_sec: 8.82125493399199
collect_time: 0.9069004421550781
reward_mean: 2274.0927430490156
reward_std: 834.274095479958
reward_max: 3650.98018232875
reward_min: 1262.6120370526935
total_envstep_count: 18093969
total_train_sample_count: 13592634
total_episode_count: 41039
total_duration: 3648.0134141883054
[2023-06-29 13:20:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2345
train_sample_count: 2345
avg_envstep_per_episode: 293.125
avg_sample_per_episode: 293.125
avg_envstep_per_sec: 2715.2434944382744
avg_train_sample_per_sec: 2715.2434944382744
avg_episode_per_sec: 9.263090812582599
collect_time: 0.8636426179837438
reward_mean: 2268.323050870317
reward_std: 801.4910074810323
reward_max: 3630.811560943986
reward_min: 1533.6513409930185
total_envstep_count: 18099241
total_train_sample_count: 13596179
total_episode_count: 41047
total_duration: 3648.877056806289
[2023-06-29 13:20:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1853
train_sample_count: 1853
avg_envstep_per_episode: 264.7142857142857
avg_sample_per_episode: 264.7142857142857
avg_envstep_per_sec: 2660.8596122235276
avg_train_sample_per_sec: 2660.8596122235276
avg_episode_per_sec: 10.051817207536262
collect_time: 0.6963914937442168
reward_mean: 2478.6295450934554
reward_std: 775.9690554820986
reward_max: 3672.1397516460206
reward_min: 1682.4305885856463
total_envstep_count: 18103729
total_train_sample_count: 13599632
total_episode_count: 41054
total_duration: 3649.5734483000333
[2023-06-29 13:20:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2011
train_sample_count: 2011
avg_envstep_per_episode: 201.1
avg_sample_per_episode: 201.1
avg_envstep_per_sec: 2676.0319702772263
avg_train_sample_per_sec: 2676.0319702772263
avg_episode_per_sec: 13.306971508091628
collect_time: 0.7514857902806252
reward_mean: 1806.2110344886119
reward_std: 636.5650345244529
reward_max: 3207.7516316964675
reward_min: 1065.274113904056
total_envstep_count: 18108241
total_train_sample_count: 13602843
total_episode_count: 41064
total_duration: 3650.324934090314
[2023-06-29 13:20:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2430
train_sample_count: 2430
avg_envstep_per_episode: 347.14285714285717
avg_sample_per_episode: 347.14285714285717
avg_envstep_per_sec: 2513.0451282735917
avg_train_sample_per_sec: 2513.0451282735917
avg_episode_per_sec: 7.239224649347795
collect_time: 0.9669543824186548
reward_mean: 2541.3036457140365
reward_std: 873.9274398870818
reward_max: 3570.8168808926794
reward_min: 1036.147238704527
total_envstep_count: 18112769
total_train_sample_count: 13606073
total_episode_count: 41071
total_duration: 3651.291888472733
[2023-06-29 13:20:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1355
train_sample_count: 1355
avg_envstep_per_episode: 193.57142857142858
avg_sample_per_episode: 193.57142857142858
avg_envstep_per_sec: 2727.2196134069713
avg_train_sample_per_sec: 2727.2196134069713
avg_episode_per_sec: 14.088957412434539
collect_time: 0.49684300939273096
reward_mean: 1877.6753224557635
reward_std: 549.9318598330196
reward_max: 2944.344728544611
reward_min: 1309.674485360158
total_envstep_count: 18116801
total_train_sample_count: 13609428
total_episode_count: 41078
total_duration: 3651.7887314821255
[2023-06-29 13:20:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1788
train_sample_count: 1788
avg_envstep_per_episode: 255.42857142857142
avg_sample_per_episode: 255.42857142857142
avg_envstep_per_sec: 2706.5274251739434
avg_train_sample_per_sec: 2706.5274251739434
avg_episode_per_sec: 10.596024595200001
collect_time: 0.6606251181382685
reward_mean: 2147.4180920571484
reward_std: 232.23192021844332
reward_max: 2539.9271385609068
reward_min: 1865.0321339226177
total_envstep_count: 18121481
total_train_sample_count: 13612816
total_episode_count: 41085
total_duration: 3652.449356600264
[2023-06-29 13:20:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2601.442998604627
avg_train_sample_per_sec: 2601.442998604627
avg_episode_per_sec: 9.670791816374079
collect_time: 0.9306373429279773
reward_mean: 2356.7383212125123
reward_std: 804.2372995427469
reward_max: 3559.9286467496927
reward_min: 1213.3989302440248
total_envstep_count: 18126217
total_train_sample_count: 13616037
total_episode_count: 41094
total_duration: 3653.379993943192
[2023-06-29 13:20:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2591
train_sample_count: 2591
avg_envstep_per_episode: 323.875
avg_sample_per_episode: 323.875
avg_envstep_per_sec: 2661.7949622703927
avg_train_sample_per_sec: 2661.7949622703927
avg_episode_per_sec: 8.218587301490984
collect_time: 0.9734032999258486
reward_mean: 2172.657240037325
reward_std: 710.1379379459561
reward_max: 3617.806182408206
reward_min: 1420.1166376281988
total_envstep_count: 18131009
total_train_sample_count: 13619428
total_episode_count: 41102
total_duration: 3654.353397243118
[2023-06-29 13:21:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 256.3333333333333
avg_sample_per_episode: 256.3333333333333
avg_envstep_per_sec: 2529.8510331387347
avg_train_sample_per_sec: 2529.8510331387347
avg_episode_per_sec: 9.869379843194023
collect_time: 0.9119114010194316
reward_mean: 2003.3837641966556
reward_std: 652.6450377805525
reward_max: 3690.205554243213
reward_min: 1473.4009022752377
total_envstep_count: 18135409
total_train_sample_count: 13622935
total_episode_count: 41111
total_duration: 3655.2653086441373
[2023-06-29 13:21:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2346
train_sample_count: 2346
avg_envstep_per_episode: 260.6666666666667
avg_sample_per_episode: 260.6666666666667
avg_envstep_per_sec: 2500.597303386043
avg_train_sample_per_sec: 2500.597303386043
avg_episode_per_sec: 9.593084284089679
collect_time: 0.9381758497552949
reward_mean: 1750.41180934942
reward_std: 277.1468027068611
reward_max: 2219.6791914233777
reward_min: 1344.4755963557493
total_envstep_count: 18140097
total_train_sample_count: 13626481
total_episode_count: 41120
total_duration: 3656.2034844938926
[2023-06-29 13:21:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2642
train_sample_count: 2642
avg_envstep_per_episode: 264.2
avg_sample_per_episode: 264.2
avg_envstep_per_sec: 2807.2995408799397
avg_train_sample_per_sec: 2807.2995408799397
avg_episode_per_sec: 10.62566063921249
collect_time: 0.9411179539365695
reward_mean: 1931.275229432084
reward_std: 648.0346124519965
reward_max: 3247.0171747858717
reward_min: 1352.612856747343
total_envstep_count: 18145353
total_train_sample_count: 13629923
total_episode_count: 41130
total_duration: 3657.144602447829
[2023-06-29 13:21:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3314
train_sample_count: 3314
avg_envstep_per_episode: 276.1666666666667
avg_sample_per_episode: 276.1666666666667
avg_envstep_per_sec: 2773.924990531227
avg_train_sample_per_sec: 2773.924990531227
avg_episode_per_sec: 10.04438741290728
collect_time: 1.1946970488792288
reward_mean: 1854.8123338753494
reward_std: 445.1999077939379
reward_max: 2844.4715069436456
reward_min: 1322.0755278782062
total_envstep_count: 18150329
total_train_sample_count: 13633237
total_episode_count: 41142
total_duration: 3658.3392994967085
[2023-06-29 13:21:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2385
train_sample_count: 2385
avg_envstep_per_episode: 238.5
avg_sample_per_episode: 238.5
avg_envstep_per_sec: 2521.803299260905
avg_train_sample_per_sec: 2521.803299260905
avg_episode_per_sec: 10.573598739039435
collect_time: 0.9457517962241545
reward_mean: 1509.4844031946059
reward_std: 339.36583147074737
reward_max: 1949.8767859383381
reward_min: 894.8284065771768
total_envstep_count: 18155193
total_train_sample_count: 13636822
total_episode_count: 41152
total_duration: 3659.2850512929326
[2023-06-29 13:21:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 204.3
avg_sample_per_episode: 204.3
avg_envstep_per_sec: 2737.9638877251555
avg_train_sample_per_sec: 2737.9638877251555
avg_episode_per_sec: 13.40168324877707
collect_time: 0.7461749255200849
reward_mean: 1647.94036456983
reward_std: 374.88605083706113
reward_max: 2575.7268268260395
reward_min: 1209.2654625141352
total_envstep_count: 18159521
total_train_sample_count: 13640065
total_episode_count: 41162
total_duration: 3660.0312262184525
[2023-06-29 13:21:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3107
train_sample_count: 3107
avg_envstep_per_episode: 282.45454545454544
avg_sample_per_episode: 282.45454545454544
avg_envstep_per_sec: 2556.6720721842103
avg_train_sample_per_sec: 2556.6720721842103
avg_episode_per_sec: 9.051623042815034
collect_time: 1.2152516679018732
reward_mean: 1894.3643527466904
reward_std: 509.35655023734694
reward_max: 2771.298845974085
reward_min: 1021.2701920307202
total_envstep_count: 18164089
total_train_sample_count: 13643572
total_episode_count: 41173
total_duration: 3661.2464778863546
[2023-06-29 13:21:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2629
train_sample_count: 2629
avg_envstep_per_episode: 292.1111111111111
avg_sample_per_episode: 292.1111111111111
avg_envstep_per_sec: 2744.222265491629
avg_train_sample_per_sec: 2744.222265491629
avg_episode_per_sec: 9.39444670575301
collect_time: 0.9580127794528381
reward_mean: 1700.3820060169855
reward_std: 429.6534282688283
reward_max: 2741.481803198742
reward_min: 1053.7426838906056
total_envstep_count: 18168641
total_train_sample_count: 13647001
total_episode_count: 41182
total_duration: 3662.2044906658075
[2023-06-29 13:21:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2669
train_sample_count: 2669
avg_envstep_per_episode: 266.9
avg_sample_per_episode: 266.9
avg_envstep_per_sec: 2647.1288187507803
avg_train_sample_per_sec: 2647.1288187507803
avg_episode_per_sec: 9.918054772389585
collect_time: 1.0082622277745974
reward_mean: 1629.9518494939516
reward_std: 539.4568466823368
reward_max: 2387.2135824710126
reward_min: 289.6523256251158
total_envstep_count: 18172921
total_train_sample_count: 13650470
total_episode_count: 41192
total_duration: 3663.212752893582
[2023-06-29 13:21:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 1938
train_sample_count: 1938
avg_envstep_per_episode: 138.42857142857142
avg_sample_per_episode: 138.42857142857142
avg_envstep_per_sec: 2770.872577310698
avg_train_sample_per_sec: 2770.872577310698
avg_episode_per_sec: 20.016623365505556
collect_time: 0.6994186653941872
reward_mean: 947.5066714235038
reward_std: 1022.101091133545
reward_max: 3445.548793057582
reward_min: 45.244648478202386
total_envstep_count: 18177665
total_train_sample_count: 13654008
total_episode_count: 41206
total_duration: 3663.9121715589763
[2023-06-29 13:21:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2176
train_sample_count: 2176
avg_envstep_per_episode: 241.77777777777777
avg_sample_per_episode: 241.77777777777777
avg_envstep_per_sec: 2694.919158010396
avg_train_sample_per_sec: 2694.919158010396
avg_episode_per_sec: 11.146264899859176
collect_time: 0.8074453712394462
reward_mean: 1899.738560099283
reward_std: 952.6841720050166
reward_max: 3651.8722029935734
reward_min: 53.685504478551344
total_envstep_count: 18182049
total_train_sample_count: 13657384
total_episode_count: 41215
total_duration: 3664.7196169302156
[2023-06-29 13:21:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2025
train_sample_count: 2025
avg_envstep_per_episode: 289.2857142857143
avg_sample_per_episode: 289.2857142857143
avg_envstep_per_sec: 2510.2191257680975
avg_train_sample_per_sec: 2510.2191257680975
avg_episode_per_sec: 8.677300681667498
collect_time: 0.8067024823501708
reward_mean: 2253.112982446727
reward_std: 727.1958923703041
reward_max: 3567.560384816581
reward_min: 1521.8521799211055
total_envstep_count: 18186161
total_train_sample_count: 13660609
total_episode_count: 41222
total_duration: 3665.526319412566
[2023-06-29 13:21:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 902
train_sample_count: 902
avg_envstep_per_episode: 225.5
avg_sample_per_episode: 225.5
avg_envstep_per_sec: 2844.6977335315864
avg_train_sample_per_sec: 2844.6977335315864
avg_episode_per_sec: 12.6150675544638
collect_time: 0.317081139893271
reward_mean: 2625.2599851475684
reward_std: 724.0507802209419
reward_max: 3578.9038530602934
reward_min: 1917.2383321209782
total_envstep_count: 18190353
total_train_sample_count: 13663911
total_episode_count: 41226
total_duration: 3665.843400552459
[2023-06-29 13:21:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2531
train_sample_count: 2531
avg_envstep_per_episode: 316.375
avg_sample_per_episode: 316.375
avg_envstep_per_sec: 2650.3526067158027
avg_train_sample_per_sec: 2650.3526067158027
avg_episode_per_sec: 8.377250436083138
collect_time: 0.9549672725005074
reward_mean: 2769.046528078552
reward_std: 699.6333751094712
reward_max: 3599.350352489844
reward_min: 1671.822039926377
total_envstep_count: 18195153
total_train_sample_count: 13667242
total_episode_count: 41234
total_duration: 3666.7983678249598
[2023-06-29 13:21:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2140
train_sample_count: 2140
avg_envstep_per_episode: 305.7142857142857
avg_sample_per_episode: 305.7142857142857
avg_envstep_per_sec: 2475.3469705349526
avg_train_sample_per_sec: 2475.3469705349526
avg_episode_per_sec: 8.09692934287134
collect_time: 0.8645252667497841
reward_mean: 2286.192462611379
reward_std: 987.2867070579148
reward_max: 3650.2929888895324
reward_min: 741.6745440925195
total_envstep_count: 18200177
total_train_sample_count: 13670582
total_episode_count: 41241
total_duration: 3667.6628930917095
[2023-06-29 13:21:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1980
train_sample_count: 1980
avg_envstep_per_episode: 282.85714285714283
avg_sample_per_episode: 282.85714285714283
avg_envstep_per_sec: 2690.2681705197424
avg_train_sample_per_sec: 2690.2681705197424
avg_episode_per_sec: 9.511049087696058
collect_time: 0.7359861078895629
reward_mean: 2548.9747386845384
reward_std: 604.3582511684892
reward_max: 3691.228238085087
reward_min: 1668.4219227806
total_envstep_count: 18205297
total_train_sample_count: 13674162
total_episode_count: 41248
total_duration: 3668.398879199599
[2023-06-29 13:21:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1205
train_sample_count: 1205
avg_envstep_per_episode: 200.83333333333334
avg_sample_per_episode: 200.83333333333334
avg_envstep_per_sec: 2727.8894036080414
avg_train_sample_per_sec: 2727.8894036080414
avg_episode_per_sec: 13.582851802197718
collect_time: 0.441733450925909
reward_mean: 2233.8973467838473
reward_std: 1123.3791662955327
reward_max: 3681.5358081351324
reward_min: 933.4830914656586
total_envstep_count: 18208953
total_train_sample_count: 13677367
total_episode_count: 41254
total_duration: 3668.8406126505247
[2023-06-29 13:21:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2495
train_sample_count: 2495
avg_envstep_per_episode: 311.875
avg_sample_per_episode: 311.875
avg_envstep_per_sec: 2653.366100557307
avg_train_sample_per_sec: 2653.366100557307
avg_episode_per_sec: 8.507787095975333
collect_time: 0.9403150207865985
reward_mean: 2834.9368977986496
reward_std: 832.8422440076657
reward_max: 3675.2240420854746
reward_min: 1598.9799730839816
total_envstep_count: 18213265
total_train_sample_count: 13680662
total_episode_count: 41262
total_duration: 3669.7809276713115
[2023-06-29 13:21:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 428.75
avg_sample_per_episode: 428.75
avg_envstep_per_sec: 2457.8686290962983
avg_train_sample_per_sec: 2457.8686290962983
avg_episode_per_sec: 5.732638201973874
collect_time: 0.6977590175885706
reward_mean: 2786.990205953384
reward_std: 963.8332389852744
reward_max: 3741.7845212721877
reward_min: 1384.922084834532
total_envstep_count: 18217841
total_train_sample_count: 13683977
total_episode_count: 41266
total_duration: 3670.4786866889
[2023-06-29 13:22:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2331
train_sample_count: 2331
avg_envstep_per_episode: 291.375
avg_sample_per_episode: 291.375
avg_envstep_per_sec: 2513.3902245835347
avg_train_sample_per_sec: 2513.3902245835347
avg_episode_per_sec: 8.625963876734568
collect_time: 0.9274325877455991
reward_mean: 2648.9496700983186
reward_std: 928.2701179184174
reward_max: 3724.5255959686124
reward_min: 1305.104911332791
total_envstep_count: 18222737
total_train_sample_count: 13687508
total_episode_count: 41274
total_duration: 3671.4061192766453
[2023-06-29 13:22:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2103
train_sample_count: 2103
avg_envstep_per_episode: 300.42857142857144
avg_sample_per_episode: 300.42857142857144
avg_envstep_per_sec: 2746.019707189346
avg_train_sample_per_sec: 2746.019707189346
avg_episode_per_sec: 9.140341393402483
collect_time: 0.7658357274327428
reward_mean: 2489.043119440612
reward_std: 880.6670827680597
reward_max: 3629.5182660340065
reward_min: 1626.074434873675
total_envstep_count: 18227537
total_train_sample_count: 13690811
total_episode_count: 41281
total_duration: 3672.171955004078
[2023-06-29 13:22:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2877
train_sample_count: 2877
avg_envstep_per_episode: 287.7
avg_sample_per_episode: 287.7
avg_envstep_per_sec: 2744.833695496296
avg_train_sample_per_sec: 2744.833695496296
avg_episode_per_sec: 9.54061068994194
collect_time: 1.0481509334137662
reward_mean: 2122.307403723869
reward_std: 1009.0293368693194
reward_max: 3575.9160888806123
reward_min: 62.81434341486247
total_envstep_count: 18232497
total_train_sample_count: 13694088
total_episode_count: 41291
total_duration: 3673.2201059374916
[2023-06-29 13:22:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2170
train_sample_count: 2170
avg_envstep_per_episode: 310.0
avg_sample_per_episode: 310.0
avg_envstep_per_sec: 2504.753176748599
avg_train_sample_per_sec: 2504.753176748599
avg_episode_per_sec: 8.079848957253546
collect_time: 0.8663528287513185
reward_mean: 2212.7427355178957
reward_std: 677.2650592505332
reward_max: 3319.3623056341567
reward_min: 1540.008893405597
total_envstep_count: 18237337
total_train_sample_count: 13697458
total_episode_count: 41298
total_duration: 3674.0864587662427
[2023-06-29 13:22:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1735
train_sample_count: 1735
avg_envstep_per_episode: 247.85714285714286
avg_sample_per_episode: 247.85714285714286
avg_envstep_per_sec: 2732.7460583121574
avg_train_sample_per_sec: 2732.7460583121574
avg_episode_per_sec: 11.02548841970323
collect_time: 0.6348925084797665
reward_mean: 2149.3436652517275
reward_std: 637.5836999176116
reward_max: 3154.5140225661085
reward_min: 1332.1383502882136
total_envstep_count: 18241713
total_train_sample_count: 13700793
total_episode_count: 41305
total_duration: 3674.7213512747226
[2023-06-29 13:22:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1919
train_sample_count: 1919
avg_envstep_per_episode: 274.14285714285717
avg_sample_per_episode: 274.14285714285717
avg_envstep_per_sec: 2769.617403422178
avg_train_sample_per_sec: 2769.617403422178
avg_episode_per_sec: 10.102825338173655
collect_time: 0.692875484400429
reward_mean: 2693.2252551596507
reward_std: 849.6240497770114
reward_max: 3593.6129230273905
reward_min: 1507.9282502439535
total_envstep_count: 18246297
total_train_sample_count: 13704312
total_episode_count: 41312
total_duration: 3675.414226759123
[2023-06-29 13:22:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1570
train_sample_count: 1570
avg_envstep_per_episode: 314.0
avg_sample_per_episode: 314.0
avg_envstep_per_sec: 2808.310232654885
avg_train_sample_per_sec: 2808.310232654885
avg_episode_per_sec: 8.94366316132129
collect_time: 0.5590550437569617
reward_mean: 2929.279976471216
reward_std: 614.2994789944181
reward_max: 3604.4349916096835
reward_min: 2193.6548763712785
total_envstep_count: 18251153
total_train_sample_count: 13707882
total_episode_count: 41317
total_duration: 3675.9732818028797
[2023-06-29 13:22:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 203.25
avg_sample_per_episode: 203.25
avg_envstep_per_sec: 2781.7814183758255
avg_train_sample_per_sec: 2781.7814183758255
avg_episode_per_sec: 13.686501443423497
collect_time: 0.5845175286810846
reward_mean: 2365.666158542291
reward_std: 1202.9907214818652
reward_max: 3647.8911956851075
reward_min: 50.99537082088495
total_envstep_count: 18255753
total_train_sample_count: 13711108
total_episode_count: 41325
total_duration: 3676.5577993315605
[2023-06-29 13:22:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2974
train_sample_count: 2974
avg_envstep_per_episode: 297.4
avg_sample_per_episode: 297.4
avg_envstep_per_sec: 2564.8205171386285
avg_train_sample_per_sec: 2564.8205171386285
avg_episode_per_sec: 8.62414430779633
collect_time: 1.1595353281553835
reward_mean: 2242.680039334976
reward_std: 937.4851462689775
reward_max: 3623.845192746016
reward_min: 449.78940259544424
total_envstep_count: 18260113
total_train_sample_count: 13714482
total_episode_count: 41335
total_duration: 3677.717334659716
[2023-06-29 13:22:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3181
train_sample_count: 3181
avg_envstep_per_episode: 289.1818181818182
avg_sample_per_episode: 289.1818181818182
avg_envstep_per_sec: 2604.248077337126
avg_train_sample_per_sec: 2604.248077337126
avg_episode_per_sec: 9.005573357657461
collect_time: 1.2214658149052413
reward_mean: 1528.8674312744513
reward_std: 444.4210945037187
reward_max: 2142.0534882858115
reward_min: 456.4180916771112
total_envstep_count: 18264865
total_train_sample_count: 13718063
total_episode_count: 41346
total_duration: 3678.938800474621
[2023-06-29 13:22:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2507
train_sample_count: 2507
avg_envstep_per_episode: 358.14285714285717
avg_sample_per_episode: 358.14285714285717
avg_envstep_per_sec: 2585.7512815348246
avg_train_sample_per_sec: 2585.7512815348246
avg_episode_per_sec: 7.219887902171429
collect_time: 0.9695441390294584
reward_mean: 2125.1338611950696
reward_std: 602.9532214321947
reward_max: 3060.1205538712775
reward_min: 1396.4330525851035
total_envstep_count: 18269249
total_train_sample_count: 13721370
total_episode_count: 41353
total_duration: 3679.9083446136506
[2023-06-29 13:22:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3151
train_sample_count: 3151
avg_envstep_per_episode: 315.1
avg_sample_per_episode: 315.1
avg_envstep_per_sec: 2741.299029774609
avg_train_sample_per_sec: 2741.299029774609
avg_episode_per_sec: 8.699774769199013
collect_time: 1.1494550451356913
reward_mean: 1950.3201905560793
reward_std: 684.4906798282476
reward_max: 3552.269199986099
reward_min: 1294.4795715277633
total_envstep_count: 18274649
total_train_sample_count: 13725321
total_episode_count: 41363
total_duration: 3681.0577996587863
[2023-06-29 13:22:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 306.625
avg_sample_per_episode: 306.625
avg_envstep_per_sec: 2726.2626210906433
avg_train_sample_per_sec: 2726.2626210906433
avg_episode_per_sec: 8.891194850682897
collect_time: 0.8997665819218383
reward_mean: 2173.959521459065
reward_std: 553.7876894179169
reward_max: 3080.466893639178
reward_min: 1583.2279423060847
total_envstep_count: 18279169
total_train_sample_count: 13728574
total_episode_count: 41371
total_duration: 3681.9575662407083
[2023-06-29 13:22:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1726
train_sample_count: 1726
avg_envstep_per_episode: 246.57142857142858
avg_sample_per_episode: 246.57142857142858
avg_envstep_per_sec: 2682.4257784741812
avg_train_sample_per_sec: 2682.4257784741812
avg_episode_per_sec: 10.87889944920004
collect_time: 0.6434474399443716
reward_mean: 2115.884479827219
reward_std: 503.33488295560807
reward_max: 3120.6338171267303
reward_min: 1470.773918730388
total_envstep_count: 18283673
total_train_sample_count: 13731900
total_episode_count: 41378
total_duration: 3682.6010136806526
[2023-06-29 13:22:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3458
train_sample_count: 3458
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 2632.6036283440844
avg_train_sample_per_sec: 2632.6036283440844
avg_episode_per_sec: 10.658314284793866
collect_time: 1.3135285398717969
reward_mean: 1679.333896276297
reward_std: 594.6467435071767
reward_max: 3013.239222628183
reward_min: 994.1263441601374
total_envstep_count: 18288329
total_train_sample_count: 13735358
total_episode_count: 41392
total_duration: 3683.9145422205243
[2023-06-29 13:22:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2851
train_sample_count: 2851
avg_envstep_per_episode: 316.77777777777777
avg_sample_per_episode: 316.77777777777777
avg_envstep_per_sec: 2807.7681561778127
avg_train_sample_per_sec: 2807.7681561778127
avg_episode_per_sec: 8.863526273448024
collect_time: 1.0153972270563245
reward_mean: 1694.6338087553634
reward_std: 495.79252494460144
reward_max: 2731.2616892011592
reward_min: 1059.5111265735559
total_envstep_count: 18292865
total_train_sample_count: 13738609
total_episode_count: 41401
total_duration: 3684.9299394475806
[2023-06-29 13:22:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 314.85714285714283
avg_sample_per_episode: 314.85714285714283
avg_envstep_per_sec: 2727.1569265772155
avg_train_sample_per_sec: 2727.1569265772155
avg_episode_per_sec: 8.661569186043788
collect_time: 0.8081676483377814
reward_mean: 2109.00455000177
reward_std: 320.8397402161018
reward_max: 2542.877456918354
reward_min: 1702.8944018921236
total_envstep_count: 18297537
total_train_sample_count: 13742013
total_episode_count: 41408
total_duration: 3685.7381070959186
[2023-06-29 13:22:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2751
train_sample_count: 2751
avg_envstep_per_episode: 275.1
avg_sample_per_episode: 275.1
avg_envstep_per_sec: 2465.8145164582397
avg_train_sample_per_sec: 2465.8145164582397
avg_episode_per_sec: 8.963338845722427
collect_time: 1.1156556917149572
reward_mean: 1969.5755452470553
reward_std: 685.8557496340359
reward_max: 3751.5668803947938
reward_min: 1049.0384219441255
total_envstep_count: 18302369
total_train_sample_count: 13745564
total_episode_count: 41418
total_duration: 3686.8537627876335
[2023-06-29 13:22:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2736
train_sample_count: 2736
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2575.1164744826833
avg_train_sample_per_sec: 2575.1164744826833
avg_episode_per_sec: 11.294370502117031
collect_time: 1.0624762130612506
reward_mean: 1511.8196353086612
reward_std: 339.55627198471734
reward_max: 2043.5441087279996
reward_min: 1041.3996361721038
total_envstep_count: 18307081
total_train_sample_count: 13749100
total_episode_count: 41430
total_duration: 3687.916239000695
[2023-06-29 13:22:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2804
train_sample_count: 2804
avg_envstep_per_episode: 280.4
avg_sample_per_episode: 280.4
avg_envstep_per_sec: 2715.6417557595732
avg_train_sample_per_sec: 2715.6417557595732
avg_episode_per_sec: 9.684885006275225
collect_time: 1.0325367821631954
reward_mean: 1806.4445292538996
reward_std: 427.1254146138238
reward_max: 2585.0157710311037
reward_min: 1252.4095598712433
total_envstep_count: 18311529
total_train_sample_count: 13752304
total_episode_count: 41440
total_duration: 3688.9487757828583
[2023-06-29 13:23:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2271
train_sample_count: 2271
avg_envstep_per_episode: 283.875
avg_sample_per_episode: 283.875
avg_envstep_per_sec: 2712.1908524834907
avg_train_sample_per_sec: 2712.1908524834907
avg_episode_per_sec: 9.55417297220076
collect_time: 0.8373304547946903
reward_mean: 1848.842934741332
reward_std: 365.4499077180589
reward_max: 2559.0850142770255
reward_min: 1255.1721090034468
total_envstep_count: 18315977
total_train_sample_count: 13755775
total_episode_count: 41448
total_duration: 3689.786106237653
[2023-06-29 13:23:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2563
train_sample_count: 2563
avg_envstep_per_episode: 284.77777777777777
avg_sample_per_episode: 284.77777777777777
avg_envstep_per_sec: 2798.0874365943064
avg_train_sample_per_sec: 2798.0874365943064
avg_episode_per_sec: 9.825511872551212
collect_time: 0.9159828125741334
reward_mean: 1977.8800790395226
reward_std: 533.314026382623
reward_max: 3186.59494050352
reward_min: 1047.6961258615947
total_envstep_count: 18320841
total_train_sample_count: 13759138
total_episode_count: 41457
total_duration: 3690.7020890502267
[2023-06-29 13:23:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2244
train_sample_count: 2244
avg_envstep_per_episode: 280.5
avg_sample_per_episode: 280.5
avg_envstep_per_sec: 2599.0726283946997
avg_train_sample_per_sec: 2599.0726283946997
avg_episode_per_sec: 9.265856072708377
collect_time: 0.8633848763918506
reward_mean: 2040.3319116033053
reward_std: 648.3735372690819
reward_max: 3378.8394758979257
reward_min: 1504.3069901641072
total_envstep_count: 18325641
total_train_sample_count: 13762582
total_episode_count: 41465
total_duration: 3691.565473926619
[2023-06-29 13:23:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3482
train_sample_count: 3482
avg_envstep_per_episode: 248.71428571428572
avg_sample_per_episode: 248.71428571428572
avg_envstep_per_sec: 2597.1227570637243
avg_train_sample_per_sec: 2597.1227570637243
avg_episode_per_sec: 10.442193738912161
collect_time: 1.3407144466042518
reward_mean: 1691.0707998092487
reward_std: 595.3883666977395
reward_max: 2987.400755373595
reward_min: 980.5318232953459
total_envstep_count: 18329681
total_train_sample_count: 13766064
total_episode_count: 41479
total_duration: 3692.906188373223
[2023-06-29 13:23:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2265
train_sample_count: 2265
avg_envstep_per_episode: 283.125
avg_sample_per_episode: 283.125
avg_envstep_per_sec: 2539.739683739138
avg_train_sample_per_sec: 2539.739683739138
avg_episode_per_sec: 8.970382988924108
collect_time: 0.8918236835459248
reward_mean: 1300.2332637325565
reward_std: 207.26256539696266
reward_max: 1640.4624172864405
reward_min: 920.7192670716943
total_envstep_count: 18334425
total_train_sample_count: 13769529
total_episode_count: 41487
total_duration: 3693.798012056769
[2023-06-29 13:23:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2633
train_sample_count: 2633
avg_envstep_per_episode: 239.36363636363637
avg_sample_per_episode: 239.36363636363637
avg_envstep_per_sec: 2765.8064623011583
avg_train_sample_per_sec: 2765.8064623011583
avg_episode_per_sec: 11.554831403460973
collect_time: 0.9519827348329127
reward_mean: 1783.159316587692
reward_std: 776.4013789931239
reward_max: 3244.0855281713784
reward_min: 1009.445131508723
total_envstep_count: 18339193
total_train_sample_count: 13772962
total_episode_count: 41498
total_duration: 3694.749994791602
[2023-06-29 13:23:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2809
train_sample_count: 2809
avg_envstep_per_episode: 216.07692307692307
avg_sample_per_episode: 216.07692307692307
avg_envstep_per_sec: 2774.2049190209436
avg_train_sample_per_sec: 2774.2049190209436
avg_episode_per_sec: 12.838969009352889
collect_time: 1.0125423615034668
reward_mean: 1389.1978146655415
reward_std: 599.3186015191153
reward_max: 2483.9974439406838
reward_min: 59.25658243339307
total_envstep_count: 18343553
total_train_sample_count: 13776171
total_episode_count: 41511
total_duration: 3695.7625371531058
[2023-06-29 13:23:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2118
train_sample_count: 2118
avg_envstep_per_episode: 264.75
avg_sample_per_episode: 264.75
avg_envstep_per_sec: 2645.0067811254657
avg_train_sample_per_sec: 2645.0067811254657
avg_episode_per_sec: 9.990582742683536
collect_time: 0.8007540907319635
reward_mean: 1505.1660462675732
reward_std: 658.4643262914312
reward_max: 3086.755562457158
reward_min: 934.438175980696
total_envstep_count: 18347537
total_train_sample_count: 13779489
total_episode_count: 41519
total_duration: 3696.5632912438377
[2023-06-29 13:23:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2542
train_sample_count: 2542
avg_envstep_per_episode: 282.44444444444446
avg_sample_per_episode: 282.44444444444446
avg_envstep_per_sec: 2594.1518169539177
avg_train_sample_per_sec: 2594.1518169539177
avg_episode_per_sec: 9.18464451321214
collect_time: 0.9798963897898794
reward_mean: 2088.377956270467
reward_std: 1121.713926708982
reward_max: 3712.304694449989
reward_min: 1020.9750576698954
total_envstep_count: 18352417
total_train_sample_count: 13782831
total_episode_count: 41528
total_duration: 3697.5431876336274
[2023-06-29 13:23:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2810
train_sample_count: 2810
avg_envstep_per_episode: 234.16666666666666
avg_sample_per_episode: 234.16666666666666
avg_envstep_per_sec: 2794.34349835658
avg_train_sample_per_sec: 2794.34349835658
avg_episode_per_sec: 11.933139494761196
collect_time: 1.0056029266454278
reward_mean: 1636.085084622
reward_std: 378.5219924105887
reward_max: 2219.4323857524564
reward_min: 969.4221048602006
total_envstep_count: 18356929
total_train_sample_count: 13786041
total_episode_count: 41540
total_duration: 3698.5487905602727
[2023-06-29 13:23:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 306.75
avg_sample_per_episode: 306.75
avg_envstep_per_sec: 2608.8008900163363
avg_train_sample_per_sec: 2608.8008900163363
avg_episode_per_sec: 8.504648378211366
collect_time: 0.9406620525894688
reward_mean: 1931.1393449839093
reward_std: 631.4741300148733
reward_max: 3052.287678820569
reward_min: 958.6594816105603
total_envstep_count: 18361809
total_train_sample_count: 13789295
total_episode_count: 41548
total_duration: 3699.4894526128624
[2023-06-29 13:23:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2525
train_sample_count: 2525
avg_envstep_per_episode: 229.54545454545453
avg_sample_per_episode: 229.54545454545453
avg_envstep_per_sec: 2507.2868459495453
avg_train_sample_per_sec: 2507.2868459495453
avg_episode_per_sec: 10.922833784334653
collect_time: 1.0070646699555217
reward_mean: 1672.1861164672382
reward_std: 556.367138591667
reward_max: 2744.1351729267362
reward_min: 734.1281963814382
total_envstep_count: 18366105
total_train_sample_count: 13792620
total_episode_count: 41559
total_duration: 3700.496517282818
[2023-06-29 13:23:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1845
train_sample_count: 1845
avg_envstep_per_episode: 263.57142857142856
avg_sample_per_episode: 263.57142857142856
avg_envstep_per_sec: 2736.9164169574633
avg_train_sample_per_sec: 2736.9164169574633
avg_episode_per_sec: 10.383964725583873
collect_time: 0.6741163115426899
reward_mean: 1763.848478381769
reward_std: 851.0261995066103
reward_max: 3579.8734152976253
reward_min: 973.455826229736
total_envstep_count: 18370281
total_train_sample_count: 13796065
total_episode_count: 41566
total_duration: 3701.1706335943604
[2023-06-29 13:23:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2652
train_sample_count: 2652
avg_envstep_per_episode: 265.2
avg_sample_per_episode: 265.2
avg_envstep_per_sec: 2786.4429125745096
avg_train_sample_per_sec: 2786.4429125745096
avg_episode_per_sec: 10.506949142437819
collect_time: 0.9517510615531354
reward_mean: 2053.026793906477
reward_std: 810.5342937549586
reward_max: 3712.315435509566
reward_min: 1182.9097146203155
total_envstep_count: 18374809
total_train_sample_count: 13799517
total_episode_count: 41576
total_duration: 3702.1223846559137
[2023-06-29 13:23:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2721
train_sample_count: 2721
avg_envstep_per_episode: 302.3333333333333
avg_sample_per_episode: 302.3333333333333
avg_envstep_per_sec: 2806.5161915182057
avg_train_sample_per_sec: 2806.5161915182057
avg_episode_per_sec: 9.282853996201341
collect_time: 0.9695294145187365
reward_mean: 1935.6894971722436
reward_std: 605.5040962205085
reward_max: 2803.1220417416266
reward_min: 1056.232845379914
total_envstep_count: 18379833
total_train_sample_count: 13803038
total_episode_count: 41585
total_duration: 3703.0919140704323
[2023-06-29 13:23:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1982
train_sample_count: 1982
avg_envstep_per_episode: 283.14285714285717
avg_sample_per_episode: 283.14285714285717
avg_envstep_per_sec: 2680.0068269872986
avg_train_sample_per_sec: 2680.0068269872986
avg_episode_per_sec: 9.465210791579763
collect_time: 0.7395503548877316
reward_mean: 2164.832416801963
reward_std: 530.5725587882189
reward_max: 3460.7531286092567
reward_min: 1886.6582778181985
total_envstep_count: 18384385
total_train_sample_count: 13806620
total_episode_count: 41592
total_duration: 3703.83146442532
[2023-06-29 13:23:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3314
train_sample_count: 3314
avg_envstep_per_episode: 331.4
avg_sample_per_episode: 331.4
avg_envstep_per_sec: 2609.1634812336742
avg_train_sample_per_sec: 2609.1634812336742
avg_episode_per_sec: 7.873154741199984
collect_time: 1.2701388869788497
reward_mean: 2292.676502252346
reward_std: 1007.4518043133137
reward_max: 3765.834197787019
reward_min: 1199.469009071611
total_envstep_count: 18389297
total_train_sample_count: 13809934
total_episode_count: 41602
total_duration: 3705.1016033122987
[2023-06-29 13:23:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2740
train_sample_count: 2740
avg_envstep_per_episode: 391.42857142857144
avg_sample_per_episode: 391.42857142857144
avg_envstep_per_sec: 2766.511134550441
avg_train_sample_per_sec: 2766.511134550441
avg_episode_per_sec: 7.0677291758587915
collect_time: 0.9904171234956012
reward_mean: 2049.341369319999
reward_std: 729.3853373685943
reward_max: 3440.461605016463
reward_min: 1313.5703212037051
total_envstep_count: 18394321
total_train_sample_count: 13813474
total_episode_count: 41609
total_duration: 3706.0920204357944
[2023-06-29 13:23:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 28
train_sample_count: 28
avg_envstep_per_episode: 14.0
avg_sample_per_episode: 14.0
avg_envstep_per_sec: 2623.5809487011684
avg_train_sample_per_sec: 2623.5809487011684
avg_episode_per_sec: 187.3986391929406
collect_time: 0.010672436089254916
reward_mean: 3432.5007867708873
reward_std: 167.19573577301617
reward_max: 3599.6965225439035
reward_min: 3265.305050997871
total_envstep_count: 18397673
total_train_sample_count: 13816702
total_episode_count: 41611
total_duration: 3706.102692871884
[2023-06-29 13:24:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2704
train_sample_count: 2704
avg_envstep_per_episode: 270.4
avg_sample_per_episode: 270.4
avg_envstep_per_sec: 2638.7364707913516
avg_train_sample_per_sec: 2638.7364707913516
avg_episode_per_sec: 9.758640794346714
collect_time: 1.0247328711794688
reward_mean: 2643.564520415512
reward_std: 783.2456189717996
reward_max: 3666.5020334484534
reward_min: 1271.8944987399782
total_envstep_count: 18402593
total_train_sample_count: 13820206
total_episode_count: 41621
total_duration: 3707.127425743063
[2023-06-29 13:24:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2006
train_sample_count: 2006
avg_envstep_per_episode: 286.57142857142856
avg_sample_per_episode: 286.57142857142856
avg_envstep_per_sec: 2495.248455542869
avg_train_sample_per_sec: 2495.248455542869
avg_episode_per_sec: 8.707247850847498
collect_time: 0.8039279597764835
reward_mean: 2286.9894572317535
reward_std: 610.9250399193919
reward_max: 3143.112758773767
reward_min: 1318.2794242117932
total_envstep_count: 18407713
total_train_sample_count: 13823412
total_episode_count: 41628
total_duration: 3707.9313537028397
[2023-06-29 13:24:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2881
train_sample_count: 2881
avg_envstep_per_episode: 320.1111111111111
avg_sample_per_episode: 320.1111111111111
avg_envstep_per_sec: 2604.1307860479624
avg_train_sample_per_sec: 2604.1307860479624
avg_episode_per_sec: 8.13508402444695
collect_time: 1.106319243040867
reward_mean: 2348.045549303327
reward_std: 720.8319695709855
reward_max: 3370.2541323880296
reward_min: 1046.0225961135372
total_envstep_count: 18412425
total_train_sample_count: 13826693
total_episode_count: 41637
total_duration: 3709.037672945881
[2023-06-29 13:24:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1778
train_sample_count: 1778
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 2807.1591470515473
avg_train_sample_per_sec: 2807.1591470515473
avg_episode_per_sec: 11.051807665557272
collect_time: 0.6333805483980104
reward_mean: 1998.8862423308597
reward_std: 723.9484549933102
reward_max: 3604.7860329345317
reward_min: 1209.8999177093024
total_envstep_count: 18416569
total_train_sample_count: 13830071
total_episode_count: 41644
total_duration: 3709.671053494279
[2023-06-29 13:24:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1231
train_sample_count: 1231
avg_envstep_per_episode: 205.16666666666666
avg_sample_per_episode: 205.16666666666666
avg_envstep_per_sec: 2780.5483075861557
avg_train_sample_per_sec: 2780.5483075861557
avg_episode_per_sec: 13.55263188100482
collect_time: 0.44271843673475086
reward_mean: 2303.6181966542795
reward_std: 497.254871639833
reward_max: 3115.3556697850013
reward_min: 1492.1886933788842
total_envstep_count: 18420753
total_train_sample_count: 13833302
total_episode_count: 41650
total_duration: 3710.1137719310136
[2023-06-29 13:24:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2339
train_sample_count: 2339
avg_envstep_per_episode: 259.8888888888889
avg_sample_per_episode: 259.8888888888889
avg_envstep_per_sec: 2504.2247307668026
avg_train_sample_per_sec: 2504.2247307668026
avg_episode_per_sec: 9.635751422360507
collect_time: 0.9340216040769591
reward_mean: 2233.7586246375304
reward_std: 758.922207127165
reward_max: 3595.5705979476543
reward_min: 1206.394402006572
total_envstep_count: 18425505
total_train_sample_count: 13836841
total_episode_count: 41659
total_duration: 3711.0477935350905
[2023-06-29 13:24:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2624
train_sample_count: 2624
avg_envstep_per_episode: 262.4
avg_sample_per_episode: 262.4
avg_envstep_per_sec: 2772.0518513768916
avg_train_sample_per_sec: 2772.0518513768916
avg_episode_per_sec: 10.564221994576569
collect_time: 0.9465912402383982
reward_mean: 1902.8222207528713
reward_std: 685.4378580619888
reward_max: 3274.5594655785344
reward_min: 1170.4473099983456
total_envstep_count: 18430121
total_train_sample_count: 13840265
total_episode_count: 41669
total_duration: 3711.994384775329
[2023-06-29 13:24:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2898
train_sample_count: 2898
avg_envstep_per_episode: 322.0
avg_sample_per_episode: 322.0
avg_envstep_per_sec: 2755.4454236319716
avg_train_sample_per_sec: 2755.4454236319716
avg_episode_per_sec: 8.557283924322894
collect_time: 1.0517355833454056
reward_mean: 2026.90714937066
reward_std: 792.0427085901085
reward_max: 3586.236450415728
reward_min: 1092.0183623937144
total_envstep_count: 18434721
total_train_sample_count: 13843563
total_episode_count: 41678
total_duration: 3713.046120358674
[2023-06-29 13:24:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1382
train_sample_count: 1382
avg_envstep_per_episode: 172.75
avg_sample_per_episode: 172.75
avg_envstep_per_sec: 2784.738935127867
avg_train_sample_per_sec: 2784.738935127867
avg_episode_per_sec: 16.120051722882007
collect_time: 0.49627632327284665
reward_mean: 1468.3236316122952
reward_std: 418.02945279963774
reward_max: 2497.721901462588
reward_min: 1019.7408788335141
total_envstep_count: 18439001
total_train_sample_count: 13846945
total_episode_count: 41686
total_duration: 3713.542396681947
[2023-06-29 13:24:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2062
train_sample_count: 2062
avg_envstep_per_episode: 257.75
avg_sample_per_episode: 257.75
avg_envstep_per_sec: 2520.577256928649
avg_train_sample_per_sec: 2520.577256928649
avg_episode_per_sec: 9.779155216018037
collect_time: 0.8180665735723449
reward_mean: 2236.947056079708
reward_std: 492.4347309716046
reward_max: 2884.8927491404274
reward_min: 1297.1686597681664
total_envstep_count: 18444217
total_train_sample_count: 13850207
total_episode_count: 41694
total_duration: 3714.3604632555193
[2023-06-29 13:24:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 237.28571428571428
avg_sample_per_episode: 237.28571428571428
avg_envstep_per_sec: 2758.7109495467403
avg_train_sample_per_sec: 2758.7109495467403
avg_episode_per_sec: 11.626114778342673
collect_time: 0.6020927999988199
reward_mean: 2478.474723249321
reward_std: 987.9926201558059
reward_max: 3671.1465002155355
reward_min: 997.7889059388767
total_envstep_count: 18448537
total_train_sample_count: 13853468
total_episode_count: 41701
total_duration: 3714.9625560555182
[2023-06-29 13:24:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2510
train_sample_count: 2510
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2755.5849356403046
avg_train_sample_per_sec: 2755.5849356403046
avg_episode_per_sec: 10.978426038407589
collect_time: 0.9108773848833518
reward_mean: 2073.209593579333
reward_std: 648.1353930455499
reward_max: 3588.845842968382
reward_min: 1146.1479485406355
total_envstep_count: 18453089
total_train_sample_count: 13856778
total_episode_count: 41711
total_duration: 3715.8734334404016
[2023-06-29 13:24:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2579
train_sample_count: 2579
avg_envstep_per_episode: 322.375
avg_sample_per_episode: 322.375
avg_envstep_per_sec: 2800.189372213879
avg_train_sample_per_sec: 2800.189372213879
avg_episode_per_sec: 8.68612445820513
collect_time: 0.9210091380216179
reward_mean: 2054.373852949015
reward_std: 735.4574962746567
reward_max: 3657.9868364966796
reward_min: 1158.4287130766093
total_envstep_count: 18457329
total_train_sample_count: 13860157
total_episode_count: 41719
total_duration: 3716.794442578423
[2023-06-29 13:24:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3087
train_sample_count: 3087
avg_envstep_per_episode: 308.7
avg_sample_per_episode: 308.7
avg_envstep_per_sec: 2600.4228032575033
avg_train_sample_per_sec: 2600.4228032575033
avg_episode_per_sec: 8.423786210746691
collect_time: 1.1871146477153522
reward_mean: 1804.2465214068434
reward_std: 754.6339131358964
reward_max: 3588.1396629862115
reward_min: 743.2636210182267
total_envstep_count: 18462185
total_train_sample_count: 13863644
total_episode_count: 41729
total_duration: 3717.981557226138
[2023-06-29 13:24:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2667
train_sample_count: 2667
avg_envstep_per_episode: 296.3333333333333
avg_sample_per_episode: 296.3333333333333
avg_envstep_per_sec: 2773.067394634242
avg_train_sample_per_sec: 2773.067394634242
avg_episode_per_sec: 9.357932715301155
collect_time: 0.9617508774437009
reward_mean: 1723.0471585713717
reward_std: 845.1579264503586
reward_max: 3570.8026812572016
reward_min: 940.9764937424611
total_envstep_count: 18466889
total_train_sample_count: 13867111
total_episode_count: 41738
total_duration: 3718.943308103582
[2023-06-29 13:24:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2764.3819574359595
avg_train_sample_per_sec: 2764.3819574359595
avg_episode_per_sec: 10.591501752628197
collect_time: 0.9441531742671505
reward_mean: 1871.5547202176222
reward_std: 880.5139187265909
reward_max: 3661.179397166251
reward_min: 839.6511413705904
total_envstep_count: 18472049
total_train_sample_count: 13870521
total_episode_count: 41748
total_duration: 3719.887461277849
[2023-06-29 13:24:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3025
train_sample_count: 3025
avg_envstep_per_episode: 302.5
avg_sample_per_episode: 302.5
avg_envstep_per_sec: 2802.109380635369
avg_train_sample_per_sec: 2802.109380635369
avg_episode_per_sec: 9.263171506232624
collect_time: 1.0795438682390377
reward_mean: 2100.7839589556506
reward_std: 705.8899075186813
reward_max: 3090.827812837746
reward_min: 944.7891800904004
total_envstep_count: 18476801
total_train_sample_count: 13873946
total_episode_count: 41758
total_duration: 3720.967005146088
[2023-06-29 13:24:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2502
train_sample_count: 2502
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2742.341357101069
avg_train_sample_per_sec: 2742.341357101069
avg_episode_per_sec: 9.864537255759242
collect_time: 0.9123590662851928
reward_mean: 1726.6526277362423
reward_std: 532.4482402832346
reward_max: 2779.28867652384
reward_min: 1175.6528582120961
total_envstep_count: 18481033
total_train_sample_count: 13877248
total_episode_count: 41767
total_duration: 3721.8793642123733
[2023-06-29 13:24:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1795
train_sample_count: 1795
avg_envstep_per_episode: 224.375
avg_sample_per_episode: 224.375
avg_envstep_per_sec: 2562.6488987395037
avg_train_sample_per_sec: 2562.6488987395037
avg_episode_per_sec: 11.42127642892258
collect_time: 0.7004471041206273
reward_mean: 1654.265484825822
reward_std: 584.2332912889593
reward_max: 2651.560733391126
reward_min: 1010.5904000968925
total_envstep_count: 18485329
total_train_sample_count: 13880643
total_episode_count: 41775
total_duration: 3722.5798113164938
[2023-06-29 13:24:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1622
train_sample_count: 1622
avg_envstep_per_episode: 324.4
avg_sample_per_episode: 324.4
avg_envstep_per_sec: 2820.483897524655
avg_train_sample_per_sec: 2820.483897524655
avg_episode_per_sec: 8.694463309262192
collect_time: 0.5750786244245245
reward_mean: 2979.309494203283
reward_std: 609.1922807892427
reward_max: 3592.905131118674
reward_min: 1934.0851937257644
total_envstep_count: 18489033
total_train_sample_count: 13883865
total_episode_count: 41780
total_duration: 3723.154889940918
[2023-06-29 13:25:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2356
train_sample_count: 2356
avg_envstep_per_episode: 294.5
avg_sample_per_episode: 294.5
avg_envstep_per_sec: 2733.8010370576344
avg_train_sample_per_sec: 2733.8010370576344
avg_episode_per_sec: 9.282855813438488
collect_time: 0.8618037553075705
reward_mean: 2163.1004236740064
reward_std: 869.2377269524811
reward_max: 3552.0786822183936
reward_min: 947.0010258497769
total_envstep_count: 18494025
total_train_sample_count: 13887421
total_episode_count: 41788
total_duration: 3724.0166936962255
[2023-06-29 13:25:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2122
train_sample_count: 2122
avg_envstep_per_episode: 303.14285714285717
avg_sample_per_episode: 303.14285714285717
avg_envstep_per_sec: 2717.8164648181514
avg_train_sample_per_sec: 2717.8164648181514
avg_episode_per_sec: 8.96546430430116
collect_time: 0.780773840864189
reward_mean: 2333.410405093539
reward_std: 697.9203597523676
reward_max: 3560.6012637818044
reward_min: 1306.020399434162
total_envstep_count: 18498049
total_train_sample_count: 13890743
total_episode_count: 41795
total_duration: 3724.7974675370897
[2023-06-29 13:25:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1504
train_sample_count: 1504
avg_envstep_per_episode: 214.85714285714286
avg_sample_per_episode: 214.85714285714286
avg_envstep_per_sec: 2724.3120598946416
avg_train_sample_per_sec: 2724.3120598946416
avg_episode_per_sec: 12.679643895786231
collect_time: 0.5520659773675725
reward_mean: 1956.118704797067
reward_std: 843.0069605769573
reward_max: 3679.489816890787
reward_min: 1025.4353571969693
total_envstep_count: 18502761
total_train_sample_count: 13894247
total_episode_count: 41802
total_duration: 3725.349533514457
[2023-06-29 13:25:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1687
train_sample_count: 1687
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2678.872678794859
avg_train_sample_per_sec: 2678.872678794859
avg_episode_per_sec: 11.115654268858336
collect_time: 0.629742508240044
reward_mean: 2604.9656932472967
reward_std: 313.0849359679246
reward_max: 3059.239566488599
reward_min: 2096.798591062443
total_envstep_count: 18507505
total_train_sample_count: 13897534
total_episode_count: 41809
total_duration: 3725.9792760226974
[2023-06-29 13:25:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1989
train_sample_count: 1989
avg_envstep_per_episode: 221.0
avg_sample_per_episode: 221.0
avg_envstep_per_sec: 2694.3121083581427
avg_train_sample_per_sec: 2694.3121083581427
avg_episode_per_sec: 12.191457503882999
collect_time: 0.7382218243498355
reward_mean: 2172.2212066661077
reward_std: 758.1137505440137
reward_max: 3595.0100211929266
reward_min: 1378.9679960270425
total_envstep_count: 18511657
total_train_sample_count: 13901123
total_episode_count: 41818
total_duration: 3726.717497847047
[2023-06-29 13:25:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 2756.4916419755064
avg_train_sample_per_sec: 2756.4916419755064
avg_episode_per_sec: 10.642824872492303
collect_time: 0.7516801315294579
reward_mean: 1986.6725885305889
reward_std: 915.8524522833526
reward_max: 3658.362735733519
reward_min: 1054.6887689312775
total_envstep_count: 18516353
total_train_sample_count: 13904395
total_episode_count: 41826
total_duration: 3727.4691779785767
[2023-06-29 13:25:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1767
train_sample_count: 1767
avg_envstep_per_episode: 294.5
avg_sample_per_episode: 294.5
avg_envstep_per_sec: 2522.569952931624
avg_train_sample_per_sec: 2522.569952931624
avg_episode_per_sec: 8.565602556643883
collect_time: 0.7004761148234829
reward_mean: 2409.1468724236756
reward_std: 1016.001098305173
reward_max: 3687.3460420153106
reward_min: 1027.5836274739434
total_envstep_count: 18521009
total_train_sample_count: 13907762
total_episode_count: 41832
total_duration: 3728.1696540934004
[2023-06-29 13:25:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3010
train_sample_count: 3010
avg_envstep_per_episode: 273.6363636363636
avg_sample_per_episode: 273.6363636363636
avg_envstep_per_sec: 2494.558079168607
avg_train_sample_per_sec: 2494.558079168607
avg_episode_per_sec: 9.116325206264012
collect_time: 1.2066265464555472
reward_mean: 2213.543170740312
reward_std: 834.048609514734
reward_max: 3750.425655355711
reward_min: 1307.7316491395648
total_envstep_count: 18525169
total_train_sample_count: 13911172
total_episode_count: 41843
total_duration: 3729.376280639856
[2023-06-29 13:25:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2559
train_sample_count: 2559
avg_envstep_per_episode: 426.5
avg_sample_per_episode: 426.5
avg_envstep_per_sec: 2534.9522842071624
avg_train_sample_per_sec: 2534.9522842071624
avg_episode_per_sec: 5.94361614116568
collect_time: 1.0094864569809285
reward_mean: 2323.374365785209
reward_std: 547.1293319853827
reward_max: 3329.543374297092
reward_min: 1581.6322735825922
total_envstep_count: 18529641
total_train_sample_count: 13914531
total_episode_count: 41849
total_duration: 3730.385767096837
[2023-06-29 13:25:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1240
train_sample_count: 1240
avg_envstep_per_episode: 310.0
avg_sample_per_episode: 310.0
avg_envstep_per_sec: 2779.6375382034325
avg_train_sample_per_sec: 2779.6375382034325
avg_episode_per_sec: 8.96657270388204
collect_time: 0.44610132902488114
reward_mean: 2406.88812527042
reward_std: 833.6740459365326
reward_max: 3581.140232159904
reward_min: 1519.5680125397753
total_envstep_count: 18534193
total_train_sample_count: 13917771
total_episode_count: 41853
total_duration: 3730.8318684258616
[2023-06-29 13:25:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2058
train_sample_count: 2058
avg_envstep_per_episode: 343.0
avg_sample_per_episode: 343.0
avg_envstep_per_sec: 2673.6426352642225
avg_train_sample_per_sec: 2673.6426352642225
avg_episode_per_sec: 7.794876487650794
collect_time: 0.7697363786976783
reward_mean: 3489.5557224959175
reward_std: 195.56760809597614
reward_max: 3664.4277988589197
reward_min: 3099.3823179158194
total_envstep_count: 18538865
total_train_sample_count: 13921029
total_episode_count: 41859
total_duration: 3731.6016048045594
[2023-06-29 13:25:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2405
train_sample_count: 2405
avg_envstep_per_episode: 343.57142857142856
avg_sample_per_episode: 343.57142857142856
avg_envstep_per_sec: 2791.6225354948665
avg_train_sample_per_sec: 2791.6225354948665
avg_episode_per_sec: 8.125304677116036
collect_time: 0.8615061561586332
reward_mean: 2807.0793645513336
reward_std: 608.2299174770694
reward_max: 3607.679569396238
reward_min: 1800.4375943231432
total_envstep_count: 18544113
total_train_sample_count: 13924234
total_episode_count: 41866
total_duration: 3732.463110960718
[2023-06-29 13:25:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 312.25
avg_sample_per_episode: 312.25
avg_envstep_per_sec: 2706.8369187222675
avg_train_sample_per_sec: 2706.8369187222675
avg_episode_per_sec: 8.668813190463627
collect_time: 0.9228483558511361
reward_mean: 2345.94942555338
reward_std: 677.5422340097086
reward_max: 3162.0005320745363
reward_min: 992.2136369440974
total_envstep_count: 18548089
total_train_sample_count: 13927532
total_episode_count: 41874
total_duration: 3733.3859593165694
[2023-06-29 13:25:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1690
train_sample_count: 1690
avg_envstep_per_episode: 281.6666666666667
avg_sample_per_episode: 281.6666666666667
avg_envstep_per_sec: 2659.252210448305
avg_train_sample_per_sec: 2659.252210448305
avg_episode_per_sec: 9.44113210810049
collect_time: 0.6355170048782603
reward_mean: 1856.4547895220185
reward_std: 830.2827211865321
reward_max: 3647.5967310899064
reward_min: 1301.1073190915215
total_envstep_count: 18552385
total_train_sample_count: 13930822
total_episode_count: 41880
total_duration: 3734.0214763214476
[2023-06-29 13:25:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1327
train_sample_count: 1327
avg_envstep_per_episode: 189.57142857142858
avg_sample_per_episode: 189.57142857142858
avg_envstep_per_sec: 2606.0402756344442
avg_train_sample_per_sec: 2606.0402756344442
avg_episode_per_sec: 13.7470097433618
collect_time: 0.5092016468076035
reward_mean: 2307.666526876451
reward_std: 845.3005479112056
reward_max: 3590.9220922331715
reward_min: 1049.8691803649237
total_envstep_count: 18556929
total_train_sample_count: 13934149
total_episode_count: 41887
total_duration: 3734.530677968255
[2023-06-29 13:25:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1951
train_sample_count: 1951
avg_envstep_per_episode: 325.1666666666667
avg_sample_per_episode: 325.1666666666667
avg_envstep_per_sec: 2766.7224806107306
avg_train_sample_per_sec: 2766.7224806107306
avg_episode_per_sec: 8.508628848623466
collect_time: 0.7051664970638231
reward_mean: 2974.795548071861
reward_std: 890.6228270695103
reward_max: 3596.471578607069
reward_min: 1059.3676279989988
total_envstep_count: 18561313
total_train_sample_count: 13937700
total_episode_count: 41893
total_duration: 3735.2358444653187
[2023-06-29 13:25:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 492
train_sample_count: 492
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 2822.365311504766
avg_train_sample_per_sec: 2822.365311504766
avg_episode_per_sec: 17.209544582346133
collect_time: 0.17432187038101257
reward_mean: 2819.271371965225
reward_std: 549.5838273773217
reward_max: 3526.6402945026302
reward_min: 2186.686425678548
total_envstep_count: 18565025
total_train_sample_count: 13940992
total_episode_count: 41896
total_duration: 3735.4101663356996
[2023-06-29 13:25:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2288
train_sample_count: 2288
avg_envstep_per_episode: 326.85714285714283
avg_sample_per_episode: 326.85714285714283
avg_envstep_per_sec: 2641.6724454521814
avg_train_sample_per_sec: 2641.6724454521814
avg_episode_per_sec: 8.082039824372933
collect_time: 0.8661179791381584
reward_mean: 3408.524344548747
reward_std: 251.57796199659455
reward_max: 3680.602149805351
reward_min: 2849.9800453171365
total_envstep_count: 18569313
total_train_sample_count: 13944480
total_episode_count: 41903
total_duration: 3736.276284314838
[2023-06-29 13:25:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1246
train_sample_count: 1246
avg_envstep_per_episode: 311.5
avg_sample_per_episode: 311.5
avg_envstep_per_sec: 2644.6432629912233
avg_train_sample_per_sec: 2644.6432629912233
avg_episode_per_sec: 8.490026526456576
collect_time: 0.4711410485627131
reward_mean: 2726.256390160184
reward_std: 884.2006898158842
reward_max: 3592.749312978169
reward_min: 1567.401705867137
total_envstep_count: 18573873
total_train_sample_count: 13947726
total_episode_count: 41907
total_duration: 3736.747425363401
[2023-06-29 13:25:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 372.85714285714283
avg_sample_per_episode: 372.85714285714283
avg_envstep_per_sec: 2615.642459553949
avg_train_sample_per_sec: 2615.642459553949
avg_episode_per_sec: 7.015133033286453
collect_time: 0.9978428016668184
reward_mean: 3242.568547894545
reward_std: 351.72962291692903
reward_max: 3595.4104192688906
reward_min: 2591.6056344438175
total_envstep_count: 18578841
total_train_sample_count: 13951136
total_episode_count: 41914
total_duration: 3737.7452681650675
[2023-06-29 13:26:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 414.0
avg_sample_per_episode: 414.0
avg_envstep_per_sec: 2762.6195040133885
avg_train_sample_per_sec: 2762.6195040133885
avg_episode_per_sec: 6.672993971046832
collect_time: 0.44957331192214045
reward_mean: 2917.016695522077
reward_std: 882.5436892974504
reward_max: 3560.6707479392335
reward_min: 1669.1188616085146
total_envstep_count: 18582713
total_train_sample_count: 13954378
total_episode_count: 41917
total_duration: 3738.1948414769895
[2023-06-29 13:26:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1281
train_sample_count: 1281
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 2738.004993250225
avg_train_sample_per_sec: 2738.004993250225
avg_episode_per_sec: 12.824379359485834
collect_time: 0.46785889841616146
reward_mean: 3070.299158206369
reward_std: 774.8027343465719
reward_max: 3669.0431354512248
reward_min: 1542.2750811357655
total_envstep_count: 18587497
total_train_sample_count: 13957659
total_episode_count: 41923
total_duration: 3738.6627003754056
[2023-06-29 13:26:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2514
train_sample_count: 2514
avg_envstep_per_episode: 314.25
avg_sample_per_episode: 314.25
avg_envstep_per_sec: 2599.8151846563505
avg_train_sample_per_sec: 2599.8151846563505
avg_episode_per_sec: 8.273079346559587
collect_time: 0.9669918134324254
reward_mean: 2566.164423461343
reward_std: 862.1550240633592
reward_max: 3524.1695141785654
reward_min: 1120.1304867014167
total_envstep_count: 18592193
total_train_sample_count: 13960973
total_episode_count: 41931
total_duration: 3739.629692188838
[2023-06-29 13:26:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1160
train_sample_count: 1160
avg_envstep_per_episode: 232.0
avg_sample_per_episode: 232.0
avg_envstep_per_sec: 2790.589130833647
avg_train_sample_per_sec: 2790.589130833647
avg_episode_per_sec: 12.028401426007099
collect_time: 0.41568283456098293
reward_mean: 2161.758959840759
reward_std: 1139.3249778760187
reward_max: 3558.7168947579867
reward_min: 1029.3691636126039
total_envstep_count: 18597137
total_train_sample_count: 13964533
total_episode_count: 41936
total_duration: 3740.0453750233987
[2023-06-29 13:26:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1383
train_sample_count: 1383
avg_envstep_per_episode: 197.57142857142858
avg_sample_per_episode: 197.57142857142858
avg_envstep_per_sec: 2794.356543355428
avg_train_sample_per_sec: 2794.356543355428
avg_episode_per_sec: 14.143525526744757
collect_time: 0.49492610500566653
reward_mean: 2917.52266914922
reward_std: 906.4684864508765
reward_max: 3545.997052515135
reward_min: 1086.80518964274
total_envstep_count: 18601249
total_train_sample_count: 13967916
total_episode_count: 41943
total_duration: 3740.5403011284043
[2023-06-29 13:26:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1585
train_sample_count: 1585
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2762.574786001524
avg_train_sample_per_sec: 2762.574786001524
avg_episode_per_sec: 8.714746958995343
collect_time: 0.5737401238987221
reward_mean: 2712.3945706726354
reward_std: 1040.129295216796
reward_max: 3540.878691829121
reward_min: 1029.6678421575
total_envstep_count: 18605713
total_train_sample_count: 13971501
total_episode_count: 41948
total_duration: 3741.114041252303
[2023-06-29 13:26:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2347.9858193832715
avg_train_sample_per_sec: 2347.9858193832715
avg_episode_per_sec: 10.770577153134273
collect_time: 0.4642276759091767
reward_mean: 2997.9704576664267
reward_std: 742.4719405048916
reward_max: 3521.5606068177094
reward_min: 1602.6169594081684
total_envstep_count: 18610137
total_train_sample_count: 13974991
total_episode_count: 41953
total_duration: 3741.5782689282123
[2023-06-29 13:26:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1601
train_sample_count: 1601
avg_envstep_per_episode: 320.2
avg_sample_per_episode: 320.2
avg_envstep_per_sec: 2557.464943932144
avg_train_sample_per_sec: 2557.464943932144
avg_episode_per_sec: 7.987086021024809
collect_time: 0.6260105358622967
reward_mean: 3321.1962956835196
reward_std: 264.00753106133317
reward_max: 3545.5411987324237
reward_min: 2876.755386217203
total_envstep_count: 18613849
total_train_sample_count: 13978192
total_episode_count: 41958
total_duration: 3742.2042794640747
[2023-06-29 13:26:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 844
train_sample_count: 844
avg_envstep_per_episode: 281.3333333333333
avg_sample_per_episode: 281.3333333333333
avg_envstep_per_sec: 2766.1890987907823
avg_train_sample_per_sec: 2766.1890987907823
avg_episode_per_sec: 9.832425706602306
collect_time: 0.30511290799640123
reward_mean: 3503.6849739792233
reward_std: 12.581483181114775
reward_max: 3521.4760862838148
reward_min: 3494.5707382003884
total_envstep_count: 18618065
total_train_sample_count: 13981436
total_episode_count: 41961
total_duration: 3742.509392372071
[2023-06-29 13:26:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1646
train_sample_count: 1646
avg_envstep_per_episode: 329.2
avg_sample_per_episode: 329.2
avg_envstep_per_sec: 2797.7063053146453
avg_train_sample_per_sec: 2797.7063053146453
avg_episode_per_sec: 8.49850031991083
collect_time: 0.5883390965210273
reward_mean: 3525.8386636274954
reward_std: 11.69025404960509
reward_max: 3537.785130813138
reward_min: 3505.5356495157794
total_envstep_count: 18621849
total_train_sample_count: 13984682
total_episode_count: 41966
total_duration: 3743.097731468592
[2023-06-29 13:26:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1255
train_sample_count: 1255
avg_envstep_per_episode: 313.75
avg_sample_per_episode: 313.75
avg_envstep_per_sec: 2662.2595995803877
avg_train_sample_per_sec: 2662.2595995803877
avg_episode_per_sec: 8.485289560415577
collect_time: 0.4714040660038589
reward_mean: 3075.7667686844993
reward_std: 638.2631361259586
reward_max: 3540.3898363227972
reward_min: 1992.158015881802
total_envstep_count: 18626065
total_train_sample_count: 13987937
total_episode_count: 41970
total_duration: 3743.5691355345957
[2023-06-29 13:26:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1727
train_sample_count: 1727
avg_envstep_per_episode: 287.8333333333333
avg_sample_per_episode: 287.8333333333333
avg_envstep_per_sec: 2723.0668363596747
avg_train_sample_per_sec: 2723.0668363596747
avg_episode_per_sec: 9.460568047572696
collect_time: 0.6342113887695595
reward_mean: 2992.732762539063
reward_std: 913.9142005805586
reward_max: 3579.0872917785778
reward_min: 1032.9776548053126
total_envstep_count: 18630393
total_train_sample_count: 13991264
total_episode_count: 41976
total_duration: 3744.203346923365
[2023-06-29 13:26:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1757
train_sample_count: 1757
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2727.666713797874
avg_train_sample_per_sec: 2727.666713797874
avg_episode_per_sec: 10.867198062939735
collect_time: 0.6441402797168121
reward_mean: 2104.4502513923503
reward_std: 919.1467592771525
reward_max: 3527.786743697947
reward_min: 1348.8054644508743
total_envstep_count: 18634473
total_train_sample_count: 13994621
total_episode_count: 41983
total_duration: 3744.847487203082
[2023-06-29 13:26:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 447
train_sample_count: 447
avg_envstep_per_episode: 149.0
avg_sample_per_episode: 149.0
avg_envstep_per_sec: 2778.2057674102266
avg_train_sample_per_sec: 2778.2057674102266
avg_episode_per_sec: 18.645676291343804
collect_time: 0.1608952098665759
reward_mean: 3156.0634458596
reward_std: 376.65250687174535
reward_max: 3684.3216056810443
reward_min: 2832.7046957176385
total_envstep_count: 18638241
total_train_sample_count: 13997868
total_episode_count: 41986
total_duration: 3745.008382412949
[2023-06-29 13:26:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2111
train_sample_count: 2111
avg_envstep_per_episode: 351.8333333333333
avg_sample_per_episode: 351.8333333333333
avg_envstep_per_sec: 2778.508671423186
avg_train_sample_per_sec: 2778.508671423186
avg_episode_per_sec: 7.897229762453395
collect_time: 0.7597600906239821
reward_mean: 3482.4868530208296
reward_std: 131.8657802005395
reward_max: 3647.9332990083467
reward_min: 3281.938804260223
total_envstep_count: 18642337
total_train_sample_count: 14001179
total_episode_count: 41992
total_duration: 3745.7681425035726
[2023-06-29 13:26:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1955
train_sample_count: 1955
avg_envstep_per_episode: 279.2857142857143
avg_sample_per_episode: 279.2857142857143
avg_envstep_per_sec: 2483.0143342660845
avg_train_sample_per_sec: 2483.0143342660845
avg_episode_per_sec: 8.890588409136875
collect_time: 0.7873494619103147
reward_mean: 2291.6528156680474
reward_std: 701.9087034156338
reward_max: 3558.0213791244205
reward_min: 1580.417345059925
total_envstep_count: 18647313
total_train_sample_count: 14004734
total_episode_count: 41999
total_duration: 3746.555491965483
[2023-06-29 13:26:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2989
train_sample_count: 2989
avg_envstep_per_episode: 332.1111111111111
avg_sample_per_episode: 332.1111111111111
avg_envstep_per_sec: 2561.650966067367
avg_train_sample_per_sec: 2561.650966067367
avg_episode_per_sec: 7.713234758985046
collect_time: 1.1668256290936845
reward_mean: 2552.2326029164515
reward_std: 706.1333459111834
reward_max: 3531.6777608089155
reward_min: 1684.220057406318
total_envstep_count: 18652209
total_train_sample_count: 14008123
total_episode_count: 42008
total_duration: 3747.7223175945765
[2023-06-29 13:26:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1902
train_sample_count: 1902
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2723.9976699110384
avg_train_sample_per_sec: 2723.9976699110384
avg_episode_per_sec: 8.593052586470153
collect_time: 0.698238482730463
reward_mean: 2348.909830217323
reward_std: 581.5257898254014
reward_max: 3101.229986698548
reward_min: 1491.9902946840239
total_envstep_count: 18656889
total_train_sample_count: 14011625
total_episode_count: 42014
total_duration: 3748.420556077307
[2023-06-29 13:26:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2368
train_sample_count: 2368
avg_envstep_per_episode: 296.0
avg_sample_per_episode: 296.0
avg_envstep_per_sec: 2776.329022554542
avg_train_sample_per_sec: 2776.329022554542
avg_episode_per_sec: 9.379489941062642
collect_time: 0.8529248445564883
reward_mean: 2427.623763278837
reward_std: 416.6291783937285
reward_max: 3118.1550755740986
reward_min: 1831.6958677940563
total_envstep_count: 18661865
total_train_sample_count: 14015193
total_episode_count: 42022
total_duration: 3749.2734809218637
[2023-06-29 13:27:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 250.875
avg_sample_per_episode: 250.875
avg_envstep_per_sec: 2792.313069053053
avg_train_sample_per_sec: 2792.313069053053
avg_episode_per_sec: 11.1302962393744
collect_time: 0.718758946567774
reward_mean: 1874.70167235007
reward_std: 900.6499216054864
reward_max: 3645.0274969528004
reward_min: 723.8871483691817
total_envstep_count: 18666177
total_train_sample_count: 14018400
total_episode_count: 42030
total_duration: 3749.9922398684316
[2023-06-29 13:27:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2024
train_sample_count: 2024
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2797.11960261161
avg_train_sample_per_sec: 2797.11960261161
avg_episode_per_sec: 11.055808705974743
collect_time: 0.7236015214044602
reward_mean: 2125.978094488463
reward_std: 577.8105143751708
reward_max: 3558.549955681599
reward_min: 1586.8384377714729
total_envstep_count: 18670457
total_train_sample_count: 14021624
total_episode_count: 42038
total_duration: 3750.715841389836
[2023-06-29 13:27:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1668
train_sample_count: 1668
avg_envstep_per_episode: 333.6
avg_sample_per_episode: 333.6
avg_envstep_per_sec: 2674.0292743805744
avg_train_sample_per_sec: 2674.0292743805744
avg_episode_per_sec: 8.01567528291539
collect_time: 0.6237777633853256
reward_mean: 2320.649824770759
reward_std: 1022.8043201817412
reward_max: 3522.0875961768675
reward_min: 1045.6416209996473
total_envstep_count: 18674457
total_train_sample_count: 14024892
total_episode_count: 42043
total_duration: 3751.3396191532215
[2023-06-29 13:27:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1663
train_sample_count: 1663
avg_envstep_per_episode: 277.1666666666667
avg_sample_per_episode: 277.1666666666667
avg_envstep_per_sec: 2839.8326377269896
avg_train_sample_per_sec: 2839.8326377269896
avg_episode_per_sec: 10.245938560650593
collect_time: 0.5855978897865862
reward_mean: 2707.1312123502935
reward_std: 928.657087735662
reward_max: 3686.4629932143557
reward_min: 1421.6391386743744
total_envstep_count: 18678289
total_train_sample_count: 14028155
total_episode_count: 42049
total_duration: 3751.925217043008
[2023-06-29 13:27:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1810
train_sample_count: 1810
avg_envstep_per_episode: 226.25
avg_sample_per_episode: 226.25
avg_envstep_per_sec: 2614.5093727105104
avg_train_sample_per_sec: 2614.5093727105104
avg_episode_per_sec: 11.555842531317172
collect_time: 0.6922904996601865
reward_mean: 2020.1434178311006
reward_std: 476.1161702131428
reward_max: 2727.2678698902914
reward_min: 1280.7323428863701
total_envstep_count: 18682241
total_train_sample_count: 14031565
total_episode_count: 42057
total_duration: 3752.617507542668
[2023-06-29 13:27:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2852
train_sample_count: 2852
avg_envstep_per_episode: 356.5
avg_sample_per_episode: 356.5
avg_envstep_per_sec: 2592.8219866030263
avg_train_sample_per_sec: 2592.8219866030263
avg_episode_per_sec: 7.272992949798111
collect_time: 1.0999598178109151
reward_mean: 2194.3339360922137
reward_std: 839.779992759485
reward_max: 3546.4997290416663
reward_min: 1274.4337537648476
total_envstep_count: 18687025
total_train_sample_count: 14034817
total_episode_count: 42065
total_duration: 3753.717467360479
[2023-06-29 13:27:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 230.4
avg_sample_per_episode: 230.4
avg_envstep_per_sec: 2653.195860393559
avg_train_sample_per_sec: 2653.195860393559
avg_episode_per_sec: 11.515607032958155
collect_time: 0.43419335044082247
reward_mean: 2043.3083631136942
reward_std: 823.883677626402
reward_max: 3586.912990114452
reward_min: 1295.4029521067623
total_envstep_count: 18691969
total_train_sample_count: 14038369
total_episode_count: 42070
total_duration: 3754.1516607109197
[2023-06-29 13:27:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 290.4
avg_sample_per_episode: 290.4
avg_envstep_per_sec: 2773.086477671161
avg_train_sample_per_sec: 2773.086477671161
avg_episode_per_sec: 9.549195859749176
collect_time: 0.5236042985646052
reward_mean: 3562.414683835438
reward_std: 55.929424581812
reward_max: 3672.370062904483
reward_min: 3515.5553909442096
total_envstep_count: 18696761
total_train_sample_count: 14041821
total_episode_count: 42075
total_duration: 3754.6752650094845
[2023-06-29 13:27:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 207.5
avg_sample_per_episode: 207.5
avg_envstep_per_sec: 2752.4118470316753
avg_train_sample_per_sec: 2752.4118470316753
avg_episode_per_sec: 13.264635407381567
collect_time: 0.4523305628634988
reward_mean: 2524.843944052905
reward_std: 966.3750801762114
reward_max: 3572.8660854043505
reward_min: 1370.4843487235119
total_envstep_count: 18700961
total_train_sample_count: 14045066
total_episode_count: 42081
total_duration: 3755.127595572348
[2023-06-29 13:27:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 167.4
avg_sample_per_episode: 167.4
avg_envstep_per_sec: 2245.1086704018176
avg_train_sample_per_sec: 2245.1086704018176
avg_episode_per_sec: 13.41164080287824
collect_time: 0.37281046170927584
reward_mean: 3176.20237612555
reward_std: 711.6632988693104
reward_max: 3650.165146048274
reward_min: 1758.263888007863
total_envstep_count: 18706041
total_train_sample_count: 14048303
total_episode_count: 42086
total_duration: 3755.5004060340575
[2023-06-29 13:27:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2437
train_sample_count: 2437
avg_envstep_per_episode: 348.14285714285717
avg_sample_per_episode: 348.14285714285717
avg_envstep_per_sec: 2774.017541477109
avg_train_sample_per_sec: 2774.017541477109
avg_episode_per_sec: 7.968043820410243
collect_time: 0.8785092248199506
reward_mean: 3235.2547650792862
reward_std: 721.6364593097455
reward_max: 3558.2065834484074
reward_min: 1468.4802368911137
total_envstep_count: 18710841
total_train_sample_count: 14051540
total_episode_count: 42093
total_duration: 3756.3789152588774
[2023-06-29 13:27:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 117
train_sample_count: 117
avg_envstep_per_episode: 39.0
avg_sample_per_episode: 39.0
avg_envstep_per_sec: 2678.6381461567785
avg_train_sample_per_sec: 2678.6381461567785
avg_episode_per_sec: 68.68302938863535
collect_time: 0.04367891205009073
reward_mean: 2802.1761295343554
reward_std: 1030.7136728324224
reward_max: 3552.173395833847
reward_min: 1344.7339235120933
total_envstep_count: 18714601
total_train_sample_count: 14054857
total_episode_count: 42096
total_duration: 3756.4225941709274
[2023-06-29 13:27:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2025
train_sample_count: 2025
avg_envstep_per_episode: 337.5
avg_sample_per_episode: 337.5
avg_envstep_per_sec: 2754.8268983260937
avg_train_sample_per_sec: 2754.8268983260937
avg_episode_per_sec: 8.162450069114351
collect_time: 0.7350734092332423
reward_mean: 3399.4090938474224
reward_std: 159.88139690288858
reward_max: 3552.9230950820097
reward_min: 3104.351000901635
total_envstep_count: 18719025
total_train_sample_count: 14058082
total_episode_count: 42102
total_duration: 3757.1576675801607
[2023-06-29 13:27:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2328
train_sample_count: 2328
avg_envstep_per_episode: 258.6666666666667
avg_sample_per_episode: 258.6666666666667
avg_envstep_per_sec: 2567.8751342892374
avg_train_sample_per_sec: 2567.8751342892374
avg_episode_per_sec: 9.927352323283134
collect_time: 0.9065861376645042
reward_mean: 2221.182690227526
reward_std: 820.1126076603172
reward_max: 3561.3987897046572
reward_min: 1326.6489416357178
total_envstep_count: 18724201
total_train_sample_count: 14061610
total_episode_count: 42111
total_duration: 3758.064253717825
[2023-06-29 13:27:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1995
train_sample_count: 1995
avg_envstep_per_episode: 221.66666666666666
avg_sample_per_episode: 221.66666666666666
avg_envstep_per_sec: 2733.191583630659
avg_train_sample_per_sec: 2733.191583630659
avg_episode_per_sec: 12.330187595326281
collect_time: 0.7299159019617367
reward_mean: 2082.6570085188455
reward_std: 760.2988401835513
reward_max: 3156.62159517319
reward_min: 1151.2106419504782
total_envstep_count: 18729257
total_train_sample_count: 14065205
total_episode_count: 42120
total_duration: 3758.7941696197868
[2023-06-29 13:27:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2859
train_sample_count: 2859
avg_envstep_per_episode: 317.6666666666667
avg_sample_per_episode: 317.6666666666667
avg_envstep_per_sec: 2621.514919079308
avg_train_sample_per_sec: 2621.514919079308
avg_episode_per_sec: 8.252407929945356
collect_time: 1.0905907798549161
reward_mean: 2430.4437395514683
reward_std: 972.2454874883304
reward_max: 3651.1927156189586
reward_min: 1181.7613597492477
total_envstep_count: 18733865
total_train_sample_count: 14068464
total_episode_count: 42129
total_duration: 3759.884760399642
[2023-06-29 13:27:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 212.33333333333334
avg_sample_per_episode: 212.33333333333334
avg_envstep_per_sec: 2771.537301859429
avg_train_sample_per_sec: 2771.537301859429
avg_episode_per_sec: 13.052765942823058
collect_time: 0.4596726874811575
reward_mean: 1752.1996514929033
reward_std: 341.9128963315182
reward_max: 2209.6078121462847
reward_min: 1364.824379197091
total_envstep_count: 18738009
total_train_sample_count: 14071738
total_episode_count: 42135
total_duration: 3760.344433087123
[2023-06-29 13:27:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 267.25
avg_sample_per_episode: 267.25
avg_envstep_per_sec: 2597.249800580263
avg_train_sample_per_sec: 2597.249800580263
avg_episode_per_sec: 9.718427691600612
collect_time: 1.2347676373999565
reward_mean: 1979.3939766320834
reward_std: 677.9934782724386
reward_max: 3005.3212866855897
reward_min: 1186.9821796908209
total_envstep_count: 18742345
total_train_sample_count: 14074945
total_episode_count: 42147
total_duration: 3761.579200724523
[2023-06-29 13:27:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2585
train_sample_count: 2585
avg_envstep_per_episode: 258.5
avg_sample_per_episode: 258.5
avg_envstep_per_sec: 2611.280623252548
avg_train_sample_per_sec: 2611.280623252548
avg_episode_per_sec: 10.10166585397504
collect_time: 0.9899357338240371
reward_mean: 1396.8331135185363
reward_std: 221.35392061121559
reward_max: 1761.7106579490342
reward_min: 1097.082112020483
total_envstep_count: 18746729
total_train_sample_count: 14078330
total_episode_count: 42157
total_duration: 3762.569136458347
[2023-06-29 13:27:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1924
train_sample_count: 1924
avg_envstep_per_episode: 274.85714285714283
avg_sample_per_episode: 274.85714285714283
avg_envstep_per_sec: 2681.698814451331
avg_train_sample_per_sec: 2681.698814451331
avg_episode_per_sec: 9.756700468378023
collect_time: 0.7174556626686825
reward_mean: 1915.2102361033897
reward_std: 693.679297458747
reward_max: 2810.094331572743
reward_min: 406.753521593641
total_envstep_count: 18751793
total_train_sample_count: 14081854
total_episode_count: 42164
total_duration: 3763.286592121016
[2023-06-29 13:28:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2412
train_sample_count: 2412
avg_envstep_per_episode: 219.27272727272728
avg_sample_per_episode: 219.27272727272728
avg_envstep_per_sec: 2756.5039063233758
avg_train_sample_per_sec: 2756.5039063233758
avg_episode_per_sec: 12.571120634144748
collect_time: 0.8750214336598293
reward_mean: 1902.7491607840611
reward_std: 846.8033588350122
reward_max: 3636.2135119240024
reward_min: 868.3599351361049
total_envstep_count: 18755985
total_train_sample_count: 14085066
total_episode_count: 42175
total_duration: 3764.1616135546756
[2023-06-29 13:28:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3359
train_sample_count: 3359
avg_envstep_per_episode: 335.9
avg_sample_per_episode: 335.9
avg_envstep_per_sec: 2557.0891918801794
avg_train_sample_per_sec: 2557.0891918801794
avg_episode_per_sec: 7.612650169336646
collect_time: 1.3136029868125916
reward_mean: 1892.1344429950332
reward_std: 719.7182568016939
reward_max: 3567.2354908588422
reward_min: 1092.2670250791982
total_envstep_count: 18761129
total_train_sample_count: 14088425
total_episode_count: 42185
total_duration: 3765.475216541488
[2023-06-29 13:28:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2283
train_sample_count: 2283
avg_envstep_per_episode: 285.375
avg_sample_per_episode: 285.375
avg_envstep_per_sec: 2569.8543526140725
avg_train_sample_per_sec: 2569.8543526140725
avg_episode_per_sec: 9.00518389001865
collect_time: 0.8883771944809704
reward_mean: 1695.6222069488088
reward_std: 505.0391955427377
reward_max: 2403.9757069258776
reward_min: 1085.4798466861453
total_envstep_count: 18766081
total_train_sample_count: 14091908
total_episode_count: 42193
total_duration: 3766.363593735969
[2023-06-29 13:28:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 157.75
avg_sample_per_episode: 157.75
avg_envstep_per_sec: 2681.0533707682703
avg_train_sample_per_sec: 2681.0533707682703
avg_episode_per_sec: 16.99558396683531
collect_time: 0.47071051018964505
reward_mean: 1910.2400795540643
reward_std: 872.3120876350921
reward_max: 3638.9930784377225
reward_min: 416.56914801370044
total_envstep_count: 18770553
total_train_sample_count: 14095170
total_episode_count: 42201
total_duration: 3766.834304246159
[2023-06-29 13:28:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 748
train_sample_count: 748
avg_envstep_per_episode: 106.85714285714286
avg_sample_per_episode: 106.85714285714286
avg_envstep_per_sec: 2785.37083938492
avg_train_sample_per_sec: 2785.37083938492
avg_episode_per_sec: 26.066304646650323
collect_time: 0.2685459291177103
reward_mean: 2145.6336948280123
reward_std: 416.4470199832312
reward_max: 2601.1443123415465
reward_min: 1354.168338398488
total_envstep_count: 18774633
total_train_sample_count: 14098718
total_episode_count: 42208
total_duration: 3767.1028501752767
[2023-06-29 13:28:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2138
train_sample_count: 2138
avg_envstep_per_episode: 267.25
avg_sample_per_episode: 267.25
avg_envstep_per_sec: 2783.808264700052
avg_train_sample_per_sec: 2783.808264700052
avg_episode_per_sec: 10.416494910009549
collect_time: 0.7680126634836196
reward_mean: 2426.664123022564
reward_std: 604.2184069343003
reward_max: 3216.22514030118
reward_min: 1657.0403091679366
total_envstep_count: 18778961
total_train_sample_count: 14102056
total_episode_count: 42216
total_duration: 3767.8708628387603
[2023-06-29 13:28:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1247
train_sample_count: 1247
avg_envstep_per_episode: 207.83333333333334
avg_sample_per_episode: 207.83333333333334
avg_envstep_per_sec: 2359.203513252531
avg_train_sample_per_sec: 2359.203513252531
avg_episode_per_sec: 11.351420272265587
collect_time: 0.5285682193143293
reward_mean: 1984.054174849287
reward_std: 679.6014460557726
reward_max: 3260.7844421316436
reward_min: 1317.697189407163
total_envstep_count: 18783193
total_train_sample_count: 14105303
total_episode_count: 42222
total_duration: 3768.3994310580747
[2023-06-29 13:28:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2866
train_sample_count: 2866
avg_envstep_per_episode: 409.42857142857144
avg_sample_per_episode: 409.42857142857144
avg_envstep_per_sec: 2556.486670623753
avg_train_sample_per_sec: 2556.486670623753
avg_episode_per_sec: 6.2440358319491525
collect_time: 1.1210697997892276
reward_mean: 3258.7173401743735
reward_std: 626.5913890913894
reward_max: 3615.7703723599548
reward_min: 1736.2261283116875
total_envstep_count: 18787721
total_train_sample_count: 14108569
total_episode_count: 42229
total_duration: 3769.520500857864
[2023-06-29 13:28:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2243
train_sample_count: 2243
avg_envstep_per_episode: 373.8333333333333
avg_sample_per_episode: 373.8333333333333
avg_envstep_per_sec: 2750.716154245184
avg_train_sample_per_sec: 2750.716154245184
avg_episode_per_sec: 7.35813505370981
collect_time: 0.8154240111391992
reward_mean: 2054.0010346111744
reward_std: 788.5833741580751
reward_max: 3642.468212253251
reward_min: 1389.5913676576133
total_envstep_count: 18792657
total_train_sample_count: 14112012
total_episode_count: 42235
total_duration: 3770.3359248690035
[2023-06-29 13:28:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3299
train_sample_count: 3299
avg_envstep_per_episode: 274.9166666666667
avg_sample_per_episode: 274.9166666666667
avg_envstep_per_sec: 2747.459991682859
avg_train_sample_per_sec: 2747.459991682859
avg_episode_per_sec: 9.993792027946137
collect_time: 1.2007454194007443
reward_mean: 2033.9959953249074
reward_std: 847.7154555181619
reward_max: 3536.092630015132
reward_min: 1350.7476868308327
total_envstep_count: 18797497
total_train_sample_count: 14115311
total_episode_count: 42247
total_duration: 3771.5366702884044
[2023-06-29 13:28:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2274
train_sample_count: 2274
avg_envstep_per_episode: 227.4
avg_sample_per_episode: 227.4
avg_envstep_per_sec: 2780.454757549447
avg_train_sample_per_sec: 2780.454757549447
avg_episode_per_sec: 12.227153727130375
collect_time: 0.8178518257942053
reward_mean: 1435.1142324215273
reward_std: 335.10245775713395
reward_max: 2234.302704394159
reward_min: 1027.774598934972
total_envstep_count: 18802049
total_train_sample_count: 14118785
total_episode_count: 42257
total_duration: 3772.3545221141985
[2023-06-29 13:28:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3399
train_sample_count: 3399
avg_envstep_per_episode: 242.78571428571428
avg_sample_per_episode: 242.78571428571428
avg_envstep_per_sec: 2612.3039816798964
avg_train_sample_per_sec: 2612.3039816798964
avg_episode_per_sec: 10.75971042763123
collect_time: 1.3011502581005914
reward_mean: 1489.900629581696
reward_std: 567.3016549225392
reward_max: 3114.2611936188755
reward_min: 877.4175802746755
total_envstep_count: 18807161
total_train_sample_count: 14122184
total_episode_count: 42271
total_duration: 3773.6556723722993
[2023-06-29 13:28:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1844
train_sample_count: 1844
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 2671.5091640981095
avg_train_sample_per_sec: 2671.5091640981095
avg_episode_per_sec: 11.5900614494495
collect_time: 0.6902465560594574
reward_mean: 1616.2497979396649
reward_std: 352.35015675209337
reward_max: 2075.5835391822866
reward_min: 1136.6291288845814
total_envstep_count: 18811913
total_train_sample_count: 14125628
total_episode_count: 42279
total_duration: 3774.3459189283585
[2023-06-29 13:28:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3112
train_sample_count: 3112
avg_envstep_per_episode: 259.3333333333333
avg_sample_per_episode: 259.3333333333333
avg_envstep_per_sec: 2616.307032641154
avg_train_sample_per_sec: 2616.307032641154
avg_episode_per_sec: 10.088587529464604
collect_time: 1.1894628425389528
reward_mean: 1880.491994316589
reward_std: 789.690454423265
reward_max: 3516.5835194142915
reward_min: 1132.027534829703
total_envstep_count: 18816961
total_train_sample_count: 14129140
total_episode_count: 42291
total_duration: 3775.5353817708974
[2023-06-29 13:28:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2913
train_sample_count: 2913
avg_envstep_per_episode: 291.3
avg_sample_per_episode: 291.3
avg_envstep_per_sec: 2757.0075468659898
avg_train_sample_per_sec: 2757.0075468659898
avg_episode_per_sec: 9.46449552648812
collect_time: 1.0565803504278883
reward_mean: 1802.3232219171628
reward_std: 426.05035537166583
reward_max: 2777.1652440466446
reward_min: 1191.5893543319821
total_envstep_count: 18821353
total_train_sample_count: 14132453
total_episode_count: 42301
total_duration: 3776.591962121325
[2023-06-29 13:28:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 302.5
avg_sample_per_episode: 302.5
avg_envstep_per_sec: 2834.064883553326
avg_train_sample_per_sec: 2834.064883553326
avg_episode_per_sec: 9.368809532407688
collect_time: 0.8538971757646653
reward_mean: 1736.1029758844606
reward_std: 524.2530187995352
reward_max: 2848.5378337011625
reward_min: 1234.6522741016615
total_envstep_count: 18825889
total_train_sample_count: 14135673
total_episode_count: 42309
total_duration: 3777.44585929709
[2023-06-29 13:28:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1952
train_sample_count: 1952
avg_envstep_per_episode: 216.88888888888889
avg_sample_per_episode: 216.88888888888889
avg_envstep_per_sec: 2530.879667292808
avg_train_sample_per_sec: 2530.879667292808
avg_episode_per_sec: 11.669014859444298
collect_time: 0.7712733344165609
reward_mean: 1560.2104356494826
reward_std: 710.5020080095443
reward_max: 3149.0728195785737
reward_min: 407.49542945456176
total_envstep_count: 18830401
total_train_sample_count: 14139225
total_episode_count: 42318
total_duration: 3778.2171326315065
[2023-06-29 13:28:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2625
train_sample_count: 2625
avg_envstep_per_episode: 262.5
avg_sample_per_episode: 262.5
avg_envstep_per_sec: 2630.167319557193
avg_train_sample_per_sec: 2630.167319557193
avg_episode_per_sec: 10.019685026884545
collect_time: 0.9980353647014126
reward_mean: 2081.067483764986
reward_std: 809.3672859620925
reward_max: 3569.3383764659325
reward_min: 1224.442929073864
total_envstep_count: 18835441
total_train_sample_count: 14142650
total_episode_count: 42328
total_duration: 3779.215167996208
[2023-06-29 13:28:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2416
train_sample_count: 2416
avg_envstep_per_episode: 241.6
avg_sample_per_episode: 241.6
avg_envstep_per_sec: 2793.703345285426
avg_train_sample_per_sec: 2793.703345285426
avg_episode_per_sec: 11.563341660949613
collect_time: 0.8648019139459358
reward_mean: 1747.6371629773555
reward_std: 500.26647879764926
reward_max: 2496.1804662962786
reward_min: 804.9408819848742
total_envstep_count: 18839977
total_train_sample_count: 14145866
total_episode_count: 42338
total_duration: 3780.079969910154
[2023-06-29 13:29:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2561
train_sample_count: 2561
avg_envstep_per_episode: 284.55555555555554
avg_sample_per_episode: 284.55555555555554
avg_envstep_per_sec: 2754.856477643838
avg_train_sample_per_sec: 2754.856477643838
avg_episode_per_sec: 9.68126056180966
collect_time: 0.9296310064727442
reward_mean: 1940.6767335499999
reward_std: 519.7040922209262
reward_max: 2939.93417073153
reward_min: 1345.9017623749112
total_envstep_count: 18844585
total_train_sample_count: 14149227
total_episode_count: 42347
total_duration: 3781.009600916627
[2023-06-29 13:29:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2094
train_sample_count: 2094
avg_envstep_per_episode: 261.75
avg_sample_per_episode: 261.75
avg_envstep_per_sec: 2641.4648350636176
avg_train_sample_per_sec: 2641.4648350636176
avg_episode_per_sec: 10.091556198905893
collect_time: 0.7927419559797273
reward_mean: 1908.000045682293
reward_std: 567.8477864360345
reward_max: 2686.0925288106696
reward_min: 1045.443122793098
total_envstep_count: 18849033
total_train_sample_count: 14152521
total_episode_count: 42355
total_duration: 3781.8023428726065
[2023-06-29 13:29:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3112
train_sample_count: 3112
avg_envstep_per_episode: 282.90909090909093
avg_sample_per_episode: 282.90909090909093
avg_envstep_per_sec: 2634.236469037977
avg_train_sample_per_sec: 2634.236469037977
avg_episode_per_sec: 9.311247159195934
collect_time: 1.1813669868204741
reward_mean: 1900.2704178552774
reward_std: 657.3759966184587
reward_max: 3145.6306484732972
reward_min: 1062.9769433466236
total_envstep_count: 18853481
total_train_sample_count: 14156033
total_episode_count: 42366
total_duration: 3782.983709859427
[2023-06-29 13:29:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2904
train_sample_count: 2904
avg_envstep_per_episode: 264.0
avg_sample_per_episode: 264.0
avg_envstep_per_sec: 2567.546330666623
avg_train_sample_per_sec: 2567.546330666623
avg_episode_per_sec: 9.725554282828117
collect_time: 1.1310409340290355
reward_mean: 1444.6327268195043
reward_std: 311.39685052392394
reward_max: 2202.3421032877104
reward_min: 1115.6444487045349
total_envstep_count: 18858049
total_train_sample_count: 14159337
total_episode_count: 42377
total_duration: 3784.114750793456
[2023-06-29 13:29:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 246.91666666666666
avg_sample_per_episode: 246.91666666666666
avg_envstep_per_sec: 2813.1944854587227
avg_train_sample_per_sec: 2813.1944854587227
avg_episode_per_sec: 11.393295249917204
collect_time: 1.053251033768058
reward_mean: 1445.74812566469
reward_std: 331.82820003521266
reward_max: 2271.8433592390215
reward_min: 1138.030540520972
total_envstep_count: 18862465
total_train_sample_count: 14162700
total_episode_count: 42389
total_duration: 3785.168001827224
[2023-06-29 13:29:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3265
train_sample_count: 3265
avg_envstep_per_episode: 272.0833333333333
avg_sample_per_episode: 272.0833333333333
avg_envstep_per_sec: 2607.4986242649557
avg_train_sample_per_sec: 2607.4986242649557
avg_episode_per_sec: 9.583455893163697
collect_time: 1.2521578993815927
reward_mean: 1475.4864756093332
reward_std: 323.4465515057626
reward_max: 2269.618209867995
reward_min: 1058.2896715399427
total_envstep_count: 18866929
total_train_sample_count: 14165965
total_episode_count: 42401
total_duration: 3786.4201597266056
[2023-06-29 13:29:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2870
train_sample_count: 2870
avg_envstep_per_episode: 260.90909090909093
avg_sample_per_episode: 260.90909090909093
avg_envstep_per_sec: 2589.7741543601983
avg_train_sample_per_sec: 2589.7741543601983
avg_episode_per_sec: 9.925963657826543
collect_time: 1.1082047425517811
reward_mean: 1374.4605823760373
reward_std: 313.0355513719299
reward_max: 2009.0928867479488
reward_min: 717.4257137029156
total_envstep_count: 18871337
total_train_sample_count: 14169235
total_episode_count: 42412
total_duration: 3787.528364469157
[2023-06-29 13:29:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2882
train_sample_count: 2882
avg_envstep_per_episode: 240.16666666666666
avg_sample_per_episode: 240.16666666666666
avg_envstep_per_sec: 2729.4701599846526
avg_train_sample_per_sec: 2729.4701599846526
avg_episode_per_sec: 11.364900041573849
collect_time: 1.0558825819939373
reward_mean: 1379.8289685398092
reward_std: 368.13930789329686
reward_max: 2317.0127867420338
reward_min: 844.2145472463224
total_envstep_count: 18875737
total_train_sample_count: 14172517
total_episode_count: 42424
total_duration: 3788.584247051151
[2023-06-29 13:29:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3278
train_sample_count: 3278
avg_envstep_per_episode: 234.14285714285714
avg_sample_per_episode: 234.14285714285714
avg_envstep_per_sec: 2764.017630815728
avg_train_sample_per_sec: 2764.017630815728
avg_episode_per_sec: 11.804834298785904
collect_time: 1.1859548084838314
reward_mean: 1287.032651523911
reward_std: 330.5593150094924
reward_max: 1940.48554670769
reward_min: 418.34649910586126
total_envstep_count: 18879785
total_train_sample_count: 14175795
total_episode_count: 42438
total_duration: 3789.770201859635
[2023-06-29 13:29:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2861
train_sample_count: 2861
avg_envstep_per_episode: 317.8888888888889
avg_sample_per_episode: 317.8888888888889
avg_envstep_per_sec: 2650.056095006016
avg_train_sample_per_sec: 2650.056095006016
avg_episode_per_sec: 8.336422528854996
collect_time: 1.0795997886201367
reward_mean: 1503.2293615170827
reward_std: 351.8168320380462
reward_max: 2024.7162965735756
reward_min: 1188.6930593476045
total_envstep_count: 18884169
total_train_sample_count: 14179056
total_episode_count: 42447
total_duration: 3790.8498016482554
[2023-06-29 13:29:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 233.41666666666666
avg_sample_per_episode: 233.41666666666666
avg_envstep_per_sec: 2781.508472921919
avg_train_sample_per_sec: 2781.508472921919
avg_episode_per_sec: 11.916494707269912
collect_time: 1.0070075382720678
reward_mean: 1362.9976201071092
reward_std: 396.74769653222955
reward_max: 2525.897518889894
reward_min: 1002.2206073491067
total_envstep_count: 18888569
total_train_sample_count: 14182257
total_episode_count: 42459
total_duration: 3791.8568091865272
[2023-06-29 13:29:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3352
train_sample_count: 3352
avg_envstep_per_episode: 257.84615384615387
avg_sample_per_episode: 257.84615384615387
avg_envstep_per_sec: 2742.806719206418
avg_train_sample_per_sec: 2742.806719206418
avg_episode_per_sec: 10.637376894296969
collect_time: 1.2221058000652123
reward_mean: 1427.7980427732005
reward_std: 497.39417144415637
reward_max: 2787.210404587421
reward_min: 983.5938976891731
total_envstep_count: 18893625
total_train_sample_count: 14185609
total_episode_count: 42472
total_duration: 3793.0789149865923
[2023-06-29 13:29:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3286
train_sample_count: 3286
avg_envstep_per_episode: 219.06666666666666
avg_sample_per_episode: 219.06666666666666
avg_envstep_per_sec: 2748.801942630859
avg_train_sample_per_sec: 2748.801942630859
avg_episode_per_sec: 12.547787321808546
collect_time: 1.1954298885772006
reward_mean: 1249.9460745215713
reward_std: 150.33647573026758
reward_max: 1654.328940045477
reward_min: 1026.0391253656212
total_envstep_count: 18898137
total_train_sample_count: 14188895
total_episode_count: 42487
total_duration: 3794.2743448751694
[2023-06-29 13:29:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3192
train_sample_count: 3192
avg_envstep_per_episode: 245.53846153846155
avg_sample_per_episode: 245.53846153846155
avg_envstep_per_sec: 2644.8549633254324
avg_train_sample_per_sec: 2644.8549633254324
avg_episode_per_sec: 10.771652419558466
collect_time: 1.2068714709356427
reward_mean: 1281.318946433198
reward_std: 145.57704577436309
reward_max: 1568.7818342991357
reward_min: 1053.235681438756
total_envstep_count: 18902441
total_train_sample_count: 14192487
total_episode_count: 42500
total_duration: 3795.481216346105
[2023-06-29 13:29:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 293.27272727272725
avg_sample_per_episode: 293.27272727272725
avg_envstep_per_sec: 2563.6877866456875
avg_train_sample_per_sec: 2563.6877866456875
avg_episode_per_sec: 8.74165085341059
collect_time: 1.2583435536902399
reward_mean: 1492.7781279539727
reward_std: 267.93799196646313
reward_max: 2231.421782401213
reward_min: 1235.8698390709665
total_envstep_count: 18906905
total_train_sample_count: 14195713
total_episode_count: 42511
total_duration: 3796.7395598997955
[2023-06-29 13:29:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2893
train_sample_count: 2893
avg_envstep_per_episode: 241.08333333333334
avg_sample_per_episode: 241.08333333333334
avg_envstep_per_sec: 2795.299919616775
avg_train_sample_per_sec: 2795.299919616775
avg_episode_per_sec: 11.594745605047112
collect_time: 1.03495155553706
reward_mean: 1287.5856313856755
reward_std: 342.45652889383706
reward_max: 1938.4984755715384
reward_min: 424.0132015899198
total_envstep_count: 18911049
total_train_sample_count: 14199006
total_episode_count: 42523
total_duration: 3797.7745114553327
[2023-06-29 13:29:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3494
train_sample_count: 3494
avg_envstep_per_episode: 268.7692307692308
avg_sample_per_episode: 268.7692307692308
avg_envstep_per_sec: 2628.0772513578418
avg_train_sample_per_sec: 2628.0772513578418
avg_episode_per_sec: 9.778192406311375
collect_time: 1.329489077307284
reward_mean: 1367.330729695998
reward_std: 333.8000451130003
reward_max: 2136.2109272409893
reward_min: 1031.1313163627542
total_envstep_count: 18915377
total_train_sample_count: 14202500
total_episode_count: 42536
total_duration: 3799.10400053264
[2023-06-29 13:29:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2891
train_sample_count: 2891
avg_envstep_per_episode: 289.1
avg_sample_per_episode: 289.1
avg_envstep_per_sec: 2630.655906674921
avg_train_sample_per_sec: 2630.655906674921
avg_episode_per_sec: 9.09946698953622
collect_time: 1.0989654681421817
reward_mean: 1401.6900194366785
reward_std: 402.88391717780456
reward_max: 2334.7253833991995
reward_min: 1038.5682215241459
total_envstep_count: 18920201
total_train_sample_count: 14205791
total_episode_count: 42546
total_duration: 3800.202966000782
[2023-06-29 13:29:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2329
train_sample_count: 2329
avg_envstep_per_episode: 291.125
avg_sample_per_episode: 291.125
avg_envstep_per_sec: 2813.872781903733
avg_train_sample_per_sec: 2813.872781903733
avg_episode_per_sec: 9.665514064074653
collect_time: 0.8276848956989125
reward_mean: 1978.052967454999
reward_std: 658.1692686088508
reward_max: 3525.7516097648418
reward_min: 1215.6030043080227
total_envstep_count: 18925129
total_train_sample_count: 14209320
total_episode_count: 42554
total_duration: 3801.030650896481
[2023-06-29 13:29:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1900
train_sample_count: 1900
avg_envstep_per_episode: 237.5
avg_sample_per_episode: 237.5
avg_envstep_per_sec: 2736.8483966996696
avg_train_sample_per_sec: 2736.8483966996696
avg_episode_per_sec: 11.523572196630187
collect_time: 0.6942291733408346
reward_mean: 1971.8269651776704
reward_std: 729.0087788897854
reward_max: 3513.565030905685
reward_min: 1227.6828344097746
total_envstep_count: 18929417
total_train_sample_count: 14212820
total_episode_count: 42562
total_duration: 3801.7248800698217
[2023-06-29 13:29:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1840
train_sample_count: 1840
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 2705.8289602533728
avg_train_sample_per_sec: 2705.8289602533728
avg_episode_per_sec: 11.764473740232056
collect_time: 0.6800134180793538
reward_mean: 2019.6293548225403
reward_std: 831.3541054574649
reward_max: 3598.881017411576
reward_min: 1047.103711824605
total_envstep_count: 18933545
total_train_sample_count: 14216260
total_episode_count: 42570
total_duration: 3802.404893487901
[2023-06-29 13:30:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1307
train_sample_count: 1307
avg_envstep_per_episode: 261.4
avg_sample_per_episode: 261.4
avg_envstep_per_sec: 2521.617798613616
avg_train_sample_per_sec: 2521.617798613616
avg_episode_per_sec: 9.646586834788124
collect_time: 0.5183180419802668
reward_mean: 2244.273053134056
reward_std: 869.728103407198
reward_max: 3705.098444544834
reward_min: 1337.0699044676426
total_envstep_count: 18938161
total_train_sample_count: 14219567
total_episode_count: 42575
total_duration: 3802.9232115298814
[2023-06-29 13:30:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1728
train_sample_count: 1728
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2438.6965623832107
avg_train_sample_per_sec: 2438.6965623832107
avg_episode_per_sec: 11.290261862885234
collect_time: 0.708575239188969
reward_mean: 2610.7489311637787
reward_std: 973.8220749606746
reward_max: 3558.564306952082
reward_min: 1290.356731710275
total_envstep_count: 18942513
total_train_sample_count: 14222895
total_episode_count: 42583
total_duration: 3803.6317867690705
[2023-06-29 13:30:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 213.625
avg_sample_per_episode: 213.625
avg_envstep_per_sec: 2682.3073459270618
avg_train_sample_per_sec: 2682.3073459270618
avg_episode_per_sec: 12.556149073971032
collect_time: 0.6371380232004449
reward_mean: 1737.5313628421197
reward_std: 749.7886372047865
reward_max: 3529.2491086233003
reward_min: 997.4780989252002
total_envstep_count: 18946297
total_train_sample_count: 14226204
total_episode_count: 42591
total_duration: 3804.268924792271
[2023-06-29 13:30:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2032
train_sample_count: 2032
avg_envstep_per_episode: 338.6666666666667
avg_sample_per_episode: 338.6666666666667
avg_envstep_per_sec: 2784.109353761505
avg_train_sample_per_sec: 2784.109353761505
avg_episode_per_sec: 8.220795335909957
collect_time: 0.7298563891733065
reward_mean: 2586.3890650860367
reward_std: 729.2826471174935
reward_max: 3489.8377341710734
reward_min: 1379.132858109108
total_envstep_count: 18950945
total_train_sample_count: 14229436
total_episode_count: 42597
total_duration: 3804.998781181444
[2023-06-29 13:30:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1640
train_sample_count: 1640
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2747.708791386215
avg_train_sample_per_sec: 2747.708791386215
avg_episode_per_sec: 13.403457518957147
collect_time: 0.5968609210485593
reward_mean: 1925.1614237657166
reward_std: 953.9779395000784
reward_max: 3575.885923094975
reward_min: 1187.4351939396047
total_envstep_count: 18954529
total_train_sample_count: 14232676
total_episode_count: 42605
total_duration: 3805.5956421024925
[2023-06-29 13:30:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2433
train_sample_count: 2433
avg_envstep_per_episode: 304.125
avg_sample_per_episode: 304.125
avg_envstep_per_sec: 2536.806839307564
avg_train_sample_per_sec: 2536.806839307564
avg_episode_per_sec: 8.341329516835394
collect_time: 0.9590797227052972
reward_mean: 2180.8029046831903
reward_std: 788.5769656079149
reward_max: 3502.5065531967807
reward_min: 1274.7055952562919
total_envstep_count: 18959625
total_train_sample_count: 14235909
total_episode_count: 42613
total_duration: 3806.5547218251977
[2023-06-29 13:30:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 194.2
avg_sample_per_episode: 194.2
avg_envstep_per_sec: 2808.2547517971675
avg_train_sample_per_sec: 2808.2547517971675
avg_episode_per_sec: 14.460632089583767
collect_time: 0.34576635163836184
reward_mean: 2053.0258576110014
reward_std: 883.0493917658199
reward_max: 3505.156923975692
reward_min: 977.8663471484529
total_envstep_count: 18964417
total_train_sample_count: 14239280
total_episode_count: 42618
total_duration: 3806.900488176836
[2023-06-29 13:30:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1263
train_sample_count: 1263
avg_envstep_per_episode: 210.5
avg_sample_per_episode: 210.5
avg_envstep_per_sec: 2824.860354410441
avg_train_sample_per_sec: 2824.860354410441
avg_episode_per_sec: 13.419764153968838
collect_time: 0.4471017471812666
reward_mean: 2883.971274126446
reward_std: 936.1804179230635
reward_max: 3623.362851139092
reward_min: 1275.9199106012663
total_envstep_count: 18968985
total_train_sample_count: 14242543
total_episode_count: 42624
total_duration: 3807.3475899240175
[2023-06-29 13:30:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 684
train_sample_count: 684
avg_envstep_per_episode: 171.0
avg_sample_per_episode: 171.0
avg_envstep_per_sec: 2710.065734150514
avg_train_sample_per_sec: 2710.065734150514
avg_episode_per_sec: 15.848337626611194
collect_time: 0.2523924019187689
reward_mean: 3462.3430302263396
reward_std: 23.60543726931342
reward_max: 3502.254072959861
reward_min: 3444.031508063784
total_envstep_count: 18973361
total_train_sample_count: 14246027
total_episode_count: 42628
total_duration: 3807.5999823259363
[2023-06-29 13:30:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1655
train_sample_count: 1655
avg_envstep_per_episode: 275.8333333333333
avg_sample_per_episode: 275.8333333333333
avg_envstep_per_sec: 2440.7407992175135
avg_train_sample_per_sec: 2440.7407992175135
avg_episode_per_sec: 8.848607127072556
collect_time: 0.6780728213870899
reward_mean: 3424.9504748835902
reward_std: 15.82795510417001
reward_max: 3456.0504617946867
reward_min: 3405.205527593815
total_envstep_count: 18977217
total_train_sample_count: 14249282
total_episode_count: 42634
total_duration: 3808.2780551473234
[2023-06-29 13:30:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1775
train_sample_count: 1775
avg_envstep_per_episode: 355.0
avg_sample_per_episode: 355.0
avg_envstep_per_sec: 2808.390194284426
avg_train_sample_per_sec: 2808.390194284426
avg_episode_per_sec: 7.910958293758946
collect_time: 0.6320346807977186
reward_mean: 2830.602181329
reward_std: 804.7720498256351
reward_max: 3527.9746351111257
reward_min: 1489.5979633008487
total_envstep_count: 18981857
total_train_sample_count: 14252657
total_episode_count: 42639
total_duration: 3808.9100898281213
[2023-06-29 13:30:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 381.875
avg_sample_per_episode: 381.875
avg_envstep_per_sec: 2616.1248001652257
avg_train_sample_per_sec: 2616.1248001652257
avg_episode_per_sec: 6.85073597424609
collect_time: 1.1677577460398894
reward_mean: 2730.5120757907616
reward_std: 949.651620825487
reward_max: 3527.722196953211
reward_min: 1324.2825202806566
total_envstep_count: 18986409
total_train_sample_count: 14256112
total_episode_count: 42647
total_duration: 3810.0778475741613
[2023-06-29 13:30:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 850
train_sample_count: 850
avg_envstep_per_episode: 283.3333333333333
avg_sample_per_episode: 283.3333333333333
avg_envstep_per_sec: 2740.075837704285
avg_train_sample_per_sec: 2740.075837704285
avg_episode_per_sec: 9.670855897779829
collect_time: 0.3102103921007364
reward_mean: 2282.772135584364
reward_std: 928.6527459224412
reward_max: 3475.1630842329864
reward_min: 1209.8726095156148
total_envstep_count: 18991097
total_train_sample_count: 14259362
total_episode_count: 42650
total_duration: 3810.388057966262
[2023-06-29 13:30:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2732
train_sample_count: 2732
avg_envstep_per_episode: 273.2
avg_sample_per_episode: 273.2
avg_envstep_per_sec: 2597.3996339302034
avg_train_sample_per_sec: 2597.3996339302034
avg_episode_per_sec: 9.507319304283321
collect_time: 1.0518212000615896
reward_mean: 2625.186210281298
reward_std: 975.8414295752867
reward_max: 3633.530882974295
reward_min: 1279.664610491362
total_envstep_count: 18995537
total_train_sample_count: 14262894
total_episode_count: 42660
total_duration: 3811.4398791663234
[2023-06-29 13:30:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1160
train_sample_count: 1160
avg_envstep_per_episode: 193.33333333333334
avg_sample_per_episode: 193.33333333333334
avg_envstep_per_sec: 2728.4812726570512
avg_train_sample_per_sec: 2728.4812726570512
avg_episode_per_sec: 14.112834168915782
collect_time: 0.42514493745099746
reward_mean: 1601.124978894738
reward_std: 543.0694681605497
reward_max: 2446.5727997587533
reward_min: 722.2029759468479
total_envstep_count: 18999809
total_train_sample_count: 14266454
total_episode_count: 42666
total_duration: 3811.8650241037744
[2023-06-29 13:30:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3121
train_sample_count: 3121
avg_envstep_per_episode: 312.1
avg_sample_per_episode: 312.1
avg_envstep_per_sec: 2643.5386614982826
avg_train_sample_per_sec: 2643.5386614982826
avg_episode_per_sec: 8.470165528671204
collect_time: 1.180614471600391
reward_mean: 2360.1263993663006
reward_std: 755.258966661981
reward_max: 3521.1029624632697
reward_min: 1404.0116639227458
total_envstep_count: 19004337
total_train_sample_count: 14269975
total_episode_count: 42676
total_duration: 3813.0456385753746
[2023-06-29 13:30:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1662
train_sample_count: 1662
avg_envstep_per_episode: 277.0
avg_sample_per_episode: 277.0
avg_envstep_per_sec: 2815.1453852486925
avg_train_sample_per_sec: 2815.1453852486925
avg_episode_per_sec: 10.162979730139684
collect_time: 0.5903780347220602
reward_mean: 1791.896108089971
reward_std: 586.7993122315544
reward_max: 2906.3954434700945
reward_min: 1205.811967122662
total_envstep_count: 19009305
total_train_sample_count: 14273237
total_episode_count: 42682
total_duration: 3813.6360166100967
[2023-06-29 13:30:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1404
train_sample_count: 1404
avg_envstep_per_episode: 200.57142857142858
avg_sample_per_episode: 200.57142857142858
avg_envstep_per_sec: 2549.8905727918554
avg_train_sample_per_sec: 2549.8905727918554
avg_episode_per_sec: 12.713129636426629
collect_time: 0.5506118634976447
reward_mean: 2375.6234924396854
reward_std: 709.2451743740737
reward_max: 3489.223341320644
reward_min: 1566.7626071088766
total_envstep_count: 19013793
total_train_sample_count: 14276641
total_episode_count: 42689
total_duration: 3814.1866284735943
[2023-06-29 13:30:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 857
train_sample_count: 857
avg_envstep_per_episode: 214.25
avg_sample_per_episode: 214.25
avg_envstep_per_sec: 2688.6472065845846
avg_train_sample_per_sec: 2688.6472065845846
avg_episode_per_sec: 12.549111816030733
collect_time: 0.3187476578932257
reward_mean: 2988.4303462520916
reward_std: 713.9357220896999
reward_max: 3540.7506694221975
reward_min: 1768.321212757193
total_envstep_count: 19017601
total_train_sample_count: 14279898
total_episode_count: 42693
total_duration: 3814.5053761314875
[2023-06-29 13:31:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2436
train_sample_count: 2436
avg_envstep_per_episode: 270.6666666666667
avg_sample_per_episode: 270.6666666666667
avg_envstep_per_sec: 2569.7982926674845
avg_train_sample_per_sec: 2569.7982926674845
avg_episode_per_sec: 9.494328667490706
collect_time: 0.9479343211296946
reward_mean: 2588.3603116763047
reward_std: 998.7715665659514
reward_max: 3640.29315418975
reward_min: 952.8706468730878
total_envstep_count: 19021529
total_train_sample_count: 14283134
total_episode_count: 42702
total_duration: 3815.453310452617
[2023-06-29 13:31:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2098
train_sample_count: 2098
avg_envstep_per_episode: 419.6
avg_sample_per_episode: 419.6
avg_envstep_per_sec: 2769.3198520687706
avg_train_sample_per_sec: 2769.3198520687706
avg_episode_per_sec: 6.599904318562371
collect_time: 0.7575867404527963
reward_mean: 2382.189152754423
reward_std: 813.4623212944268
reward_max: 3510.7833174503744
reward_min: 1349.680816795603
total_envstep_count: 19026329
total_train_sample_count: 14286432
total_episode_count: 42707
total_duration: 3816.21089719307
[2023-06-29 13:31:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1467
train_sample_count: 1467
avg_envstep_per_episode: 293.4
avg_sample_per_episode: 293.4
avg_envstep_per_sec: 2795.351167557673
avg_train_sample_per_sec: 2795.351167557673
avg_episode_per_sec: 9.52744092555444
collect_time: 0.5247998952781783
reward_mean: 2964.1108769187003
reward_std: 893.858845333653
reward_max: 3598.069960772047
reward_min: 1268.4686474640112
total_envstep_count: 19031537
total_train_sample_count: 14289899
total_episode_count: 42712
total_duration: 3816.7356970883484
[2023-06-29 13:31:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2157
train_sample_count: 2157
avg_envstep_per_episode: 308.14285714285717
avg_sample_per_episode: 308.14285714285717
avg_envstep_per_sec: 2643.7124278995343
avg_train_sample_per_sec: 2643.7124278995343
avg_episode_per_sec: 8.579502547657274
collect_time: 0.8158981200968843
reward_mean: 3136.71891573554
reward_std: 741.9020345914065
reward_max: 3707.3160438150003
reward_min: 1624.1601332223947
total_envstep_count: 19036337
total_train_sample_count: 14293256
total_episode_count: 42719
total_duration: 3817.551595208445
[2023-06-29 13:31:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1112
train_sample_count: 1112
avg_envstep_per_episode: 222.4
avg_sample_per_episode: 222.4
avg_envstep_per_sec: 2770.1867195080945
avg_train_sample_per_sec: 2770.1867195080945
avg_episode_per_sec: 12.45587553735654
collect_time: 0.40141698469966647
reward_mean: 2363.1955819160075
reward_std: 821.994574511006
reward_max: 3493.7917722726606
reward_min: 1195.773102358542
total_envstep_count: 19040673
total_train_sample_count: 14296768
total_episode_count: 42724
total_duration: 3817.953012193145
[2023-06-29 13:31:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 202.66666666666666
avg_sample_per_episode: 202.66666666666666
avg_envstep_per_sec: 2748.8646617301833
avg_train_sample_per_sec: 2748.8646617301833
avg_episode_per_sec: 13.563476949326562
collect_time: 0.44236444846820083
reward_mean: 3009.432633067481
reward_std: 660.2716191617882
reward_max: 3501.8596982032545
reward_min: 1910.6323173036258
total_envstep_count: 19044953
total_train_sample_count: 14299984
total_episode_count: 42730
total_duration: 3818.395376641613
[2023-06-29 13:31:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1837
train_sample_count: 1837
avg_envstep_per_episode: 262.42857142857144
avg_sample_per_episode: 262.42857142857144
avg_envstep_per_sec: 2763.6983274347854
avg_train_sample_per_sec: 2763.6983274347854
avg_episode_per_sec: 10.531240224302394
collect_time: 0.6646890443013982
reward_mean: 2443.3990796571193
reward_std: 747.102010649579
reward_max: 3498.2928698631163
reward_min: 1387.1097112478988
total_envstep_count: 19050369
total_train_sample_count: 14303421
total_episode_count: 42737
total_duration: 3819.060065685914
[2023-06-29 13:31:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2107
train_sample_count: 2107
avg_envstep_per_episode: 191.54545454545453
avg_sample_per_episode: 191.54545454545453
avg_envstep_per_sec: 2607.3345169582394
avg_train_sample_per_sec: 2607.3345169582394
avg_episode_per_sec: 13.61209287448535
collect_time: 0.8081049770545216
reward_mean: 1999.5076190157183
reward_std: 951.1671287473852
reward_max: 3501.230524018467
reward_min: 425.0203266124724
total_envstep_count: 19054137
total_train_sample_count: 14306728
total_episode_count: 42748
total_duration: 3819.8681706629686
[2023-06-29 13:31:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2925
train_sample_count: 2925
avg_envstep_per_episode: 292.5
avg_sample_per_episode: 292.5
avg_envstep_per_sec: 2806.209594367707
avg_train_sample_per_sec: 2806.209594367707
avg_episode_per_sec: 9.593878955103271
collect_time: 1.0423312662998214
reward_mean: 1692.4252862454953
reward_std: 531.7928762559891
reward_max: 2874.7444179849535
reward_min: 1114.995119362276
total_envstep_count: 19059097
total_train_sample_count: 14310053
total_episode_count: 42758
total_duration: 3820.9105019292683
[2023-06-29 13:31:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1651
train_sample_count: 1651
avg_envstep_per_episode: 330.2
avg_sample_per_episode: 330.2
avg_envstep_per_sec: 2804.819371030591
avg_train_sample_per_sec: 2804.819371030591
avg_episode_per_sec: 8.494304576107181
collect_time: 0.5886297053750608
reward_mean: 2340.2950798779398
reward_std: 793.4077449556837
reward_max: 3573.310991221052
reward_min: 1511.6441925046195
total_envstep_count: 19063713
total_train_sample_count: 14313304
total_episode_count: 42763
total_duration: 3821.499131634643
[2023-06-29 13:31:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1466
train_sample_count: 1466
avg_envstep_per_episode: 209.42857142857142
avg_sample_per_episode: 209.42857142857142
avg_envstep_per_sec: 2820.5823264397013
avg_train_sample_per_sec: 2820.5823264397013
avg_episode_per_sec: 13.467992008920811
collect_time: 0.5197508281385526
reward_mean: 2374.2997507514133
reward_std: 992.548429753266
reward_max: 3497.860171210014
reward_min: 994.8631020325892
total_envstep_count: 19068361
total_train_sample_count: 14316770
total_episode_count: 42770
total_duration: 3822.0188824627817
[2023-06-29 13:31:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 244.0
avg_sample_per_episode: 244.0
avg_envstep_per_sec: 2692.512426821765
avg_train_sample_per_sec: 2692.512426821765
avg_episode_per_sec: 11.034886995171169
collect_time: 0.4531084008552135
reward_mean: 3022.499400065294
reward_std: 537.2734295822404
reward_max: 3531.309245985257
reward_min: 2245.2726359135972
total_envstep_count: 19072985
total_train_sample_count: 14319990
total_episode_count: 42775
total_duration: 3822.471990863637
[2023-06-29 13:31:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1757
train_sample_count: 1757
avg_envstep_per_episode: 195.22222222222223
avg_sample_per_episode: 195.22222222222223
avg_envstep_per_sec: 2785.8311024484237
avg_train_sample_per_sec: 2785.8311024484237
avg_episode_per_sec: 14.270051179303252
collect_time: 0.6306915011666716
reward_mean: 2245.258425183674
reward_std: 935.9829449072173
reward_max: 3508.615738779895
reward_min: 1275.2635374870194
total_envstep_count: 19077201
total_train_sample_count: 14323347
total_episode_count: 42784
total_duration: 3823.102682364804
[2023-06-29 13:31:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1769
train_sample_count: 1769
avg_envstep_per_episode: 353.8
avg_sample_per_episode: 353.8
avg_envstep_per_sec: 2706.7054807735417
avg_train_sample_per_sec: 2706.7054807735417
avg_episode_per_sec: 7.650382930394409
collect_time: 0.6535620563691482
reward_mean: 2752.571248583222
reward_std: 1019.0522213022264
reward_max: 3566.301622658027
reward_min: 907.4541634708742
total_envstep_count: 19082241
total_train_sample_count: 14326716
total_episode_count: 42789
total_duration: 3823.756244421173
[2023-06-29 13:31:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3029
train_sample_count: 3029
avg_envstep_per_episode: 252.41666666666666
avg_sample_per_episode: 252.41666666666666
avg_envstep_per_sec: 2731.787810806951
avg_train_sample_per_sec: 2731.787810806951
avg_episode_per_sec: 10.822533420166197
collect_time: 1.1087976848045364
reward_mean: 2055.137171479256
reward_std: 849.9249279745634
reward_max: 3513.4240018917844
reward_min: 1104.0823792624528
total_envstep_count: 19086689
total_train_sample_count: 14330145
total_episode_count: 42801
total_duration: 3824.8650421059774
[2023-06-29 13:31:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 241.25
avg_sample_per_episode: 241.25
avg_envstep_per_sec: 2631.2129337379206
avg_train_sample_per_sec: 2631.2129337379206
avg_episode_per_sec: 10.90658210875822
collect_time: 1.1002530288901178
reward_mean: 1333.1154448036452
reward_std: 240.41053688395053
reward_max: 1919.7991112180562
reward_min: 1030.7218624095733
total_envstep_count: 19091353
total_train_sample_count: 14333440
total_episode_count: 42813
total_duration: 3825.9652951348676
[2023-06-29 13:31:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2055
train_sample_count: 2055
avg_envstep_per_episode: 228.33333333333334
avg_sample_per_episode: 228.33333333333334
avg_envstep_per_sec: 2685.5247335946333
avg_train_sample_per_sec: 2685.5247335946333
avg_episode_per_sec: 11.761422190925401
collect_time: 0.7652135816486553
reward_mean: 1491.0125575162185
reward_std: 688.531620501617
reward_max: 3362.1848555921674
reward_min: 1045.9863345413617
total_envstep_count: 19096417
total_train_sample_count: 14336695
total_episode_count: 42822
total_duration: 3826.7305087165164
[2023-06-29 13:31:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1047
train_sample_count: 1047
avg_envstep_per_episode: 130.875
avg_sample_per_episode: 130.875
avg_envstep_per_sec: 2737.5282786607327
avg_train_sample_per_sec: 2737.5282786607327
avg_episode_per_sec: 20.91712151794256
collect_time: 0.38246180255431683
reward_mean: 1784.0952714850466
reward_std: 710.4735467247175
reward_max: 3535.1685430119587
reward_min: 1127.5308388543822
total_envstep_count: 19100513
total_train_sample_count: 14340142
total_episode_count: 42830
total_duration: 3827.1129705190706
[2023-06-29 13:31:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 806
train_sample_count: 806
avg_envstep_per_episode: 268.6666666666667
avg_sample_per_episode: 268.6666666666667
avg_envstep_per_sec: 2753.768746903183
avg_train_sample_per_sec: 2753.768746903183
avg_episode_per_sec: 10.249759603858001
collect_time: 0.29268979136552653
reward_mean: 3092.5261019813156
reward_std: 269.4788652491498
reward_max: 3470.2715080783814
reward_min: 2859.9544933014467
total_envstep_count: 19104313
total_train_sample_count: 14343348
total_episode_count: 42833
total_duration: 3827.405660310436
[2023-06-29 13:31:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 160.75
avg_sample_per_episode: 160.75
avg_envstep_per_sec: 2421.578593569133
avg_train_sample_per_sec: 2421.578593569133
avg_episode_per_sec: 15.064252526091028
collect_time: 0.5310585431400686
reward_mean: 2426.495646046753
reward_std: 1071.3119875684315
reward_max: 3551.080133773685
reward_min: 1008.2676656024596
total_envstep_count: 19108881
total_train_sample_count: 14346634
total_episode_count: 42841
total_duration: 3827.936718853576
[2023-06-29 13:32:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2049
train_sample_count: 2049
avg_envstep_per_episode: 292.7142857142857
avg_sample_per_episode: 292.7142857142857
avg_envstep_per_sec: 2793.120883181863
avg_train_sample_per_sec: 2793.120883181863
avg_episode_per_sec: 9.542140645326032
collect_time: 0.7335880134431645
reward_mean: 2425.6100474786945
reward_std: 979.0831702906638
reward_max: 3483.8682558511473
reward_min: 1081.7117804045615
total_envstep_count: 19112753
total_train_sample_count: 14349883
total_episode_count: 42848
total_duration: 3828.6703068670195
[2023-06-29 13:32:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 206.85714285714286
avg_sample_per_episode: 206.85714285714286
avg_envstep_per_sec: 2814.463655324935
avg_train_sample_per_sec: 2814.463655324935
avg_episode_per_sec: 13.605832587896785
collect_time: 0.514485236737877
reward_mean: 2172.1625044578823
reward_std: 1077.4873634500648
reward_max: 3449.173181070226
reward_min: 1023.9795266686889
total_envstep_count: 19117449
total_train_sample_count: 14353331
total_episode_count: 42855
total_duration: 3829.1847921037574
[2023-06-29 13:32:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 932
train_sample_count: 932
avg_envstep_per_episode: 310.6666666666667
avg_sample_per_episode: 310.6666666666667
avg_envstep_per_sec: 2762.9361638475257
avg_train_sample_per_sec: 2762.9361638475257
avg_episode_per_sec: 8.893571342856843
collect_time: 0.337322306680493
reward_mean: 2882.21861307288
reward_std: 673.747188485495
reward_max: 3395.3584320132577
reward_min: 1930.3656276893328
total_envstep_count: 19121409
total_train_sample_count: 14356663
total_episode_count: 42858
total_duration: 3829.522114410438
[2023-06-29 13:32:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 202.66666666666666
avg_sample_per_episode: 202.66666666666666
avg_envstep_per_sec: 2394.4955815261274
avg_train_sample_per_sec: 2394.4955815261274
avg_episode_per_sec: 11.814945303582867
collect_time: 0.5078313818499446
reward_mean: 3080.691409231719
reward_std: 637.7801491312848
reward_max: 3399.370780537074
reward_min: 1655.1981771038447
total_envstep_count: 19126057
total_train_sample_count: 14359879
total_episode_count: 42864
total_duration: 3830.029945792288
[2023-06-29 13:32:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 820
train_sample_count: 820
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2667.2736874660022
avg_train_sample_per_sec: 2667.2736874660022
avg_episode_per_sec: 9.758318368778058
collect_time: 0.30743001884408305
reward_mean: 3367.9896099658604
reward_std: 26.857937522161055
reward_max: 3399.577339480193
reward_min: 3333.928706039374
total_envstep_count: 19129681
total_train_sample_count: 14363099
total_episode_count: 42867
total_duration: 3830.337375811132
[2023-06-29 13:32:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2232
train_sample_count: 2232
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2736.596417116105
avg_train_sample_per_sec: 2736.596417116105
avg_episode_per_sec: 9.808589308659876
collect_time: 0.8156116795446726
reward_mean: 2870.1887786475168
reward_std: 846.6842122445355
reward_max: 3387.64079888802
reward_min: 1374.5274641475578
total_envstep_count: 19134673
total_train_sample_count: 14366531
total_episode_count: 42875
total_duration: 3831.152987490677
[2023-06-29 13:32:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2091
train_sample_count: 2091
avg_envstep_per_episode: 348.5
avg_sample_per_episode: 348.5
avg_envstep_per_sec: 2844.0227139901017
avg_train_sample_per_sec: 2844.0227139901017
avg_episode_per_sec: 8.160753842152372
collect_time: 0.7352261955272406
reward_mean: 2344.4821456374657
reward_std: 970.8572856989838
reward_max: 3340.691569840899
reward_min: 1330.3368799737625
total_envstep_count: 19139473
total_train_sample_count: 14369822
total_episode_count: 42881
total_duration: 3831.888213686204
[2023-06-29 13:32:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1123
train_sample_count: 1123
avg_envstep_per_episode: 224.6
avg_sample_per_episode: 224.6
avg_envstep_per_sec: 2620.9600372914583
avg_train_sample_per_sec: 2620.9600372914583
avg_episode_per_sec: 11.669456978145407
collect_time: 0.42846895184274764
reward_mean: 2540.512012419002
reward_std: 942.9937511420881
reward_max: 3318.6445395473042
reward_min: 1384.5055080152713
total_envstep_count: 19144609
total_train_sample_count: 14373345
total_episode_count: 42886
total_duration: 3832.3166826380466
[2023-06-29 13:32:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 239.5
avg_sample_per_episode: 239.5
avg_envstep_per_sec: 2786.7590158558573
avg_train_sample_per_sec: 2786.7590158558573
avg_episode_per_sec: 11.635737018187296
collect_time: 0.5156527679013088
reward_mean: 2994.11734917568
reward_std: 720.7737644959761
reward_max: 3388.764445806333
reward_min: 1404.987229872618
total_envstep_count: 19149009
total_train_sample_count: 14376782
total_episode_count: 42892
total_duration: 3832.832335405948
[2023-06-29 13:32:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 957
train_sample_count: 957
avg_envstep_per_episode: 191.4
avg_sample_per_episode: 191.4
avg_envstep_per_sec: 2658.9953494541082
avg_train_sample_per_sec: 2658.9953494541082
avg_episode_per_sec: 13.892347698297327
collect_time: 0.3599103699810803
reward_mean: 2583.356141150488
reward_std: 942.6984857339472
reward_max: 3378.115896142776
reward_min: 1175.8432484360071
total_envstep_count: 19153657
total_train_sample_count: 14380139
total_episode_count: 42897
total_duration: 3833.192245775929
[2023-06-29 13:32:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1505
train_sample_count: 1505
avg_envstep_per_episode: 250.83333333333334
avg_sample_per_episode: 250.83333333333334
avg_envstep_per_sec: 2763.3366427449882
avg_train_sample_per_sec: 2763.3366427449882
avg_episode_per_sec: 11.016624489348791
collect_time: 0.5446314345924184
reward_mean: 2996.129657869071
reward_std: 716.885063766639
reward_max: 3353.6924211605447
reward_min: 1395.0064772116543
total_envstep_count: 19157769
total_train_sample_count: 14383644
total_episode_count: 42903
total_duration: 3833.7368772105215
[2023-06-29 13:32:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 295.0
avg_sample_per_episode: 295.0
avg_envstep_per_sec: 2548.3829248667334
avg_train_sample_per_sec: 2548.3829248667334
avg_episode_per_sec: 8.638586185988926
collect_time: 0.8103177822493016
reward_mean: 2726.068783128588
reward_std: 1032.938487207312
reward_max: 3413.0829488188087
reward_min: 1057.048811487163
total_envstep_count: 19162025
total_train_sample_count: 14386909
total_episode_count: 42910
total_duration: 3834.547194992771
[2023-06-29 13:32:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 316.55555555555554
avg_sample_per_episode: 316.55555555555554
avg_envstep_per_sec: 2602.8285696427965
avg_train_sample_per_sec: 2602.8285696427965
avg_episode_per_sec: 8.222343673845268
collect_time: 1.0945784264197573
reward_mean: 1984.0757403993016
reward_std: 1050.430367018288
reward_max: 3460.828282103446
reward_min: 282.5224028109411
total_envstep_count: 19166313
total_train_sample_count: 14390158
total_episode_count: 42919
total_duration: 3835.641773419191
[2023-06-29 13:32:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 306.75
avg_sample_per_episode: 306.75
avg_envstep_per_sec: 2753.0034052921164
avg_train_sample_per_sec: 2753.0034052921164
avg_episode_per_sec: 8.974746227521162
collect_time: 0.44569505349732946
reward_mean: 1642.220106931711
reward_std: 192.53730470762227
reward_max: 1858.781793769472
reward_min: 1336.5514560949355
total_envstep_count: 19170401
total_train_sample_count: 14393385
total_episode_count: 42923
total_duration: 3836.087468472688
[2023-06-29 13:32:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2186
train_sample_count: 2186
avg_envstep_per_episode: 273.25
avg_sample_per_episode: 273.25
avg_envstep_per_sec: 2831.654617418286
avg_train_sample_per_sec: 2831.654617418286
avg_episode_per_sec: 10.362871426965365
collect_time: 0.7719868046594783
reward_mean: 2457.0384102280395
reward_std: 1066.4656772665246
reward_max: 3365.4272291855746
reward_min: 1016.8340180420727
total_envstep_count: 19175465
total_train_sample_count: 14396771
total_episode_count: 42931
total_duration: 3836.8594552773475
[2023-06-29 13:32:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1695
train_sample_count: 1695
avg_envstep_per_episode: 339.0
avg_sample_per_episode: 339.0
avg_envstep_per_sec: 2779.948357387996
avg_train_sample_per_sec: 2779.948357387996
avg_episode_per_sec: 8.200437632412967
collect_time: 0.609723556732759
reward_mean: 2454.9734528486542
reward_std: 1001.9365404322104
reward_max: 3408.2195526049545
reward_min: 718.6869729530096
total_envstep_count: 19180265
total_train_sample_count: 14400066
total_episode_count: 42936
total_duration: 3837.46917883408
[2023-06-29 13:32:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 409
train_sample_count: 409
avg_envstep_per_episode: 102.25
avg_sample_per_episode: 102.25
avg_envstep_per_sec: 2747.6669198799873
avg_train_sample_per_sec: 2747.6669198799873
avg_episode_per_sec: 26.87204811618569
collect_time: 0.14885355901066216
reward_mean: 3387.6416453392526
reward_std: 14.374772133167959
reward_max: 3411.1255704610776
reward_min: 3372.0327764171384
total_envstep_count: 19184177
total_train_sample_count: 14403275
total_episode_count: 42940
total_duration: 3837.6180323930907
[2023-06-29 13:32:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 344.3333333333333
avg_sample_per_episode: 344.3333333333333
avg_envstep_per_sec: 2490.0319840015936
avg_train_sample_per_sec: 2490.0319840015936
avg_episode_per_sec: 7.231457843179846
collect_time: 0.8297082179160787
reward_mean: 2965.753885726322
reward_std: 736.0752879622431
reward_max: 3401.6767928513113
reward_min: 1333.8328612480661
total_envstep_count: 19188625
total_train_sample_count: 14406541
total_episode_count: 42946
total_duration: 3838.447740611007
[2023-06-29 13:32:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 956
train_sample_count: 956
avg_envstep_per_episode: 191.2
avg_sample_per_episode: 191.2
avg_envstep_per_sec: 2774.190181197694
avg_train_sample_per_sec: 2774.190181197694
avg_episode_per_sec: 14.509362872372877
collect_time: 0.34460506942868224
reward_mean: 2622.8391659079844
reward_std: 965.6912220328599
reward_max: 3418.7481726289075
reward_min: 1253.7796124540769
total_envstep_count: 19192969
total_train_sample_count: 14409897
total_episode_count: 42951
total_duration: 3838.7923456804356
[2023-06-29 13:33:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 185.4
avg_sample_per_episode: 185.4
avg_envstep_per_sec: 2797.817142424029
avg_train_sample_per_sec: 2797.817142424029
avg_episode_per_sec: 15.09070734856542
collect_time: 0.3313297305759043
reward_mean: 2848.007725759193
reward_std: 690.4830708790992
reward_max: 3433.203509367327
reward_min: 1875.438689679849
total_envstep_count: 19197145
total_train_sample_count: 14413224
total_episode_count: 42956
total_duration: 3839.1236754110114
[2023-06-29 13:33:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1716
train_sample_count: 1716
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2489.4438627261075
avg_train_sample_per_sec: 2489.4438627261075
avg_episode_per_sec: 8.704349170371005
collect_time: 0.6893105828547847
reward_mean: 3032.7730555580274
reward_std: 759.583482283596
reward_max: 3423.377446855481
reward_min: 1335.5572387263571
total_envstep_count: 19201465
total_train_sample_count: 14416540
total_episode_count: 42962
total_duration: 3839.8129859938663
[2023-06-29 13:33:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1686
train_sample_count: 1686
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2448.214896905615
avg_train_sample_per_sec: 2448.214896905615
avg_episode_per_sec: 8.71250852991322
collect_time: 0.6886650359537452
reward_mean: 2376.729838450877
reward_std: 961.5679415095076
reward_max: 3405.2730635221155
reward_min: 703.4057851460774
total_envstep_count: 19205769
total_train_sample_count: 14419826
total_episode_count: 42968
total_duration: 3840.50165102982
[2023-06-29 13:33:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 897
train_sample_count: 897
avg_envstep_per_episode: 224.25
avg_sample_per_episode: 224.25
avg_envstep_per_sec: 2783.603259689187
avg_train_sample_per_sec: 2783.603259689187
avg_episode_per_sec: 12.41294653150139
collect_time: 0.32224419801123444
reward_mean: 2351.129233499435
reward_std: 1114.8063449535227
reward_max: 3405.5313028083774
reward_min: 706.1891033669197
total_envstep_count: 19210537
total_train_sample_count: 14423123
total_episode_count: 42972
total_duration: 3840.823895227831
[2023-06-29 13:33:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1416
train_sample_count: 1416
avg_envstep_per_episode: 236.0
avg_sample_per_episode: 236.0
avg_envstep_per_sec: 2700.9263372694454
avg_train_sample_per_sec: 2700.9263372694454
avg_episode_per_sec: 11.444603124023073
collect_time: 0.5242645756239073
reward_mean: 3015.5430291812463
reward_std: 809.543124795725
reward_max: 3443.992309259701
reward_min: 1207.8920816887698
total_envstep_count: 19215065
total_train_sample_count: 14426539
total_episode_count: 42978
total_duration: 3841.348159803455
[2023-06-29 13:33:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1236
train_sample_count: 1236
avg_envstep_per_episode: 176.57142857142858
avg_sample_per_episode: 176.57142857142858
avg_envstep_per_sec: 2377.8100069241136
avg_train_sample_per_sec: 2377.8100069241136
avg_episode_per_sec: 13.466561527887373
collect_time: 0.5198060384979473
reward_mean: 2275.148495843688
reward_std: 1274.5921727178766
reward_max: 3452.164841326216
reward_min: 416.2650771529289
total_envstep_count: 19218881
total_train_sample_count: 14429775
total_episode_count: 42985
total_duration: 3841.867965841953
[2023-06-29 13:33:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 484
train_sample_count: 484
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 2812.3971822337876
avg_train_sample_per_sec: 2812.3971822337876
avg_episode_per_sec: 11.62147595964375
collect_time: 0.17209518024604759
reward_mean: 3389.350189089744
reward_std: 3.8726058876170555
reward_max: 3393.2227949773614
reward_min: 3385.4775832021273
total_envstep_count: 19223065
total_train_sample_count: 14433059
total_episode_count: 42987
total_duration: 3842.0400610221986
[2023-06-29 13:33:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2192
train_sample_count: 2192
avg_envstep_per_episode: 219.2
avg_sample_per_episode: 219.2
avg_envstep_per_sec: 2790.5007440399477
avg_train_sample_per_sec: 2790.5007440399477
avg_episode_per_sec: 12.730386606021659
collect_time: 0.7855220983838663
reward_mean: 2412.4421057329287
reward_std: 1221.6817658814634
reward_max: 3415.529151530149
reward_min: 177.34151616085475
total_envstep_count: 19227649
total_train_sample_count: 14436451
total_episode_count: 42997
total_duration: 3842.8255831205825
[2023-06-29 13:33:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 190.83333333333334
avg_sample_per_episode: 190.83333333333334
avg_envstep_per_sec: 2543.5319435881615
avg_train_sample_per_sec: 2543.5319435881615
avg_episode_per_sec: 13.328551669457616
collect_time: 0.45016143905185163
reward_mean: 1980.783483839883
reward_std: 702.6161573106942
reward_max: 3352.19290178596
reward_min: 1187.8688760395012
total_envstep_count: 19232849
total_train_sample_count: 14439996
total_episode_count: 43003
total_duration: 3843.2757445596344
[2023-06-29 13:33:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1429
train_sample_count: 1429
avg_envstep_per_episode: 238.16666666666666
avg_sample_per_episode: 238.16666666666666
avg_envstep_per_sec: 2606.2479931787225
avg_train_sample_per_sec: 2606.2479931787225
avg_episode_per_sec: 10.94295868374551
collect_time: 0.5482977843014523
reward_mean: 3003.356275405708
reward_std: 791.2766071376391
reward_max: 3388.0782940052964
reward_min: 1234.4948081022278
total_envstep_count: 19237185
total_train_sample_count: 14443425
total_episode_count: 43009
total_duration: 3843.824042343936
[2023-06-29 13:33:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 281.75
avg_sample_per_episode: 281.75
avg_envstep_per_sec: 2363.015863596292
avg_train_sample_per_sec: 2363.015863596292
avg_episode_per_sec: 8.386924094396779
collect_time: 0.47693289637286224
reward_mean: 3299.6157031751504
reward_std: 101.6737064284234
reward_max: 3378.4609387344476
reward_min: 3125.2595186802387
total_envstep_count: 19241681
total_train_sample_count: 14446952
total_episode_count: 43013
total_duration: 3844.300975240309
[2023-06-29 13:33:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2049
train_sample_count: 2049
avg_envstep_per_episode: 341.5
avg_sample_per_episode: 341.5
avg_envstep_per_sec: 2525.8855140906335
avg_train_sample_per_sec: 2525.8855140906335
avg_episode_per_sec: 7.396443672300538
collect_time: 0.8112006615381689
reward_mean: 3321.546558500458
reward_std: 33.66525947218618
reward_max: 3391.4716762300086
reward_min: 3282.8795410486405
total_envstep_count: 19246481
total_train_sample_count: 14450201
total_episode_count: 43019
total_duration: 3845.1121759018474
[2023-06-29 13:33:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2593
train_sample_count: 2593
avg_envstep_per_episode: 432.1666666666667
avg_sample_per_episode: 432.1666666666667
avg_envstep_per_sec: 2541.378332894038
avg_train_sample_per_sec: 2541.378332894038
avg_episode_per_sec: 5.880551483750184
collect_time: 1.0203124684104696
reward_mean: 2956.834935069206
reward_std: 865.6385589298035
reward_max: 3408.628419348848
reward_min: 1023.6857440937698
total_envstep_count: 19251697
total_train_sample_count: 14453594
total_episode_count: 43025
total_duration: 3846.1324883702578
[2023-06-29 13:33:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 343.0
avg_sample_per_episode: 343.0
avg_envstep_per_sec: 2756.965164924601
avg_train_sample_per_sec: 2756.965164924601
avg_episode_per_sec: 8.037799314648984
collect_time: 0.6220608159359542
reward_mean: 2886.142376190089
reward_std: 634.9198845135855
reward_max: 3368.592338624254
reward_min: 1699.2081207519018
total_envstep_count: 19256585
total_train_sample_count: 14456909
total_episode_count: 43030
total_duration: 3846.754549186194
[2023-06-29 13:33:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 277.6666666666667
avg_sample_per_episode: 277.6666666666667
avg_envstep_per_sec: 2266.4912394424027
avg_train_sample_per_sec: 2266.4912394424027
avg_episode_per_sec: 8.16263351539881
collect_time: 0.36752844463009393
reward_mean: 3354.9618223807797
reward_std: 44.04964125589705
reward_max: 3386.7473450241387
reward_min: 3292.670604674472
total_envstep_count: 19260273
total_train_sample_count: 14460142
total_episode_count: 43033
total_duration: 3847.1220776308237
[2023-06-29 13:33:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2391
train_sample_count: 2391
avg_envstep_per_episode: 265.6666666666667
avg_sample_per_episode: 265.6666666666667
avg_envstep_per_sec: 2590.4634063972458
avg_train_sample_per_sec: 2590.4634063972458
avg_episode_per_sec: 9.750803286313346
collect_time: 0.923000878566876
reward_mean: 2421.2178224651516
reward_std: 1151.7204684877547
reward_max: 3429.2116900444553
reward_min: 401.68499338517375
total_envstep_count: 19265409
total_train_sample_count: 14463733
total_episode_count: 43042
total_duration: 3848.0450785093904
[2023-06-29 13:33:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 327.0
avg_sample_per_episode: 327.0
avg_envstep_per_sec: 2771.7668562091326
avg_train_sample_per_sec: 2771.7668562091326
avg_episode_per_sec: 8.476351242229763
collect_time: 0.3539258714355529
reward_mean: 2931.979567605898
reward_std: 402.55566447795354
reward_max: 3475.3651200226614
reward_min: 2513.229997696999
total_envstep_count: 19270017
total_train_sample_count: 14467114
total_episode_count: 43045
total_duration: 3848.3990043808258
[2023-06-29 13:33:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 870
train_sample_count: 870
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 2733.0386361324577
avg_train_sample_per_sec: 2733.0386361324577
avg_episode_per_sec: 18.84854231815488
collect_time: 0.31832700368668887
reward_mean: 2772.6274777614726
reward_std: 965.5434823759962
reward_max: 3402.797907368383
reward_min: 711.8796002346168
total_envstep_count: 19274489
total_train_sample_count: 14470384
total_episode_count: 43051
total_duration: 3848.7173313845124
[2023-06-29 13:33:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1981
train_sample_count: 1981
avg_envstep_per_episode: 330.1666666666667
avg_sample_per_episode: 330.1666666666667
avg_envstep_per_sec: 2630.1645915166455
avg_train_sample_per_sec: 2630.1645915166455
avg_episode_per_sec: 7.966172412468386
collect_time: 0.7531848031068222
reward_mean: 3138.676541807579
reward_std: 223.59214858570044
reward_max: 3358.8908375796586
reward_min: 2812.114369147342
total_envstep_count: 19278897
total_train_sample_count: 14473965
total_episode_count: 43057
total_duration: 3849.470516187619
[2023-06-29 13:33:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1443
train_sample_count: 1443
avg_envstep_per_episode: 288.6
avg_sample_per_episode: 288.6
avg_envstep_per_sec: 2795.566565904614
avg_train_sample_per_sec: 2795.566565904614
avg_episode_per_sec: 9.686647837507325
collect_time: 0.5161744376253339
reward_mean: 2662.445130213781
reward_std: 970.4776333846921
reward_max: 3370.4162554344603
reward_min: 827.4118155090191
total_envstep_count: 19283385
total_train_sample_count: 14477408
total_episode_count: 43062
total_duration: 3849.9866906252446
[2023-06-29 13:34:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1613
train_sample_count: 1613
avg_envstep_per_episode: 268.8333333333333
avg_sample_per_episode: 268.8333333333333
avg_envstep_per_sec: 2794.5190619317973
avg_train_sample_per_sec: 2794.5190619317973
avg_episode_per_sec: 10.394987211153618
collect_time: 0.5772012873245402
reward_mean: 2534.3159509415505
reward_std: 926.357753874842
reward_max: 3497.9152498962344
reward_min: 1188.552006282877
total_envstep_count: 19286897
total_train_sample_count: 14480621
total_episode_count: 43068
total_duration: 3850.563891912569
[2023-06-29 13:34:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 2767.139842538434
avg_train_sample_per_sec: 2767.139842538434
avg_episode_per_sec: 14.837210951948709
collect_time: 0.404388669773005
reward_mean: 2126.971045146928
reward_std: 1084.855642903802
reward_max: 3426.767397022945
reward_min: 397.2855594963907
total_envstep_count: 19291921
total_train_sample_count: 14484140
total_episode_count: 43074
total_duration: 3850.9682805823422
[2023-06-29 13:34:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2961
train_sample_count: 2961
avg_envstep_per_episode: 296.1
avg_sample_per_episode: 296.1
avg_envstep_per_sec: 2753.501326872636
avg_train_sample_per_sec: 2753.501326872636
avg_episode_per_sec: 9.299227716557366
collect_time: 1.0753581162653865
reward_mean: 2334.7494714558006
reward_std: 1257.190893328152
reward_max: 3386.8708193077578
reward_min: 123.64529469420725
total_envstep_count: 19296721
total_train_sample_count: 14487501
total_episode_count: 43084
total_duration: 3852.0436386986075
[2023-06-29 13:34:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1799
train_sample_count: 1799
avg_envstep_per_episode: 359.8
avg_sample_per_episode: 359.8
avg_envstep_per_sec: 2815.920274708919
avg_train_sample_per_sec: 2815.920274708919
avg_episode_per_sec: 7.826348734599552
collect_time: 0.6388675191402435
reward_mean: 1920.714891274906
reward_std: 877.600840173036
reward_max: 3166.408347574466
reward_min: 696.3387316813867
total_envstep_count: 19301761
total_train_sample_count: 14490900
total_episode_count: 43089
total_duration: 3852.6825062177477
[2023-06-29 13:34:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2343
train_sample_count: 2343
avg_envstep_per_episode: 334.7142857142857
avg_sample_per_episode: 334.7142857142857
avg_envstep_per_sec: 2761.9968711343686
avg_train_sample_per_sec: 2761.9968711343686
avg_episode_per_sec: 8.25180456591574
collect_time: 0.8482992955157533
reward_mean: 2884.2979269145567
reward_std: 619.5571998707325
reward_max: 3354.7417004140666
reward_min: 1545.2802435244869
total_envstep_count: 19306289
total_train_sample_count: 14494443
total_episode_count: 43096
total_duration: 3853.5308055132637
[2023-06-29 13:34:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1862
train_sample_count: 1862
avg_envstep_per_episode: 372.4
avg_sample_per_episode: 372.4
avg_envstep_per_sec: 2683.8896808306176
avg_train_sample_per_sec: 2683.8896808306176
avg_episode_per_sec: 7.207007735850209
collect_time: 0.6937692012079062
reward_mean: 2435.2479042181462
reward_std: 1041.4913223936949
reward_max: 3401.9870481688963
reward_min: 1002.6589840303294
total_envstep_count: 19311513
total_train_sample_count: 14497905
total_episode_count: 43101
total_duration: 3854.2245747144716
[2023-06-29 13:34:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1741
train_sample_count: 1741
avg_envstep_per_episode: 290.1666666666667
avg_sample_per_episode: 290.1666666666667
avg_envstep_per_sec: 2807.4607040784963
avg_train_sample_per_sec: 2807.4607040784963
avg_episode_per_sec: 9.675338440247547
collect_time: 0.6201333459345623
reward_mean: 2801.4603541133183
reward_std: 776.3457145788532
reward_max: 3352.453202148153
reward_min: 1312.556701671725
total_envstep_count: 19316433
total_train_sample_count: 14501246
total_episode_count: 43107
total_duration: 3854.844708060406
[2023-06-29 13:34:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 292.42857142857144
avg_sample_per_episode: 292.42857142857144
avg_envstep_per_sec: 2684.521210798187
avg_train_sample_per_sec: 2684.521210798187
avg_episode_per_sec: 9.1800920740534
collect_time: 0.7625195851558821
reward_mean: 2871.7237993183066
reward_std: 606.6432492308232
reward_max: 3359.1248600294234
reward_min: 1593.0861406439167
total_envstep_count: 19321009
total_train_sample_count: 14504493
total_episode_count: 43114
total_duration: 3855.607227645562
[2023-06-29 13:34:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1204
train_sample_count: 1204
avg_envstep_per_episode: 240.8
avg_sample_per_episode: 240.8
avg_envstep_per_sec: 2808.5025115376757
avg_train_sample_per_sec: 2808.5025115376757
avg_episode_per_sec: 11.663216410040182
collect_time: 0.4286982101863249
reward_mean: 2073.8936443573525
reward_std: 1148.1924367197664
reward_max: 3337.236343551554
reward_min: 693.2233239842476
total_envstep_count: 19324665
total_train_sample_count: 14507697
total_episode_count: 43119
total_duration: 3856.0359258557482
[2023-06-29 13:34:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2277
train_sample_count: 2277
avg_envstep_per_episode: 325.2857142857143
avg_sample_per_episode: 325.2857142857143
avg_envstep_per_sec: 2810.388104716894
avg_train_sample_per_sec: 2810.388104716894
avg_episode_per_sec: 8.639752627588168
collect_time: 0.8102083823150024
reward_mean: 2629.3286366690604
reward_std: 653.2204625472936
reward_max: 3333.4273903133753
reward_min: 1370.7961329887285
total_envstep_count: 19329713
total_train_sample_count: 14511174
total_episode_count: 43126
total_duration: 3856.8461342380633
[2023-06-29 13:34:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 332.0
avg_sample_per_episode: 332.0
avg_envstep_per_sec: 2736.5848194933606
avg_train_sample_per_sec: 2736.5848194933606
avg_episode_per_sec: 8.24272535991976
collect_time: 0.4852763892207296
reward_mean: 2625.21276702884
reward_std: 668.2132251690643
reward_max: 3553.5577376276306
reward_min: 1870.0743883222888
total_envstep_count: 19334137
total_train_sample_count: 14514502
total_episode_count: 43130
total_duration: 3857.331410627284
[2023-06-29 13:34:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1605
train_sample_count: 1605
avg_envstep_per_episode: 200.625
avg_sample_per_episode: 200.625
avg_envstep_per_sec: 2515.390105115887
avg_train_sample_per_sec: 2515.390105115887
avg_episode_per_sec: 12.5377699943471
collect_time: 0.6380720019275323
reward_mean: 2541.477530690172
reward_std: 937.8057266883502
reward_max: 3435.640174122185
reward_min: 1147.7819225450003
total_envstep_count: 19338841
total_train_sample_count: 14517707
total_episode_count: 43138
total_duration: 3857.9694826292116
[2023-06-29 13:34:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3371
train_sample_count: 3371
avg_envstep_per_episode: 421.375
avg_sample_per_episode: 421.375
avg_envstep_per_sec: 2647.583170569485
avg_train_sample_per_sec: 2647.583170569485
avg_episode_per_sec: 6.283199455519395
collect_time: 1.2732366776885466
reward_mean: 2821.11035375757
reward_std: 699.3895372094785
reward_max: 3432.8152879421937
reward_min: 1137.6324284625853
total_envstep_count: 19343817
total_train_sample_count: 14521078
total_episode_count: 43146
total_duration: 3859.2427193069
[2023-06-29 13:34:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1751
train_sample_count: 1751
avg_envstep_per_episode: 291.8333333333333
avg_sample_per_episode: 291.8333333333333
avg_envstep_per_sec: 2823.822058845219
avg_train_sample_per_sec: 2823.822058845219
avg_episode_per_sec: 9.676146403810002
collect_time: 0.6200815644580872
reward_mean: 1957.0333276356284
reward_std: 480.81185018628526
reward_max: 2670.636296436984
reward_min: 1241.0203699309984
total_envstep_count: 19348569
total_train_sample_count: 14524429
total_episode_count: 43152
total_duration: 3859.862800871358
[2023-06-29 13:34:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 292.90909090909093
avg_sample_per_episode: 292.90909090909093
avg_envstep_per_sec: 2722.0653433458197
avg_train_sample_per_sec: 2722.0653433458197
avg_episode_per_sec: 9.293208807201744
collect_time: 1.183660049850121
reward_mean: 2007.2889400386061
reward_std: 850.037980672364
reward_max: 3392.9344096537425
reward_min: 723.1636981798222
total_envstep_count: 19353369
total_train_sample_count: 14527651
total_episode_count: 43163
total_duration: 3861.046460921208
[2023-06-29 13:34:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2107
train_sample_count: 2107
avg_envstep_per_episode: 301.0
avg_sample_per_episode: 301.0
avg_envstep_per_sec: 2838.405926136958
avg_train_sample_per_sec: 2838.405926136958
avg_episode_per_sec: 9.429920020388565
collect_time: 0.7423180668409912
reward_mean: 1792.1439308538932
reward_std: 516.5103696104349
reward_max: 2802.115474259795
reward_min: 1288.0856782650264
total_envstep_count: 19358185
total_train_sample_count: 14530958
total_episode_count: 43170
total_duration: 3861.788778988049
[2023-06-29 13:34:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 697
train_sample_count: 697
avg_envstep_per_episode: 116.16666666666667
avg_sample_per_episode: 116.16666666666667
avg_envstep_per_sec: 2621.7888438538134
avg_train_sample_per_sec: 2621.7888438538134
avg_episode_per_sec: 22.569200951395814
collect_time: 0.2658490219889209
reward_mean: 1805.0505721281725
reward_std: 788.7314990121889
reward_max: 3092.0552849516944
reward_min: 1025.7940315701983
total_envstep_count: 19362425
total_train_sample_count: 14534455
total_episode_count: 43176
total_duration: 3862.054628010038
[2023-06-29 13:34:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1740
train_sample_count: 1740
avg_envstep_per_episode: 348.0
avg_sample_per_episode: 348.0
avg_envstep_per_sec: 2404.2358341227928
avg_train_sample_per_sec: 2404.2358341227928
avg_episode_per_sec: 6.9087236612723935
collect_time: 0.7237226794911551
reward_mean: 3279.7863351704973
reward_std: 203.18880289141947
reward_max: 3404.202362471509
reward_min: 2874.3426794485104
total_envstep_count: 19366633
total_train_sample_count: 14537795
total_episode_count: 43181
total_duration: 3862.778350689529
[2023-06-29 13:34:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 204.33333333333334
avg_sample_per_episode: 204.33333333333334
avg_envstep_per_sec: 2679.6399739449535
avg_train_sample_per_sec: 2679.6399739449535
avg_episode_per_sec: 13.114061862699609
collect_time: 0.45752414948306974
reward_mean: 2358.3257081135416
reward_std: 1106.982829890294
reward_max: 3388.905543630031
reward_min: 403.0675135898316
total_envstep_count: 19370217
total_train_sample_count: 14541021
total_episode_count: 43187
total_duration: 3863.235874839012
[2023-06-29 13:34:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2969
train_sample_count: 2969
avg_envstep_per_episode: 371.125
avg_sample_per_episode: 371.125
avg_envstep_per_sec: 2718.6810012460646
avg_train_sample_per_sec: 2718.6810012460646
avg_episode_per_sec: 7.3255129706866
collect_time: 1.0920736925881358
reward_mean: 2371.8264853338123
reward_std: 1349.7679280098569
reward_max: 3500.4877311890737
reward_min: 383.7119305221015
total_envstep_count: 19374993
total_train_sample_count: 14544390
total_episode_count: 43195
total_duration: 3864.3279485316
[2023-06-29 13:35:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1956
train_sample_count: 1956
avg_envstep_per_episode: 244.5
avg_sample_per_episode: 244.5
avg_envstep_per_sec: 2539.5912558309287
avg_train_sample_per_sec: 2539.5912558309287
avg_episode_per_sec: 10.38687630196699
collect_time: 0.7702026834078134
reward_mean: 1790.083431912177
reward_std: 769.5150135374757
reward_max: 3412.736164800359
reward_min: 1176.8272514117834
total_envstep_count: 19379849
total_train_sample_count: 14547946
total_episode_count: 43203
total_duration: 3865.098151215008
[2023-06-29 13:35:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2084
train_sample_count: 2084
avg_envstep_per_episode: 347.3333333333333
avg_sample_per_episode: 347.3333333333333
avg_envstep_per_sec: 2608.082576513235
avg_train_sample_per_sec: 2608.082576513235
avg_episode_per_sec: 7.5088749803644
collect_time: 0.7990544543210419
reward_mean: 2369.7277266978476
reward_std: 860.4543681016884
reward_max: 3413.1982312710156
reward_min: 1213.0720716147948
total_envstep_count: 19384217
total_train_sample_count: 14551230
total_episode_count: 43209
total_duration: 3865.8972056693287
[2023-06-29 13:35:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2674.6971042868154
avg_train_sample_per_sec: 2674.6971042868154
avg_episode_per_sec: 10.656163762098867
collect_time: 0.750739213341847
reward_mean: 2259.192091065017
reward_std: 976.0358646522682
reward_max: 3381.4454846304006
reward_min: 1102.3727118929576
total_envstep_count: 19388457
total_train_sample_count: 14554438
total_episode_count: 43217
total_duration: 3866.647944882671
[2023-06-29 13:35:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2715
train_sample_count: 2715
avg_envstep_per_episode: 301.6666666666667
avg_sample_per_episode: 301.6666666666667
avg_envstep_per_sec: 2736.1928650937807
avg_train_sample_per_sec: 2736.1928650937807
avg_episode_per_sec: 9.070252591471098
collect_time: 0.9922546157604082
reward_mean: 1926.248811382559
reward_std: 761.9182267248065
reward_max: 3314.982154586408
reward_min: 705.8185698888317
total_envstep_count: 19393393
total_train_sample_count: 14557953
total_episode_count: 43226
total_duration: 3867.6401994984312
[2023-06-29 13:35:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1730
train_sample_count: 1730
avg_envstep_per_episode: 288.3333333333333
avg_sample_per_episode: 288.3333333333333
avg_envstep_per_sec: 2805.8590455829126
avg_train_sample_per_sec: 2805.8590455829126
avg_episode_per_sec: 9.731303048264436
collect_time: 0.6165669664423914
reward_mean: 1934.6634520283108
reward_std: 574.7350346496429
reward_max: 3078.595874094271
reward_min: 1359.486661135278
total_envstep_count: 19397881
total_train_sample_count: 14561283
total_episode_count: 43232
total_duration: 3868.2567664648736
[2023-06-29 13:35:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2853
train_sample_count: 2853
avg_envstep_per_episode: 237.75
avg_sample_per_episode: 237.75
avg_envstep_per_sec: 2618.6781780577544
avg_train_sample_per_sec: 2618.6781780577544
avg_episode_per_sec: 11.014419255763425
collect_time: 1.0894809541339057
reward_mean: 1903.315400003093
reward_std: 862.5200278569599
reward_max: 3447.716028684912
reward_min: 1030.9057700956891
total_envstep_count: 19402481
total_train_sample_count: 14564536
total_episode_count: 43244
total_duration: 3869.3462474190073
[2023-06-29 13:35:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2229
train_sample_count: 2229
avg_envstep_per_episode: 247.66666666666666
avg_sample_per_episode: 247.66666666666666
avg_envstep_per_sec: 2677.1239018272054
avg_train_sample_per_sec: 2677.1239018272054
avg_episode_per_sec: 10.809383183689928
collect_time: 0.8326099507305772
reward_mean: 1543.1410836038908
reward_std: 338.8597822745492
reward_max: 2032.9879749485149
reward_min: 1068.2119627041247
total_envstep_count: 19406577
total_train_sample_count: 14567965
total_episode_count: 43253
total_duration: 3870.178857369738
[2023-06-29 13:35:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1670
train_sample_count: 1670
avg_envstep_per_episode: 278.3333333333333
avg_sample_per_episode: 278.3333333333333
avg_envstep_per_sec: 2788.581361623741
avg_train_sample_per_sec: 2788.581361623741
avg_episode_per_sec: 10.018855191462542
collect_time: 0.5988708176072686
reward_mean: 2135.4396293531627
reward_std: 884.7118959638917
reward_max: 3301.7122085307433
reward_min: 1176.776916513168
total_envstep_count: 19410969
total_train_sample_count: 14571235
total_episode_count: 43259
total_duration: 3870.7777281873455
[2023-06-29 13:35:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1587
train_sample_count: 1587
avg_envstep_per_episode: 198.375
avg_sample_per_episode: 198.375
avg_envstep_per_sec: 2384.296175913275
avg_train_sample_per_sec: 2384.296175913275
avg_episode_per_sec: 12.019136362511784
collect_time: 0.6656052280887962
reward_mean: 1789.7250486332655
reward_std: 656.1918343934979
reward_max: 2893.3530756045493
reward_min: 1048.6765107389801
total_envstep_count: 19415169
total_train_sample_count: 14574822
total_episode_count: 43267
total_duration: 3871.443333415434
[2023-06-29 13:35:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2512
train_sample_count: 2512
avg_envstep_per_episode: 251.2
avg_sample_per_episode: 251.2
avg_envstep_per_sec: 2580.343784519602
avg_train_sample_per_sec: 2580.343784519602
avg_episode_per_sec: 10.272069205890137
collect_time: 0.973513690334745
reward_mean: 2047.4339760954038
reward_std: 779.3407243754764
reward_max: 3443.5363722781067
reward_min: 1251.8014333781573
total_envstep_count: 19419865
total_train_sample_count: 14578134
total_episode_count: 43277
total_duration: 3872.4168471057687
[2023-06-29 13:35:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2941
train_sample_count: 2941
avg_envstep_per_episode: 210.07142857142858
avg_sample_per_episode: 210.07142857142858
avg_envstep_per_sec: 2575.6155887882023
avg_train_sample_per_sec: 2575.6155887882023
avg_episode_per_sec: 12.260665842582398
collect_time: 1.1418629444558173
reward_mean: 1347.0380914683167
reward_std: 411.574824889854
reward_max: 2363.899819708706
reward_min: 948.7777436678266
total_envstep_count: 19424521
total_train_sample_count: 14581475
total_episode_count: 43291
total_duration: 3873.5587100502244
[2023-06-29 13:35:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2294
train_sample_count: 2294
avg_envstep_per_episode: 286.75
avg_sample_per_episode: 286.75
avg_envstep_per_sec: 2719.308610864957
avg_train_sample_per_sec: 2719.308610864957
avg_episode_per_sec: 9.483203525248324
collect_time: 0.8435967844305561
reward_mean: 1743.2390827476177
reward_std: 915.6136565401416
reward_max: 3489.3568228290205
reward_min: 944.1597173338106
total_envstep_count: 19429833
total_train_sample_count: 14584969
total_episode_count: 43299
total_duration: 3874.402306834655
[2023-06-29 13:35:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2028
train_sample_count: 2028
avg_envstep_per_episode: 202.8
avg_sample_per_episode: 202.8
avg_envstep_per_sec: 2718.4315336219106
avg_train_sample_per_sec: 2718.4315336219106
avg_episode_per_sec: 13.404494741725397
collect_time: 0.7460184208862484
reward_mean: 1846.9091718050327
reward_std: 901.3261853621583
reward_max: 3434.790023610094
reward_min: 693.6332289798513
total_envstep_count: 19434321
total_train_sample_count: 14588197
total_episode_count: 43309
total_duration: 3875.1483252555413
[2023-06-29 13:35:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1621
train_sample_count: 1621
avg_envstep_per_episode: 324.2
avg_sample_per_episode: 324.2
avg_envstep_per_sec: 2685.8475560860147
avg_train_sample_per_sec: 2685.8475560860147
avg_episode_per_sec: 8.284539037896405
collect_time: 0.6035338812610135
reward_mean: 2424.483591099072
reward_std: 614.6204613690962
reward_max: 3433.8837550966264
reward_min: 1902.2832180414935
total_envstep_count: 19438777
total_train_sample_count: 14591418
total_episode_count: 43314
total_duration: 3875.7518591368025
[2023-06-29 13:35:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2299
train_sample_count: 2299
avg_envstep_per_episode: 328.42857142857144
avg_sample_per_episode: 328.42857142857144
avg_envstep_per_sec: 2702.607664688375
avg_train_sample_per_sec: 2702.607664688375
avg_episode_per_sec: 8.228905460121194
collect_time: 0.850659912660718
reward_mean: 2828.1143696186914
reward_std: 789.5886869640717
reward_max: 3463.1079890484802
reward_min: 1389.0642491382373
total_envstep_count: 19443457
total_train_sample_count: 14594917
total_episode_count: 43321
total_duration: 3876.6025190494634
[2023-06-29 13:35:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2924
train_sample_count: 2924
avg_envstep_per_episode: 243.66666666666666
avg_sample_per_episode: 243.66666666666666
avg_envstep_per_sec: 2507.255289852617
avg_train_sample_per_sec: 2507.255289852617
avg_episode_per_sec: 10.289693392008004
collect_time: 1.166215507385321
reward_mean: 1593.3613552264635
reward_std: 835.7544014361168
reward_max: 3390.7007870235793
reward_min: 1017.9007495048999
total_envstep_count: 19448033
total_train_sample_count: 14598241
total_episode_count: 43333
total_duration: 3877.768734556849
[2023-06-29 13:35:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2446
train_sample_count: 2446
avg_envstep_per_episode: 305.75
avg_sample_per_episode: 305.75
avg_envstep_per_sec: 2431.5934981415867
avg_train_sample_per_sec: 2431.5934981415867
avg_episode_per_sec: 7.952881433006008
collect_time: 1.0059247163925318
reward_mean: 1674.0602398595902
reward_std: 736.9605159739547
reward_max: 3406.0552840186742
reward_min: 988.827417510779
total_envstep_count: 19452353
total_train_sample_count: 14601487
total_episode_count: 43341
total_duration: 3878.7746592732415
[2023-06-29 13:35:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 201.83333333333334
avg_sample_per_episode: 201.83333333333334
avg_envstep_per_sec: 2648.57057940585
avg_train_sample_per_sec: 2648.57057940585
avg_episode_per_sec: 13.122562738592155
collect_time: 0.45722776255849745
reward_mean: 1979.5658330848019
reward_std: 1086.4703026644602
reward_max: 3529.9072973543834
reward_min: 1002.7758636001829
total_envstep_count: 19456569
total_train_sample_count: 14604698
total_episode_count: 43347
total_duration: 3879.2318870358
[2023-06-29 13:35:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1953
train_sample_count: 1953
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2641.2414317673783
avg_train_sample_per_sec: 2641.2414317673783
avg_episode_per_sec: 9.466815167625013
collect_time: 0.7394250205643473
reward_mean: 2497.7969233484596
reward_std: 849.1318947163674
reward_max: 3567.5866225919654
reward_min: 944.2596615306528
total_envstep_count: 19461417
total_train_sample_count: 14608251
total_episode_count: 43354
total_duration: 3879.9713120563642
[2023-06-29 13:35:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1424
train_sample_count: 1424
avg_envstep_per_episode: 237.33333333333334
avg_sample_per_episode: 237.33333333333334
avg_envstep_per_sec: 2664.8959646733683
avg_train_sample_per_sec: 2664.8959646733683
avg_episode_per_sec: 11.228494233174306
collect_time: 0.5343548186784609
reward_mean: 2138.0895286393747
reward_std: 838.5275101718258
reward_max: 3402.201471153153
reward_min: 1389.9958322696073
total_envstep_count: 19466161
total_train_sample_count: 14611675
total_episode_count: 43360
total_duration: 3880.5056668750426
[2023-06-29 13:36:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1928
train_sample_count: 1928
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 2751.064896695535
avg_train_sample_per_sec: 2751.064896695535
avg_episode_per_sec: 11.415207040230436
collect_time: 0.7008195271277801
reward_mean: 2795.869859472763
reward_std: 978.1258274970842
reward_max: 3503.916697286911
reward_min: 931.3800195561903
total_envstep_count: 19470953
total_train_sample_count: 14615203
total_episode_count: 43368
total_duration: 3881.2064864021704
[2023-06-29 13:36:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2331
train_sample_count: 2331
avg_envstep_per_episode: 291.375
avg_sample_per_episode: 291.375
avg_envstep_per_sec: 2640.321627323389
avg_train_sample_per_sec: 2640.321627323389
avg_episode_per_sec: 9.061592886566757
collect_time: 0.8828469895021986
reward_mean: 2258.7598284645337
reward_std: 918.3830065382319
reward_max: 3420.7347427767027
reward_min: 979.7848373928558
total_envstep_count: 19475241
total_train_sample_count: 14618734
total_episode_count: 43376
total_duration: 3882.0893333916724
[2023-06-29 13:36:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2068
train_sample_count: 2068
avg_envstep_per_episode: 344.6666666666667
avg_sample_per_episode: 344.6666666666667
avg_envstep_per_sec: 2530.617034681384
avg_train_sample_per_sec: 2530.617034681384
avg_episode_per_sec: 7.342215767934384
collect_time: 0.8171920016575602
reward_mean: 2391.6309407907816
reward_std: 1104.958791527027
reward_max: 3563.4290816572507
reward_min: 922.7210775365902
total_envstep_count: 19480041
total_train_sample_count: 14622002
total_episode_count: 43382
total_duration: 3882.90652539333
[2023-06-29 13:36:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 275.5
avg_sample_per_episode: 275.5
avg_envstep_per_sec: 2465.740737228849
avg_train_sample_per_sec: 2465.740737228849
avg_episode_per_sec: 8.950057122427765
collect_time: 0.8938490437064323
reward_mean: 2134.6820205235063
reward_std: 1108.3443769478624
reward_max: 3527.050926377834
reward_min: 780.762720624167
total_envstep_count: 19484689
total_train_sample_count: 14625406
total_episode_count: 43390
total_duration: 3883.800374437036
[2023-06-29 13:36:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1480
train_sample_count: 1480
avg_envstep_per_episode: 211.42857142857142
avg_sample_per_episode: 211.42857142857142
avg_envstep_per_sec: 2795.9952221177546
avg_train_sample_per_sec: 2795.9952221177546
avg_episode_per_sec: 13.224301726232625
collect_time: 0.529328515403904
reward_mean: 1726.9958815012437
reward_std: 852.6864554442416
reward_max: 3425.373382376209
reward_min: 867.206312118587
total_envstep_count: 19489329
total_train_sample_count: 14628886
total_episode_count: 43397
total_duration: 3884.32970295244
[2023-06-29 13:36:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2283
train_sample_count: 2283
avg_envstep_per_episode: 253.66666666666666
avg_sample_per_episode: 253.66666666666666
avg_envstep_per_sec: 2440.9222016496265
avg_train_sample_per_sec: 2440.9222016496265
avg_episode_per_sec: 9.62255795656883
collect_time: 0.9353022388247773
reward_mean: 2377.45218790215
reward_std: 950.5018861750647
reward_max: 3532.666864447744
reward_min: 958.3706462437625
total_envstep_count: 19493641
total_train_sample_count: 14632369
total_episode_count: 43406
total_duration: 3885.265005191265
[2023-06-29 13:36:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2832
train_sample_count: 2832
avg_envstep_per_episode: 283.2
avg_sample_per_episode: 283.2
avg_envstep_per_sec: 2703.878517686338
avg_train_sample_per_sec: 2703.878517686338
avg_episode_per_sec: 9.547593635898085
collect_time: 1.047384333828464
reward_mean: 1887.7067768240206
reward_std: 718.5541897763693
reward_max: 3481.9465950238737
reward_min: 1046.4394588179857
total_envstep_count: 19497921
total_train_sample_count: 14635601
total_episode_count: 43416
total_duration: 3886.3123895250937
[2023-06-29 13:36:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2665
train_sample_count: 2665
avg_envstep_per_episode: 333.125
avg_sample_per_episode: 333.125
avg_envstep_per_sec: 2157.077119695546
avg_train_sample_per_sec: 2157.077119695546
avg_episode_per_sec: 6.475278408091696
collect_time: 1.235468113618554
reward_mean: 1786.9288361344416
reward_std: 939.405212437745
reward_max: 3632.944437055375
reward_min: 1009.3956449744794
total_envstep_count: 19502937
total_train_sample_count: 14639066
total_episode_count: 43424
total_duration: 3887.5478576387122
[2023-06-29 13:36:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2544
train_sample_count: 2544
avg_envstep_per_episode: 282.6666666666667
avg_sample_per_episode: 282.6666666666667
avg_envstep_per_sec: 2617.6225960658307
avg_train_sample_per_sec: 2617.6225960658307
avg_episode_per_sec: 9.260457297402702
collect_time: 0.9718742510182782
reward_mean: 1883.0109649622916
reward_std: 824.3417393483182
reward_max: 3464.33524182288
reward_min: 855.6662968976395
total_envstep_count: 19507473
total_train_sample_count: 14642410
total_episode_count: 43433
total_duration: 3888.5197318897303
[2023-06-29 13:36:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2983
train_sample_count: 2983
avg_envstep_per_episode: 271.1818181818182
avg_sample_per_episode: 271.1818181818182
avg_envstep_per_sec: 2672.938369747915
avg_train_sample_per_sec: 2672.938369747915
avg_episode_per_sec: 9.856628249154229
collect_time: 1.1160002915747462
reward_mean: 1775.1479931419963
reward_std: 721.061208573151
reward_max: 3315.2081705972264
reward_min: 1018.2737103422611
total_envstep_count: 19511793
total_train_sample_count: 14645793
total_episode_count: 43444
total_duration: 3889.6357321813052
[2023-06-29 13:36:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3437
train_sample_count: 3437
avg_envstep_per_episode: 286.4166666666667
avg_sample_per_episode: 286.4166666666667
avg_envstep_per_sec: 2724.032251701935
avg_train_sample_per_sec: 2724.032251701935
avg_episode_per_sec: 9.51073233064394
collect_time: 1.2617324915491046
reward_mean: 1458.5497015937997
reward_std: 586.7013589402944
reward_max: 2882.4751152428826
reward_min: 966.8265590986252
total_envstep_count: 19516753
total_train_sample_count: 14649230
total_episode_count: 43456
total_duration: 3890.8974646728543
[2023-06-29 13:36:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2823
train_sample_count: 2823
avg_envstep_per_episode: 256.6363636363636
avg_sample_per_episode: 256.6363636363636
avg_envstep_per_sec: 2600.4084265202528
avg_train_sample_per_sec: 2600.4084265202528
avg_episode_per_sec: 10.132657701637541
collect_time: 1.0855986971929672
reward_mean: 1444.277517683333
reward_std: 349.7496585959538
reward_max: 2226.512366095481
reward_min: 1042.0788471536957
total_envstep_count: 19521145
total_train_sample_count: 14652453
total_episode_count: 43467
total_duration: 3891.983063370047
[2023-06-29 13:36:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2267
train_sample_count: 2267
avg_envstep_per_episode: 226.7
avg_sample_per_episode: 226.7
avg_envstep_per_sec: 2262.401594081309
avg_train_sample_per_sec: 2262.401594081309
avg_episode_per_sec: 9.979715898020771
collect_time: 1.002032533008605
reward_mean: 1294.5682378067727
reward_std: 422.8219749757916
reward_max: 2510.623069626767
reward_min: 1011.9910334301004
total_envstep_count: 19525673
total_train_sample_count: 14655920
total_episode_count: 43477
total_duration: 3892.985095903056
[2023-06-29 13:36:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2442
train_sample_count: 2442
avg_envstep_per_episode: 244.2
avg_sample_per_episode: 244.2
avg_envstep_per_sec: 2590.6224581885645
avg_train_sample_per_sec: 2590.6224581885645
avg_episode_per_sec: 10.608609574891746
collect_time: 0.9426305991755799
reward_mean: 1764.2445968927943
reward_std: 911.67589229721
reward_max: 3452.628464135047
reward_min: 275.3520024751583
total_envstep_count: 19529785
total_train_sample_count: 14659162
total_episode_count: 43487
total_duration: 3893.9277265022315
[2023-06-29 13:36:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2930
train_sample_count: 2930
avg_envstep_per_episode: 244.16666666666666
avg_sample_per_episode: 244.16666666666666
avg_envstep_per_sec: 2655.8149700928843
avg_train_sample_per_sec: 2655.8149700928843
avg_episode_per_sec: 10.877057897991335
collect_time: 1.1032395076444375
reward_mean: 1350.0631951201674
reward_std: 444.97067646854794
reward_max: 2521.60124282406
reward_min: 982.9398979322972
total_envstep_count: 19534161
total_train_sample_count: 14662492
total_episode_count: 43499
total_duration: 3895.030966009876
[2023-06-29 13:36:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3474
train_sample_count: 3474
avg_envstep_per_episode: 231.6
avg_sample_per_episode: 231.6
avg_envstep_per_sec: 2573.767679562802
avg_train_sample_per_sec: 2573.767679562802
avg_episode_per_sec: 11.112986526609681
collect_time: 1.3497721754708325
reward_mean: 1216.1482157222406
reward_std: 440.65249516122117
reward_max: 2723.1921019926926
reward_min: 935.9303607907665
total_envstep_count: 19538905
total_train_sample_count: 14665966
total_episode_count: 43514
total_duration: 3896.3807381853467
[2023-06-29 13:36:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3307
train_sample_count: 3307
avg_envstep_per_episode: 254.3846153846154
avg_sample_per_episode: 254.3846153846154
avg_envstep_per_sec: 2393.3381958511395
avg_train_sample_per_sec: 2393.3381958511395
avg_episode_per_sec: 9.408344888438107
collect_time: 1.3817520673562542
reward_mean: 1310.213469315309
reward_std: 318.4329108312295
reward_max: 2285.605051623468
reward_min: 1013.9122689745725
total_envstep_count: 19543609
total_train_sample_count: 14669273
total_episode_count: 43527
total_duration: 3897.7624902527027
[2023-06-29 13:36:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2834
train_sample_count: 2834
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2449.9243188009164
avg_train_sample_per_sec: 2449.9243188009164
avg_episode_per_sec: 11.238184948628057
collect_time: 1.1567704268461094
reward_mean: 1088.269452793616
reward_std: 190.20058340145331
reward_max: 1567.4051812492637
reward_min: 799.2189479715378
total_envstep_count: 19548361
total_train_sample_count: 14672507
total_episode_count: 43540
total_duration: 3898.9192606795486
[2023-06-29 13:36:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3348
train_sample_count: 3348
avg_envstep_per_episode: 257.53846153846155
avg_sample_per_episode: 257.53846153846155
avg_envstep_per_sec: 2650.225558630995
avg_train_sample_per_sec: 2650.225558630995
avg_episode_per_sec: 10.290601034110791
collect_time: 1.2632886997472959
reward_mean: 1560.551619388191
reward_std: 606.0230647631791
reward_max: 3416.3176726308507
reward_min: 980.8842233614985
total_envstep_count: 19552641
total_train_sample_count: 14675855
total_episode_count: 43553
total_duration: 3900.182549379296
[2023-06-29 13:37:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2651
train_sample_count: 2651
avg_envstep_per_episode: 220.91666666666666
avg_sample_per_episode: 220.91666666666666
avg_envstep_per_sec: 2712.1149460062325
avg_train_sample_per_sec: 2712.1149460062325
avg_episode_per_sec: 12.276642531902977
collect_time: 0.9774659454990179
reward_mean: 1071.4053516132958
reward_std: 100.2210027438864
reward_max: 1376.0123327025356
reward_min: 963.4346906586229
total_envstep_count: 19557009
total_train_sample_count: 14679306
total_episode_count: 43565
total_duration: 3901.1600153247946
[2023-06-29 13:37:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2937
train_sample_count: 2937
avg_envstep_per_episode: 244.75
avg_sample_per_episode: 244.75
avg_envstep_per_sec: 2374.2068220740416
avg_train_sample_per_sec: 2374.2068220740416
avg_episode_per_sec: 9.70053859887249
collect_time: 1.2370447143414058
reward_mean: 1403.371815130589
reward_std: 465.1612797196996
reward_max: 2609.108213881113
reward_min: 809.6031370400385
total_envstep_count: 19561297
total_train_sample_count: 14682643
total_episode_count: 43577
total_duration: 3902.397060039136
[2023-06-29 13:37:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2940
train_sample_count: 2940
avg_envstep_per_episode: 226.15384615384616
avg_sample_per_episode: 226.15384615384616
avg_envstep_per_sec: 2334.3810897290105
avg_train_sample_per_sec: 2334.3810897290105
avg_episode_per_sec: 10.322093253903788
collect_time: 1.2594344654930758
reward_mean: 1224.654286595162
reward_std: 539.5384542043964
reward_max: 3042.757450867855
reward_min: 765.3020516989823
total_envstep_count: 19565833
total_train_sample_count: 14685983
total_episode_count: 43590
total_duration: 3903.656494504629
[2023-06-29 13:37:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2918
train_sample_count: 2918
avg_envstep_per_episode: 265.27272727272725
avg_sample_per_episode: 265.27272727272725
avg_envstep_per_sec: 2568.8061384387906
avg_train_sample_per_sec: 2568.8061384387906
avg_episode_per_sec: 9.683642057171589
collect_time: 1.1359362453771753
reward_mean: 1497.0545609845199
reward_std: 719.5236295968821
reward_max: 2989.8478906985565
reward_min: 975.0498941294202
total_envstep_count: 19570121
total_train_sample_count: 14689301
total_episode_count: 43601
total_duration: 3904.792430750006
[2023-06-29 13:37:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3453
train_sample_count: 3453
avg_envstep_per_episode: 246.64285714285714
avg_sample_per_episode: 246.64285714285714
avg_envstep_per_sec: 2521.140385218278
avg_train_sample_per_sec: 2521.140385218278
avg_episode_per_sec: 10.221826062280885
collect_time: 1.369618296642788
reward_mean: 1248.8427637571874
reward_std: 316.6433715910418
reward_max: 1943.0560412270577
reward_min: 973.2222564296303
total_envstep_count: 19574561
total_train_sample_count: 14692754
total_episode_count: 43615
total_duration: 3906.162049046649
[2023-06-29 13:37:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3492
train_sample_count: 3492
avg_envstep_per_episode: 232.8
avg_sample_per_episode: 232.8
avg_envstep_per_sec: 2606.805548921993
avg_train_sample_per_sec: 2606.805548921993
avg_episode_per_sec: 11.197618337293783
collect_time: 1.3395705718994142
reward_mean: 1095.1820906179867
reward_std: 116.17108395533452
reward_max: 1374.8026019515512
reward_min: 937.5356410495631
total_envstep_count: 19578889
total_train_sample_count: 14696246
total_episode_count: 43630
total_duration: 3907.5016196185484
[2023-06-29 13:37:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3343
train_sample_count: 3343
avg_envstep_per_episode: 238.78571428571428
avg_sample_per_episode: 238.78571428571428
avg_envstep_per_sec: 2531.1319864945617
avg_train_sample_per_sec: 2531.1319864945617
avg_episode_per_sec: 10.600014301801933
collect_time: 1.3207529349861435
reward_mean: 1095.9881124805747
reward_std: 176.3265663174416
reward_max: 1548.6455941491547
reward_min: 891.7747482336551
total_envstep_count: 19583185
total_train_sample_count: 14699589
total_episode_count: 43644
total_duration: 3908.8223725535345
[2023-06-29 13:37:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3453
train_sample_count: 3453
avg_envstep_per_episode: 287.75
avg_sample_per_episode: 287.75
avg_envstep_per_sec: 2762.667021711294
avg_train_sample_per_sec: 2762.667021711294
avg_episode_per_sec: 9.600927964244288
collect_time: 1.2498791830008849
reward_mean: 1362.2038049911423
reward_std: 404.1256150483848
reward_max: 2510.4126584767687
reward_min: 860.9733084875536
total_envstep_count: 19588041
total_train_sample_count: 14703042
total_episode_count: 43656
total_duration: 3910.0722517365352
[2023-06-29 13:37:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2854
train_sample_count: 2854
avg_envstep_per_episode: 219.53846153846155
avg_sample_per_episode: 219.53846153846155
avg_envstep_per_sec: 2438.0628577652365
avg_train_sample_per_sec: 2438.0628577652365
avg_episode_per_sec: 11.105401944971295
collect_time: 1.17060148425214
reward_mean: 1221.584863725393
reward_std: 185.41427261250024
reward_max: 1608.9515661768746
reward_min: 976.1305694318885
total_envstep_count: 19592441
total_train_sample_count: 14706296
total_episode_count: 43669
total_duration: 3911.2428532207873
[2023-06-29 13:37:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2936
train_sample_count: 2936
avg_envstep_per_episode: 244.66666666666666
avg_sample_per_episode: 244.66666666666666
avg_envstep_per_sec: 2625.546298897077
avg_train_sample_per_sec: 2625.546298897077
avg_episode_per_sec: 10.731115663067072
collect_time: 1.1182434685053302
reward_mean: 1307.623430711195
reward_std: 654.6422491879266
reward_max: 3376.787080597645
reward_min: 663.7929976404943
total_envstep_count: 19596561
total_train_sample_count: 14709632
total_episode_count: 43681
total_duration: 3912.3610966892925
[2023-06-29 13:37:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 271.44444444444446
avg_sample_per_episode: 271.44444444444446
avg_envstep_per_sec: 2517.7854785837026
avg_train_sample_per_sec: 2517.7854785837026
avg_episode_per_sec: 9.27550933575658
collect_time: 0.9702971205371433
reward_mean: 1493.3140304470196
reward_std: 804.5637583344734
reward_max: 3189.863346801828
reward_min: 904.8319258115984
total_envstep_count: 19600713
total_train_sample_count: 14712875
total_episode_count: 43690
total_duration: 3913.3313938098295
[2023-06-29 13:37:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3378
train_sample_count: 3378
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 2507.602005826221
avg_train_sample_per_sec: 2507.602005826221
avg_episode_per_sec: 8.908000020697054
collect_time: 1.3471037238570858
reward_mean: 1589.2973028590084
reward_std: 646.4218539035169
reward_max: 3101.8782659068856
reward_min: 965.5817128775692
total_envstep_count: 19605633
total_train_sample_count: 14716253
total_episode_count: 43702
total_duration: 3914.6784975336864
[2023-06-29 13:37:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2786
train_sample_count: 2786
avg_envstep_per_episode: 253.27272727272728
avg_sample_per_episode: 253.27272727272728
avg_envstep_per_sec: 2597.6079749583196
avg_train_sample_per_sec: 2597.6079749583196
avg_episode_per_sec: 10.256169319648786
collect_time: 1.0725251950478414
reward_mean: 1429.3400907692867
reward_std: 572.2033863527729
reward_max: 2597.42142142528
reward_min: 641.1550506315147
total_envstep_count: 19610193
total_train_sample_count: 14719839
total_episode_count: 43713
total_duration: 3915.7510227287344
[2023-06-29 13:37:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2113
train_sample_count: 2113
avg_envstep_per_episode: 234.77777777777777
avg_sample_per_episode: 234.77777777777777
avg_envstep_per_sec: 2625.2016725880717
avg_train_sample_per_sec: 2625.2016725880717
avg_episode_per_sec: 11.18164460638554
collect_time: 0.8048905431013555
reward_mean: 1337.5353424005325
reward_std: 438.0123512470453
reward_max: 2291.872423370976
reward_min: 879.7768245767263
total_envstep_count: 19614433
total_train_sample_count: 14723152
total_episode_count: 43722
total_duration: 3916.555913271836
[2023-06-29 13:37:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 227.54545454545453
avg_sample_per_episode: 227.54545454545453
avg_envstep_per_sec: 2487.2711437989815
avg_train_sample_per_sec: 2487.2711437989815
avg_episode_per_sec: 10.930875981537673
collect_time: 1.0063237400716172
reward_mean: 1750.7601120208783
reward_std: 873.2800053343234
reward_max: 3479.8633906282735
reward_min: 976.4294047954363
total_envstep_count: 19618649
total_train_sample_count: 14726455
total_episode_count: 43733
total_duration: 3917.5622370119077
[2023-06-29 13:37:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 291.27272727272725
avg_sample_per_episode: 291.27272727272725
avg_envstep_per_sec: 2758.6465592228337
avg_train_sample_per_sec: 2758.6465592228337
avg_episode_per_sec: 9.47100878634556
collect_time: 1.1614391083512456
reward_mean: 1636.248096934562
reward_std: 506.815501796498
reward_max: 2851.653637710951
reward_min: 1027.2367420017317
total_envstep_count: 19623097
total_train_sample_count: 14729659
total_episode_count: 43744
total_duration: 3918.723676120259
[2023-06-29 13:37:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2553
train_sample_count: 2553
avg_envstep_per_episode: 319.125
avg_sample_per_episode: 319.125
avg_envstep_per_sec: 2685.871979936274
avg_train_sample_per_sec: 2685.871979936274
avg_episode_per_sec: 8.416363431057654
collect_time: 0.9505292951678856
reward_mean: 1664.7666457081482
reward_std: 583.6129530567666
reward_max: 2577.573280123646
reward_min: 1012.5794395986309
total_envstep_count: 19626945
total_train_sample_count: 14733012
total_episode_count: 43752
total_duration: 3919.674205415427
[2023-06-29 13:37:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3014
train_sample_count: 3014
avg_envstep_per_episode: 334.8888888888889
avg_sample_per_episode: 334.8888888888889
avg_envstep_per_sec: 2652.1247285291342
avg_train_sample_per_sec: 2652.1247285291342
avg_episode_per_sec: 7.919416906689519
collect_time: 1.136447304901667
reward_mean: 1840.1695119186184
reward_std: 803.3758345763338
reward_max: 3743.9111834045843
reward_min: 1072.9428675875547
total_envstep_count: 19631761
total_train_sample_count: 14736426
total_episode_count: 43761
total_duration: 3920.8106527203286
[2023-06-29 13:37:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 247.4
avg_sample_per_episode: 247.4
avg_envstep_per_sec: 2718.2480525492883
avg_train_sample_per_sec: 2718.2480525492883
avg_episode_per_sec: 10.987259711193566
collect_time: 0.9101450464315712
reward_mean: 1496.5296805743096
reward_std: 748.0828745395257
reward_max: 3493.3088589294402
reward_min: 798.2848501290533
total_envstep_count: 19635769
total_train_sample_count: 14739700
total_episode_count: 43771
total_duration: 3921.72079776676
[2023-06-29 13:37:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 248.4
avg_sample_per_episode: 248.4
avg_envstep_per_sec: 2768.1233287135533
avg_train_sample_per_sec: 2768.1233287135533
avg_episode_per_sec: 11.14381372267936
collect_time: 0.8973588619530202
reward_mean: 1551.3234731840844
reward_std: 799.7230693433042
reward_max: 3537.4150887910096
reward_min: 865.4982804790437
total_envstep_count: 19640057
total_train_sample_count: 14742984
total_episode_count: 43781
total_duration: 3922.6181566287128
[2023-06-29 13:37:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2449
train_sample_count: 2449
avg_envstep_per_episode: 222.63636363636363
avg_sample_per_episode: 222.63636363636363
avg_envstep_per_sec: 2726.9417260864825
avg_train_sample_per_sec: 2726.9417260864825
avg_episode_per_sec: 12.248411182911926
collect_time: 0.8980756635069848
reward_mean: 1428.0148773816597
reward_std: 674.0600234945442
reward_max: 3302.5927800199024
reward_min: 914.0626459830808
total_envstep_count: 19644681
total_train_sample_count: 14746233
total_episode_count: 43792
total_duration: 3923.5162322922197
[2023-06-29 13:38:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2136
train_sample_count: 2136
avg_envstep_per_episode: 356.0
avg_sample_per_episode: 356.0
avg_envstep_per_sec: 2567.7499951938235
avg_train_sample_per_sec: 2567.7499951938235
avg_episode_per_sec: 7.212780885375909
collect_time: 0.8318566854242235
reward_mean: 2209.7628356549235
reward_std: 879.3794865405677
reward_max: 3476.7945687953784
reward_min: 1134.228667000438
total_envstep_count: 19649393
total_train_sample_count: 14749569
total_episode_count: 43798
total_duration: 3924.348088977644
[2023-06-29 13:38:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2201
train_sample_count: 2201
avg_envstep_per_episode: 244.55555555555554
avg_sample_per_episode: 244.55555555555554
avg_envstep_per_sec: 2786.326224475508
avg_train_sample_per_sec: 2786.326224475508
avg_episode_per_sec: 11.393428450831246
collect_time: 0.7899290401339533
reward_mean: 2060.9645266949533
reward_std: 889.8190539698373
reward_max: 3554.6903528278117
reward_min: 997.8809360998182
total_envstep_count: 19653801
total_train_sample_count: 14752970
total_episode_count: 43807
total_duration: 3925.1380180177775
[2023-06-29 13:38:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 269.6666666666667
avg_sample_per_episode: 269.6666666666667
avg_envstep_per_sec: 2522.116973100877
avg_train_sample_per_sec: 2522.116973100877
avg_episode_per_sec: 9.352720543019322
collect_time: 0.9622868510400875
reward_mean: 1956.1242202844285
reward_std: 947.3071166327142
reward_max: 3522.2254471636315
reward_min: 573.8095417329928
total_envstep_count: 19658041
total_train_sample_count: 14756197
total_episode_count: 43816
total_duration: 3926.1003048688176
[2023-06-29 13:38:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1402
train_sample_count: 1402
avg_envstep_per_episode: 280.4
avg_sample_per_episode: 280.4
avg_envstep_per_sec: 2770.531747578806
avg_train_sample_per_sec: 2770.531747578806
avg_episode_per_sec: 9.880641039867353
collect_time: 0.5060400413116439
reward_mean: 2070.715182222306
reward_std: 1207.3802455886282
reward_max: 3648.3968731599525
reward_min: 876.2815031845859
total_envstep_count: 19662785
total_train_sample_count: 14759599
total_episode_count: 43821
total_duration: 3926.6063449101293
[2023-06-29 13:38:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1630
train_sample_count: 1630
avg_envstep_per_episode: 203.75
avg_sample_per_episode: 203.75
avg_envstep_per_sec: 2390.714136133951
avg_train_sample_per_sec: 2390.714136133951
avg_episode_per_sec: 11.733566312313869
collect_time: 0.6818046437939629
reward_mean: 2422.577706164996
reward_std: 826.2880018883701
reward_max: 3546.4536476348144
reward_min: 1384.9825399507058
total_envstep_count: 19666905
total_train_sample_count: 14762829
total_episode_count: 43829
total_duration: 3927.288149553923
[2023-06-29 13:38:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 229.33333333333334
avg_sample_per_episode: 229.33333333333334
avg_envstep_per_sec: 2699.3812621412126
avg_train_sample_per_sec: 2699.3812621412126
avg_episode_per_sec: 11.770557829104126
collect_time: 0.5097464442308992
reward_mean: 2171.257813916186
reward_std: 655.7581579349591
reward_max: 3461.515249021225
reward_min: 1653.7306515018468
total_envstep_count: 19670937
total_train_sample_count: 14766205
total_episode_count: 43835
total_duration: 3927.797895998154
[2023-06-29 13:38:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 1
envstep_count: 52
train_sample_count: 52
avg_envstep_per_episode: 52.0
avg_sample_per_episode: 52.0
avg_envstep_per_sec: 2529.557412219318
avg_train_sample_per_sec: 2529.557412219318
avg_episode_per_sec: 48.6453348503715
collect_time: 0.020556955832988024
reward_mean: 3490.3862672525347
reward_std: 0.0
reward_max: 3490.3862672525347
reward_min: 3490.3862672525347
total_envstep_count: 19674553
total_train_sample_count: 14769457
total_episode_count: 43836
total_duration: 3927.818452953987
[2023-06-29 13:38:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1942
train_sample_count: 1942
avg_envstep_per_episode: 194.2
avg_sample_per_episode: 194.2
avg_envstep_per_sec: 2579.6164639745707
avg_train_sample_per_sec: 2579.6164639745707
avg_episode_per_sec: 13.283297960734144
collect_time: 0.7528250912958756
reward_mean: 2728.94672560293
reward_std: 840.0730123018014
reward_max: 3512.110284311451
reward_min: 1246.448884107121
total_envstep_count: 19679201
total_train_sample_count: 14772999
total_episode_count: 43846
total_duration: 3928.571278045283
[2023-06-29 13:38:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1214
train_sample_count: 1214
avg_envstep_per_episode: 242.8
avg_sample_per_episode: 242.8
avg_envstep_per_sec: 2710.6713076919154
avg_train_sample_per_sec: 2710.6713076919154
avg_episode_per_sec: 11.1642146115812
collect_time: 0.4478595381723717
reward_mean: 2037.9030097493974
reward_std: 554.7963068546894
reward_max: 2799.968932122995
reward_min: 1380.6703188848605
total_envstep_count: 19683481
total_train_sample_count: 14776213
total_episode_count: 43851
total_duration: 3929.0191375834556
[2023-06-29 13:38:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1704
train_sample_count: 1704
avg_envstep_per_episode: 170.4
avg_sample_per_episode: 170.4
avg_envstep_per_sec: 2712.4448578456518
avg_train_sample_per_sec: 2712.4448578456518
avg_episode_per_sec: 15.918103625854764
collect_time: 0.6282155359108
reward_mean: 2026.665774842016
reward_std: 1010.2845777567022
reward_max: 3596.111953640273
reward_min: 889.2705216666878
total_envstep_count: 19687377
total_train_sample_count: 14779517
total_episode_count: 43861
total_duration: 3929.6473531193665
[2023-06-29 13:38:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2599
train_sample_count: 2599
avg_envstep_per_episode: 259.9
avg_sample_per_episode: 259.9
avg_envstep_per_sec: 2720.740484698364
avg_train_sample_per_sec: 2720.740484698364
avg_episode_per_sec: 10.468412792221486
collect_time: 0.9552546502016487
reward_mean: 1749.689797842504
reward_std: 844.9253575478087
reward_max: 3512.312029752262
reward_min: 957.4697714654093
total_envstep_count: 19691889
total_train_sample_count: 14782916
total_episode_count: 43871
total_duration: 3930.6026077695683
[2023-06-29 13:38:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2847
train_sample_count: 2847
avg_envstep_per_episode: 237.25
avg_sample_per_episode: 237.25
avg_envstep_per_sec: 2763.0035253285546
avg_train_sample_per_sec: 2763.0035253285546
avg_episode_per_sec: 11.645957957127733
collect_time: 1.0304004225479435
reward_mean: 1515.3046299540504
reward_std: 807.2717118160334
reward_max: 3609.2070042456235
reward_min: 655.4586474313504
total_envstep_count: 19696305
total_train_sample_count: 14786163
total_episode_count: 43883
total_duration: 3931.6330081921164
[2023-06-29 13:38:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2583
train_sample_count: 2583
avg_envstep_per_episode: 258.3
avg_sample_per_episode: 258.3
avg_envstep_per_sec: 2589.6749836797703
avg_train_sample_per_sec: 2589.6749836797703
avg_episode_per_sec: 10.02584198095149
collect_time: 0.9974224627716466
reward_mean: 1612.1529550329046
reward_std: 553.3873883716933
reward_max: 3118.3921438698744
reward_min: 926.8626374418599
total_envstep_count: 19700473
total_train_sample_count: 14789546
total_episode_count: 43893
total_duration: 3932.630430654888
[2023-06-29 13:38:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1648
train_sample_count: 1648
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 2663.0905227188655
avg_train_sample_per_sec: 2663.0905227188655
avg_episode_per_sec: 12.927623896693522
collect_time: 0.6188298842795192
reward_mean: 1498.412270399486
reward_std: 544.5101526718233
reward_max: 2463.908908627758
reward_min: 1000.1791980752467
total_envstep_count: 19705073
total_train_sample_count: 14792794
total_episode_count: 43901
total_duration: 3933.2492605391676
[2023-06-29 13:38:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1711
train_sample_count: 1711
avg_envstep_per_episode: 171.1
avg_sample_per_episode: 171.1
avg_envstep_per_sec: 2720.0504715972347
avg_train_sample_per_sec: 2720.0504715972347
avg_episode_per_sec: 15.897431160708562
collect_time: 0.6290324454881484
reward_mean: 1703.4233876208389
reward_std: 916.0587699840455
reward_max: 3580.113899129202
reward_min: 10.933058117125515
total_envstep_count: 19708969
total_train_sample_count: 14796105
total_episode_count: 43911
total_duration: 3933.8782929846557
[2023-06-29 13:38:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2824
train_sample_count: 2824
avg_envstep_per_episode: 235.33333333333334
avg_sample_per_episode: 235.33333333333334
avg_envstep_per_sec: 2608.7853191276604
avg_train_sample_per_sec: 2608.7853191276604
avg_episode_per_sec: 11.085490024621786
collect_time: 1.0824961254168297
reward_mean: 1545.0726377190567
reward_std: 386.55840828608785
reward_max: 2147.359279677619
reward_min: 1089.732575379182
total_envstep_count: 19713305
total_train_sample_count: 14799329
total_episode_count: 43923
total_duration: 3934.9607891100727
[2023-06-29 13:38:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2546
train_sample_count: 2546
avg_envstep_per_episode: 363.7142857142857
avg_sample_per_episode: 363.7142857142857
avg_envstep_per_sec: 2526.489913781036
avg_train_sample_per_sec: 2526.489913781036
avg_episode_per_sec: 6.946358757449825
collect_time: 1.0077222102144734
reward_mean: 2072.7368536828553
reward_std: 636.0513166776393
reward_max: 3106.176595565893
reward_min: 899.5139810615846
total_envstep_count: 19718001
total_train_sample_count: 14802675
total_episode_count: 43930
total_duration: 3935.9685113202872
[2023-06-29 13:38:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1951
train_sample_count: 1951
avg_envstep_per_episode: 278.7142857142857
avg_sample_per_episode: 278.7142857142857
avg_envstep_per_sec: 2753.7381949108726
avg_train_sample_per_sec: 2753.7381949108726
avg_episode_per_sec: 9.880147290812973
collect_time: 0.7084914621170608
reward_mean: 2189.2405685495387
reward_std: 807.2383731062997
reward_max: 3527.2384701902497
reward_min: 975.290306721857
total_envstep_count: 19722369
total_train_sample_count: 14806226
total_episode_count: 43937
total_duration: 3936.677002782404
[2023-06-29 13:38:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2859
train_sample_count: 2859
avg_envstep_per_episode: 238.25
avg_sample_per_episode: 238.25
avg_envstep_per_sec: 2750.1942646314046
avg_train_sample_per_sec: 2750.1942646314046
avg_episode_per_sec: 11.543312758159097
collect_time: 1.039562927160412
reward_mean: 1615.3733716457427
reward_std: 505.8083353729995
reward_max: 2497.800486326014
reward_min: 798.9901721069468
total_envstep_count: 19726729
total_train_sample_count: 14809485
total_episode_count: 43949
total_duration: 3937.7165657095643
[2023-06-29 13:38:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1825
train_sample_count: 1825
avg_envstep_per_episode: 260.7142857142857
avg_sample_per_episode: 260.7142857142857
avg_envstep_per_sec: 2597.576530034307
avg_train_sample_per_sec: 2597.576530034307
avg_episode_per_sec: 9.963307238487753
collect_time: 0.7025779525255784
reward_mean: 1642.2195968709743
reward_std: 626.3540864936989
reward_max: 2975.050297673712
reward_min: 990.4533318292546
total_envstep_count: 19730817
total_train_sample_count: 14812910
total_episode_count: 43956
total_duration: 3938.41914366209
[2023-06-29 13:39:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2882
train_sample_count: 2882
avg_envstep_per_episode: 240.16666666666666
avg_sample_per_episode: 240.16666666666666
avg_envstep_per_sec: 2609.391475044802
avg_train_sample_per_sec: 2609.391475044802
avg_episode_per_sec: 10.864919396439147
collect_time: 1.1044720685118807
reward_mean: 1640.3511607353614
reward_std: 692.9901916768
reward_max: 3350.135368963974
reward_min: 1006.564156556772
total_envstep_count: 19735177
total_train_sample_count: 14816192
total_episode_count: 43968
total_duration: 3939.5236157306017
[2023-06-29 13:39:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3394
train_sample_count: 3394
avg_envstep_per_episode: 282.8333333333333
avg_sample_per_episode: 282.8333333333333
avg_envstep_per_sec: 2552.950450799913
avg_train_sample_per_sec: 2552.950450799913
avg_episode_per_sec: 9.026342194931926
collect_time: 1.3294421750083563
reward_mean: 1496.9744281751184
reward_std: 412.70244422707935
reward_max: 2462.4079791619406
reward_min: 878.3123244426455
total_envstep_count: 19739817
total_train_sample_count: 14819586
total_episode_count: 43980
total_duration: 3940.85305790561
[2023-06-29 13:39:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2184
train_sample_count: 2184
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2684.290403164075
avg_train_sample_per_sec: 2684.290403164075
avg_episode_per_sec: 9.832565579355586
collect_time: 0.8136228470010682
reward_mean: 1598.8141549404647
reward_std: 507.79025751430635
reward_max: 2495.983049361177
reward_min: 1029.9759198659553
total_envstep_count: 19744769
total_train_sample_count: 14822970
total_episode_count: 43988
total_duration: 3941.6666807526112
[2023-06-29 13:39:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1677
train_sample_count: 1677
avg_envstep_per_episode: 209.625
avg_sample_per_episode: 209.625
avg_envstep_per_sec: 2734.3645501329315
avg_train_sample_per_sec: 2734.3645501329315
avg_episode_per_sec: 13.04407656592931
collect_time: 0.6133052009902895
reward_mean: 1705.68839992934
reward_std: 1029.6333920367754
reward_max: 3650.163254884225
reward_min: 834.8912020522243
total_envstep_count: 19749025
total_train_sample_count: 14826247
total_episode_count: 43996
total_duration: 3942.2799859536017
[2023-06-29 13:39:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2631
train_sample_count: 2631
avg_envstep_per_episode: 239.1818181818182
avg_sample_per_episode: 239.1818181818182
avg_envstep_per_sec: 2545.040494470106
avg_train_sample_per_sec: 2545.040494470106
avg_episode_per_sec: 10.64061020112929
collect_time: 1.033775299731642
reward_mean: 1944.2488997840794
reward_std: 914.2754314264986
reward_max: 3552.5809623642517
reward_min: 889.5869003463557
total_envstep_count: 19753961
total_train_sample_count: 14829678
total_episode_count: 44007
total_duration: 3943.3137612533333
[2023-06-29 13:39:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2943
train_sample_count: 2943
avg_envstep_per_episode: 267.54545454545456
avg_sample_per_episode: 267.54545454545456
avg_envstep_per_sec: 2518.4606848623735
avg_train_sample_per_sec: 2518.4606848623735
avg_episode_per_sec: 9.413206773185902
collect_time: 1.1685709519665686
reward_mean: 1740.2865768844779
reward_std: 757.7800752537701
reward_max: 3427.84220142857
reward_min: 879.3854302174576
total_envstep_count: 19758697
total_train_sample_count: 14833021
total_episode_count: 44018
total_duration: 3944.4823322053
[2023-06-29 13:39:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 302.5
avg_sample_per_episode: 302.5
avg_envstep_per_sec: 2298.917928525077
avg_train_sample_per_sec: 2298.917928525077
avg_episode_per_sec: 7.599728689339098
collect_time: 0.5263345789713785
reward_mean: 1726.1957052747111
reward_std: 1068.4518589078302
reward_max: 2742.9452764204925
reward_min: 11.83348492466011
total_envstep_count: 19762273
total_train_sample_count: 14836231
total_episode_count: 44022
total_duration: 3945.008666784271
[2023-06-29 13:39:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2126
train_sample_count: 2126
avg_envstep_per_episode: 212.6
avg_sample_per_episode: 212.6
avg_envstep_per_sec: 2730.9717404202497
avg_train_sample_per_sec: 2730.9717404202497
avg_episode_per_sec: 12.845586737630525
collect_time: 0.7784774805735797
reward_mean: 1959.5347268917005
reward_std: 1114.5083582323514
reward_max: 3430.6481611888917
reward_min: 9.331336487407924
total_envstep_count: 19766697
total_train_sample_count: 14839557
total_episode_count: 44032
total_duration: 3945.7871442648448
[2023-06-29 13:39:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2497
train_sample_count: 2497
avg_envstep_per_episode: 277.44444444444446
avg_sample_per_episode: 277.44444444444446
avg_envstep_per_sec: 2577.7189095937874
avg_train_sample_per_sec: 2577.7189095937874
avg_episode_per_sec: 9.290937199176646
collect_time: 0.9686859147856011
reward_mean: 1901.6780962883943
reward_std: 742.4423613615227
reward_max: 3272.031570301602
reward_min: 1007.3370287706657
total_envstep_count: 19771681
total_train_sample_count: 14842854
total_episode_count: 44041
total_duration: 3946.7558301796303
[2023-06-29 13:39:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2738
train_sample_count: 2738
avg_envstep_per_episode: 273.8
avg_sample_per_episode: 273.8
avg_envstep_per_sec: 2614.073678799486
avg_train_sample_per_sec: 2614.073678799486
avg_episode_per_sec: 9.547383779399146
collect_time: 1.0474073558850212
reward_mean: 1886.658753447391
reward_std: 672.0117080840107
reward_max: 3401.5131961061084
reward_min: 1296.5198077529144
total_envstep_count: 19776537
total_train_sample_count: 14846392
total_episode_count: 44051
total_duration: 3947.803237535515
[2023-06-29 13:39:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 241.33333333333334
avg_sample_per_episode: 241.33333333333334
avg_envstep_per_sec: 2598.540111134535
avg_train_sample_per_sec: 2598.540111134535
avg_episode_per_sec: 10.767431399728737
collect_time: 0.5572359625296668
reward_mean: 1811.9637707571264
reward_std: 888.7004788328285
reward_max: 3643.5669361321234
reward_min: 1121.495377435686
total_envstep_count: 19780825
total_train_sample_count: 14849840
total_episode_count: 44057
total_duration: 3948.360473498045
[2023-06-29 13:39:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1988
train_sample_count: 1988
avg_envstep_per_episode: 198.8
avg_sample_per_episode: 198.8
avg_envstep_per_sec: 2495.772921916437
avg_train_sample_per_sec: 2495.772921916437
avg_episode_per_sec: 12.554189748070609
collect_time: 0.7965468262527138
reward_mean: 2031.074945676851
reward_std: 992.1202596031792
reward_max: 3619.1427723624765
reward_min: 554.4194516322852
total_envstep_count: 19785457
total_train_sample_count: 14853428
total_episode_count: 44067
total_duration: 3949.1570203242977
[2023-06-29 13:39:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1803
train_sample_count: 1803
avg_envstep_per_episode: 200.33333333333334
avg_sample_per_episode: 200.33333333333334
avg_envstep_per_sec: 2766.0626801736407
avg_train_sample_per_sec: 2766.0626801736407
avg_episode_per_sec: 13.807301232147958
collect_time: 0.6518290467252954
reward_mean: 1835.301264483097
reward_std: 827.5566464903314
reward_max: 3641.0186153775335
reward_min: 849.3269582655205
total_envstep_count: 19789929
total_train_sample_count: 14856831
total_episode_count: 44076
total_duration: 3949.808849371023
[2023-06-29 13:39:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2111
train_sample_count: 2111
avg_envstep_per_episode: 263.875
avg_sample_per_episode: 263.875
avg_envstep_per_sec: 2778.8166117046967
avg_train_sample_per_sec: 2778.8166117046967
avg_episode_per_sec: 10.530806676284971
collect_time: 0.7596758962459862
reward_mean: 2063.5954212295496
reward_std: 1146.6301817335539
reward_max: 3594.812623067547
reward_min: 388.2514915906732
total_envstep_count: 19794113
total_train_sample_count: 14860142
total_episode_count: 44084
total_duration: 3950.568525267269
[2023-06-29 13:39:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 207.0
avg_sample_per_episode: 207.0
avg_envstep_per_sec: 2342.602871236885
avg_train_sample_per_sec: 2342.602871236885
avg_episode_per_sec: 11.316922083269978
collect_time: 0.5301794919017703
reward_mean: 1916.2882960822863
reward_std: 1404.5503873110843
reward_max: 3509.6828939307134
reward_min: 114.32370137573321
total_envstep_count: 19799153
total_train_sample_count: 14863384
total_episode_count: 44090
total_duration: 3951.0987047591707
[2023-06-29 13:39:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2092
train_sample_count: 2092
avg_envstep_per_episode: 232.44444444444446
avg_sample_per_episode: 232.44444444444446
avg_envstep_per_sec: 2685.4726345932067
avg_train_sample_per_sec: 2685.4726345932067
avg_episode_per_sec: 11.553180550353183
collect_time: 0.7790062624551356
reward_mean: 2420.512570951245
reward_std: 917.6582102280108
reward_max: 3593.784809019192
reward_min: 1130.4472141476579
total_envstep_count: 19803553
total_train_sample_count: 14866676
total_episode_count: 44099
total_duration: 3951.8777110216256
[2023-06-29 13:39:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1881
train_sample_count: 1881
avg_envstep_per_episode: 268.7142857142857
avg_sample_per_episode: 268.7142857142857
avg_envstep_per_sec: 2737.788514203531
avg_train_sample_per_sec: 2737.788514203531
avg_episode_per_sec: 10.188474002883954
collect_time: 0.6870508771007883
reward_mean: 2087.624600762608
reward_std: 870.6784112733164
reward_max: 3534.172254120954
reward_min: 938.1038851385479
total_envstep_count: 19808481
total_train_sample_count: 14870157
total_episode_count: 44106
total_duration: 3952.5647618987264
[2023-06-29 13:39:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1255
train_sample_count: 1255
avg_envstep_per_episode: 313.75
avg_sample_per_episode: 313.75
avg_envstep_per_sec: 2761.076607190316
avg_train_sample_per_sec: 2761.076607190316
avg_episode_per_sec: 8.800244166343637
collect_time: 0.45453284299746166
reward_mean: 3379.7983250103066
reward_std: 181.81316252816166
reward_max: 3497.311036583153
reward_min: 3065.555557381348
total_envstep_count: 19812753
total_train_sample_count: 14873412
total_episode_count: 44110
total_duration: 3953.019294741724
[2023-06-29 13:39:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1855
train_sample_count: 1855
avg_envstep_per_episode: 309.1666666666667
avg_sample_per_episode: 309.1666666666667
avg_envstep_per_sec: 2723.6132800008163
avg_train_sample_per_sec: 2723.6132800008163
avg_episode_per_sec: 8.809530824800484
collect_time: 0.6810805387170986
reward_mean: 3080.1036141740365
reward_std: 852.5055689070937
reward_max: 3479.5042192467436
reward_min: 1174.2488836713828
total_envstep_count: 19817633
total_train_sample_count: 14876867
total_episode_count: 44116
total_duration: 3953.700375280441
[2023-06-29 13:40:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1672
train_sample_count: 1672
avg_envstep_per_episode: 278.6666666666667
avg_sample_per_episode: 278.6666666666667
avg_envstep_per_sec: 2440.8987763086893
avg_train_sample_per_sec: 2440.8987763086893
avg_episode_per_sec: 8.759206135079028
collect_time: 0.6849935836046934
reward_mean: 2615.6351928078466
reward_std: 1010.0220359763462
reward_max: 3568.3509790415087
reward_min: 988.6597340420539
total_envstep_count: 19821881
total_train_sample_count: 14880139
total_episode_count: 44122
total_duration: 3954.385368864046
[2023-06-29 13:40:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1318
train_sample_count: 1318
avg_envstep_per_episode: 263.6
avg_sample_per_episode: 263.6
avg_envstep_per_sec: 2718.0248526459936
avg_train_sample_per_sec: 2718.0248526459936
avg_episode_per_sec: 10.31117167164641
collect_time: 0.48491094506252536
reward_mean: 3172.7529143899387
reward_std: 565.5960248121534
reward_max: 3555.274816690437
reward_min: 2054.2863593105512
total_envstep_count: 19826233
total_train_sample_count: 14883457
total_episode_count: 44127
total_duration: 3954.8702798091085
[2023-06-29 13:40:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1824
train_sample_count: 1824
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 2719.7318921814954
avg_train_sample_per_sec: 2719.7318921814954
avg_episode_per_sec: 8.94648648743913
collect_time: 0.6706543410560115
reward_mean: 2784.401105074619
reward_std: 892.0281624006437
reward_max: 3493.9209986075557
reward_min: 1200.170743367382
total_envstep_count: 19830489
total_train_sample_count: 14886881
total_episode_count: 44133
total_duration: 3955.5409341501645
[2023-06-29 13:40:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2410.517104203935
avg_train_sample_per_sec: 2410.517104203935
avg_episode_per_sec: 7.604154902851531
collect_time: 0.5260282110376282
reward_mean: 2533.5070720969716
reward_std: 965.2845187881246
reward_max: 3498.5244856957484
reward_min: 1462.1022791813696
total_envstep_count: 19834761
total_train_sample_count: 14890149
total_episode_count: 44137
total_duration: 3956.066962361202
[2023-06-29 13:40:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 203.6
avg_sample_per_episode: 203.6
avg_envstep_per_sec: 2523.251563925597
avg_train_sample_per_sec: 2523.251563925597
avg_episode_per_sec: 12.393180569379162
collect_time: 0.8068953683050348
reward_mean: 2177.8823206642764
reward_std: 937.963228958196
reward_max: 3511.047658465378
reward_min: 1179.7732136530112
total_envstep_count: 19838881
total_train_sample_count: 14893385
total_episode_count: 44147
total_duration: 3956.873857729507
[2023-06-29 13:40:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2070
train_sample_count: 2070
avg_envstep_per_episode: 258.75
avg_sample_per_episode: 258.75
avg_envstep_per_sec: 2725.23055418097
avg_train_sample_per_sec: 2725.23055418097
avg_episode_per_sec: 10.532291996834667
collect_time: 0.7595687626590952
reward_mean: 1969.2401672210567
reward_std: 792.4526732378047
reward_max: 3436.2499793209486
reward_min: 1078.7957549691484
total_envstep_count: 19843505
total_train_sample_count: 14897055
total_episode_count: 44155
total_duration: 3957.633426492166
[2023-06-29 13:40:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1533
train_sample_count: 1533
avg_envstep_per_episode: 219.0
avg_sample_per_episode: 219.0
avg_envstep_per_sec: 2718.2312417429157
avg_train_sample_per_sec: 2718.2312417429157
avg_episode_per_sec: 12.412014802479067
collect_time: 0.5639696786860003
reward_mean: 2177.581794853075
reward_std: 789.1805369615269
reward_max: 3567.957909783469
reward_min: 1284.5814966794796
total_envstep_count: 19847745
total_train_sample_count: 14900588
total_episode_count: 44162
total_duration: 3958.1973961708522
[2023-06-29 13:40:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2090
train_sample_count: 2090
avg_envstep_per_episode: 261.25
avg_sample_per_episode: 261.25
avg_envstep_per_sec: 2626.1874262191827
avg_train_sample_per_sec: 2626.1874262191827
avg_episode_per_sec: 10.052392062082996
collect_time: 0.795830480008386
reward_mean: 2183.8541973677507
reward_std: 933.643417597699
reward_max: 3532.1686672656692
reward_min: 1020.185215548585
total_envstep_count: 19851769
total_train_sample_count: 14903878
total_episode_count: 44170
total_duration: 3958.993226650861
[2023-06-29 13:40:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1753
train_sample_count: 1753
avg_envstep_per_episode: 438.25
avg_sample_per_episode: 438.25
avg_envstep_per_sec: 2728.020314103113
avg_train_sample_per_sec: 2728.020314103113
avg_episode_per_sec: 6.2248039112449804
collect_time: 0.6425905228555203
reward_mean: 2965.1344085208075
reward_std: 655.1863576952152
reward_max: 3567.327264591681
reward_min: 1981.2602550502882
total_envstep_count: 19856217
total_train_sample_count: 14907231
total_episode_count: 44174
total_duration: 3959.6358171737165
[2023-06-29 13:40:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2990
train_sample_count: 2990
avg_envstep_per_episode: 249.16666666666666
avg_sample_per_episode: 249.16666666666666
avg_envstep_per_sec: 2537.484742883681
avg_train_sample_per_sec: 2537.484742883681
avg_episode_per_sec: 10.18388525572046
collect_time: 1.1783322080597283
reward_mean: 1932.877154716443
reward_std: 946.458303963736
reward_max: 3740.2284832274177
reward_min: 919.643111575357
total_envstep_count: 19861289
total_train_sample_count: 14910621
total_episode_count: 44186
total_duration: 3960.814149381776
[2023-06-29 13:40:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3462
train_sample_count: 3462
avg_envstep_per_episode: 247.28571428571428
avg_sample_per_episode: 247.28571428571428
avg_envstep_per_sec: 2643.7893208340524
avg_train_sample_per_sec: 2643.7893208340524
avg_episode_per_sec: 10.691233533124416
collect_time: 1.309484069974162
reward_mean: 1465.0865493138258
reward_std: 562.2736193609827
reward_max: 2881.8302098405115
reward_min: 1021.239076169554
total_envstep_count: 19866097
total_train_sample_count: 14914083
total_episode_count: 44200
total_duration: 3962.1236334517503
[2023-06-29 13:40:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2659
train_sample_count: 2659
avg_envstep_per_episode: 241.72727272727272
avg_sample_per_episode: 241.72727272727272
avg_envstep_per_sec: 2546.4264895692413
avg_train_sample_per_sec: 2546.4264895692413
avg_episode_per_sec: 10.534295368658013
collect_time: 1.0442084273360672
reward_mean: 1370.4242982936123
reward_std: 266.8909501313453
reward_max: 1836.609052302896
reward_min: 1051.0351516350893
total_envstep_count: 19870489
total_train_sample_count: 14917542
total_episode_count: 44211
total_duration: 3963.167841879086
[2023-06-29 13:40:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 302.90909090909093
avg_sample_per_episode: 302.90909090909093
avg_envstep_per_sec: 2642.0724656485095
avg_train_sample_per_sec: 2642.0724656485095
avg_episode_per_sec: 8.72232806786723
collect_time: 1.2611311927745117
reward_mean: 1717.2810664168908
reward_std: 796.1752278665692
reward_max: 3652.1878400312476
reward_min: 973.2329789284122
total_envstep_count: 19875329
total_train_sample_count: 14920874
total_episode_count: 44222
total_duration: 3964.4289730718606
[2023-06-29 13:40:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 236.9090909090909
avg_sample_per_episode: 236.9090909090909
avg_envstep_per_sec: 2545.2376602460267
avg_train_sample_per_sec: 2545.2376602460267
avg_episode_per_sec: 10.74352043849052
collect_time: 1.0238729532817379
reward_mean: 1406.3000057475947
reward_std: 234.3847971698117
reward_max: 1849.2912228318155
reward_min: 1070.651555536485
total_envstep_count: 19880201
total_train_sample_count: 14924280
total_episode_count: 44233
total_duration: 3965.452846025142
[2023-06-29 13:40:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2697
train_sample_count: 2697
avg_envstep_per_episode: 224.75
avg_sample_per_episode: 224.75
avg_envstep_per_sec: 2467.092433821154
avg_train_sample_per_sec: 2467.092433821154
avg_episode_per_sec: 10.97705198585608
collect_time: 1.093189684758894
reward_mean: 1551.7214955659622
reward_std: 437.2228004336242
reward_max: 2793.5510544511453
reward_min: 964.7872388480839
total_envstep_count: 19884625
total_train_sample_count: 14927777
total_episode_count: 44245
total_duration: 3966.546035709901
[2023-06-29 13:40:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 323.55555555555554
avg_sample_per_episode: 323.55555555555554
avg_envstep_per_sec: 2735.4620159705883
avg_train_sample_per_sec: 2735.4620159705883
avg_episode_per_sec: 8.45438123067833
collect_time: 1.0645368069447578
reward_mean: 1913.791262419966
reward_std: 926.1840995757507
reward_max: 3254.517332277685
reward_min: 1013.8585234628814
total_envstep_count: 19889369
total_train_sample_count: 14931089
total_episode_count: 44254
total_duration: 3967.610572516846
[2023-06-29 13:40:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3167
train_sample_count: 3167
avg_envstep_per_episode: 316.7
avg_sample_per_episode: 316.7
avg_envstep_per_sec: 2631.4091432131777
avg_train_sample_per_sec: 2631.4091432131777
avg_episode_per_sec: 8.308838469255377
collect_time: 1.2035376589642839
reward_mean: 1870.6296449602644
reward_std: 510.76424068429964
reward_max: 2773.9669867471243
reward_min: 1097.399321575115
total_envstep_count: 19894369
total_train_sample_count: 14934656
total_episode_count: 44264
total_duration: 3968.81411017581
[2023-06-29 13:40:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 226.55555555555554
avg_sample_per_episode: 226.55555555555554
avg_envstep_per_sec: 2419.007628568929
avg_train_sample_per_sec: 2419.007628568929
avg_episode_per_sec: 10.677326462540638
collect_time: 0.8429076353125272
reward_mean: 1588.8678998807632
reward_std: 457.8770467503546
reward_max: 2539.71379359302
reward_min: 1053.066299279785
total_envstep_count: 19898905
total_train_sample_count: 14937895
total_episode_count: 44273
total_duration: 3969.657017811123
[2023-06-29 13:40:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2918
train_sample_count: 2918
avg_envstep_per_episode: 224.46153846153845
avg_sample_per_episode: 224.46153846153845
avg_envstep_per_sec: 2751.2322113189816
avg_train_sample_per_sec: 2751.2322113189816
avg_episode_per_sec: 12.257031784491693
collect_time: 1.0606156717687845
reward_mean: 1559.4204688114983
reward_std: 587.7666609209684
reward_max: 2922.2876172374663
reward_min: 949.724768308539
total_envstep_count: 19903193
total_train_sample_count: 14941213
total_episode_count: 44286
total_duration: 3970.7176334828914
[2023-06-29 13:40:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2834
train_sample_count: 2834
avg_envstep_per_episode: 283.4
avg_sample_per_episode: 283.4
avg_envstep_per_sec: 2757.814439092974
avg_train_sample_per_sec: 2757.814439092974
avg_episode_per_sec: 9.731173038436747
collect_time: 1.027625339771621
reward_mean: 1467.8564317071002
reward_std: 643.4573194889867
reward_max: 2865.4403821850847
reward_min: 906.3778011476884
total_envstep_count: 19907577
total_train_sample_count: 14944447
total_episode_count: 44296
total_duration: 3971.745258822663
[2023-06-29 13:41:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3232
train_sample_count: 3232
avg_envstep_per_episode: 323.2
avg_sample_per_episode: 323.2
avg_envstep_per_sec: 2600.215138312688
avg_train_sample_per_sec: 2600.215138312688
avg_episode_per_sec: 8.045220106165495
collect_time: 1.2429740725597365
reward_mean: 1856.1785330514826
reward_std: 737.8525378469963
reward_max: 3711.6068267920036
reward_min: 987.8918034899756
total_envstep_count: 19912353
total_train_sample_count: 14947679
total_episode_count: 44306
total_duration: 3972.9882328952226
[2023-06-29 13:41:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2858
train_sample_count: 2858
avg_envstep_per_episode: 285.8
avg_sample_per_episode: 285.8
avg_envstep_per_sec: 2524.6761613944195
avg_train_sample_per_sec: 2524.6761613944195
avg_episode_per_sec: 8.833716449945486
collect_time: 1.1320263737989589
reward_mean: 1654.9000763680633
reward_std: 329.8994406092321
reward_max: 2192.630260550847
reward_min: 1177.1455779664066
total_envstep_count: 19917185
total_train_sample_count: 14950937
total_episode_count: 44316
total_duration: 3974.1202592690215
[2023-06-29 13:41:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3438
train_sample_count: 3438
avg_envstep_per_episode: 286.5
avg_sample_per_episode: 286.5
avg_envstep_per_sec: 2606.53674051917
avg_train_sample_per_sec: 2606.53674051917
avg_episode_per_sec: 9.097859478251902
collect_time: 1.3189915747419003
reward_mean: 1677.241912757777
reward_std: 662.3108868679794
reward_max: 3008.385881750317
reward_min: 761.9851801971892
total_envstep_count: 19921689
total_train_sample_count: 14954375
total_episode_count: 44328
total_duration: 3975.4392508437636
[2023-06-29 13:41:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1555
train_sample_count: 1555
avg_envstep_per_episode: 222.14285714285714
avg_sample_per_episode: 222.14285714285714
avg_envstep_per_sec: 2675.0338267698817
avg_train_sample_per_sec: 2675.0338267698817
avg_episode_per_sec: 12.04195291793516
collect_time: 0.5813010603599249
reward_mean: 1302.1958701574383
reward_std: 338.8228425058912
reward_max: 1903.064155898553
reward_min: 942.9054158219598
total_envstep_count: 19926465
total_train_sample_count: 14957930
total_episode_count: 44335
total_duration: 3976.0205519041237
[2023-06-29 13:41:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3128
train_sample_count: 3128
avg_envstep_per_episode: 240.6153846153846
avg_sample_per_episode: 240.6153846153846
avg_envstep_per_sec: 2584.136436233557
avg_train_sample_per_sec: 2584.136436233557
avg_episode_per_sec: 10.739697465165039
collect_time: 1.2104624028904363
reward_mean: 1877.944704649129
reward_std: 639.5488016986059
reward_max: 3245.119804774824
reward_min: 773.0919549600301
total_envstep_count: 19931249
total_train_sample_count: 14961458
total_episode_count: 44348
total_duration: 3977.231014307014
[2023-06-29 13:41:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3135
train_sample_count: 3135
avg_envstep_per_episode: 261.25
avg_sample_per_episode: 261.25
avg_envstep_per_sec: 2748.9574449891124
avg_train_sample_per_sec: 2748.9574449891124
avg_episode_per_sec: 10.522325148283684
collect_time: 1.1404323503496128
reward_mean: 1480.789633679635
reward_std: 609.5150465811425
reward_max: 2726.144159697447
reward_min: 144.00658460669388
total_envstep_count: 19935777
total_train_sample_count: 14964993
total_episode_count: 44360
total_duration: 3978.371446657364
[2023-06-29 13:41:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2587
train_sample_count: 2587
avg_envstep_per_episode: 258.7
avg_sample_per_episode: 258.7
avg_envstep_per_sec: 2519.0467575141975
avg_train_sample_per_sec: 2519.0467575141975
avg_episode_per_sec: 9.737328015130256
collect_time: 1.02697577656433
reward_mean: 1448.7104923496265
reward_std: 264.67935722608905
reward_max: 1847.8079051899979
reward_min: 995.2767174262364
total_envstep_count: 19940745
total_train_sample_count: 14968380
total_episode_count: 44370
total_duration: 3979.3984224339283
[2023-06-29 13:41:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3145
train_sample_count: 3145
avg_envstep_per_episode: 262.0833333333333
avg_sample_per_episode: 262.0833333333333
avg_envstep_per_sec: 2503.031649056923
avg_train_sample_per_sec: 2503.031649056923
avg_episode_per_sec: 9.550518215797482
collect_time: 1.2564763218974693
reward_mean: 1766.3763285936313
reward_std: 603.6102613979382
reward_max: 3257.843142032748
reward_min: 1022.9793139664826
total_envstep_count: 19945569
total_train_sample_count: 14971925
total_episode_count: 44382
total_duration: 3980.654898755826
[2023-06-29 13:41:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3183
train_sample_count: 3183
avg_envstep_per_episode: 244.84615384615384
avg_sample_per_episode: 244.84615384615384
avg_envstep_per_sec: 2565.167355634687
avg_train_sample_per_sec: 2565.167355634687
avg_episode_per_sec: 10.476649583176542
collect_time: 1.2408547118799762
reward_mean: 1389.6058426702593
reward_std: 421.73397661593486
reward_max: 2356.832877308995
reward_min: 1011.9694485654677
total_envstep_count: 19950561
total_train_sample_count: 14975508
total_episode_count: 44395
total_duration: 3981.8957534677056
[2023-06-29 13:41:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3441
train_sample_count: 3441
avg_envstep_per_episode: 286.75
avg_sample_per_episode: 286.75
avg_envstep_per_sec: 2743.119663893599
avg_train_sample_per_sec: 2743.119663893599
avg_episode_per_sec: 9.566241199280206
collect_time: 1.2544111893083898
reward_mean: 1639.380111037459
reward_std: 490.713601540231
reward_max: 2752.1143399221596
reward_min: 1126.8166022204164
total_envstep_count: 19954913
total_train_sample_count: 14978949
total_episode_count: 44407
total_duration: 3983.150164657014
[2023-06-29 13:41:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2940
train_sample_count: 2940
avg_envstep_per_episode: 326.6666666666667
avg_sample_per_episode: 326.6666666666667
avg_envstep_per_sec: 2771.0566546170944
avg_train_sample_per_sec: 2771.0566546170944
avg_episode_per_sec: 8.482826493725799
collect_time: 1.0609671206474305
reward_mean: 1572.483009613335
reward_std: 463.9232224550397
reward_max: 2476.901938324647
reward_min: 1074.626031473811
total_envstep_count: 19959217
total_train_sample_count: 14982289
total_episode_count: 44416
total_duration: 3984.2111317776616
[2023-06-29 13:41:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2341
train_sample_count: 2341
avg_envstep_per_episode: 292.625
avg_sample_per_episode: 292.625
avg_envstep_per_sec: 2586.337858627561
avg_train_sample_per_sec: 2586.337858627561
avg_episode_per_sec: 8.838403617693503
collect_time: 0.9051408315394069
reward_mean: 1670.2044080704989
reward_std: 558.5983395877935
reward_max: 2307.8216497743615
reward_min: 1034.8779862055335
total_envstep_count: 19963913
total_train_sample_count: 14985830
total_episode_count: 44424
total_duration: 3985.116272609201
[2023-06-29 13:41:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2490
train_sample_count: 2490
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 2721.808836980159
avg_train_sample_per_sec: 2721.808836980159
avg_episode_per_sec: 10.930959184659272
collect_time: 0.914832800220698
reward_mean: 1659.878826124485
reward_std: 1024.7803574518327
reward_max: 3763.3263867516994
reward_min: 276.9686933354027
total_envstep_count: 19967841
total_train_sample_count: 14989120
total_episode_count: 44434
total_duration: 3986.031105409422
[2023-06-29 13:41:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2570
train_sample_count: 2570
avg_envstep_per_episode: 285.55555555555554
avg_sample_per_episode: 285.55555555555554
avg_envstep_per_sec: 2713.6209125034748
avg_train_sample_per_sec: 2713.6209125034748
avg_episode_per_sec: 9.502952611879872
collect_time: 0.9470740692475811
reward_mean: 1822.9668371274747
reward_std: 649.6328983082294
reward_max: 3576.624963125037
reward_min: 1363.278295078027
total_envstep_count: 19973001
total_train_sample_count: 14992490
total_episode_count: 44443
total_duration: 3986.9781794786695
[2023-06-29 13:41:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2121
train_sample_count: 2121
avg_envstep_per_episode: 235.66666666666666
avg_sample_per_episode: 235.66666666666666
avg_envstep_per_sec: 2721.7017382923627
avg_train_sample_per_sec: 2721.7017382923627
avg_episode_per_sec: 11.548946555696022
collect_time: 0.779291856326163
reward_mean: 1735.355254099997
reward_std: 765.6906939204209
reward_max: 3472.254400479046
reward_min: 1033.6626342107672
total_envstep_count: 19977257
total_train_sample_count: 14995811
total_episode_count: 44452
total_duration: 3987.757471334996
[2023-06-29 13:41:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 282.9
avg_sample_per_episode: 282.9
avg_envstep_per_sec: 2623.311972809167
avg_train_sample_per_sec: 2623.311972809167
avg_episode_per_sec: 9.272930267971605
collect_time: 1.0784077644301575
reward_mean: 2011.656452605479
reward_std: 1014.528504241371
reward_max: 3584.331042614825
reward_min: 702.3250421683441
total_envstep_count: 19981569
total_train_sample_count: 14999040
total_episode_count: 44462
total_duration: 3988.835879099426
[2023-06-29 13:41:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3586
train_sample_count: 3586
avg_envstep_per_episode: 358.6
avg_sample_per_episode: 358.6
avg_envstep_per_sec: 2626.7315492642488
avg_train_sample_per_sec: 2626.7315492642488
avg_episode_per_sec: 7.324962490976712
collect_time: 1.3651947040436787
reward_mean: 1889.744713558217
reward_std: 408.75231898979547
reward_max: 2611.186839016407
reward_min: 1321.2525542094297
total_envstep_count: 19986161
total_train_sample_count: 15002626
total_episode_count: 44472
total_duration: 3990.2010738034696
[2023-06-29 13:41:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2403
train_sample_count: 2403
avg_envstep_per_episode: 300.375
avg_sample_per_episode: 300.375
avg_envstep_per_sec: 2467.8458995441897
avg_train_sample_per_sec: 2467.8458995441897
avg_episode_per_sec: 8.215883144549945
collect_time: 0.9737236836561931
reward_mean: 1502.740117795519
reward_std: 585.8215279539174
reward_max: 2283.540512757276
reward_min: 278.5046045259769
total_envstep_count: 19990873
total_train_sample_count: 15005829
total_episode_count: 44480
total_duration: 3991.174797487126
[2023-06-29 13:41:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1773
train_sample_count: 1773
avg_envstep_per_episode: 221.625
avg_sample_per_episode: 221.625
avg_envstep_per_sec: 2729.7732691911683
avg_train_sample_per_sec: 2729.7732691911683
avg_episode_per_sec: 12.31708186888288
collect_time: 0.6495044918237256
reward_mean: 1785.69899882028
reward_std: 854.8801331729796
reward_max: 3173.4182798917755
reward_min: 659.1720704014691
total_envstep_count: 19994961
total_train_sample_count: 15009202
total_episode_count: 44488
total_duration: 3991.8243019789497
[2023-06-29 13:42:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3294
train_sample_count: 3294
avg_envstep_per_episode: 329.4
avg_sample_per_episode: 329.4
avg_envstep_per_sec: 2605.326306998413
avg_train_sample_per_sec: 2605.326306998413
avg_episode_per_sec: 7.90930876441534
collect_time: 1.2643329901332034
reward_mean: 2224.392655014344
reward_std: 975.4864298588811
reward_max: 3595.4674004700337
reward_min: 1020.5173598853928
total_envstep_count: 19999377
total_train_sample_count: 15012496
total_episode_count: 44498
total_duration: 3993.088634969083
[2023-06-29 13:42:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2188
train_sample_count: 2188
avg_envstep_per_episode: 243.11111111111111
avg_sample_per_episode: 243.11111111111111
avg_envstep_per_sec: 2488.4624691275053
avg_train_sample_per_sec: 2488.4624691275053
avg_episode_per_sec: 10.235905951621366
collect_time: 0.8792577855382113
reward_mean: 1356.8916687378041
reward_std: 283.60442662795725
reward_max: 1864.4521208286194
reward_min: 962.6542414387584
total_envstep_count: 20004009
total_train_sample_count: 15015884
total_episode_count: 44507
total_duration: 3993.9678927546215
[2023-06-29 13:42:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3505
train_sample_count: 3505
avg_envstep_per_episode: 269.61538461538464
avg_sample_per_episode: 269.61538461538464
avg_envstep_per_sec: 2576.1430622996095
avg_train_sample_per_sec: 2576.1430622996095
avg_episode_per_sec: 9.554881543479294
collect_time: 1.3605610850164667
reward_mean: 1733.4081159957302
reward_std: 804.8628606370869
reward_max: 3409.0613669494446
reward_min: 109.40866840648609
total_envstep_count: 20008961
total_train_sample_count: 15019389
total_episode_count: 44520
total_duration: 3995.328453839638
[2023-06-29 13:42:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2790
train_sample_count: 2790
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2725.034456508347
avg_train_sample_per_sec: 2725.034456508347
avg_episode_per_sec: 9.767148589635651
collect_time: 1.023840264968574
reward_mean: 1561.6611760035112
reward_std: 387.68677970055376
reward_max: 2446.5542899644884
reward_min: 911.5513755840568
total_envstep_count: 20013737
total_train_sample_count: 15022979
total_episode_count: 44530
total_duration: 3996.3522941046062
[2023-06-29 13:42:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 2590.327187247151
avg_train_sample_per_sec: 2590.327187247151
avg_episode_per_sec: 11.262292118465874
collect_time: 1.2430862077396596
reward_mean: 1384.342482302384
reward_std: 586.41100780839
reward_max: 3017.9666775400033
reward_min: 866.8329700350971
total_envstep_count: 20018153
total_train_sample_count: 15026199
total_episode_count: 44544
total_duration: 3997.5953803123457
[2023-06-29 13:42:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 276.55555555555554
avg_sample_per_episode: 276.55555555555554
avg_envstep_per_sec: 2743.7853173026856
avg_train_sample_per_sec: 2743.7853173026856
avg_episode_per_sec: 9.9212807777116
collect_time: 0.9071409429535269
reward_mean: 1493.312885287588
reward_std: 419.389731947823
reward_max: 2224.705307122779
reward_min: 982.3769996452905
total_envstep_count: 20022929
total_train_sample_count: 15029488
total_episode_count: 44553
total_duration: 3998.502521255299
[2023-06-29 13:42:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2221
train_sample_count: 2221
avg_envstep_per_episode: 277.625
avg_sample_per_episode: 277.625
avg_envstep_per_sec: 2541.9268215726343
avg_train_sample_per_sec: 2541.9268215726343
avg_episode_per_sec: 9.15597234244983
collect_time: 0.8737466323385015
reward_mean: 1911.7839894250012
reward_std: 1026.5827802640247
reward_max: 3624.8538299324046
reward_min: 1075.79208604835
total_envstep_count: 20027761
total_train_sample_count: 15032909
total_episode_count: 44561
total_duration: 3999.376267887638
[2023-06-29 13:42:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2266
train_sample_count: 2266
avg_envstep_per_episode: 226.6
avg_sample_per_episode: 226.6
avg_envstep_per_sec: 2800.6256834624305
avg_train_sample_per_sec: 2800.6256834624305
avg_episode_per_sec: 12.359336643700047
collect_time: 0.8091049130130559
reward_mean: 1780.495527829782
reward_std: 805.1566605351492
reward_max: 3574.9765730972194
reward_min: 1120.026715640717
total_envstep_count: 20032353
total_train_sample_count: 15036375
total_episode_count: 44571
total_duration: 4000.185372800651
[2023-06-29 13:42:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 349.57142857142856
avg_sample_per_episode: 349.57142857142856
avg_envstep_per_sec: 2638.722580587471
avg_train_sample_per_sec: 2638.722580587471
avg_episode_per_sec: 7.548450373564486
collect_time: 0.9273426536014305
reward_mean: 2498.214197911027
reward_std: 815.6458355800416
reward_max: 3574.2518710257864
reward_min: 1230.8294867640413
total_envstep_count: 20036729
total_train_sample_count: 15039622
total_episode_count: 44578
total_duration: 4001.1127154542523
[2023-06-29 13:42:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1668
train_sample_count: 1668
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2437.5606892032633
avg_train_sample_per_sec: 2437.5606892032633
avg_episode_per_sec: 8.76820391799735
collect_time: 0.6842906547468155
reward_mean: 2197.445128527408
reward_std: 867.171152147118
reward_max: 3589.8986130603566
reward_min: 1083.269990955245
total_envstep_count: 20041073
total_train_sample_count: 15042890
total_episode_count: 44584
total_duration: 4001.797006108999
[2023-06-29 13:42:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1916
train_sample_count: 1916
avg_envstep_per_episode: 319.3333333333333
avg_sample_per_episode: 319.3333333333333
avg_envstep_per_sec: 2768.5779600459828
avg_train_sample_per_sec: 2768.5779600459828
avg_episode_per_sec: 8.669868350874685
collect_time: 0.6920520309163256
reward_mean: 2886.6870230535174
reward_std: 757.492825965953
reward_max: 3725.429578697124
reward_min: 1782.6857401975792
total_envstep_count: 20045697
total_train_sample_count: 15046406
total_episode_count: 44590
total_duration: 4002.4890581399154
[2023-06-29 13:42:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1852
train_sample_count: 1852
avg_envstep_per_episode: 308.6666666666667
avg_sample_per_episode: 308.6666666666667
avg_envstep_per_sec: 2776.0468241253575
avg_train_sample_per_sec: 2776.0468241253575
avg_episode_per_sec: 8.993672216388848
collect_time: 0.6671357211647556
reward_mean: 2715.151673834251
reward_std: 956.6558088752308
reward_max: 3680.096695029952
reward_min: 1097.8196446770933
total_envstep_count: 20050377
total_train_sample_count: 15049858
total_episode_count: 44596
total_duration: 4003.1561938610803
[2023-06-29 13:42:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1351
train_sample_count: 1351
avg_envstep_per_episode: 337.75
avg_sample_per_episode: 337.75
avg_envstep_per_sec: 2730.366377921718
avg_train_sample_per_sec: 2730.366377921718
avg_episode_per_sec: 8.08398631509021
collect_time: 0.4948053898276996
reward_mean: 3236.124947738349
reward_std: 482.63117646765727
reward_max: 3683.373056871096
reward_min: 2427.6376688460864
total_envstep_count: 20054905
total_train_sample_count: 15053209
total_episode_count: 44600
total_duration: 4003.650999250908
[2023-06-29 13:42:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 177.57142857142858
avg_sample_per_episode: 177.57142857142858
avg_envstep_per_sec: 2539.519622701625
avg_train_sample_per_sec: 2539.519622701625
avg_episode_per_sec: 14.301397714329346
collect_time: 0.48946264832466835
reward_mean: 2751.306107094254
reward_std: 977.2505660975872
reward_max: 3622.4060198052375
reward_min: 1155.0474986422903
total_envstep_count: 20059369
total_train_sample_count: 15056452
total_episode_count: 44607
total_duration: 4004.140461899233
[2023-06-29 13:42:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1954
train_sample_count: 1954
avg_envstep_per_episode: 279.14285714285717
avg_sample_per_episode: 279.14285714285717
avg_envstep_per_sec: 2351.044741136791
avg_train_sample_per_sec: 2351.044741136791
avg_episode_per_sec: 8.422371129968033
collect_time: 0.8311198701625688
reward_mean: 2507.2856197155265
reward_std: 1082.2411441516292
reward_max: 3559.107887206634
reward_min: 758.085232928881
total_envstep_count: 20063945
total_train_sample_count: 15060006
total_episode_count: 44614
total_duration: 4004.9715817693955
[2023-06-29 13:42:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2164
train_sample_count: 2164
avg_envstep_per_episode: 309.14285714285717
avg_sample_per_episode: 309.14285714285717
avg_envstep_per_sec: 2764.1444713518913
avg_train_sample_per_sec: 2764.1444713518913
avg_episode_per_sec: 8.941317606036618
collect_time: 0.7828823791332542
reward_mean: 2636.0654603722114
reward_std: 1043.3608638836117
reward_max: 3580.901030885909
reward_min: 1098.4215995660804
total_envstep_count: 20068745
total_train_sample_count: 15063370
total_episode_count: 44621
total_duration: 4005.7544641485288
[2023-06-29 13:42:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1886
train_sample_count: 1886
avg_envstep_per_episode: 209.55555555555554
avg_sample_per_episode: 209.55555555555554
avg_envstep_per_sec: 2798.5949016462687
avg_train_sample_per_sec: 2798.5949016462687
avg_episode_per_sec: 13.354906741684209
collect_time: 0.6739096104586497
reward_mean: 1829.085136008124
reward_std: 960.8912281334487
reward_max: 3258.348833823209
reward_min: 126.95343398466925
total_envstep_count: 20073729
total_train_sample_count: 15067256
total_episode_count: 44630
total_duration: 4006.4283737589876
[2023-06-29 13:42:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2893
train_sample_count: 2893
avg_envstep_per_episode: 289.3
avg_sample_per_episode: 289.3
avg_envstep_per_sec: 2692.8856090992986
avg_train_sample_per_sec: 2692.8856090992986
avg_episode_per_sec: 9.30828070895022
collect_time: 1.0743122508525844
reward_mean: 2328.5006940999774
reward_std: 901.1960451272354
reward_max: 3606.421294599656
reward_min: 1305.6352567750487
total_envstep_count: 20078649
total_train_sample_count: 15070549
total_episode_count: 44640
total_duration: 4007.50268600984
[2023-06-29 13:42:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1566
train_sample_count: 1566
avg_envstep_per_episode: 223.71428571428572
avg_sample_per_episode: 223.71428571428572
avg_envstep_per_sec: 2702.286355591073
avg_train_sample_per_sec: 2702.286355591073
avg_episode_per_sec: 12.079185497533533
collect_time: 0.5795092724943532
reward_mean: 1792.563592389291
reward_std: 464.37086506691486
reward_max: 2657.892275972036
reward_min: 1110.8368682333953
total_envstep_count: 20083193
total_train_sample_count: 15074115
total_episode_count: 44647
total_duration: 4008.0821952823344
[2023-06-29 13:43:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2107
train_sample_count: 2107
avg_envstep_per_episode: 234.11111111111111
avg_sample_per_episode: 234.11111111111111
avg_envstep_per_sec: 2674.7424448751317
avg_train_sample_per_sec: 2674.7424448751317
avg_episode_per_sec: 11.425098245788412
collect_time: 0.7877393967546523
reward_mean: 2041.092650540767
reward_std: 989.1612243166433
reward_max: 3526.3564709978245
reward_min: 983.2409390779251
total_envstep_count: 20087601
total_train_sample_count: 15077422
total_episode_count: 44656
total_duration: 4008.869934679089
[2023-06-29 13:43:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2176
train_sample_count: 2176
avg_envstep_per_episode: 241.77777777777777
avg_sample_per_episode: 241.77777777777777
avg_envstep_per_sec: 2780.0438605560294
avg_train_sample_per_sec: 2780.0438605560294
avg_episode_per_sec: 11.498343173255636
collect_time: 0.7827214638134464
reward_mean: 1844.449495057356
reward_std: 902.8567200325396
reward_max: 3564.990704737902
reward_min: 1044.980891558444
total_envstep_count: 20092145
total_train_sample_count: 15080798
total_episode_count: 44665
total_duration: 4009.6526561429023
[2023-06-29 13:43:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2161
train_sample_count: 2161
avg_envstep_per_episode: 196.45454545454547
avg_sample_per_episode: 196.45454545454547
avg_envstep_per_sec: 2770.382419712419
avg_train_sample_per_sec: 2770.382419712419
avg_episode_per_sec: 14.101900331715228
collect_time: 0.7800367142902689
reward_mean: 1630.1620605612522
reward_std: 975.264415828347
reward_max: 3611.2701539790364
reward_min: 861.0612586851744
total_envstep_count: 20096609
total_train_sample_count: 15084159
total_episode_count: 44676
total_duration: 4010.4326928571927
[2023-06-29 13:43:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1687
train_sample_count: 1687
avg_envstep_per_episode: 210.875
avg_sample_per_episode: 210.875
avg_envstep_per_sec: 2682.514631315987
avg_train_sample_per_sec: 2682.514631315987
avg_episode_per_sec: 12.720875548623532
collect_time: 0.6288875297475608
reward_mean: 1634.554470041716
reward_std: 770.684222110786
reward_max: 3018.7062750088635
reward_min: 734.967711755667
total_envstep_count: 20100857
total_train_sample_count: 15087446
total_episode_count: 44684
total_duration: 4011.0615803869405
[2023-06-29 13:43:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2055
train_sample_count: 2055
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 2586.296015110591
avg_train_sample_per_sec: 2586.296015110591
avg_episode_per_sec: 12.585382068664677
collect_time: 0.794572619682178
reward_mean: 1896.0430628401748
reward_std: 1078.1995640983287
reward_max: 3713.218269396086
reward_min: 280.50282801894093
total_envstep_count: 20105305
total_train_sample_count: 15090701
total_episode_count: 44694
total_duration: 4011.8561530066227
[2023-06-29 13:43:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2345
train_sample_count: 2345
avg_envstep_per_episode: 293.125
avg_sample_per_episode: 293.125
avg_envstep_per_sec: 2497.78433876769
avg_train_sample_per_sec: 2497.78433876769
avg_episode_per_sec: 8.52122588918615
collect_time: 0.9388320535138482
reward_mean: 2068.4952667073367
reward_std: 1135.7384490227512
reward_max: 3562.544911950895
reward_min: 406.94687067395205
total_envstep_count: 20109889
total_train_sample_count: 15094246
total_episode_count: 44702
total_duration: 4012.7949850601367
[2023-06-29 13:43:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1616
train_sample_count: 1616
avg_envstep_per_episode: 230.85714285714286
avg_sample_per_episode: 230.85714285714286
avg_envstep_per_sec: 2784.698047568774
avg_train_sample_per_sec: 2784.698047568774
avg_episode_per_sec: 12.062429661498403
collect_time: 0.5803142647407948
reward_mean: 1657.4271257119642
reward_std: 849.4928833540271
reward_max: 3320.843193939167
reward_min: 802.515606329855
total_envstep_count: 20114057
total_train_sample_count: 15097462
total_episode_count: 44709
total_duration: 4013.3752993248777
[2023-06-29 13:43:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1712
train_sample_count: 1712
avg_envstep_per_episode: 285.3333333333333
avg_sample_per_episode: 285.3333333333333
avg_envstep_per_sec: 2779.3951097537433
avg_train_sample_per_sec: 2779.3951097537433
avg_episode_per_sec: 9.740870711753773
collect_time: 0.6159613629570229
reward_mean: 2838.592597541616
reward_std: 1085.9841170318077
reward_max: 3632.6598446718776
reward_min: 1159.5483538179392
total_envstep_count: 20118697
total_train_sample_count: 15100774
total_episode_count: 44715
total_duration: 4013.9912606878347
[2023-06-29 13:43:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 205.0
avg_sample_per_episode: 205.0
avg_envstep_per_sec: 2454.451813797233
avg_train_sample_per_sec: 2454.451813797233
avg_episode_per_sec: 11.972935677059674
collect_time: 1.0022604583930224
reward_mean: 1817.609333957388
reward_std: 1033.186925254658
reward_max: 3580.0682214649746
reward_min: 675.6064003112315
total_envstep_count: 20123065
total_train_sample_count: 15104034
total_episode_count: 44727
total_duration: 4014.9935211462275
[2023-06-29 13:43:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 370.44444444444446
avg_sample_per_episode: 370.44444444444446
avg_envstep_per_sec: 2634.0106367170424
avg_train_sample_per_sec: 2634.0106367170424
avg_episode_per_sec: 7.1104066378084525
collect_time: 1.2657503935350105
reward_mean: 2145.6769405374816
reward_std: 986.1981482203981
reward_max: 3719.201226396342
reward_min: 654.0870499449032
total_envstep_count: 20127617
total_train_sample_count: 15107368
total_episode_count: 44736
total_duration: 4016.2592715397627
[2023-06-29 13:43:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 302.625
avg_sample_per_episode: 302.625
avg_envstep_per_sec: 2692.9293104425433
avg_train_sample_per_sec: 2692.9293104425433
avg_episode_per_sec: 8.898568559909272
collect_time: 0.8990209994046017
reward_mean: 1581.7622610968501
reward_std: 724.5784273721168
reward_max: 2700.1087304169223
reward_min: 138.7117579006379
total_envstep_count: 20131921
total_train_sample_count: 15110589
total_episode_count: 44744
total_duration: 4017.158292539167
[2023-06-29 13:43:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2522
train_sample_count: 2522
avg_envstep_per_episode: 252.2
avg_sample_per_episode: 252.2
avg_envstep_per_sec: 2748.339549214271
avg_train_sample_per_sec: 2748.339549214271
avg_episode_per_sec: 10.897460544069274
collect_time: 0.9176449833940716
reward_mean: 1622.6923762800657
reward_std: 900.7431936959521
reward_max: 3560.20582271238
reward_min: 417.3379730277463
total_envstep_count: 20136577
total_train_sample_count: 15113911
total_episode_count: 44754
total_duration: 4018.075937522561
[2023-06-29 13:43:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3075
train_sample_count: 3075
avg_envstep_per_episode: 341.6666666666667
avg_sample_per_episode: 341.6666666666667
avg_envstep_per_sec: 2558.0133488731244
avg_train_sample_per_sec: 2558.0133488731244
avg_episode_per_sec: 7.486868338165242
collect_time: 1.2021047510774807
reward_mean: 2111.2855803021916
reward_std: 688.7027675576736
reward_max: 3178.5605855045897
reward_min: 986.1430486385501
total_envstep_count: 20141449
total_train_sample_count: 15117386
total_episode_count: 44763
total_duration: 4019.2780422736387
[2023-06-29 13:43:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2911
train_sample_count: 2911
avg_envstep_per_episode: 264.6363636363636
avg_sample_per_episode: 264.6363636363636
avg_envstep_per_sec: 2591.150536208897
avg_train_sample_per_sec: 2591.150536208897
avg_episode_per_sec: 9.791362383475734
collect_time: 1.1234391670115291
reward_mean: 1700.0798035559367
reward_std: 686.3832374411068
reward_max: 3516.5383440655623
reward_min: 1037.5005839338232
total_envstep_count: 20145665
total_train_sample_count: 15120697
total_episode_count: 44774
total_duration: 4020.40148144065
[2023-06-29 13:43:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1710
train_sample_count: 1710
avg_envstep_per_episode: 342.0
avg_sample_per_episode: 342.0
avg_envstep_per_sec: 2753.6593735182287
avg_train_sample_per_sec: 2753.6593735182287
avg_episode_per_sec: 8.05163559508254
collect_time: 0.6209918396025899
reward_mean: 1831.573275912228
reward_std: 1026.0817600848989
reward_max: 3577.3212666799877
reward_min: 673.4090911468338
total_envstep_count: 20149457
total_train_sample_count: 15124007
total_episode_count: 44779
total_duration: 4021.0224732802526
[2023-06-29 13:43:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 255.6
avg_sample_per_episode: 255.6
avg_envstep_per_sec: 2792.4682925547113
avg_train_sample_per_sec: 2792.4682925547113
avg_episode_per_sec: 10.925149814376804
collect_time: 0.9153192560197787
reward_mean: 1846.9889175259127
reward_std: 1035.7016698618481
reward_max: 3733.9691409494717
reward_min: 636.4553974103599
total_envstep_count: 20153241
total_train_sample_count: 15127363
total_episode_count: 44789
total_duration: 4021.9377925362724
[2023-06-29 13:43:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 266.09090909090907
avg_sample_per_episode: 266.09090909090907
avg_envstep_per_sec: 2602.495643788579
avg_train_sample_per_sec: 2602.495643788579
avg_episode_per_sec: 9.780475600162067
collect_time: 1.124689682761207
reward_mean: 1455.833113824604
reward_std: 803.2594888071961
reward_max: 3498.308266117137
reward_min: 135.90410940549165
total_envstep_count: 20157625
total_train_sample_count: 15130690
total_episode_count: 44800
total_duration: 4023.0624822190334
[2023-06-29 13:43:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1923
train_sample_count: 1923
avg_envstep_per_episode: 274.7142857142857
avg_sample_per_episode: 274.7142857142857
avg_envstep_per_sec: 2653.6116724735534
avg_train_sample_per_sec: 2653.6116724735534
avg_episode_per_sec: 9.659532869118499
collect_time: 0.7246727243280037
reward_mean: 1573.760137909221
reward_std: 740.3871317711988
reward_max: 2995.506956530728
reward_min: 906.3282548374335
total_envstep_count: 20162673
total_train_sample_count: 15134213
total_episode_count: 44807
total_duration: 4023.7871549433617
[2023-06-29 13:43:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2212
train_sample_count: 2212
avg_envstep_per_episode: 221.2
avg_sample_per_episode: 221.2
avg_envstep_per_sec: 2722.710016622627
avg_train_sample_per_sec: 2722.710016622627
avg_episode_per_sec: 12.30881562668457
collect_time: 0.8124258501622825
reward_mean: 2095.781895380578
reward_std: 922.4147425217004
reward_max: 3626.667006968354
reward_min: 919.3250130677869
total_envstep_count: 20167297
total_train_sample_count: 15137625
total_episode_count: 44817
total_duration: 4024.5995807935237
[2023-06-29 13:44:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2750.4423101387697
avg_train_sample_per_sec: 2750.4423101387697
avg_episode_per_sec: 10.224692602746355
collect_time: 1.1736294152038171
reward_mean: 1772.6667703605217
reward_std: 875.3085105385135
reward_max: 3550.2026999794816
reward_min: 926.1528303680429
total_envstep_count: 20171889
total_train_sample_count: 15140853
total_episode_count: 44829
total_duration: 4025.7732102087275
[2023-06-29 13:44:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2966
train_sample_count: 2966
avg_envstep_per_episode: 247.16666666666666
avg_sample_per_episode: 247.16666666666666
avg_envstep_per_sec: 2602.4289459056313
avg_train_sample_per_sec: 2602.4289459056313
avg_episode_per_sec: 10.529044959833977
collect_time: 1.1397045074626804
reward_mean: 1237.1638905250704
reward_std: 435.7954933335253
reward_max: 2123.103597672763
reward_min: 695.2775366534931
total_envstep_count: 20176833
total_train_sample_count: 15144219
total_episode_count: 44841
total_duration: 4026.9129147161902
[2023-06-29 13:44:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1951
train_sample_count: 1951
avg_envstep_per_episode: 216.77777777777777
avg_sample_per_episode: 216.77777777777777
avg_envstep_per_sec: 2571.311063247428
avg_train_sample_per_sec: 2571.311063247428
avg_episode_per_sec: 11.86150669873237
collect_time: 0.7587568956110629
reward_mean: 1615.7868764943817
reward_std: 767.6209845859823
reward_max: 3631.8484338039275
reward_min: 778.1424141655788
total_envstep_count: 20181249
total_train_sample_count: 15147770
total_episode_count: 44850
total_duration: 4027.6716716118012
[2023-06-29 13:44:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 269.1666666666667
avg_sample_per_episode: 269.1666666666667
avg_envstep_per_sec: 2742.8163730903834
avg_train_sample_per_sec: 2742.8163730903834
avg_episode_per_sec: 10.190029869066441
collect_time: 0.5888108354043216
reward_mean: 2288.1868490479455
reward_std: 1130.3166123056055
reward_max: 3570.016898591373
reward_min: 1082.9159799020515
total_envstep_count: 20185129
total_train_sample_count: 15150985
total_episode_count: 44856
total_duration: 4028.2604824472055
[2023-06-29 13:44:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2875
train_sample_count: 2875
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 2765.838559538555
avg_train_sample_per_sec: 2765.838559538555
avg_episode_per_sec: 9.620308033177583
collect_time: 1.0394677556594834
reward_mean: 2225.810751557511
reward_std: 875.8709285788719
reward_max: 3725.2222584506753
reward_min: 977.107882073867
total_envstep_count: 20189841
total_train_sample_count: 15154260
total_episode_count: 44866
total_duration: 4029.299950202865
[2023-06-29 13:44:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2091
train_sample_count: 2091
avg_envstep_per_episode: 209.1
avg_sample_per_episode: 209.1
avg_envstep_per_sec: 2748.1618242634872
avg_train_sample_per_sec: 2748.1618242634872
avg_episode_per_sec: 13.142811211207496
collect_time: 0.7608722243132069
reward_mean: 1325.384126595471
reward_std: 469.2569599891087
reward_max: 2388.0717241724788
reward_min: 799.2036891741873
total_envstep_count: 20193801
total_train_sample_count: 15157551
total_episode_count: 44876
total_duration: 4030.060822427178
[2023-06-29 13:44:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 223.77777777777777
avg_sample_per_episode: 223.77777777777777
avg_envstep_per_sec: 2531.556131256127
avg_train_sample_per_sec: 2531.556131256127
avg_episode_per_sec: 11.312812900350123
collect_time: 0.7955581055991351
reward_mean: 1721.8369784446465
reward_std: 832.7637351728886
reward_max: 3664.3741624897602
reward_min: 944.4703501630913
total_envstep_count: 20198401
total_train_sample_count: 15160765
total_episode_count: 44885
total_duration: 4030.856380532777
[2023-06-29 13:44:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2136
train_sample_count: 2136
avg_envstep_per_episode: 213.6
avg_sample_per_episode: 213.6
avg_envstep_per_sec: 2677.8568704575828
avg_train_sample_per_sec: 2677.8568704575828
avg_episode_per_sec: 12.536783101393178
collect_time: 0.7976527885282412
reward_mean: 1705.0741670755992
reward_std: 1002.8817877724592
reward_max: 3587.9328066005723
reward_min: 839.1949049916362
total_envstep_count: 20202377
total_train_sample_count: 15164101
total_episode_count: 44895
total_duration: 4031.6540333213056
[2023-06-29 13:44:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2840
train_sample_count: 2840
avg_envstep_per_episode: 236.66666666666666
avg_sample_per_episode: 236.66666666666666
avg_envstep_per_sec: 2788.2815253392605
avg_train_sample_per_sec: 2788.2815253392605
avg_episode_per_sec: 11.781471233827862
collect_time: 1.0185485124764964
reward_mean: 1487.7335286845646
reward_std: 519.7773934524585
reward_max: 2577.334823197873
reward_min: 952.8800317935463
total_envstep_count: 20206849
total_train_sample_count: 15167341
total_episode_count: 44907
total_duration: 4032.6725818337823
[2023-06-29 13:44:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1864
train_sample_count: 1864
avg_envstep_per_episode: 266.2857142857143
avg_sample_per_episode: 266.2857142857143
avg_envstep_per_sec: 2516.151088405426
avg_train_sample_per_sec: 2516.151088405426
avg_episode_per_sec: 9.449065246157716
collect_time: 0.7408140189154073
reward_mean: 1843.8823254617066
reward_std: 844.3597623484411
reward_max: 3624.518670379463
reward_min: 1065.7763235512891
total_envstep_count: 20211457
total_train_sample_count: 15170805
total_episode_count: 44914
total_duration: 4033.4133958526977
[2023-06-29 13:44:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2820
train_sample_count: 2820
avg_envstep_per_episode: 256.3636363636364
avg_sample_per_episode: 256.3636363636364
avg_envstep_per_sec: 2578.7883557549776
avg_train_sample_per_sec: 2578.7883557549776
avg_episode_per_sec: 10.059103515356295
collect_time: 1.0935368130179122
reward_mean: 1845.4104210048126
reward_std: 956.2117402131138
reward_max: 3616.4915131669095
reward_min: 871.0064241498815
total_envstep_count: 20215465
total_train_sample_count: 15174025
total_episode_count: 44925
total_duration: 4034.506932665716
[2023-06-29 13:44:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 245.7
avg_sample_per_episode: 245.7
avg_envstep_per_sec: 2679.960957271515
avg_train_sample_per_sec: 2679.960957271515
avg_episode_per_sec: 10.90745200354707
collect_time: 0.9168044009497389
reward_mean: 1406.4445680070057
reward_std: 676.0977196403261
reward_max: 3258.0476489114226
reward_min: 862.4005792634556
total_envstep_count: 20219705
total_train_sample_count: 15177282
total_episode_count: 44935
total_duration: 4035.4237370666656
[2023-06-29 13:44:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2144
train_sample_count: 2144
avg_envstep_per_episode: 238.22222222222223
avg_sample_per_episode: 238.22222222222223
avg_envstep_per_sec: 2743.254775559908
avg_train_sample_per_sec: 2743.254775559908
avg_episode_per_sec: 11.515528442182449
collect_time: 0.7815533646751429
reward_mean: 1485.0279463758359
reward_std: 578.5082228892234
reward_max: 2358.5065200930926
reward_min: 625.8128364153889
total_envstep_count: 20224129
total_train_sample_count: 15180626
total_episode_count: 44944
total_duration: 4036.205290431341
[2023-06-29 13:44:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2254
train_sample_count: 2254
avg_envstep_per_episode: 250.44444444444446
avg_sample_per_episode: 250.44444444444446
avg_envstep_per_sec: 2572.8633607965353
avg_train_sample_per_sec: 2572.8633607965353
avg_episode_per_sec: 10.273189994307373
collect_time: 0.8760667334087193
reward_mean: 1931.4097985747774
reward_std: 900.7366165735044
reward_max: 3620.5391250873467
reward_min: 896.8189058940773
total_envstep_count: 20229057
total_train_sample_count: 15184080
total_episode_count: 44953
total_duration: 4037.0813571647495
[2023-06-29 13:44:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2903
train_sample_count: 2903
avg_envstep_per_episode: 263.90909090909093
avg_sample_per_episode: 263.90909090909093
avg_envstep_per_sec: 2531.7134761982074
avg_train_sample_per_sec: 2531.7134761982074
avg_episode_per_sec: 9.593127191932581
collect_time: 1.1466542431805282
reward_mean: 1829.471136872212
reward_std: 871.9098019599018
reward_max: 3602.8941293207895
reward_min: 852.1353388031073
total_envstep_count: 20233369
total_train_sample_count: 15187383
total_episode_count: 44964
total_duration: 4038.22801140793
[2023-06-29 13:44:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2326
train_sample_count: 2326
avg_envstep_per_episode: 258.44444444444446
avg_sample_per_episode: 258.44444444444446
avg_envstep_per_sec: 2475.8131186582905
avg_train_sample_per_sec: 2475.8131186582905
avg_episode_per_sec: 9.579672428170513
collect_time: 0.9394893267471343
reward_mean: 1620.0018413228395
reward_std: 779.747577147814
reward_max: 3622.518323987806
reward_min: 962.9993740188759
total_envstep_count: 20237617
total_train_sample_count: 15190909
total_episode_count: 44973
total_duration: 4039.167500734677
[2023-06-29 13:44:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2659
train_sample_count: 2659
avg_envstep_per_episode: 332.375
avg_sample_per_episode: 332.375
avg_envstep_per_sec: 2708.743731303512
avg_train_sample_per_sec: 2708.743731303512
avg_episode_per_sec: 8.149661470638623
collect_time: 0.9816358665721492
reward_mean: 2061.090273897086
reward_std: 939.4442141448006
reward_max: 3579.0157868860333
reward_min: 1053.1781236624117
total_envstep_count: 20242409
total_train_sample_count: 15194368
total_episode_count: 44981
total_duration: 4040.149136601249
[2023-06-29 13:44:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2659
train_sample_count: 2659
avg_envstep_per_episode: 265.9
avg_sample_per_episode: 265.9
avg_envstep_per_sec: 2717.787980673266
avg_train_sample_per_sec: 2717.787980673266
avg_episode_per_sec: 10.221090562893064
collect_time: 0.9783691807119176
reward_mean: 1684.4341537703772
reward_std: 997.1978886647975
reward_max: 3655.7583835478877
reward_min: 909.8038612400712
total_envstep_count: 20247273
total_train_sample_count: 15197827
total_episode_count: 44991
total_duration: 4041.127505781961
[2023-06-29 13:44:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 187.72727272727272
avg_sample_per_episode: 187.72727272727272
avg_envstep_per_sec: 2505.6634308858615
avg_train_sample_per_sec: 2505.6634308858615
avg_episode_per_sec: 13.347359680263668
collect_time: 0.8241330318134277
reward_mean: 1605.268325188189
reward_std: 960.8335599694095
reward_max: 3641.0426802754782
reward_min: 461.49413778262385
total_envstep_count: 20251481
total_train_sample_count: 15201092
total_episode_count: 45002
total_duration: 4041.9516388137745
[2023-06-29 13:45:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 231.83333333333334
avg_sample_per_episode: 231.83333333333334
avg_envstep_per_sec: 2650.329107651006
avg_train_sample_per_sec: 2650.329107651006
avg_episode_per_sec: 11.432045036596719
collect_time: 0.5248404796160757
reward_mean: 1721.0877094126856
reward_std: 633.6150030973957
reward_max: 2636.0591103588968
reward_min: 968.9500027129253
total_envstep_count: 20255985
total_train_sample_count: 15204483
total_episode_count: 45008
total_duration: 4042.4764792933906
[2023-06-29 13:45:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2054
train_sample_count: 2054
avg_envstep_per_episode: 228.22222222222223
avg_sample_per_episode: 228.22222222222223
avg_envstep_per_sec: 2674.8033257650486
avg_train_sample_per_sec: 2674.8033257650486
avg_episode_per_sec: 11.720170366059122
collect_time: 0.7679069261709228
reward_mean: 2216.234553957632
reward_std: 1163.818500948825
reward_max: 3598.4409371955185
reward_min: 636.8223748435895
total_envstep_count: 20260785
total_train_sample_count: 15207737
total_episode_count: 45017
total_duration: 4043.2443862195614
[2023-06-29 13:45:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1749
train_sample_count: 1749
avg_envstep_per_episode: 218.625
avg_sample_per_episode: 218.625
avg_envstep_per_sec: 2412.4023699055283
avg_train_sample_per_sec: 2412.4023699055283
avg_episode_per_sec: 11.03443050843009
collect_time: 0.7250034330170602
reward_mean: 1984.0073495972306
reward_std: 964.5264151007824
reward_max: 3589.9866352984163
reward_min: 894.8226411448876
total_envstep_count: 20265089
total_train_sample_count: 15211086
total_episode_count: 45025
total_duration: 4043.9693896525787
[2023-06-29 13:45:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1782
train_sample_count: 1782
avg_envstep_per_episode: 222.75
avg_sample_per_episode: 222.75
avg_envstep_per_sec: 2342.3195128539837
avg_train_sample_per_sec: 2342.3195128539837
avg_episode_per_sec: 10.515463581836068
collect_time: 0.7607843380123379
reward_mean: 1997.2608814482592
reward_std: 1255.4491097706873
reward_max: 3652.2395597230256
reward_min: 753.2693557753873
total_envstep_count: 20269697
total_train_sample_count: 15214468
total_episode_count: 45033
total_duration: 4044.730173990591
[2023-06-29 13:45:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2433
train_sample_count: 2433
avg_envstep_per_episode: 304.125
avg_sample_per_episode: 304.125
avg_envstep_per_sec: 2418.5985778222034
avg_train_sample_per_sec: 2418.5985778222034
avg_episode_per_sec: 7.9526463717951605
collect_time: 1.00595444912184
reward_mean: 2566.852574688808
reward_std: 970.8619965262346
reward_max: 3722.558855015185
reward_min: 1048.4695867754333
total_envstep_count: 20274065
total_train_sample_count: 15217701
total_episode_count: 45041
total_duration: 4045.736128439713
[2023-06-29 13:45:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1723
train_sample_count: 1723
avg_envstep_per_episode: 246.14285714285714
avg_sample_per_episode: 246.14285714285714
avg_envstep_per_sec: 2604.4040075414628
avg_train_sample_per_sec: 2604.4040075414628
avg_episode_per_sec: 10.58086364062115
collect_time: 0.6615717050852254
reward_mean: 1782.7111901367841
reward_std: 1116.2952769229883
reward_max: 3556.4344978957024
reward_min: 948.4215740349852
total_envstep_count: 20278417
total_train_sample_count: 15221024
total_episode_count: 45048
total_duration: 4046.3977001447984
[2023-06-29 13:45:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2102
train_sample_count: 2102
avg_envstep_per_episode: 350.3333333333333
avg_sample_per_episode: 350.3333333333333
avg_envstep_per_sec: 2668.9362892994036
avg_train_sample_per_sec: 2668.9362892994036
avg_episode_per_sec: 7.61827675347118
collect_time: 0.7875796842463315
reward_mean: 3043.7140539403194
reward_std: 937.8370837430051
reward_max: 3673.6559537395697
reward_min: 1044.4368043319014
total_envstep_count: 20283049
total_train_sample_count: 15224326
total_episode_count: 45054
total_duration: 4047.1852798290447
[2023-06-29 13:45:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2040
train_sample_count: 2040
avg_envstep_per_episode: 340.0
avg_sample_per_episode: 340.0
avg_envstep_per_sec: 2550.5289886037094
avg_train_sample_per_sec: 2550.5289886037094
avg_episode_per_sec: 7.50155584883444
collect_time: 0.7998340772110968
reward_mean: 2546.691843657692
reward_std: 792.4645224993145
reward_max: 3364.587365708154
reward_min: 1183.4237344685876
total_envstep_count: 20287073
total_train_sample_count: 15227566
total_episode_count: 45060
total_duration: 4047.9851139062557
[2023-06-29 13:45:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 282.5
avg_sample_per_episode: 282.5
avg_envstep_per_sec: 2721.678171142509
avg_train_sample_per_sec: 2721.678171142509
avg_episode_per_sec: 9.634259012893837
collect_time: 0.4151850178251043
reward_mean: 2683.422978866595
reward_std: 973.4360681277169
reward_max: 3592.2566213754135
reward_min: 1271.8396044143408
total_envstep_count: 20291329
total_train_sample_count: 15231096
total_episode_count: 45064
total_duration: 4048.4002989240807
[2023-06-29 13:45:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2861
train_sample_count: 2861
avg_envstep_per_episode: 286.1
avg_sample_per_episode: 286.1
avg_envstep_per_sec: 2638.349621448423
avg_train_sample_per_sec: 2638.349621448423
avg_episode_per_sec: 9.221774279791761
collect_time: 1.0843900204664099
reward_mean: 2501.303627312051
reward_std: 1109.9358368477053
reward_max: 3606.1961273093507
reward_min: 705.340036791141
total_envstep_count: 20296137
total_train_sample_count: 15234357
total_episode_count: 45074
total_duration: 4049.484688944547
[2023-06-29 13:45:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1273
train_sample_count: 1273
avg_envstep_per_episode: 318.25
avg_sample_per_episode: 318.25
avg_envstep_per_sec: 2739.905385560133
avg_train_sample_per_sec: 2739.905385560133
avg_episode_per_sec: 8.609286364682271
collect_time: 0.4646145836673678
reward_mean: 1786.4466466715157
reward_std: 1119.7015782881792
reward_max: 3609.4039068445963
reward_min: 712.4875012642891
total_envstep_count: 20300057
total_train_sample_count: 15237630
total_episode_count: 45078
total_duration: 4049.9493035282144
[2023-06-29 13:45:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2262
train_sample_count: 2262
avg_envstep_per_episode: 282.75
avg_sample_per_episode: 282.75
avg_envstep_per_sec: 2609.754495521218
avg_train_sample_per_sec: 2609.754495521218
avg_episode_per_sec: 9.22990095675055
collect_time: 0.866748195618391
reward_mean: 2686.019802502444
reward_std: 1196.2803164220152
reward_max: 3668.8980895487143
reward_min: 723.8507746934266
total_envstep_count: 20304969
total_train_sample_count: 15241092
total_episode_count: 45086
total_duration: 4050.816051723833
[2023-06-29 13:45:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1551
train_sample_count: 1551
avg_envstep_per_episode: 193.875
avg_sample_per_episode: 193.875
avg_envstep_per_sec: 2560.482711743614
avg_train_sample_per_sec: 2560.482711743614
avg_episode_per_sec: 13.206874077336499
collect_time: 0.6057451561326163
reward_mean: 1630.5398888049035
reward_std: 1226.5273826207813
reward_max: 3690.5389068781283
reward_min: 22.90435171045601
total_envstep_count: 20309305
total_train_sample_count: 15244643
total_episode_count: 45094
total_duration: 4051.4217968799658
[2023-06-29 13:45:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2675
train_sample_count: 2675
avg_envstep_per_episode: 243.1818181818182
avg_sample_per_episode: 243.1818181818182
avg_envstep_per_sec: 2519.377052663639
avg_train_sample_per_sec: 2519.377052663639
avg_episode_per_sec: 10.360055169831785
collect_time: 1.061770407558419
reward_mean: 2077.5044734272774
reward_std: 1170.38078339951
reward_max: 3623.4991385733206
reward_min: 278.61136219270014
total_envstep_count: 20313273
total_train_sample_count: 15248118
total_episode_count: 45105
total_duration: 4052.4835672875242
[2023-06-29 13:45:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2182
train_sample_count: 2182
avg_envstep_per_episode: 272.75
avg_sample_per_episode: 272.75
avg_envstep_per_sec: 2576.468348431428
avg_train_sample_per_sec: 2576.468348431428
avg_episode_per_sec: 9.44626342229671
collect_time: 0.8468957134010271
reward_mean: 1529.638749748658
reward_std: 970.9866061283572
reward_max: 3642.547168784926
reward_min: 804.868909315782
total_envstep_count: 20317905
total_train_sample_count: 15251500
total_episode_count: 45113
total_duration: 4053.330463000925
[2023-06-29 13:45:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2096
train_sample_count: 2096
avg_envstep_per_episode: 232.88888888888889
avg_sample_per_episode: 232.88888888888889
avg_envstep_per_sec: 2669.7727647505526
avg_train_sample_per_sec: 2669.7727647505526
avg_episode_per_sec: 11.463718932612105
collect_time: 0.7850855427375062
reward_mean: 1726.6603245691178
reward_std: 1071.8919296164054
reward_max: 3701.39408106774
reward_min: 739.3265784949048
total_envstep_count: 20322241
total_train_sample_count: 15254796
total_episode_count: 45122
total_duration: 4054.1155485436625
[2023-06-29 13:45:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3290
train_sample_count: 3290
avg_envstep_per_episode: 274.1666666666667
avg_sample_per_episode: 274.1666666666667
avg_envstep_per_sec: 2585.3654023661975
avg_train_sample_per_sec: 2585.3654023661975
avg_episode_per_sec: 9.429904203159383
collect_time: 1.2725473919427024
reward_mean: 1849.1568069451605
reward_std: 1002.2812536544014
reward_max: 3745.56608847602
reward_min: 777.1662947604531
total_envstep_count: 20326609
total_train_sample_count: 15258086
total_episode_count: 45134
total_duration: 4055.388095935605
[2023-06-29 13:45:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2028
train_sample_count: 2028
avg_envstep_per_episode: 253.5
avg_sample_per_episode: 253.5
avg_envstep_per_sec: 2692.7882580021387
avg_train_sample_per_sec: 2692.7882580021387
avg_episode_per_sec: 10.622438887582401
collect_time: 0.7531227135937657
reward_mean: 1435.5303950028583
reward_std: 537.838356409831
reward_max: 2523.924609193615
reward_min: 740.5478639472411
total_envstep_count: 20330585
total_train_sample_count: 15261314
total_episode_count: 45142
total_duration: 4056.141218649199
[2023-06-29 13:45:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2319
train_sample_count: 2319
avg_envstep_per_episode: 231.9
avg_sample_per_episode: 231.9
avg_envstep_per_sec: 2655.367119502954
avg_train_sample_per_sec: 2655.367119502954
avg_episode_per_sec: 11.450483482117095
collect_time: 0.8733255687952041
reward_mean: 1518.1005828831728
reward_std: 874.4055529531903
reward_max: 3730.8794651491808
reward_min: 723.2193327948753
total_envstep_count: 20334889
total_train_sample_count: 15264833
total_episode_count: 45152
total_duration: 4057.014544217994
[2023-06-29 13:45:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2890
train_sample_count: 2890
avg_envstep_per_episode: 262.72727272727275
avg_sample_per_episode: 262.72727272727275
avg_envstep_per_sec: 2578.739594660907
avg_train_sample_per_sec: 2578.739594660907
avg_episode_per_sec: 9.815271813588227
collect_time: 1.1207025346737356
reward_mean: 1712.4832497175498
reward_std: 857.4805671115453
reward_max: 3550.8023157360494
reward_min: 858.5328147959077
total_envstep_count: 20339089
total_train_sample_count: 15268123
total_episode_count: 45163
total_duration: 4058.135246752668
[2023-06-29 13:46:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3392
train_sample_count: 3392
avg_envstep_per_episode: 226.13333333333333
avg_sample_per_episode: 226.13333333333333
avg_envstep_per_sec: 2631.857566708147
avg_train_sample_per_sec: 2631.857566708147
avg_episode_per_sec: 11.638521079192866
collect_time: 1.2888235453572123
reward_mean: 1151.965432336998
reward_std: 473.8171860084923
reward_max: 2493.020640019873
reward_min: 664.2845711492974
total_envstep_count: 20343673
total_train_sample_count: 15271515
total_episode_count: 45178
total_duration: 4059.424070298025
[2023-06-29 13:46:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2119
train_sample_count: 2119
avg_envstep_per_episode: 192.63636363636363
avg_sample_per_episode: 192.63636363636363
avg_envstep_per_sec: 2801.5449599041717
avg_train_sample_per_sec: 2801.5449599041717
avg_episode_per_sec: 14.543178177888574
collect_time: 0.7563683718545361
reward_mean: 1104.8472551474372
reward_std: 355.72592467142374
reward_max: 1789.9494980145826
reward_min: 708.6787119126648
total_envstep_count: 20348209
total_train_sample_count: 15274834
total_episode_count: 45189
total_duration: 4060.1804386698795
[2023-06-29 13:46:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2884
train_sample_count: 2884
avg_envstep_per_episode: 262.1818181818182
avg_sample_per_episode: 262.1818181818182
avg_envstep_per_sec: 2688.008523873592
avg_train_sample_per_sec: 2688.008523873592
avg_episode_per_sec: 10.252459695773062
collect_time: 1.0729132643686605
reward_mean: 1747.0975395717883
reward_std: 954.8461449422969
reward_max: 3610.428481325827
reward_min: 894.2337341773866
total_envstep_count: 20352681
total_train_sample_count: 15278118
total_episode_count: 45200
total_duration: 4061.2533519342483
[2023-06-29 13:46:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1671
train_sample_count: 1671
avg_envstep_per_episode: 167.1
avg_sample_per_episode: 167.1
avg_envstep_per_sec: 2603.505626957104
avg_train_sample_per_sec: 2603.505626957104
avg_episode_per_sec: 15.580524398307027
collect_time: 0.641826920863241
reward_mean: 1310.827101874233
reward_std: 652.2443742727083
reward_max: 3124.325244124269
reward_min: 724.9609227285767
total_envstep_count: 20356593
total_train_sample_count: 15281389
total_episode_count: 45210
total_duration: 4061.8951788551117
[2023-06-29 13:46:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2874
train_sample_count: 2874
avg_envstep_per_episode: 221.07692307692307
avg_sample_per_episode: 221.07692307692307
avg_envstep_per_sec: 2510.8004309249936
avg_train_sample_per_sec: 2510.8004309249936
avg_episode_per_sec: 11.35713486500519
collect_time: 1.1446548935556784
reward_mean: 1454.5040233606342
reward_std: 874.7431785101892
reward_max: 3742.1646528705287
reward_min: 690.2387829894535
total_envstep_count: 20361425
total_train_sample_count: 15284663
total_episode_count: 45223
total_duration: 4063.039833748667
[2023-06-29 13:46:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2577
train_sample_count: 2577
avg_envstep_per_episode: 214.75
avg_sample_per_episode: 214.75
avg_envstep_per_sec: 2708.958052021231
avg_train_sample_per_sec: 2708.958052021231
avg_episode_per_sec: 12.614472884848574
collect_time: 0.9512882630564273
reward_mean: 1314.8182838462671
reward_std: 569.7102401809447
reward_max: 2822.584654323385
reward_min: 713.2643626296438
total_envstep_count: 20365897
total_train_sample_count: 15288040
total_episode_count: 45235
total_duration: 4063.9911220117237
[2023-06-29 13:46:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2906
train_sample_count: 2906
avg_envstep_per_episode: 223.53846153846155
avg_sample_per_episode: 223.53846153846155
avg_envstep_per_sec: 2602.6738738512345
avg_train_sample_per_sec: 2602.6738738512345
avg_episode_per_sec: 11.643069635260169
collect_time: 1.1165440392652526
reward_mean: 1457.1136226833912
reward_std: 714.4884396083902
reward_max: 3216.85207445389
reward_min: 670.6608972818972
total_envstep_count: 20370497
total_train_sample_count: 15291346
total_episode_count: 45248
total_duration: 4065.107666050989
[2023-06-29 13:46:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3298
train_sample_count: 3298
avg_envstep_per_episode: 299.8181818181818
avg_sample_per_episode: 299.8181818181818
avg_envstep_per_sec: 2696.746975889718
avg_train_sample_per_sec: 2696.746975889718
avg_episode_per_sec: 8.994607863792268
collect_time: 1.2229549266155808
reward_mean: 1706.102151247677
reward_std: 831.2852012829031
reward_max: 3726.2691034934983
reward_min: 654.4452845347032
total_envstep_count: 20375033
total_train_sample_count: 15294644
total_episode_count: 45259
total_duration: 4066.3306209776047
[2023-06-29 13:46:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 236.91666666666666
avg_sample_per_episode: 236.91666666666666
avg_envstep_per_sec: 2554.2005646868297
avg_train_sample_per_sec: 2554.2005646868297
avg_episode_per_sec: 10.78100836308194
collect_time: 1.1130684251291676
reward_mean: 1222.2756651977106
reward_std: 552.3189538598587
reward_max: 2259.0990283268056
reward_min: 687.9439433855161
total_envstep_count: 20379073
total_train_sample_count: 15297887
total_episode_count: 45271
total_duration: 4067.443689402734
[2023-06-29 13:46:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1839
train_sample_count: 1839
avg_envstep_per_episode: 229.875
avg_sample_per_episode: 229.875
avg_envstep_per_sec: 2756.5036874827606
avg_train_sample_per_sec: 2756.5036874827606
avg_episode_per_sec: 11.99131566061016
collect_time: 0.6671494793752207
reward_mean: 1331.3985721644726
reward_std: 563.801698450259
reward_max: 2574.3429843471167
reward_min: 869.779212611889
total_envstep_count: 20383289
total_train_sample_count: 15301326
total_episode_count: 45279
total_duration: 4068.1108388821094
[2023-06-29 13:46:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2540
train_sample_count: 2540
avg_envstep_per_episode: 230.9090909090909
avg_sample_per_episode: 230.9090909090909
avg_envstep_per_sec: 2693.9180280776163
avg_train_sample_per_sec: 2693.9180280776163
avg_episode_per_sec: 11.666574137344007
collect_time: 0.9428646207964048
reward_mean: 1648.801933638186
reward_std: 1137.1217577028374
reward_max: 3776.554623924308
reward_min: 566.0287066734154
total_envstep_count: 20387833
total_train_sample_count: 15304666
total_episode_count: 45290
total_duration: 4069.053703502906
[2023-06-29 13:46:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2166
train_sample_count: 2166
avg_envstep_per_episode: 216.6
avg_sample_per_episode: 216.6
avg_envstep_per_sec: 2508.137731255265
avg_train_sample_per_sec: 2508.137731255265
avg_episode_per_sec: 11.579583246792543
collect_time: 0.8635889381226154
reward_mean: 1655.601073827503
reward_std: 846.46547151903
reward_max: 3676.3641786757116
reward_min: 778.5599609055458
total_envstep_count: 20392729
total_train_sample_count: 15308032
total_episode_count: 45300
total_duration: 4069.9172924410286
[2023-06-29 13:46:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3386
train_sample_count: 3386
avg_envstep_per_episode: 241.85714285714286
avg_sample_per_episode: 241.85714285714286
avg_envstep_per_sec: 2535.206705176629
avg_train_sample_per_sec: 2535.206705176629
avg_episode_per_sec: 10.482248633335146
collect_time: 1.335591292452067
reward_mean: 1609.024915945385
reward_std: 1056.5018603886074
reward_max: 3695.8290326862843
reward_min: 636.1311379321055
total_envstep_count: 20397297
total_train_sample_count: 15311418
total_episode_count: 45314
total_duration: 4071.2528837334808
[2023-06-29 13:46:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2410
train_sample_count: 2410
avg_envstep_per_episode: 219.0909090909091
avg_sample_per_episode: 219.0909090909091
avg_envstep_per_sec: 2672.091792051504
avg_train_sample_per_sec: 2672.091792051504
avg_episode_per_sec: 12.196269590276575
collect_time: 0.9019151240121573
reward_mean: 1126.4631825977415
reward_std: 689.5509745409008
reward_max: 3245.1328593726103
reward_min: 672.1796358874242
total_envstep_count: 20401353
total_train_sample_count: 15314628
total_episode_count: 45325
total_duration: 4072.154798857493
[2023-06-29 13:46:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1257
train_sample_count: 1257
avg_envstep_per_episode: 314.25
avg_sample_per_episode: 314.25
avg_envstep_per_sec: 2784.03332539497
avg_train_sample_per_sec: 2784.03332539497
avg_episode_per_sec: 8.859294591551217
collect_time: 0.4515032160477712
reward_mean: 2283.1085331760532
reward_std: 1217.1125689891287
reward_max: 3562.4987932894323
reward_min: 894.5660865846849
total_envstep_count: 20405841
total_train_sample_count: 15317885
total_episode_count: 45329
total_duration: 4072.606302073541
[2023-06-29 13:46:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2506
train_sample_count: 2506
avg_envstep_per_episode: 227.8181818181818
avg_sample_per_episode: 227.8181818181818
avg_envstep_per_sec: 2607.8540817094117
avg_train_sample_per_sec: 2607.8540817094117
avg_episode_per_sec: 11.447084955627904
collect_time: 0.9609433355862274
reward_mean: 2095.2684533188385
reward_std: 1188.3562606473645
reward_max: 3612.2608238715757
reward_min: 688.7929466545748
total_envstep_count: 20409985
total_train_sample_count: 15321191
total_episode_count: 45340
total_duration: 4073.5672454091273
[2023-06-29 13:46:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2275
train_sample_count: 2275
avg_envstep_per_episode: 227.5
avg_sample_per_episode: 227.5
avg_envstep_per_sec: 2478.6482408908764
avg_train_sample_per_sec: 2478.6482408908764
avg_episode_per_sec: 10.89515710281704
collect_time: 0.9178389908131211
reward_mean: 1430.992446543843
reward_std: 917.7328243518128
reward_max: 3689.2453765033342
reward_min: 782.9248230886508
total_envstep_count: 20414153
total_train_sample_count: 15324666
total_episode_count: 45350
total_duration: 4074.48508439994
[2023-06-29 13:46:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3004
train_sample_count: 3004
avg_envstep_per_episode: 273.09090909090907
avg_sample_per_episode: 273.09090909090907
avg_envstep_per_sec: 2500.9128973373795
avg_train_sample_per_sec: 2500.9128973373795
avg_episode_per_sec: 9.157803552167502
collect_time: 1.2011613851878795
reward_mean: 1647.854642478304
reward_std: 917.6709404147948
reward_max: 3398.7127338199602
reward_min: 284.0684696874577
total_envstep_count: 20419177
total_train_sample_count: 15328070
total_episode_count: 45361
total_duration: 4075.686245785128
[2023-06-29 13:46:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2589
train_sample_count: 2589
avg_envstep_per_episode: 258.9
avg_sample_per_episode: 258.9
avg_envstep_per_sec: 2739.999326566222
avg_train_sample_per_sec: 2739.999326566222
avg_episode_per_sec: 10.58323416981932
collect_time: 0.9448907431829718
reward_mean: 1637.588402565394
reward_std: 767.5630391762105
reward_max: 2795.4586783548402
reward_min: 854.9595128073721
total_envstep_count: 20424121
total_train_sample_count: 15331459
total_episode_count: 45371
total_duration: 4076.631136528311
[2023-06-29 13:46:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1845
train_sample_count: 1845
avg_envstep_per_episode: 184.5
avg_sample_per_episode: 184.5
avg_envstep_per_sec: 2585.9695930644284
avg_train_sample_per_sec: 2585.9695930644284
avg_episode_per_sec: 14.016095355362754
collect_time: 0.7134654656993226
reward_mean: 1581.883864076579
reward_std: 807.1535657839992
reward_max: 3626.1109993282143
reward_min: 847.4003302567912
total_envstep_count: 20428545
total_train_sample_count: 15334904
total_episode_count: 45381
total_duration: 4077.34460199401
[2023-06-29 13:47:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3777
train_sample_count: 3777
avg_envstep_per_episode: 209.83333333333334
avg_sample_per_episode: 209.83333333333334
avg_envstep_per_sec: 2712.507345806668
avg_train_sample_per_sec: 2712.507345806668
avg_episode_per_sec: 12.926961139666409
collect_time: 1.392438625406474
reward_mean: 1354.6009415860563
reward_std: 834.5429491127098
reward_max: 3681.233845745422
reward_min: 24.12727901352235
total_envstep_count: 20433377
total_train_sample_count: 15338681
total_episode_count: 45399
total_duration: 4078.737040619417
[2023-06-29 13:47:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1445
train_sample_count: 1445
avg_envstep_per_episode: 206.42857142857142
avg_sample_per_episode: 206.42857142857142
avg_envstep_per_sec: 2591.810515096391
avg_train_sample_per_sec: 2591.810515096391
avg_episode_per_sec: 12.555483464134765
collect_time: 0.557525325089693
reward_mean: 1311.1199787403025
reward_std: 242.86347845350818
reward_max: 1663.2799613868085
reward_min: 1020.6021437182628
total_envstep_count: 20437617
total_train_sample_count: 15342126
total_episode_count: 45406
total_duration: 4079.2945659445063
[2023-06-29 13:47:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2999
train_sample_count: 2999
avg_envstep_per_episode: 249.91666666666666
avg_sample_per_episode: 249.91666666666666
avg_envstep_per_sec: 2581.1310669798936
avg_train_sample_per_sec: 2581.1310669798936
avg_episode_per_sec: 10.32796692356076
collect_time: 1.1618937288252638
reward_mean: 1751.406736858038
reward_std: 834.1007900443293
reward_max: 3593.7961446585687
reward_min: 874.0576324007752
total_envstep_count: 20441745
total_train_sample_count: 15345525
total_episode_count: 45418
total_duration: 4080.4564596733317
[2023-06-29 13:47:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 272.22222222222223
avg_sample_per_episode: 272.22222222222223
avg_envstep_per_sec: 2551.90198196399
avg_train_sample_per_sec: 2551.90198196399
avg_episode_per_sec: 9.374333811296289
collect_time: 0.9600682225711648
reward_mean: 1495.4132399800205
reward_std: 648.939185833541
reward_max: 2540.998137961903
reward_min: 277.10596687521837
total_envstep_count: 20446705
total_train_sample_count: 15348775
total_episode_count: 45427
total_duration: 4081.4165278959026
[2023-06-29 13:47:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2421
train_sample_count: 2421
avg_envstep_per_episode: 242.1
avg_sample_per_episode: 242.1
avg_envstep_per_sec: 2755.9879322793786
avg_train_sample_per_sec: 2755.9879322793786
avg_episode_per_sec: 11.383675887151503
collect_time: 0.8784508711537347
reward_mean: 1842.066261907333
reward_std: 790.6953285079957
reward_max: 3589.9760243617366
reward_min: 1028.5670463132774
total_envstep_count: 20451305
total_train_sample_count: 15351996
total_episode_count: 45437
total_duration: 4082.2949787670564
[2023-06-29 13:47:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3337
train_sample_count: 3337
avg_envstep_per_episode: 303.3636363636364
avg_sample_per_episode: 303.3636363636364
avg_envstep_per_sec: 2734.3441840358514
avg_train_sample_per_sec: 2734.3441840358514
avg_episode_per_sec: 9.013421044169723
collect_time: 1.2204023251654579
reward_mean: 1849.0986916204101
reward_std: 886.8412017206597
reward_max: 3595.493759946235
reward_min: 1064.2762123987602
total_envstep_count: 20456129
total_train_sample_count: 15355333
total_episode_count: 45448
total_duration: 4083.515381092222
[2023-06-29 13:47:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 216.75
avg_sample_per_episode: 216.75
avg_envstep_per_sec: 2557.4865076468027
avg_train_sample_per_sec: 2557.4865076468027
avg_episode_per_sec: 11.79924571001985
collect_time: 0.33900472100544726
reward_mean: 1520.4854219340318
reward_std: 454.5166401011828
reward_max: 2282.3937798866177
reward_min: 1086.7396980636179
total_envstep_count: 20459945
total_train_sample_count: 15358600
total_episode_count: 45452
total_duration: 4083.8543858132275
[2023-06-29 13:47:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1622
train_sample_count: 1622
avg_envstep_per_episode: 270.3333333333333
avg_sample_per_episode: 270.3333333333333
avg_envstep_per_sec: 2672.832803289923
avg_train_sample_per_sec: 2672.832803289923
avg_episode_per_sec: 9.887174364820924
collect_time: 0.6068467874247581
reward_mean: 2854.770663809311
reward_std: 766.8146625163466
reward_max: 3561.061355068549
reward_min: 1511.1044593003573
total_envstep_count: 20464353
total_train_sample_count: 15361822
total_episode_count: 45458
total_duration: 4084.4612326006522
[2023-06-29 13:47:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1614
train_sample_count: 1614
avg_envstep_per_episode: 269.0
avg_sample_per_episode: 269.0
avg_envstep_per_sec: 2380.928891947255
avg_train_sample_per_sec: 2380.928891947255
avg_episode_per_sec: 8.851036773038123
collect_time: 0.6778866876112296
reward_mean: 2392.5327251895983
reward_std: 1137.3578085031645
reward_max: 3533.982158559963
reward_min: 1098.3964348182851
total_envstep_count: 20468649
total_train_sample_count: 15365036
total_episode_count: 45464
total_duration: 4085.1391192882634
[2023-06-29 13:47:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2002
train_sample_count: 2002
avg_envstep_per_episode: 250.25
avg_sample_per_episode: 250.25
avg_envstep_per_sec: 2700.890630393216
avg_train_sample_per_sec: 2700.890630393216
avg_episode_per_sec: 10.792769751821043
collect_time: 0.7412369747487827
reward_mean: 2531.1197101699754
reward_std: 1015.2018644747396
reward_max: 3653.2013042605195
reward_min: 1292.3625644549743
total_envstep_count: 20473481
total_train_sample_count: 15368238
total_episode_count: 45472
total_duration: 4085.8803562630123
[2023-06-29 13:47:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 160.16666666666666
avg_sample_per_episode: 160.16666666666666
avg_envstep_per_sec: 2285.732012581215
avg_train_sample_per_sec: 2285.732012581215
avg_episode_per_sec: 14.270959495824442
collect_time: 0.42043423932045687
reward_mean: 1854.7950865692194
reward_std: 555.1540079983457
reward_max: 2623.6178285871847
reward_min: 1241.5739378866128
total_envstep_count: 20478161
total_train_sample_count: 15371599
total_episode_count: 45478
total_duration: 4086.300790502333
[2023-06-29 13:47:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3299
train_sample_count: 3299
avg_envstep_per_episode: 253.76923076923077
avg_sample_per_episode: 253.76923076923077
avg_envstep_per_sec: 2676.167619622073
avg_train_sample_per_sec: 2676.167619622073
avg_episode_per_sec: 10.545674160377978
collect_time: 1.2327329483442009
reward_mean: 2236.747106886268
reward_std: 1143.0069135693516
reward_max: 3791.041692405213
reward_min: 835.5995201811663
total_envstep_count: 20482961
total_train_sample_count: 15375298
total_episode_count: 45491
total_duration: 4087.533523450677
[2023-06-29 13:47:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2818
train_sample_count: 2818
avg_envstep_per_episode: 313.1111111111111
avg_sample_per_episode: 313.1111111111111
avg_envstep_per_sec: 2394.3806962097296
avg_train_sample_per_sec: 2394.3806962097296
avg_episode_per_sec: 7.647063969442004
collect_time: 1.1769222849402576
reward_mean: 1772.9947407947848
reward_std: 687.1390104535279
reward_max: 3158.2513424205176
reward_min: 1004.5523234430966
total_envstep_count: 20487177
total_train_sample_count: 15378516
total_episode_count: 45500
total_duration: 4088.710445735617
[2023-06-29 13:47:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1266
train_sample_count: 1266
avg_envstep_per_episode: 211.0
avg_sample_per_episode: 211.0
avg_envstep_per_sec: 2755.214669714679
avg_train_sample_per_sec: 2755.214669714679
avg_episode_per_sec: 13.057889429927389
collect_time: 0.459492327010259
reward_mean: 1516.5820603114064
reward_std: 346.67282320735575
reward_max: 2271.547870128514
reward_min: 1278.865462828872
total_envstep_count: 20491601
total_train_sample_count: 15381782
total_episode_count: 45506
total_duration: 4089.1699380626274
[2023-06-29 13:47:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2617
train_sample_count: 2617
avg_envstep_per_episode: 290.77777777777777
avg_sample_per_episode: 290.77777777777777
avg_envstep_per_sec: 2500.4217489722605
avg_train_sample_per_sec: 2500.4217489722605
avg_episode_per_sec: 8.599081291841935
collect_time: 1.0466234350567685
reward_mean: 2292.3558160742714
reward_std: 1002.3836742528263
reward_max: 3706.8759400940917
reward_min: 945.3259699131515
total_envstep_count: 20495921
total_train_sample_count: 15385199
total_episode_count: 45515
total_duration: 4090.2165614976843
[2023-06-29 13:47:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1461
train_sample_count: 1461
avg_envstep_per_episode: 243.5
avg_sample_per_episode: 243.5
avg_envstep_per_sec: 2769.5176304509255
avg_train_sample_per_sec: 2769.5176304509255
avg_episode_per_sec: 11.373789036759447
collect_time: 0.5275286872833966
reward_mean: 1861.5676537415857
reward_std: 861.2651522569026
reward_max: 3599.6739604748122
reward_min: 1065.138698637227
total_envstep_count: 20500729
total_train_sample_count: 15388660
total_episode_count: 45521
total_duration: 4090.7440901849677
[2023-06-29 13:47:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2327
train_sample_count: 2327
avg_envstep_per_episode: 258.55555555555554
avg_sample_per_episode: 258.55555555555554
avg_envstep_per_sec: 2773.058978842761
avg_train_sample_per_sec: 2773.058978842761
avg_episode_per_sec: 10.725195878635517
collect_time: 0.8391455132234843
reward_mean: 2531.71316808354
reward_std: 1015.5832784077821
reward_max: 3806.0331294747702
reward_min: 958.9594350305665
total_envstep_count: 20505081
total_train_sample_count: 15392187
total_episode_count: 45530
total_duration: 4091.5832356981914
[2023-06-29 13:47:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2279
train_sample_count: 2279
avg_envstep_per_episode: 284.875
avg_sample_per_episode: 284.875
avg_envstep_per_sec: 2771.805972499972
avg_train_sample_per_sec: 2771.805972499972
avg_episode_per_sec: 9.729902492321095
collect_time: 0.8222076229760426
reward_mean: 1931.2351151077587
reward_std: 829.6414085820146
reward_max: 3568.366839714905
reward_min: 1035.7643379235487
total_envstep_count: 20509905
total_train_sample_count: 15395666
total_episode_count: 45538
total_duration: 4092.4054433211672
[2023-06-29 13:47:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2691
train_sample_count: 2691
avg_envstep_per_episode: 299.0
avg_sample_per_episode: 299.0
avg_envstep_per_sec: 2562.4236804861116
avg_train_sample_per_sec: 2562.4236804861116
avg_episode_per_sec: 8.569978864502046
collect_time: 1.0501776191396641
reward_mean: 2184.480094604848
reward_std: 909.2602029639878
reward_max: 3637.081392380654
reward_min: 988.1918015136971
total_envstep_count: 20514673
total_train_sample_count: 15399157
total_episode_count: 45547
total_duration: 4093.4556209403067
[2023-06-29 13:48:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2896
train_sample_count: 2896
avg_envstep_per_episode: 241.33333333333334
avg_sample_per_episode: 241.33333333333334
avg_envstep_per_sec: 2571.9730569386347
avg_train_sample_per_sec: 2571.9730569386347
avg_episode_per_sec: 10.657346921016442
collect_time: 1.1259838014971462
reward_mean: 1560.6345177616195
reward_std: 415.041863697077
reward_max: 2491.852806199957
reward_min: 1055.1446745879234
total_envstep_count: 20519825
total_train_sample_count: 15402453
total_episode_count: 45559
total_duration: 4094.581604741804
[2023-06-29 13:48:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1925
train_sample_count: 1925
avg_envstep_per_episode: 175.0
avg_sample_per_episode: 175.0
avg_envstep_per_sec: 2602.0338140469694
avg_train_sample_per_sec: 2602.0338140469694
avg_episode_per_sec: 14.868764651696969
collect_time: 0.7398059124397112
reward_mean: 1411.7340476844308
reward_std: 382.90029665523883
reward_max: 2260.8773774901188
reward_min: 824.8349607761659
total_envstep_count: 20524169
total_train_sample_count: 15405978
total_episode_count: 45570
total_duration: 4095.3214106542437
[2023-06-29 13:48:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1916
train_sample_count: 1916
avg_envstep_per_episode: 212.88888888888889
avg_sample_per_episode: 212.88888888888889
avg_envstep_per_sec: 2705.7273707815143
avg_train_sample_per_sec: 2705.7273707815143
avg_episode_per_sec: 12.709575332481016
collect_time: 0.7081275152442976
reward_mean: 1778.6567859662764
reward_std: 897.2061322828907
reward_max: 3572.794731991069
reward_min: 791.707982991742
total_envstep_count: 20528681
total_train_sample_count: 15409494
total_episode_count: 45579
total_duration: 4096.029538169488
[2023-06-29 13:48:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3119
train_sample_count: 3119
avg_envstep_per_episode: 259.9166666666667
avg_sample_per_episode: 259.9166666666667
avg_envstep_per_sec: 2719.805446697714
avg_train_sample_per_sec: 2719.805446697714
avg_episode_per_sec: 10.464144071937342
collect_time: 1.146773201659322
reward_mean: 1764.3266907091274
reward_std: 746.4579830539192
reward_max: 3509.214430371832
reward_min: 1058.6669704517808
total_envstep_count: 20533121
total_train_sample_count: 15413013
total_episode_count: 45591
total_duration: 4097.176311371147
[2023-06-29 13:48:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2332
train_sample_count: 2332
avg_envstep_per_episode: 333.14285714285717
avg_sample_per_episode: 333.14285714285717
avg_envstep_per_sec: 2584.962020767797
avg_train_sample_per_sec: 2584.962020767797
avg_episode_per_sec: 7.759319959423062
collect_time: 0.9021409139726311
reward_mean: 1843.8487781110343
reward_std: 728.1493049976616
reward_max: 3329.9282077207954
reward_min: 1015.472560699225
total_envstep_count: 20538065
total_train_sample_count: 15416545
total_episode_count: 45598
total_duration: 4098.078452285119
[2023-06-29 13:48:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3064
train_sample_count: 3064
avg_envstep_per_episode: 255.33333333333334
avg_sample_per_episode: 255.33333333333334
avg_envstep_per_sec: 2566.3696852349485
avg_train_sample_per_sec: 2566.3696852349485
avg_episode_per_sec: 10.051056208491966
collect_time: 1.1939043769212438
reward_mean: 1816.0599077799616
reward_std: 894.9961152314764
reward_max: 3594.2399697070123
reward_min: 1051.1968281666768
total_envstep_count: 20543353
total_train_sample_count: 15420009
total_episode_count: 45610
total_duration: 4099.272356662041
[2023-06-29 13:48:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 2783.3885332254667
avg_train_sample_per_sec: 2783.3885332254667
avg_episode_per_sec: 12.049301009634055
collect_time: 0.41496183023415506
reward_mean: 1981.9511245721587
reward_std: 646.4507484799661
reward_max: 2852.8053321609245
reward_min: 1223.0096192284202
total_envstep_count: 20548065
total_train_sample_count: 15423564
total_episode_count: 45615
total_duration: 4099.687318492275
[2023-06-29 13:48:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 224.54545454545453
avg_sample_per_episode: 224.54545454545453
avg_envstep_per_sec: 2761.2774459467114
avg_train_sample_per_sec: 2761.2774459467114
avg_episode_per_sec: 12.297187006240415
collect_time: 0.894513517149724
reward_mean: 2245.9316045075643
reward_std: 985.5857735306278
reward_max: 3687.7437980143372
reward_min: 835.5127944569044
total_envstep_count: 20552377
total_train_sample_count: 15426834
total_episode_count: 45626
total_duration: 4100.581832009425
[2023-06-29 13:48:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2610
train_sample_count: 2610
avg_envstep_per_episode: 326.25
avg_sample_per_episode: 326.25
avg_envstep_per_sec: 2753.8079770381096
avg_train_sample_per_sec: 2753.8079770381096
avg_episode_per_sec: 8.440790734216428
collect_time: 0.9477785022640598
reward_mean: 2000.5539451864495
reward_std: 811.4199307205431
reward_max: 3030.1914596414526
reward_min: 1014.2506499568029
total_envstep_count: 20556993
total_train_sample_count: 15430244
total_episode_count: 45634
total_duration: 4101.529610511689
[2023-06-29 13:48:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2129
train_sample_count: 2129
avg_envstep_per_episode: 212.9
avg_sample_per_episode: 212.9
avg_envstep_per_sec: 2707.472124233209
avg_train_sample_per_sec: 2707.472124233209
avg_episode_per_sec: 12.717107206356077
collect_time: 0.7863423526855186
reward_mean: 1583.4680979361415
reward_std: 758.9674717409949
reward_max: 3692.8933052245707
reward_min: 840.8662312710965
total_envstep_count: 20562033
total_train_sample_count: 15433573
total_episode_count: 45644
total_duration: 4102.315952864374
[2023-06-29 13:48:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2719
train_sample_count: 2719
avg_envstep_per_episode: 271.9
avg_sample_per_episode: 271.9
avg_envstep_per_sec: 2530.369139863703
avg_train_sample_per_sec: 2530.369139863703
avg_episode_per_sec: 9.306249135210383
collect_time: 1.074546775474213
reward_mean: 2010.8156900033277
reward_std: 776.4070841173727
reward_max: 3597.239995511012
reward_min: 1100.6277456367827
total_envstep_count: 20566305
total_train_sample_count: 15437092
total_episode_count: 45654
total_duration: 4103.390499639848
[2023-06-29 13:48:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2778
train_sample_count: 2778
avg_envstep_per_episode: 308.6666666666667
avg_sample_per_episode: 308.6666666666667
avg_envstep_per_sec: 2503.914407996195
avg_train_sample_per_sec: 2503.914407996195
avg_episode_per_sec: 8.112033719210137
collect_time: 1.1094628439089285
reward_mean: 1821.7077304490595
reward_std: 786.8318570591244
reward_max: 3623.726850368975
reward_min: 1040.2510315023178
total_envstep_count: 20570841
total_train_sample_count: 15440670
total_episode_count: 45663
total_duration: 4104.4999624837565
[2023-06-29 13:48:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2079
train_sample_count: 2079
avg_envstep_per_episode: 259.875
avg_sample_per_episode: 259.875
avg_envstep_per_sec: 2686.6297002196407
avg_train_sample_per_sec: 2686.6297002196407
avg_episode_per_sec: 10.338161424606602
collect_time: 0.7738319872776047
reward_mean: 1585.2632173414934
reward_std: 503.7657996934592
reward_max: 2724.252742591257
reward_min: 1035.8573189731803
total_envstep_count: 20575529
total_train_sample_count: 15443949
total_episode_count: 45671
total_duration: 4105.273794471034
[2023-06-29 13:48:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 203.33333333333334
avg_sample_per_episode: 203.33333333333334
avg_envstep_per_sec: 2600.4499875846627
avg_train_sample_per_sec: 2600.4499875846627
avg_episode_per_sec: 12.789098299596702
collect_time: 0.938299145013094
reward_mean: 1712.5485503912032
reward_std: 778.8560881813632
reward_max: 3703.9593394765666
reward_min: 877.6222849323578
total_envstep_count: 20580137
total_train_sample_count: 15447189
total_episode_count: 45683
total_duration: 4106.212093616047
[2023-06-29 13:48:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2423
train_sample_count: 2423
avg_envstep_per_episode: 220.27272727272728
avg_sample_per_episode: 220.27272727272728
avg_envstep_per_sec: 2539.1325463882677
avg_train_sample_per_sec: 2539.1325463882677
avg_episode_per_sec: 11.527221630322305
collect_time: 0.9542629050407558
reward_mean: 1539.9992469998795
reward_std: 414.39656912583587
reward_max: 2265.0915182710232
reward_min: 997.473120914081
total_envstep_count: 20584361
total_train_sample_count: 15450412
total_episode_count: 45694
total_duration: 4107.166356521088
[2023-06-29 13:48:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2837
train_sample_count: 2837
avg_envstep_per_episode: 257.90909090909093
avg_sample_per_episode: 257.90909090909093
avg_envstep_per_sec: 2573.4669156870286
avg_train_sample_per_sec: 2573.4669156870286
avg_episode_per_sec: 9.978193892336028
collect_time: 1.1024039138434454
reward_mean: 1565.4021003957357
reward_std: 410.571203253445
reward_max: 2397.936789449052
reward_min: 1132.0439251738799
total_envstep_count: 20589361
total_train_sample_count: 15453649
total_episode_count: 45705
total_duration: 4108.268760434932
[2023-06-29 13:48:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2668
train_sample_count: 2668
avg_envstep_per_episode: 266.8
avg_sample_per_episode: 266.8
avg_envstep_per_sec: 2483.4709971405205
avg_train_sample_per_sec: 2483.4709971405205
avg_episode_per_sec: 9.308362058247829
collect_time: 1.0743028620313855
reward_mean: 1797.5162690235109
reward_std: 652.8001730267116
reward_max: 2890.7483667381416
reward_min: 987.2556819979488
total_envstep_count: 20593713
total_train_sample_count: 15457117
total_episode_count: 45715
total_duration: 4109.343063296964
[2023-06-29 13:48:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2249
train_sample_count: 2249
avg_envstep_per_episode: 321.2857142857143
avg_sample_per_episode: 321.2857142857143
avg_envstep_per_sec: 2718.689187711668
avg_train_sample_per_sec: 2718.689187711668
avg_episode_per_sec: 8.461904986207948
collect_time: 0.8272368942229077
reward_mean: 1964.482416262134
reward_std: 654.9453117133287
reward_max: 2902.887144294585
reward_min: 1047.2729260594008
total_envstep_count: 20598657
total_train_sample_count: 15460566
total_episode_count: 45722
total_duration: 4110.1703001911865
[2023-06-29 13:48:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 286.85714285714283
avg_sample_per_episode: 286.85714285714283
avg_envstep_per_sec: 2575.825071956056
avg_train_sample_per_sec: 2575.825071956056
avg_episode_per_sec: 8.97946987235677
collect_time: 0.7795560427848249
reward_mean: 2384.4891628734986
reward_std: 773.089729918772
reward_max: 3643.276570251926
reward_min: 1271.0968262186088
total_envstep_count: 20603009
total_train_sample_count: 15463774
total_episode_count: 45729
total_duration: 4110.949856233971
[2023-06-29 13:49:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2110
train_sample_count: 2110
avg_envstep_per_episode: 351.6666666666667
avg_sample_per_episode: 351.6666666666667
avg_envstep_per_sec: 2627.3140589149975
avg_train_sample_per_sec: 2627.3140589149975
avg_episode_per_sec: 7.471035238620845
collect_time: 0.8031015526447445
reward_mean: 2818.931658132367
reward_std: 861.3159879934109
reward_max: 3596.667735516375
reward_min: 1176.5239206838141
total_envstep_count: 20607281
total_train_sample_count: 15467084
total_episode_count: 45735
total_duration: 4111.752957786616
[2023-06-29 13:49:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3006
train_sample_count: 3006
avg_envstep_per_episode: 300.6
avg_sample_per_episode: 300.6
avg_envstep_per_sec: 2493.0137973873225
avg_train_sample_per_sec: 2493.0137973873225
avg_episode_per_sec: 8.293459073144785
collect_time: 1.2057695000125097
reward_mean: 2008.5318140909772
reward_std: 1017.1239396330669
reward_max: 3787.3149181301987
reward_min: 1033.8326043379222
total_envstep_count: 20611665
total_train_sample_count: 15470490
total_episode_count: 45745
total_duration: 4112.958727286628
[2023-06-29 13:49:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2595
train_sample_count: 2595
avg_envstep_per_episode: 259.5
avg_sample_per_episode: 259.5
avg_envstep_per_sec: 2694.2897211528443
avg_train_sample_per_sec: 2694.2897211528443
avg_episode_per_sec: 10.382619349336588
collect_time: 0.9631480904323979
reward_mean: 1360.5006954986063
reward_std: 319.28792572788956
reward_max: 1920.7404405991401
reward_min: 825.9016979743777
total_envstep_count: 20616713
total_train_sample_count: 15473885
total_episode_count: 45755
total_duration: 4113.921875377061
[2023-06-29 13:49:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3049
train_sample_count: 3049
avg_envstep_per_episode: 254.08333333333334
avg_sample_per_episode: 254.08333333333334
avg_envstep_per_sec: 2785.8767074025536
avg_train_sample_per_sec: 2785.8767074025536
avg_episode_per_sec: 10.964421282004148
collect_time: 1.0944490084210412
reward_mean: 1782.4677669775738
reward_std: 826.9840960693571
reward_max: 3503.4266353865883
reward_min: 945.4981853064377
total_envstep_count: 20621257
total_train_sample_count: 15477334
total_episode_count: 45767
total_duration: 4115.016324385482
[2023-06-29 13:49:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2549
train_sample_count: 2549
avg_envstep_per_episode: 283.22222222222223
avg_sample_per_episode: 283.22222222222223
avg_envstep_per_sec: 2525.4258519446657
avg_train_sample_per_sec: 2525.4258519446657
avg_episode_per_sec: 8.916764483131422
collect_time: 1.0093347219191493
reward_mean: 1649.6154412301578
reward_std: 723.8491094980363
reward_max: 3508.6085292261687
reward_min: 1016.6355296813555
total_envstep_count: 20625881
total_train_sample_count: 15480683
total_episode_count: 45776
total_duration: 4116.025659107401
[2023-06-29 13:49:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2527
train_sample_count: 2527
avg_envstep_per_episode: 280.77777777777777
avg_sample_per_episode: 280.77777777777777
avg_envstep_per_sec: 2568.525744910633
avg_train_sample_per_sec: 2568.525744910633
avg_episode_per_sec: 9.14789541123692
collect_time: 0.9838328484762462
reward_mean: 1741.6055099904927
reward_std: 711.9301034047137
reward_max: 3605.179837377827
reward_min: 1179.0519206785164
total_envstep_count: 20630369
total_train_sample_count: 15484010
total_episode_count: 45785
total_duration: 4117.009491955878
[2023-06-29 13:49:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2435
train_sample_count: 2435
avg_envstep_per_episode: 221.36363636363637
avg_sample_per_episode: 221.36363636363637
avg_envstep_per_sec: 2664.6604491460484
avg_train_sample_per_sec: 2664.6604491460484
avg_episode_per_sec: 12.037480468421574
collect_time: 0.9138124899854883
reward_mean: 1577.0894289700293
reward_std: 706.5149436095513
reward_max: 3502.545368440107
reward_min: 984.8739097884902
total_envstep_count: 20634817
total_train_sample_count: 15487245
total_episode_count: 45796
total_duration: 4117.923304445863
[2023-06-29 13:49:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2404
train_sample_count: 2404
avg_envstep_per_episode: 300.5
avg_sample_per_episode: 300.5
avg_envstep_per_sec: 2569.2138457612896
avg_train_sample_per_sec: 2569.2138457612896
avg_episode_per_sec: 8.549796491718102
collect_time: 0.9356947861565277
reward_mean: 2055.5578108092072
reward_std: 788.0398419564518
reward_max: 3145.5220480053667
reward_min: 1136.4332309812005
total_envstep_count: 20639121
total_train_sample_count: 15490449
total_episode_count: 45804
total_duration: 4118.858999232019
[2023-06-29 13:49:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 292.54545454545456
avg_sample_per_episode: 292.54545454545456
avg_envstep_per_sec: 2638.440942292642
avg_train_sample_per_sec: 2638.440942292642
avg_episode_per_sec: 9.018909373902753
collect_time: 1.2196596665922554
reward_mean: 1714.9427034529892
reward_std: 760.6026122410852
reward_max: 2685.757069596259
reward_min: 23.18687660277246
total_envstep_count: 20643913
total_train_sample_count: 15493667
total_episode_count: 45815
total_duration: 4120.078658898612
[2023-06-29 13:49:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2863
train_sample_count: 2863
avg_envstep_per_episode: 260.27272727272725
avg_sample_per_episode: 260.27272727272725
avg_envstep_per_sec: 2553.48743415092
avg_train_sample_per_sec: 2553.48743415092
avg_episode_per_sec: 9.810814451854739
collect_time: 1.121211705101654
reward_mean: 1490.5880093607398
reward_std: 708.2644321811705
reward_max: 2701.090675176156
reward_min: 25.653738237131563
total_envstep_count: 20648673
total_train_sample_count: 15496930
total_episode_count: 45826
total_duration: 4121.199870603714
[2023-06-29 13:49:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2477
train_sample_count: 2477
avg_envstep_per_episode: 225.1818181818182
avg_sample_per_episode: 225.1818181818182
avg_envstep_per_sec: 2739.3863862876433
avg_train_sample_per_sec: 2739.3863862876433
avg_episode_per_sec: 12.165220124813919
collect_time: 0.9042170948935672
reward_mean: 1466.207369525705
reward_std: 655.5655106404602
reward_max: 2670.65246735045
reward_min: 22.828740025565548
total_envstep_count: 20652681
total_train_sample_count: 15500207
total_episode_count: 45837
total_duration: 4122.104087698607
[2023-06-29 13:49:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3432
train_sample_count: 3432
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 2619.355119468229
avg_train_sample_per_sec: 2619.355119468229
avg_episode_per_sec: 9.158584333804997
collect_time: 1.3102461649784818
reward_mean: 1540.343185105469
reward_std: 606.7816787288534
reward_max: 3117.549869091653
reward_min: 966.5670409041228
total_envstep_count: 20657297
total_train_sample_count: 15503639
total_episode_count: 45849
total_duration: 4123.414333863586
[2023-06-29 13:49:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2238
train_sample_count: 2238
avg_envstep_per_episode: 223.8
avg_sample_per_episode: 223.8
avg_envstep_per_sec: 2514.9345403850466
avg_train_sample_per_sec: 2514.9345403850466
avg_episode_per_sec: 11.23741975149708
collect_time: 0.8898839966058731
reward_mean: 1214.7895837795984
reward_std: 127.71812517905869
reward_max: 1356.0128341853886
reward_min: 999.5762416378507
total_envstep_count: 20661993
total_train_sample_count: 15507077
total_episode_count: 45859
total_duration: 4124.304217860192
[2023-06-29 13:49:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2839
train_sample_count: 2839
avg_envstep_per_episode: 258.09090909090907
avg_sample_per_episode: 258.09090909090907
avg_envstep_per_sec: 2688.4391621885516
avg_train_sample_per_sec: 2688.4391621885516
avg_episode_per_sec: 10.416636415665398
collect_time: 1.0560030667344107
reward_mean: 1836.8945100677718
reward_std: 757.6731266118629
reward_max: 3454.4781447356913
reward_min: 1041.7770987195158
total_envstep_count: 20666473
total_train_sample_count: 15510316
total_episode_count: 45870
total_duration: 4125.360220926927
[2023-06-29 13:49:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2325
train_sample_count: 2325
avg_envstep_per_episode: 258.3333333333333
avg_sample_per_episode: 258.3333333333333
avg_envstep_per_sec: 2783.478151070782
avg_train_sample_per_sec: 2783.478151070782
avg_episode_per_sec: 10.77475413317722
collect_time: 0.835285881121643
reward_mean: 1651.6700439732947
reward_std: 262.80261584946754
reward_max: 1940.6238797315405
reward_min: 1282.8503369163857
total_envstep_count: 20671033
total_train_sample_count: 15513841
total_episode_count: 45879
total_duration: 4126.195506808048
[2023-06-29 13:49:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1034
train_sample_count: 1034
avg_envstep_per_episode: 206.8
avg_sample_per_episode: 206.8
avg_envstep_per_sec: 2533.203802197517
avg_train_sample_per_sec: 2533.203802197517
avg_episode_per_sec: 12.249534826873871
collect_time: 0.40817876520752905
reward_mean: 2138.16571884449
reward_std: 334.70101585480444
reward_max: 2687.2213336883797
reward_min: 1672.7005219516327
total_envstep_count: 20675465
total_train_sample_count: 15517275
total_episode_count: 45884
total_duration: 4126.6036855732555
[2023-06-29 13:49:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1886
train_sample_count: 1886
avg_envstep_per_episode: 235.75
avg_sample_per_episode: 235.75
avg_envstep_per_sec: 2617.9584952718837
avg_train_sample_per_sec: 2617.9584952718837
avg_episode_per_sec: 11.104808039329306
collect_time: 0.7204086708808317
reward_mean: 2308.6609139521875
reward_std: 1005.4325179194732
reward_max: 3648.305856823731
reward_min: 1009.7946595708879
total_envstep_count: 20679897
total_train_sample_count: 15520761
total_episode_count: 45892
total_duration: 4127.324094244136
[2023-06-29 13:49:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 239.5
avg_sample_per_episode: 239.5
avg_envstep_per_sec: 2665.5605700660212
avg_train_sample_per_sec: 2665.5605700660212
avg_episode_per_sec: 11.129689227833074
collect_time: 0.5390986106777562
reward_mean: 2550.941228447434
reward_std: 1018.1280233401203
reward_max: 3614.621529262288
reward_min: 1141.1509940349702
total_envstep_count: 20684721
total_train_sample_count: 15524198
total_episode_count: 45898
total_duration: 4127.863192854814
[2023-06-29 13:49:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2742
train_sample_count: 2742
avg_envstep_per_episode: 274.2
avg_sample_per_episode: 274.2
avg_envstep_per_sec: 2480.1199762538326
avg_train_sample_per_sec: 2480.1199762538326
avg_episode_per_sec: 9.044930620911133
collect_time: 1.1055916755050421
reward_mean: 2407.2720531511377
reward_std: 813.7704931755168
reward_max: 3585.022373740332
reward_min: 1373.5119609520734
total_envstep_count: 20689497
total_train_sample_count: 15527740
total_episode_count: 45908
total_duration: 4128.968784530319
[2023-06-29 13:50:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2078
train_sample_count: 2078
avg_envstep_per_episode: 259.75
avg_sample_per_episode: 259.75
avg_envstep_per_sec: 2680.426281073516
avg_train_sample_per_sec: 2680.426281073516
avg_episode_per_sec: 10.319254210100157
collect_time: 0.7752498230123893
reward_mean: 1782.9850420292455
reward_std: 387.10684911422624
reward_max: 2569.953320314655
reward_min: 1248.23061581748
total_envstep_count: 20694161
total_train_sample_count: 15531018
total_episode_count: 45916
total_duration: 4129.744034353331
[2023-06-29 13:50:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 607
train_sample_count: 607
avg_envstep_per_episode: 151.75
avg_sample_per_episode: 151.75
avg_envstep_per_sec: 2499.5459647077273
avg_train_sample_per_sec: 2499.5459647077273
avg_episode_per_sec: 16.471472584564925
collect_time: 0.24284410391747954
reward_mean: 2547.688357285408
reward_std: 686.9485767792878
reward_max: 3587.17769372175
reward_min: 1688.8914625273708
total_envstep_count: 20698441
total_train_sample_count: 15534425
total_episode_count: 45920
total_duration: 4129.986878457248
[2023-06-29 13:50:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 195.8181818181818
avg_sample_per_episode: 195.8181818181818
avg_envstep_per_sec: 2511.09752608908
avg_train_sample_per_sec: 2511.09752608908
avg_episode_per_sec: 12.823617821253425
collect_time: 0.8577922512451187
reward_mean: 2205.3829306590033
reward_std: 864.14771657989
reward_max: 3660.670850980796
reward_min: 1038.9476867923265
total_envstep_count: 20702737
total_train_sample_count: 15537779
total_episode_count: 45931
total_duration: 4130.844670708493
[2023-06-29 13:50:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2614
train_sample_count: 2614
avg_envstep_per_episode: 290.44444444444446
avg_sample_per_episode: 290.44444444444446
avg_envstep_per_sec: 2758.3771056947585
avg_train_sample_per_sec: 2758.3771056947585
avg_episode_per_sec: 9.49709026444255
collect_time: 0.9476586774894965
reward_mean: 1922.6573339307583
reward_std: 771.0430363802783
reward_max: 3219.21782528619
reward_min: 1104.1090933967505
total_envstep_count: 20707921
total_train_sample_count: 15541193
total_episode_count: 45940
total_duration: 4131.792329385983
[2023-06-29 13:50:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1955
train_sample_count: 1955
avg_envstep_per_episode: 244.375
avg_sample_per_episode: 244.375
avg_envstep_per_sec: 2670.6012858172876
avg_train_sample_per_sec: 2670.6012858172876
avg_episode_per_sec: 10.928291706669208
collect_time: 0.7320448808223009
reward_mean: 2113.1777205605463
reward_std: 490.0561351749831
reward_max: 3100.8436006826646
reward_min: 1495.4316820707295
total_envstep_count: 20712185
total_train_sample_count: 15544748
total_episode_count: 45948
total_duration: 4132.524374266805
[2023-06-29 13:50:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1784
train_sample_count: 1784
avg_envstep_per_episode: 297.3333333333333
avg_sample_per_episode: 297.3333333333333
avg_envstep_per_sec: 2678.7793581862907
avg_train_sample_per_sec: 2678.7793581862907
avg_episode_per_sec: 9.009347617218467
collect_time: 0.665974968990311
reward_mean: 2456.078938538458
reward_std: 801.1126449993653
reward_max: 3580.370201743948
reward_min: 1652.94323644056
total_envstep_count: 20716321
total_train_sample_count: 15548132
total_episode_count: 45954
total_duration: 4133.190349235796
[2023-06-29 13:50:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1706
train_sample_count: 1706
avg_envstep_per_episode: 284.3333333333333
avg_sample_per_episode: 284.3333333333333
avg_envstep_per_sec: 2544.8221117487597
avg_train_sample_per_sec: 2544.8221117487597
avg_episode_per_sec: 8.950136383641594
collect_time: 0.6703808459239082
reward_mean: 2156.354918174988
reward_std: 799.7037953604832
reward_max: 3651.778461652307
reward_min: 1191.0448403742598
total_envstep_count: 20720697
total_train_sample_count: 15551438
total_episode_count: 45960
total_duration: 4133.86073008172
[2023-06-29 13:50:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 230.16666666666666
avg_sample_per_episode: 230.16666666666666
avg_envstep_per_sec: 2688.264983447098
avg_train_sample_per_sec: 2688.264983447098
avg_episode_per_sec: 11.67964511273178
collect_time: 0.5137142389249056
reward_mean: 2497.8115890569234
reward_std: 988.484184538092
reward_max: 3528.078055828853
reward_min: 1214.1909324444919
total_envstep_count: 20725025
total_train_sample_count: 15554819
total_episode_count: 45966
total_duration: 4134.374444320645
[2023-06-29 13:50:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2850
train_sample_count: 2850
avg_envstep_per_episode: 316.6666666666667
avg_sample_per_episode: 316.6666666666667
avg_envstep_per_sec: 2615.3362990784512
avg_train_sample_per_sec: 2615.3362990784512
avg_episode_per_sec: 8.258956733931951
collect_time: 1.0897260138224807
reward_mean: 2643.5286269673534
reward_std: 881.4988421946701
reward_max: 3690.2563107540877
reward_min: 1586.0097813391899
total_envstep_count: 20729633
total_train_sample_count: 15558069
total_episode_count: 45975
total_duration: 4135.464170334468
[2023-06-29 13:50:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 325.75
avg_sample_per_episode: 325.75
avg_envstep_per_sec: 2753.1809788763694
avg_train_sample_per_sec: 2753.1809788763694
avg_episode_per_sec: 8.451821884501518
collect_time: 0.9465414805617184
reward_mean: 2030.259903043633
reward_std: 472.03958779310307
reward_max: 2841.526703157597
reward_min: 1433.8507985243007
total_envstep_count: 20734153
total_train_sample_count: 15561475
total_episode_count: 45983
total_duration: 4136.41071181503
[2023-06-29 13:50:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 349.0
avg_sample_per_episode: 349.0
avg_envstep_per_sec: 2571.3638920414687
avg_train_sample_per_sec: 2571.3638920414687
avg_episode_per_sec: 7.367804848256357
collect_time: 0.9500794529942794
reward_mean: 2142.5583020396402
reward_std: 677.3611463992258
reward_max: 3549.8962554144996
reward_min: 1324.0545662696334
total_envstep_count: 20739017
total_train_sample_count: 15564718
total_episode_count: 45990
total_duration: 4137.360791268024
[2023-06-29 13:50:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 304.875
avg_sample_per_episode: 304.875
avg_envstep_per_sec: 2537.3952296929538
avg_train_sample_per_sec: 2537.3952296929538
avg_episode_per_sec: 8.322739580788696
collect_time: 0.9612219537021592
reward_mean: 2288.146014553223
reward_std: 1026.6543587079975
reward_max: 3664.1538034391933
reward_min: 1065.5374049931397
total_envstep_count: 20744017
total_train_sample_count: 15567957
total_episode_count: 45998
total_duration: 4138.322013221726
[2023-06-29 13:50:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 252.875
avg_sample_per_episode: 252.875
avg_envstep_per_sec: 2450.5498530975374
avg_train_sample_per_sec: 2450.5498530975374
avg_episode_per_sec: 9.690755721591843
collect_time: 0.8255290123736487
reward_mean: 2013.292268227402
reward_std: 910.3340173229274
reward_max: 3548.4089159990194
reward_min: 1220.236762447501
total_envstep_count: 20748833
total_train_sample_count: 15571180
total_episode_count: 46006
total_duration: 4139.147542234099
[2023-06-29 13:50:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1658
train_sample_count: 1658
avg_envstep_per_episode: 207.25
avg_sample_per_episode: 207.25
avg_envstep_per_sec: 2559.3176484932314
avg_train_sample_per_sec: 2559.3176484932314
avg_episode_per_sec: 12.348939196589777
collect_time: 0.6478289246261121
reward_mean: 2129.7380041897613
reward_std: 819.7948281710426
reward_max: 3519.6541004431124
reward_min: 1302.7573134216118
total_envstep_count: 20752985
total_train_sample_count: 15574438
total_episode_count: 46014
total_duration: 4139.795371158725
[2023-06-29 13:50:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3318
train_sample_count: 3318
avg_envstep_per_episode: 301.6363636363636
avg_sample_per_episode: 301.6363636363636
avg_envstep_per_sec: 2657.949402982336
avg_train_sample_per_sec: 2657.949402982336
avg_episode_per_sec: 8.81176715877206
collect_time: 1.2483307606521998
reward_mean: 1986.166090062921
reward_std: 863.288048035873
reward_max: 3597.76441479913
reward_min: 1074.8856229963108
total_envstep_count: 20757785
total_train_sample_count: 15577756
total_episode_count: 46025
total_duration: 4141.043701919378
[2023-06-29 13:50:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3016
train_sample_count: 3016
avg_envstep_per_episode: 335.1111111111111
avg_sample_per_episode: 335.1111111111111
avg_envstep_per_sec: 2587.1467678950303
avg_train_sample_per_sec: 2587.1467678950303
avg_episode_per_sec: 7.720265554063419
collect_time: 1.1657630086652935
reward_mean: 1860.4099743361285
reward_std: 419.30525153416863
reward_max: 2685.7649320567434
reward_min: 1342.4525686286725
total_envstep_count: 20762321
total_train_sample_count: 15581172
total_episode_count: 46034
total_duration: 4142.209464928043
[2023-06-29 13:50:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2104
train_sample_count: 2104
avg_envstep_per_episode: 350.6666666666667
avg_sample_per_episode: 350.6666666666667
avg_envstep_per_sec: 2765.976213898264
avg_train_sample_per_sec: 2765.976213898264
avg_episode_per_sec: 7.887764868531171
collect_time: 0.7606717619001866
reward_mean: 2058.385297055263
reward_std: 885.6240094735965
reward_max: 3494.3317010828873
reward_min: 1361.0069146168883
total_envstep_count: 20766449
total_train_sample_count: 15584476
total_episode_count: 46040
total_duration: 4142.9701366899435
[2023-06-29 13:50:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1899
train_sample_count: 1899
avg_envstep_per_episode: 316.5
avg_sample_per_episode: 316.5
avg_envstep_per_sec: 2423.297872555147
avg_train_sample_per_sec: 2423.297872555147
avg_episode_per_sec: 7.6565493603638135
collect_time: 0.7836428288519386
reward_mean: 2368.6936633977843
reward_std: 1055.2281103679918
reward_max: 3475.5767689224785
reward_min: 874.3596315011731
total_envstep_count: 20771473
total_train_sample_count: 15587975
total_episode_count: 46046
total_duration: 4143.753779518795
[2023-06-29 13:50:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 304.875
avg_sample_per_episode: 304.875
avg_envstep_per_sec: 2705.9641279139714
avg_train_sample_per_sec: 2705.9641279139714
avg_episode_per_sec: 8.875651096068786
collect_time: 0.9013423255836824
reward_mean: 2631.840023070138
reward_std: 731.9652910651414
reward_max: 3578.9427816520315
reward_min: 1466.2957538993521
total_envstep_count: 20776393
total_train_sample_count: 15591214
total_episode_count: 46054
total_duration: 4144.655121844379
[2023-06-29 13:51:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 947
train_sample_count: 947
avg_envstep_per_episode: 157.83333333333334
avg_sample_per_episode: 157.83333333333334
avg_envstep_per_sec: 2148.4620882851873
avg_train_sample_per_sec: 2148.4620882851873
avg_episode_per_sec: 13.612220200328537
collect_time: 0.4407804099330679
reward_mean: 1850.70092201567
reward_std: 300.2432223053787
reward_max: 2292.8310130510254
reward_min: 1347.825486016826
total_envstep_count: 20781169
total_train_sample_count: 15594561
total_episode_count: 46060
total_duration: 4145.095902254312
[2023-06-29 13:51:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1929
train_sample_count: 1929
avg_envstep_per_episode: 321.5
avg_sample_per_episode: 321.5
avg_envstep_per_sec: 2444.1352359317716
avg_train_sample_per_sec: 2444.1352359317716
avg_episode_per_sec: 7.602286892478295
collect_time: 0.7892361975889652
reward_mean: 3282.4121365071314
reward_std: 469.98456804324013
reward_max: 3505.2586935846284
reward_min: 2231.800898039386
total_envstep_count: 20785881
total_train_sample_count: 15598090
total_episode_count: 46066
total_duration: 4145.885138451901
[2023-06-29 13:51:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2472
train_sample_count: 2472
avg_envstep_per_episode: 309.0
avg_sample_per_episode: 309.0
avg_envstep_per_sec: 2512.093799302303
avg_train_sample_per_sec: 2512.093799302303
avg_episode_per_sec: 8.129753395800334
collect_time: 0.9840396886002272
reward_mean: 2687.1608502045806
reward_std: 767.3904294215407
reward_max: 3567.9077482590305
reward_min: 1661.168711808333
total_envstep_count: 20790529
total_train_sample_count: 15601362
total_episode_count: 46074
total_duration: 4146.869178140501
[2023-06-29 13:51:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 184.2
avg_sample_per_episode: 184.2
avg_envstep_per_sec: 2733.222005905144
avg_train_sample_per_sec: 2733.222005905144
avg_episode_per_sec: 14.838338794273312
collect_time: 0.3369649439416825
reward_mean: 1826.764707419466
reward_std: 444.107984114114
reward_max: 2558.528994262852
reward_min: 1372.6873725908108
total_envstep_count: 20794673
total_train_sample_count: 15604683
total_episode_count: 46079
total_duration: 4147.206143084443
[2023-06-29 13:51:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1900
train_sample_count: 1900
avg_envstep_per_episode: 271.42857142857144
avg_sample_per_episode: 271.42857142857144
avg_envstep_per_sec: 2546.9179832904624
avg_train_sample_per_sec: 2546.9179832904624
avg_episode_per_sec: 9.383382043701703
collect_time: 0.7459996797954664
reward_mean: 2877.2283834935292
reward_std: 667.0847564060404
reward_max: 3619.1015946244916
reward_min: 1935.979674051582
total_envstep_count: 20799601
total_train_sample_count: 15608183
total_episode_count: 46086
total_duration: 4147.9521427642385
[2023-06-29 13:51:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1415
train_sample_count: 1415
avg_envstep_per_episode: 353.75
avg_sample_per_episode: 353.75
avg_envstep_per_sec: 2436.68049231412
avg_train_sample_per_sec: 2436.68049231412
avg_episode_per_sec: 6.888142734456876
collect_time: 0.5807080593714492
reward_mean: 2973.7648268991716
reward_std: 927.8794763529098
reward_max: 3603.790897278759
reward_min: 1377.4076526247393
total_envstep_count: 20803865
total_train_sample_count: 15611598
total_episode_count: 46090
total_duration: 4148.53285082361
[2023-06-29 13:51:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 254.875
avg_sample_per_episode: 254.875
avg_envstep_per_sec: 2761.1828362067226
avg_train_sample_per_sec: 2761.1828362067226
avg_episode_per_sec: 10.833478513807641
collect_time: 0.7384516422683374
reward_mean: 2763.393323968208
reward_std: 897.4062678952592
reward_max: 3493.818647362552
reward_min: 1344.6760037939582
total_envstep_count: 20807961
total_train_sample_count: 15614837
total_episode_count: 46098
total_duration: 4149.271302465878
[2023-06-29 13:51:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 312.875
avg_sample_per_episode: 312.875
avg_envstep_per_sec: 2789.5278817322437
avg_train_sample_per_sec: 2789.5278817322437
avg_episode_per_sec: 8.915790273215322
collect_time: 0.8972844531834128
reward_mean: 2047.2791438840347
reward_std: 879.6173752999415
reward_max: 3487.566855206956
reward_min: 833.1605974285349
total_envstep_count: 20812681
total_train_sample_count: 15618140
total_episode_count: 46106
total_duration: 4150.168586919061
[2023-06-29 13:51:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1585
train_sample_count: 1585
avg_envstep_per_episode: 264.1666666666667
avg_sample_per_episode: 264.1666666666667
avg_envstep_per_sec: 2574.195369055663
avg_train_sample_per_sec: 2574.195369055663
avg_episode_per_sec: 9.74458814784478
collect_time: 0.6157263815533369
reward_mean: 2116.937183602818
reward_std: 853.6241957396585
reward_max: 3515.6330922440065
reward_min: 1256.832117741337
total_envstep_count: 20817793
total_train_sample_count: 15621725
total_episode_count: 46112
total_duration: 4150.7843133006145
[2023-06-29 13:51:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2333
train_sample_count: 2333
avg_envstep_per_episode: 179.46153846153845
avg_sample_per_episode: 179.46153846153845
avg_envstep_per_sec: 2660.106804576198
avg_train_sample_per_sec: 2660.106804576198
avg_episode_per_sec: 14.822712584436596
collect_time: 0.8770324544813485
reward_mean: 1683.2474540687983
reward_std: 1283.2670177228745
reward_max: 3612.0805701109293
reward_min: 22.618510113442653
total_envstep_count: 20822393
total_train_sample_count: 15625258
total_episode_count: 46125
total_duration: 4151.661345755096
[2023-06-29 13:51:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 187.4
avg_sample_per_episode: 187.4
avg_envstep_per_sec: 2743.518142640515
avg_train_sample_per_sec: 2743.518142640515
avg_episode_per_sec: 14.639904709928043
collect_time: 0.34153227763902405
reward_mean: 2315.3427773763246
reward_std: 834.4605393555618
reward_max: 3518.8851741750354
reward_min: 1321.9683552425656
total_envstep_count: 20826905
total_train_sample_count: 15628595
total_episode_count: 46130
total_duration: 4152.002878032735
[2023-06-29 13:51:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3258
train_sample_count: 3258
avg_envstep_per_episode: 362.0
avg_sample_per_episode: 362.0
avg_envstep_per_sec: 2780.503285665494
avg_train_sample_per_sec: 2780.503285665494
avg_episode_per_sec: 7.680948302943353
collect_time: 1.1717303183190524
reward_mean: 2878.051772520619
reward_std: 868.6230128716749
reward_max: 3552.2854466250474
reward_min: 1221.9033637587931
total_envstep_count: 20831225
total_train_sample_count: 15631853
total_episode_count: 46139
total_duration: 4153.174608351053
[2023-06-29 13:51:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3406
train_sample_count: 3406
avg_envstep_per_episode: 340.6
avg_sample_per_episode: 340.6
avg_envstep_per_sec: 2756.881175752772
avg_train_sample_per_sec: 2756.881175752772
avg_episode_per_sec: 8.094190181305848
collect_time: 1.2354540449390188
reward_mean: 1647.9793523163212
reward_std: 466.0295066235453
reward_max: 2545.9984041269595
reward_min: 866.5927130190261
total_envstep_count: 20835977
total_train_sample_count: 15635259
total_episode_count: 46149
total_duration: 4154.410062395992
[2023-06-29 13:51:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2127
train_sample_count: 2127
avg_envstep_per_episode: 193.36363636363637
avg_sample_per_episode: 193.36363636363637
avg_envstep_per_sec: 2631.3907149570337
avg_train_sample_per_sec: 2631.3907149570337
avg_episode_per_sec: 13.608508634004405
collect_time: 0.8083178176125512
reward_mean: 1149.1333915590803
reward_std: 604.5945405452072
reward_max: 1981.8287960193882
reward_min: 20.858806804026713
total_envstep_count: 20840161
total_train_sample_count: 15638586
total_episode_count: 46160
total_duration: 4155.218380213605
[2023-06-29 13:51:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 232.57142857142858
avg_sample_per_episode: 232.57142857142858
avg_envstep_per_sec: 2742.08569543942
avg_train_sample_per_sec: 2742.08569543942
avg_episode_per_sec: 11.790294759260405
collect_time: 0.5937086513042448
reward_mean: 1883.4810479507573
reward_std: 504.8369344237983
reward_max: 2428.534528156103
reward_min: 953.6667892515098
total_envstep_count: 20844713
total_train_sample_count: 15641814
total_episode_count: 46167
total_duration: 4155.812088864909
[2023-06-29 13:51:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2778
train_sample_count: 2778
avg_envstep_per_episode: 308.6666666666667
avg_sample_per_episode: 308.6666666666667
avg_envstep_per_sec: 2767.413877505456
avg_train_sample_per_sec: 2767.413877505456
avg_episode_per_sec: 8.965703706821133
collect_time: 1.003825276219286
reward_mean: 2187.3721411699757
reward_std: 843.9818137289867
reward_max: 3509.9349776218282
reward_min: 1364.8341407429252
total_envstep_count: 20849193
total_train_sample_count: 15645392
total_episode_count: 46176
total_duration: 4156.815914141129
[2023-06-29 13:51:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1874
train_sample_count: 1874
avg_envstep_per_episode: 312.3333333333333
avg_sample_per_episode: 312.3333333333333
avg_envstep_per_sec: 2771.2727263919182
avg_train_sample_per_sec: 2771.2727263919182
avg_episode_per_sec: 8.87280488706057
collect_time: 0.6762235929192975
reward_mean: 2231.5166635674996
reward_std: 817.8924924588739
reward_max: 3481.14823303218
reward_min: 1002.7537641519199
total_envstep_count: 20853417
total_train_sample_count: 15648866
total_episode_count: 46182
total_duration: 4157.492137734048
[2023-06-29 13:51:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1875
train_sample_count: 1875
avg_envstep_per_episode: 267.85714285714283
avg_sample_per_episode: 267.85714285714283
avg_envstep_per_sec: 2423.452036681977
avg_train_sample_per_sec: 2423.452036681977
avg_episode_per_sec: 9.047554270279381
collect_time: 0.7736897498359903
reward_mean: 2178.9767047986074
reward_std: 1259.002790908339
reward_max: 3487.79992779607
reward_min: 22.81608218694616
total_envstep_count: 20857689
total_train_sample_count: 15652341
total_episode_count: 46189
total_duration: 4158.265827483884
[2023-06-29 13:51:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2052
train_sample_count: 2052
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2737.275744278349
avg_train_sample_per_sec: 2737.275744278349
avg_episode_per_sec: 12.005595369641883
collect_time: 0.7496504523847253
reward_mean: 1922.649208324275
reward_std: 542.3832167962811
reward_max: 2657.5936894333154
reward_min: 990.9203622267718
total_envstep_count: 20862081
total_train_sample_count: 15655593
total_episode_count: 46198
total_duration: 4159.015477936269
[2023-06-29 13:51:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2999
train_sample_count: 2999
avg_envstep_per_episode: 272.6363636363636
avg_sample_per_episode: 272.6363636363636
avg_envstep_per_sec: 2739.126961845853
avg_train_sample_per_sec: 2739.126961845853
avg_episode_per_sec: 10.046814464923102
collect_time: 1.0948744040615856
reward_mean: 1802.2576830811513
reward_std: 592.5075314082275
reward_max: 2964.270813168653
reward_min: 1232.3647238858885
total_envstep_count: 20866825
total_train_sample_count: 15658992
total_episode_count: 46209
total_duration: 4160.110352340331
[2023-06-29 13:52:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2586
train_sample_count: 2586
avg_envstep_per_episode: 323.25
avg_sample_per_episode: 323.25
avg_envstep_per_sec: 2612.0309047631386
avg_train_sample_per_sec: 2612.0309047631386
avg_episode_per_sec: 8.080528707697257
collect_time: 0.9900342278815806
reward_mean: 1849.9240380687093
reward_std: 737.6273840784448
reward_max: 3492.6687851631355
reward_min: 1032.8488456418233
total_envstep_count: 20872065
total_train_sample_count: 15662378
total_episode_count: 46217
total_duration: 4161.100386568212
[2023-06-29 13:52:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1297
train_sample_count: 1297
avg_envstep_per_episode: 216.16666666666666
avg_sample_per_episode: 216.16666666666666
avg_envstep_per_sec: 2382.5587116205843
avg_train_sample_per_sec: 2382.5587116205843
avg_episode_per_sec: 11.021859884135317
collect_time: 0.5443727341005579
reward_mean: 2208.5070163031246
reward_std: 975.7686993096193
reward_max: 3546.1009012501377
reward_min: 1245.1415477320504
total_envstep_count: 20875961
total_train_sample_count: 15665675
total_episode_count: 46223
total_duration: 4161.644759302313
[2023-06-29 13:52:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2232
train_sample_count: 2232
avg_envstep_per_episode: 223.2
avg_sample_per_episode: 223.2
avg_envstep_per_sec: 2677.8365014046244
avg_train_sample_per_sec: 2677.8365014046244
avg_episode_per_sec: 11.99747536471606
collect_time: 0.8335086921211333
reward_mean: 1827.8509835981208
reward_std: 1070.4964022189445
reward_max: 3496.333121563899
reward_min: 20.931693728819287
total_envstep_count: 20881041
total_train_sample_count: 15669107
total_episode_count: 46233
total_duration: 4162.478267994435
[2023-06-29 13:52:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1924
train_sample_count: 1924
avg_envstep_per_episode: 213.77777777777777
avg_sample_per_episode: 213.77777777777777
avg_envstep_per_sec: 2749.9044188080943
avg_train_sample_per_sec: 2749.9044188080943
avg_episode_per_sec: 12.863378258457821
collect_time: 0.6996606816006825
reward_mean: 1962.8517946010334
reward_std: 826.5294248303345
reward_max: 3486.878465382958
reward_min: 1306.5764388577281
total_envstep_count: 20885713
total_train_sample_count: 15672631
total_episode_count: 46242
total_duration: 4163.177928676036
[2023-06-29 13:52:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2811
train_sample_count: 2811
avg_envstep_per_episode: 281.1
avg_sample_per_episode: 281.1
avg_envstep_per_sec: 2793.505617455263
avg_train_sample_per_sec: 2793.505617455263
avg_episode_per_sec: 9.937764558716694
collect_time: 1.006262519192882
reward_mean: 2054.2301658923766
reward_std: 973.8467092376421
reward_max: 3571.8042249759374
reward_min: 970.289389183587
total_envstep_count: 20889961
total_train_sample_count: 15675842
total_episode_count: 46252
total_duration: 4164.184191195229
[2023-06-29 13:52:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2289
train_sample_count: 2289
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 2546.705299197633
avg_train_sample_per_sec: 2546.705299197633
avg_episode_per_sec: 10.01325805713355
collect_time: 0.8988083547480638
reward_mean: 1506.5964481872797
reward_std: 372.31646000619173
reward_max: 2160.5520066610466
reward_min: 1069.2884365914256
total_envstep_count: 20894377
total_train_sample_count: 15679331
total_episode_count: 46261
total_duration: 4165.082999549977
[2023-06-29 13:52:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3511
train_sample_count: 3511
avg_envstep_per_episode: 292.5833333333333
avg_sample_per_episode: 292.5833333333333
avg_envstep_per_sec: 2555.660001680095
avg_train_sample_per_sec: 2555.660001680095
avg_episode_per_sec: 8.73481060101428
collect_time: 1.3738134171571583
reward_mean: 1771.878591236736
reward_std: 569.3432548880552
reward_max: 2750.2636534729645
reward_min: 1053.7803489183405
total_envstep_count: 20899673
total_train_sample_count: 15682842
total_episode_count: 46273
total_duration: 4166.456812967134
[2023-06-29 13:52:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2906
train_sample_count: 2906
avg_envstep_per_episode: 207.57142857142858
avg_sample_per_episode: 207.57142857142858
avg_envstep_per_sec: 2767.6112093358397
avg_train_sample_per_sec: 2767.6112093358397
avg_episode_per_sec: 13.33329557147342
collect_time: 1.0500029737548904
reward_mean: 1240.3378071177008
reward_std: 434.4165071315586
reward_max: 1942.9949888064152
reward_min: 18.808732409315574
total_envstep_count: 20903953
total_train_sample_count: 15686148
total_episode_count: 46287
total_duration: 4167.506815940889
[2023-06-29 13:52:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2977
train_sample_count: 2977
avg_envstep_per_episode: 212.64285714285714
avg_sample_per_episode: 212.64285714285714
avg_envstep_per_sec: 2669.543361225067
avg_train_sample_per_sec: 2669.543361225067
avg_episode_per_sec: 12.55411725131036
collect_time: 1.1151719965446971
reward_mean: 1134.3257201006759
reward_std: 379.36359381125266
reward_max: 1896.4490441452672
reward_min: 22.643986765647306
total_envstep_count: 20908793
total_train_sample_count: 15689525
total_episode_count: 46301
total_duration: 4168.621987937434
[2023-06-29 13:52:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3366
train_sample_count: 3366
avg_envstep_per_episode: 224.4
avg_sample_per_episode: 224.4
avg_envstep_per_sec: 2543.9261260909143
avg_train_sample_per_sec: 2543.9261260909143
avg_episode_per_sec: 11.336569189353451
collect_time: 1.3231516298676145
reward_mean: 1274.6506311386356
reward_std: 271.7381253673497
reward_max: 1829.0162777760793
reward_min: 835.5038769073567
total_envstep_count: 20913329
total_train_sample_count: 15692891
total_episode_count: 46316
total_duration: 4169.945139567301
[2023-06-29 13:52:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3486
train_sample_count: 3486
avg_envstep_per_episode: 268.15384615384613
avg_sample_per_episode: 268.15384615384613
avg_envstep_per_sec: 2605.2501825930317
avg_train_sample_per_sec: 2605.2501825930317
avg_episode_per_sec: 9.71550555757585
collect_time: 1.3380672701960428
reward_mean: 1312.2319571690819
reward_std: 288.3772027823959
reward_max: 1849.9145508290862
reward_min: 873.5568121991732
total_envstep_count: 20917881
total_train_sample_count: 15696377
total_episode_count: 46329
total_duration: 4171.283206837497
[2023-06-29 13:52:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3241
train_sample_count: 3241
avg_envstep_per_episode: 294.6363636363636
avg_sample_per_episode: 294.6363636363636
avg_envstep_per_sec: 2553.0979653234394
avg_train_sample_per_sec: 2553.0979653234394
avg_episode_per_sec: 8.66525073081081
collect_time: 1.2694381665019319
reward_mean: 1448.9746667629263
reward_std: 280.55226199113287
reward_max: 1958.9146984085148
reward_min: 1018.7637036042328
total_envstep_count: 20922041
total_train_sample_count: 15699618
total_episode_count: 46340
total_duration: 4172.552645004
[2023-06-29 13:52:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3379
train_sample_count: 3379
avg_envstep_per_episode: 241.35714285714286
avg_sample_per_episode: 241.35714285714286
avg_envstep_per_sec: 2551.666468764928
avg_train_sample_per_sec: 2551.666468764928
avg_episode_per_sec: 10.572160569017163
collect_time: 1.3242326304642482
reward_mean: 1113.4883121176138
reward_std: 206.40629238021143
reward_max: 1535.5400104901873
reward_min: 787.7236163888791
total_envstep_count: 20926713
total_train_sample_count: 15702997
total_episode_count: 46354
total_duration: 4173.876877634464
[2023-06-29 13:52:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3406
train_sample_count: 3406
avg_envstep_per_episode: 283.8333333333333
avg_sample_per_episode: 283.8333333333333
avg_envstep_per_sec: 2692.8331005923665
avg_train_sample_per_sec: 2692.8331005923665
avg_episode_per_sec: 9.487374400207985
collect_time: 1.2648388788932934
reward_mean: 1442.177599064936
reward_std: 356.199677596106
reward_max: 2022.7966764099103
reward_min: 761.3699267965274
total_envstep_count: 20931329
total_train_sample_count: 15706403
total_episode_count: 46366
total_duration: 4175.141716513357
[2023-06-29 13:52:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3396
train_sample_count: 3396
avg_envstep_per_episode: 242.57142857142858
avg_sample_per_episode: 242.57142857142858
avg_envstep_per_sec: 2499.06050697506
avg_train_sample_per_sec: 2499.06050697506
avg_episode_per_sec: 10.30236958116927
collect_time: 1.3589106748402116
reward_mean: 1207.5045350203297
reward_std: 227.37573051730035
reward_max: 1663.1210912933602
reward_min: 929.232240159986
total_envstep_count: 20935489
total_train_sample_count: 15709799
total_episode_count: 46380
total_duration: 4176.5006271881975
[2023-06-29 13:52:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 256.46153846153845
avg_sample_per_episode: 256.46153846153845
avg_envstep_per_sec: 2192.009634020308
avg_train_sample_per_sec: 2192.009634020308
avg_episode_per_sec: 8.547128147049792
collect_time: 1.5209787166332829
reward_mean: 1159.1862305780987
reward_std: 249.81671554874958
reward_max: 1572.8563109627487
reward_min: 678.1489546824466
total_envstep_count: 20940153
total_train_sample_count: 15713133
total_episode_count: 46393
total_duration: 4178.021605904831
[2023-06-29 13:52:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2797
train_sample_count: 2797
avg_envstep_per_episode: 254.27272727272728
avg_sample_per_episode: 254.27272727272728
avg_envstep_per_sec: 2477.9141024969804
avg_train_sample_per_sec: 2477.9141024969804
avg_episode_per_sec: 9.745103728089662
collect_time: 1.12877197687421
reward_mean: 1396.406669905301
reward_std: 407.8075406941799
reward_max: 2084.0753171721767
reward_min: 817.2609250377603
total_envstep_count: 20944897
total_train_sample_count: 15716730
total_episode_count: 46404
total_duration: 4179.150377881705
[2023-06-29 13:52:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3366
train_sample_count: 3366
avg_envstep_per_episode: 224.4
avg_sample_per_episode: 224.4
avg_envstep_per_sec: 2597.7751066062538
avg_train_sample_per_sec: 2597.7751066062538
avg_episode_per_sec: 11.576537908227513
collect_time: 1.2957241723658515
reward_mean: 1293.1996052979603
reward_std: 354.53413956485406
reward_max: 1829.8037555230412
reward_min: 711.8521682856311
total_envstep_count: 20949809
total_train_sample_count: 15720096
total_episode_count: 46419
total_duration: 4180.446102054071
[2023-06-29 13:52:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2981
train_sample_count: 2981
avg_envstep_per_episode: 212.92857142857142
avg_sample_per_episode: 212.92857142857142
avg_envstep_per_sec: 2496.0112800094944
avg_train_sample_per_sec: 2496.0112800094944
avg_episode_per_sec: 11.722293834328386
collect_time: 1.1943055000891907
reward_mean: 1195.7288582214053
reward_std: 258.26613359100423
reward_max: 1612.11783227217
reward_min: 773.3445778649484
total_envstep_count: 20954265
total_train_sample_count: 15723477
total_episode_count: 46433
total_duration: 4181.64040755416
[2023-06-29 13:53:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3472
train_sample_count: 3472
avg_envstep_per_episode: 231.46666666666667
avg_sample_per_episode: 231.46666666666667
avg_envstep_per_sec: 2521.2425579076767
avg_train_sample_per_sec: 2521.2425579076767
avg_episode_per_sec: 10.892464967919109
collect_time: 1.3770987599389628
reward_mean: 1222.6337769812683
reward_std: 360.09894438719704
reward_max: 1967.9455274069426
reward_min: 661.3941085165964
total_envstep_count: 20959137
total_train_sample_count: 15726949
total_episode_count: 46448
total_duration: 4183.0175063141
[2023-06-29 13:53:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2886
train_sample_count: 2886
avg_envstep_per_episode: 262.3636363636364
avg_sample_per_episode: 262.3636363636364
avg_envstep_per_sec: 2470.3429462459612
avg_train_sample_per_sec: 2470.3429462459612
avg_episode_per_sec: 9.415721555338036
collect_time: 1.1682588461596755
reward_mean: 1449.4926438914074
reward_std: 284.58574573541847
reward_max: 2174.4732174914116
reward_min: 1103.4152394327803
total_envstep_count: 20963777
total_train_sample_count: 15730235
total_episode_count: 46459
total_duration: 4184.1857651602595
[2023-06-29 13:53:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3326
train_sample_count: 3326
avg_envstep_per_episode: 221.73333333333332
avg_sample_per_episode: 221.73333333333332
avg_envstep_per_sec: 2650.2978355926725
avg_train_sample_per_sec: 2650.2978355926725
avg_episode_per_sec: 11.952636059497921
collect_time: 1.2549532944308592
reward_mean: 1249.6980392287162
reward_std: 343.41023316680156
reward_max: 1742.8399863609704
reward_min: 164.0163240252123
total_envstep_count: 20968209
total_train_sample_count: 15733561
total_episode_count: 46474
total_duration: 4185.440718454691
[2023-06-29 13:53:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2900
train_sample_count: 2900
avg_envstep_per_episode: 207.14285714285714
avg_sample_per_episode: 207.14285714285714
avg_envstep_per_sec: 2531.6020843392544
avg_train_sample_per_sec: 2531.6020843392544
avg_episode_per_sec: 12.221527303706745
collect_time: 1.1455196762317792
reward_mean: 1036.6840626998453
reward_std: 189.4901313028495
reward_max: 1312.1244426930152
reward_min: 552.0149472591326
total_envstep_count: 20972337
total_train_sample_count: 15736861
total_episode_count: 46488
total_duration: 4186.5862381309225
[2023-06-29 13:53:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2885
train_sample_count: 2885
avg_envstep_per_episode: 221.92307692307693
avg_sample_per_episode: 221.92307692307693
avg_envstep_per_sec: 2611.159108942808
avg_train_sample_per_sec: 2611.159108942808
avg_episode_per_sec: 11.766054910314212
collect_time: 1.1048733070762828
reward_mean: 1151.209643956674
reward_std: 422.9497152232967
reward_max: 1993.4829706705093
reward_min: 138.94303120099383
total_envstep_count: 20976737
total_train_sample_count: 15740146
total_episode_count: 46501
total_duration: 4187.691111437999
[2023-06-29 13:53:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2846
train_sample_count: 2846
avg_envstep_per_episode: 237.16666666666666
avg_sample_per_episode: 237.16666666666666
avg_envstep_per_sec: 2689.1742702162824
avg_train_sample_per_sec: 2689.1742702162824
avg_episode_per_sec: 11.338753071888751
collect_time: 1.0583174290787427
reward_mean: 1339.166905931025
reward_std: 680.1221803877637
reward_max: 3404.293425555115
reward_min: 767.0871559244623
total_envstep_count: 20981041
total_train_sample_count: 15743392
total_episode_count: 46513
total_duration: 4188.749428867078
[2023-06-29 13:53:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3373
train_sample_count: 3373
avg_envstep_per_episode: 224.86666666666667
avg_sample_per_episode: 224.86666666666667
avg_envstep_per_sec: 2829.3440913158656
avg_train_sample_per_sec: 2829.3440913158656
avg_episode_per_sec: 12.582318816999106
collect_time: 1.1921490957401693
reward_mean: 1191.6866066872137
reward_std: 256.60540458525657
reward_max: 1867.5387937682615
reward_min: 850.7655451458122
total_envstep_count: 20985881
total_train_sample_count: 15746765
total_episode_count: 46528
total_duration: 4189.941577962818
[2023-06-29 13:53:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2991
train_sample_count: 2991
avg_envstep_per_episode: 230.07692307692307
avg_sample_per_episode: 230.07692307692307
avg_envstep_per_sec: 2615.2319694374214
avg_train_sample_per_sec: 2615.2319694374214
avg_episode_per_sec: 11.366772184114502
collect_time: 1.1436843977719546
reward_mean: 1269.1737669838308
reward_std: 252.05663519541312
reward_max: 1822.0860658822821
reward_min: 944.2075018790646
total_envstep_count: 20990553
total_train_sample_count: 15750156
total_episode_count: 46541
total_duration: 4191.08526236059
[2023-06-29 13:53:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 223.84615384615384
avg_sample_per_episode: 223.84615384615384
avg_envstep_per_sec: 2565.8312687947805
avg_train_sample_per_sec: 2565.8312687947805
avg_episode_per_sec: 11.462476458533382
collect_time: 1.1341353717958556
reward_mean: 1303.272188876198
reward_std: 314.9569340175271
reward_max: 1998.1466352079506
reward_min: 795.1169937550062
total_envstep_count: 20995177
total_train_sample_count: 15753466
total_episode_count: 46554
total_duration: 4192.219397732386
[2023-06-29 13:53:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3535
train_sample_count: 3535
avg_envstep_per_episode: 252.5
avg_sample_per_episode: 252.5
avg_envstep_per_sec: 2687.6190852728446
avg_train_sample_per_sec: 2687.6190852728446
avg_episode_per_sec: 10.644035981278593
collect_time: 1.3152905556336045
reward_mean: 1388.0033699037692
reward_std: 334.1421557624242
reward_max: 2131.6238468717384
reward_min: 898.9564551418109
total_envstep_count: 21000001
total_train_sample_count: 15757001
total_episode_count: 46568
total_duration: 4193.534688288019
[2023-06-29 13:53:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3007
train_sample_count: 3007
avg_envstep_per_episode: 250.58333333333334
avg_sample_per_episode: 250.58333333333334
avg_envstep_per_sec: 2655.467589617718
avg_train_sample_per_sec: 2655.467589617718
avg_episode_per_sec: 10.597143689861197
collect_time: 1.1323806066233664
reward_mean: 1330.2416814774163
reward_std: 348.01514112844984
reward_max: 2222.222141294352
reward_min: 922.1828255357398
total_envstep_count: 21004257
total_train_sample_count: 15760408
total_episode_count: 46580
total_duration: 4194.667068894642
[2023-06-29 13:53:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 256.46153846153845
avg_sample_per_episode: 256.46153846153845
avg_envstep_per_sec: 2755.7532521590306
avg_train_sample_per_sec: 2755.7532521590306
avg_episode_per_sec: 10.74528862569508
collect_time: 1.2098325557224452
reward_mean: 1295.1688758990663
reward_std: 319.72884448994654
reward_max: 1949.134409516072
reward_min: 710.886128098133
total_envstep_count: 21008793
total_train_sample_count: 15763742
total_episode_count: 46593
total_duration: 4195.876901450365
[2023-06-29 13:53:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3393
train_sample_count: 3393
avg_envstep_per_episode: 242.35714285714286
avg_sample_per_episode: 242.35714285714286
avg_envstep_per_sec: 2640.9652459396275
avg_train_sample_per_sec: 2640.9652459396275
avg_episode_per_sec: 10.896997772813082
collect_time: 1.2847575352294371
reward_mean: 1204.3075187917595
reward_std: 223.07383944935523
reward_max: 1675.197766335508
reward_min: 964.2205899470862
total_envstep_count: 21013377
total_train_sample_count: 15767135
total_episode_count: 46607
total_duration: 4197.161658985595
[2023-06-29 13:53:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 2535.326221144157
avg_train_sample_per_sec: 2535.326221144157
avg_episode_per_sec: 10.834727440786995
collect_time: 1.2921414107102902
reward_mean: 1173.2879210839653
reward_std: 655.0740877196461
reward_max: 2046.5979923486245
reward_min: 11.5511570499419
total_envstep_count: 21018369
total_train_sample_count: 15770411
total_episode_count: 46621
total_duration: 4198.453800396305
[2023-06-29 13:53:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2934
train_sample_count: 2934
avg_envstep_per_episode: 266.72727272727275
avg_sample_per_episode: 266.72727272727275
avg_envstep_per_sec: 2730.479350926766
avg_train_sample_per_sec: 2730.479350926766
avg_episode_per_sec: 10.236970981661358
collect_time: 1.0745366006903352
reward_mean: 1529.6710639301282
reward_std: 526.8183705644915
reward_max: 2846.7844078796234
reward_min: 1032.4443981231218
total_envstep_count: 21022761
total_train_sample_count: 15773745
total_episode_count: 46632
total_duration: 4199.528336996996
[2023-06-29 13:53:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2973
train_sample_count: 2973
avg_envstep_per_episode: 270.27272727272725
avg_sample_per_episode: 270.27272727272725
avg_envstep_per_sec: 2709.4652313117194
avg_train_sample_per_sec: 2709.4652313117194
avg_episode_per_sec: 10.024930220124089
collect_time: 1.097264495459385
reward_mean: 1486.74660804682
reward_std: 668.6179736343853
reward_max: 3491.6303292517837
reward_min: 1086.2623814243068
total_envstep_count: 21027257
total_train_sample_count: 15777118
total_episode_count: 46643
total_duration: 4200.625601492455
[2023-06-29 13:53:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2108
train_sample_count: 2108
avg_envstep_per_episode: 210.8
avg_sample_per_episode: 210.8
avg_envstep_per_sec: 2483.2074981690507
avg_train_sample_per_sec: 2483.2074981690507
avg_episode_per_sec: 11.7799217180695
collect_time: 0.848902075865306
reward_mean: 1345.4438859506517
reward_std: 296.7881759721671
reward_max: 2044.583895791002
reward_min: 1091.3127047998703
total_envstep_count: 21032345
total_train_sample_count: 15780426
total_episode_count: 46653
total_duration: 4201.47450356832
[2023-06-29 13:53:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2705
train_sample_count: 2705
avg_envstep_per_episode: 180.33333333333334
avg_sample_per_episode: 180.33333333333334
avg_envstep_per_sec: 2599.2602946082384
avg_train_sample_per_sec: 2599.2602946082384
avg_episode_per_sec: 14.413643038493005
collect_time: 1.0406806911993778
reward_mean: 1391.0890131175515
reward_std: 628.802477295959
reward_max: 2312.262587676556
reward_min: 25.924631897993383
total_envstep_count: 21036689
total_train_sample_count: 15783931
total_episode_count: 46668
total_duration: 4202.51518425952
[2023-06-29 13:53:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3282
train_sample_count: 3282
avg_envstep_per_episode: 252.46153846153845
avg_sample_per_episode: 252.46153846153845
avg_envstep_per_sec: 2578.9654210195536
avg_train_sample_per_sec: 2578.9654210195536
avg_episode_per_sec: 10.21528046107684
collect_time: 1.272603336690925
reward_mean: 1407.3749297880036
reward_std: 558.8152144599078
reward_max: 3194.114749888864
reward_min: 1041.7239286454915
total_envstep_count: 21041337
total_train_sample_count: 15787213
total_episode_count: 46681
total_duration: 4203.78778759621
[2023-06-29 13:53:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3120
train_sample_count: 3120
avg_envstep_per_episode: 222.85714285714286
avg_sample_per_episode: 222.85714285714286
avg_envstep_per_sec: 2721.5624821003235
avg_train_sample_per_sec: 2721.5624821003235
avg_episode_per_sec: 12.212139342757862
collect_time: 1.1464002831168472
reward_mean: 1185.795785274256
reward_std: 114.55227969999811
reward_max: 1443.3780599022546
reward_min: 1022.7278932915445
total_envstep_count: 21046121
total_train_sample_count: 15790733
total_episode_count: 46695
total_duration: 4204.9341878793275
[2023-06-29 13:54:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3356
train_sample_count: 3356
avg_envstep_per_episode: 279.6666666666667
avg_sample_per_episode: 279.6666666666667
avg_envstep_per_sec: 2780.976462388641
avg_train_sample_per_sec: 2780.976462388641
avg_episode_per_sec: 9.94389676658632
collect_time: 1.2067703719856222
reward_mean: 1539.6126318333063
reward_std: 522.8748475019243
reward_max: 2966.3596804817307
reward_min: 1068.399956044782
total_envstep_count: 21050721
total_train_sample_count: 15794089
total_episode_count: 46707
total_duration: 4206.140958251313
[2023-06-29 13:54:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3439
train_sample_count: 3439
avg_envstep_per_episode: 264.53846153846155
avg_sample_per_episode: 264.53846153846155
avg_envstep_per_sec: 2633.146244357424
avg_train_sample_per_sec: 2633.146244357424
avg_episode_per_sec: 9.953736893470927
collect_time: 1.3060421567428857
reward_mean: 1330.4488103081303
reward_std: 280.7588713484206
reward_max: 1987.606603243789
reward_min: 931.8378680470786
total_envstep_count: 21055249
total_train_sample_count: 15797528
total_episode_count: 46720
total_duration: 4207.447000408056
[2023-06-29 13:54:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3445
train_sample_count: 3445
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 2688.785142348785
avg_train_sample_per_sec: 2688.785142348785
avg_episode_per_sec: 10.146359027731265
collect_time: 1.2812477820338684
reward_mean: 1284.8788094782233
reward_std: 282.8451695185889
reward_max: 2093.13646097625
reward_min: 998.0753528293081
total_envstep_count: 21059985
total_train_sample_count: 15800973
total_episode_count: 46733
total_duration: 4208.728248190089
[2023-06-29 13:54:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 247.33333333333334
avg_sample_per_episode: 247.33333333333334
avg_envstep_per_sec: 2566.5866664093337
avg_train_sample_per_sec: 2566.5866664093337
avg_episode_per_sec: 10.377035039390837
collect_time: 1.1563996801059695
reward_mean: 1307.4404827723433
reward_std: 234.67923338046637
reward_max: 1701.94142760289
reward_min: 947.6592554908021
total_envstep_count: 21064617
total_train_sample_count: 15804341
total_episode_count: 46745
total_duration: 4209.884647870195
[2023-06-29 13:54:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3454
train_sample_count: 3454
avg_envstep_per_episode: 246.71428571428572
avg_sample_per_episode: 246.71428571428572
avg_envstep_per_sec: 2703.1058381490207
avg_train_sample_per_sec: 2703.1058381490207
avg_episode_per_sec: 10.956422042294815
collect_time: 1.2777894047852605
reward_mean: 1356.6110600120574
reward_std: 542.695861886076
reward_max: 3227.2433545659223
reward_min: 985.3129370775713
total_envstep_count: 21069193
total_train_sample_count: 15807795
total_episode_count: 46759
total_duration: 4211.16243727498
[2023-06-29 13:54:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3026
train_sample_count: 3026
avg_envstep_per_episode: 232.76923076923077
avg_sample_per_episode: 232.76923076923077
avg_envstep_per_sec: 2550.3234279174812
avg_train_sample_per_sec: 2550.3234279174812
avg_episode_per_sec: 10.956445658601208
collect_time: 1.1865161755075677
reward_mean: 1174.879049379268
reward_std: 177.2552809473125
reward_max: 1433.8239735729412
reward_min: 871.0416313178397
total_envstep_count: 21073177
total_train_sample_count: 15811221
total_episode_count: 46772
total_duration: 4212.348953450488
[2023-06-29 13:54:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3368
train_sample_count: 3368
avg_envstep_per_episode: 280.6666666666667
avg_sample_per_episode: 280.6666666666667
avg_envstep_per_sec: 2480.310721945054
avg_train_sample_per_sec: 2480.310721945054
avg_episode_per_sec: 8.837211598379051
collect_time: 1.3578943840386346
reward_mean: 1311.9965297777428
reward_std: 318.1143432651622
reward_max: 1885.64178820636
reward_min: 917.7169710482256
total_envstep_count: 21077945
total_train_sample_count: 15814589
total_episode_count: 46784
total_duration: 4213.706847834526
[2023-06-29 13:54:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3049
train_sample_count: 3049
avg_envstep_per_episode: 217.78571428571428
avg_sample_per_episode: 217.78571428571428
avg_envstep_per_sec: 2481.706900045852
avg_train_sample_per_sec: 2481.706900045852
avg_episode_per_sec: 11.395177632221031
collect_time: 1.2285898870425298
reward_mean: 1166.2236062826544
reward_std: 272.08208941242424
reward_max: 1960.9630881360993
reward_min: 894.2159170427195
total_envstep_count: 21082209
total_train_sample_count: 15818038
total_episode_count: 46798
total_duration: 4214.935437721569
[2023-06-29 13:54:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2869
train_sample_count: 2869
avg_envstep_per_episode: 239.08333333333334
avg_sample_per_episode: 239.08333333333334
avg_envstep_per_sec: 2552.6890691628982
avg_train_sample_per_sec: 2552.6890691628982
avg_episode_per_sec: 10.676984604376011
collect_time: 1.1239128316324203
reward_mean: 1251.5674485066797
reward_std: 245.16177821597267
reward_max: 1849.9466594688943
reward_min: 906.5247947755316
total_envstep_count: 21086793
total_train_sample_count: 15821307
total_episode_count: 46810
total_duration: 4216.059350553201
[2023-06-29 13:54:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3184
train_sample_count: 3184
avg_envstep_per_episode: 227.42857142857142
avg_sample_per_episode: 227.42857142857142
avg_envstep_per_sec: 2683.908547670831
avg_train_sample_per_sec: 2683.908547670831
avg_episode_per_sec: 11.801105423175764
collect_time: 1.1863295426974074
reward_mean: 1287.9975798317755
reward_std: 461.8629064165847
reward_max: 2625.1412995561977
reward_min: 671.0882961056128
total_envstep_count: 21091537
total_train_sample_count: 15824891
total_episode_count: 46824
total_duration: 4217.245680095898
[2023-06-29 13:54:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3362
train_sample_count: 3362
avg_envstep_per_episode: 258.61538461538464
avg_sample_per_episode: 258.61538461538464
avg_envstep_per_sec: 2622.6883174770855
avg_train_sample_per_sec: 2622.6883174770855
avg_episode_per_sec: 10.141269520286173
collect_time: 1.2818907902995125
reward_mean: 1396.7482574052601
reward_std: 380.8438774431732
reward_max: 2111.357111907879
reward_min: 847.6393813382185
total_envstep_count: 21095505
total_train_sample_count: 15828253
total_episode_count: 46837
total_duration: 4218.527570886197
[2023-06-29 13:54:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2922
train_sample_count: 2922
avg_envstep_per_episode: 265.6363636363636
avg_sample_per_episode: 265.6363636363636
avg_envstep_per_sec: 2502.784650833084
avg_train_sample_per_sec: 2502.784650833084
avg_episode_per_sec: 9.421845023670064
collect_time: 1.1674995685415341
reward_mean: 1155.3657226227365
reward_std: 184.813769373771
reward_max: 1492.9004834997638
reward_min: 830.5808376696505
total_envstep_count: 21100185
total_train_sample_count: 15831575
total_episode_count: 46848
total_duration: 4219.695070454739
[2023-06-29 13:54:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 2718.8772786744885
avg_train_sample_per_sec: 2718.8772786744885
avg_episode_per_sec: 10.919185858130476
collect_time: 1.1905649531846865
reward_mean: 1401.1229845703028
reward_std: 443.2061969976407
reward_max: 2662.8736902919727
reward_min: 943.7843710335155
total_envstep_count: 21104257
total_train_sample_count: 15834812
total_episode_count: 46861
total_duration: 4220.8856354079235
[2023-06-29 13:54:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 262.61538461538464
avg_sample_per_episode: 262.61538461538464
avg_envstep_per_sec: 2355.379643421622
avg_train_sample_per_sec: 2355.379643421622
avg_episode_per_sec: 8.968932444194811
collect_time: 1.449447866943665
reward_mean: 1185.993885559337
reward_std: 176.30150244565476
reward_max: 1608.7986299635904
reward_min: 891.3690494583515
total_envstep_count: 21108497
total_train_sample_count: 15838226
total_episode_count: 46874
total_duration: 4222.335083274867
[2023-06-29 13:54:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2665
train_sample_count: 2665
avg_envstep_per_episode: 266.5
avg_sample_per_episode: 266.5
avg_envstep_per_sec: 2484.482384194371
avg_train_sample_per_sec: 2484.482384194371
avg_episode_per_sec: 9.322635587971375
collect_time: 1.0726580381306121
reward_mean: 1231.5927197304022
reward_std: 268.3634898625162
reward_max: 1889.2842774354538
reward_min: 767.5200443267953
total_envstep_count: 21113489
total_train_sample_count: 15841691
total_episode_count: 46884
total_duration: 4223.407741312998
[2023-06-29 13:54:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3255
train_sample_count: 3255
avg_envstep_per_episode: 232.5
avg_sample_per_episode: 232.5
avg_envstep_per_sec: 2576.1676626238423
avg_train_sample_per_sec: 2576.1676626238423
avg_episode_per_sec: 11.080291022038033
collect_time: 1.2635047195199876
reward_mean: 1433.4897328253176
reward_std: 685.1238499325627
reward_max: 3364.6340788072425
reward_min: 123.21959733653726
total_envstep_count: 21117737
total_train_sample_count: 15844946
total_episode_count: 46898
total_duration: 4224.671246032518
[2023-06-29 13:54:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3102
train_sample_count: 3102
avg_envstep_per_episode: 221.57142857142858
avg_sample_per_episode: 221.57142857142858
avg_envstep_per_sec: 2657.8874172058863
avg_train_sample_per_sec: 2657.8874172058863
avg_episode_per_sec: 11.995623417434691
collect_time: 1.167092322992743
reward_mean: 1044.9599094714767
reward_std: 194.55932005490476
reward_max: 1388.1731864121416
reward_min: 733.0808246548787
total_envstep_count: 21122913
total_train_sample_count: 15848448
total_episode_count: 46912
total_duration: 4225.838338355511
[2023-06-29 13:54:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2293
train_sample_count: 2293
avg_envstep_per_episode: 208.45454545454547
avg_sample_per_episode: 208.45454545454547
avg_envstep_per_sec: 2686.427959093325
avg_train_sample_per_sec: 2686.427959093325
avg_episode_per_sec: 12.887356105550186
collect_time: 0.8535497824307532
reward_mean: 1425.4918876227002
reward_std: 256.5623653742694
reward_max: 1935.4962290948488
reward_min: 1136.0440786013671
total_envstep_count: 21127161
total_train_sample_count: 15851941
total_episode_count: 46923
total_duration: 4226.6918881379415
[2023-06-29 13:54:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3025
train_sample_count: 3025
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2712.916036279975
avg_train_sample_per_sec: 2712.916036279975
avg_episode_per_sec: 9.865149222836273
collect_time: 1.1150363518614321
reward_mean: 1634.816761732079
reward_std: 562.5671281286297
reward_max: 2929.02168965539
reward_min: 900.5764840549141
total_envstep_count: 21131305
total_train_sample_count: 15855366
total_episode_count: 46934
total_duration: 4227.806924489803
[2023-06-29 13:54:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2522
train_sample_count: 2522
avg_envstep_per_episode: 252.2
avg_sample_per_episode: 252.2
avg_envstep_per_sec: 2639.733102778554
avg_train_sample_per_sec: 2639.733102778554
avg_episode_per_sec: 10.4668243567746
collect_time: 0.9553996187513695
reward_mean: 1128.3368702900282
reward_std: 342.8881001361271
reward_max: 1602.4060637508821
reward_min: 457.9417707190579
total_envstep_count: 21135161
total_train_sample_count: 15858688
total_episode_count: 46944
total_duration: 4228.762324108555
[2023-06-29 13:55:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 2565.499306960493
avg_train_sample_per_sec: 2565.499306960493
avg_episode_per_sec: 10.689580445668721
collect_time: 0.9354904105756433
reward_mean: 1480.513185061148
reward_std: 694.6513217908325
reward_max: 3374.8660782117795
reward_min: 996.3982849767074
total_envstep_count: 21140185
total_train_sample_count: 15861888
total_episode_count: 46954
total_duration: 4229.697814519131
[2023-06-29 13:55:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1271
train_sample_count: 1271
avg_envstep_per_episode: 158.875
avg_sample_per_episode: 158.875
avg_envstep_per_sec: 2764.64977791164
avg_train_sample_per_sec: 2764.64977791164
avg_episode_per_sec: 17.40141480982936
collect_time: 0.459732733655721
reward_mean: 1510.526962463035
reward_std: 442.3814981791394
reward_max: 2398.94220144454
reward_min: 879.2928743743931
total_envstep_count: 21144057
total_train_sample_count: 15865159
total_episode_count: 46962
total_duration: 4230.157547252787
[2023-06-29 13:55:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1632
train_sample_count: 1632
avg_envstep_per_episode: 204.0
avg_sample_per_episode: 204.0
avg_envstep_per_sec: 2512.907257430338
avg_train_sample_per_sec: 2512.907257430338
avg_episode_per_sec: 12.318172830540874
collect_time: 0.6494469683170317
reward_mean: 2045.0413171237076
reward_std: 822.0478214457931
reward_max: 3412.227234411117
reward_min: 1237.6787075018415
total_envstep_count: 21148633
total_train_sample_count: 15868391
total_episode_count: 46970
total_duration: 4230.806994221103
[2023-06-29 13:55:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2218
train_sample_count: 2218
avg_envstep_per_episode: 246.44444444444446
avg_sample_per_episode: 246.44444444444446
avg_envstep_per_sec: 2725.1609462182287
avg_train_sample_per_sec: 2725.1609462182287
avg_episode_per_sec: 11.057911864726806
collect_time: 0.8138968830732629
reward_mean: 2015.5578033795382
reward_std: 852.7608933066301
reward_max: 3380.3790778042885
reward_min: 955.9475658730737
total_envstep_count: 21153025
total_train_sample_count: 15871809
total_episode_count: 46979
total_duration: 4231.620891104177
[2023-06-29 13:55:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2337
train_sample_count: 2337
avg_envstep_per_episode: 292.125
avg_sample_per_episode: 292.125
avg_envstep_per_sec: 2694.6112639013677
avg_train_sample_per_sec: 2694.6112639013677
avg_episode_per_sec: 9.224172062991416
collect_time: 0.8672865104172379
reward_mean: 1979.4249868874276
reward_std: 854.5371284329323
reward_max: 3429.461975184273
reward_min: 1114.7381359353744
total_envstep_count: 21157569
total_train_sample_count: 15875346
total_episode_count: 46987
total_duration: 4232.488177614594
[2023-06-29 13:55:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 2733.1757876654447
avg_train_sample_per_sec: 2733.1757876654447
avg_episode_per_sec: 11.883372989849759
collect_time: 0.5890583427768432
reward_mean: 1598.2587667201258
reward_std: 817.6000157505157
reward_max: 3371.6195166448897
reward_min: 670.1750501068319
total_envstep_count: 21161617
total_train_sample_count: 15878556
total_episode_count: 46994
total_duration: 4233.077235957371
[2023-06-29 13:55:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1883
train_sample_count: 1883
avg_envstep_per_episode: 209.22222222222223
avg_sample_per_episode: 209.22222222222223
avg_envstep_per_sec: 2553.9020484382954
avg_train_sample_per_sec: 2553.9020484382954
avg_episode_per_sec: 12.206648133799606
collect_time: 0.737303140169941
reward_mean: 2094.559682612726
reward_std: 1188.5895967327308
reward_max: 3463.5729679733945
reward_min: 766.0398677894934
total_envstep_count: 21165977
total_train_sample_count: 15882039
total_episode_count: 47003
total_duration: 4233.8145390975415
[2023-06-29 13:55:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1200
train_sample_count: 1200
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 2786.1753225948537
avg_train_sample_per_sec: 2786.1753225948537
avg_episode_per_sec: 11.609063844145222
collect_time: 0.4306979500781745
reward_mean: 1853.861568978312
reward_std: 822.9216179831067
reward_max: 3475.1180348353
reward_min: 1340.0721371597656
total_envstep_count: 21169641
total_train_sample_count: 15885239
total_episode_count: 47008
total_duration: 4234.245237047619
[2023-06-29 13:55:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2532
train_sample_count: 2532
avg_envstep_per_episode: 281.3333333333333
avg_sample_per_episode: 281.3333333333333
avg_envstep_per_sec: 2541.8568645418277
avg_train_sample_per_sec: 2541.8568645418277
avg_episode_per_sec: 9.035036248371425
collect_time: 0.9961221795454622
reward_mean: 2073.197398364988
reward_std: 968.1757253197529
reward_max: 3446.9441711177546
reward_min: 1192.0190350118307
total_envstep_count: 21173441
total_train_sample_count: 15888571
total_episode_count: 47017
total_duration: 4235.241359227165
[2023-06-29 13:55:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1312
train_sample_count: 1312
avg_envstep_per_episode: 262.4
avg_sample_per_episode: 262.4
avg_envstep_per_sec: 2697.722345307434
avg_train_sample_per_sec: 2697.722345307434
avg_episode_per_sec: 10.280954059860647
collect_time: 0.4863361873701216
reward_mean: 2179.3208395288448
reward_std: 1099.156785915551
reward_max: 3471.2800055069156
reward_min: 738.9108298230094
total_envstep_count: 21177873
total_train_sample_count: 15891883
total_episode_count: 47022
total_duration: 4235.727695414535
[2023-06-29 13:55:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2024
train_sample_count: 2024
avg_envstep_per_episode: 337.3333333333333
avg_sample_per_episode: 337.3333333333333
avg_envstep_per_sec: 2435.7321099115306
avg_train_sample_per_sec: 2435.7321099115306
avg_episode_per_sec: 7.22054973293932
collect_time: 0.8309616610808299
reward_mean: 2875.600085405169
reward_std: 917.9393328163262
reward_max: 3428.0117900256255
reward_min: 918.4289354704629
total_envstep_count: 21181481
total_train_sample_count: 15895107
total_episode_count: 47028
total_duration: 4236.558657075616
[2023-06-29 13:55:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2251
train_sample_count: 2251
avg_envstep_per_episode: 375.1666666666667
avg_sample_per_episode: 375.1666666666667
avg_envstep_per_sec: 2611.593974464595
avg_train_sample_per_sec: 2611.593974464595
avg_episode_per_sec: 6.961156751127307
collect_time: 0.86192571357172
reward_mean: 2321.3357075853964
reward_std: 1138.704804585748
reward_max: 3468.7611453858844
reward_min: 977.3485476833056
total_envstep_count: 21186057
total_train_sample_count: 15898558
total_episode_count: 47034
total_duration: 4237.420582789187
[2023-06-29 13:55:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1867
train_sample_count: 1867
avg_envstep_per_episode: 311.1666666666667
avg_sample_per_episode: 311.1666666666667
avg_envstep_per_sec: 2681.883147120712
avg_train_sample_per_sec: 2681.883147120712
avg_episode_per_sec: 8.61879961581375
collect_time: 0.6961526276804506
reward_mean: 2491.7158082596925
reward_std: 1086.064422698533
reward_max: 3514.124123998275
reward_min: 746.9584498247528
total_envstep_count: 21190673
total_train_sample_count: 15902025
total_episode_count: 47040
total_duration: 4238.116735416867
[2023-06-29 13:55:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2068
train_sample_count: 2068
avg_envstep_per_episode: 206.8
avg_sample_per_episode: 206.8
avg_envstep_per_sec: 2603.989543917506
avg_train_sample_per_sec: 2603.989543917506
avg_episode_per_sec: 12.591825647570147
collect_time: 0.7941660153092818
reward_mean: 1613.9366984567
reward_std: 1198.0368527370717
reward_max: 3471.949575727703
reward_min: 18.6774227720092
total_envstep_count: 21195065
total_train_sample_count: 15905293
total_episode_count: 47050
total_duration: 4238.910901432177
[2023-06-29 13:55:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 161.8
avg_sample_per_episode: 161.8
avg_envstep_per_sec: 2485.9748938161424
avg_train_sample_per_sec: 2485.9748938161424
avg_episode_per_sec: 15.364492545217196
collect_time: 0.3254256517281755
reward_mean: 1331.7896594007657
reward_std: 1145.7131464689228
reward_max: 3467.449043859143
reward_min: 21.078383936129168
total_envstep_count: 21198321
total_train_sample_count: 15908502
total_episode_count: 47055
total_duration: 4239.236327083905
[2023-06-29 13:55:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2232
train_sample_count: 2232
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2282.591090933725
avg_train_sample_per_sec: 2282.591090933725
avg_episode_per_sec: 8.181330075031271
collect_time: 0.9778361130319536
reward_mean: 2736.2961626856886
reward_std: 1152.1325549629996
reward_max: 3446.4593158342323
reward_min: 259.863569414422
total_envstep_count: 21202425
total_train_sample_count: 15911934
total_episode_count: 47063
total_duration: 4240.214163196937
[2023-06-29 13:55:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 242.6
avg_sample_per_episode: 242.6
avg_envstep_per_sec: 2679.8324992167886
avg_train_sample_per_sec: 2679.8324992167886
avg_episode_per_sec: 11.046300491412978
collect_time: 0.45264023044519125
reward_mean: 1682.3284017650142
reward_std: 747.6519585673458
reward_max: 2979.283469418854
reward_min: 899.912174716811
total_envstep_count: 21207089
total_train_sample_count: 15915147
total_episode_count: 47068
total_duration: 4240.666803427383
[2023-06-29 13:55:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2253
train_sample_count: 2253
avg_envstep_per_episode: 281.625
avg_sample_per_episode: 281.625
avg_envstep_per_sec: 2611.8292936960293
avg_train_sample_per_sec: 2611.8292936960293
avg_episode_per_sec: 9.274138637180753
collect_time: 0.862613803068176
reward_mean: 2552.667776358356
reward_std: 1152.7364222296148
reward_max: 3505.468131411992
reward_min: 1038.88901877152
total_envstep_count: 21211625
total_train_sample_count: 15918600
total_episode_count: 47076
total_duration: 4241.529417230451
[2023-06-29 13:55:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1676
train_sample_count: 1676
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 2688.2268660917857
avg_train_sample_per_sec: 2688.2268660917857
avg_episode_per_sec: 12.831631819053868
collect_time: 0.6234592850552872
reward_mean: 1881.2487545405138
reward_std: 1271.6763251911266
reward_max: 3476.6456992568496
reward_min: 146.44879092882746
total_envstep_count: 21215817
total_train_sample_count: 15921876
total_episode_count: 47084
total_duration: 4242.152876515506
[2023-06-29 13:55:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1654
train_sample_count: 1654
avg_envstep_per_episode: 275.6666666666667
avg_sample_per_episode: 275.6666666666667
avg_envstep_per_sec: 2700.180498281135
avg_train_sample_per_sec: 2700.180498281135
avg_episode_per_sec: 9.795092496787673
collect_time: 0.612551642770879
reward_mean: 2245.9481109188287
reward_std: 1070.6833274187056
reward_max: 3479.3069821514696
reward_min: 615.9528873051357
total_envstep_count: 21219833
total_train_sample_count: 15925130
total_episode_count: 47090
total_duration: 4242.765428158277
[2023-06-29 13:56:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1690
train_sample_count: 1690
avg_envstep_per_episode: 338.0
avg_sample_per_episode: 338.0
avg_envstep_per_sec: 2783.801144305098
avg_train_sample_per_sec: 2783.801144305098
avg_episode_per_sec: 8.236098060074255
collect_time: 0.607083592683077
reward_mean: 2975.9839470759216
reward_std: 945.5599260585494
reward_max: 3484.5816514384655
reward_min: 1085.8285794827793
total_envstep_count: 21223817
total_train_sample_count: 15928420
total_episode_count: 47095
total_duration: 4243.37251175096
[2023-06-29 13:56:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1536
train_sample_count: 1536
avg_envstep_per_episode: 307.2
avg_sample_per_episode: 307.2
avg_envstep_per_sec: 2774.2871275917214
avg_train_sample_per_sec: 2774.2871275917214
avg_episode_per_sec: 9.030882576795968
collect_time: 0.5536557426676154
reward_mean: 2683.9339483737695
reward_std: 974.3751027923855
reward_max: 3466.868461097991
reward_min: 988.6769429160167
total_envstep_count: 21228569
total_train_sample_count: 15931956
total_episode_count: 47100
total_duration: 4243.926167493628
[2023-06-29 13:56:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1005
train_sample_count: 1005
avg_envstep_per_episode: 251.25
avg_sample_per_episode: 251.25
avg_envstep_per_sec: 2528.607873924513
avg_train_sample_per_sec: 2528.607873924513
avg_episode_per_sec: 10.064110940993086
collect_time: 0.3974518984789029
reward_mean: 3154.5840052330022
reward_std: 488.72543353886186
reward_max: 3454.52983551127
reward_min: 2308.353484683866
total_envstep_count: 21233321
total_train_sample_count: 15935361
total_episode_count: 47104
total_duration: 4244.323619392107
[2023-06-29 13:56:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1684
train_sample_count: 1684
avg_envstep_per_episode: 187.11111111111111
avg_sample_per_episode: 187.11111111111111
avg_envstep_per_sec: 2428.6349313861347
avg_train_sample_per_sec: 2428.6349313861347
avg_episode_per_sec: 12.979640369640864
collect_time: 0.6933936336981132
reward_mean: 2415.7812027556456
reward_std: 903.5466281553701
reward_max: 3437.5430191102364
reward_min: 1183.8067629367351
total_envstep_count: 21237329
total_train_sample_count: 15938645
total_episode_count: 47113
total_duration: 4245.017013025805
[2023-06-29 13:56:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2079
train_sample_count: 2079
avg_envstep_per_episode: 259.875
avg_sample_per_episode: 259.875
avg_envstep_per_sec: 2687.456903083906
avg_train_sample_per_sec: 2687.456903083906
avg_episode_per_sec: 10.341344504411374
collect_time: 0.7735938007468359
reward_mean: 1974.8046970676035
reward_std: 843.944728957851
reward_max: 3592.6108546692653
reward_min: 968.7044620862146
total_envstep_count: 21241937
total_train_sample_count: 15941924
total_episode_count: 47121
total_duration: 4245.790606826552
[2023-06-29 13:56:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2586
train_sample_count: 2586
avg_envstep_per_episode: 323.25
avg_sample_per_episode: 323.25
avg_envstep_per_sec: 2689.110630367079
avg_train_sample_per_sec: 2689.110630367079
avg_episode_per_sec: 8.318981068420973
collect_time: 0.961656233401969
reward_mean: 2261.115097622739
reward_std: 856.2269747773328
reward_max: 3443.354101111803
reward_min: 1240.0002377799367
total_envstep_count: 21246737
total_train_sample_count: 15945310
total_episode_count: 47129
total_duration: 4246.752263059954
[2023-06-29 13:56:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1708
train_sample_count: 1708
avg_envstep_per_episode: 213.5
avg_sample_per_episode: 213.5
avg_envstep_per_sec: 2718.743334294088
avg_train_sample_per_sec: 2718.743334294088
avg_episode_per_sec: 12.734160816365751
collect_time: 0.6282314253263176
reward_mean: 1808.326638086044
reward_std: 765.5573445610913
reward_max: 2959.4095887563094
reward_min: 819.9191612722465
total_envstep_count: 21251225
total_train_sample_count: 15948618
total_episode_count: 47137
total_duration: 4247.380494485281
[2023-06-29 13:56:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2345
train_sample_count: 2345
avg_envstep_per_episode: 180.3846153846154
avg_sample_per_episode: 180.3846153846154
avg_envstep_per_sec: 2497.415250009506
avg_train_sample_per_sec: 2497.415250009506
avg_episode_per_sec: 13.844945948879992
collect_time: 0.9389708019085228
reward_mean: 1489.7458743813863
reward_std: 661.2335574955173
reward_max: 3171.3562443218448
reward_min: 696.7969724834516
total_envstep_count: 21256049
total_train_sample_count: 15952163
total_episode_count: 47150
total_duration: 4248.31946528719
[2023-06-29 13:56:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1481
train_sample_count: 1481
avg_envstep_per_episode: 185.125
avg_sample_per_episode: 185.125
avg_envstep_per_sec: 2419.2690358389104
avg_train_sample_per_sec: 2419.2690358389104
avg_episode_per_sec: 13.068299991027201
collect_time: 0.6121683773323894
reward_mean: 1511.8881460343696
reward_std: 424.65749410171856
reward_max: 2259.72678827463
reward_min: 933.6645189530722
total_envstep_count: 21260313
total_train_sample_count: 15955644
total_episode_count: 47158
total_duration: 4248.931633664522
[2023-06-29 13:56:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2993
train_sample_count: 2993
avg_envstep_per_episode: 249.41666666666666
avg_sample_per_episode: 249.41666666666666
avg_envstep_per_sec: 2593.1299265734547
avg_train_sample_per_sec: 2593.1299265734547
avg_episode_per_sec: 10.39677885696006
collect_time: 1.1542036399058997
reward_mean: 1948.6073843863157
reward_std: 956.9706980361663
reward_max: 3559.191460579041
reward_min: 1010.3922493993506
total_envstep_count: 21265137
total_train_sample_count: 15959037
total_episode_count: 47170
total_duration: 4250.085837304428
[2023-06-29 13:56:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 255.375
avg_sample_per_episode: 255.375
avg_envstep_per_sec: 2780.05993895596
avg_train_sample_per_sec: 2780.05993895596
avg_episode_per_sec: 10.886186740894606
collect_time: 0.7348762418292464
reward_mean: 1720.1281914253605
reward_std: 620.8972067283665
reward_max: 2583.604020218022
reward_min: 800.4932178226132
total_envstep_count: 21269641
total_train_sample_count: 15962280
total_episode_count: 47178
total_duration: 4250.820713546258
[2023-06-29 13:56:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 909
train_sample_count: 909
avg_envstep_per_episode: 181.8
avg_sample_per_episode: 181.8
avg_envstep_per_sec: 2741.2658256747136
avg_train_sample_per_sec: 2741.2658256747136
avg_episode_per_sec: 15.078469888199745
collect_time: 0.33159863282367585
reward_mean: 1630.6931420074939
reward_std: 584.6852236736295
reward_max: 2493.67947216563
reward_min: 1037.7457236480377
total_envstep_count: 21274089
total_train_sample_count: 15965589
total_episode_count: 47183
total_duration: 4251.1523121790815
[2023-06-29 13:56:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 222.45454545454547
avg_sample_per_episode: 222.45454545454547
avg_envstep_per_sec: 2563.822737443335
avg_train_sample_per_sec: 2563.822737443335
avg_episode_per_sec: 11.52515329459611
collect_time: 0.9544341596877203
reward_mean: 2332.7043531268614
reward_std: 1006.6586294899575
reward_max: 3652.2995771521673
reward_min: 1025.7574894053375
total_envstep_count: 21278577
total_train_sample_count: 15968836
total_episode_count: 47194
total_duration: 4252.106746338769
[2023-06-29 13:56:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2045
train_sample_count: 2045
avg_envstep_per_episode: 292.14285714285717
avg_sample_per_episode: 292.14285714285717
avg_envstep_per_sec: 2474.7833566718373
avg_train_sample_per_sec: 2474.7833566718373
avg_episode_per_sec: 8.471141074182327
collect_time: 0.8263349575577303
reward_mean: 1891.2919659665174
reward_std: 904.9150850336363
reward_max: 3497.066587983318
reward_min: 913.3712388143044
total_envstep_count: 21282449
total_train_sample_count: 15972081
total_episode_count: 47201
total_duration: 4252.933081296327
[2023-06-29 13:56:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2676
train_sample_count: 2676
avg_envstep_per_episode: 267.6
avg_sample_per_episode: 267.6
avg_envstep_per_sec: 2748.0682299706987
avg_train_sample_per_sec: 2748.0682299706987
avg_episode_per_sec: 10.269313265959262
collect_time: 0.9737749488223344
reward_mean: 1806.4730517088865
reward_std: 1057.3571242698772
reward_max: 3513.7120111494933
reward_min: 697.4620290928386
total_envstep_count: 21287825
total_train_sample_count: 15975557
total_episode_count: 47211
total_duration: 4253.906856245149
[2023-06-29 13:56:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2628
train_sample_count: 2628
avg_envstep_per_episode: 202.15384615384616
avg_sample_per_episode: 202.15384615384616
avg_envstep_per_sec: 2703.4444065182465
avg_train_sample_per_sec: 2703.4444065182465
avg_episode_per_sec: 13.373202924177019
collect_time: 0.9720932280551643
reward_mean: 1358.1214566056465
reward_std: 982.7727234536208
reward_max: 3478.9930738204375
reward_min: 163.70932530426103
total_envstep_count: 21292649
total_train_sample_count: 15978985
total_episode_count: 47224
total_duration: 4254.878949473205
[2023-06-29 13:56:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 234.15384615384616
avg_sample_per_episode: 234.15384615384616
avg_envstep_per_sec: 2754.7031621252895
avg_train_sample_per_sec: 2754.7031621252895
avg_episode_per_sec: 11.76450102090301
collect_time: 1.105019241946749
reward_mean: 1561.2720197619337
reward_std: 947.0085542758738
reward_max: 3569.928483397089
reward_min: 838.6272637923424
total_envstep_count: 21297153
total_train_sample_count: 15982429
total_episode_count: 47237
total_duration: 4255.983968715152
[2023-06-29 13:56:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3316
train_sample_count: 3316
avg_envstep_per_episode: 236.85714285714286
avg_sample_per_episode: 236.85714285714286
avg_envstep_per_sec: 2584.5542936795173
avg_train_sample_per_sec: 2584.5542936795173
avg_episode_per_sec: 10.91186975618614
collect_time: 1.2830065160980446
reward_mean: 1225.3050985013833
reward_std: 676.2499595983384
reward_max: 3508.8888312948625
reward_min: 716.2001223680761
total_envstep_count: 21301641
total_train_sample_count: 15985745
total_episode_count: 47251
total_duration: 4257.2669752312495
[2023-06-29 13:56:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2812
train_sample_count: 2812
avg_envstep_per_episode: 200.85714285714286
avg_sample_per_episode: 200.85714285714286
avg_envstep_per_sec: 2531.3137881641196
avg_train_sample_per_sec: 2531.3137881641196
avg_episode_per_sec: 12.602557978057495
collect_time: 1.1108855856386943
reward_mean: 1031.370537416023
reward_std: 225.86482680156234
reward_max: 1772.4836080449465
reward_min: 773.8267935933519
total_envstep_count: 21305929
total_train_sample_count: 15988957
total_episode_count: 47265
total_duration: 4258.377860816888
[2023-06-29 13:56:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2466
train_sample_count: 2466
avg_envstep_per_episode: 189.69230769230768
avg_sample_per_episode: 189.69230769230768
avg_envstep_per_sec: 2479.6960125304627
avg_train_sample_per_sec: 2479.6960125304627
avg_episode_per_sec: 13.072201201498789
collect_time: 0.9944767372850327
reward_mean: 1097.5037972167818
reward_std: 305.98639025524534
reward_max: 1906.4996683382542
reward_min: 723.40661490438
total_envstep_count: 21310329
total_train_sample_count: 15992223
total_episode_count: 47278
total_duration: 4259.372337554173
[2023-06-29 13:57:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2549
train_sample_count: 2549
avg_envstep_per_episode: 182.07142857142858
avg_sample_per_episode: 182.07142857142858
avg_envstep_per_sec: 2792.129021988551
avg_train_sample_per_sec: 2792.129021988551
avg_episode_per_sec: 15.3353496696115
collect_time: 0.9129234286546706
reward_mean: 1172.6458311273793
reward_std: 484.36308149843575
reward_max: 2582.4545665864885
reward_min: 706.5538258573764
total_envstep_count: 21314553
total_train_sample_count: 15995572
total_episode_count: 47292
total_duration: 4260.285260982828
[2023-06-29 13:57:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3084
train_sample_count: 3084
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 2593.3997419732
avg_train_sample_per_sec: 2593.3997419732
avg_episode_per_sec: 10.091049579662256
collect_time: 1.189172633160488
reward_mean: 1464.2307686097165
reward_std: 494.53117587633403
reward_max: 2583.7476416779155
reward_min: 723.9619595798389
total_envstep_count: 21319265
total_train_sample_count: 15999056
total_episode_count: 47304
total_duration: 4261.474433615988
[2023-06-29 13:57:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2835
train_sample_count: 2835
avg_envstep_per_episode: 236.25
avg_sample_per_episode: 236.25
avg_envstep_per_sec: 2577.1710137488667
avg_train_sample_per_sec: 2577.1710137488667
avg_episode_per_sec: 10.908660375656579
collect_time: 1.1000434138346464
reward_mean: 1365.297563148449
reward_std: 480.4271247340601
reward_max: 2322.7364735969218
reward_min: 758.5068244152602
total_envstep_count: 21323721
total_train_sample_count: 16002291
total_episode_count: 47316
total_duration: 4262.574477029823
[2023-06-29 13:57:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2666
train_sample_count: 2666
avg_envstep_per_episode: 205.07692307692307
avg_sample_per_episode: 205.07692307692307
avg_envstep_per_sec: 2507.4192405138106
avg_train_sample_per_sec: 2507.4192405138106
avg_episode_per_sec: 12.226725478874545
collect_time: 1.0632446129964663
reward_mean: 1212.4850881596253
reward_std: 358.5000523383236
reward_max: 1985.6048956872853
reward_min: 759.0362856003846
total_envstep_count: 21328057
total_train_sample_count: 16005757
total_episode_count: 47329
total_duration: 4263.63772164282
[2023-06-29 13:57:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 214.2
avg_sample_per_episode: 214.2
avg_envstep_per_sec: 2803.2287949999923
avg_train_sample_per_sec: 2803.2287949999923
avg_episode_per_sec: 13.086969164332363
collect_time: 1.1461782947331665
reward_mean: 1188.463297643979
reward_std: 332.1160547860702
reward_max: 1924.6173326213534
reward_min: 785.4157465509977
total_envstep_count: 21332489
total_train_sample_count: 16008970
total_episode_count: 47344
total_duration: 4264.7838999375535
[2023-06-29 13:57:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1707
train_sample_count: 1707
avg_envstep_per_episode: 189.66666666666666
avg_sample_per_episode: 189.66666666666666
avg_envstep_per_sec: 2598.240670980114
avg_train_sample_per_sec: 2598.240670980114
avg_episode_per_sec: 13.698984205519054
collect_time: 0.6569830189580097
reward_mean: 1179.9181670045573
reward_std: 136.72630496509603
reward_max: 1442.0770281929097
reward_min: 1021.5575122342308
total_envstep_count: 21336561
total_train_sample_count: 16012277
total_episode_count: 47353
total_duration: 4265.440882956512
[2023-06-29 13:57:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 321.2
avg_sample_per_episode: 321.2
avg_envstep_per_sec: 2656.872568261235
avg_train_sample_per_sec: 2656.872568261235
avg_episode_per_sec: 8.271707871298988
collect_time: 1.208940179657191
reward_mean: 2055.6635620034854
reward_std: 859.51293365848
reward_max: 3668.1275999683266
reward_min: 1122.1639296043843
total_envstep_count: 21341321
total_train_sample_count: 16015489
total_episode_count: 47363
total_duration: 4266.649823136169
[2023-06-29 13:57:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1086
train_sample_count: 1086
avg_envstep_per_episode: 155.14285714285714
avg_sample_per_episode: 155.14285714285714
avg_envstep_per_sec: 2777.222257792608
avg_train_sample_per_sec: 2777.222257792608
avg_episode_per_sec: 17.901064276747935
collect_time: 0.3910382026331499
reward_mean: 1287.375861476458
reward_std: 244.37806110193165
reward_max: 1810.8540935777394
reward_min: 994.341498249522
total_envstep_count: 21346193
total_train_sample_count: 16018975
total_episode_count: 47370
total_duration: 4267.040861338803
[2023-06-29 13:57:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2822
train_sample_count: 2822
avg_envstep_per_episode: 217.07692307692307
avg_sample_per_episode: 217.07692307692307
avg_envstep_per_sec: 2698.1271493511445
avg_train_sample_per_sec: 2698.1271493511445
avg_episode_per_sec: 12.429359653283088
collect_time: 1.0459106794424589
reward_mean: 1923.8883567883688
reward_std: 956.4646662818358
reward_max: 3528.554143213767
reward_min: 144.524719884934
total_envstep_count: 21350705
total_train_sample_count: 16022197
total_episode_count: 47383
total_duration: 4268.086772018245
[2023-06-29 13:57:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 216.4
avg_sample_per_episode: 216.4
avg_envstep_per_sec: 2599.3835501952776
avg_train_sample_per_sec: 2599.3835501952776
avg_episode_per_sec: 12.011938771697217
collect_time: 0.41625253799837086
reward_mean: 1538.0113512258617
reward_std: 723.4557901685716
reward_max: 2538.11327737278
reward_min: 473.3005172135163
total_envstep_count: 21355225
total_train_sample_count: 16025679
total_episode_count: 47388
total_duration: 4268.503024556243
[2023-06-29 13:57:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2435
train_sample_count: 2435
avg_envstep_per_episode: 221.36363636363637
avg_sample_per_episode: 221.36363636363637
avg_envstep_per_sec: 2625.1648980693135
avg_train_sample_per_sec: 2625.1648980693135
avg_episode_per_sec: 11.859061141175545
collect_time: 0.9275607798164713
reward_mean: 2096.0449457256505
reward_std: 1177.5903756519479
reward_max: 3497.3929795014446
reward_min: 242.74953783384984
total_envstep_count: 21359377
total_train_sample_count: 16028914
total_episode_count: 47399
total_duration: 4269.430585336059
[2023-06-29 13:57:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 295.0
avg_sample_per_episode: 295.0
avg_envstep_per_sec: 2704.9099046964316
avg_train_sample_per_sec: 2704.9099046964316
avg_episode_per_sec: 9.169186117615023
collect_time: 0.7634265364678577
reward_mean: 2022.5596326881516
reward_std: 817.55640024462
reward_max: 3523.4097268623345
reward_min: 1291.4304057495299
total_envstep_count: 21363985
total_train_sample_count: 16032179
total_episode_count: 47406
total_duration: 4270.194011872527
[2023-06-29 13:57:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 299.6666666666667
avg_sample_per_episode: 299.6666666666667
avg_envstep_per_sec: 2683.0358183639723
avg_train_sample_per_sec: 2683.0358183639723
avg_episode_per_sec: 8.953400951158972
collect_time: 0.33506820663623527
reward_mean: 2860.915680260831
reward_std: 858.4971498249404
reward_max: 3482.7462032438407
reward_min: 1646.9383307037676
total_envstep_count: 21367553
total_train_sample_count: 16035478
total_episode_count: 47409
total_duration: 4270.529080079164
[2023-06-29 13:57:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 307.7142857142857
avg_sample_per_episode: 307.7142857142857
avg_envstep_per_sec: 2594.626616769887
avg_train_sample_per_sec: 2594.626616769887
avg_episode_per_sec: 8.43193422348617
collect_time: 0.8301772540519015
reward_mean: 2982.567421465346
reward_std: 860.2822674086855
reward_max: 3659.9568338822014
reward_min: 1322.4173595558768
total_envstep_count: 21372561
total_train_sample_count: 16038832
total_episode_count: 47416
total_duration: 4271.359257333215
[2023-06-29 13:57:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2214
train_sample_count: 2214
avg_envstep_per_episode: 316.2857142857143
avg_sample_per_episode: 316.2857142857143
avg_envstep_per_sec: 2491.5885731451494
avg_train_sample_per_sec: 2491.5885731451494
avg_episode_per_sec: 7.8776513152737335
collect_time: 0.8885897229835392
reward_mean: 2471.4907464947282
reward_std: 1106.1410716861903
reward_max: 3482.1188437833857
reward_min: 241.64367489911413
total_envstep_count: 21378009
total_train_sample_count: 16042246
total_episode_count: 47423
total_duration: 4272.247847056199
[2023-06-29 13:57:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1633
train_sample_count: 1633
avg_envstep_per_episode: 204.125
avg_sample_per_episode: 204.125
avg_envstep_per_sec: 2757.9876730796063
avg_train_sample_per_sec: 2757.9876730796063
avg_episode_per_sec: 13.511268453543693
collect_time: 0.5920983679294586
reward_mean: 2176.69743661968
reward_std: 907.6766051621639
reward_max: 3466.580356314442
reward_min: 1302.3115199925674
total_envstep_count: 21382113
total_train_sample_count: 16045479
total_episode_count: 47431
total_duration: 4272.839945424129
[2023-06-29 13:57:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3046
train_sample_count: 3046
avg_envstep_per_episode: 338.44444444444446
avg_sample_per_episode: 338.44444444444446
avg_envstep_per_sec: 2530.286050986423
avg_train_sample_per_sec: 2530.286050986423
avg_episode_per_sec: 7.476222737648656
collect_time: 1.2038164613097906
reward_mean: 2407.4722383161698
reward_std: 811.6968614821049
reward_max: 3646.4583435192344
reward_min: 1234.921141784265
total_envstep_count: 21387041
total_train_sample_count: 16048925
total_episode_count: 47440
total_duration: 4274.0437618854385
[2023-06-29 13:57:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1914
train_sample_count: 1914
avg_envstep_per_episode: 273.42857142857144
avg_sample_per_episode: 273.42857142857144
avg_envstep_per_sec: 2787.236257625314
avg_train_sample_per_sec: 2787.236257625314
avg_episode_per_sec: 10.193654024752977
collect_time: 0.6867017443403599
reward_mean: 1702.59566540864
reward_std: 488.93129815370145
reward_max: 2511.401265473026
reward_min: 1040.3224849675205
total_envstep_count: 21391505
total_train_sample_count: 16052439
total_episode_count: 47447
total_duration: 4274.730463629779
[2023-06-29 13:57:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1129
train_sample_count: 1129
avg_envstep_per_episode: 188.16666666666666
avg_sample_per_episode: 188.16666666666666
avg_envstep_per_sec: 2352.1994597172034
avg_train_sample_per_sec: 2352.1994597172034
avg_episode_per_sec: 12.500617146415607
collect_time: 0.47997630274761466
reward_mean: 2361.241414316119
reward_std: 1170.9133736321626
reward_max: 3508.7158256347884
reward_min: 521.6638218439394
total_envstep_count: 21396377
total_train_sample_count: 16055968
total_episode_count: 47453
total_duration: 4275.210439932526
[2023-06-29 13:58:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2807
train_sample_count: 2807
avg_envstep_per_episode: 255.1818181818182
avg_sample_per_episode: 255.1818181818182
avg_envstep_per_sec: 2583.8695655238166
avg_train_sample_per_sec: 2583.8695655238166
avg_episode_per_sec: 10.125602144909863
collect_time: 1.0863551463484764
reward_mean: 2243.803835549619
reward_std: 941.7395102049561
reward_max: 3601.801540045245
reward_min: 1086.6845663504762
total_envstep_count: 21400753
total_train_sample_count: 16059175
total_episode_count: 47464
total_duration: 4276.296795078874
[2023-06-29 13:58:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1982
train_sample_count: 1982
avg_envstep_per_episode: 283.14285714285717
avg_sample_per_episode: 283.14285714285717
avg_envstep_per_sec: 2603.696839866645
avg_train_sample_per_sec: 2603.696839866645
avg_episode_per_sec: 9.195700241708634
collect_time: 0.7612253353203414
reward_mean: 1781.1745445785036
reward_std: 505.1699823248762
reward_max: 2874.323850300772
reward_min: 1213.145485891449
total_envstep_count: 21405889
total_train_sample_count: 16062757
total_episode_count: 47471
total_duration: 4277.058020414194
[2023-06-29 13:58:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2558
train_sample_count: 2558
avg_envstep_per_episode: 319.75
avg_sample_per_episode: 319.75
avg_envstep_per_sec: 2529.0365552459803
avg_train_sample_per_sec: 2529.0365552459803
avg_episode_per_sec: 7.909418468322064
collect_time: 1.0114523630328478
reward_mean: 2494.5598354731205
reward_std: 982.1152420046311
reward_max: 3566.2916146677935
reward_min: 1251.7928396904056
total_envstep_count: 21410409
total_train_sample_count: 16066115
total_episode_count: 47479
total_duration: 4278.069472777227
[2023-06-29 13:58:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 291.85714285714283
avg_sample_per_episode: 291.85714285714283
avg_envstep_per_sec: 2726.511473237482
avg_train_sample_per_sec: 2726.511473237482
avg_episode_per_sec: 9.341938479031997
collect_time: 0.7493091520257296
reward_mean: 2100.1740734293267
reward_std: 984.1483518981302
reward_max: 3536.154325502269
reward_min: 819.2303889280287
total_envstep_count: 21414921
total_train_sample_count: 16069358
total_episode_count: 47486
total_duration: 4278.8187819292525
[2023-06-29 13:58:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1538
train_sample_count: 1538
avg_envstep_per_episode: 219.71428571428572
avg_sample_per_episode: 219.71428571428572
avg_envstep_per_sec: 2484.7292366957286
avg_train_sample_per_sec: 2484.7292366957286
avg_episode_per_sec: 11.308910700175618
collect_time: 0.6189809244750067
reward_mean: 2071.607269460732
reward_std: 982.4457505950039
reward_max: 3484.446386714398
reward_min: 1008.0399197738852
total_envstep_count: 21419201
total_train_sample_count: 16072896
total_episode_count: 47493
total_duration: 4279.437762853728
[2023-06-29 13:58:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 401.4
avg_sample_per_episode: 401.4
avg_envstep_per_sec: 2557.5094933704804
avg_train_sample_per_sec: 2557.5094933704804
avg_episode_per_sec: 6.371473575910515
collect_time: 0.7847478201752529
reward_mean: 3288.852777138533
reward_std: 311.0302102128289
reward_max: 3559.2466767760648
reward_min: 2704.1438410323344
total_envstep_count: 21423961
total_train_sample_count: 16076103
total_episode_count: 47498
total_duration: 4280.222510673903
[2023-06-29 13:58:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1204
train_sample_count: 1204
avg_envstep_per_episode: 240.8
avg_sample_per_episode: 240.8
avg_envstep_per_sec: 2256.3357357969276
avg_train_sample_per_sec: 2256.3357357969276
avg_episode_per_sec: 9.370165015767972
collect_time: 0.5336085321428252
reward_mean: 2636.7100519126134
reward_std: 1134.4237312351493
reward_max: 3674.5104527933922
reward_min: 1111.1454474609468
total_envstep_count: 21428337
total_train_sample_count: 16079307
total_episode_count: 47503
total_duration: 4280.756119206047
[2023-06-29 13:58:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2364
train_sample_count: 2364
avg_envstep_per_episode: 295.5
avg_sample_per_episode: 295.5
avg_envstep_per_sec: 2782.237326853367
avg_train_sample_per_sec: 2782.237326853367
avg_episode_per_sec: 9.415354744004626
collect_time: 0.8496758983079342
reward_mean: 2684.616008531847
reward_std: 916.7604125790575
reward_max: 3708.850182856011
reward_min: 1207.6812515018278
total_envstep_count: 21432753
total_train_sample_count: 16082871
total_episode_count: 47511
total_duration: 4281.605795104355
[2023-06-29 13:58:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1826
train_sample_count: 1826
avg_envstep_per_episode: 304.3333333333333
avg_sample_per_episode: 304.3333333333333
avg_envstep_per_sec: 2762.5227856797696
avg_train_sample_per_sec: 2762.5227856797696
avg_episode_per_sec: 9.077292833558937
collect_time: 0.6609900231286885
reward_mean: 2201.2729138517047
reward_std: 920.4116009280881
reward_max: 3505.089874563702
reward_min: 1386.2089186935864
total_envstep_count: 21437889
total_train_sample_count: 16086297
total_episode_count: 47517
total_duration: 4282.266785127484
[2023-06-29 13:58:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2105
train_sample_count: 2105
avg_envstep_per_episode: 350.8333333333333
avg_sample_per_episode: 350.8333333333333
avg_envstep_per_sec: 2527.819628914984
avg_train_sample_per_sec: 2527.819628914984
avg_episode_per_sec: 7.205186590731547
collect_time: 0.8327334656007592
reward_mean: 3294.8875059484412
reward_std: 530.8104468278323
reward_max: 3626.685324089923
reward_min: 2114.477270943672
total_envstep_count: 21442721
total_train_sample_count: 16089602
total_episode_count: 47523
total_duration: 4283.099518593084
[2023-06-29 13:58:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 331.3333333333333
avg_sample_per_episode: 331.3333333333333
avg_envstep_per_sec: 2746.531884368541
avg_train_sample_per_sec: 2746.531884368541
avg_episode_per_sec: 8.289331642963402
collect_time: 0.3619109632978217
reward_mean: 3570.901469457492
reward_std: 78.26819524602139
reward_max: 3680.150691112348
reward_min: 3500.871623920392
total_envstep_count: 21447161
total_train_sample_count: 16092996
total_episode_count: 47526
total_duration: 4283.461429556382
[2023-06-29 13:58:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1816
train_sample_count: 1816
avg_envstep_per_episode: 259.42857142857144
avg_sample_per_episode: 259.42857142857144
avg_envstep_per_sec: 2636.2388870770737
avg_train_sample_per_sec: 2636.2388870770737
avg_episode_per_sec: 10.161713771772861
collect_time: 0.6888601821716877
reward_mean: 2838.022474256109
reward_std: 1011.5688180415334
reward_max: 3497.4467636356885
reward_min: 1096.379545447002
total_envstep_count: 21451889
total_train_sample_count: 16096412
total_episode_count: 47533
total_duration: 4284.150289738554
[2023-06-29 13:58:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 207.75
avg_sample_per_episode: 207.75
avg_envstep_per_sec: 2756.1609840800065
avg_train_sample_per_sec: 2756.1609840800065
avg_episode_per_sec: 13.266719538291248
collect_time: 0.3015063360957429
reward_mean: 2908.975156260715
reward_std: 773.0002233094685
reward_max: 3505.026561323056
reward_min: 1612.0231244889758
total_envstep_count: 21455897
total_train_sample_count: 16099643
total_episode_count: 47537
total_duration: 4284.45179607465
[2023-06-29 13:58:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 208.33333333333334
avg_sample_per_episode: 208.33333333333334
avg_envstep_per_sec: 2630.5837886586896
avg_train_sample_per_sec: 2630.5837886586896
avg_episode_per_sec: 12.62680218556171
collect_time: 0.47517969410028316
reward_mean: 3109.441546613627
reward_std: 635.6783441942783
reward_max: 3504.2654999956267
reward_min: 1753.5730480002903
total_envstep_count: 21460145
total_train_sample_count: 16102893
total_episode_count: 47543
total_duration: 4284.92697576875
[2023-06-29 13:58:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 405.0
avg_sample_per_episode: 405.0
avg_envstep_per_sec: 2756.499954832546
avg_train_sample_per_sec: 2756.499954832546
avg_episode_per_sec: 6.806172727981595
collect_time: 0.4407763540390879
reward_mean: 3403.856974109461
reward_std: 135.88871873204442
reward_max: 3500.8511355503333
reward_min: 3211.684163696284
total_envstep_count: 21464033
total_train_sample_count: 16106108
total_episode_count: 47546
total_duration: 4285.367752122789
[2023-06-29 13:58:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2535
train_sample_count: 2535
avg_envstep_per_episode: 230.45454545454547
avg_sample_per_episode: 230.45454545454547
avg_envstep_per_sec: 2658.314222887337
avg_train_sample_per_sec: 2658.314222887337
avg_episode_per_sec: 11.535091302469707
collect_time: 0.9536118710776791
reward_mean: 2176.392259179037
reward_std: 1249.6312141225774
reward_max: 3561.485482552918
reward_min: 124.6680696880711
total_envstep_count: 21468937
total_train_sample_count: 16109443
total_episode_count: 47557
total_duration: 4286.321363993867
[2023-06-29 13:58:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1954
train_sample_count: 1954
avg_envstep_per_episode: 279.14285714285717
avg_sample_per_episode: 279.14285714285717
avg_envstep_per_sec: 2751.057771751559
avg_train_sample_per_sec: 2751.057771751559
avg_episode_per_sec: 9.855375845578768
collect_time: 0.7102722523910926
reward_mean: 1929.7724084374036
reward_std: 1151.6524441845922
reward_max: 3540.9378098646425
reward_min: 138.17251497844163
total_envstep_count: 21474193
total_train_sample_count: 16112997
total_episode_count: 47564
total_duration: 4287.031636246258
[2023-06-29 13:58:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1321
train_sample_count: 1321
avg_envstep_per_episode: 165.125
avg_sample_per_episode: 165.125
avg_envstep_per_sec: 2659.7270644942214
avg_train_sample_per_sec: 2659.7270644942214
avg_episode_per_sec: 16.107355424643277
collect_time: 0.4966675030812622
reward_mean: 2214.815237021116
reward_std: 823.4645306123937
reward_max: 3491.503873663485
reward_min: 1238.3139219234995
total_envstep_count: 21479113
total_train_sample_count: 16116318
total_episode_count: 47572
total_duration: 4287.528303749339
[2023-06-29 13:58:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1334
train_sample_count: 1334
avg_envstep_per_episode: 333.5
avg_sample_per_episode: 333.5
avg_envstep_per_sec: 2399.419972108094
avg_train_sample_per_sec: 2399.419972108094
avg_episode_per_sec: 7.194662585031766
collect_time: 0.5559676986550911
reward_mean: 2960.83563945506
reward_std: 928.4174823773351
reward_max: 3527.2517268251995
reward_min: 1353.516553006491
total_envstep_count: 21482953
total_train_sample_count: 16119652
total_episode_count: 47576
total_duration: 4288.084271447994
[2023-06-29 13:59:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2579
train_sample_count: 2579
avg_envstep_per_episode: 234.45454545454547
avg_sample_per_episode: 234.45454545454547
avg_envstep_per_sec: 2477.4858182456787
avg_train_sample_per_sec: 2477.4858182456787
avg_episode_per_sec: 10.56701977537901
collect_time: 1.0409746772339565
reward_mean: 2284.8209494968537
reward_std: 1168.4337399681167
reward_max: 3624.1328911553114
reward_min: 260.5059568172491
total_envstep_count: 21488001
total_train_sample_count: 16123031
total_episode_count: 47587
total_duration: 4289.125246125228
[2023-06-29 13:59:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 2804.9279679070487
avg_train_sample_per_sec: 2804.9279679070487
avg_episode_per_sec: 12.521999856727895
collect_time: 1.0381728277225049
reward_mean: 1536.3459247654196
reward_std: 526.2989191122443
reward_max: 2508.6745685361834
reward_min: 917.835614650967
total_envstep_count: 21492433
total_train_sample_count: 16126343
total_episode_count: 47600
total_duration: 4290.16341895295
[2023-06-29 13:59:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 434
train_sample_count: 434
avg_envstep_per_episode: 144.66666666666666
avg_sample_per_episode: 144.66666666666666
avg_envstep_per_sec: 2756.7965116452297
avg_train_sample_per_sec: 2756.7965116452297
avg_episode_per_sec: 19.056197085105275
collect_time: 0.1574291022811085
reward_mean: 1509.0159795492725
reward_std: 353.8481746418453
reward_max: 1999.2696899253397
reward_min: 1176.9910769555397
total_envstep_count: 21496801
total_train_sample_count: 16129577
total_episode_count: 47603
total_duration: 4290.320848055231
[2023-06-29 13:59:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2050
train_sample_count: 2050
avg_envstep_per_episode: 292.85714285714283
avg_sample_per_episode: 292.85714285714283
avg_envstep_per_sec: 2683.868415164236
avg_train_sample_per_sec: 2683.868415164236
avg_episode_per_sec: 9.164428734707148
collect_time: 0.7638228418417274
reward_mean: 3068.7325272859985
reward_std: 837.0680341552555
reward_max: 3602.418559172366
reward_min: 1094.1273093668653
total_envstep_count: 21500777
total_train_sample_count: 16132827
total_episode_count: 47610
total_duration: 4291.084670897073
[2023-06-29 13:59:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1972
train_sample_count: 1972
avg_envstep_per_episode: 281.7142857142857
avg_sample_per_episode: 281.7142857142857
avg_envstep_per_sec: 2683.55769170289
avg_train_sample_per_sec: 2683.55769170289
avg_episode_per_sec: 9.52581330726178
collect_time: 0.7348453905414789
reward_mean: 2315.0225264843825
reward_std: 966.4749092655063
reward_max: 3563.3375118164745
reward_min: 1209.696143653249
total_envstep_count: 21505593
total_train_sample_count: 16136399
total_episode_count: 47617
total_duration: 4291.8195162876145
[2023-06-29 13:59:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2679
train_sample_count: 2679
avg_envstep_per_episode: 267.9
avg_sample_per_episode: 267.9
avg_envstep_per_sec: 2743.2541327403587
avg_train_sample_per_sec: 2743.2541327403587
avg_episode_per_sec: 10.239843720568715
collect_time: 0.9765774041954427
reward_mean: 2013.6734599360382
reward_std: 885.2791145637177
reward_max: 3691.1883742074106
reward_min: 1134.4757458699082
total_envstep_count: 21510273
total_train_sample_count: 16139878
total_episode_count: 47627
total_duration: 4292.79609369181
[2023-06-29 13:59:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2592
train_sample_count: 2592
avg_envstep_per_episode: 324.0
avg_sample_per_episode: 324.0
avg_envstep_per_sec: 2733.5243549689585
avg_train_sample_per_sec: 2733.5243549689585
avg_episode_per_sec: 8.436803564719007
collect_time: 0.9482264152094722
reward_mean: 2196.5608888711404
reward_std: 935.3917040584964
reward_max: 3681.3083419974755
reward_min: 1310.5189753079974
total_envstep_count: 21514785
total_train_sample_count: 16143270
total_episode_count: 47635
total_duration: 4293.744320107019
[2023-06-29 13:59:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 272.6666666666667
avg_sample_per_episode: 272.6666666666667
avg_envstep_per_sec: 2659.520187958353
avg_train_sample_per_sec: 2659.520187958353
avg_episode_per_sec: 9.753741520629655
collect_time: 0.6151485547684135
reward_mean: 1970.2915068832406
reward_std: 624.9097310626744
reward_max: 2701.5364434031126
reward_min: 978.8103061889846
total_envstep_count: 21518673
total_train_sample_count: 16146506
total_episode_count: 47641
total_duration: 4294.359468661787
[2023-06-29 13:59:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2169
train_sample_count: 2169
avg_envstep_per_episode: 309.85714285714283
avg_sample_per_episode: 309.85714285714283
avg_envstep_per_sec: 2534.505648934552
avg_train_sample_per_sec: 2534.505648934552
avg_episode_per_sec: 8.179594072172367
collect_time: 0.8557881892714652
reward_mean: 2098.6511182915933
reward_std: 1106.9680603594506
reward_max: 3493.889174487883
reward_min: 695.6082699598392
total_envstep_count: 21522977
total_train_sample_count: 16149875
total_episode_count: 47648
total_duration: 4295.215256851058
[2023-06-29 13:59:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 275.1111111111111
avg_sample_per_episode: 275.1111111111111
avg_envstep_per_sec: 2662.3797034941313
avg_train_sample_per_sec: 2662.3797034941313
avg_episode_per_sec: 9.677470650826809
collect_time: 0.929995070481673
reward_mean: 1980.7230617886812
reward_std: 944.3360160747197
reward_max: 3511.138439513744
reward_min: 1003.0370715537061
total_envstep_count: 21527833
total_train_sample_count: 16153151
total_episode_count: 47657
total_duration: 4296.14525192154
[2023-06-29 13:59:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3372
train_sample_count: 3372
avg_envstep_per_episode: 259.38461538461536
avg_sample_per_episode: 259.38461538461536
avg_envstep_per_sec: 2736.3148419199542
avg_train_sample_per_sec: 2736.3148419199542
avg_episode_per_sec: 10.549256507995079
collect_time: 1.2323143332563342
reward_mean: 1701.3457097693283
reward_std: 716.4383839939667
reward_max: 3579.0901807702753
reward_min: 1008.6343904551617
total_envstep_count: 21532713
total_train_sample_count: 16156523
total_episode_count: 47670
total_duration: 4297.377566254796
[2023-06-29 13:59:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2176
train_sample_count: 2176
avg_envstep_per_episode: 217.6
avg_sample_per_episode: 217.6
avg_envstep_per_sec: 2560.5410671414475
avg_train_sample_per_sec: 2560.5410671414475
avg_episode_per_sec: 11.767192404142682
collect_time: 0.8498203867627306
reward_mean: 1206.8182263679041
reward_std: 324.4160521438608
reward_max: 1996.8363507657655
reward_min: 941.9458283425669
total_envstep_count: 21537281
total_train_sample_count: 16159899
total_episode_count: 47680
total_duration: 4298.227386641559
[2023-06-29 13:59:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2102
train_sample_count: 2102
avg_envstep_per_episode: 191.0909090909091
avg_sample_per_episode: 191.0909090909091
avg_envstep_per_sec: 2577.8653991563406
avg_train_sample_per_sec: 2577.8653991563406
avg_episode_per_sec: 13.490256608334798
collect_time: 0.8154033180661499
reward_mean: 1601.6783775907033
reward_std: 715.3616486653709
reward_max: 3527.420561832062
reward_min: 851.5258858524617
total_envstep_count: 21541665
total_train_sample_count: 16163201
total_episode_count: 47691
total_duration: 4299.042789959625
[2023-06-29 13:59:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 244.0909090909091
avg_sample_per_episode: 244.0909090909091
avg_envstep_per_sec: 2514.9208705038527
avg_train_sample_per_sec: 2514.9208705038527
avg_episode_per_sec: 10.303213994615412
collect_time: 1.06762802420184
reward_mean: 1653.0569700822098
reward_std: 733.0925602699532
reward_max: 3453.4198557909763
reward_min: 890.8815265825949
total_envstep_count: 21546041
total_train_sample_count: 16166686
total_episode_count: 47702
total_duration: 4300.110417983827
[2023-06-29 13:59:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3402
train_sample_count: 3402
avg_envstep_per_episode: 261.6923076923077
avg_sample_per_episode: 261.6923076923077
avg_envstep_per_sec: 2557.3479656246973
avg_train_sample_per_sec: 2557.3479656246973
avg_episode_per_sec: 9.772346723433587
collect_time: 1.3302843593163416
reward_mean: 1444.0556690878707
reward_std: 564.9622149344198
reward_max: 2751.791131565427
reward_min: 886.6018212672903
total_envstep_count: 21550745
total_train_sample_count: 16170088
total_episode_count: 47715
total_duration: 4301.440702343143
[2023-06-29 13:59:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2995
train_sample_count: 2995
avg_envstep_per_episode: 230.3846153846154
avg_sample_per_episode: 230.3846153846154
avg_envstep_per_sec: 2692.4941409826656
avg_train_sample_per_sec: 2692.4941409826656
avg_episode_per_sec: 11.686952865701052
collect_time: 1.1123515384538332
reward_mean: 1216.081055414351
reward_std: 288.67723009293707
reward_max: 1739.0933308045987
reward_min: 781.4589656273945
total_envstep_count: 21555281
total_train_sample_count: 16173483
total_episode_count: 47728
total_duration: 4302.553053881597
[2023-06-29 13:59:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 283.0833333333333
avg_sample_per_episode: 283.0833333333333
avg_envstep_per_sec: 2549.2536887024103
avg_train_sample_per_sec: 2549.2536887024103
avg_episode_per_sec: 9.005311823499829
collect_time: 1.3325468606967474
reward_mean: 1521.190787686661
reward_std: 572.4892798581278
reward_max: 2835.6979734900415
reward_min: 844.9638752745988
total_envstep_count: 21559921
total_train_sample_count: 16176880
total_episode_count: 47740
total_duration: 4303.885600742294
[2023-06-29 13:59:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3402
train_sample_count: 3402
avg_envstep_per_episode: 243.0
avg_sample_per_episode: 243.0
avg_envstep_per_sec: 2561.4507879405587
avg_train_sample_per_sec: 2561.4507879405587
avg_episode_per_sec: 10.540949744611353
collect_time: 1.3281535667274147
reward_mean: 1226.8533181911314
reward_std: 292.7943254361586
reward_max: 1960.4633608856157
reward_min: 840.6253665720898
total_envstep_count: 21564729
total_train_sample_count: 16180282
total_episode_count: 47754
total_duration: 4305.213754309021
[2023-06-29 13:59:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3514
train_sample_count: 3514
avg_envstep_per_episode: 219.625
avg_sample_per_episode: 219.625
avg_envstep_per_sec: 2587.1557759575035
avg_train_sample_per_sec: 2587.1557759575035
avg_episode_per_sec: 11.779878319669908
collect_time: 1.3582483253059907
reward_mean: 1117.6605646465257
reward_std: 202.16128335960406
reward_max: 1515.2227464717826
reward_min: 721.9453071495046
total_envstep_count: 21569225
total_train_sample_count: 16183796
total_episode_count: 47770
total_duration: 4306.572002634327
[2023-06-29 13:59:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3439
train_sample_count: 3439
avg_envstep_per_episode: 286.5833333333333
avg_sample_per_episode: 286.5833333333333
avg_envstep_per_sec: 2767.4191312696407
avg_train_sample_per_sec: 2767.4191312696407
avg_episode_per_sec: 9.656594816875744
collect_time: 1.2426740717161446
reward_mean: 1334.6629256655963
reward_std: 499.9221764539916
reward_max: 2464.2482202557535
reward_min: 875.0918613070966
total_envstep_count: 21573993
total_train_sample_count: 16187235
total_episode_count: 47782
total_duration: 4307.814676706043
[2023-06-29 14:00:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 243.85714285714286
avg_sample_per_episode: 243.85714285714286
avg_envstep_per_sec: 2736.0912843436167
avg_train_sample_per_sec: 2736.0912843436167
avg_episode_per_sec: 11.220057990864275
collect_time: 1.247765386899002
reward_mean: 1229.9096750298218
reward_std: 314.06094283788195
reward_max: 2105.2286080642994
reward_min: 825.3842789288262
total_envstep_count: 21578729
total_train_sample_count: 16190649
total_episode_count: 47796
total_duration: 4309.062442092943
[2023-06-29 14:00:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 202.9
avg_sample_per_episode: 202.9
avg_envstep_per_sec: 2630.197840147822
avg_train_sample_per_sec: 2630.197840147822
avg_episode_per_sec: 12.96302533340474
collect_time: 0.771424859768711
reward_mean: 1223.0871194694498
reward_std: 406.03469891279553
reward_max: 1943.8692059217285
reward_min: 698.6862494631732
total_envstep_count: 21582921
total_train_sample_count: 16193878
total_episode_count: 47806
total_duration: 4309.833866952711
[2023-06-29 14:00:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3483
train_sample_count: 3483
avg_envstep_per_episode: 232.2
avg_sample_per_episode: 232.2
avg_envstep_per_sec: 2566.1220098388476
avg_train_sample_per_sec: 2566.1220098388476
avg_episode_per_sec: 11.051343711622943
collect_time: 1.3573010116610678
reward_mean: 1380.6459933363826
reward_std: 531.3953118647311
reward_max: 2491.1372955837246
reward_min: 693.8959749432056
total_envstep_count: 21587953
total_train_sample_count: 16197361
total_episode_count: 47821
total_duration: 4311.191167964372
[2023-06-29 14:00:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3024
train_sample_count: 3024
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2568.1534605022007
avg_train_sample_per_sec: 2568.1534605022007
avg_episode_per_sec: 11.889599354176855
collect_time: 1.1774997275313364
reward_mean: 1192.8339409027199
reward_std: 422.2025946127964
reward_max: 2295.9413142815874
reward_min: 714.0792359197538
total_envstep_count: 21592753
total_train_sample_count: 16200785
total_episode_count: 47835
total_duration: 4312.368667691903
[2023-06-29 14:00:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 267.5833333333333
avg_sample_per_episode: 267.5833333333333
avg_envstep_per_sec: 2725.2044999795653
avg_train_sample_per_sec: 2725.2044999795653
avg_episode_per_sec: 10.184507629945433
collect_time: 1.1782602002983913
reward_mean: 1514.2540431807595
reward_std: 711.9851065211799
reward_max: 3528.429638133321
reward_min: 838.5303580745785
total_envstep_count: 21597129
total_train_sample_count: 16203996
total_episode_count: 47847
total_duration: 4313.546927892202
[2023-06-29 14:00:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3277
train_sample_count: 3277
avg_envstep_per_episode: 273.0833333333333
avg_sample_per_episode: 273.0833333333333
avg_envstep_per_sec: 2565.641056591115
avg_train_sample_per_sec: 2565.641056591115
avg_episode_per_sec: 9.3950847357624
collect_time: 1.2772636264069006
reward_mean: 1352.3214212190326
reward_std: 536.9778518537503
reward_max: 2641.256528414439
reward_min: 811.2765154833651
total_envstep_count: 21601697
total_train_sample_count: 16207273
total_episode_count: 47859
total_duration: 4314.824191518609
[2023-06-29 14:00:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2888
train_sample_count: 2888
avg_envstep_per_episode: 262.54545454545456
avg_sample_per_episode: 262.54545454545456
avg_envstep_per_sec: 2705.9807538772493
avg_train_sample_per_sec: 2705.9807538772493
avg_episode_per_sec: 10.306713397731906
collect_time: 1.067265536113642
reward_mean: 1405.4175904456488
reward_std: 393.244306976718
reward_max: 2432.4217994490123
reward_min: 1002.6431805130924
total_envstep_count: 21606785
total_train_sample_count: 16210561
total_episode_count: 47870
total_duration: 4315.891457054723
[2023-06-29 14:00:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1855
train_sample_count: 1855
avg_envstep_per_episode: 206.11111111111111
avg_sample_per_episode: 206.11111111111111
avg_envstep_per_sec: 2728.66213868512
avg_train_sample_per_sec: 2728.66213868512
avg_episode_per_sec: 13.238792047528884
collect_time: 0.6798203316200525
reward_mean: 1313.4382148253792
reward_std: 395.01614934595244
reward_max: 2163.3152885774166
reward_min: 712.8386074030611
total_envstep_count: 21610737
total_train_sample_count: 16214016
total_episode_count: 47879
total_duration: 4316.571277386343
[2023-06-29 14:00:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3059
train_sample_count: 3059
avg_envstep_per_episode: 235.30769230769232
avg_sample_per_episode: 235.30769230769232
avg_envstep_per_sec: 2797.034505996952
avg_train_sample_per_sec: 2797.034505996952
avg_episode_per_sec: 11.88671087870558
collect_time: 1.0936582989739254
reward_mean: 1690.8102419540228
reward_std: 940.6104455080914
reward_max: 3608.170215542825
reward_min: 923.1111716589365
total_envstep_count: 21615601
total_train_sample_count: 16217475
total_episode_count: 47892
total_duration: 4317.664935685318
[2023-06-29 14:00:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3309
train_sample_count: 3309
avg_envstep_per_episode: 220.6
avg_sample_per_episode: 220.6
avg_envstep_per_sec: 2631.7722713191274
avg_train_sample_per_sec: 2631.7722713191274
avg_episode_per_sec: 11.930064693196407
collect_time: 1.2573276328127831
reward_mean: 1254.550252128089
reward_std: 368.77179836558986
reward_max: 2213.9790697916005
reward_min: 877.2898248550392
total_envstep_count: 21619889
total_train_sample_count: 16220784
total_episode_count: 47907
total_duration: 4318.922263318131
[2023-06-29 14:00:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3483
train_sample_count: 3483
avg_envstep_per_episode: 248.78571428571428
avg_sample_per_episode: 248.78571428571428
avg_envstep_per_sec: 2693.7700038835164
avg_train_sample_per_sec: 2693.7700038835164
avg_episode_per_sec: 10.827671563126394
collect_time: 1.2929834377020597
reward_mean: 1175.5764242533282
reward_std: 256.2788153952856
reward_max: 1863.2806090510605
reward_min: 782.6752925306349
total_envstep_count: 21624889
total_train_sample_count: 16224267
total_episode_count: 47921
total_duration: 4320.215246755833
[2023-06-29 14:00:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 810
train_sample_count: 810
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 2729.3727996011353
avg_train_sample_per_sec: 2729.3727996011353
avg_episode_per_sec: 16.847980244451453
collect_time: 0.2967714780913665
reward_mean: 1207.5655651240256
reward_std: 438.2226461135584
reward_max: 1996.230063851101
reward_min: 732.4343764611081
total_envstep_count: 21629041
total_train_sample_count: 16227477
total_episode_count: 47926
total_duration: 4320.512018233924
[2023-06-29 14:00:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3099
train_sample_count: 3099
avg_envstep_per_episode: 238.3846153846154
avg_sample_per_episode: 238.3846153846154
avg_envstep_per_sec: 2755.7469355387293
avg_train_sample_per_sec: 2755.7469355387293
avg_episode_per_sec: 11.560087177155044
collect_time: 1.124558993438259
reward_mean: 2011.1359940473826
reward_std: 800.5406009632408
reward_max: 3557.989351101804
reward_min: 1033.7736607483898
total_envstep_count: 21633489
total_train_sample_count: 16230976
total_episode_count: 47939
total_duration: 4321.636577227362
[2023-06-29 14:00:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3011
train_sample_count: 3011
avg_envstep_per_episode: 250.91666666666666
avg_sample_per_episode: 250.91666666666666
avg_envstep_per_sec: 2580.717597126917
avg_train_sample_per_sec: 2580.717597126917
avg_episode_per_sec: 10.285158141987049
collect_time: 1.1667297511948271
reward_mean: 1318.2471715882523
reward_std: 425.16938946789037
reward_max: 2304.434117125556
reward_min: 741.2240038005966
total_envstep_count: 21638345
total_train_sample_count: 16234387
total_episode_count: 47951
total_duration: 4322.803306978557
[2023-06-29 14:00:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 246.91666666666666
avg_sample_per_episode: 246.91666666666666
avg_envstep_per_sec: 2650.334792211844
avg_train_sample_per_sec: 2650.334792211844
avg_episode_per_sec: 10.733721736936257
collect_time: 1.1179719666764139
reward_mean: 1385.9122378885404
reward_std: 737.8014481702389
reward_max: 3508.266701857844
reward_min: 765.0050462283854
total_envstep_count: 21642849
total_train_sample_count: 16237750
total_episode_count: 47963
total_duration: 4323.921278945233
[2023-06-29 14:00:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3271
train_sample_count: 3271
avg_envstep_per_episode: 327.1
avg_sample_per_episode: 327.1
avg_envstep_per_sec: 2600.221929383682
avg_train_sample_per_sec: 2600.221929383682
avg_episode_per_sec: 7.949318035413275
collect_time: 1.2579695459976792
reward_mean: 1867.6535000537474
reward_std: 712.6666148523092
reward_max: 3522.7302089645705
reward_min: 1124.4549013513194
total_envstep_count: 21646945
total_train_sample_count: 16241021
total_episode_count: 47973
total_duration: 4325.179248491231
[2023-06-29 14:00:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2804
train_sample_count: 2804
avg_envstep_per_episode: 233.66666666666666
avg_sample_per_episode: 233.66666666666666
avg_envstep_per_sec: 2678.454915348911
avg_train_sample_per_sec: 2678.454915348911
avg_episode_per_sec: 11.46271718408949
collect_time: 1.0468722037961706
reward_mean: 1098.7539882560748
reward_std: 247.00323136743484
reward_max: 1596.925128693201
reward_min: 634.996845748527
total_envstep_count: 21651385
total_train_sample_count: 16244225
total_episode_count: 47985
total_duration: 4326.226120695027
[2023-06-29 14:00:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1977
train_sample_count: 1977
avg_envstep_per_episode: 219.66666666666666
avg_sample_per_episode: 219.66666666666666
avg_envstep_per_sec: 2730.3736035697943
avg_train_sample_per_sec: 2730.3736035697943
avg_episode_per_sec: 12.429621867540794
collect_time: 0.7240767334606498
reward_mean: 1151.7748510043093
reward_std: 183.33729811719175
reward_max: 1386.6744471942216
reward_min: 840.886039003571
total_envstep_count: 21656081
total_train_sample_count: 16247802
total_episode_count: 47994
total_duration: 4326.950197428488
[2023-06-29 14:00:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3466
train_sample_count: 3466
avg_envstep_per_episode: 216.625
avg_sample_per_episode: 216.625
avg_envstep_per_sec: 2605.6858671374266
avg_train_sample_per_sec: 2605.6858671374266
avg_episode_per_sec: 12.028555647489563
collect_time: 1.3301680159196256
reward_mean: 1562.0899002662738
reward_std: 928.8408564442097
reward_max: 3522.381180129888
reward_min: 835.9791107936547
total_envstep_count: 21660849
total_train_sample_count: 16251268
total_episode_count: 48010
total_duration: 4328.280365444407
[2023-06-29 14:00:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2977
train_sample_count: 2977
avg_envstep_per_episode: 212.64285714285714
avg_sample_per_episode: 212.64285714285714
avg_envstep_per_sec: 2594.3835055870013
avg_train_sample_per_sec: 2594.3835055870013
avg_episode_per_sec: 12.200661430372193
collect_time: 1.147478772351518
reward_mean: 1035.7700403582573
reward_std: 241.70655971688723
reward_max: 1586.7915850628654
reward_min: 744.304073781213
total_envstep_count: 21665209
total_train_sample_count: 16254645
total_episode_count: 48024
total_duration: 4329.427844216759
[2023-06-29 14:01:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 215.2
avg_sample_per_episode: 215.2
avg_envstep_per_sec: 2498.560835851959
avg_train_sample_per_sec: 2498.560835851959
avg_episode_per_sec: 11.610412806003525
collect_time: 1.291943727637641
reward_mean: 1177.2445105185932
reward_std: 692.1434051753337
reward_max: 3600.475891299626
reward_min: 700.1295642773051
total_envstep_count: 21669129
total_train_sample_count: 16257873
total_episode_count: 48039
total_duration: 4330.719787944397
[2023-06-29 14:01:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 213.33333333333334
avg_sample_per_episode: 213.33333333333334
avg_envstep_per_sec: 2739.2430715620844
avg_train_sample_per_sec: 2739.2430715620844
avg_episode_per_sec: 12.84020189794727
collect_time: 1.1682059300327676
reward_mean: 932.2628270471693
reward_std: 142.2459633674521
reward_max: 1162.141361756848
reward_min: 694.0792283922854
total_envstep_count: 21673265
total_train_sample_count: 16261073
total_episode_count: 48054
total_duration: 4331.887993874429
[2023-06-29 14:01:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 226.46666666666667
avg_sample_per_episode: 226.46666666666667
avg_envstep_per_sec: 2613.5429567021215
avg_train_sample_per_sec: 2613.5429567021215
avg_episode_per_sec: 11.540519384907807
collect_time: 1.2997681906428191
reward_mean: 1046.2946597724356
reward_std: 271.8239498629318
reward_max: 1747.1969242543637
reward_min: 684.3944246029293
total_envstep_count: 21677889
total_train_sample_count: 16264470
total_episode_count: 48069
total_duration: 4333.187762065072
[2023-06-29 14:01:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2823
train_sample_count: 2823
avg_envstep_per_episode: 217.15384615384616
avg_sample_per_episode: 217.15384615384616
avg_envstep_per_sec: 2765.0552114292036
avg_train_sample_per_sec: 2765.0552114292036
avg_episode_per_sec: 12.733162503924778
collect_time: 1.0209561054445802
reward_mean: 1133.830888730581
reward_std: 492.2895368552265
reward_max: 2367.2692596070433
reward_min: 575.1817768350022
total_envstep_count: 21681753
total_train_sample_count: 16267693
total_episode_count: 48082
total_duration: 4334.2087181705165
[2023-06-29 14:01:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3273
train_sample_count: 3273
avg_envstep_per_episode: 233.78571428571428
avg_sample_per_episode: 233.78571428571428
avg_envstep_per_sec: 2767.9649422357115
avg_train_sample_per_sec: 2767.9649422357115
avg_episode_per_sec: 11.839752273541082
collect_time: 1.1824571727979931
reward_mean: 1117.185076359497
reward_std: 300.50405834386436
reward_max: 1837.7822238730175
reward_min: 718.502027801066
total_envstep_count: 21685953
total_train_sample_count: 16270966
total_episode_count: 48096
total_duration: 4335.391175343315
[2023-06-29 14:01:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3420
train_sample_count: 3420
avg_envstep_per_episode: 244.28571428571428
avg_sample_per_episode: 244.28571428571428
avg_envstep_per_sec: 2534.9869479363037
avg_train_sample_per_sec: 2534.9869479363037
avg_episode_per_sec: 10.377139552955631
collect_time: 1.349119372304529
reward_mean: 1136.6645888421094
reward_std: 376.67161512363845
reward_max: 1866.5660370711798
reward_min: 628.5257225000448
total_envstep_count: 21690313
total_train_sample_count: 16274386
total_episode_count: 48110
total_duration: 4336.74029471562
[2023-06-29 14:01:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3282
train_sample_count: 3282
avg_envstep_per_episode: 205.125
avg_sample_per_episode: 205.125
avg_envstep_per_sec: 2612.855675955899
avg_train_sample_per_sec: 2612.855675955899
avg_episode_per_sec: 12.737870449510782
collect_time: 1.256096932640299
reward_mean: 949.8927077407425
reward_std: 178.5429902437455
reward_max: 1377.2452516965866
reward_min: 693.2876692337794
total_envstep_count: 21694673
total_train_sample_count: 16277668
total_episode_count: 48126
total_duration: 4337.99639164826
[2023-06-29 14:01:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2845
train_sample_count: 2845
avg_envstep_per_episode: 203.21428571428572
avg_sample_per_episode: 203.21428571428572
avg_envstep_per_sec: 2760.15709556353
avg_train_sample_per_sec: 2760.15709556353
avg_episode_per_sec: 13.582495373599093
collect_time: 1.0307384331757203
reward_mean: 1012.4616240773338
reward_std: 284.6133561341536
reward_max: 1891.162754919094
reward_min: 719.1591014531054
total_envstep_count: 21699009
total_train_sample_count: 16280913
total_episode_count: 48140
total_duration: 4339.027130081436
[2023-06-29 14:01:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3042
train_sample_count: 3042
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 2716.6070099483177
avg_train_sample_per_sec: 2716.6070099483177
avg_episode_per_sec: 11.609431666445802
collect_time: 1.1197791910497472
reward_mean: 1240.8185233814272
reward_std: 666.0165019419003
reward_max: 3162.578042952095
reward_min: 722.9281115415637
total_envstep_count: 21703209
total_train_sample_count: 16284355
total_episode_count: 48153
total_duration: 4340.146909272486
[2023-06-29 14:01:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3285
train_sample_count: 3285
avg_envstep_per_episode: 219.0
avg_sample_per_episode: 219.0
avg_envstep_per_sec: 2570.6017277057913
avg_train_sample_per_sec: 2570.6017277057913
avg_episode_per_sec: 11.737907432446537
collect_time: 1.2779109126841652
reward_mean: 1098.7212781246023
reward_std: 440.126535334204
reward_max: 2534.1031966775427
reward_min: 696.3665254738053
total_envstep_count: 21707433
total_train_sample_count: 16287640
total_episode_count: 48168
total_duration: 4341.42482018517
[2023-06-29 14:01:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3499
train_sample_count: 3499
avg_envstep_per_episode: 218.6875
avg_sample_per_episode: 218.6875
avg_envstep_per_sec: 2607.2589774837297
avg_train_sample_per_sec: 2607.2589774837297
avg_episode_per_sec: 11.92230455551291
collect_time: 1.3420224190298469
reward_mean: 990.9493745986027
reward_std: 402.2050412923067
reward_max: 2288.3838574637484
reward_min: 665.7010113809622
total_envstep_count: 21712273
total_train_sample_count: 16291139
total_episode_count: 48184
total_duration: 4342.766842604199
[2023-06-29 14:01:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 189.23529411764707
avg_sample_per_episode: 189.23529411764707
avg_envstep_per_sec: 2805.6133435009683
avg_train_sample_per_sec: 2805.6133435009683
avg_episode_per_sec: 14.826057457108007
collect_time: 1.1466298474278303
reward_mean: 971.9168356346325
reward_std: 288.37242009461073
reward_max: 1964.3037903978575
reward_min: 618.9872765980383
total_envstep_count: 21716713
total_train_sample_count: 16294356
total_episode_count: 48201
total_duration: 4343.913472451627
[2023-06-29 14:01:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 189.05882352941177
avg_sample_per_episode: 189.05882352941177
avg_envstep_per_sec: 2626.8719301886163
avg_train_sample_per_sec: 2626.8719301886163
avg_episode_per_sec: 13.894468828004506
collect_time: 1.223508448609151
reward_mean: 939.6953216903781
reward_std: 226.85126342201366
reward_max: 1437.0596279032704
reward_min: 699.3683560529134
total_envstep_count: 21720745
total_train_sample_count: 16297570
total_episode_count: 48218
total_duration: 4345.136980900236
[2023-06-29 14:01:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2851
train_sample_count: 2851
avg_envstep_per_episode: 219.30769230769232
avg_sample_per_episode: 219.30769230769232
avg_envstep_per_sec: 2622.191233150106
avg_train_sample_per_sec: 2622.191233150106
avg_episode_per_sec: 11.956676966310551
collect_time: 1.087258611788973
reward_mean: 1020.048004528695
reward_std: 357.6226163116112
reward_max: 1726.9967024120351
reward_min: 161.9836427125129
total_envstep_count: 21725025
total_train_sample_count: 16300821
total_episode_count: 48231
total_duration: 4346.224239512026
[2023-06-29 14:01:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1866
train_sample_count: 1866
avg_envstep_per_episode: 207.33333333333334
avg_sample_per_episode: 207.33333333333334
avg_envstep_per_sec: 2732.4111707198495
avg_train_sample_per_sec: 2732.4111707198495
avg_episode_per_sec: 13.178832013118246
collect_time: 0.6829133257819339
reward_mean: 1337.599964120716
reward_std: 385.92787225167194
reward_max: 2126.569951273991
reward_min: 715.2447162903634
total_envstep_count: 21729865
total_train_sample_count: 16304287
total_episode_count: 48240
total_duration: 4346.907152837807
[2023-06-29 14:01:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2141
train_sample_count: 2141
avg_envstep_per_episode: 194.63636363636363
avg_sample_per_episode: 194.63636363636363
avg_envstep_per_sec: 2709.8045446528836
avg_train_sample_per_sec: 2709.8045446528836
avg_episode_per_sec: 13.922396072480952
collect_time: 0.7900938848983496
reward_mean: 1632.408535222533
reward_std: 539.6817917258261
reward_max: 2798.5363567975974
reward_min: 941.4658941484163
total_envstep_count: 21734561
total_train_sample_count: 16307628
total_episode_count: 48251
total_duration: 4347.697246722705
[2023-06-29 14:01:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2270
train_sample_count: 2270
avg_envstep_per_episode: 252.22222222222223
avg_sample_per_episode: 252.22222222222223
avg_envstep_per_sec: 2613.87923175159
avg_train_sample_per_sec: 2613.87923175159
avg_episode_per_sec: 10.363397835138462
collect_time: 0.8684410405904054
reward_mean: 2020.511906450303
reward_std: 851.0125802942777
reward_max: 3695.8740717142514
reward_min: 1027.3700033606951
total_envstep_count: 21738817
total_train_sample_count: 16311098
total_episode_count: 48260
total_duration: 4348.5656877632955
[2023-06-29 14:01:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2610.645500493408
avg_train_sample_per_sec: 2610.645500493408
avg_episode_per_sec: 11.706930495486134
collect_time: 0.512516923399642
reward_mean: 1741.9220253324713
reward_std: 759.8141777908493
reward_max: 3322.711260920592
reward_min: 937.7025371994094
total_envstep_count: 21743161
total_train_sample_count: 16314436
total_episode_count: 48266
total_duration: 4349.078204686695
[2023-06-29 14:01:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2508
train_sample_count: 2508
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2516.9626041390115
avg_train_sample_per_sec: 2516.9626041390115
avg_episode_per_sec: 11.039309667276367
collect_time: 0.9964391190698372
reward_mean: 2051.008101072295
reward_std: 998.4975891154202
reward_max: 3583.6425869080836
reward_min: 1010.8270589209268
total_envstep_count: 21748385
total_train_sample_count: 16317744
total_episode_count: 48277
total_duration: 4350.074643805765
[2023-06-29 14:01:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1852
train_sample_count: 1852
avg_envstep_per_episode: 205.77777777777777
avg_sample_per_episode: 205.77777777777777
avg_envstep_per_sec: 2738.995896178209
avg_train_sample_per_sec: 2738.995896178209
avg_episode_per_sec: 13.310455219008574
collect_time: 0.6761601952686906
reward_mean: 1974.1350954872864
reward_std: 820.6233669445547
reward_max: 3563.7532867000627
reward_min: 961.8861438254797
total_envstep_count: 21753177
total_train_sample_count: 16321196
total_episode_count: 48286
total_duration: 4350.750804001033
[2023-06-29 14:02:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2844
train_sample_count: 2844
avg_envstep_per_episode: 237.0
avg_sample_per_episode: 237.0
avg_envstep_per_sec: 2766.3553289292486
avg_train_sample_per_sec: 2766.3553289292486
avg_episode_per_sec: 11.672385354131851
collect_time: 1.0280674974247812
reward_mean: 1787.7419234601657
reward_std: 781.5365901774188
reward_max: 3576.5745537047137
reward_min: 977.5053233845955
total_envstep_count: 21757809
total_train_sample_count: 16324440
total_episode_count: 48298
total_duration: 4351.778871498458
[2023-06-29 14:02:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 340.5
avg_sample_per_episode: 340.5
avg_envstep_per_sec: 2486.739998408545
avg_train_sample_per_sec: 2486.739998408545
avg_episode_per_sec: 7.303201170069149
collect_time: 0.8215575417242944
reward_mean: 1776.4729193713817
reward_std: 494.95701927897153
reward_max: 2670.127863119301
reward_min: 1114.6968334636547
total_envstep_count: 21761689
total_train_sample_count: 16327683
total_episode_count: 48304
total_duration: 4352.6004290401825
[2023-06-29 14:02:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 271.1666666666667
avg_sample_per_episode: 271.1666666666667
avg_envstep_per_sec: 2834.012199085125
avg_train_sample_per_sec: 2834.012199085125
avg_episode_per_sec: 10.451182049484173
collect_time: 0.5740977404844015
reward_mean: 2669.3323901851795
reward_std: 932.7983986648369
reward_max: 3606.795757106193
reward_min: 1195.6797410416923
total_envstep_count: 21765801
total_train_sample_count: 16330910
total_episode_count: 48310
total_duration: 4353.174526780667
[2023-06-29 14:02:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 329.57142857142856
avg_sample_per_episode: 329.57142857142856
avg_envstep_per_sec: 2708.0916294527906
avg_train_sample_per_sec: 2708.0916294527906
avg_episode_per_sec: 8.217009712253807
collect_time: 0.8518914112467321
reward_mean: 2513.705814614703
reward_std: 595.8945606465238
reward_max: 3220.503264558862
reward_min: 1450.5094178054478
total_envstep_count: 21770617
total_train_sample_count: 16334417
total_episode_count: 48317
total_duration: 4354.026418191914
[2023-06-29 14:02:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1440
train_sample_count: 1440
avg_envstep_per_episode: 205.71428571428572
avg_sample_per_episode: 205.71428571428572
avg_envstep_per_sec: 2746.092707051562
avg_train_sample_per_sec: 2746.092707051562
avg_episode_per_sec: 13.349061770389536
collect_time: 0.5243814224852249
reward_mean: 2102.3667802163827
reward_std: 555.9641445499309
reward_max: 3085.744894565558
reward_min: 1458.6710660093838
total_envstep_count: 21775121
total_train_sample_count: 16337857
total_episode_count: 48324
total_duration: 4354.550799614399
[2023-06-29 14:02:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2899
train_sample_count: 2899
avg_envstep_per_episode: 241.58333333333334
avg_sample_per_episode: 241.58333333333334
avg_envstep_per_sec: 2623.9168089534833
avg_train_sample_per_sec: 2623.9168089534833
avg_episode_per_sec: 10.86133208259462
collect_time: 1.104836856910959
reward_mean: 1859.4545138407655
reward_std: 1096.9663861919844
reward_max: 3577.219418352759
reward_min: 132.22583177653243
total_envstep_count: 21779377
total_train_sample_count: 16341156
total_episode_count: 48336
total_duration: 4355.65563647131
[2023-06-29 14:02:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1815
train_sample_count: 1815
avg_envstep_per_episode: 226.875
avg_sample_per_episode: 226.875
avg_envstep_per_sec: 2705.966103884525
avg_train_sample_per_sec: 2705.966103884525
avg_episode_per_sec: 11.927123322906999
collect_time: 0.6707401091959331
reward_mean: 1347.6197524594156
reward_std: 405.3784110666556
reward_max: 1951.2755189619113
reward_min: 824.3785925373476
total_envstep_count: 21783833
total_train_sample_count: 16344571
total_episode_count: 48344
total_duration: 4356.326376580506
[2023-06-29 14:02:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1413
train_sample_count: 1413
avg_envstep_per_episode: 235.5
avg_sample_per_episode: 235.5
avg_envstep_per_sec: 2714.482589670085
avg_train_sample_per_sec: 2714.482589670085
avg_episode_per_sec: 11.526465348917558
collect_time: 0.5205411909352988
reward_mean: 2545.5361891894477
reward_std: 730.0250822263893
reward_max: 3721.2993847608573
reward_min: 1280.0574900120039
total_envstep_count: 21788401
total_train_sample_count: 16347984
total_episode_count: 48350
total_duration: 4356.846917771441
[2023-06-29 14:02:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2309
train_sample_count: 2309
avg_envstep_per_episode: 209.9090909090909
avg_sample_per_episode: 209.9090909090909
avg_envstep_per_sec: 2697.6376758793117
avg_train_sample_per_sec: 2697.6376758793117
avg_episode_per_sec: 12.85145709600365
collect_time: 0.8559340717419982
reward_mean: 1920.330757932653
reward_std: 748.1118680797218
reward_max: 3363.8513805686575
reward_min: 802.8644262680577
total_envstep_count: 21793281
total_train_sample_count: 16351493
total_episode_count: 48361
total_duration: 4357.702851843183
[2023-06-29 14:02:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2494
train_sample_count: 2494
avg_envstep_per_episode: 311.75
avg_sample_per_episode: 311.75
avg_envstep_per_sec: 2726.7905325558945
avg_train_sample_per_sec: 2726.7905325558945
avg_episode_per_sec: 8.746721836586671
collect_time: 0.9146283772895112
reward_mean: 2213.2387458710787
reward_std: 707.9370955306315
reward_max: 3241.391969422667
reward_min: 940.4625822513301
total_envstep_count: 21797577
total_train_sample_count: 16354787
total_episode_count: 48369
total_duration: 4358.617480220473
[2023-06-29 14:02:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2094
train_sample_count: 2094
avg_envstep_per_episode: 261.75
avg_sample_per_episode: 261.75
avg_envstep_per_sec: 2547.868827586885
avg_train_sample_per_sec: 2547.868827586885
avg_episode_per_sec: 9.733978328889723
collect_time: 0.8218633460747078
reward_mean: 1903.4519815755407
reward_std: 722.8901258118144
reward_max: 3556.9981675125655
reward_min: 1032.8700100174756
total_envstep_count: 21802529
total_train_sample_count: 16358081
total_episode_count: 48377
total_duration: 4359.439343566548
[2023-06-29 14:02:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2425
train_sample_count: 2425
avg_envstep_per_episode: 269.44444444444446
avg_sample_per_episode: 269.44444444444446
avg_envstep_per_sec: 2558.987297116644
avg_train_sample_per_sec: 2558.987297116644
avg_episode_per_sec: 9.497272442907134
collect_time: 0.9476404993226752
reward_mean: 2055.5031665265096
reward_std: 1131.9646301032517
reward_max: 3570.4635094116593
reward_min: 137.73879064334866
total_envstep_count: 21806657
total_train_sample_count: 16361306
total_episode_count: 48386
total_duration: 4360.386984065871
[2023-06-29 14:02:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1725
train_sample_count: 1725
avg_envstep_per_episode: 191.66666666666666
avg_sample_per_episode: 191.66666666666666
avg_envstep_per_sec: 2261.677429541448
avg_train_sample_per_sec: 2261.677429541448
avg_episode_per_sec: 11.800056154129292
collect_time: 0.762708234812133
reward_mean: 1459.3740398398122
reward_std: 1024.5431461320572
reward_max: 3469.5602542220295
reward_min: 138.5801755853631
total_envstep_count: 21810905
total_train_sample_count: 16364631
total_episode_count: 48395
total_duration: 4361.149692300683
[2023-06-29 14:02:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 271.3333333333333
avg_sample_per_episode: 271.3333333333333
avg_envstep_per_sec: 2803.4806041170973
avg_train_sample_per_sec: 2803.4806041170973
avg_episode_per_sec: 10.332238098711661
collect_time: 0.5807067106543109
reward_mean: 2208.6887897176343
reward_std: 1072.9055283191228
reward_max: 3686.7407072097694
reward_min: 587.461880362576
total_envstep_count: 21815281
total_train_sample_count: 16367859
total_episode_count: 48401
total_duration: 4361.730399011337
[2023-06-29 14:02:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1993
train_sample_count: 1993
avg_envstep_per_episode: 221.44444444444446
avg_sample_per_episode: 221.44444444444446
avg_envstep_per_sec: 2507.4998649824956
avg_train_sample_per_sec: 2507.4998649824956
avg_episode_per_sec: 11.323381226714732
collect_time: 0.7948155961371957
reward_mean: 2207.7455834526063
reward_std: 744.6787005415753
reward_max: 3607.3562789561606
reward_min: 1101.212784332539
total_envstep_count: 21819449
total_train_sample_count: 16371452
total_episode_count: 48410
total_duration: 4362.5252146074745
[2023-06-29 14:02:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2184
train_sample_count: 2184
avg_envstep_per_episode: 312.0
avg_sample_per_episode: 312.0
avg_envstep_per_sec: 2619.378013801182
avg_train_sample_per_sec: 2619.378013801182
avg_episode_per_sec: 8.395442351926865
collect_time: 0.8337857264177875
reward_mean: 2111.340772102128
reward_std: 1062.6031985889465
reward_max: 3611.816195755233
reward_min: 563.959892206729
total_envstep_count: 21824249
total_train_sample_count: 16374836
total_episode_count: 48417
total_duration: 4363.359000333892
[2023-06-29 14:02:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2216
train_sample_count: 2216
avg_envstep_per_episode: 246.22222222222223
avg_sample_per_episode: 246.22222222222223
avg_envstep_per_sec: 2754.6952766376958
avg_train_sample_per_sec: 2754.6952766376958
avg_episode_per_sec: 11.187841827499668
collect_time: 0.8044446944072841
reward_mean: 2074.773295628792
reward_std: 1137.7744783940016
reward_max: 3748.1929255631408
reward_min: 143.20366215643847
total_envstep_count: 21828977
total_train_sample_count: 16378252
total_episode_count: 48426
total_duration: 4364.1634450283
[2023-06-29 14:02:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1364
train_sample_count: 1364
avg_envstep_per_episode: 227.33333333333334
avg_sample_per_episode: 227.33333333333334
avg_envstep_per_sec: 2755.596005618977
avg_train_sample_per_sec: 2755.596005618977
avg_episode_per_sec: 12.121390054042422
collect_time: 0.4949927337747069
reward_mean: 2311.125649928696
reward_std: 908.8434303681381
reward_max: 3542.3702435576597
reward_min: 1199.1976527504912
total_envstep_count: 21833481
total_train_sample_count: 16381616
total_episode_count: 48432
total_duration: 4364.658437762075
[2023-06-29 14:02:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2744
train_sample_count: 2744
avg_envstep_per_episode: 392.0
avg_sample_per_episode: 392.0
avg_envstep_per_sec: 2688.003811379251
avg_train_sample_per_sec: 2688.003811379251
avg_episode_per_sec: 6.85715258004911
collect_time: 1.0208318858714773
reward_mean: 3051.470873237613
reward_std: 650.3397754862044
reward_max: 3668.6119400288485
reward_min: 1907.693101779962
total_envstep_count: 21838713
total_train_sample_count: 16385560
total_episode_count: 48439
total_duration: 4365.679269647946
[2023-06-29 14:03:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 254.8
avg_sample_per_episode: 254.8
avg_envstep_per_sec: 2292.1185788314174
avg_train_sample_per_sec: 2292.1185788314174
avg_episode_per_sec: 8.995755803890964
collect_time: 0.5558176665753125
reward_mean: 2241.96985778597
reward_std: 628.5706067123634
reward_max: 3438.7010393099763
reward_min: 1664.1258446494764
total_envstep_count: 21843249
total_train_sample_count: 16388834
total_episode_count: 48444
total_duration: 4366.2350873145215
[2023-06-29 14:03:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1444
train_sample_count: 1444
avg_envstep_per_episode: 180.5
avg_sample_per_episode: 180.5
avg_envstep_per_sec: 2791.6286106766256
avg_train_sample_per_sec: 2791.6286106766256
avg_episode_per_sec: 15.466086485743077
collect_time: 0.5172607826404273
reward_mean: 2497.3008598850874
reward_std: 1097.1608065832138
reward_max: 3569.1731800875928
reward_min: 152.8277664024555
total_envstep_count: 21848057
total_train_sample_count: 16392278
total_episode_count: 48452
total_duration: 4366.752348097162
[2023-06-29 14:03:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1567
train_sample_count: 1567
avg_envstep_per_episode: 261.1666666666667
avg_sample_per_episode: 261.1666666666667
avg_envstep_per_sec: 2618.3582055417314
avg_train_sample_per_sec: 2618.3582055417314
avg_episode_per_sec: 10.025621718730305
collect_time: 0.5984666256448253
reward_mean: 2529.957302740848
reward_std: 960.8923772905421
reward_max: 3545.5074201163065
reward_min: 979.0941421417936
total_envstep_count: 21852505
total_train_sample_count: 16395845
total_episode_count: 48458
total_duration: 4367.350814722807
[2023-06-29 14:03:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2584
train_sample_count: 2584
avg_envstep_per_episode: 258.4
avg_sample_per_episode: 258.4
avg_envstep_per_sec: 2801.4592509345653
avg_train_sample_per_sec: 2801.4592509345653
avg_episode_per_sec: 10.841560568632218
collect_time: 0.9223764361869548
reward_mean: 2205.2055519298438
reward_std: 1293.1021845007951
reward_max: 3594.5338208521716
reward_min: 164.42572608692228
total_envstep_count: 21857257
total_train_sample_count: 16399229
total_episode_count: 48468
total_duration: 4368.2731911589935
[2023-06-29 14:03:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1259
train_sample_count: 1259
avg_envstep_per_episode: 314.75
avg_sample_per_episode: 314.75
avg_envstep_per_sec: 2723.8324529053266
avg_train_sample_per_sec: 2723.8324529053266
avg_episode_per_sec: 8.65395537062852
collect_time: 0.4622163887713102
reward_mean: 2466.81093839323
reward_std: 1244.3448725126495
reward_max: 3519.3032822740483
reward_min: 342.99139084547124
total_envstep_count: 21862041
total_train_sample_count: 16402488
total_episode_count: 48472
total_duration: 4368.735407547765
[2023-06-29 14:03:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 254.25
avg_sample_per_episode: 254.25
avg_envstep_per_sec: 2515.4642584560556
avg_train_sample_per_sec: 2515.4642584560556
avg_episode_per_sec: 9.89366473335715
collect_time: 0.8085982510633766
reward_mean: 2589.0310777162285
reward_std: 1245.443104718656
reward_max: 3566.421455847651
reward_min: 667.0525479811565
total_envstep_count: 21866585
total_train_sample_count: 16405722
total_episode_count: 48480
total_duration: 4369.544005798829
[2023-06-29 14:03:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 157.25
avg_sample_per_episode: 157.25
avg_envstep_per_sec: 2046.6552548633185
avg_train_sample_per_sec: 2046.6552548633185
avg_episode_per_sec: 13.015295738399482
collect_time: 0.30733070384245365
reward_mean: 2192.655140029273
reward_std: 1350.9727011384484
reward_max: 3528.824455468266
reward_min: 548.6596598457194
total_envstep_count: 21870753
total_train_sample_count: 16409151
total_episode_count: 48484
total_duration: 4369.851336502671
[2023-06-29 14:03:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 254.25
avg_sample_per_episode: 254.25
avg_envstep_per_sec: 2707.718563551189
avg_train_sample_per_sec: 2707.718563551189
avg_episode_per_sec: 10.649827191941746
collect_time: 0.7511858977442607
reward_mean: 3040.354451439213
reward_std: 608.0109852575125
reward_max: 3636.5239441036115
reward_min: 1954.9728494644855
total_envstep_count: 21875585
total_train_sample_count: 16412385
total_episode_count: 48492
total_duration: 4370.602522400415
[2023-06-29 14:03:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3044
train_sample_count: 3044
avg_envstep_per_episode: 338.22222222222223
avg_sample_per_episode: 338.22222222222223
avg_envstep_per_sec: 2715.9143727739133
avg_train_sample_per_sec: 2715.9143727739133
avg_episode_per_sec: 8.029970221736274
collect_time: 1.1208011675607412
reward_mean: 2385.278700863561
reward_std: 1141.948539020454
reward_max: 3576.6610118773524
reward_min: 141.23382360698957
total_envstep_count: 21881089
total_train_sample_count: 16416629
total_episode_count: 48501
total_duration: 4371.723323567976
[2023-06-29 14:03:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1801
train_sample_count: 1801
avg_envstep_per_episode: 300.1666666666667
avg_sample_per_episode: 300.1666666666667
avg_envstep_per_sec: 2763.33572143946
avg_train_sample_per_sec: 2763.33572143946
avg_episode_per_sec: 9.206004624451282
collect_time: 0.6517485320465637
reward_mean: 2273.0337849737602
reward_std: 925.3985569864021
reward_max: 3573.5239291144408
reward_min: 1250.0273923133318
total_envstep_count: 21884905
total_train_sample_count: 16420030
total_episode_count: 48507
total_duration: 4372.375072100022
[2023-06-29 14:03:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1785
train_sample_count: 1785
avg_envstep_per_episode: 297.5
avg_sample_per_episode: 297.5
avg_envstep_per_sec: 2488.5682752952157
avg_train_sample_per_sec: 2488.5682752952157
avg_episode_per_sec: 8.364935379143583
collect_time: 0.7172798985345289
reward_mean: 2623.858058942052
reward_std: 801.730531509587
reward_max: 3735.585663973994
reward_min: 1455.9880666227048
total_envstep_count: 21889473
total_train_sample_count: 16423415
total_episode_count: 48513
total_duration: 4373.092351998557
[2023-06-29 14:03:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2727.388363666703
avg_train_sample_per_sec: 2727.388363666703
avg_episode_per_sec: 9.978250110975743
collect_time: 0.9019617568114774
reward_mean: 2169.1495966938514
reward_std: 1026.0593227934844
reward_max: 3670.8513771944317
reward_min: 314.9427113307222
total_envstep_count: 21893889
total_train_sample_count: 16426675
total_episode_count: 48522
total_duration: 4373.994313755368
[2023-06-29 14:03:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2430
train_sample_count: 2430
avg_envstep_per_episode: 347.14285714285717
avg_sample_per_episode: 347.14285714285717
avg_envstep_per_sec: 2780.2398100292776
avg_train_sample_per_sec: 2780.2398100292776
avg_episode_per_sec: 8.008921263458824
collect_time: 0.8740253237271682
reward_mean: 2111.631275292391
reward_std: 839.3830973732856
reward_max: 3732.1373827677176
reward_min: 1151.8735824498958
total_envstep_count: 21898049
total_train_sample_count: 16429905
total_episode_count: 48529
total_duration: 4374.868339079096
[2023-06-29 14:03:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2082
train_sample_count: 2082
avg_envstep_per_episode: 231.33333333333334
avg_sample_per_episode: 231.33333333333334
avg_envstep_per_sec: 2485.7185938417974
avg_train_sample_per_sec: 2485.7185938417974
avg_episode_per_sec: 10.745181241391055
collect_time: 0.8375847552325579
reward_mean: 1588.478398114575
reward_std: 786.9021750093052
reward_max: 2745.881746784196
reward_min: 135.88448140522345
total_envstep_count: 21902681
total_train_sample_count: 16433187
total_episode_count: 48538
total_duration: 4375.705923834328
[2023-06-29 14:03:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 189.0
avg_sample_per_episode: 189.0
avg_envstep_per_sec: 2657.5417757573655
avg_train_sample_per_sec: 2657.5417757573655
avg_episode_per_sec: 14.061067596599816
collect_time: 0.35559177606180326
reward_mean: 2131.960571441912
reward_std: 989.2292901201529
reward_max: 3171.1434034926538
reward_min: 603.8914855074246
total_envstep_count: 21906697
total_train_sample_count: 16436532
total_episode_count: 48543
total_duration: 4376.0615156103895
[2023-06-29 14:03:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1754
train_sample_count: 1754
avg_envstep_per_episode: 250.57142857142858
avg_sample_per_episode: 250.57142857142858
avg_envstep_per_sec: 2732.8685686334825
avg_train_sample_per_sec: 2732.8685686334825
avg_episode_per_sec: 10.90654502875392
collect_time: 0.6418164488887417
reward_mean: 2773.894171545874
reward_std: 686.7372538662959
reward_max: 3558.4366593824484
reward_min: 1614.1432609760707
total_envstep_count: 21911289
total_train_sample_count: 16439886
total_episode_count: 48550
total_duration: 4376.703332059278
[2023-06-29 14:03:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1357
train_sample_count: 1357
avg_envstep_per_episode: 193.85714285714286
avg_sample_per_episode: 193.85714285714286
avg_envstep_per_sec: 2710.02063086482
avg_train_sample_per_sec: 2710.02063086482
avg_episode_per_sec: 13.979472672110345
collect_time: 0.5007341953581199
reward_mean: 2273.1183005562953
reward_std: 1091.8051955307171
reward_max: 3705.1407729939647
reward_min: 133.87893622352672
total_envstep_count: 21915993
total_train_sample_count: 16443243
total_episode_count: 48557
total_duration: 4377.204066254636
[2023-06-29 14:03:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1905
train_sample_count: 1905
avg_envstep_per_episode: 211.66666666666666
avg_sample_per_episode: 211.66666666666666
avg_envstep_per_sec: 2731.2715463281334
avg_train_sample_per_sec: 2731.2715463281334
avg_episode_per_sec: 12.903645100762834
collect_time: 0.6974773352583868
reward_mean: 2254.519635991614
reward_std: 915.318358233175
reward_max: 3740.9356840204055
reward_min: 1250.006835272135
total_envstep_count: 21921465
total_train_sample_count: 16446748
total_episode_count: 48566
total_duration: 4377.901543589895
[2023-06-29 14:03:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3495
train_sample_count: 3495
avg_envstep_per_episode: 388.3333333333333
avg_sample_per_episode: 388.3333333333333
avg_envstep_per_sec: 2624.8243067536346
avg_train_sample_per_sec: 2624.8243067536346
avg_episode_per_sec: 6.759204223399917
collect_time: 1.3315176909202708
reward_mean: 2870.4771196021493
reward_std: 784.98615602469
reward_max: 3690.377928116947
reward_min: 1037.6383038135486
total_envstep_count: 21926401
total_train_sample_count: 16450243
total_episode_count: 48575
total_duration: 4379.233061280815
[2023-06-29 14:04:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1994
train_sample_count: 1994
avg_envstep_per_episode: 284.85714285714283
avg_sample_per_episode: 284.85714285714283
avg_envstep_per_sec: 2784.9515408114694
avg_train_sample_per_sec: 2784.9515408114694
avg_episode_per_sec: 9.776660373962029
collect_time: 0.7159909143047406
reward_mean: 1623.0255932712353
reward_std: 861.6901504006423
reward_max: 2830.123674263452
reward_min: 374.0963973523403
total_envstep_count: 21931257
total_train_sample_count: 16453837
total_episode_count: 48582
total_duration: 4379.949052195119
[2023-06-29 14:04:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2193
train_sample_count: 2193
avg_envstep_per_episode: 313.2857142857143
avg_sample_per_episode: 313.2857142857143
avg_envstep_per_sec: 2800.693007260347
avg_train_sample_per_sec: 2800.693007260347
avg_episode_per_sec: 8.939740561250536
collect_time: 0.7830204861136154
reward_mean: 2717.1320121969475
reward_std: 560.0435798712856
reward_max: 3497.6461177552937
reward_min: 1920.5615157584664
total_envstep_count: 21935641
total_train_sample_count: 16457230
total_episode_count: 48589
total_duration: 4380.732072681233
[2023-06-29 14:04:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2416
train_sample_count: 2416
avg_envstep_per_episode: 302.0
avg_sample_per_episode: 302.0
avg_envstep_per_sec: 2745.1960072565557
avg_train_sample_per_sec: 2745.1960072565557
avg_episode_per_sec: 9.090053004160781
collect_time: 0.8800828770017257
reward_mean: 1998.5868642895812
reward_std: 977.012388372109
reward_max: 3160.864468822089
reward_min: 311.15161437999825
total_envstep_count: 21940089
total_train_sample_count: 16460446
total_episode_count: 48597
total_duration: 4381.612155558235
[2023-06-29 14:04:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 137.16666666666666
avg_sample_per_episode: 137.16666666666666
avg_envstep_per_sec: 2137.8984128177563
avg_train_sample_per_sec: 2137.8984128177563
avg_episode_per_sec: 15.586136666958126
collect_time: 0.3849574867850169
reward_mean: 1370.7177436017055
reward_std: 865.5297991262295
reward_max: 2930.883612320078
reward_min: 377.7230943075164
total_envstep_count: 21944481
total_train_sample_count: 16463669
total_episode_count: 48603
total_duration: 4381.99711304502
[2023-06-29 14:04:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3184
train_sample_count: 3184
avg_envstep_per_episode: 244.92307692307693
avg_sample_per_episode: 244.92307692307693
avg_envstep_per_sec: 2621.4091030918007
avg_train_sample_per_sec: 2621.4091030918007
avg_episode_per_sec: 10.702989428452705
collect_time: 1.214613925100304
reward_mean: 2032.2227487701805
reward_std: 1244.0371016491235
reward_max: 3596.906677961004
reward_min: 294.91593197536776
total_envstep_count: 21949465
total_train_sample_count: 16467253
total_episode_count: 48616
total_duration: 4383.21172697012
[2023-06-29 14:04:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 302.0
avg_sample_per_episode: 302.0
avg_envstep_per_sec: 2501.218197501183
avg_train_sample_per_sec: 2501.218197501183
avg_episode_per_sec: 8.282179461924446
collect_time: 0.8451881575593727
reward_mean: 1774.9025629073778
reward_std: 879.6821108005565
reward_max: 3420.975413773386
reward_min: 297.4776616102993
total_envstep_count: 21953969
total_train_sample_count: 16470567
total_episode_count: 48623
total_duration: 4384.0569151276795
[2023-06-29 14:04:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2409
train_sample_count: 2409
avg_envstep_per_episode: 267.6666666666667
avg_sample_per_episode: 267.6666666666667
avg_envstep_per_sec: 2720.7811420983335
avg_train_sample_per_sec: 2720.7811420983335
avg_episode_per_sec: 10.164811240716066
collect_time: 0.8854074893146752
reward_mean: 2032.9029223750101
reward_std: 1016.8311925834356
reward_max: 3596.505295413335
reward_min: 240.36949096409637
total_envstep_count: 21958641
total_train_sample_count: 16473776
total_episode_count: 48632
total_duration: 4384.942322616994
[2023-06-29 14:04:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2512
train_sample_count: 2512
avg_envstep_per_episode: 251.2
avg_sample_per_episode: 251.2
avg_envstep_per_sec: 2720.7276008148015
avg_train_sample_per_sec: 2720.7276008148015
avg_episode_per_sec: 10.830921977765929
collect_time: 0.9232824334371835
reward_mean: 1579.1272361635938
reward_std: 890.1808233682109
reward_max: 2992.1212826619508
reward_min: 486.08969372414896
total_envstep_count: 21963457
total_train_sample_count: 16477088
total_episode_count: 48642
total_duration: 4385.865605050431
[2023-06-29 14:04:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2110
train_sample_count: 2110
avg_envstep_per_episode: 301.42857142857144
avg_sample_per_episode: 301.42857142857144
avg_envstep_per_sec: 2596.474847138372
avg_train_sample_per_sec: 2596.474847138372
avg_episode_per_sec: 8.613897597141516
collect_time: 0.812640261978842
reward_mean: 2249.315212911704
reward_std: 900.8457461894475
reward_max: 3506.284195335849
reward_min: 533.4043240338713
total_envstep_count: 21967921
total_train_sample_count: 16480398
total_episode_count: 48649
total_duration: 4386.678245312411
[2023-06-29 14:04:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1753
train_sample_count: 1753
avg_envstep_per_episode: 250.42857142857142
avg_sample_per_episode: 250.42857142857142
avg_envstep_per_sec: 2785.0560708814082
avg_train_sample_per_sec: 2785.0560708814082
avg_episode_per_sec: 11.12115943877345
collect_time: 0.6294307746002451
reward_mean: 2086.748652847246
reward_std: 813.3099952478115
reward_max: 3605.9686861486302
reward_min: 1077.0357811804975
total_envstep_count: 21972209
total_train_sample_count: 16483751
total_episode_count: 48656
total_duration: 4387.307676087011
[2023-06-29 14:04:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2370
train_sample_count: 2370
avg_envstep_per_episode: 296.25
avg_sample_per_episode: 296.25
avg_envstep_per_sec: 2650.743064642258
avg_train_sample_per_sec: 2650.743064642258
avg_episode_per_sec: 8.947655914404246
collect_time: 0.8940889185424892
reward_mean: 2403.1887268399296
reward_std: 890.9144414633688
reward_max: 3475.902498932548
reward_min: 700.7176331806862
total_envstep_count: 21977073
total_train_sample_count: 16487321
total_episode_count: 48664
total_duration: 4388.201765005553
[2023-06-29 14:04:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2208
train_sample_count: 2208
avg_envstep_per_episode: 315.42857142857144
avg_sample_per_episode: 315.42857142857144
avg_envstep_per_sec: 2750.674529535072
avg_train_sample_per_sec: 2750.674529535072
avg_episode_per_sec: 8.72043555559126
collect_time: 0.8027121988777071
reward_mean: 2273.4132797150364
reward_std: 1056.4206469043138
reward_max: 3542.8562461506003
reward_min: 230.6850066660424
total_envstep_count: 21982041
total_train_sample_count: 16490729
total_episode_count: 48671
total_duration: 4389.004477204431
[2023-06-29 14:04:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2916
train_sample_count: 2916
avg_envstep_per_episode: 324.0
avg_sample_per_episode: 324.0
avg_envstep_per_sec: 2719.104212068958
avg_train_sample_per_sec: 2719.104212068958
avg_episode_per_sec: 8.392296950830119
collect_time: 1.072412005048245
reward_mean: 2188.6002478991377
reward_std: 1190.2089620402157
reward_max: 3545.5097155368617
reward_min: 231.00350031209305
total_envstep_count: 21986481
total_train_sample_count: 16494045
total_episode_count: 48680
total_duration: 4390.076889209479
[2023-06-29 14:04:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2546
train_sample_count: 2546
avg_envstep_per_episode: 318.25
avg_sample_per_episode: 318.25
avg_envstep_per_sec: 2562.04532791043
avg_train_sample_per_sec: 2562.04532791043
avg_episode_per_sec: 8.050417369710699
collect_time: 0.9937372974101453
reward_mean: 1790.5135688728424
reward_std: 904.0010187937987
reward_max: 3500.080003004332
reward_min: 218.88348293239258
total_envstep_count: 21990873
total_train_sample_count: 16497391
total_episode_count: 48688
total_duration: 4391.070626506889
[2023-06-29 14:04:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1749
train_sample_count: 1749
avg_envstep_per_episode: 249.85714285714286
avg_sample_per_episode: 249.85714285714286
avg_envstep_per_sec: 2708.8569919982824
avg_train_sample_per_sec: 2708.8569919982824
avg_episode_per_sec: 10.841623181239553
collect_time: 0.6456597764911131
reward_mean: 2052.068141611758
reward_std: 984.5798409645173
reward_max: 3640.2334235395647
reward_min: 1249.3563002282674
total_envstep_count: 21995505
total_train_sample_count: 16500740
total_episode_count: 48695
total_duration: 4391.71628628338
[2023-06-29 14:04:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2321
train_sample_count: 2321
avg_envstep_per_episode: 290.125
avg_sample_per_episode: 290.125
avg_envstep_per_sec: 2791.595527274531
avg_train_sample_per_sec: 2791.595527274531
avg_episode_per_sec: 9.622044040584337
collect_time: 0.831424172063358
reward_mean: 2417.2671136999693
reward_std: 655.4128628388955
reward_max: 3590.8891776324144
reward_min: 1295.4773814951923
total_envstep_count: 21999993
total_train_sample_count: 16504261
total_episode_count: 48703
total_duration: 4392.547710455444
[2023-06-29 14:04:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1827
train_sample_count: 1827
avg_envstep_per_episode: 304.5
avg_sample_per_episode: 304.5
avg_envstep_per_sec: 2735.749819991587
avg_train_sample_per_sec: 2735.749819991587
avg_episode_per_sec: 8.984400065653816
collect_time: 0.6678242237828671
reward_mean: 2234.8068767997925
reward_std: 991.3584858090715
reward_max: 3509.7565453875022
reward_min: 675.8158433034804
total_envstep_count: 22004297
total_train_sample_count: 16507688
total_episode_count: 48709
total_duration: 4393.215534679227
[2023-06-29 14:04:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2081
train_sample_count: 2081
avg_envstep_per_episode: 346.8333333333333
avg_sample_per_episode: 346.8333333333333
avg_envstep_per_sec: 2604.9509141648523
avg_train_sample_per_sec: 2604.9509141648523
avg_episode_per_sec: 7.510670583848685
collect_time: 0.7988634214503688
reward_mean: 2699.020912132117
reward_std: 825.8526430942027
reward_max: 3587.2321200977008
reward_min: 1477.5297632361937
total_envstep_count: 22008673
total_train_sample_count: 16510969
total_episode_count: 48715
total_duration: 4394.014398100678
[2023-06-29 14:04:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 274.0
avg_sample_per_episode: 274.0
avg_envstep_per_sec: 2391.7504002317546
avg_train_sample_per_sec: 2391.7504002317546
avg_episode_per_sec: 8.72901605923998
collect_time: 0.6873626946359873
reward_mean: 2496.649996351877
reward_std: 673.0055656272899
reward_max: 3570.831179582608
reward_min: 1866.631889971281
total_envstep_count: 22013289
total_train_sample_count: 16514213
total_episode_count: 48721
total_duration: 4394.701760795314
[2023-06-29 14:04:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2408
train_sample_count: 2408
avg_envstep_per_episode: 301.0
avg_sample_per_episode: 301.0
avg_envstep_per_sec: 2566.9662832891763
avg_train_sample_per_sec: 2566.9662832891763
avg_episode_per_sec: 8.52812718700723
collect_time: 0.9380723134838043
reward_mean: 2526.7444959113436
reward_std: 742.3458682130072
reward_max: 3577.9805316139664
reward_min: 1504.6750848046447
total_envstep_count: 22018313
total_train_sample_count: 16517421
total_episode_count: 48729
total_duration: 4395.639833108798
[2023-06-29 14:05:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 967
train_sample_count: 967
avg_envstep_per_episode: 138.14285714285714
avg_sample_per_episode: 138.14285714285714
avg_envstep_per_sec: 2727.8468854920598
avg_train_sample_per_sec: 2727.8468854920598
avg_episode_per_sec: 19.746564838101776
collect_time: 0.35449203734379275
reward_mean: 1771.452239564084
reward_std: 444.64811424521884
reward_max: 2626.2162549866925
reward_min: 1221.1923565568188
total_envstep_count: 22022713
total_train_sample_count: 16520788
total_episode_count: 48736
total_duration: 4395.994325146142
[2023-06-29 14:05:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2300
train_sample_count: 2300
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 2770.965014425353
avg_train_sample_per_sec: 2770.965014425353
avg_episode_per_sec: 9.638139180609922
collect_time: 0.8300357413487509
reward_mean: 2503.4362012930965
reward_std: 825.8561600041942
reward_max: 3503.3864461073745
reward_min: 656.9109308023923
total_envstep_count: 22027137
total_train_sample_count: 16524288
total_episode_count: 48744
total_duration: 4396.824360887491
[2023-06-29 14:05:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 276.8333333333333
avg_sample_per_episode: 276.8333333333333
avg_envstep_per_sec: 2711.5413491858367
avg_train_sample_per_sec: 2711.5413491858367
avg_episode_per_sec: 9.794851351664672
collect_time: 0.6125667235348372
reward_mean: 2496.294357518261
reward_std: 509.2612603503978
reward_max: 3499.9021650869663
reward_min: 1893.8420560977818
total_envstep_count: 22030993
total_train_sample_count: 16527549
total_episode_count: 48750
total_duration: 4397.436927611026
[2023-06-29 14:05:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1001
train_sample_count: 1001
avg_envstep_per_episode: 200.2
avg_sample_per_episode: 200.2
avg_envstep_per_sec: 2782.9639317226424
avg_train_sample_per_sec: 2782.9639317226424
avg_episode_per_sec: 13.900918739873338
collect_time: 0.3596884561059997
reward_mean: 2187.422542105518
reward_std: 300.3695906747628
reward_max: 2744.2102234899694
reward_min: 1882.7415454033319
total_envstep_count: 22035185
total_train_sample_count: 16530950
total_episode_count: 48755
total_duration: 4397.796616067131
[2023-06-29 14:05:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2166
train_sample_count: 2166
avg_envstep_per_episode: 240.66666666666666
avg_sample_per_episode: 240.66666666666666
avg_envstep_per_sec: 2790.323795607784
avg_train_sample_per_sec: 2790.323795607784
avg_episode_per_sec: 11.594143195046195
collect_time: 0.7762539972634986
reward_mean: 2277.8508813474873
reward_std: 600.8465173076272
reward_max: 3553.794295687783
reward_min: 1243.420236787931
total_envstep_count: 22040113
total_train_sample_count: 16534316
total_episode_count: 48764
total_duration: 4398.572870064395
[2023-06-29 14:05:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 973
train_sample_count: 973
avg_envstep_per_episode: 243.25
avg_sample_per_episode: 243.25
avg_envstep_per_sec: 2623.738116141202
avg_train_sample_per_sec: 2623.738116141202
avg_episode_per_sec: 10.786179305822003
collect_time: 0.3708449383778499
reward_mean: 2593.306941240278
reward_std: 769.3112009134485
reward_max: 3552.3834215450565
reward_min: 1423.2517646021593
total_envstep_count: 22044249
total_train_sample_count: 16537689
total_episode_count: 48768
total_duration: 4398.9437150027725
[2023-06-29 14:05:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 954
train_sample_count: 954
avg_envstep_per_episode: 190.8
avg_sample_per_episode: 190.8
avg_envstep_per_sec: 2786.5210739764325
avg_train_sample_per_sec: 2786.5210739764325
avg_episode_per_sec: 14.60440814453057
collect_time: 0.3423623847346753
reward_mean: 3244.08628001273
reward_std: 405.5303482890014
reward_max: 3556.1150434664337
reward_min: 2533.4770757596593
total_envstep_count: 22048825
total_train_sample_count: 16541043
total_episode_count: 48773
total_duration: 4399.286077387507
[2023-06-29 14:05:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1663
train_sample_count: 1663
avg_envstep_per_episode: 332.6
avg_sample_per_episode: 332.6
avg_envstep_per_sec: 2754.1766159275558
avg_train_sample_per_sec: 2754.1766159275558
avg_episode_per_sec: 8.280747492265652
collect_time: 0.6038102242182941
reward_mean: 3538.403626443308
reward_std: 12.82800051757239
reward_max: 3555.818338432329
reward_min: 3522.63230300265
total_envstep_count: 22052897
total_train_sample_count: 16544306
total_episode_count: 48778
total_duration: 4399.8898876117255
[2023-06-29 14:05:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 605
train_sample_count: 605
avg_envstep_per_episode: 201.66666666666666
avg_sample_per_episode: 201.66666666666666
avg_envstep_per_sec: 2764.8774140469945
avg_train_sample_per_sec: 2764.8774140469945
avg_episode_per_sec: 13.710135937423113
collect_time: 0.21881621113698926
reward_mean: 3592.772069580253
reward_std: 76.61066526743446
reward_max: 3685.343854323729
reward_min: 3497.7353869468793
total_envstep_count: 22056993
total_train_sample_count: 16547711
total_episode_count: 48781
total_duration: 4400.1087038228625
[2023-06-29 14:05:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1465
train_sample_count: 1465
avg_envstep_per_episode: 244.16666666666666
avg_sample_per_episode: 244.16666666666666
avg_envstep_per_sec: 2571.1788300076505
avg_train_sample_per_sec: 2571.1788300076505
avg_episode_per_sec: 10.530425242352152
collect_time: 0.5697775599667803
reward_mean: 3145.5325649297997
reward_std: 559.6212825789302
reward_max: 3548.460153618347
reward_min: 2117.8432686141473
total_envstep_count: 22061649
total_train_sample_count: 16551176
total_episode_count: 48787
total_duration: 4400.678481382829
[2023-06-29 14:05:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 253.6
avg_sample_per_episode: 253.6
avg_envstep_per_sec: 2808.905187732448
avg_train_sample_per_sec: 2808.905187732448
avg_episode_per_sec: 11.076124557304606
collect_time: 0.4514214312173426
reward_mean: 2791.547676267306
reward_std: 933.5000795516919
reward_max: 3524.9015728475124
reward_min: 1252.3234701043762
total_envstep_count: 22066193
total_train_sample_count: 16554444
total_episode_count: 48792
total_duration: 4401.1299028140465
[2023-06-29 14:05:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 169.0
avg_sample_per_episode: 169.0
avg_envstep_per_sec: 2744.8590188277294
avg_train_sample_per_sec: 2744.8590188277294
avg_episode_per_sec: 16.241769342175914
collect_time: 0.24627858675550673
reward_mean: 3524.700751599202
reward_std: 13.41414354766205
reward_max: 3540.3732379264775
reward_min: 3503.5403517924415
total_envstep_count: 22070921
total_train_sample_count: 16557920
total_episode_count: 48796
total_duration: 4401.376181400802
[2023-06-29 14:05:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 313.85714285714283
avg_sample_per_episode: 313.85714285714283
avg_envstep_per_sec: 2789.9610909165367
avg_train_sample_per_sec: 2789.9610909165367
avg_episode_per_sec: 8.889270658359472
collect_time: 0.7874661790635432
reward_mean: 3504.637461189273
reward_std: 25.242446086569466
reward_max: 3542.03113222343
reward_min: 3461.533645929464
total_envstep_count: 22075721
total_train_sample_count: 16561317
total_episode_count: 48803
total_duration: 4402.163647579866
[2023-06-29 14:05:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 897
train_sample_count: 897
avg_envstep_per_episode: 299.0
avg_sample_per_episode: 299.0
avg_envstep_per_sec: 2675.830834593368
avg_train_sample_per_sec: 2675.830834593368
avg_episode_per_sec: 8.94926700532899
collect_time: 0.33522298510186366
reward_mean: 2826.522438566552
reward_std: 992.0127525269528
reward_max: 3540.488949554073
reward_min: 1423.679336986624
total_envstep_count: 22080097
total_train_sample_count: 16564614
total_episode_count: 48806
total_duration: 4402.498870564968
[2023-06-29 14:05:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 565
train_sample_count: 565
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 2757.7005169320687
avg_train_sample_per_sec: 2757.7005169320687
avg_episode_per_sec: 24.40442935338114
collect_time: 0.20488084058836104
reward_mean: 3303.0751739348516
reward_std: 455.42339206235357
reward_max: 3554.9472100151393
reward_min: 2392.604713820129
total_envstep_count: 22084249
total_train_sample_count: 16567979
total_episode_count: 48811
total_duration: 4402.7037514055555
[2023-06-29 14:05:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1600
train_sample_count: 1600
avg_envstep_per_episode: 266.6666666666667
avg_sample_per_episode: 266.6666666666667
avg_envstep_per_sec: 2698.531338969858
avg_train_sample_per_sec: 2698.531338969858
avg_episode_per_sec: 10.119492521136968
collect_time: 0.5929151078937578
reward_mean: 3064.055226372531
reward_std: 777.2591397533939
reward_max: 3614.3876841212723
reward_min: 1488.0666123651438
total_envstep_count: 22088697
total_train_sample_count: 16571179
total_episode_count: 48817
total_duration: 4403.296666513449
[2023-06-29 14:05:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 883
train_sample_count: 883
avg_envstep_per_episode: 220.75
avg_sample_per_episode: 220.75
avg_envstep_per_sec: 2699.133999822831
avg_train_sample_per_sec: 2699.133999822831
avg_episode_per_sec: 12.22710758696639
collect_time: 0.32714196481462554
reward_mean: 3102.0330167359907
reward_std: 767.5532944532798
reward_max: 3561.2200613141104
reward_min: 1772.765425994958
total_envstep_count: 22092897
total_train_sample_count: 16574462
total_episode_count: 48821
total_duration: 4403.6238084782635
[2023-06-29 14:05:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1885
train_sample_count: 1885
avg_envstep_per_episode: 314.1666666666667
avg_sample_per_episode: 314.1666666666667
avg_envstep_per_sec: 2666.1855164232657
avg_train_sample_per_sec: 2666.1855164232657
avg_episode_per_sec: 8.486532147766361
collect_time: 0.7070025654211641
reward_mean: 3536.639522798796
reward_std: 11.918165303566834
reward_max: 3549.2572814033233
reward_min: 3514.7319372272723
total_envstep_count: 22097073
total_train_sample_count: 16577947
total_episode_count: 48827
total_duration: 4404.330811043685
[2023-06-29 14:05:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1639
train_sample_count: 1639
avg_envstep_per_episode: 409.75
avg_sample_per_episode: 409.75
avg_envstep_per_sec: 2397.6830179814297
avg_train_sample_per_sec: 2397.6830179814297
avg_episode_per_sec: 5.851575394707576
collect_time: 0.683576597785577
reward_mean: 3333.984852681984
reward_std: 399.49953033214376
reward_max: 3597.4390086636513
reward_min: 2642.9364940923997
total_envstep_count: 22101497
total_train_sample_count: 16581186
total_episode_count: 48831
total_duration: 4405.01438764147
[2023-06-29 14:06:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1316
train_sample_count: 1316
avg_envstep_per_episode: 329.0
avg_sample_per_episode: 329.0
avg_envstep_per_sec: 2812.8107738708236
avg_train_sample_per_sec: 2812.8107738708236
avg_episode_per_sec: 8.54957682027606
collect_time: 0.4678594138734042
reward_mean: 3560.6266639775613
reward_std: 14.511055507206448
reward_max: 3578.5892102124935
reward_min: 3545.0492288228347
total_envstep_count: 22105073
total_train_sample_count: 16584502
total_episode_count: 48835
total_duration: 4405.482247055344
[2023-06-29 14:06:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1637
train_sample_count: 1637
avg_envstep_per_episode: 409.25
avg_sample_per_episode: 409.25
avg_envstep_per_sec: 2796.4987638793777
avg_train_sample_per_sec: 2796.4987638793777
avg_episode_per_sec: 6.83322850062157
collect_time: 0.5853748341118914
reward_mean: 3575.576424387505
reward_std: 96.95886240196612
reward_max: 3742.996414034663
reward_min: 3512.0137437832104
total_envstep_count: 22109497
total_train_sample_count: 16587739
total_episode_count: 48839
total_duration: 4406.067621889455
[2023-06-29 14:06:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1542
train_sample_count: 1542
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 2674.389036869581
avg_train_sample_per_sec: 2674.389036869581
avg_episode_per_sec: 10.406183022838837
collect_time: 0.576580287587829
reward_mean: 2766.9267287631906
reward_std: 936.9191515784177
reward_max: 3570.4276999440394
reward_min: 1387.1618785909736
total_envstep_count: 22114665
total_train_sample_count: 16591281
total_episode_count: 48845
total_duration: 4406.644202177043
[2023-06-29 14:06:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1577
train_sample_count: 1577
avg_envstep_per_episode: 315.4
avg_sample_per_episode: 315.4
avg_envstep_per_sec: 2736.6432018421824
avg_train_sample_per_sec: 2736.6432018421824
avg_episode_per_sec: 8.676738116176862
collect_time: 0.5762534183990211
reward_mean: 3437.4666384244388
reward_std: 164.1609671012585
reward_max: 3555.9907973017293
reward_min: 3127.9806219163806
total_envstep_count: 22119401
total_train_sample_count: 16594858
total_episode_count: 48850
total_duration: 4407.220455595441
[2023-06-29 14:06:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 284.3
avg_sample_per_episode: 284.3
avg_envstep_per_sec: 2667.7336690874267
avg_train_sample_per_sec: 2667.7336690874267
avg_episode_per_sec: 9.383516247229782
collect_time: 1.0656985863856971
reward_mean: 2397.9730142562985
reward_std: 950.8944993876238
reward_max: 3586.0147469750473
reward_min: 1313.3617193601415
total_envstep_count: 22124201
total_train_sample_count: 16598101
total_episode_count: 48860
total_duration: 4408.286154181827
[2023-06-29 14:06:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 366.3333333333333
avg_sample_per_episode: 366.3333333333333
avg_envstep_per_sec: 2777.46731716964
avg_train_sample_per_sec: 2777.46731716964
avg_episode_per_sec: 7.581803413565896
collect_time: 0.3956842239713297
reward_mean: 2443.2757705605113
reward_std: 631.5834782106218
reward_max: 3336.194533811402
reward_min: 1977.6175192075177
total_envstep_count: 22128593
total_train_sample_count: 16601600
total_episode_count: 48863
total_duration: 4408.681838405799
[2023-06-29 14:06:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 231.83333333333334
avg_sample_per_episode: 231.83333333333334
avg_envstep_per_sec: 2623.511386034154
avg_train_sample_per_sec: 2623.511386034154
avg_episode_per_sec: 11.31636830783963
collect_time: 0.530205436654389
reward_mean: 3220.6259619345997
reward_std: 724.6218740207452
reward_max: 3578.3350411694896
reward_min: 1601.1856872087326
total_envstep_count: 22132521
total_train_sample_count: 16604991
total_episode_count: 48869
total_duration: 4409.212043842454
[2023-06-29 14:06:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 2
envstep_count: 509
train_sample_count: 509
avg_envstep_per_episode: 254.5
avg_sample_per_episode: 254.5
avg_envstep_per_sec: 1984.6329550161197
avg_train_sample_per_sec: 1984.6329550161197
avg_episode_per_sec: 7.798164852715598
collect_time: 0.25647059760522106
reward_mean: 3561.2502217016977
reward_std: 2.4991878341315896
reward_max: 3563.7494095358293
reward_min: 3558.751033867566
total_envstep_count: 22136593
total_train_sample_count: 16608300
total_episode_count: 48871
total_duration: 4409.468514440059
[2023-06-29 14:06:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1751
train_sample_count: 1751
avg_envstep_per_episode: 250.14285714285714
avg_sample_per_episode: 250.14285714285714
avg_envstep_per_sec: 2737.2932825886287
avg_train_sample_per_sec: 2737.2932825886287
avg_episode_per_sec: 10.94292003319269
collect_time: 0.6396830077134074
reward_mean: 3230.6980488276045
reward_std: 766.5110005444769
reward_max: 3576.8284428009847
reward_min: 1353.6801587775499
total_envstep_count: 22140521
total_train_sample_count: 16611651
total_episode_count: 48878
total_duration: 4410.108197447773
[2023-06-29 14:06:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 688
train_sample_count: 688
avg_envstep_per_episode: 229.33333333333334
avg_sample_per_episode: 229.33333333333334
avg_envstep_per_sec: 2555.7629441483564
avg_train_sample_per_sec: 2555.7629441483564
avg_episode_per_sec: 11.1443151634376
collect_time: 0.26919554553180935
reward_mean: 2628.7878998848446
reward_std: 915.8383268189609
reward_max: 3544.3886607860977
reward_min: 1377.642577883813
total_envstep_count: 22145153
total_train_sample_count: 16615139
total_episode_count: 48881
total_duration: 4410.377392993305
[2023-06-29 14:06:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1861
train_sample_count: 1861
avg_envstep_per_episode: 265.85714285714283
avg_sample_per_episode: 265.85714285714283
avg_envstep_per_sec: 2653.568341755119
avg_train_sample_per_sec: 2653.568341755119
avg_episode_per_sec: 9.981181296230968
collect_time: 0.7013197929430754
reward_mean: 3517.0413115927013
reward_std: 16.116959840438945
reward_max: 3539.201936389454
reward_min: 3493.647064716794
total_envstep_count: 22150457
total_train_sample_count: 16618600
total_episode_count: 48888
total_duration: 4411.078712786248
[2023-06-29 14:06:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2219
train_sample_count: 2219
avg_envstep_per_episode: 277.375
avg_sample_per_episode: 277.375
avg_envstep_per_sec: 2578.7549961926993
avg_train_sample_per_sec: 2578.7549961926993
avg_episode_per_sec: 9.296998634313471
collect_time: 0.8604927584342656
reward_mean: 2557.6099364280553
reward_std: 925.9705466195176
reward_max: 3554.1110601048763
reward_min: 1359.4924116566058
total_envstep_count: 22155225
total_train_sample_count: 16622019
total_episode_count: 48896
total_duration: 4411.939205544682
[2023-06-29 14:06:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2156
train_sample_count: 2156
avg_envstep_per_episode: 269.5
avg_sample_per_episode: 269.5
avg_envstep_per_sec: 2658.375943056681
avg_train_sample_per_sec: 2658.375943056681
avg_episode_per_sec: 9.864103684811433
collect_time: 0.8110214831093325
reward_mean: 3506.4635912255353
reward_std: 49.98039468803993
reward_max: 3561.5537938246957
reward_min: 3403.569845821667
total_envstep_count: 22163225
total_train_sample_count: 16628575
total_episode_count: 48904
total_duration: 4412.750227027792
[2023-06-29 14:06:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1598
train_sample_count: 1598
avg_envstep_per_episode: 399.5
avg_sample_per_episode: 399.5
avg_envstep_per_sec: 2710.24123172068
avg_train_sample_per_sec: 2710.24123172068
avg_episode_per_sec: 6.7840831832808
collect_time: 0.5896154118301347
reward_mean: 2834.2752012268115
reward_std: 841.9435208628757
reward_max: 3615.758211980193
reward_min: 1538.561962890018
total_envstep_count: 22167729
total_train_sample_count: 16632173
total_episode_count: 48908
total_duration: 4413.339842439622
[2023-06-29 14:06:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2653
train_sample_count: 2653
avg_envstep_per_episode: 265.3
avg_sample_per_episode: 265.3
avg_envstep_per_sec: 2630.4734014049486
avg_train_sample_per_sec: 2630.4734014049486
avg_episode_per_sec: 9.915090091990006
collect_time: 1.0085637051425875
reward_mean: 2405.6549104769447
reward_std: 957.4161558506652
reward_max: 3656.3900869299405
reward_min: 1169.0605958065184
total_envstep_count: 22172537
total_train_sample_count: 16635626
total_episode_count: 48918
total_duration: 4414.348406144764
[2023-06-29 14:06:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2397
train_sample_count: 2397
avg_envstep_per_episode: 299.625
avg_sample_per_episode: 299.625
avg_envstep_per_sec: 2583.672809092371
avg_train_sample_per_sec: 2583.672809092371
avg_episode_per_sec: 8.623021473816841
collect_time: 0.9277490522656588
reward_mean: 1947.095695172468
reward_std: 823.2107486376751
reward_max: 3514.837927760509
reward_min: 1076.5302822533004
total_envstep_count: 22177433
total_train_sample_count: 16639223
total_episode_count: 48926
total_duration: 4415.27615519703
[2023-06-29 14:06:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 231.75
avg_sample_per_episode: 231.75
avg_envstep_per_sec: 2702.705645823592
avg_train_sample_per_sec: 2702.705645823592
avg_episode_per_sec: 11.662160284028444
collect_time: 0.34298962649982423
reward_mean: 2536.419576284075
reward_std: 800.9549124355402
reward_max: 3515.7613867350174
reward_min: 1581.3323462926069
total_envstep_count: 22181641
total_train_sample_count: 16642550
total_episode_count: 48930
total_duration: 4415.6191448235295
[2023-06-29 14:06:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 201.875
avg_sample_per_episode: 201.875
avg_envstep_per_sec: 2730.364920133752
avg_train_sample_per_sec: 2730.364920133752
avg_episode_per_sec: 13.52502746815481
collect_time: 0.5914960260773077
reward_mean: 2719.002919683213
reward_std: 873.041587377213
reward_max: 3716.653972426998
reward_min: 1023.0312771808905
total_envstep_count: 22186081
total_train_sample_count: 16645765
total_episode_count: 48938
total_duration: 4416.2106408496065
[2023-06-29 14:06:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2004
train_sample_count: 2004
avg_envstep_per_episode: 334.0
avg_sample_per_episode: 334.0
avg_envstep_per_sec: 2502.1086562159753
avg_train_sample_per_sec: 2502.1086562159753
avg_episode_per_sec: 7.491343282083758
collect_time: 0.8009244502717632
reward_mean: 2703.223976636275
reward_std: 620.3990649639909
reward_max: 3554.546103283332
reward_min: 1863.965008050706
total_envstep_count: 22190377
total_train_sample_count: 16648969
total_episode_count: 48944
total_duration: 4417.011565299878
[2023-06-29 14:07:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 260.6
avg_sample_per_episode: 260.6
avg_envstep_per_sec: 2754.6720741359586
avg_train_sample_per_sec: 2754.6720741359586
avg_episode_per_sec: 10.570499133292243
collect_time: 0.4730145603297279
reward_mean: 2411.805482292705
reward_std: 735.5742120286596
reward_max: 3558.2542372694215
reward_min: 1578.1744917136214
total_envstep_count: 22194721
total_train_sample_count: 16652272
total_episode_count: 48949
total_duration: 4417.484579860208
[2023-06-29 14:07:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2722
train_sample_count: 2722
avg_envstep_per_episode: 247.45454545454547
avg_sample_per_episode: 247.45454545454547
avg_envstep_per_sec: 2701.0471284997643
avg_train_sample_per_sec: 2701.0471284997643
avg_episode_per_sec: 10.91532638262212
collect_time: 1.0077573142945764
reward_mean: 1972.9135765473015
reward_std: 1025.5459518544762
reward_max: 3599.993680172062
reward_min: 955.369564431261
total_envstep_count: 22199329
total_train_sample_count: 16655794
total_episode_count: 48960
total_duration: 4418.492337174503
[2023-06-29 14:07:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 919
train_sample_count: 919
avg_envstep_per_episode: 229.75
avg_sample_per_episode: 229.75
avg_envstep_per_sec: 2729.279746539418
avg_train_sample_per_sec: 2729.279746539418
avg_episode_per_sec: 11.87934601322924
collect_time: 0.33671887286938734
reward_mean: 2060.301315656035
reward_std: 883.7809686116016
reward_max: 3522.687063111902
reward_min: 1172.9512516939412
total_envstep_count: 22203553
total_train_sample_count: 16659113
total_episode_count: 48964
total_duration: 4418.829056047372
[2023-06-29 14:07:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 885
train_sample_count: 885
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 2271.316800670255
avg_train_sample_per_sec: 2271.316800670255
avg_episode_per_sec: 12.832298308871495
collect_time: 0.389641814712435
reward_mean: 3084.8515794894147
reward_std: 528.1079718975387
reward_max: 3547.3125078626567
reward_min: 2300.4210950219854
total_envstep_count: 22207417
total_train_sample_count: 16662398
total_episode_count: 48969
total_duration: 4419.218697862085
[2023-06-29 14:07:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1747
train_sample_count: 1747
avg_envstep_per_episode: 349.4
avg_sample_per_episode: 349.4
avg_envstep_per_sec: 2742.2054149972982
avg_train_sample_per_sec: 2742.2054149972982
avg_episode_per_sec: 7.848326888944758
collect_time: 0.6370784589825198
reward_mean: 3386.6293229796343
reward_std: 219.7549028398793
reward_max: 3515.15872077157
reward_min: 2948.6471096927644
total_envstep_count: 22212193
total_train_sample_count: 16665745
total_episode_count: 48974
total_duration: 4419.855776321067
[2023-06-29 14:07:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 291.14285714285717
avg_sample_per_episode: 291.14285714285717
avg_envstep_per_sec: 2794.3866257164286
avg_train_sample_per_sec: 2794.3866257164286
avg_episode_per_sec: 9.597991354276251
collect_time: 0.7293192650023849
reward_mean: 2927.227681751807
reward_std: 937.831494076044
reward_max: 3577.6409270587146
reward_min: 1348.1255585967708
total_envstep_count: 22217129
total_train_sample_count: 16668983
total_episode_count: 48981
total_duration: 4420.58509558607
[2023-06-29 14:07:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 325.2
avg_sample_per_episode: 325.2
avg_envstep_per_sec: 2742.116972576678
avg_train_sample_per_sec: 2742.116972576678
avg_episode_per_sec: 8.432094011613401
collect_time: 0.5929725158559158
reward_mean: 2486.4649481461465
reward_std: 1374.9401877033733
reward_max: 3570.3523206653194
reward_min: 63.1885192100814
total_envstep_count: 22220681
total_train_sample_count: 16672209
total_episode_count: 48986
total_duration: 4421.178068101925
[2023-06-29 14:07:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2015
train_sample_count: 2015
avg_envstep_per_episode: 251.875
avg_sample_per_episode: 251.875
avg_envstep_per_sec: 2815.024048682791
avg_train_sample_per_sec: 2815.024048682791
avg_episode_per_sec: 11.176274138690982
collect_time: 0.7158020553831008
reward_mean: 2127.802011125356
reward_std: 1469.467295809922
reward_max: 3536.4882914481454
reward_min: 57.30754271712822
total_envstep_count: 22225417
total_train_sample_count: 16675424
total_episode_count: 48994
total_duration: 4421.893870157309
[2023-06-29 14:07:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1870
train_sample_count: 1870
avg_envstep_per_episode: 311.6666666666667
avg_sample_per_episode: 311.6666666666667
avg_envstep_per_sec: 2501.9461994711314
avg_train_sample_per_sec: 2501.9461994711314
avg_episode_per_sec: 8.027634864613256
collect_time: 0.7474181500766427
reward_mean: 2525.5969928675645
reward_std: 1376.0649552576238
reward_max: 3572.219682328532
reward_min: 54.762585022698715
total_envstep_count: 22230505
total_train_sample_count: 16678894
total_episode_count: 49000
total_duration: 4422.641288307385
[2023-06-29 14:07:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1696
train_sample_count: 1696
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2698.2049665197706
avg_train_sample_per_sec: 2698.2049665197706
avg_episode_per_sec: 12.727381917546086
collect_time: 0.6285660359552129
reward_mean: 2217.367582597215
reward_std: 1393.577933248476
reward_max: 3551.296022017009
reward_min: 55.88546755695486
total_envstep_count: 22235305
total_train_sample_count: 16682190
total_episode_count: 49008
total_duration: 4423.269854343341
[2023-06-29 14:07:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1270
train_sample_count: 1270
avg_envstep_per_episode: 181.42857142857142
avg_sample_per_episode: 181.42857142857142
avg_envstep_per_sec: 2707.368728051387
avg_train_sample_per_sec: 2707.368728051387
avg_episode_per_sec: 14.922504800283235
collect_time: 0.469090148985386
reward_mean: 2293.966349318425
reward_std: 884.581543876103
reward_max: 3521.928732322976
reward_min: 1261.668268438572
total_envstep_count: 22239569
total_train_sample_count: 16685460
total_episode_count: 49015
total_duration: 4423.7389444923265
[2023-06-29 14:07:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 168.25
avg_sample_per_episode: 168.25
avg_envstep_per_sec: 2735.245199993564
avg_train_sample_per_sec: 2735.245199993564
avg_episode_per_sec: 16.257029420466946
collect_time: 0.49209482206683597
reward_mean: 1557.2328458398028
reward_std: 1355.8592189952608
reward_max: 3522.6016152987636
reward_min: 55.353674468445945
total_envstep_count: 22244073
total_train_sample_count: 16688806
total_episode_count: 49023
total_duration: 4424.2310393143935
[2023-06-29 14:07:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1691
train_sample_count: 1691
avg_envstep_per_episode: 187.88888888888889
avg_sample_per_episode: 187.88888888888889
avg_envstep_per_sec: 2775.648958307399
avg_train_sample_per_sec: 2775.648958307399
avg_episode_per_sec: 14.77282118555091
collect_time: 0.6092268962683156
reward_mean: 2214.3112780829542
reward_std: 1242.6920523310127
reward_max: 3500.3618864284826
reward_min: 60.63134310404278
total_envstep_count: 22248401
total_train_sample_count: 16692097
total_episode_count: 49032
total_duration: 4424.840266210662
[2023-06-29 14:07:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2117
train_sample_count: 2117
avg_envstep_per_episode: 264.625
avg_sample_per_episode: 264.625
avg_envstep_per_sec: 2515.366396426503
avg_train_sample_per_sec: 2515.366396426503
avg_episode_per_sec: 9.505399703076062
collect_time: 0.8416268910197542
reward_mean: 2281.238085734263
reward_std: 1048.499088706236
reward_max: 3556.432323766651
reward_min: 50.69177617440922
total_envstep_count: 22252609
total_train_sample_count: 16695414
total_episode_count: 49040
total_duration: 4425.681893101681
[2023-06-29 14:07:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1207
train_sample_count: 1207
avg_envstep_per_episode: 402.3333333333333
avg_sample_per_episode: 402.3333333333333
avg_envstep_per_sec: 2354.7986013949044
avg_train_sample_per_sec: 2354.7986013949044
avg_episode_per_sec: 5.8528548501944595
collect_time: 0.5125703740799801
reward_mean: 2861.7081491932863
reward_std: 878.7197323557748
reward_max: 3525.1630092681016
reward_min: 1619.9844067845388
total_envstep_count: 22256313
total_train_sample_count: 16698621
total_episode_count: 49043
total_duration: 4426.194463475761
[2023-06-29 14:07:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1702
train_sample_count: 1702
avg_envstep_per_episode: 243.14285714285714
avg_sample_per_episode: 243.14285714285714
avg_envstep_per_sec: 2715.652790019366
avg_train_sample_per_sec: 2715.652790019366
avg_episode_per_sec: 11.168959770937462
collect_time: 0.6267369695622476
reward_mean: 2673.0769193696847
reward_std: 923.6231985917116
reward_max: 3695.807772564337
reward_min: 1031.8042344548244
total_envstep_count: 22261041
total_train_sample_count: 16701923
total_episode_count: 49050
total_duration: 4426.8212004453235
[2023-06-29 14:07:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1309
train_sample_count: 1309
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 2628.0113786881047
avg_train_sample_per_sec: 2628.0113786881047
avg_episode_per_sec: 14.053536784428367
collect_time: 0.49809525583311925
reward_mean: 1735.696022789603
reward_std: 1016.6937390987293
reward_max: 3464.4834820994515
reward_min: 56.60670184868793
total_envstep_count: 22264889
total_train_sample_count: 16705232
total_episode_count: 49057
total_duration: 4427.319295701157
[2023-06-29 14:07:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2604
train_sample_count: 2604
avg_envstep_per_episode: 325.5
avg_sample_per_episode: 325.5
avg_envstep_per_sec: 2554.3047063582303
avg_train_sample_per_sec: 2554.3047063582303
avg_episode_per_sec: 7.847326286814839
collect_time: 1.0194555072141813
reward_mean: 2680.4201145384695
reward_std: 1069.2962264806763
reward_max: 3524.458900838218
reward_min: 943.7624016233162
total_envstep_count: 22269625
total_train_sample_count: 16708636
total_episode_count: 49065
total_duration: 4428.338751208371
[2023-06-29 14:07:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1878
train_sample_count: 1878
avg_envstep_per_episode: 469.5
avg_sample_per_episode: 469.5
avg_envstep_per_sec: 2724.707428852893
avg_train_sample_per_sec: 2724.707428852893
avg_episode_per_sec: 5.803423703627035
collect_time: 0.6892483134567742
reward_mean: 3131.403570920954
reward_std: 535.8364217200863
reward_max: 3466.1320596187215
reward_min: 2203.7016817901936
total_envstep_count: 22275121
total_train_sample_count: 16712114
total_episode_count: 49069
total_duration: 4429.027999521828
[2023-06-29 14:07:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 271.1666666666667
avg_sample_per_episode: 271.1666666666667
avg_envstep_per_sec: 2413.8435127066086
avg_train_sample_per_sec: 2413.8435127066086
avg_episode_per_sec: 8.901697035181101
collect_time: 0.6740287808366119
reward_mean: 3100.379608471685
reward_std: 862.6582510836242
reward_max: 3540.807384045533
reward_min: 1172.2544696354194
total_envstep_count: 22279993
total_train_sample_count: 16715341
total_episode_count: 49075
total_duration: 4429.702028302665
[2023-06-29 14:08:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2369
train_sample_count: 2369
avg_envstep_per_episode: 263.22222222222223
avg_sample_per_episode: 263.22222222222223
avg_envstep_per_sec: 2810.8565601972427
avg_train_sample_per_sec: 2810.8565601972427
avg_episode_per_sec: 10.678644593404469
collect_time: 0.8428035900322722
reward_mean: 2393.397363899168
reward_std: 681.0712682856743
reward_max: 3451.9029144033625
reward_min: 1496.8111484329168
total_envstep_count: 22284169
total_train_sample_count: 16718910
total_episode_count: 49084
total_duration: 4430.544831892697
[2023-06-29 14:08:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3400
train_sample_count: 3400
avg_envstep_per_episode: 283.3333333333333
avg_sample_per_episode: 283.3333333333333
avg_envstep_per_sec: 2610.8583260331934
avg_train_sample_per_sec: 2610.8583260331934
avg_episode_per_sec: 9.214794091881858
collect_time: 1.3022537324596195
reward_mean: 1623.4813350887946
reward_std: 968.7724244556154
reward_max: 3511.496591567091
reward_min: 64.0520496747483
total_envstep_count: 22289345
total_train_sample_count: 16722310
total_episode_count: 49096
total_duration: 4431.847085625157
[2023-06-29 14:08:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2415
train_sample_count: 2415
avg_envstep_per_episode: 301.875
avg_sample_per_episode: 301.875
avg_envstep_per_sec: 2584.376546983164
avg_train_sample_per_sec: 2584.376546983164
avg_episode_per_sec: 8.561081729136776
collect_time: 0.9344613511599602
reward_mean: 1687.0849891405373
reward_std: 566.6194139031111
reward_max: 2573.073654363777
reward_min: 840.7123985958757
total_envstep_count: 22293721
total_train_sample_count: 16725525
total_episode_count: 49104
total_duration: 4432.781546976317
[2023-06-29 14:08:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 2864
train_sample_count: 2864
avg_envstep_per_episode: 168.47058823529412
avg_sample_per_episode: 168.47058823529412
avg_envstep_per_sec: 2599.0224231939346
avg_train_sample_per_sec: 2599.0224231939346
avg_episode_per_sec: 15.427158238232154
collect_time: 1.101952785955742
reward_mean: 1089.8625779141228
reward_std: 1034.6241473388288
reward_max: 3620.845226671215
reward_min: 54.79451088668388
total_envstep_count: 22298401
total_train_sample_count: 16728789
total_episode_count: 49121
total_duration: 4433.883499762273
[2023-06-29 14:08:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2196
train_sample_count: 2196
avg_envstep_per_episode: 244.0
avg_sample_per_episode: 244.0
avg_envstep_per_sec: 2788.521247441451
avg_train_sample_per_sec: 2788.521247441451
avg_episode_per_sec: 11.428365768202669
collect_time: 0.7875141715398057
reward_mean: 1495.9345046284907
reward_std: 890.117578199631
reward_max: 3513.280488158757
reward_min: 366.7722625072232
total_envstep_count: 22303057
total_train_sample_count: 16732185
total_episode_count: 49130
total_duration: 4434.671013933812
[2023-06-29 14:08:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2909
train_sample_count: 2909
avg_envstep_per_episode: 323.22222222222223
avg_sample_per_episode: 323.22222222222223
avg_envstep_per_sec: 2580.9350079171813
avg_train_sample_per_sec: 2580.9350079171813
avg_episode_per_sec: 7.985017212531671
collect_time: 1.1271109078982844
reward_mean: 2305.5031700424133
reward_std: 1029.6676298493164
reward_max: 3537.970290387508
reward_min: 773.8186205674322
total_envstep_count: 22308169
total_train_sample_count: 16735494
total_episode_count: 49139
total_duration: 4435.79812484171
[2023-06-29 14:08:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2306
train_sample_count: 2306
avg_envstep_per_episode: 192.16666666666666
avg_sample_per_episode: 192.16666666666666
avg_envstep_per_sec: 2659.564212491638
avg_train_sample_per_sec: 2659.564212491638
avg_episode_per_sec: 13.83988315260176
collect_time: 0.8670593434702605
reward_mean: 1326.2123739678955
reward_std: 862.5748200398822
reward_max: 2853.0776910354793
reward_min: 54.191451105681004
total_envstep_count: 22312425
total_train_sample_count: 16739000
total_episode_count: 49151
total_duration: 4436.66518418518
[2023-06-29 14:08:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2465
train_sample_count: 2465
avg_envstep_per_episode: 205.41666666666666
avg_sample_per_episode: 205.41666666666666
avg_envstep_per_sec: 2803.631609249639
avg_train_sample_per_sec: 2803.631609249639
avg_episode_per_sec: 13.648510876671672
collect_time: 0.8792167957685888
reward_mean: 1355.471031003766
reward_std: 570.4094192763039
reward_max: 2526.752171238008
reward_min: 627.2441943871073
total_envstep_count: 22316881
total_train_sample_count: 16742265
total_episode_count: 49163
total_duration: 4437.544400980949
[2023-06-29 14:08:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2321
train_sample_count: 2321
avg_envstep_per_episode: 193.41666666666666
avg_sample_per_episode: 193.41666666666666
avg_envstep_per_sec: 2560.2417572194126
avg_train_sample_per_sec: 2560.2417572194126
avg_episode_per_sec: 13.236924207941813
collect_time: 0.9065550131956115
reward_mean: 1280.9853433370533
reward_std: 611.9705915320557
reward_max: 2602.3645345591544
reward_min: 277.1752524469488
total_envstep_count: 22321257
total_train_sample_count: 16745786
total_episode_count: 49175
total_duration: 4438.450955994144
[2023-06-29 14:08:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1365
train_sample_count: 1365
avg_envstep_per_episode: 195.0
avg_sample_per_episode: 195.0
avg_envstep_per_sec: 2757.122476982371
avg_train_sample_per_sec: 2757.122476982371
avg_episode_per_sec: 14.139089625550621
collect_time: 0.4950813797339797
reward_mean: 1755.561351083515
reward_std: 409.56594646112023
reward_max: 2267.44696578688
reward_min: 902.3230458358282
total_envstep_count: 22325545
total_train_sample_count: 16749151
total_episode_count: 49182
total_duration: 4438.946037373878
[2023-06-29 14:08:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2517
train_sample_count: 2517
avg_envstep_per_episode: 209.75
avg_sample_per_episode: 209.75
avg_envstep_per_sec: 2699.7421335547783
avg_train_sample_per_sec: 2699.7421335547783
avg_episode_per_sec: 12.871237823860682
collect_time: 0.9323112636264413
reward_mean: 1689.4417596660487
reward_std: 1037.3839271678282
reward_max: 3116.826099916452
reward_min: 22.252002618485264
total_envstep_count: 22330497
total_train_sample_count: 16752468
total_episode_count: 49194
total_duration: 4439.878348637505
[2023-06-29 14:08:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2442
train_sample_count: 2442
avg_envstep_per_episode: 244.2
avg_sample_per_episode: 244.2
avg_envstep_per_sec: 2638.2177388727077
avg_train_sample_per_sec: 2638.2177388727077
avg_episode_per_sec: 10.803512444196183
collect_time: 0.9256248883549125
reward_mean: 1730.950876707578
reward_std: 596.2616107990212
reward_max: 2782.401295305174
reward_min: 883.952881063162
total_envstep_count: 22335265
total_train_sample_count: 16755710
total_episode_count: 49204
total_duration: 4440.80397352586
[2023-06-29 14:08:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1996
train_sample_count: 1996
avg_envstep_per_episode: 285.14285714285717
avg_sample_per_episode: 285.14285714285717
avg_envstep_per_sec: 2585.034589369237
avg_train_sample_per_sec: 2585.034589369237
avg_episode_per_sec: 9.065752567928186
collect_time: 0.7721366701275109
reward_mean: 2203.869363980966
reward_std: 825.1601155087246
reward_max: 3624.253250227404
reward_min: 1171.3374354788568
total_envstep_count: 22340129
total_train_sample_count: 16759306
total_episode_count: 49211
total_duration: 4441.576110195987
[2023-06-29 14:08:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 213.125
avg_sample_per_episode: 213.125
avg_envstep_per_sec: 2731.935809947757
avg_train_sample_per_sec: 2731.935809947757
avg_episode_per_sec: 12.818467143449887
collect_time: 0.6240995830837639
reward_mean: 1989.626504243428
reward_std: 1019.5759007942797
reward_max: 3626.6440215559105
reward_min: 792.1358645463685
total_envstep_count: 22344777
total_train_sample_count: 16762611
total_episode_count: 49219
total_duration: 4442.200209779071
[2023-06-29 14:08:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1189
train_sample_count: 1189
avg_envstep_per_episode: 198.16666666666666
avg_sample_per_episode: 198.16666666666666
avg_envstep_per_sec: 2693.1251618969886
avg_train_sample_per_sec: 2693.1251618969886
avg_episode_per_sec: 13.590202667268237
collect_time: 0.4414945197580382
reward_mean: 2471.2295480315956
reward_std: 1162.1623299257894
reward_max: 3571.698609905647
reward_min: 52.89298775509441
total_envstep_count: 22349353
total_train_sample_count: 16766200
total_episode_count: 49225
total_duration: 4442.641704298829
[2023-06-29 14:08:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1805
train_sample_count: 1805
avg_envstep_per_episode: 180.5
avg_sample_per_episode: 180.5
avg_envstep_per_sec: 2722.51129961115
avg_train_sample_per_sec: 2722.51129961115
avg_episode_per_sec: 15.083165094798616
collect_time: 0.6629908203715459
reward_mean: 1944.969835875438
reward_std: 1200.985388627035
reward_max: 3483.767557797595
reward_min: 27.550626510299267
total_envstep_count: 22353657
total_train_sample_count: 16769605
total_episode_count: 49235
total_duration: 4443.3046951192
[2023-06-29 14:08:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1726
train_sample_count: 1726
avg_envstep_per_episode: 191.77777777777777
avg_sample_per_episode: 191.77777777777777
avg_envstep_per_sec: 2558.7561231990885
avg_train_sample_per_sec: 2558.7561231990885
avg_episode_per_sec: 13.342297282034645
collect_time: 0.6745465049799533
reward_mean: 1814.0989968732335
reward_std: 966.1320411198451
reward_max: 3308.8095978761426
reward_min: 733.0936391234502
total_envstep_count: 22357633
total_train_sample_count: 16772931
total_episode_count: 49244
total_duration: 4443.97924162418
[2023-06-29 14:08:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3038
train_sample_count: 3038
avg_envstep_per_episode: 303.8
avg_sample_per_episode: 303.8
avg_envstep_per_sec: 2566.940944203014
avg_train_sample_per_sec: 2566.940944203014
avg_episode_per_sec: 8.44944352930551
collect_time: 1.1835098921386524
reward_mean: 1963.9311747488493
reward_std: 1301.8595007320275
reward_max: 3722.583831233649
reward_min: 257.55473872657626
total_envstep_count: 22362481
total_train_sample_count: 16776369
total_episode_count: 49254
total_duration: 4445.162751516318
[2023-06-29 14:08:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 204.5
avg_sample_per_episode: 204.5
avg_envstep_per_sec: 2772.9878315486435
avg_train_sample_per_sec: 2772.9878315486435
avg_episode_per_sec: 13.559842697059382
collect_time: 0.5899773455141112
reward_mean: 1273.7446302848095
reward_std: 346.32633057751804
reward_max: 2020.584393145086
reward_min: 880.7382166258828
total_envstep_count: 22366377
total_train_sample_count: 16779605
total_episode_count: 49262
total_duration: 4445.752728861832
[2023-06-29 14:09:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2671
train_sample_count: 2671
avg_envstep_per_episode: 267.1
avg_sample_per_episode: 267.1
avg_envstep_per_sec: 2696.290625866858
avg_train_sample_per_sec: 2696.290625866858
avg_episode_per_sec: 10.094685982279513
collect_time: 0.9906202151859178
reward_mean: 1980.7631395065862
reward_std: 997.7819132358824
reward_max: 3517.330337190642
reward_min: 660.5089785101482
total_envstep_count: 22371025
total_train_sample_count: 16783076
total_episode_count: 49272
total_duration: 4446.743349077018
[2023-06-29 14:09:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2816
train_sample_count: 2816
avg_envstep_per_episode: 281.6
avg_sample_per_episode: 281.6
avg_envstep_per_sec: 2572.819485639151
avg_train_sample_per_sec: 2572.819485639151
avg_episode_per_sec: 9.136432832525394
collect_time: 1.0945190736148507
reward_mean: 1646.2569514513175
reward_std: 791.9235076345911
reward_max: 2954.9307482926483
reward_min: 282.1541797574564
total_envstep_count: 22375449
total_train_sample_count: 16786292
total_episode_count: 49282
total_duration: 4447.837868150633
[2023-06-29 14:09:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1819
train_sample_count: 1819
avg_envstep_per_episode: 303.1666666666667
avg_sample_per_episode: 303.1666666666667
avg_envstep_per_sec: 2454.7255038764256
avg_train_sample_per_sec: 2454.7255038764256
avg_episode_per_sec: 8.096950535051432
collect_time: 0.7410197177352384
reward_mean: 1917.0750391665551
reward_std: 1201.1979234428595
reward_max: 3471.835523384173
reward_min: 445.3349668909002
total_envstep_count: 22380465
total_train_sample_count: 16789711
total_episode_count: 49288
total_duration: 4448.578887868368
[2023-06-29 14:09:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2508
train_sample_count: 2508
avg_envstep_per_episode: 278.6666666666667
avg_sample_per_episode: 278.6666666666667
avg_envstep_per_sec: 2698.0920747948517
avg_train_sample_per_sec: 2698.0920747948517
avg_episode_per_sec: 9.682148593761429
collect_time: 0.9295457421299067
reward_mean: 2353.804386532986
reward_std: 1032.5658123330577
reward_max: 3541.5520087653117
reward_min: 656.6548077728595
total_envstep_count: 22385233
total_train_sample_count: 16793019
total_episode_count: 49297
total_duration: 4449.508433610498
[2023-06-29 14:09:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1623
train_sample_count: 1623
avg_envstep_per_episode: 202.875
avg_sample_per_episode: 202.875
avg_envstep_per_sec: 2771.5769711733888
avg_train_sample_per_sec: 2771.5769711733888
avg_episode_per_sec: 13.661500782123913
collect_time: 0.5855872006732971
reward_mean: 1402.1362156282235
reward_std: 662.6121534399525
reward_max: 2801.0999637339555
reward_min: 456.13717206891516
total_envstep_count: 22389561
total_train_sample_count: 16796242
total_episode_count: 49305
total_duration: 4450.0940208111715
[2023-06-29 14:09:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2713
train_sample_count: 2713
avg_envstep_per_episode: 208.69230769230768
avg_sample_per_episode: 208.69230769230768
avg_envstep_per_sec: 2516.327195373197
avg_train_sample_per_sec: 2516.327195373197
avg_episode_per_sec: 12.057594375175658
collect_time: 1.078158677054569
reward_mean: 1765.006389426674
reward_std: 1014.335349229574
reward_max: 3638.532991169404
reward_min: 659.5923633980018
total_envstep_count: 22393969
total_train_sample_count: 16799755
total_episode_count: 49318
total_duration: 4451.172179488226
[2023-06-29 14:09:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 177.16666666666666
avg_sample_per_episode: 177.16666666666666
avg_envstep_per_sec: 2320.0256947235885
avg_train_sample_per_sec: 2320.0256947235885
avg_episode_per_sec: 13.09515914237209
collect_time: 0.45818458063527934
reward_mean: 1455.709782833582
reward_std: 454.70664791241074
reward_max: 2241.458416080423
reward_min: 697.5099477076265
total_envstep_count: 22398961
total_train_sample_count: 16803218
total_episode_count: 49324
total_duration: 4451.630364068861
[2023-06-29 14:09:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2165
train_sample_count: 2165
avg_envstep_per_episode: 240.55555555555554
avg_sample_per_episode: 240.55555555555554
avg_envstep_per_sec: 2655.951039573531
avg_train_sample_per_sec: 2655.951039573531
avg_episode_per_sec: 11.04090501439343
collect_time: 0.815150568569079
reward_mean: 2453.3680645855225
reward_std: 1100.8958723965357
reward_max: 3631.982357599165
reward_min: 653.8948973938992
total_envstep_count: 22403681
total_train_sample_count: 16806583
total_episode_count: 49333
total_duration: 4452.44551463743
[2023-06-29 14:09:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3138
train_sample_count: 3138
avg_envstep_per_episode: 313.8
avg_sample_per_episode: 313.8
avg_envstep_per_sec: 2577.718597222071
avg_train_sample_per_sec: 2577.718597222071
avg_episode_per_sec: 8.214527078464217
collect_time: 1.2173555342238394
reward_mean: 2143.000835228835
reward_std: 856.6059445339712
reward_max: 3501.7431322945954
reward_min: 1031.9039424203363
total_envstep_count: 22408113
total_train_sample_count: 16810121
total_episode_count: 49343
total_duration: 4453.6628701716545
[2023-06-29 14:09:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 323.6666666666667
avg_sample_per_episode: 323.6666666666667
avg_envstep_per_sec: 2710.857585971829
avg_train_sample_per_sec: 2710.857585971829
avg_episode_per_sec: 8.37546113070596
collect_time: 0.35818923318758605
reward_mean: 1700.3493831883122
reward_std: 543.723649530956
reward_max: 2414.5818771340114
reward_min: 1096.540880493941
total_envstep_count: 22412185
total_train_sample_count: 16813492
total_episode_count: 49346
total_duration: 4454.021059404842
[2023-06-29 14:09:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 253.75
avg_sample_per_episode: 253.75
avg_envstep_per_sec: 2733.6992901306357
avg_train_sample_per_sec: 2733.6992901306357
avg_episode_per_sec: 10.773199172928614
collect_time: 0.7425835048239677
reward_mean: 2646.332938208204
reward_std: 971.9774831733953
reward_max: 3618.9787617932557
reward_min: 727.5418901504207
total_envstep_count: 22416985
total_train_sample_count: 16816722
total_episode_count: 49354
total_duration: 4454.7636429096665
[2023-06-29 14:09:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1809
train_sample_count: 1809
avg_envstep_per_episode: 258.42857142857144
avg_sample_per_episode: 258.42857142857144
avg_envstep_per_sec: 2484.71383035048
avg_train_sample_per_sec: 2484.71383035048
avg_episode_per_sec: 9.614702494446302
collect_time: 0.7280516484044492
reward_mean: 2256.788103657941
reward_std: 889.3986546321837
reward_max: 3568.0153274184777
reward_min: 988.6673082558659
total_envstep_count: 22421529
total_train_sample_count: 16820131
total_episode_count: 49361
total_duration: 4455.491694558071
[2023-06-29 14:09:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2711
train_sample_count: 2711
avg_envstep_per_episode: 301.22222222222223
avg_sample_per_episode: 301.22222222222223
avg_envstep_per_sec: 2500.4902864223673
avg_train_sample_per_sec: 2500.4902864223673
avg_episode_per_sec: 8.30114812903036
collect_time: 1.0841873750602824
reward_mean: 2203.226341273472
reward_std: 997.2832836249081
reward_max: 3527.32262934764
reward_min: 1178.9473777549565
total_envstep_count: 22426713
total_train_sample_count: 16823642
total_episode_count: 49370
total_duration: 4456.575881933131
[2023-06-29 14:09:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2897
train_sample_count: 2897
avg_envstep_per_episode: 241.41666666666666
avg_sample_per_episode: 241.41666666666666
avg_envstep_per_sec: 2709.7887276167876
avg_train_sample_per_sec: 2709.7887276167876
avg_episode_per_sec: 11.22453045612753
collect_time: 1.0690870363712308
reward_mean: 1610.1866815643252
reward_std: 803.9744072054189
reward_max: 3469.753126754592
reward_min: 283.29187352465107
total_envstep_count: 22431305
total_train_sample_count: 16826939
total_episode_count: 49382
total_duration: 4457.644968969503
[2023-06-29 14:09:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1671
train_sample_count: 1671
avg_envstep_per_episode: 334.2
avg_sample_per_episode: 334.2
avg_envstep_per_sec: 2698.592518974004
avg_train_sample_per_sec: 2698.592518974004
avg_episode_per_sec: 8.074783120807911
collect_time: 0.6192116772914307
reward_mean: 2429.0510349917718
reward_std: 560.5264772193984
reward_max: 3469.2237144072687
reward_min: 1813.338857366725
total_envstep_count: 22435737
total_train_sample_count: 16830210
total_episode_count: 49387
total_duration: 4458.264180646795
[2023-06-29 14:09:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2645
train_sample_count: 2645
avg_envstep_per_episode: 293.8888888888889
avg_sample_per_episode: 293.8888888888889
avg_envstep_per_sec: 2472.053010529084
avg_train_sample_per_sec: 2472.053010529084
avg_episode_per_sec: 8.411522531100854
collect_time: 1.069960874113254
reward_mean: 2266.7270096587986
reward_std: 940.5357020831126
reward_max: 3545.815239587664
reward_min: 986.7151431139673
total_envstep_count: 22440273
total_train_sample_count: 16833655
total_episode_count: 49396
total_duration: 4459.334141520908
[2023-06-29 14:09:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2908
train_sample_count: 2908
avg_envstep_per_episode: 290.8
avg_sample_per_episode: 290.8
avg_envstep_per_sec: 2525.1771666320583
avg_train_sample_per_sec: 2525.1771666320583
avg_episode_per_sec: 8.68355284261368
collect_time: 1.1516023661335928
reward_mean: 1739.6844725865435
reward_std: 583.9528716793197
reward_max: 2754.1531567115694
reward_min: 979.5035229002718
total_envstep_count: 22444209
total_train_sample_count: 16836963
total_episode_count: 49406
total_duration: 4460.485743887041
[2023-06-29 14:09:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2039
train_sample_count: 2039
avg_envstep_per_episode: 339.8333333333333
avg_sample_per_episode: 339.8333333333333
avg_envstep_per_sec: 2460.7004932192262
avg_train_sample_per_sec: 2460.7004932192262
avg_episode_per_sec: 7.240903854495026
collect_time: 0.8286258346429093
reward_mean: 1735.5271788010577
reward_std: 837.4523515096975
reward_max: 3514.3726801262424
reward_min: 1016.4270080670536
total_envstep_count: 22448801
total_train_sample_count: 16840202
total_episode_count: 49412
total_duration: 4461.314369721684
[2023-06-29 14:09:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2251
train_sample_count: 2251
avg_envstep_per_episode: 225.1
avg_sample_per_episode: 225.1
avg_envstep_per_sec: 2762.4453113426034
avg_train_sample_per_sec: 2762.4453113426034
avg_episode_per_sec: 12.272080459096417
collect_time: 0.8148577605346219
reward_mean: 1799.302822351868
reward_std: 804.3668863577423
reward_max: 3679.548466086649
reward_min: 1014.6342556643825
total_envstep_count: 22453329
total_train_sample_count: 16843653
total_episode_count: 49422
total_duration: 4462.129227482218
[2023-06-29 14:09:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 322.6
avg_sample_per_episode: 322.6
avg_envstep_per_sec: 2416.2113557907237
avg_train_sample_per_sec: 2416.2113557907237
avg_episode_per_sec: 7.4898058146023665
collect_time: 1.3351480996347966
reward_mean: 2006.4768111204514
reward_std: 1087.1842520191224
reward_max: 3631.928044592827
reward_min: 610.3505860855352
total_envstep_count: 22457449
total_train_sample_count: 16846879
total_episode_count: 49432
total_duration: 4463.464375581852
[2023-06-29 14:10:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2510
train_sample_count: 2510
avg_envstep_per_episode: 278.8888888888889
avg_sample_per_episode: 278.8888888888889
avg_envstep_per_sec: 2494.9490044198656
avg_train_sample_per_sec: 2494.9490044198656
avg_episode_per_sec: 8.946032286764458
collect_time: 1.0060325864590705
reward_mean: 1372.286171640008
reward_std: 368.7002334040702
reward_max: 1978.7149570618155
reward_min: 827.068522360025
total_envstep_count: 22461449
total_train_sample_count: 16850189
total_episode_count: 49441
total_duration: 4464.470408168311
[2023-06-29 14:10:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2265
train_sample_count: 2265
avg_envstep_per_episode: 251.66666666666666
avg_sample_per_episode: 251.66666666666666
avg_envstep_per_sec: 2731.7732581631376
avg_train_sample_per_sec: 2731.7732581631376
avg_episode_per_sec: 10.854728178131673
collect_time: 0.8291317711789159
reward_mean: 1483.4078556364375
reward_std: 864.127756437803
reward_max: 3254.569237411265
reward_min: 160.986362905987
total_envstep_count: 22465905
total_train_sample_count: 16853654
total_episode_count: 49450
total_duration: 4465.29953993949
[2023-06-29 14:10:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2574.425799689516
avg_train_sample_per_sec: 2574.425799689516
avg_episode_per_sec: 9.606066416751926
collect_time: 1.2492106008213015
reward_mean: 1621.7594088499025
reward_std: 953.7909039995899
reward_max: 3534.2165528832743
reward_min: 131.73907314252023
total_envstep_count: 22470793
total_train_sample_count: 16856870
total_episode_count: 49462
total_duration: 4466.548750540312
[2023-06-29 14:10:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1802
train_sample_count: 1802
avg_envstep_per_episode: 200.22222222222223
avg_sample_per_episode: 200.22222222222223
avg_envstep_per_sec: 2382.7211585617933
avg_train_sample_per_sec: 2382.7211585617933
avg_episode_per_sec: 11.90038314487022
collect_time: 0.7562781710838898
reward_mean: 1307.7205402530494
reward_std: 514.8646672834899
reward_max: 2233.5100391786555
reward_min: 153.24953373017703
total_envstep_count: 22475177
total_train_sample_count: 16860272
total_episode_count: 49471
total_duration: 4467.305028711396
[2023-06-29 14:10:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2099
train_sample_count: 2099
avg_envstep_per_episode: 299.85714285714283
avg_sample_per_episode: 299.85714285714283
avg_envstep_per_sec: 2328.6365024031247
avg_train_sample_per_sec: 2328.6365024031247
avg_episode_per_sec: 7.76581968405044
collect_time: 0.9013858529804275
reward_mean: 2370.3732247622725
reward_std: 803.4531078577747
reward_max: 3567.479723925727
reward_min: 1507.1376496872542
total_envstep_count: 22479673
total_train_sample_count: 16863571
total_episode_count: 49478
total_duration: 4468.206414564376
[2023-06-29 14:10:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2248
train_sample_count: 2248
avg_envstep_per_episode: 281.0
avg_sample_per_episode: 281.0
avg_envstep_per_sec: 2540.8022062114214
avg_train_sample_per_sec: 2540.8022062114214
avg_episode_per_sec: 9.042000733848475
collect_time: 0.8847599370405076
reward_mean: 2108.4478038682796
reward_std: 793.3986546838697
reward_max: 3549.3474879542587
reward_min: 1031.037417041384
total_envstep_count: 22484185
total_train_sample_count: 16867019
total_episode_count: 49486
total_duration: 4469.091174501416
[2023-06-29 14:10:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2068
train_sample_count: 2068
avg_envstep_per_episode: 295.42857142857144
avg_sample_per_episode: 295.42857142857144
avg_envstep_per_sec: 2130.4178502219297
avg_train_sample_per_sec: 2130.4178502219297
avg_episode_per_sec: 7.211278990112915
collect_time: 0.9707015925465384
reward_mean: 2167.2762616701907
reward_std: 630.2798558787996
reward_max: 3487.656420287336
reward_min: 1388.8395780958995
total_envstep_count: 22488417
total_train_sample_count: 16870287
total_episode_count: 49493
total_duration: 4470.061876093963
[2023-06-29 14:10:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1294
train_sample_count: 1294
avg_envstep_per_episode: 258.8
avg_sample_per_episode: 258.8
avg_envstep_per_sec: 2704.246291040256
avg_train_sample_per_sec: 2704.246291040256
avg_episode_per_sec: 10.44917423122201
collect_time: 0.47850671156961466
reward_mean: 2340.2324705982764
reward_std: 872.7227957889661
reward_max: 3483.017292614542
reward_min: 1190.4245496075391
total_envstep_count: 22492881
total_train_sample_count: 16873581
total_episode_count: 49498
total_duration: 4470.540382805533
[2023-06-29 14:10:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3034
train_sample_count: 3034
avg_envstep_per_episode: 252.83333333333334
avg_sample_per_episode: 252.83333333333334
avg_envstep_per_sec: 2596.276826634648
avg_train_sample_per_sec: 2596.276826634648
avg_episode_per_sec: 10.268728384843696
collect_time: 1.1685964951328933
reward_mean: 2082.1329275017683
reward_std: 997.6289242016734
reward_max: 3562.4057709796293
reward_min: 1052.1440549050997
total_envstep_count: 22497961
total_train_sample_count: 16877015
total_episode_count: 49510
total_duration: 4471.708979300666
[2023-06-29 14:10:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3498
train_sample_count: 3498
avg_envstep_per_episode: 349.8
avg_sample_per_episode: 349.8
avg_envstep_per_sec: 2631.5938453920317
avg_train_sample_per_sec: 2631.5938453920317
avg_episode_per_sec: 7.523138494545544
collect_time: 1.329232474884018
reward_mean: 2037.5889360223787
reward_std: 530.0727534059233
reward_max: 2773.0643409526297
reward_min: 1269.3696486315914
total_envstep_count: 22503217
total_train_sample_count: 16880513
total_episode_count: 49520
total_duration: 4473.03821177555
[2023-06-29 14:10:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2803
train_sample_count: 2803
avg_envstep_per_episode: 350.375
avg_sample_per_episode: 350.375
avg_envstep_per_sec: 2611.8264222704943
avg_train_sample_per_sec: 2611.8264222704943
avg_episode_per_sec: 7.454374376797699
collect_time: 1.073195360954851
reward_mean: 1947.9306575068529
reward_std: 562.9332912133027
reward_max: 3111.4864125462195
reward_min: 1130.3226167813164
total_envstep_count: 22507665
total_train_sample_count: 16883716
total_episode_count: 49528
total_duration: 4474.111407136505
[2023-06-29 14:10:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2420
train_sample_count: 2420
avg_envstep_per_episode: 302.5
avg_sample_per_episode: 302.5
avg_envstep_per_sec: 2747.3808666104915
avg_train_sample_per_sec: 2747.3808666104915
avg_episode_per_sec: 9.082250798712368
collect_time: 0.8808389216838404
reward_mean: 1956.7800416012312
reward_std: 779.9273622435827
reward_max: 3506.8110071753813
reward_min: 969.9689796049871
total_envstep_count: 22512417
total_train_sample_count: 16886936
total_episode_count: 49536
total_duration: 4474.992246058188
[2023-06-29 14:10:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 206.83333333333334
avg_sample_per_episode: 206.83333333333334
avg_envstep_per_sec: 2709.577371445602
avg_train_sample_per_sec: 2709.577371445602
avg_episode_per_sec: 13.100293496110886
collect_time: 0.916010011803359
reward_mean: 1494.4058085333
reward_std: 525.4719549031851
reward_max: 2495.30709554746
reward_min: 899.1375580684057
total_envstep_count: 22517065
total_train_sample_count: 16890218
total_episode_count: 49548
total_duration: 4475.908256069992
[2023-06-29 14:10:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2614
train_sample_count: 2614
avg_envstep_per_episode: 237.63636363636363
avg_sample_per_episode: 237.63636363636363
avg_envstep_per_sec: 2604.463385532114
avg_train_sample_per_sec: 2604.463385532114
avg_episode_per_sec: 10.959868875613333
collect_time: 1.0036616427479312
reward_mean: 1589.1729732536246
reward_std: 849.8291785476468
reward_max: 3492.8195941778863
reward_min: 149.7696179989641
total_envstep_count: 22521553
total_train_sample_count: 16893632
total_episode_count: 49559
total_duration: 4476.9119177127395
[2023-06-29 14:10:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2396
train_sample_count: 2396
avg_envstep_per_episode: 239.6
avg_sample_per_episode: 239.6
avg_envstep_per_sec: 2505.976623046406
avg_train_sample_per_sec: 2505.976623046406
avg_episode_per_sec: 10.459000930911545
collect_time: 0.9561142661767082
reward_mean: 1535.4741896174269
reward_std: 681.8823447939852
reward_max: 2331.8208001100456
reward_min: 22.986771526453918
total_envstep_count: 22526273
total_train_sample_count: 16897228
total_episode_count: 49569
total_duration: 4477.868031978916
[2023-06-29 14:10:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2348
train_sample_count: 2348
avg_envstep_per_episode: 293.5
avg_sample_per_episode: 293.5
avg_envstep_per_sec: 2653.9813024333985
avg_train_sample_per_sec: 2653.9813024333985
avg_episode_per_sec: 9.04252573231141
collect_time: 0.8847085689138622
reward_mean: 2177.5198080907894
reward_std: 510.3305661359784
reward_max: 3243.1489611458096
reward_min: 1671.4661172667666
total_envstep_count: 22530937
total_train_sample_count: 16900776
total_episode_count: 49577
total_duration: 4478.75274054783
[2023-06-29 14:10:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2956
train_sample_count: 2956
avg_envstep_per_episode: 328.44444444444446
avg_sample_per_episode: 328.44444444444446
avg_envstep_per_sec: 2751.778862987656
avg_train_sample_per_sec: 2751.778862987656
avg_episode_per_sec: 8.378217106525339
collect_time: 1.0742142254812648
reward_mean: 2168.386440563863
reward_std: 783.5911646220949
reward_max: 3617.348043712727
reward_min: 1110.2699788814432
total_envstep_count: 22535657
total_train_sample_count: 16904132
total_episode_count: 49586
total_duration: 4479.826954773312
[2023-06-29 14:10:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2434
train_sample_count: 2434
avg_envstep_per_episode: 270.44444444444446
avg_sample_per_episode: 270.44444444444446
avg_envstep_per_sec: 2457.4041887885114
avg_train_sample_per_sec: 2457.4041887885114
avg_episode_per_sec: 9.086539728470257
collect_time: 0.9904760523745791
reward_mean: 1594.756528611584
reward_std: 333.9584292871072
reward_max: 2478.540284838749
reward_min: 1292.3458536358778
total_envstep_count: 22539857
total_train_sample_count: 16907366
total_episode_count: 49595
total_duration: 4480.817430825687
[2023-06-29 14:10:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2203
train_sample_count: 2203
avg_envstep_per_episode: 220.3
avg_sample_per_episode: 220.3
avg_envstep_per_sec: 2314.026892163555
avg_train_sample_per_sec: 2314.026892163555
avg_episode_per_sec: 10.503980445590354
collect_time: 0.9520200510462746
reward_mean: 1561.9214192206377
reward_std: 899.6502054795081
reward_max: 3657.454785278226
reward_min: 24.368551342416843
total_envstep_count: 22544569
total_train_sample_count: 16910769
total_episode_count: 49605
total_duration: 4481.769450876733
[2023-06-29 14:11:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1442
train_sample_count: 1442
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 2683.937110190588
avg_train_sample_per_sec: 2683.937110190588
avg_episode_per_sec: 13.028820923255282
collect_time: 0.5372704131273787
reward_mean: 2041.2165364463092
reward_std: 648.5284536482889
reward_max: 3072.5190870204597
reward_min: 1130.5415174079703
total_envstep_count: 22549097
total_train_sample_count: 16914211
total_episode_count: 49612
total_duration: 4482.30672128986
[2023-06-29 14:11:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2150
train_sample_count: 2150
avg_envstep_per_episode: 195.45454545454547
avg_sample_per_episode: 195.45454545454547
avg_envstep_per_sec: 2656.264330724311
avg_train_sample_per_sec: 2656.264330724311
avg_episode_per_sec: 13.590189599054614
collect_time: 0.8094073978750967
reward_mean: 1772.1003417017907
reward_std: 528.7528957952276
reward_max: 2849.016083417536
reward_min: 1189.5739686963034
total_envstep_count: 22553337
total_train_sample_count: 16917561
total_episode_count: 49623
total_duration: 4483.116128687736
[2023-06-29 14:11:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 245.7
avg_sample_per_episode: 245.7
avg_envstep_per_sec: 2654.6866022474546
avg_train_sample_per_sec: 2654.6866022474546
avg_episode_per_sec: 10.804585275732416
collect_time: 0.9255329792676494
reward_mean: 1640.3917221729255
reward_std: 733.6403091598693
reward_max: 3533.8886359281414
reward_min: 1056.3020316114505
total_envstep_count: 22558137
total_train_sample_count: 16920818
total_episode_count: 49633
total_duration: 4484.041661667004
[2023-06-29 14:11:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2975
train_sample_count: 2975
avg_envstep_per_episode: 228.84615384615384
avg_sample_per_episode: 228.84615384615384
avg_envstep_per_sec: 2600.2780072207443
avg_train_sample_per_sec: 2600.2780072207443
avg_episode_per_sec: 11.362559359283924
collect_time: 1.1441084344591945
reward_mean: 1501.1344831392826
reward_std: 468.43536200204517
reward_max: 2448.0261078154635
reward_min: 1028.6354769732375
total_envstep_count: 22563177
total_train_sample_count: 16924193
total_episode_count: 49646
total_duration: 4485.185770101462
[2023-06-29 14:11:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 264.54545454545456
avg_sample_per_episode: 264.54545454545456
avg_envstep_per_sec: 2570.022400414423
avg_train_sample_per_sec: 2570.022400414423
avg_episode_per_sec: 9.714861307408471
collect_time: 1.1322858507111668
reward_mean: 1665.0260307253084
reward_std: 592.922776778979
reward_max: 2561.4696603073407
reward_min: 1041.3338499319518
total_envstep_count: 22567625
total_train_sample_count: 16927503
total_episode_count: 49657
total_duration: 4486.318055952173
[2023-06-29 14:11:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2438
train_sample_count: 2438
avg_envstep_per_episode: 243.8
avg_sample_per_episode: 243.8
avg_envstep_per_sec: 2517.1023905372363
avg_train_sample_per_sec: 2517.1023905372363
avg_episode_per_sec: 10.324456072753225
collect_time: 0.9685740274870769
reward_mean: 1437.615799508912
reward_std: 570.1672649919271
reward_max: 2995.20406636614
reward_min: 1023.6221043389453
total_envstep_count: 22572065
total_train_sample_count: 16930741
total_episode_count: 49667
total_duration: 4487.286629979661
[2023-06-29 14:11:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2702
train_sample_count: 2702
avg_envstep_per_episode: 225.16666666666666
avg_sample_per_episode: 225.16666666666666
avg_envstep_per_sec: 2713.7068645333593
avg_train_sample_per_sec: 2713.7068645333593
avg_episode_per_sec: 12.051991996447192
collect_time: 0.9956860246453434
reward_mean: 1424.5451361417354
reward_std: 742.4023329961994
reward_max: 3534.471495621977
reward_min: 552.2371562998615
total_envstep_count: 22576625
total_train_sample_count: 16934243
total_episode_count: 49679
total_duration: 4488.282316004306
[2023-06-29 14:11:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2373
train_sample_count: 2373
avg_envstep_per_episode: 263.6666666666667
avg_sample_per_episode: 263.6666666666667
avg_envstep_per_sec: 2610.961839664708
avg_train_sample_per_sec: 2610.961839664708
avg_episode_per_sec: 9.902510137792824
collect_time: 0.9088604681808501
reward_mean: 1735.3654963503775
reward_std: 577.4103673411475
reward_max: 2464.937911349919
reward_min: 1017.4771629267998
total_envstep_count: 22581409
total_train_sample_count: 16937816
total_episode_count: 49688
total_duration: 4489.191176472487
[2023-06-29 14:11:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2264
train_sample_count: 2264
avg_envstep_per_episode: 205.8181818181818
avg_sample_per_episode: 205.8181818181818
avg_envstep_per_sec: 2472.456927088694
avg_train_sample_per_sec: 2472.456927088694
avg_episode_per_sec: 12.01282075882316
collect_time: 0.9156883483773564
reward_mean: 1536.0397545756016
reward_std: 728.8283245596206
reward_max: 3284.2110757847727
reward_min: 581.8533782526948
total_envstep_count: 22585913
total_train_sample_count: 16941280
total_episode_count: 49699
total_duration: 4490.106864820865
[2023-06-29 14:11:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3531
train_sample_count: 3531
avg_envstep_per_episode: 294.25
avg_sample_per_episode: 294.25
avg_envstep_per_sec: 2540.0403700641536
avg_train_sample_per_sec: 2540.0403700641536
avg_episode_per_sec: 8.632252744483106
collect_time: 1.3901353858839722
reward_mean: 1776.9444510893088
reward_std: 682.2515209894536
reward_max: 3251.3728884622005
reward_min: 1082.2827473001685
total_envstep_count: 22590745
total_train_sample_count: 16944811
total_episode_count: 49711
total_duration: 4491.497000206748
[2023-06-29 14:11:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2245
train_sample_count: 2245
avg_envstep_per_episode: 280.625
avg_sample_per_episode: 280.625
avg_envstep_per_sec: 2742.3424935374906
avg_train_sample_per_sec: 2742.3424935374906
avg_episode_per_sec: 9.772267237550077
collect_time: 0.8186431874539702
reward_mean: 1591.4234243566239
reward_std: 362.3635534698865
reward_max: 2177.7540662016377
reward_min: 1076.6246294330413
total_envstep_count: 22595409
total_train_sample_count: 16948256
total_episode_count: 49719
total_duration: 4492.315643394202
[2023-06-29 14:11:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3356
train_sample_count: 3356
avg_envstep_per_episode: 335.6
avg_sample_per_episode: 335.6
avg_envstep_per_sec: 2753.6902269407806
avg_train_sample_per_sec: 2753.6902269407806
avg_episode_per_sec: 8.205274812100061
collect_time: 1.2187282240996138
reward_mean: 2143.283435312431
reward_std: 1038.979808316238
reward_max: 3660.2466212976437
reward_min: 607.246341131956
total_envstep_count: 22600017
total_train_sample_count: 16951612
total_episode_count: 49729
total_duration: 4493.5343716183015
[2023-06-29 14:11:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2856
train_sample_count: 2856
avg_envstep_per_episode: 317.3333333333333
avg_sample_per_episode: 317.3333333333333
avg_envstep_per_sec: 2518.550683007374
avg_train_sample_per_sec: 2518.550683007374
avg_episode_per_sec: 7.936609295191305
collect_time: 1.1339855176508424
reward_mean: 1684.8562490616996
reward_std: 662.9108586587935
reward_max: 3194.11442301906
reward_min: 1098.7293239473574
total_envstep_count: 22604865
total_train_sample_count: 16954868
total_episode_count: 49738
total_duration: 4494.668357135953
[2023-06-29 14:11:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3109
train_sample_count: 3109
avg_envstep_per_episode: 282.6363636363636
avg_sample_per_episode: 282.6363636363636
avg_envstep_per_sec: 2541.87418118661
avg_train_sample_per_sec: 2541.87418118661
avg_episode_per_sec: 8.993443548746448
collect_time: 1.2231132536027578
reward_mean: 1699.047404809843
reward_std: 501.7305138484187
reward_max: 2672.286536742291
reward_min: 1029.0027233051753
total_envstep_count: 22610161
total_train_sample_count: 16958377
total_episode_count: 49749
total_duration: 4495.891470389555
[2023-06-29 14:11:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2171
train_sample_count: 2171
avg_envstep_per_episode: 217.1
avg_sample_per_episode: 217.1
avg_envstep_per_sec: 2690.5865026913652
avg_train_sample_per_sec: 2690.5865026913652
avg_episode_per_sec: 12.393304941001222
collect_time: 0.8068872707970443
reward_mean: 1456.9806845644625
reward_std: 450.17223163527814
reward_max: 2516.226850642372
reward_min: 1004.6014377312428
total_envstep_count: 22614353
total_train_sample_count: 16961748
total_episode_count: 49759
total_duration: 4496.6983576603525
[2023-06-29 14:11:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1657
train_sample_count: 1657
avg_envstep_per_episode: 236.71428571428572
avg_sample_per_episode: 236.71428571428572
avg_envstep_per_sec: 2796.1390300969283
avg_train_sample_per_sec: 2796.1390300969283
avg_episode_per_sec: 11.812295238792093
collect_time: 0.5926028649378569
reward_mean: 1941.6774406305685
reward_std: 718.3317989613295
reward_max: 3531.557733346305
reward_min: 1187.5575231663995
total_envstep_count: 22618161
total_train_sample_count: 16965005
total_episode_count: 49766
total_duration: 4497.290960525291
[2023-06-29 14:11:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2041
train_sample_count: 2041
avg_envstep_per_episode: 291.57142857142856
avg_sample_per_episode: 291.57142857142856
avg_envstep_per_sec: 2498.971455557802
avg_train_sample_per_sec: 2498.971455557802
avg_episode_per_sec: 8.570700729497606
collect_time: 0.8167360197175293
reward_mean: 2219.2165022216936
reward_std: 1131.7436820755654
reward_max: 3580.4898540513805
reward_min: 768.0695023645645
total_envstep_count: 22622649
total_train_sample_count: 16968246
total_episode_count: 49773
total_duration: 4498.107696545008
[2023-06-29 14:11:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1836
train_sample_count: 1836
avg_envstep_per_episode: 262.2857142857143
avg_sample_per_episode: 262.2857142857143
avg_envstep_per_sec: 2757.7296720118534
avg_train_sample_per_sec: 2757.7296720118534
avg_episode_per_sec: 10.514219882398134
collect_time: 0.6657650380432606
reward_mean: 2262.796299980051
reward_std: 957.7444531358346
reward_max: 3528.141347812481
reward_min: 1029.564154330927
total_envstep_count: 22627289
total_train_sample_count: 16971682
total_episode_count: 49780
total_duration: 4498.773461583051
[2023-06-29 14:11:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2355
train_sample_count: 2355
avg_envstep_per_episode: 261.6666666666667
avg_sample_per_episode: 261.6666666666667
avg_envstep_per_sec: 2807.4341219908974
avg_train_sample_per_sec: 2807.4341219908974
avg_episode_per_sec: 10.729047599965213
collect_time: 0.8388442605128512
reward_mean: 2079.1455855512518
reward_std: 857.9349544201069
reward_max: 3366.851390972741
reward_min: 874.9768624917926
total_envstep_count: 22632105
total_train_sample_count: 16975237
total_episode_count: 49789
total_duration: 4499.612305843564
[2023-06-29 14:12:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2170
train_sample_count: 2170
avg_envstep_per_episode: 361.6666666666667
avg_sample_per_episode: 361.6666666666667
avg_envstep_per_sec: 2760.9173358195876
avg_train_sample_per_sec: 2760.9173358195876
avg_episode_per_sec: 7.633872817934344
collect_time: 0.7859706525243821
reward_mean: 2391.6209569183015
reward_std: 708.3398824387028
reward_max: 3296.775496980155
reward_min: 1318.2678321373128
total_envstep_count: 22636433
total_train_sample_count: 16978607
total_episode_count: 49795
total_duration: 4500.398276496088
[2023-06-29 14:12:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2183
train_sample_count: 2183
avg_envstep_per_episode: 311.85714285714283
avg_sample_per_episode: 311.85714285714283
avg_envstep_per_sec: 2668.6222761642393
avg_train_sample_per_sec: 2668.6222761642393
avg_episode_per_sec: 8.557194655588491
collect_time: 0.8180250983806328
reward_mean: 2336.0675652726977
reward_std: 1114.760192673347
reward_max: 3544.3969101302696
reward_min: 1027.1875776008694
total_envstep_count: 22641881
total_train_sample_count: 16981990
total_episode_count: 49802
total_duration: 4501.216301594469
[2023-06-29 14:12:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1778
train_sample_count: 1778
avg_envstep_per_episode: 296.3333333333333
avg_sample_per_episode: 296.3333333333333
avg_envstep_per_sec: 2715.443775777688
avg_train_sample_per_sec: 2715.443775777688
avg_episode_per_sec: 9.163477308586124
collect_time: 0.6547732697911561
reward_mean: 2808.574254068449
reward_std: 814.1283023824725
reward_max: 3505.8058367558683
reward_min: 1449.367614591011
total_envstep_count: 22646705
total_train_sample_count: 16985368
total_episode_count: 49808
total_duration: 4501.87107486426
[2023-06-29 14:12:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1680
train_sample_count: 1680
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 2680.0702577780344
avg_train_sample_per_sec: 2680.0702577780344
avg_episode_per_sec: 9.571679492064408
collect_time: 0.6268492384199053
reward_mean: 2930.9960382689655
reward_std: 995.0625034009024
reward_max: 3715.509804907528
reward_min: 1167.2001134207867
total_envstep_count: 22651433
total_train_sample_count: 16988648
total_episode_count: 49814
total_duration: 4502.4979241026795
[2023-06-29 14:12:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2632
train_sample_count: 2632
avg_envstep_per_episode: 292.44444444444446
avg_sample_per_episode: 292.44444444444446
avg_envstep_per_sec: 2757.260065149434
avg_train_sample_per_sec: 2757.260065149434
avg_episode_per_sec: 9.428320891468429
collect_time: 0.9545708195129409
reward_mean: 2375.155066535541
reward_std: 1035.0914703300382
reward_max: 3590.849224115454
reward_min: 764.6050555617828
total_envstep_count: 22656657
total_train_sample_count: 16992080
total_episode_count: 49823
total_duration: 4503.452494922192
[2023-06-29 14:12:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1904
train_sample_count: 1904
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 2718.3638587060464
avg_train_sample_per_sec: 2718.3638587060464
avg_episode_per_sec: 11.421696885319522
collect_time: 0.7004213192071767
reward_mean: 1992.0779315238087
reward_std: 989.6272469882537
reward_max: 3607.6664521512735
reward_min: 991.7630855555155
total_envstep_count: 22661129
total_train_sample_count: 16995584
total_episode_count: 49831
total_duration: 4504.152916241399
[2023-06-29 14:12:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 315.0
avg_sample_per_episode: 315.0
avg_envstep_per_sec: 2649.013624625319
avg_train_sample_per_sec: 2649.013624625319
avg_episode_per_sec: 8.409567062302601
collect_time: 0.4756487427195534
reward_mean: 3072.4113758341837
reward_std: 481.404458942548
reward_max: 3567.1324497160504
reward_min: 2561.1476927879344
total_envstep_count: 22665169
total_train_sample_count: 16998844
total_episode_count: 49835
total_duration: 4504.628564984118
[2023-06-29 14:12:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3481
train_sample_count: 3481
avg_envstep_per_episode: 316.45454545454544
avg_sample_per_episode: 316.45454545454544
avg_envstep_per_sec: 2510.222620411997
avg_train_sample_per_sec: 2510.222620411997
avg_episode_per_sec: 7.93233232534673
collect_time: 1.3867295958908503
reward_mean: 2349.1282959975697
reward_std: 1023.9573583086684
reward_max: 3776.0815119006825
reward_min: 983.5847180978077
total_envstep_count: 22670097
total_train_sample_count: 17002325
total_episode_count: 49846
total_duration: 4506.015294580009
[2023-06-29 14:12:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2894
train_sample_count: 2894
avg_envstep_per_episode: 289.4
avg_sample_per_episode: 289.4
avg_envstep_per_sec: 2485.977274857997
avg_train_sample_per_sec: 2485.977274857997
avg_episode_per_sec: 8.590108067926735
collect_time: 1.1641297083720565
reward_mean: 1560.6184983028027
reward_std: 503.95834189809796
reward_max: 2393.534531382615
reward_min: 598.245539623551
total_envstep_count: 22675313
total_train_sample_count: 17005619
total_episode_count: 49856
total_duration: 4507.179424288382
[2023-06-29 14:12:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2140
train_sample_count: 2140
avg_envstep_per_episode: 356.6666666666667
avg_sample_per_episode: 356.6666666666667
avg_envstep_per_sec: 2600.9701706509613
avg_train_sample_per_sec: 2600.9701706509613
avg_episode_per_sec: 7.2924397307970885
collect_time: 0.8227699126070364
reward_mean: 2147.9249057056327
reward_std: 611.690132530287
reward_max: 2839.612504087721
reward_min: 1372.2368978623313
total_envstep_count: 22679593
total_train_sample_count: 17008959
total_episode_count: 49862
total_duration: 4508.002194200989
[2023-06-29 14:12:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2461
train_sample_count: 2461
avg_envstep_per_episode: 223.72727272727272
avg_sample_per_episode: 223.72727272727272
avg_envstep_per_sec: 2369.0525670255092
avg_train_sample_per_sec: 2369.0525670255092
avg_episode_per_sec: 10.58902000702178
collect_time: 1.0388119006957859
reward_mean: 1844.7182549943122
reward_std: 1046.4476696583047
reward_max: 3655.470680435355
reward_min: 937.7822678699438
total_envstep_count: 22684265
total_train_sample_count: 17012220
total_episode_count: 49873
total_duration: 4509.041006101685
[2023-06-29 14:12:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2414
train_sample_count: 2414
avg_envstep_per_episode: 268.22222222222223
avg_sample_per_episode: 268.22222222222223
avg_envstep_per_sec: 2175.984446440103
avg_train_sample_per_sec: 2175.984446440103
avg_episode_per_sec: 8.112618068749349
collect_time: 1.109382929620333
reward_mean: 1695.2857867071207
reward_std: 930.1839010491371
reward_max: 3485.9272423037855
reward_min: 865.2540305304765
total_envstep_count: 22688601
total_train_sample_count: 17015434
total_episode_count: 49882
total_duration: 4510.150389031305
[2023-06-29 14:12:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2958
train_sample_count: 2958
avg_envstep_per_episode: 246.5
avg_sample_per_episode: 246.5
avg_envstep_per_sec: 1960.7970109576584
avg_train_sample_per_sec: 1960.7970109576584
avg_episode_per_sec: 7.954551768590906
collect_time: 1.5085702311201021
reward_mean: 1626.9594232902093
reward_std: 924.3974001926513
reward_max: 3625.9862403691786
reward_min: 929.8121499878777
total_envstep_count: 22693577
total_train_sample_count: 17018792
total_episode_count: 49894
total_duration: 4511.658959262425
[2023-06-29 14:12:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 224.77777777777777
avg_sample_per_episode: 224.77777777777777
avg_envstep_per_sec: 2362.60215598127
avg_train_sample_per_sec: 2362.60215598127
avg_episode_per_sec: 10.510835098285431
collect_time: 0.8562592711085455
reward_mean: 1511.913757587587
reward_std: 372.389502957266
reward_max: 2071.875025949117
reward_min: 1013.6450577856765
total_envstep_count: 22697329
total_train_sample_count: 17022015
total_episode_count: 49903
total_duration: 4512.515218533534
[2023-06-29 14:12:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 247.4
avg_sample_per_episode: 247.4
avg_envstep_per_sec: 2382.554961738195
avg_train_sample_per_sec: 2382.554961738195
avg_episode_per_sec: 9.630375754802728
collect_time: 0.5191905411900952
reward_mean: 2288.4317843787444
reward_std: 812.0474921796813
reward_max: 3663.575339916299
reward_min: 1313.0924353106734
total_envstep_count: 22702001
total_train_sample_count: 17025252
total_episode_count: 49908
total_duration: 4513.034409074724
[2023-06-29 14:12:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2894
train_sample_count: 2894
avg_envstep_per_episode: 361.75
avg_sample_per_episode: 361.75
avg_envstep_per_sec: 2567.4617786302842
avg_train_sample_per_sec: 2567.4617786302842
avg_episode_per_sec: 7.097337328625527
collect_time: 1.1271832843190057
reward_mean: 2977.4264071752496
reward_std: 856.2422214818049
reward_max: 3610.8048799132876
reward_min: 1282.1054075833924
total_envstep_count: 22706889
total_train_sample_count: 17028546
total_episode_count: 49916
total_duration: 4514.1615923590425
[2023-06-29 14:12:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2231
train_sample_count: 2231
avg_envstep_per_episode: 247.88888888888889
avg_sample_per_episode: 247.88888888888889
avg_envstep_per_sec: 2354.654450439659
avg_train_sample_per_sec: 2354.654450439659
avg_episode_per_sec: 9.498830145207052
collect_time: 0.947485096840188
reward_mean: 1614.1288113009396
reward_std: 443.03568536359546
reward_max: 2564.1615451004895
reward_min: 1181.6062367933287
total_envstep_count: 22710921
total_train_sample_count: 17031977
total_episode_count: 49925
total_duration: 4515.1090774558825
[2023-06-29 14:12:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1872
train_sample_count: 1872
avg_envstep_per_episode: 267.42857142857144
avg_sample_per_episode: 267.42857142857144
avg_envstep_per_sec: 2298.34551034691
avg_train_sample_per_sec: 2298.34551034691
avg_episode_per_sec: 8.59424069039977
collect_time: 0.8144989478616043
reward_mean: 1962.081213104926
reward_std: 802.562765873309
reward_max: 3476.2533891279904
reward_min: 1168.4657547762895
total_envstep_count: 22715705
total_train_sample_count: 17035449
total_episode_count: 49932
total_duration: 4515.923576403744
[2023-06-29 14:13:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1547
train_sample_count: 1547
avg_envstep_per_episode: 221.0
avg_sample_per_episode: 221.0
avg_envstep_per_sec: 2677.1884696806615
avg_train_sample_per_sec: 2677.1884696806615
avg_episode_per_sec: 12.113974975930596
collect_time: 0.5778450107341633
reward_mean: 2249.5758610200824
reward_std: 1141.3537608513807
reward_max: 3591.9336299650386
reward_min: 988.0564745415595
total_envstep_count: 22720057
total_train_sample_count: 17038996
total_episode_count: 49939
total_duration: 4516.5014214144785
[2023-06-29 14:13:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1699
train_sample_count: 1699
avg_envstep_per_episode: 242.71428571428572
avg_sample_per_episode: 242.71428571428572
avg_envstep_per_sec: 2731.644014870052
avg_train_sample_per_sec: 2731.644014870052
avg_episode_per_sec: 11.254566276686502
collect_time: 0.6219697701279072
reward_mean: 2256.6984661494425
reward_std: 1000.097701807505
reward_max: 3573.2049741282135
reward_min: 1191.460456941894
total_envstep_count: 22724121
total_train_sample_count: 17042295
total_episode_count: 49946
total_duration: 4517.123391184607
[2023-06-29 14:13:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2397
train_sample_count: 2397
avg_envstep_per_episode: 217.9090909090909
avg_sample_per_episode: 217.9090909090909
avg_envstep_per_sec: 2315.6844312677727
avg_train_sample_per_sec: 2315.6844312677727
avg_episode_per_sec: 10.626837189797872
collect_time: 1.0351151338387283
reward_mean: 1786.5042369187702
reward_std: 979.177761407109
reward_max: 3669.6638309856144
reward_min: 780.8404637418801
total_envstep_count: 22728625
total_train_sample_count: 17045892
total_episode_count: 49957
total_duration: 4518.158506318446
[2023-06-29 14:13:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2655
train_sample_count: 2655
avg_envstep_per_episode: 221.25
avg_sample_per_episode: 221.25
avg_envstep_per_sec: 2500.1285129282755
avg_train_sample_per_sec: 2500.1285129282755
avg_episode_per_sec: 11.300015877641922
collect_time: 1.0619454105142505
reward_mean: 1453.9078887286269
reward_std: 478.54329670073645
reward_max: 2552.7732502776944
reward_min: 863.9522287704998
total_envstep_count: 22733353
total_train_sample_count: 17049347
total_episode_count: 49969
total_duration: 4519.22045172896
[2023-06-29 14:13:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1654
train_sample_count: 1654
avg_envstep_per_episode: 183.77777777777777
avg_sample_per_episode: 183.77777777777777
avg_envstep_per_sec: 2726.739656897244
avg_train_sample_per_sec: 2726.739656897244
avg_episode_per_sec: 14.837156536925754
collect_time: 0.6065852292925119
reward_mean: 1428.821670147002
reward_std: 293.91909810158313
reward_max: 2007.5965296396885
reward_min: 981.7334823274125
total_envstep_count: 22737129
total_train_sample_count: 17052601
total_episode_count: 49978
total_duration: 4519.827036958252
[2023-06-29 14:13:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2913
train_sample_count: 2913
avg_envstep_per_episode: 323.6666666666667
avg_sample_per_episode: 323.6666666666667
avg_envstep_per_sec: 2727.7419742600405
avg_train_sample_per_sec: 2727.7419742600405
avg_episode_per_sec: 8.427627108939364
collect_time: 1.067916257288307
reward_mean: 2101.1494411290323
reward_std: 933.2911755845897
reward_max: 3693.4232128805447
reward_min: 1072.7549103275287
total_envstep_count: 22741121
total_train_sample_count: 17055914
total_episode_count: 49987
total_duration: 4520.894953215541
[2023-06-29 14:13:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3074
train_sample_count: 3074
avg_envstep_per_episode: 307.4
avg_sample_per_episode: 307.4
avg_envstep_per_sec: 2639.7231903156066
avg_train_sample_per_sec: 2639.7231903156066
avg_episode_per_sec: 8.587258263876404
collect_time: 1.164516041408293
reward_mean: 1595.5124181404958
reward_std: 795.5442954844793
reward_max: 3594.648987252628
reward_min: 992.4756618536123
total_envstep_count: 22745497
total_train_sample_count: 17059388
total_episode_count: 49997
total_duration: 4522.059469256949
[2023-06-29 14:13:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2058
train_sample_count: 2058
avg_envstep_per_episode: 294.0
avg_sample_per_episode: 294.0
avg_envstep_per_sec: 2651.4426833221455
avg_train_sample_per_sec: 2651.4426833221455
avg_episode_per_sec: 9.018512528306617
collect_time: 0.7761812137011437
reward_mean: 1757.351613214462
reward_std: 679.3700875935291
reward_max: 3082.3852699031363
reward_min: 969.0087061126741
total_envstep_count: 22750025
total_train_sample_count: 17062646
total_episode_count: 50004
total_duration: 4522.835650470651
[2023-06-29 14:13:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2162
train_sample_count: 2162
avg_envstep_per_episode: 240.22222222222223
avg_sample_per_episode: 240.22222222222223
avg_envstep_per_sec: 2747.2586329882765
avg_train_sample_per_sec: 2747.2586329882765
avg_episode_per_sec: 11.436321783947497
collect_time: 0.7869663139972836
reward_mean: 1792.840797809817
reward_std: 672.3428948599645
reward_max: 2938.709658718806
reward_min: 1030.132138473008
total_envstep_count: 22754001
total_train_sample_count: 17066008
total_episode_count: 50013
total_duration: 4523.622616784648
[2023-06-29 14:13:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3003
train_sample_count: 3003
avg_envstep_per_episode: 300.3
avg_sample_per_episode: 300.3
avg_envstep_per_sec: 2736.9893056439596
avg_train_sample_per_sec: 2736.9893056439596
avg_episode_per_sec: 9.114183501977887
collect_time: 1.0971909878520527
reward_mean: 1875.2382774534708
reward_std: 878.0195168204714
reward_max: 3484.4730998264795
reward_min: 915.134429189058
total_envstep_count: 22758849
total_train_sample_count: 17069411
total_episode_count: 50023
total_duration: 4524.7198077725
[2023-06-29 14:13:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2240
train_sample_count: 2240
avg_envstep_per_episode: 203.63636363636363
avg_sample_per_episode: 203.63636363636363
avg_envstep_per_sec: 2135.3717694899296
avg_train_sample_per_sec: 2135.3717694899296
avg_episode_per_sec: 10.48620065374519
collect_time: 1.0489976649523014
reward_mean: 1327.1506667614312
reward_std: 876.7634236415919
reward_max: 3524.612951329732
reward_min: 19.565011685458625
total_envstep_count: 22763513
total_train_sample_count: 17072851
total_episode_count: 50034
total_duration: 4525.768805437452
[2023-06-29 14:13:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2767
train_sample_count: 2767
avg_envstep_per_episode: 212.84615384615384
avg_sample_per_episode: 212.84615384615384
avg_envstep_per_sec: 2557.8046517253433
avg_train_sample_per_sec: 2557.8046517253433
avg_episode_per_sec: 12.017152321080399
collect_time: 1.081787070069462
reward_mean: 1480.1728405248748
reward_std: 533.4007467101732
reward_max: 2543.0622876853276
reward_min: 902.6416280433831
total_envstep_count: 22768041
total_train_sample_count: 17076418
total_episode_count: 50047
total_duration: 4526.8505925075215
[2023-06-29 14:13:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1285
train_sample_count: 1285
avg_envstep_per_episode: 160.625
avg_sample_per_episode: 160.625
avg_envstep_per_sec: 2639.88565387074
avg_train_sample_per_sec: 2639.88565387074
avg_episode_per_sec: 16.435085782852855
collect_time: 0.48676350739505136
reward_mean: 1317.9606187191266
reward_std: 282.5532466543197
reward_max: 1873.6281618534556
reward_min: 947.6840133716468
total_envstep_count: 22771993
total_train_sample_count: 17079703
total_episode_count: 50055
total_duration: 4527.337356014917
[2023-06-29 14:13:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 182.42857142857142
avg_sample_per_episode: 182.42857142857142
avg_envstep_per_sec: 2074.753581970689
avg_train_sample_per_sec: 2074.753581970689
avg_episode_per_sec: 11.372964035861257
collect_time: 0.6154947802461683
reward_mean: 1781.0067412437454
reward_std: 874.2649281610079
reward_max: 3489.6528270589984
reward_min: 930.5585025828086
total_envstep_count: 22776033
total_train_sample_count: 17082980
total_episode_count: 50062
total_duration: 4527.952850795163
[2023-06-29 14:13:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1781
train_sample_count: 1781
avg_envstep_per_episode: 178.1
avg_sample_per_episode: 178.1
avg_envstep_per_sec: 2714.126496456374
avg_train_sample_per_sec: 2714.126496456374
avg_episode_per_sec: 15.239340238385031
collect_time: 0.6561963866921142
reward_mean: 1876.34386747481
reward_std: 954.9165759224902
reward_max: 3545.779231395828
reward_min: 717.3250966202655
total_envstep_count: 22780001
total_train_sample_count: 17086361
total_episode_count: 50072
total_duration: 4528.609047181855
[2023-06-29 14:13:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1649
train_sample_count: 1649
avg_envstep_per_episode: 274.8333333333333
avg_sample_per_episode: 274.8333333333333
avg_envstep_per_sec: 2513.840993788446
avg_train_sample_per_sec: 2513.840993788446
avg_episode_per_sec: 9.146783482553472
collect_time: 0.6559682987406851
reward_mean: 2240.3001860952577
reward_std: 958.8461027526313
reward_max: 3551.451804345712
reward_min: 668.0099467679281
total_envstep_count: 22784225
total_train_sample_count: 17089610
total_episode_count: 50078
total_duration: 4529.265015480596
[2023-06-29 14:13:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1660
train_sample_count: 1660
avg_envstep_per_episode: 332.0
avg_sample_per_episode: 332.0
avg_envstep_per_sec: 2679.3766090061054
avg_train_sample_per_sec: 2679.3766090061054
avg_episode_per_sec: 8.070411472909957
collect_time: 0.6195470970449968
reward_mean: 2614.6343544666775
reward_std: 863.1683430702012
reward_max: 3548.092863074915
reward_min: 1285.5129434470075
total_envstep_count: 22788225
total_train_sample_count: 17092870
total_episode_count: 50083
total_duration: 4529.884562577641
[2023-06-29 14:13:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1111
train_sample_count: 1111
avg_envstep_per_episode: 222.2
avg_sample_per_episode: 222.2
avg_envstep_per_sec: 2658.186761237845
avg_train_sample_per_sec: 2658.186761237845
avg_episode_per_sec: 11.963036729243228
collect_time: 0.41795407914929106
reward_mean: 2869.4304178664056
reward_std: 803.0720506498668
reward_max: 3549.5261350970122
reward_min: 1611.4342784891335
total_envstep_count: 22793065
total_train_sample_count: 17096381
total_episode_count: 50088
total_duration: 4530.30251665679
[2023-06-29 14:13:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 367.3333333333333
avg_sample_per_episode: 367.3333333333333
avg_envstep_per_sec: 2703.067569647882
avg_train_sample_per_sec: 2703.067569647882
avg_episode_per_sec: 7.358623147861747
collect_time: 0.815369924432598
reward_mean: 3113.138030733761
reward_std: 853.0386599217672
reward_max: 3506.5317733990755
reward_min: 1205.8084420380285
total_envstep_count: 22797441
total_train_sample_count: 17099785
total_episode_count: 50094
total_duration: 4531.117886581223
[2023-06-29 14:13:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 211.2
avg_sample_per_episode: 211.2
avg_envstep_per_sec: 2329.7393452127553
avg_train_sample_per_sec: 2329.7393452127553
avg_episode_per_sec: 11.030962808772514
collect_time: 0.45326959093939523
reward_mean: 2576.3061164214514
reward_std: 1117.4610203239884
reward_max: 3507.3383268016423
reward_min: 1190.4681189536263
total_envstep_count: 22802105
total_train_sample_count: 17103241
total_episode_count: 50099
total_duration: 4531.571156172162
[2023-06-29 14:14:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2869
train_sample_count: 2869
avg_envstep_per_episode: 358.625
avg_sample_per_episode: 358.625
avg_envstep_per_sec: 2489.5784411073414
avg_train_sample_per_sec: 2489.5784411073414
avg_episode_per_sec: 6.942010292387149
collect_time: 1.15240393820405
reward_mean: 3073.762446319315
reward_std: 786.0648547930629
reward_max: 3618.6874057714804
reward_min: 1567.2506244972863
total_envstep_count: 22806905
total_train_sample_count: 17106510
total_episode_count: 50107
total_duration: 4532.723560110366
[2023-06-29 14:14:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1687
train_sample_count: 1687
avg_envstep_per_episode: 337.4
avg_sample_per_episode: 337.4
avg_envstep_per_sec: 2639.5851578693064
avg_train_sample_per_sec: 2639.5851578693064
avg_episode_per_sec: 7.823311078450819
collect_time: 0.6391155803292058
reward_mean: 2309.8491598529445
reward_std: 814.9422162802358
reward_max: 3500.5885863625167
reward_min: 1267.389686003296
total_envstep_count: 22811425
total_train_sample_count: 17109797
total_episode_count: 50112
total_duration: 4533.362675690695
[2023-06-29 14:14:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1396
train_sample_count: 1396
avg_envstep_per_episode: 279.2
avg_sample_per_episode: 279.2
avg_envstep_per_sec: 2756.378875576987
avg_train_sample_per_sec: 2756.378875576987
avg_episode_per_sec: 9.87241717613534
collect_time: 0.5064615798536688
reward_mean: 3133.046362037893
reward_std: 461.2846971295688
reward_max: 3543.5622031516696
reward_min: 2464.826099913745
total_envstep_count: 22815505
total_train_sample_count: 17113193
total_episode_count: 50117
total_duration: 4533.869137270549
[2023-06-29 14:14:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2140
train_sample_count: 2140
avg_envstep_per_episode: 428.0
avg_sample_per_episode: 428.0
avg_envstep_per_sec: 2624.900335561946
avg_train_sample_per_sec: 2624.900335561946
avg_episode_per_sec: 6.132944709256884
collect_time: 0.8152690488882363
reward_mean: 3260.805261611828
reward_std: 348.7084225532716
reward_max: 3546.5556892293266
reward_min: 2627.159968345077
total_envstep_count: 22820041
total_train_sample_count: 17116533
total_episode_count: 50122
total_duration: 4534.684406319437
[2023-06-29 14:14:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2994
train_sample_count: 2994
avg_envstep_per_episode: 272.1818181818182
avg_sample_per_episode: 272.1818181818182
avg_envstep_per_sec: 2248.5541922891057
avg_train_sample_per_sec: 2248.5541922891057
avg_episode_per_sec: 8.261221147354764
collect_time: 1.3315222778562454
reward_mean: 1957.7745859028307
reward_std: 942.3711373950148
reward_max: 3520.8637906212443
reward_min: 962.2851395322243
total_envstep_count: 22824825
total_train_sample_count: 17119927
total_episode_count: 50133
total_duration: 4536.015928597293
[2023-06-29 14:14:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 276.55555555555554
avg_sample_per_episode: 276.55555555555554
avg_envstep_per_sec: 2659.1303953178517
avg_train_sample_per_sec: 2659.1303953178517
avg_episode_per_sec: 9.615176198417302
collect_time: 0.9360202885810286
reward_mean: 1672.1801119087213
reward_std: 492.28165752425485
reward_max: 2400.514260112641
reward_min: 1012.3495892099419
total_envstep_count: 22828649
total_train_sample_count: 17123216
total_episode_count: 50142
total_duration: 4536.951948885874
[2023-06-29 14:14:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 978
train_sample_count: 978
avg_envstep_per_episode: 195.6
avg_sample_per_episode: 195.6
avg_envstep_per_sec: 2616.941383658717
avg_train_sample_per_sec: 2616.941383658717
avg_episode_per_sec: 13.379045928725546
collect_time: 0.3737187260314822
reward_mean: 1698.1944558783903
reward_std: 882.7849444640541
reward_max: 3317.930868901857
reward_min: 763.2312719258072
total_envstep_count: 22833825
total_train_sample_count: 17126594
total_episode_count: 50147
total_duration: 4537.325667611905
[2023-06-29 14:14:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 268.5
avg_sample_per_episode: 268.5
avg_envstep_per_sec: 2576.636288164748
avg_train_sample_per_sec: 2576.636288164748
avg_episode_per_sec: 9.596410756665728
collect_time: 1.0420562701585003
reward_mean: 2575.8226558915894
reward_std: 811.2753562345184
reward_max: 3596.0201616742825
reward_min: 1167.6422609039967
total_envstep_count: 22838729
total_train_sample_count: 17130079
total_episode_count: 50157
total_duration: 4538.367723882064
[2023-06-29 14:14:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2250
train_sample_count: 2250
avg_envstep_per_episode: 281.25
avg_sample_per_episode: 281.25
avg_envstep_per_sec: 2368.556944973468
avg_train_sample_per_sec: 2368.556944973468
avg_episode_per_sec: 8.421535804350109
collect_time: 0.9499454951990627
reward_mean: 1987.1919436986568
reward_std: 664.0487924969515
reward_max: 3533.7302696289144
reward_min: 1073.9266873280694
total_envstep_count: 22843673
total_train_sample_count: 17133529
total_episode_count: 50165
total_duration: 4539.317669377263
[2023-06-29 14:14:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 316.55555555555554
avg_sample_per_episode: 316.55555555555554
avg_envstep_per_sec: 2628.2383399674036
avg_train_sample_per_sec: 2628.2383399674036
avg_episode_per_sec: 8.302613218570247
collect_time: 1.0839960579965264
reward_mean: 2231.6482482583106
reward_std: 964.0224737028299
reward_max: 3679.9238939699676
reward_min: 999.0891276826354
total_envstep_count: 22848305
total_train_sample_count: 17136778
total_episode_count: 50174
total_duration: 4540.40166543526
[2023-06-29 14:14:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3009
train_sample_count: 3009
avg_envstep_per_episode: 376.125
avg_sample_per_episode: 376.125
avg_envstep_per_sec: 2637.5495638805337
avg_train_sample_per_sec: 2637.5495638805337
avg_episode_per_sec: 7.0124282190243505
collect_time: 1.1408316420689226
reward_mean: 2149.792132785441
reward_std: 662.0942698888095
reward_max: 3487.6187822338748
reward_min: 1124.6772869645831
total_envstep_count: 22852753
total_train_sample_count: 17140187
total_episode_count: 50182
total_duration: 4541.542497077329
[2023-06-29 14:14:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3049
train_sample_count: 3049
avg_envstep_per_episode: 254.08333333333334
avg_sample_per_episode: 254.08333333333334
avg_envstep_per_sec: 2733.407850171103
avg_train_sample_per_sec: 2733.407850171103
avg_episode_per_sec: 10.757918728125036
collect_time: 1.1154573949910702
reward_mean: 1412.7837769036378
reward_std: 513.8264881015176
reward_max: 2910.790921433902
reward_min: 887.888859314508
total_envstep_count: 22857881
total_train_sample_count: 17143636
total_episode_count: 50194
total_duration: 4542.65795447232
[2023-06-29 14:14:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1459
train_sample_count: 1459
avg_envstep_per_episode: 208.42857142857142
avg_sample_per_episode: 208.42857142857142
avg_envstep_per_sec: 2341.278255702687
avg_train_sample_per_sec: 2341.278255702687
avg_episode_per_sec: 11.23300054141111
collect_time: 0.6231638620682063
reward_mean: 1771.8806944232742
reward_std: 784.3918499455864
reward_max: 3407.0034726663143
reward_min: 876.7584681182587
total_envstep_count: 22862473
total_train_sample_count: 17147095
total_episode_count: 50201
total_duration: 4543.281118334388
[2023-06-29 14:14:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3048
train_sample_count: 3048
avg_envstep_per_episode: 234.46153846153845
avg_sample_per_episode: 234.46153846153845
avg_envstep_per_sec: 2495.0668420729016
avg_train_sample_per_sec: 2495.0668420729016
avg_episode_per_sec: 10.641689287056339
collect_time: 1.2216105591254307
reward_mean: 1763.8430848630148
reward_std: 1056.575574331296
reward_max: 3578.9878103839324
reward_min: 250.34389157349605
total_envstep_count: 22867161
total_train_sample_count: 17150543
total_episode_count: 50214
total_duration: 4544.502728893513
[2023-06-29 14:14:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2775
train_sample_count: 2775
avg_envstep_per_episode: 252.27272727272728
avg_sample_per_episode: 252.27272727272728
avg_envstep_per_sec: 2446.6825990452903
avg_train_sample_per_sec: 2446.6825990452903
avg_episode_per_sec: 9.698561653873222
collect_time: 1.134188799594529
reward_mean: 1467.7117433055698
reward_std: 484.1491323706068
reward_max: 2514.6511244098256
reward_min: 704.8440658451126
total_envstep_count: 22871977
total_train_sample_count: 17154118
total_episode_count: 50225
total_duration: 4545.6369176931075
[2023-06-29 14:14:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2527
train_sample_count: 2527
avg_envstep_per_episode: 280.77777777777777
avg_sample_per_episode: 280.77777777777777
avg_envstep_per_sec: 2452.628725649382
avg_train_sample_per_sec: 2452.628725649382
avg_episode_per_sec: 8.735124072356326
collect_time: 1.0303230870505795
reward_mean: 1806.3238890572911
reward_std: 499.23868374923154
reward_max: 2440.995844582923
reward_min: 1000.3795328710845
total_envstep_count: 22876473
total_train_sample_count: 17157445
total_episode_count: 50234
total_duration: 4546.667240780158
[2023-06-29 14:14:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2115
train_sample_count: 2115
avg_envstep_per_episode: 211.5
avg_sample_per_episode: 211.5
avg_envstep_per_sec: 2347.222012908472
avg_train_sample_per_sec: 2347.222012908472
avg_episode_per_sec: 11.097976420371026
collect_time: 0.9010651691099629
reward_mean: 1553.3117003507537
reward_std: 782.4222584243994
reward_max: 3635.1128012743134
reward_min: 649.2424524526288
total_envstep_count: 22880825
total_train_sample_count: 17160760
total_episode_count: 50244
total_duration: 4547.568305949268
[2023-06-29 14:14:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1749
train_sample_count: 1749
avg_envstep_per_episode: 194.33333333333334
avg_sample_per_episode: 194.33333333333334
avg_envstep_per_sec: 2220.4222879367103
avg_train_sample_per_sec: 2220.4222879367103
avg_episode_per_sec: 11.425843677204343
collect_time: 0.7876880039901006
reward_mean: 1621.9133014994359
reward_std: 506.93798957925685
reward_max: 2341.7223369178323
reward_min: 1000.4327946294857
total_envstep_count: 22885585
total_train_sample_count: 17164109
total_episode_count: 50253
total_duration: 4548.355993953258
[2023-06-29 14:15:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 247.76923076923077
avg_sample_per_episode: 247.76923076923077
avg_envstep_per_sec: 2302.330934252736
avg_train_sample_per_sec: 2302.330934252736
avg_episode_per_sec: 9.292239101299462
collect_time: 1.3990169493359281
reward_mean: 1725.0770531418889
reward_std: 871.9587142643144
reward_max: 3509.6016582657644
reward_min: 692.4149606584533
total_envstep_count: 22890217
total_train_sample_count: 17167330
total_episode_count: 50266
total_duration: 4549.755010902594
[2023-06-29 14:15:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2840
train_sample_count: 2840
avg_envstep_per_episode: 315.55555555555554
avg_sample_per_episode: 315.55555555555554
avg_envstep_per_sec: 2387.7902070981386
avg_train_sample_per_sec: 2387.7902070981386
avg_episode_per_sec: 7.566940797141988
collect_time: 1.1893842229344882
reward_mean: 1653.8988359884747
reward_std: 436.973431070159
reward_max: 2492.815911360027
reward_min: 1237.5215766027036
total_envstep_count: 22894857
total_train_sample_count: 17170570
total_episode_count: 50275
total_duration: 4550.944395125529
[2023-06-29 14:15:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3124
train_sample_count: 3124
avg_envstep_per_episode: 240.30769230769232
avg_sample_per_episode: 240.30769230769232
avg_envstep_per_sec: 2549.9203778564324
avg_train_sample_per_sec: 2549.9203778564324
avg_episode_per_sec: 10.611064312462748
collect_time: 1.225136293324642
reward_mean: 1437.4007616394304
reward_std: 660.6053526324023
reward_max: 3372.8524759236425
reward_min: 852.4952487388439
total_envstep_count: 22899953
total_train_sample_count: 17174094
total_episode_count: 50288
total_duration: 4552.169531418854
[2023-06-29 14:15:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2424
train_sample_count: 2424
avg_envstep_per_episode: 303.0
avg_sample_per_episode: 303.0
avg_envstep_per_sec: 2380.799235131637
avg_train_sample_per_sec: 2380.799235131637
avg_episode_per_sec: 7.857423218256228
collect_time: 1.0181454883851113
reward_mean: 1862.1231733116665
reward_std: 511.42620354715615
reward_max: 2504.055765872731
reward_min: 1090.38579042407
total_envstep_count: 22904545
total_train_sample_count: 17177318
total_episode_count: 50296
total_duration: 4553.187676907239
[2023-06-29 14:15:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2796
train_sample_count: 2796
avg_envstep_per_episode: 279.6
avg_sample_per_episode: 279.6
avg_envstep_per_sec: 2427.1972660489723
avg_train_sample_per_sec: 2427.1972660489723
avg_episode_per_sec: 8.680963040232376
collect_time: 1.1519459250839428
reward_mean: 1953.4122358561658
reward_std: 903.3246242680339
reward_max: 3607.962996346063
reward_min: 1044.8002414049674
total_envstep_count: 22909865
total_train_sample_count: 17180914
total_episode_count: 50306
total_duration: 4554.339622832323
[2023-06-29 14:15:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3141
train_sample_count: 3141
avg_envstep_per_episode: 285.54545454545456
avg_sample_per_episode: 285.54545454545456
avg_envstep_per_sec: 2410.5787219019217
avg_train_sample_per_sec: 2410.5787219019217
avg_episode_per_sec: 8.442013989468684
collect_time: 1.3030066064475105
reward_mean: 1885.6584197775953
reward_std: 601.18280854557
reward_max: 3113.0493940363885
reward_min: 986.0391103184243
total_envstep_count: 22914873
total_train_sample_count: 17184455
total_episode_count: 50317
total_duration: 4555.64262943877
[2023-06-29 14:15:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2284
train_sample_count: 2284
avg_envstep_per_episode: 285.5
avg_sample_per_episode: 285.5
avg_envstep_per_sec: 2486.0086206474884
avg_train_sample_per_sec: 2486.0086206474884
avg_episode_per_sec: 8.707560842898383
collect_time: 0.9187417859416455
reward_mean: 1860.4221465078176
reward_std: 798.8535782883858
reward_max: 3464.225700816389
reward_min: 1165.965230694689
total_envstep_count: 22919377
total_train_sample_count: 17187939
total_episode_count: 50325
total_duration: 4556.561371224712
[2023-06-29 14:15:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3161
train_sample_count: 3161
avg_envstep_per_episode: 287.3636363636364
avg_sample_per_episode: 287.3636363636364
avg_envstep_per_sec: 2407.751574467141
avg_train_sample_per_sec: 2407.751574467141
avg_episode_per_sec: 8.378762201562338
collect_time: 1.312843082949519
reward_mean: 1841.1489089467927
reward_std: 791.4585259183546
reward_max: 3347.8170403872273
reward_min: 928.1025896479686
total_envstep_count: 22923777
total_train_sample_count: 17191500
total_episode_count: 50336
total_duration: 4557.8742143076615
[2023-06-29 14:15:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3270
train_sample_count: 3270
avg_envstep_per_episode: 297.27272727272725
avg_sample_per_episode: 297.27272727272725
avg_envstep_per_sec: 2444.853261887855
avg_train_sample_per_sec: 2444.853261887855
avg_episode_per_sec: 8.22427702775731
collect_time: 1.3375035839471967
reward_mean: 1507.1528754848607
reward_std: 501.7880926463589
reward_max: 2086.878220317142
reward_min: 431.94717310854446
total_envstep_count: 22928025
total_train_sample_count: 17194770
total_episode_count: 50347
total_duration: 4559.211717891609
[2023-06-29 14:15:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2891
train_sample_count: 2891
avg_envstep_per_episode: 262.8181818181818
avg_sample_per_episode: 262.8181818181818
avg_envstep_per_sec: 2415.4579794007086
avg_train_sample_per_sec: 2415.4579794007086
avg_episode_per_sec: 9.190604556695881
collect_time: 1.1968744745943694
reward_mean: 1266.102699048408
reward_std: 417.0223608949194
reward_max: 1861.8832343202864
reward_min: 480.72149931320274
total_envstep_count: 22932569
total_train_sample_count: 17198061
total_episode_count: 50358
total_duration: 4560.408592366203
[2023-06-29 14:15:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3024
train_sample_count: 3024
avg_envstep_per_episode: 274.90909090909093
avg_sample_per_episode: 274.90909090909093
avg_envstep_per_sec: 2515.479772861979
avg_train_sample_per_sec: 2515.479772861979
avg_episode_per_sec: 9.150224041495296
collect_time: 1.2021563570592553
reward_mean: 1579.138481636586
reward_std: 564.995428652994
reward_max: 2623.1880086922242
reward_min: 969.9352494401213
total_envstep_count: 22936905
total_train_sample_count: 17201485
total_episode_count: 50369
total_duration: 4561.610748723262
[2023-06-29 14:15:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3273
train_sample_count: 3273
avg_envstep_per_episode: 272.75
avg_sample_per_episode: 272.75
avg_envstep_per_sec: 2405.910009281526
avg_train_sample_per_sec: 2405.910009281526
avg_episode_per_sec: 8.820934956119252
collect_time: 1.3604000097149984
reward_mean: 1396.3889571172565
reward_std: 679.4280487860816
reward_max: 2842.3225033997787
reward_min: 244.97331385764417
total_envstep_count: 22941545
total_train_sample_count: 17204758
total_episode_count: 50381
total_duration: 4562.971148732977
[2023-06-29 14:15:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2844
train_sample_count: 2844
avg_envstep_per_episode: 284.4
avg_sample_per_episode: 284.4
avg_envstep_per_sec: 2452.8663657712623
avg_train_sample_per_sec: 2452.8663657712623
avg_episode_per_sec: 8.624705927465762
collect_time: 1.1594598220624026
reward_mean: 1554.3859976430947
reward_std: 562.6507938700013
reward_max: 2746.924328920865
reward_min: 701.8194687119031
total_envstep_count: 22946145
total_train_sample_count: 17208002
total_episode_count: 50391
total_duration: 4564.1306085550395
[2023-06-29 14:15:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3274
train_sample_count: 3274
avg_envstep_per_episode: 251.84615384615384
avg_sample_per_episode: 251.84615384615384
avg_envstep_per_sec: 2456.3992514132074
avg_train_sample_per_sec: 2456.3992514132074
avg_episode_per_sec: 9.753570637865515
collect_time: 1.3328452197322618
reward_mean: 1403.8335667551555
reward_std: 599.712391224366
reward_max: 2604.650018666923
reward_min: 260.9942027147017
total_envstep_count: 22951249
total_train_sample_count: 17211276
total_episode_count: 50404
total_duration: 4565.463453774772
[2023-06-29 14:15:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1425
train_sample_count: 1425
avg_envstep_per_episode: 178.125
avg_sample_per_episode: 178.125
avg_envstep_per_sec: 2512.6704998979653
avg_train_sample_per_sec: 2512.6704998979653
avg_episode_per_sec: 14.106220350304365
collect_time: 0.5671256935829296
reward_mean: 1419.885349208455
reward_std: 298.3503513390594
reward_max: 1879.7883219859823
reward_min: 1038.426359277146
total_envstep_count: 22955777
total_train_sample_count: 17214701
total_episode_count: 50412
total_duration: 4566.0305794683545
[2023-06-29 14:15:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2332
train_sample_count: 2332
avg_envstep_per_episode: 233.2
avg_sample_per_episode: 233.2
avg_envstep_per_sec: 2664.9571350781484
avg_train_sample_per_sec: 2664.9571350781484
avg_episode_per_sec: 11.427775021775938
collect_time: 0.8750609791446478
reward_mean: 2042.9500074874297
reward_std: 788.549591731771
reward_max: 3565.167582814583
reward_min: 832.8177033783776
total_envstep_count: 22960553
total_train_sample_count: 17218233
total_episode_count: 50422
total_duration: 4566.9056404474995
[2023-06-29 14:15:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1414
train_sample_count: 1414
avg_envstep_per_episode: 282.8
avg_sample_per_episode: 282.8
avg_envstep_per_sec: 2353.770463539127
avg_train_sample_per_sec: 2353.770463539127
avg_episode_per_sec: 8.323092162443873
collect_time: 0.6007382715959104
reward_mean: 1974.942928056341
reward_std: 181.39762588445097
reward_max: 2195.543757010724
reward_min: 1689.2261975703161
total_envstep_count: 22964857
total_train_sample_count: 17221647
total_episode_count: 50427
total_duration: 4567.506378719096
[2023-06-29 14:15:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1603
train_sample_count: 1603
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 2024.5308975815487
avg_train_sample_per_sec: 2024.5308975815487
avg_episode_per_sec: 8.840746277648684
collect_time: 0.7917883604122326
reward_mean: 2912.606348481607
reward_std: 593.33460095211
reward_max: 3623.1158031573486
reward_min: 1797.201050606947
total_envstep_count: 22968665
total_train_sample_count: 17224850
total_episode_count: 50434
total_duration: 4568.298167079508
[2023-06-29 14:16:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3076
train_sample_count: 3076
avg_envstep_per_episode: 384.5
avg_sample_per_episode: 384.5
avg_envstep_per_sec: 2435.0598802768345
avg_train_sample_per_sec: 2435.0598802768345
avg_episode_per_sec: 6.33305560540139
collect_time: 1.2632132888864724
reward_mean: 2409.752964097801
reward_std: 851.4376784910877
reward_max: 3620.717493834648
reward_min: 1413.5669837632622
total_envstep_count: 22973153
total_train_sample_count: 17228326
total_episode_count: 50442
total_duration: 4569.561380368395
[2023-06-29 14:16:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1817
train_sample_count: 1817
avg_envstep_per_episode: 259.57142857142856
avg_sample_per_episode: 259.57142857142856
avg_envstep_per_sec: 2488.1608621129685
avg_train_sample_per_sec: 2488.1608621129685
avg_episode_per_sec: 9.585649991629488
collect_time: 0.7302582512518854
reward_mean: 1608.0475580343777
reward_std: 808.832498329719
reward_max: 2778.624286921571
reward_min: 24.37887027977065
total_envstep_count: 22977617
total_train_sample_count: 17231743
total_episode_count: 50449
total_duration: 4570.291638619647
[2023-06-29 14:16:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2170
train_sample_count: 2170
avg_envstep_per_episode: 271.25
avg_sample_per_episode: 271.25
avg_envstep_per_sec: 2414.3438252765063
avg_train_sample_per_sec: 2414.3438252765063
avg_episode_per_sec: 8.900806729129977
collect_time: 0.8987949343757936
reward_mean: 2160.198626906152
reward_std: 975.5563882096013
reward_max: 3473.7256535222186
reward_min: 1007.939763133458
total_envstep_count: 22982089
total_train_sample_count: 17235113
total_episode_count: 50457
total_duration: 4571.190433554022
[2023-06-29 14:16:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2258
train_sample_count: 2258
avg_envstep_per_episode: 282.25
avg_sample_per_episode: 282.25
avg_envstep_per_sec: 2217.6831877201166
avg_train_sample_per_sec: 2217.6831877201166
avg_episode_per_sec: 7.857159212471626
collect_time: 1.0181796987518903
reward_mean: 2198.6522604647353
reward_std: 793.8062548903579
reward_max: 3318.21897792144
reward_min: 1265.8895014459563
total_envstep_count: 22986913
total_train_sample_count: 17238571
total_episode_count: 50465
total_duration: 4572.208613252774
[2023-06-29 14:16:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1976
train_sample_count: 1976
avg_envstep_per_episode: 247.0
avg_sample_per_episode: 247.0
avg_envstep_per_sec: 2252.110755804391
avg_train_sample_per_sec: 2252.110755804391
avg_episode_per_sec: 9.117857310948951
collect_time: 0.8773991220934549
reward_mean: 1843.0557451853858
reward_std: 667.5426766550152
reward_max: 3134.290116860824
reward_min: 1192.949954713924
total_envstep_count: 22991497
total_train_sample_count: 17242147
total_episode_count: 50473
total_duration: 4573.086012374867
[2023-06-29 14:16:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 213.125
avg_sample_per_episode: 213.125
avg_envstep_per_sec: 2564.1078198531673
avg_train_sample_per_sec: 2564.1078198531673
avg_episode_per_sec: 12.031004433328643
collect_time: 0.664948637026362
reward_mean: 2158.804078007267
reward_std: 804.4441509703238
reward_max: 3552.8770126803133
reward_min: 1260.38028356315
total_envstep_count: 22995809
total_train_sample_count: 17245452
total_episode_count: 50481
total_duration: 4573.750961011893
[2023-06-29 14:16:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2784
train_sample_count: 2784
avg_envstep_per_episode: 253.0909090909091
avg_sample_per_episode: 253.0909090909091
avg_envstep_per_sec: 2430.6697055676595
avg_train_sample_per_sec: 2430.6697055676595
avg_episode_per_sec: 9.603939210217046
collect_time: 1.1453633513525128
reward_mean: 1810.3655371671657
reward_std: 806.1889030983918
reward_max: 3351.178475791898
reward_min: 563.1428784798799
total_envstep_count: 23000137
total_train_sample_count: 17249036
total_episode_count: 50492
total_duration: 4574.896324363246
[2023-06-29 14:16:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2804
train_sample_count: 2804
avg_envstep_per_episode: 280.4
avg_sample_per_episode: 280.4
avg_envstep_per_sec: 2492.5054354164317
avg_train_sample_per_sec: 2492.5054354164317
avg_episode_per_sec: 8.889106403054322
collect_time: 1.1249724715370684
reward_mean: 1595.2475324111558
reward_std: 782.2883519540559
reward_max: 2943.0809283188187
reward_min: 700.5211430476612
total_envstep_count: 23004625
total_train_sample_count: 17252240
total_episode_count: 50502
total_duration: 4576.021296834783
[2023-06-29 14:16:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2945
train_sample_count: 2945
avg_envstep_per_episode: 245.41666666666666
avg_sample_per_episode: 245.41666666666666
avg_envstep_per_sec: 2481.9184648076593
avg_train_sample_per_sec: 2481.9184648076593
avg_episode_per_sec: 10.113080331983673
collect_time: 1.1865820903299609
reward_mean: 1401.239094889659
reward_std: 494.87606162992904
reward_max: 2440.3734873405006
reward_min: 795.4513065125078
total_envstep_count: 23009265
total_train_sample_count: 17255585
total_episode_count: 50514
total_duration: 4577.207878925114
[2023-06-29 14:16:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3103
train_sample_count: 3103
avg_envstep_per_episode: 258.5833333333333
avg_sample_per_episode: 258.5833333333333
avg_envstep_per_sec: 2406.527870209661
avg_train_sample_per_sec: 2406.527870209661
avg_episode_per_sec: 9.306585382699303
collect_time: 1.289409542441601
reward_mean: 1481.5052306057198
reward_std: 569.4441284017123
reward_max: 2549.785172306998
reward_min: 708.3910147224141
total_envstep_count: 23013665
total_train_sample_count: 17259088
total_episode_count: 50526
total_duration: 4578.497288467555
[2023-06-29 14:16:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2495
train_sample_count: 2495
avg_envstep_per_episode: 311.875
avg_sample_per_episode: 311.875
avg_envstep_per_sec: 2607.3456931626088
avg_train_sample_per_sec: 2607.3456931626088
avg_episode_per_sec: 8.360226671463275
collect_time: 0.9569118535155429
reward_mean: 1503.9292500769961
reward_std: 710.3220440728328
reward_max: 2649.1328902443656
reward_min: 490.25418860990914
total_envstep_count: 23017897
total_train_sample_count: 17262383
total_episode_count: 50534
total_duration: 4579.454200321071
[2023-06-29 14:16:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2934
train_sample_count: 2934
avg_envstep_per_episode: 244.5
avg_sample_per_episode: 244.5
avg_envstep_per_sec: 2420.291625745471
avg_train_sample_per_sec: 2420.291625745471
avg_episode_per_sec: 9.898943254582703
collect_time: 1.2122506101289767
reward_mean: 1573.0088777579765
reward_std: 864.0550010052872
reward_max: 3687.7867464507344
reward_min: 706.8094282094318
total_envstep_count: 23022609
total_train_sample_count: 17265717
total_episode_count: 50546
total_duration: 4580.6664509311995
[2023-06-29 14:16:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3011
train_sample_count: 3011
avg_envstep_per_episode: 200.73333333333332
avg_sample_per_episode: 200.73333333333332
avg_envstep_per_sec: 2380.2740733525898
avg_train_sample_per_sec: 2380.2740733525898
avg_episode_per_sec: 11.857891431514064
collect_time: 1.264980379238026
reward_mean: 1159.7191686563717
reward_std: 572.6630442822736
reward_max: 3163.7956197337003
reward_min: 582.9584746161772
total_envstep_count: 23026849
total_train_sample_count: 17269128
total_episode_count: 50561
total_duration: 4581.931431310438
[2023-06-29 14:16:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2813
train_sample_count: 2813
avg_envstep_per_episode: 281.3
avg_sample_per_episode: 281.3
avg_envstep_per_sec: 2528.2523916438327
avg_train_sample_per_sec: 2528.2523916438327
avg_episode_per_sec: 8.987744015797485
collect_time: 1.1126262588724494
reward_mean: 1486.328858589359
reward_std: 679.6282124895387
reward_max: 3367.1268144055393
reward_min: 863.9702897206419
total_envstep_count: 23030889
total_train_sample_count: 17272341
total_episode_count: 50571
total_duration: 4583.04405756931
[2023-06-29 14:16:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3014
train_sample_count: 3014
avg_envstep_per_episode: 215.28571428571428
avg_sample_per_episode: 215.28571428571428
avg_envstep_per_sec: 2281.998148407114
avg_train_sample_per_sec: 2281.998148407114
avg_episode_per_sec: 10.59985868536815
collect_time: 1.3207723249485717
reward_mean: 1082.1385687635911
reward_std: 262.9430520744431
reward_max: 1767.476040678728
reward_min: 686.6327240074731
total_envstep_count: 23035313
total_train_sample_count: 17275755
total_episode_count: 50585
total_duration: 4584.364829894259
[2023-06-29 14:16:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1992
train_sample_count: 1992
avg_envstep_per_episode: 199.2
avg_sample_per_episode: 199.2
avg_envstep_per_sec: 2408.5744297720316
avg_train_sample_per_sec: 2408.5744297720316
avg_episode_per_sec: 12.091237097249154
collect_time: 0.8270452328054235
reward_mean: 1254.8900746379593
reward_std: 401.1650902006565
reward_max: 2208.2308396926283
reward_min: 835.3991394895594
total_envstep_count: 23040161
total_train_sample_count: 17279347
total_episode_count: 50595
total_duration: 4585.191875127064
[2023-06-29 14:16:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2992
train_sample_count: 2992
avg_envstep_per_episode: 249.33333333333334
avg_sample_per_episode: 249.33333333333334
avg_envstep_per_sec: 2327.2308915198305
avg_train_sample_per_sec: 2327.2308915198305
avg_episode_per_sec: 9.333813736042101
collect_time: 1.285648111196235
reward_mean: 1799.015607440807
reward_std: 679.058299675053
reward_max: 3277.198083042037
reward_min: 975.7061039009983
total_envstep_count: 23044913
total_train_sample_count: 17282739
total_episode_count: 50607
total_duration: 4586.477523238261
[2023-06-29 14:16:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 325.2
avg_sample_per_episode: 325.2
avg_envstep_per_sec: 2525.1156548257413
avg_train_sample_per_sec: 2525.1156548257413
avg_episode_per_sec: 7.764808286672022
collect_time: 0.6439309014985337
reward_mean: 1971.483400706662
reward_std: 599.7473200121757
reward_max: 3103.171651868475
reward_min: 1443.3715038107478
total_envstep_count: 23048625
total_train_sample_count: 17285965
total_episode_count: 50612
total_duration: 4587.121454139759
[2023-06-29 14:16:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 244.14285714285714
avg_sample_per_episode: 244.14285714285714
avg_envstep_per_sec: 2528.943997738149
avg_train_sample_per_sec: 2528.943997738149
avg_episode_per_sec: 10.358459908816291
collect_time: 0.6757761348327622
reward_mean: 2120.6543720086493
reward_std: 729.7125575065347
reward_max: 3292.603326136671
reward_min: 1232.625095825276
total_envstep_count: 23053065
total_train_sample_count: 17289274
total_episode_count: 50619
total_duration: 4587.797230274592
[2023-06-29 14:17:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1971
train_sample_count: 1971
avg_envstep_per_episode: 197.1
avg_sample_per_episode: 197.1
avg_envstep_per_sec: 2242.659007021672
avg_train_sample_per_sec: 2242.659007021672
avg_episode_per_sec: 11.378280096507721
collect_time: 0.8788674487868557
reward_mean: 1888.3057017768976
reward_std: 753.2132864350954
reward_max: 3546.060608613423
reward_min: 1056.6833744981902
total_envstep_count: 23058233
total_train_sample_count: 17292845
total_episode_count: 50629
total_duration: 4588.676097723379
[2023-06-29 14:17:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1780
train_sample_count: 1780
avg_envstep_per_episode: 222.5
avg_sample_per_episode: 222.5
avg_envstep_per_sec: 2250.040775418386
avg_train_sample_per_sec: 2250.040775418386
avg_episode_per_sec: 10.11254281086915
collect_time: 0.7910967745324597
reward_mean: 2189.496922150737
reward_std: 608.206628675234
reward_max: 2939.6040591767746
reward_min: 1201.5870242851634
total_envstep_count: 23062609
total_train_sample_count: 17296225
total_episode_count: 50637
total_duration: 4589.467194497912
[2023-06-29 14:17:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2667
train_sample_count: 2667
avg_envstep_per_episode: 296.3333333333333
avg_sample_per_episode: 296.3333333333333
avg_envstep_per_sec: 2371.8200510797137
avg_train_sample_per_sec: 2371.8200510797137
avg_episode_per_sec: 8.0038921858708
collect_time: 1.1244529275253883
reward_mean: 2218.3810974552816
reward_std: 691.2914025142559
reward_max: 3477.370897514566
reward_min: 1559.8938301303472
total_envstep_count: 23067241
total_train_sample_count: 17299692
total_episode_count: 50646
total_duration: 4590.591647425437
[2023-06-29 14:17:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2515
train_sample_count: 2515
avg_envstep_per_episode: 279.44444444444446
avg_sample_per_episode: 279.44444444444446
avg_envstep_per_sec: 2564.424362121162
avg_train_sample_per_sec: 2564.424362121162
avg_episode_per_sec: 9.176866504608533
collect_time: 0.9807269175682449
reward_mean: 1875.4450477388261
reward_std: 786.9771168204434
reward_max: 3689.595112618183
reward_min: 1079.7904768672056
total_envstep_count: 23071993
total_train_sample_count: 17303007
total_episode_count: 50655
total_duration: 4591.572374343005
[2023-06-29 14:17:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1231
train_sample_count: 1231
avg_envstep_per_episode: 205.16666666666666
avg_sample_per_episode: 205.16666666666666
avg_envstep_per_sec: 2432.0296759236994
avg_train_sample_per_sec: 2432.0296759236994
avg_episode_per_sec: 11.853922059741832
collect_time: 0.5061615868369118
reward_mean: 1620.5105478640444
reward_std: 177.17155602428448
reward_max: 1925.217146937047
reward_min: 1321.5393699467409
total_envstep_count: 23075785
total_train_sample_count: 17306238
total_episode_count: 50661
total_duration: 4592.0785359298425
[2023-06-29 14:17:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1637
train_sample_count: 1637
avg_envstep_per_episode: 163.7
avg_sample_per_episode: 163.7
avg_envstep_per_sec: 2362.7260246733267
avg_train_sample_per_sec: 2362.7260246733267
avg_episode_per_sec: 14.433268324210914
collect_time: 0.6928437672862784
reward_mean: 1834.5949625366698
reward_std: 806.6793248541283
reward_max: 3395.597225951178
reward_min: 988.6798206539237
total_envstep_count: 23080329
total_train_sample_count: 17309475
total_episode_count: 50671
total_duration: 4592.771379697128
[2023-06-29 14:17:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2157
train_sample_count: 2157
avg_envstep_per_episode: 239.66666666666666
avg_sample_per_episode: 239.66666666666666
avg_envstep_per_sec: 2438.0310149158986
avg_train_sample_per_sec: 2438.0310149158986
avg_episode_per_sec: 10.172591160984277
collect_time: 0.884730336408131
reward_mean: 1863.4873034342334
reward_std: 1119.7834819021434
reward_max: 3606.16149041845
reward_min: 25.793837560658517
total_envstep_count: 23084425
total_train_sample_count: 17312832
total_episode_count: 50680
total_duration: 4593.656110033537
[2023-06-29 14:17:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2091
train_sample_count: 2091
avg_envstep_per_episode: 232.33333333333334
avg_sample_per_episode: 232.33333333333334
avg_envstep_per_sec: 2557.389005145665
avg_train_sample_per_sec: 2557.389005145665
avg_episode_per_sec: 11.00741322157388
collect_time: 0.8176307928878813
reward_mean: 1753.5042096301283
reward_std: 735.9727574660224
reward_max: 3574.4538774180637
reward_min: 1057.226052263214
total_envstep_count: 23089033
total_train_sample_count: 17316123
total_episode_count: 50689
total_duration: 4594.473740826425
[2023-06-29 14:17:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1725
train_sample_count: 1725
avg_envstep_per_episode: 215.625
avg_sample_per_episode: 215.625
avg_envstep_per_sec: 2583.109822095405
avg_train_sample_per_sec: 2583.109822095405
avg_episode_per_sec: 11.979639754645357
collect_time: 0.6677997138351203
reward_mean: 1932.9508143749847
reward_std: 995.9204038472683
reward_max: 3564.598641743138
reward_min: 894.8288015896304
total_envstep_count: 23093209
total_train_sample_count: 17319448
total_episode_count: 50697
total_duration: 4595.1415405402595
[2023-06-29 14:17:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2502
train_sample_count: 2502
avg_envstep_per_episode: 278.0
avg_sample_per_episode: 278.0
avg_envstep_per_sec: 2585.810459856087
avg_train_sample_per_sec: 2585.810459856087
avg_episode_per_sec: 9.301476474302472
collect_time: 0.9675883205063871
reward_mean: 1797.7190852156316
reward_std: 1007.4856598738119
reward_max: 3505.5694061654685
reward_min: 349.30087325629347
total_envstep_count: 23097793
total_train_sample_count: 17322750
total_episode_count: 50706
total_duration: 4596.109128860766
[2023-06-29 14:17:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2016
train_sample_count: 2016
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 2366.3913511241894
avg_train_sample_per_sec: 2366.3913511241894
avg_episode_per_sec: 9.390441869540435
collect_time: 0.851930091378279
reward_mean: 1937.1142463233216
reward_std: 960.527919345163
reward_max: 3562.314287673174
reward_min: 992.5065010795653
total_envstep_count: 23101521
total_train_sample_count: 17325966
total_episode_count: 50714
total_duration: 4596.961058952144
[2023-06-29 14:17:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1917
train_sample_count: 1917
avg_envstep_per_episode: 383.4
avg_sample_per_episode: 383.4
avg_envstep_per_sec: 2649.75575924523
avg_train_sample_per_sec: 2649.75575924523
avg_episode_per_sec: 6.911204379878012
collect_time: 0.7234629053305834
reward_mean: 2685.9704944376163
reward_std: 1009.2436597384102
reward_max: 3536.210230766173
reward_min: 1153.6712020128416
total_envstep_count: 23106009
total_train_sample_count: 17329483
total_episode_count: 50719
total_duration: 4597.684521857475
[2023-06-29 14:17:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2252
train_sample_count: 2252
avg_envstep_per_episode: 321.7142857142857
avg_sample_per_episode: 321.7142857142857
avg_envstep_per_sec: 2664.3427836634955
avg_train_sample_per_sec: 2664.3427836634955
avg_episode_per_sec: 8.281704922577473
collect_time: 0.845236586601473
reward_mean: 2473.1467512437644
reward_std: 1226.0717868538961
reward_max: 3636.83505667197
reward_min: 804.1624576048949
total_envstep_count: 23110897
total_train_sample_count: 17332935
total_episode_count: 50726
total_duration: 4598.529758444077
[2023-06-29 14:17:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 161.4
avg_sample_per_episode: 161.4
avg_envstep_per_sec: 2545.5275580887246
avg_train_sample_per_sec: 2545.5275580887246
avg_episode_per_sec: 15.771546208728157
collect_time: 0.31702662084158506
reward_mean: 1583.0043968686196
reward_std: 981.9589960129139
reward_max: 3523.8903134965935
reward_min: 884.7869070056282
total_envstep_count: 23114449
total_train_sample_count: 17336142
total_episode_count: 50731
total_duration: 4598.846785064919
[2023-06-29 14:17:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2480
train_sample_count: 2480
avg_envstep_per_episode: 248.0
avg_sample_per_episode: 248.0
avg_envstep_per_sec: 2603.849148924677
avg_train_sample_per_sec: 2603.849148924677
avg_episode_per_sec: 10.499391729534988
collect_time: 0.9524361275015399
reward_mean: 2318.487707473889
reward_std: 1320.8749695634074
reward_max: 3497.6013814560374
reward_min: 441.11245666579185
total_envstep_count: 23119089
total_train_sample_count: 17339422
total_episode_count: 50741
total_duration: 4599.79922119242
[2023-06-29 14:17:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1734
train_sample_count: 1734
avg_envstep_per_episode: 173.4
avg_sample_per_episode: 173.4
avg_envstep_per_sec: 2628.3266086946196
avg_train_sample_per_sec: 2628.3266086946196
avg_episode_per_sec: 15.157592899046248
collect_time: 0.6597353594731538
reward_mean: 1418.5448917022923
reward_std: 976.1627440928524
reward_max: 3475.017115989375
reward_min: 23.76187674895263
total_envstep_count: 23123249
total_train_sample_count: 17342756
total_episode_count: 50751
total_duration: 4600.458956551894
[2023-06-29 14:17:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 236.44444444444446
avg_sample_per_episode: 236.44444444444446
avg_envstep_per_sec: 2636.2270972602387
avg_train_sample_per_sec: 2636.2270972602387
avg_episode_per_sec: 11.149456708337475
collect_time: 0.8072142199780794
reward_mean: 1745.0248709929783
reward_std: 954.0172308287158
reward_max: 3487.0536662942777
reward_min: 798.6391431466584
total_envstep_count: 23127801
total_train_sample_count: 17346084
total_episode_count: 50760
total_duration: 4601.266170771872
[2023-06-29 14:17:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1775
train_sample_count: 1775
avg_envstep_per_episode: 253.57142857142858
avg_sample_per_episode: 253.57142857142858
avg_envstep_per_sec: 2415.581475561868
avg_train_sample_per_sec: 2415.581475561868
avg_episode_per_sec: 9.526236805032719
collect_time: 0.7348127223020421
reward_mean: 2166.796125789155
reward_std: 1183.8423997427035
reward_max: 3501.3050087456722
reward_min: 501.2015968199141
total_envstep_count: 23132713
total_train_sample_count: 17349459
total_episode_count: 50767
total_duration: 4602.000983494174
[2023-06-29 14:17:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1740
train_sample_count: 1740
avg_envstep_per_episode: 348.0
avg_sample_per_episode: 348.0
avg_envstep_per_sec: 2342.547399998981
avg_train_sample_per_sec: 2342.547399998981
avg_episode_per_sec: 6.731458045974083
collect_time: 0.7427811279296875
reward_mean: 2608.4983980294046
reward_std: 1078.7888178858477
reward_max: 3493.8549092455855
reward_min: 984.9544650313476
total_envstep_count: 23137369
total_train_sample_count: 17352799
total_episode_count: 50772
total_duration: 4602.743764622103
[2023-06-29 14:18:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1628
train_sample_count: 1628
avg_envstep_per_episode: 162.8
avg_sample_per_episode: 162.8
avg_envstep_per_sec: 2533.2630216902603
avg_train_sample_per_sec: 2533.2630216902603
avg_episode_per_sec: 15.560583671316095
collect_time: 0.6426494154222309
reward_mean: 1930.0572520657138
reward_std: 1247.2600306496083
reward_max: 3482.2190959963295
reward_min: 634.2833376428389
total_envstep_count: 23142017
total_train_sample_count: 17356027
total_episode_count: 50782
total_duration: 4603.386414037525
[2023-06-29 14:18:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2176
train_sample_count: 2176
avg_envstep_per_episode: 362.6666666666667
avg_sample_per_episode: 362.6666666666667
avg_envstep_per_sec: 2788.8560653231752
avg_train_sample_per_sec: 2788.8560653231752
avg_episode_per_sec: 7.6898604742366965
collect_time: 0.7802482268828898
reward_mean: 2803.0774352068197
reward_std: 964.7816429813294
reward_max: 3507.523954315715
reward_min: 1275.3661784133606
total_envstep_count: 23146993
total_train_sample_count: 17359403
total_episode_count: 50788
total_duration: 4604.166662264408
[2023-06-29 14:18:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2806
train_sample_count: 2806
avg_envstep_per_episode: 187.06666666666666
avg_sample_per_episode: 187.06666666666666
avg_envstep_per_sec: 2499.069395834641
avg_train_sample_per_sec: 2499.069395834641
avg_episode_per_sec: 13.359244810235074
collect_time: 1.1228179596280679
reward_mean: 1406.5395958867673
reward_std: 1057.3836019940031
reward_max: 3478.1125008151103
reward_min: 436.5707973592534
total_envstep_count: 23151049
total_train_sample_count: 17362609
total_episode_count: 50803
total_duration: 4605.289480224036
[2023-06-29 14:18:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2445
train_sample_count: 2445
avg_envstep_per_episode: 203.75
avg_sample_per_episode: 203.75
avg_envstep_per_sec: 2543.166326719886
avg_train_sample_per_sec: 2543.166326719886
avg_episode_per_sec: 12.481797922551587
collect_time: 0.9613999581197277
reward_mean: 1159.6251628159819
reward_std: 705.221033880285
reward_max: 3439.378037340804
reward_min: 675.7411399914773
total_envstep_count: 23154993
total_train_sample_count: 17365854
total_episode_count: 50815
total_duration: 4606.250880182156
[2023-06-29 14:18:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3116
train_sample_count: 3116
avg_envstep_per_episode: 207.73333333333332
avg_sample_per_episode: 207.73333333333332
avg_envstep_per_sec: 2670.9890058640653
avg_train_sample_per_sec: 2670.9890058640653
avg_episode_per_sec: 12.857777627715334
collect_time: 1.1666090699583294
reward_mean: 970.6244716788788
reward_std: 693.7920904897214
reward_max: 3422.937522587897
reward_min: 594.6167268637312
total_envstep_count: 23159633
total_train_sample_count: 17369370
total_episode_count: 50830
total_duration: 4607.417489252114
[2023-06-29 14:18:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2580
train_sample_count: 2580
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 2654.128457044875
avg_train_sample_per_sec: 2654.128457044875
avg_episode_per_sec: 15.430979401423691
collect_time: 0.972070508928038
reward_mean: 976.0066281713732
reward_std: 691.6893628898858
reward_max: 3456.871236742644
reward_min: 525.3461999585169
total_envstep_count: 23164457
total_train_sample_count: 17372750
total_episode_count: 50845
total_duration: 4608.389559761043
[2023-06-29 14:18:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2319
train_sample_count: 2319
avg_envstep_per_episode: 210.8181818181818
avg_sample_per_episode: 210.8181818181818
avg_envstep_per_sec: 2410.4031349277802
avg_train_sample_per_sec: 2410.4031349277802
avg_episode_per_sec: 11.43356381380146
collect_time: 0.9620797311440109
reward_mean: 1337.0769411615731
reward_std: 1025.9665842001637
reward_max: 3457.2654508165215
reward_min: 559.4807617929047
total_envstep_count: 23169281
total_train_sample_count: 17376269
total_episode_count: 50856
total_duration: 4609.351639492186
[2023-06-29 14:18:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2892
train_sample_count: 2892
avg_envstep_per_episode: 222.46153846153845
avg_sample_per_episode: 222.46153846153845
avg_envstep_per_sec: 2493.030228694506
avg_train_sample_per_sec: 2493.030228694506
avg_episode_per_sec: 11.206567418059674
collect_time: 1.1600340688666329
reward_mean: 1575.6932324115473
reward_std: 910.3980602663664
reward_max: 3475.929643691442
reward_min: 686.5105203958528
total_envstep_count: 23173473
total_train_sample_count: 17379561
total_episode_count: 50869
total_duration: 4610.511673561053
[2023-06-29 14:18:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2955
train_sample_count: 2955
avg_envstep_per_episode: 246.25
avg_sample_per_episode: 246.25
avg_envstep_per_sec: 2602.0812412321916
avg_train_sample_per_sec: 2602.0812412321916
avg_episode_per_sec: 10.5668273755622
collect_time: 1.1356294158597011
reward_mean: 1330.4609055994388
reward_std: 815.6918382240292
reward_max: 3406.7616021232143
reward_min: 661.9106878606932
total_envstep_count: 23177337
total_train_sample_count: 17382916
total_episode_count: 50881
total_duration: 4611.647302976912
[2023-06-29 14:18:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 282.9
avg_sample_per_episode: 282.9
avg_envstep_per_sec: 2544.2272434418414
avg_train_sample_per_sec: 2544.2272434418414
avg_episode_per_sec: 8.993380146489367
collect_time: 1.111928978550248
reward_mean: 1346.260571908963
reward_std: 755.2817292327691
reward_max: 3357.0166301863
reward_min: 693.3975721713538
total_envstep_count: 23181273
total_train_sample_count: 17386145
total_episode_count: 50891
total_duration: 4612.759231955462
[2023-06-29 14:18:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3372
train_sample_count: 3372
avg_envstep_per_episode: 198.35294117647058
avg_sample_per_episode: 198.35294117647058
avg_envstep_per_sec: 2516.356245927975
avg_train_sample_per_sec: 2516.356245927975
avg_episode_per_sec: 12.686256281368795
collect_time: 1.3400328373443335
reward_mean: 924.0983110110238
reward_std: 427.0401249583612
reward_max: 1955.8542387048683
reward_min: 23.878330094088458
total_envstep_count: 23185801
total_train_sample_count: 17389517
total_episode_count: 50908
total_duration: 4614.099264792807
[2023-06-29 14:18:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1787
train_sample_count: 1787
avg_envstep_per_episode: 198.55555555555554
avg_sample_per_episode: 198.55555555555554
avg_envstep_per_sec: 2736.7904844929567
avg_train_sample_per_sec: 2736.7904844929567
avg_episode_per_sec: 13.783499921900733
collect_time: 0.6529546233536676
reward_mean: 1053.8799587886613
reward_std: 335.7552168421309
reward_max: 1803.4993996155652
reward_min: 645.3182085862128
total_envstep_count: 23189777
total_train_sample_count: 17392904
total_episode_count: 50917
total_duration: 4614.75221941616
[2023-06-29 14:18:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2935
train_sample_count: 2935
avg_envstep_per_episode: 225.76923076923077
avg_sample_per_episode: 225.76923076923077
avg_envstep_per_sec: 2758.3421512566615
avg_train_sample_per_sec: 2758.3421512566615
avg_episode_per_sec: 12.217529119705826
collect_time: 1.0640449367975817
reward_mean: 1459.1326617496873
reward_std: 961.6942801348351
reward_max: 3436.1994667908793
reward_min: 219.69182852185224
total_envstep_count: 23194641
total_train_sample_count: 17396239
total_episode_count: 50930
total_duration: 4615.816264352958
[2023-06-29 14:18:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 181.83333333333334
avg_sample_per_episode: 181.83333333333334
avg_envstep_per_sec: 2658.8610922265207
avg_train_sample_per_sec: 2658.8610922265207
avg_episode_per_sec: 14.622517464123852
collect_time: 0.41032606148161
reward_mean: 1402.3800764050702
reward_std: 647.0566260405886
reward_max: 2745.579941889106
reward_min: 827.9165134189511
total_envstep_count: 23199017
total_train_sample_count: 17399730
total_episode_count: 50936
total_duration: 4616.22659041444
[2023-06-29 14:18:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 237.22222222222223
avg_sample_per_episode: 237.22222222222223
avg_envstep_per_sec: 2605.721075299375
avg_train_sample_per_sec: 2605.721075299375
avg_episode_per_sec: 10.98430429868589
collect_time: 0.8193509352318942
reward_mean: 2141.360963921046
reward_std: 1171.6417812595369
reward_max: 3461.0884078603603
reward_min: 682.6347560195462
total_envstep_count: 23203201
total_train_sample_count: 17403065
total_episode_count: 50945
total_duration: 4617.045941349672
[2023-06-29 14:18:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1306
train_sample_count: 1306
avg_envstep_per_episode: 217.66666666666666
avg_sample_per_episode: 217.66666666666666
avg_envstep_per_sec: 2697.056249143006
avg_train_sample_per_sec: 2697.056249143006
avg_episode_per_sec: 12.390763778604928
collect_time: 0.4842316508656368
reward_mean: 1968.4230851462992
reward_std: 1041.8657325672234
reward_max: 3461.8146421285173
reward_min: 976.401692635956
total_envstep_count: 23207057
total_train_sample_count: 17406371
total_episode_count: 50951
total_duration: 4617.530173000538
[2023-06-29 14:18:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2330
train_sample_count: 2330
avg_envstep_per_episode: 258.8888888888889
avg_sample_per_episode: 258.8888888888889
avg_envstep_per_sec: 2677.026205218223
avg_train_sample_per_sec: 2677.026205218223
avg_episode_per_sec: 10.34044456951245
collect_time: 0.87036876794789
reward_mean: 1873.9539042602826
reward_std: 1293.1952661732628
reward_max: 3529.2590489683357
reward_min: 104.70206884862878
total_envstep_count: 23211345
total_train_sample_count: 17409901
total_episode_count: 50960
total_duration: 4618.400541768486
[2023-06-29 14:18:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2055
train_sample_count: 2055
avg_envstep_per_episode: 228.33333333333334
avg_sample_per_episode: 228.33333333333334
avg_envstep_per_sec: 2400.4506855016043
avg_train_sample_per_sec: 2400.4506855016043
avg_episode_per_sec: 10.512922710226004
collect_time: 0.856089238746674
reward_mean: 1755.7364621918275
reward_std: 1218.3111509236262
reward_max: 3491.4381653484543
reward_min: 831.1467184873298
total_envstep_count: 23215969
total_train_sample_count: 17413156
total_episode_count: 50969
total_duration: 4619.2566310072325
[2023-06-29 14:18:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2122
train_sample_count: 2122
avg_envstep_per_episode: 303.14285714285717
avg_sample_per_episode: 303.14285714285717
avg_envstep_per_sec: 2485.3744449711035
avg_train_sample_per_sec: 2485.3744449711035
avg_episode_per_sec: 8.198690440526732
collect_time: 0.8537948896568266
reward_mean: 2246.7672928981146
reward_std: 879.6216817180249
reward_max: 3402.819832428999
reward_min: 1051.1797364844645
total_envstep_count: 23220585
total_train_sample_count: 17416478
total_episode_count: 50976
total_duration: 4620.110425896889
[2023-06-29 14:19:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1280
train_sample_count: 1280
avg_envstep_per_episode: 182.85714285714286
avg_sample_per_episode: 182.85714285714286
avg_envstep_per_sec: 2639.9260614040436
avg_train_sample_per_sec: 2639.9260614040436
avg_episode_per_sec: 14.437095648303362
collect_time: 0.4848620644016191
reward_mean: 1769.8343410574557
reward_std: 1266.821128061485
reward_max: 3629.3263599591965
reward_min: 32.011658056756524
total_envstep_count: 23225089
total_train_sample_count: 17419758
total_episode_count: 50983
total_duration: 4620.5952879612905
[2023-06-29 14:19:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2328
train_sample_count: 2328
avg_envstep_per_episode: 258.6666666666667
avg_sample_per_episode: 258.6666666666667
avg_envstep_per_sec: 2387.4537467437553
avg_train_sample_per_sec: 2387.4537467437553
avg_episode_per_sec: 9.229846959060911
collect_time: 0.9750974246831612
reward_mean: 2271.8051149400635
reward_std: 1220.1182582261515
reward_max: 3614.387108041586
reward_min: 601.6205375651735
total_envstep_count: 23229753
total_train_sample_count: 17423286
total_episode_count: 50992
total_duration: 4621.570385385974
[2023-06-29 14:19:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 852
train_sample_count: 852
avg_envstep_per_episode: 170.4
avg_sample_per_episode: 170.4
avg_envstep_per_sec: 2619.9805110825464
avg_train_sample_per_sec: 2619.9805110825464
avg_episode_per_sec: 15.375472482878793
collect_time: 0.3251932586506009
reward_mean: 2280.8692887518037
reward_std: 1007.4526557383477
reward_max: 3542.8263545531327
reward_min: 1045.0360679289615
total_envstep_count: 23233961
total_train_sample_count: 17426538
total_episode_count: 50997
total_duration: 4621.895578644625
[2023-06-29 14:19:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1638
train_sample_count: 1638
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 2446.65517955698
avg_train_sample_per_sec: 2446.65517955698
avg_episode_per_sec: 8.962106884824102
collect_time: 0.669485432065092
reward_mean: 2491.0798135442506
reward_std: 1464.8383259628974
reward_max: 3577.3397452485797
reward_min: 236.01725620036402
total_envstep_count: 23238105
total_train_sample_count: 17429776
total_episode_count: 51003
total_duration: 4622.56506407669
[2023-06-29 14:19:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 264.90909090909093
avg_sample_per_episode: 264.90909090909093
avg_envstep_per_sec: 2454.688171658668
avg_train_sample_per_sec: 2454.688171658668
avg_episode_per_sec: 9.266153015870058
collect_time: 1.187116161492304
reward_mean: 2119.41433118983
reward_std: 1094.5118560108672
reward_max: 3513.947338367319
reward_min: 981.9429488722712
total_envstep_count: 23242649
total_train_sample_count: 17433090
total_episode_count: 51014
total_duration: 4623.7521802381825
[2023-06-29 14:19:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2648
train_sample_count: 2648
avg_envstep_per_episode: 264.8
avg_sample_per_episode: 264.8
avg_envstep_per_sec: 2535.659449092943
avg_train_sample_per_sec: 2535.659449092943
avg_episode_per_sec: 9.575753206544347
collect_time: 1.0443042739620432
reward_mean: 1500.4300724799307
reward_std: 788.6958688873965
reward_max: 3593.041413025797
reward_min: 798.4485030719087
total_envstep_count: 23247497
total_train_sample_count: 17436538
total_episode_count: 51024
total_duration: 4624.796484512144
[2023-06-29 14:19:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2434
train_sample_count: 2434
avg_envstep_per_episode: 221.27272727272728
avg_sample_per_episode: 221.27272727272728
avg_envstep_per_sec: 2715.595031307671
avg_train_sample_per_sec: 2715.595031307671
avg_episode_per_sec: 12.272615178465234
collect_time: 0.896304482788779
reward_mean: 1451.906058673283
reward_std: 986.3380790428766
reward_max: 3379.7811071654737
reward_min: 229.0355206190278
total_envstep_count: 23252409
total_train_sample_count: 17439772
total_episode_count: 51035
total_duration: 4625.692788994933
[2023-06-29 14:19:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 228.11111111111111
avg_sample_per_episode: 228.11111111111111
avg_envstep_per_sec: 2477.002664099891
avg_train_sample_per_sec: 2477.002664099891
avg_episode_per_sec: 10.858754981441313
collect_time: 0.8288243003347888
reward_mean: 1905.5308457202466
reward_std: 890.3141230130036
reward_max: 3475.079853365661
reward_min: 836.1549821324618
total_envstep_count: 23256945
total_train_sample_count: 17443025
total_episode_count: 51044
total_duration: 4626.521613295267
[2023-06-29 14:19:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 226.44444444444446
avg_sample_per_episode: 226.44444444444446
avg_envstep_per_sec: 2479.344228235168
avg_train_sample_per_sec: 2479.344228235168
avg_episode_per_sec: 10.949017690930575
collect_time: 0.8219915479226041
reward_mean: 1833.5815984134929
reward_std: 1106.8051192245812
reward_max: 3513.3634596300712
reward_min: 22.617272811497685
total_envstep_count: 23260809
total_train_sample_count: 17446263
total_episode_count: 51053
total_duration: 4627.3436048431895
[2023-06-29 14:19:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2622
train_sample_count: 2622
avg_envstep_per_episode: 262.2
avg_sample_per_episode: 262.2
avg_envstep_per_sec: 2466.834611659682
avg_train_sample_per_sec: 2466.834611659682
avg_episode_per_sec: 9.408217435773006
collect_time: 1.0629006045265121
reward_mean: 1597.1787199866928
reward_std: 909.6638705233366
reward_max: 3372.646830594927
reward_min: 798.0696041954182
total_envstep_count: 23265809
total_train_sample_count: 17449685
total_episode_count: 51063
total_duration: 4628.406505447716
[2023-06-29 14:19:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 228.85714285714286
avg_sample_per_episode: 228.85714285714286
avg_envstep_per_sec: 2627.7477478530604
avg_train_sample_per_sec: 2627.7477478530604
avg_episode_per_sec: 11.482043842054571
collect_time: 1.2192951178885998
reward_mean: 1464.4032243869317
reward_std: 844.7827368256825
reward_max: 3525.2796933639156
reward_min: 527.3768586559916
total_envstep_count: 23270161
total_train_sample_count: 17452889
total_episode_count: 51077
total_duration: 4629.625800565605
[2023-06-29 14:19:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2523
train_sample_count: 2523
avg_envstep_per_episode: 252.3
avg_sample_per_episode: 252.3
avg_envstep_per_sec: 2713.616453662288
avg_train_sample_per_sec: 2713.616453662288
avg_episode_per_sec: 10.75551507595041
collect_time: 0.9297555653434246
reward_mean: 1162.6081795934574
reward_std: 419.80688204727636
reward_max: 1951.9665954538648
reward_min: 204.1128921365308
total_envstep_count: 23274729
total_train_sample_count: 17456212
total_episode_count: 51087
total_duration: 4630.555556130948
[2023-06-29 14:19:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2847
train_sample_count: 2847
avg_envstep_per_episode: 189.8
avg_sample_per_episode: 189.8
avg_envstep_per_sec: 2420.8816441502313
avg_train_sample_per_sec: 2420.8816441502313
avg_episode_per_sec: 12.754908557166655
collect_time: 1.17601783915353
reward_mean: 1254.5745585080206
reward_std: 756.3117012057784
reward_max: 3573.2245409296934
reward_min: 356.13784456188637
total_envstep_count: 23279393
total_train_sample_count: 17459459
total_episode_count: 51102
total_duration: 4631.731573970102
[2023-06-29 14:19:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 215.46153846153845
avg_sample_per_episode: 215.46153846153845
avg_envstep_per_sec: 2429.5400583279047
avg_train_sample_per_sec: 2429.5400583279047
avg_episode_per_sec: 11.275980277851753
collect_time: 1.152893112586811
reward_mean: 1284.6626633443414
reward_std: 471.695961648148
reward_max: 2577.7870504968737
reward_min: 856.1632913340525
total_envstep_count: 23283681
total_train_sample_count: 17462660
total_episode_count: 51115
total_duration: 4632.884467082688
[2023-06-29 14:19:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3464
train_sample_count: 3464
avg_envstep_per_episode: 203.76470588235293
avg_sample_per_episode: 203.76470588235293
avg_envstep_per_sec: 2696.2989862685504
avg_train_sample_per_sec: 2696.2989862685504
avg_episode_per_sec: 13.232414193581224
collect_time: 1.2847239930145442
reward_mean: 1048.345549104908
reward_std: 357.6952438017511
reward_max: 1737.4450860162453
reward_min: 24.07852396782076
total_envstep_count: 23287905
total_train_sample_count: 17466124
total_episode_count: 51132
total_duration: 4634.169191075703
[2023-06-29 14:19:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1581
train_sample_count: 1581
avg_envstep_per_episode: 225.85714285714286
avg_sample_per_episode: 225.85714285714286
avg_envstep_per_sec: 2774.8709057732576
avg_train_sample_per_sec: 2774.8709057732576
avg_episode_per_sec: 12.28595593954004
collect_time: 0.5697562350416556
reward_mean: 966.4248393905033
reward_std: 247.72936921644586
reward_max: 1223.4289012362715
reward_min: 531.6656499335483
total_envstep_count: 23292697
total_train_sample_count: 17469705
total_episode_count: 51139
total_duration: 4634.738947310744
[2023-06-29 14:19:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2569
train_sample_count: 2569
avg_envstep_per_episode: 214.08333333333334
avg_sample_per_episode: 214.08333333333334
avg_envstep_per_sec: 2552.7979623271635
avg_train_sample_per_sec: 2552.7979623271635
avg_episode_per_sec: 11.92431901437367
collect_time: 1.006346776326187
reward_mean: 1789.478077074002
reward_std: 1141.9305793334336
reward_max: 3499.854468938314
reward_min: 212.95500991297936
total_envstep_count: 23297441
total_train_sample_count: 17473074
total_episode_count: 51151
total_duration: 4635.745294087071
[2023-06-29 14:19:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1870
train_sample_count: 1870
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 2469.0173297822344
avg_train_sample_per_sec: 2469.0173297822344
avg_episode_per_sec: 13.203301228782001
collect_time: 0.7573863404858858
reward_mean: 1358.0369320673667
reward_std: 757.4706445725601
reward_max: 3502.5983043092824
reward_min: 738.7112371458635
total_envstep_count: 23301753
total_train_sample_count: 17476544
total_episode_count: 51161
total_duration: 4636.502680427557
[2023-06-29 14:19:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2411
train_sample_count: 2411
avg_envstep_per_episode: 301.375
avg_sample_per_episode: 301.375
avg_envstep_per_sec: 2556.9087112936786
avg_train_sample_per_sec: 2556.9087112936786
avg_episode_per_sec: 8.484143380485039
collect_time: 0.9429355022925885
reward_mean: 2048.1498223027993
reward_std: 919.2696885888226
reward_max: 3529.157974133501
reward_min: 952.4818718593502
total_envstep_count: 23305865
total_train_sample_count: 17479755
total_episode_count: 51169
total_duration: 4637.44561592985
[2023-06-29 14:20:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2075
train_sample_count: 2075
avg_envstep_per_episode: 230.55555555555554
avg_sample_per_episode: 230.55555555555554
avg_envstep_per_sec: 2767.7124010765656
avg_train_sample_per_sec: 2767.7124010765656
avg_episode_per_sec: 12.004535715512814
collect_time: 0.7497166248895228
reward_mean: 1616.1305747057422
reward_std: 1125.5149386016187
reward_max: 3493.6541547649936
reward_min: 271.97926520718096
total_envstep_count: 23310617
total_train_sample_count: 17483030
total_episode_count: 51178
total_duration: 4638.195332554739
[2023-06-29 14:20:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2270
train_sample_count: 2270
avg_envstep_per_episode: 206.36363636363637
avg_sample_per_episode: 206.36363636363637
avg_envstep_per_sec: 2520.648511977745
avg_train_sample_per_sec: 2520.648511977745
avg_episode_per_sec: 12.214596313548544
collect_time: 0.9005618947716428
reward_mean: 1425.492619295312
reward_std: 1052.3860997197824
reward_max: 3530.166986467435
reward_min: 25.351124650756653
total_envstep_count: 23315369
total_train_sample_count: 17486500
total_episode_count: 51189
total_duration: 4639.0958944495105
[2023-06-29 14:20:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 254.5
avg_sample_per_episode: 254.5
avg_envstep_per_sec: 2530.5997467529587
avg_train_sample_per_sec: 2530.5997467529587
avg_episode_per_sec: 9.943417472506715
collect_time: 0.8045523606063798
reward_mean: 1978.6437693923851
reward_std: 1147.0722905110536
reward_max: 3466.285960287818
reward_min: 306.21296497793224
total_envstep_count: 23319321
total_train_sample_count: 17489736
total_episode_count: 51197
total_duration: 4639.900446810117
[2023-06-29 14:20:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2059
train_sample_count: 2059
avg_envstep_per_episode: 205.9
avg_sample_per_episode: 205.9
avg_envstep_per_sec: 2621.666044012829
avg_train_sample_per_sec: 2621.666044012829
avg_episode_per_sec: 12.732715123908834
collect_time: 0.7853784446353094
reward_mean: 1551.5415243966872
reward_std: 1010.1722707055974
reward_max: 3471.2292759876923
reward_min: 659.6710366374208
total_envstep_count: 23323985
total_train_sample_count: 17492995
total_episode_count: 51207
total_duration: 4640.685825254752
[2023-06-29 14:20:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2020
train_sample_count: 2020
avg_envstep_per_episode: 183.63636363636363
avg_sample_per_episode: 183.63636363636363
avg_envstep_per_sec: 2623.7134608920146
avg_train_sample_per_sec: 2623.7134608920146
avg_episode_per_sec: 14.28754854941196
collect_time: 0.769901145879412
reward_mean: 1558.0024574932156
reward_std: 947.6460730173521
reward_max: 3467.7262272086223
reward_min: 239.84066878846997
total_envstep_count: 23328265
total_train_sample_count: 17496215
total_episode_count: 51218
total_duration: 4641.455726400631
[2023-06-29 14:20:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2104
train_sample_count: 2104
avg_envstep_per_episode: 300.57142857142856
avg_sample_per_episode: 300.57142857142856
avg_envstep_per_sec: 2549.1016439825735
avg_train_sample_per_sec: 2549.1016439825735
avg_episode_per_sec: 8.480851477128333
collect_time: 0.8253888207897542
reward_mean: 2079.5530511483503
reward_std: 751.2795748476163
reward_max: 3454.723163289025
reward_min: 1255.67425225249
total_envstep_count: 23332745
total_train_sample_count: 17499519
total_episode_count: 51225
total_duration: 4642.281115221421
[2023-06-29 14:20:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2095
train_sample_count: 2095
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 2391.115640169068
avg_train_sample_per_sec: 2391.115640169068
avg_episode_per_sec: 11.413439809876218
collect_time: 0.8761600504824892
reward_mean: 1525.467393927892
reward_std: 1083.6764952130682
reward_max: 3464.8296147223123
reward_min: 297.7936754115554
total_envstep_count: 23337113
total_train_sample_count: 17502814
total_episode_count: 51235
total_duration: 4643.157275271903
[2023-06-29 14:20:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1316
train_sample_count: 1316
avg_envstep_per_episode: 263.2
avg_sample_per_episode: 263.2
avg_envstep_per_sec: 2676.3350778114514
avg_train_sample_per_sec: 2676.3350778114514
avg_episode_per_sec: 10.168446344268432
collect_time: 0.49171720346622183
reward_mean: 2034.0006237839611
reward_std: 1195.7185576172578
reward_max: 3518.9306687437916
reward_min: 959.2858531557177
total_envstep_count: 23341537
total_train_sample_count: 17506130
total_episode_count: 51240
total_duration: 4643.64899247537
[2023-06-29 14:20:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2455
train_sample_count: 2455
avg_envstep_per_episode: 245.5
avg_sample_per_episode: 245.5
avg_envstep_per_sec: 2711.1827254019468
avg_train_sample_per_sec: 2711.1827254019468
avg_episode_per_sec: 11.043514156423408
collect_time: 0.9055088677713649
reward_mean: 2130.5709277667793
reward_std: 1235.450253103611
reward_max: 3531.6583208740703
reward_min: 229.18658449138837
total_envstep_count: 23346145
total_train_sample_count: 17509385
total_episode_count: 51250
total_duration: 4644.554501343141
[2023-06-29 14:20:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 328.8
avg_sample_per_episode: 328.8
avg_envstep_per_sec: 2469.9603664466144
avg_train_sample_per_sec: 2469.9603664466144
avg_episode_per_sec: 7.512044910117441
collect_time: 0.6655977246975526
reward_mean: 2332.9258377416095
reward_std: 871.4887692082848
reward_max: 3462.347848140843
reward_min: 941.5945291259626
total_envstep_count: 23351097
total_train_sample_count: 17512629
total_episode_count: 51255
total_duration: 4645.220099067838
[2023-06-29 14:20:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1203
train_sample_count: 1203
avg_envstep_per_episode: 171.85714285714286
avg_sample_per_episode: 171.85714285714286
avg_envstep_per_sec: 2490.148866111422
avg_train_sample_per_sec: 2490.148866111422
avg_episode_per_sec: 14.489644274962556
collect_time: 0.4831036474853755
reward_mean: 2523.9331000875686
reward_std: 1097.0454930372118
reward_max: 3512.8363773621318
reward_min: 934.1143424125178
total_envstep_count: 23355353
total_train_sample_count: 17515832
total_episode_count: 51262
total_duration: 4645.703202715324
[2023-06-29 14:20:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 253.625
avg_sample_per_episode: 253.625
avg_envstep_per_sec: 2521.4103672224037
avg_train_sample_per_sec: 2521.4103672224037
avg_episode_per_sec: 9.941489865835006
collect_time: 0.804708359407261
reward_mean: 1725.613229933355
reward_std: 1141.1431330371788
reward_max: 3519.661425218757
reward_min: 241.72435323085216
total_envstep_count: 23359145
total_train_sample_count: 17519061
total_episode_count: 51270
total_duration: 4646.507911074731
[2023-06-29 14:20:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1785
train_sample_count: 1785
avg_envstep_per_episode: 198.33333333333334
avg_sample_per_episode: 198.33333333333334
avg_envstep_per_sec: 2383.9690216225304
avg_train_sample_per_sec: 2383.9690216225304
avg_episode_per_sec: 12.020011873727043
collect_time: 0.7487513402272016
reward_mean: 1905.0634147066423
reward_std: 1143.3103125188513
reward_max: 3523.9476222889934
reward_min: 820.901898192539
total_envstep_count: 23363353
total_train_sample_count: 17522446
total_episode_count: 51279
total_duration: 4647.256662414959
[2023-06-29 14:20:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2537
train_sample_count: 2537
avg_envstep_per_episode: 281.8888888888889
avg_sample_per_episode: 281.8888888888889
avg_envstep_per_sec: 2758.162852516559
avg_train_sample_per_sec: 2758.162852516559
avg_episode_per_sec: 9.784574565490354
collect_time: 0.9198151580082485
reward_mean: 1807.1788412763135
reward_std: 1042.7806267061198
reward_max: 3473.014262196855
reward_min: 330.66636874624595
total_envstep_count: 23367921
total_train_sample_count: 17525783
total_episode_count: 51288
total_duration: 4648.176477572967
[2023-06-29 14:20:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2289
train_sample_count: 2289
avg_envstep_per_episode: 208.0909090909091
avg_sample_per_episode: 208.0909090909091
avg_envstep_per_sec: 2737.3949583011813
avg_train_sample_per_sec: 2737.3949583011813
avg_episode_per_sec: 13.154803207214064
collect_time: 0.8361964695882053
reward_mean: 1456.1474929497747
reward_std: 1041.0424646316055
reward_max: 3570.530518679864
reward_min: 301.991600693645
total_envstep_count: 23372841
total_train_sample_count: 17529272
total_episode_count: 51299
total_duration: 4649.012674042555
[2023-06-29 14:20:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 211.33333333333334
avg_sample_per_episode: 211.33333333333334
avg_envstep_per_sec: 2694.7850258590497
avg_train_sample_per_sec: 2694.7850258590497
avg_episode_per_sec: 12.751348702803075
collect_time: 0.4705384614476934
reward_mean: 2265.028390398556
reward_std: 881.4375568556447
reward_max: 3495.5651690437708
reward_min: 1028.3171117563352
total_envstep_count: 23377433
total_train_sample_count: 17532540
total_episode_count: 51305
total_duration: 4649.483212504003
[2023-06-29 14:20:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2446
train_sample_count: 2446
avg_envstep_per_episode: 244.6
avg_sample_per_episode: 244.6
avg_envstep_per_sec: 2636.1927148794384
avg_train_sample_per_sec: 2636.1927148794384
avg_episode_per_sec: 10.777566291412258
collect_time: 0.9278532582971133
reward_mean: 2240.6207084737525
reward_std: 827.0558816955502
reward_max: 3178.2236170921988
reward_min: 700.4830132036352
total_envstep_count: 23381440
total_train_sample_count: 17535786
total_episode_count: 51315
total_duration: 4650.4110657623005
[2023-06-29 14:20:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1679
train_sample_count: 1679
avg_envstep_per_episode: 279.8333333333333
avg_sample_per_episode: 279.8333333333333
avg_envstep_per_sec: 2727.8649204450107
avg_train_sample_per_sec: 2727.8649204450107
avg_episode_per_sec: 9.748177202304982
collect_time: 0.6154996852725743
reward_mean: 1851.334002304034
reward_std: 855.3627350045148
reward_max: 3470.061251592359
reward_min: 771.462399056803
total_envstep_count: 23385768
total_train_sample_count: 17539065
total_episode_count: 51321
total_duration: 4651.026565447573
[2023-06-29 14:20:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2347
train_sample_count: 2347
avg_envstep_per_episode: 293.375
avg_sample_per_episode: 293.375
avg_envstep_per_sec: 2720.937039263964
avg_train_sample_per_sec: 2720.937039263964
avg_episode_per_sec: 9.274604309378658
collect_time: 0.8625704917578259
reward_mean: 2123.703258177895
reward_std: 826.5664965572861
reward_max: 3375.858830289655
reward_min: 1183.6312075999201
total_envstep_count: 23390736
total_train_sample_count: 17542612
total_episode_count: 51329
total_duration: 4651.889135939331
[2023-06-29 14:21:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1944
train_sample_count: 1944
avg_envstep_per_episode: 277.7142857142857
avg_sample_per_episode: 277.7142857142857
avg_envstep_per_sec: 2403.678050270467
avg_train_sample_per_sec: 2403.678050270467
avg_episode_per_sec: 8.655219316817524
collect_time: 0.808760557505302
reward_mean: 2414.028739531885
reward_std: 1018.1964541933414
reward_max: 3527.6944328195104
reward_min: 966.9307738265584
total_envstep_count: 23395288
total_train_sample_count: 17546156
total_episode_count: 51336
total_duration: 4652.697896496837
[2023-06-29 14:21:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2072
train_sample_count: 2072
avg_envstep_per_episode: 230.22222222222223
avg_sample_per_episode: 230.22222222222223
avg_envstep_per_sec: 2422.440667844276
avg_train_sample_per_sec: 2422.440667844276
avg_episode_per_sec: 10.52218436804946
collect_time: 0.8553357064649463
reward_mean: 1993.783608016414
reward_std: 1047.3210081624077
reward_max: 3682.1152663117587
reward_min: 334.74631379863087
total_envstep_count: 23399744
total_train_sample_count: 17549428
total_episode_count: 51345
total_duration: 4653.553232203301
[2023-06-29 14:21:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 2013
train_sample_count: 2013
avg_envstep_per_episode: 402.6
avg_sample_per_episode: 402.6
avg_envstep_per_sec: 2508.675465449276
avg_train_sample_per_sec: 2508.675465449276
avg_episode_per_sec: 6.231185954916235
collect_time: 0.8024154689293356
reward_mean: 2841.4395542047123
reward_std: 867.065844762882
reward_max: 3570.696141731816
reward_min: 1773.9779995252525
total_envstep_count: 23404544
total_train_sample_count: 17552641
total_episode_count: 51350
total_duration: 4654.355647672231
[2023-06-29 14:21:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3444
train_sample_count: 3444
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2725.566825311111
avg_train_sample_per_sec: 2725.566825311111
avg_episode_per_sec: 9.496748520247776
collect_time: 1.263590372474864
reward_mean: 2046.829209059941
reward_std: 910.218018809914
reward_max: 3522.387890587723
reward_min: 654.9345808322189
total_envstep_count: 23409048
total_train_sample_count: 17556085
total_episode_count: 51362
total_duration: 4655.6192380447055
[2023-06-29 14:21:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 213.625
avg_sample_per_episode: 213.625
avg_envstep_per_sec: 2723.1665509128375
avg_train_sample_per_sec: 2723.1665509128375
avg_episode_per_sec: 12.747415100820772
collect_time: 0.6275782138360664
reward_mean: 1223.115939555335
reward_std: 689.5454738883941
reward_max: 2562.211416627542
reward_min: 275.8474400358448
total_envstep_count: 23413992
total_train_sample_count: 17559394
total_episode_count: 51370
total_duration: 4656.246816258542
[2023-06-29 14:21:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1759
train_sample_count: 1759
avg_envstep_per_episode: 251.28571428571428
avg_sample_per_episode: 251.28571428571428
avg_envstep_per_sec: 2499.304738595764
avg_train_sample_per_sec: 2499.304738595764
avg_episode_per_sec: 9.946067748817708
collect_time: 0.703795728802681
reward_mean: 2144.8640552037045
reward_std: 857.792706151432
reward_max: 3621.1648249698833
reward_min: 990.0246255488606
total_envstep_count: 23418776
total_train_sample_count: 17562753
total_episode_count: 51377
total_duration: 4656.950611987345
[2023-06-29 14:21:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1906
train_sample_count: 1906
avg_envstep_per_episode: 211.77777777777777
avg_sample_per_episode: 211.77777777777777
avg_envstep_per_sec: 2639.435405583236
avg_train_sample_per_sec: 2639.435405583236
avg_episode_per_sec: 12.463231191106571
collect_time: 0.7221241315351801
reward_mean: 2168.106500464484
reward_std: 1059.1704256866408
reward_max: 3535.720113259758
reward_min: 587.4340684503178
total_envstep_count: 23423200
total_train_sample_count: 17566259
total_episode_count: 51386
total_duration: 4657.6727361188805
[2023-06-29 14:21:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2403
train_sample_count: 2403
avg_envstep_per_episode: 218.45454545454547
avg_sample_per_episode: 218.45454545454547
avg_envstep_per_sec: 2758.7696890304233
avg_train_sample_per_sec: 2758.7696890304233
avg_episode_per_sec: 12.628575355528362
collect_time: 0.8710404531247915
reward_mean: 1732.1103287653607
reward_std: 792.2242869909405
reward_max: 3483.803988674488
reward_min: 863.0133514647051
total_envstep_count: 23427352
total_train_sample_count: 17569462
total_episode_count: 51397
total_duration: 4658.543776572005
[2023-06-29 14:21:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2779
train_sample_count: 2779
avg_envstep_per_episode: 308.77777777777777
avg_sample_per_episode: 308.77777777777777
avg_envstep_per_sec: 2760.3032533526016
avg_train_sample_per_sec: 2760.3032533526016
avg_episode_per_sec: 8.939449183221813
collect_time: 1.0067734393402934
reward_mean: 1817.5015456871624
reward_std: 414.42915362950396
reward_max: 2339.880541480825
reward_min: 1028.9811250300343
total_envstep_count: 23432032
total_train_sample_count: 17573041
total_episode_count: 51406
total_duration: 4659.550550011346
[2023-06-29 14:21:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2543
train_sample_count: 2543
avg_envstep_per_episode: 231.1818181818182
avg_sample_per_episode: 231.1818181818182
avg_envstep_per_sec: 2571.4163979409077
avg_train_sample_per_sec: 2571.4163979409077
avg_episode_per_sec: 11.122917961993702
collect_time: 0.9889491262622178
reward_mean: 1380.7642965699172
reward_std: 788.3241556057088
reward_max: 3445.6687182325195
reward_min: 349.71567112012764
total_envstep_count: 23436864
total_train_sample_count: 17576384
total_episode_count: 51417
total_duration: 4660.539499137608
[2023-06-29 14:21:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2661
train_sample_count: 2661
avg_envstep_per_episode: 221.75
avg_sample_per_episode: 221.75
avg_envstep_per_sec: 2573.1165378881415
avg_train_sample_per_sec: 2573.1165378881415
avg_episode_per_sec: 11.60368224526783
collect_time: 1.0341544818580148
reward_mean: 1518.6185454892977
reward_std: 764.6913760430651
reward_max: 2941.4216129361735
reward_min: 223.71771206835518
total_envstep_count: 23441912
total_train_sample_count: 17579845
total_episode_count: 51429
total_duration: 4661.573653619466
[2023-06-29 14:21:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2025
train_sample_count: 2025
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 2491.808025669168
avg_train_sample_per_sec: 2491.808025669168
avg_episode_per_sec: 12.305224818119347
collect_time: 0.812662925530225
reward_mean: 1619.46158120955
reward_std: 745.5873279511229
reward_max: 3180.6346393581084
reward_min: 939.389357503722
total_envstep_count: 23446312
total_train_sample_count: 17583070
total_episode_count: 51439
total_duration: 4662.386316544997
[2023-06-29 14:21:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1817
train_sample_count: 1817
avg_envstep_per_episode: 227.125
avg_sample_per_episode: 227.125
avg_envstep_per_sec: 2564.555906920877
avg_train_sample_per_sec: 2564.555906920877
avg_episode_per_sec: 11.29138539095598
collect_time: 0.7085047337422147
reward_mean: 1869.7356931466395
reward_std: 573.738869625851
reward_max: 2692.2675081932966
reward_min: 683.2396146108512
total_envstep_count: 23451264
total_train_sample_count: 17586487
total_episode_count: 51447
total_duration: 4663.094821278739
[2023-06-29 14:21:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2394
train_sample_count: 2394
avg_envstep_per_episode: 239.4
avg_sample_per_episode: 239.4
avg_envstep_per_sec: 2606.689117742825
avg_train_sample_per_sec: 2606.689117742825
avg_episode_per_sec: 10.888425721565685
collect_time: 0.9184064120668919
reward_mean: 1951.142203599168
reward_std: 855.0106256877278
reward_max: 3137.527672063609
reward_min: 703.2381328090185
total_envstep_count: 23455968
total_train_sample_count: 17590081
total_episode_count: 51457
total_duration: 4664.013227690806
[2023-06-29 14:21:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2515
train_sample_count: 2515
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2544.6247261692447
avg_train_sample_per_sec: 2544.6247261692447
avg_episode_per_sec: 10.11779215176638
collect_time: 0.9883579193959013
reward_mean: 1802.7370985902066
reward_std: 808.4578153821489
reward_max: 3490.978885800297
reward_min: 1002.0118754597825
total_envstep_count: 23460352
total_train_sample_count: 17593396
total_episode_count: 51467
total_duration: 4665.001585610202
[2023-06-29 14:21:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 256.75
avg_sample_per_episode: 256.75
avg_envstep_per_sec: 2635.7616317377037
avg_train_sample_per_sec: 2635.7616317377037
avg_episode_per_sec: 10.265868088559705
collect_time: 0.3896406972594558
reward_mean: 1953.8659372837183
reward_std: 664.3039155960245
reward_max: 2992.2933380534323
reward_min: 1180.4918758678996
total_envstep_count: 23464512
total_train_sample_count: 17596823
total_episode_count: 51471
total_duration: 4665.391226307462
[2023-06-29 14:21:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2642
train_sample_count: 2642
avg_envstep_per_episode: 293.55555555555554
avg_sample_per_episode: 293.55555555555554
avg_envstep_per_sec: 2752.6910798882086
avg_train_sample_per_sec: 2752.6910798882086
avg_episode_per_sec: 9.377070294850068
collect_time: 0.9597880486128854
reward_mean: 2600.9006685007084
reward_std: 949.2051320854349
reward_max: 3576.773099410015
reward_min: 1021.3907660078286
total_envstep_count: 23469120
total_train_sample_count: 17600265
total_episode_count: 51480
total_duration: 4666.351014356074
[2023-06-29 14:21:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3101
train_sample_count: 3101
avg_envstep_per_episode: 281.90909090909093
avg_sample_per_episode: 281.90909090909093
avg_envstep_per_sec: 2599.183786614016
avg_train_sample_per_sec: 2599.183786614016
avg_episode_per_sec: 9.219936037650491
collect_time: 1.1930668450497321
reward_mean: 1622.8353824027158
reward_std: 714.5215537482441
reward_max: 3012.820488273728
reward_min: 596.8183407480248
total_envstep_count: 23474088
total_train_sample_count: 17603766
total_episode_count: 51491
total_duration: 4667.544081201124
[2023-06-29 14:21:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2488
train_sample_count: 2488
avg_envstep_per_episode: 355.42857142857144
avg_sample_per_episode: 355.42857142857144
avg_envstep_per_sec: 2682.6874069768733
avg_train_sample_per_sec: 2682.6874069768733
avg_episode_per_sec: 7.5477539585362186
collect_time: 0.9274282175140686
reward_mean: 2091.0535381572267
reward_std: 783.4473197503207
reward_max: 3630.349468116191
reward_min: 1050.4251003801119
total_envstep_count: 23478488
total_train_sample_count: 17607054
total_episode_count: 51498
total_duration: 4668.471509418638
[2023-06-29 14:22:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2889
train_sample_count: 2889
avg_envstep_per_episode: 288.9
avg_sample_per_episode: 288.9
avg_envstep_per_sec: 2412.3358676789976
avg_train_sample_per_sec: 2412.3358676789976
avg_episode_per_sec: 8.350072231495318
collect_time: 1.19759443065431
reward_mean: 1852.909260251826
reward_std: 970.3728999079086
reward_max: 3525.7529160410522
reward_min: 640.3695784857528
total_envstep_count: 23483472
total_train_sample_count: 17610743
total_episode_count: 51508
total_duration: 4669.669103849292
[2023-06-29 14:22:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2468
train_sample_count: 2468
avg_envstep_per_episode: 308.5
avg_sample_per_episode: 308.5
avg_envstep_per_sec: 2667.5221636338047
avg_train_sample_per_sec: 2667.5221636338047
avg_episode_per_sec: 8.646749314858361
collect_time: 0.92520318430569
reward_mean: 2076.017426111929
reward_std: 857.0225356793669
reward_max: 3330.1160238910825
reward_min: 884.1611267617242
total_envstep_count: 23487552
total_train_sample_count: 17614011
total_episode_count: 51516
total_duration: 4670.594307033597
[2023-06-29 14:22:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2320
train_sample_count: 2320
avg_envstep_per_episode: 331.42857142857144
avg_sample_per_episode: 331.42857142857144
avg_envstep_per_sec: 2724.5780623115347
avg_train_sample_per_sec: 2724.5780623115347
avg_episode_per_sec: 8.220709670767562
collect_time: 0.8515079938769343
reward_mean: 1919.2839366461287
reward_std: 401.91475000569403
reward_max: 2422.4588657609793
reward_min: 1286.6251255795341
total_envstep_count: 23492000
total_train_sample_count: 17617531
total_episode_count: 51523
total_duration: 4671.445815027474
[2023-06-29 14:22:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2706
train_sample_count: 2706
avg_envstep_per_episode: 338.25
avg_sample_per_episode: 338.25
avg_envstep_per_sec: 2762.6481175971126
avg_train_sample_per_sec: 2762.6481175971126
avg_episode_per_sec: 8.167474109673652
collect_time: 0.9794949935041369
reward_mean: 2214.352378286938
reward_std: 726.2788817959455
reward_max: 3481.3102363154926
reward_min: 1194.445190123225
total_envstep_count: 23496912
total_train_sample_count: 17621037
total_episode_count: 51531
total_duration: 4672.425310020978
[2023-06-29 14:22:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1247
train_sample_count: 1247
avg_envstep_per_episode: 249.4
avg_sample_per_episode: 249.4
avg_envstep_per_sec: 2745.086792635245
avg_train_sample_per_sec: 2745.086792635245
avg_episode_per_sec: 11.006763402707477
collect_time: 0.4542661468284205
reward_mean: 2024.5370578626578
reward_std: 747.8883836318586
reward_max: 3394.0731558436864
reward_min: 1339.0548424654341
total_envstep_count: 23501568
total_train_sample_count: 17624284
total_episode_count: 51536
total_duration: 4672.879576167807
[2023-06-29 14:22:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2022
train_sample_count: 2022
avg_envstep_per_episode: 224.66666666666666
avg_sample_per_episode: 224.66666666666666
avg_envstep_per_sec: 2448.784946348099
avg_train_sample_per_sec: 2448.784946348099
avg_episode_per_sec: 10.89963625970964
collect_time: 0.8257156280772764
reward_mean: 2405.445256905104
reward_std: 932.8717527759053
reward_max: 3491.9015752225305
reward_min: 985.2348128434957
total_envstep_count: 23505920
total_train_sample_count: 17627506
total_episode_count: 51545
total_duration: 4673.705291795884
[2023-06-29 14:22:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2438
train_sample_count: 2438
avg_envstep_per_episode: 348.2857142857143
avg_sample_per_episode: 348.2857142857143
avg_envstep_per_sec: 2512.203762250091
avg_train_sample_per_sec: 2512.203762250091
avg_episode_per_sec: 7.2130542804555535
collect_time: 0.9704626816641538
reward_mean: 2339.188984164074
reward_std: 909.8879344713073
reward_max: 3505.4653190553277
reward_min: 1320.022969422022
total_envstep_count: 23510352
total_train_sample_count: 17630744
total_episode_count: 51552
total_duration: 4674.675754477547
[2023-06-29 14:22:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 271.0
avg_sample_per_episode: 271.0
avg_envstep_per_sec: 2628.759602315364
avg_train_sample_per_sec: 2628.759602315364
avg_episode_per_sec: 9.700219934743041
collect_time: 0.6185426763892173
reward_mean: 2030.381295683878
reward_std: 852.3046269451918
reward_max: 3487.7849001608797
reward_min: 990.1453068269448
total_envstep_count: 23514288
total_train_sample_count: 17633970
total_episode_count: 51558
total_duration: 4675.294297153937
[2023-06-29 14:22:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2824
train_sample_count: 2824
avg_envstep_per_episode: 217.23076923076923
avg_sample_per_episode: 217.23076923076923
avg_envstep_per_sec: 2638.7835994540837
avg_train_sample_per_sec: 2638.7835994540837
avg_episode_per_sec: 12.1473749266654
collect_time: 1.070190068099648
reward_mean: 1471.426762409026
reward_std: 799.9248631670481
reward_max: 2999.272950929932
reward_min: 670.8153573501075
total_envstep_count: 23519136
total_train_sample_count: 17637194
total_episode_count: 51571
total_duration: 4676.364487222037
[2023-06-29 14:22:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 226.30769230769232
avg_sample_per_episode: 226.30769230769232
avg_envstep_per_sec: 2568.069696672304
avg_train_sample_per_sec: 2568.069696672304
avg_episode_per_sec: 11.347690705893934
collect_time: 1.1456075369808825
reward_mean: 1319.5758792498427
reward_std: 549.3286063153455
reward_max: 2752.431509893607
reward_min: 781.2902655346488
total_envstep_count: 23524080
total_train_sample_count: 17640536
total_episode_count: 51584
total_duration: 4677.510094759017
[2023-06-29 14:22:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2168
train_sample_count: 2168
avg_envstep_per_episode: 216.8
avg_sample_per_episode: 216.8
avg_envstep_per_sec: 2446.389663801511
avg_train_sample_per_sec: 2446.389663801511
avg_episode_per_sec: 11.28408516513612
collect_time: 0.886203875073232
reward_mean: 1570.1728115821745
reward_std: 763.3475024193538
reward_max: 2993.9692653686175
reward_min: 700.7661618274861
total_envstep_count: 23528816
total_train_sample_count: 17643904
total_episode_count: 51594
total_duration: 4678.39629863409
[2023-06-29 14:22:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 287.4
avg_sample_per_episode: 287.4
avg_envstep_per_sec: 2649.1263056868
avg_train_sample_per_sec: 2649.1263056868
avg_episode_per_sec: 9.21755847490188
collect_time: 0.5424429922103884
reward_mean: 2215.2927889098123
reward_std: 1016.363265606283
reward_max: 3378.810482449292
reward_min: 683.7097575258788
total_envstep_count: 23533824
total_train_sample_count: 17647341
total_episode_count: 51599
total_duration: 4678.938741626301
[2023-06-29 14:22:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2325
train_sample_count: 2325
avg_envstep_per_episode: 232.5
avg_sample_per_episode: 232.5
avg_envstep_per_sec: 2701.42797463609
avg_train_sample_per_sec: 2701.42797463609
avg_episode_per_sec: 11.619045052198235
collect_time: 0.8606559278387578
reward_mean: 2359.704547704513
reward_std: 959.9356158574088
reward_max: 3548.236199173626
reward_min: 1003.0974442795967
total_envstep_count: 23537936
total_train_sample_count: 17650866
total_episode_count: 51609
total_duration: 4679.799397554139
[2023-06-29 14:22:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2262
train_sample_count: 2262
avg_envstep_per_episode: 282.75
avg_sample_per_episode: 282.75
avg_envstep_per_sec: 2387.868734730318
avg_train_sample_per_sec: 2387.868734730318
avg_episode_per_sec: 8.445159097189453
collect_time: 0.9472882521138528
reward_mean: 1894.128465124259
reward_std: 611.4769714082568
reward_max: 2552.138956426574
reward_min: 907.2969139784592
total_envstep_count: 23542904
total_train_sample_count: 17654328
total_episode_count: 51617
total_duration: 4680.7466858062535
[2023-06-29 14:22:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 338.1666666666667
avg_sample_per_episode: 338.1666666666667
avg_envstep_per_sec: 2537.6091198474587
avg_train_sample_per_sec: 2537.6091198474587
avg_episode_per_sec: 7.50401908284118
collect_time: 0.7995715274391698
reward_mean: 2540.0121296319053
reward_std: 931.6285603244719
reward_max: 3537.82237049697
reward_min: 1042.3055725004617
total_envstep_count: 23547456
total_train_sample_count: 17657557
total_episode_count: 51623
total_duration: 4681.546257333693
[2023-06-29 14:22:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1925
train_sample_count: 1925
avg_envstep_per_episode: 240.625
avg_sample_per_episode: 240.625
avg_envstep_per_sec: 2458.2274391051114
avg_train_sample_per_sec: 2458.2274391051114
avg_episode_per_sec: 10.216010136540723
collect_time: 0.7830845793100306
reward_mean: 2084.7931657177687
reward_std: 857.0758031046691
reward_max: 3465.909169262093
reward_min: 817.7840984429254
total_envstep_count: 23552240
total_train_sample_count: 17661082
total_episode_count: 51631
total_duration: 4682.329341913002
[2023-06-29 14:22:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1539
train_sample_count: 1539
avg_envstep_per_episode: 256.5
avg_sample_per_episode: 256.5
avg_envstep_per_sec: 2314.91056036338
avg_train_sample_per_sec: 2314.91056036338
avg_episode_per_sec: 9.024992438063858
collect_time: 0.6648205016432331
reward_mean: 2469.466300821817
reward_std: 830.314861186594
reward_max: 3472.8056459698064
reward_min: 1414.231611962311
total_envstep_count: 23557208
total_train_sample_count: 17664621
total_episode_count: 51637
total_duration: 4682.994162414646
[2023-06-29 14:22:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 916
train_sample_count: 916
avg_envstep_per_episode: 183.2
avg_sample_per_episode: 183.2
avg_envstep_per_sec: 2481.1931381336444
avg_train_sample_per_sec: 2481.1931381336444
avg_episode_per_sec: 13.543630666668363
collect_time: 0.3691772260377183
reward_mean: 2884.3702074755774
reward_std: 841.3843444900826
reward_max: 3544.7747211459227
reward_min: 1391.5623735967629
total_envstep_count: 23561656
total_train_sample_count: 17667937
total_episode_count: 51642
total_duration: 4683.363339640684
[2023-06-29 14:22:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1689
train_sample_count: 1689
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 2437.2408459913845
avg_train_sample_per_sec: 2437.2408459913845
avg_episode_per_sec: 8.658049186470283
collect_time: 0.6929967560563239
reward_mean: 3189.4183315356318
reward_std: 428.8252013034432
reward_max: 3511.7482560644075
reward_min: 2375.784967865865
total_envstep_count: 23566328
total_train_sample_count: 17671226
total_episode_count: 51648
total_duration: 4684.05633639674
[2023-06-29 14:23:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 234
train_sample_count: 234
avg_envstep_per_episode: 58.5
avg_sample_per_episode: 58.5
avg_envstep_per_sec: 2692.7717330474193
avg_train_sample_per_sec: 2692.7717330474193
avg_episode_per_sec: 46.030286034998625
collect_time: 0.08689930792432278
reward_mean: 2626.3867250030485
reward_std: 767.2109757714476
reward_max: 3456.7146990476667
reward_min: 1706.9074902652244
total_envstep_count: 23570680
total_train_sample_count: 17674660
total_episode_count: 51652
total_duration: 4684.143235704664
[2023-06-29 14:23:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2158
train_sample_count: 2158
avg_envstep_per_episode: 269.75
avg_sample_per_episode: 269.75
avg_envstep_per_sec: 2619.6596257415013
avg_train_sample_per_sec: 2619.6596257415013
avg_episode_per_sec: 9.711435127864695
collect_time: 0.8237711414089426
reward_mean: 2980.621787397607
reward_std: 936.9433129348116
reward_max: 3562.345208797702
reward_min: 682.7843544114162
total_envstep_count: 23574808
total_train_sample_count: 17678018
total_episode_count: 51660
total_duration: 4684.967006846073
[2023-06-29 14:23:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2886
train_sample_count: 2886
avg_envstep_per_episode: 262.3636363636364
avg_sample_per_episode: 262.3636363636364
avg_envstep_per_sec: 2617.3510742990084
avg_train_sample_per_sec: 2617.3510742990084
avg_episode_per_sec: 9.976043595734266
collect_time: 1.102641532631591
reward_mean: 1742.151608398377
reward_std: 875.5972443170915
reward_max: 3608.3871666580753
reward_min: 705.2645027305367
total_envstep_count: 23579240
total_train_sample_count: 17681304
total_episode_count: 51671
total_duration: 4686.069648378704
[2023-06-29 14:23:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2104
train_sample_count: 2104
avg_envstep_per_episode: 300.57142857142856
avg_sample_per_episode: 300.57142857142856
avg_envstep_per_sec: 2270.9548784142353
avg_train_sample_per_sec: 2270.9548784142353
avg_episode_per_sec: 7.555458245674737
collect_time: 0.9264825206343084
reward_mean: 1593.8213933781833
reward_std: 591.6434478693674
reward_max: 2466.624510344258
reward_min: 910.0952068136633
total_envstep_count: 23583872
total_train_sample_count: 17684608
total_episode_count: 51678
total_duration: 4686.996130899339
[2023-06-29 14:23:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2589
train_sample_count: 2589
avg_envstep_per_episode: 287.6666666666667
avg_sample_per_episode: 287.6666666666667
avg_envstep_per_sec: 2425.4175586783235
avg_train_sample_per_sec: 2425.4175586783235
avg_episode_per_sec: 8.431347249171461
collect_time: 1.0674450635258108
reward_mean: 2284.63416555734
reward_std: 1037.9294517974906
reward_max: 3713.9899833448712
reward_min: 1000.0074249750082
total_envstep_count: 23588728
total_train_sample_count: 17687997
total_episode_count: 51687
total_duration: 4688.063575962865
[2023-06-29 14:23:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1940
train_sample_count: 1940
avg_envstep_per_episode: 277.14285714285717
avg_sample_per_episode: 277.14285714285717
avg_envstep_per_sec: 2637.560447677575
avg_train_sample_per_sec: 2637.560447677575
avg_episode_per_sec: 9.516970687496405
collect_time: 0.7355281664570793
reward_mean: 1913.1893105112742
reward_std: 585.4263952023948
reward_max: 2947.7794212078857
reward_min: 1332.9206331546657
total_envstep_count: 23593384
total_train_sample_count: 17691537
total_episode_count: 51694
total_duration: 4688.799104129322
[2023-06-29 14:23:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2320
train_sample_count: 2320
avg_envstep_per_episode: 290.0
avg_sample_per_episode: 290.0
avg_envstep_per_sec: 2340.2189472386917
avg_train_sample_per_sec: 2340.2189472386917
avg_episode_per_sec: 8.069720507719627
collect_time: 0.991360232655774
reward_mean: 2501.911657931877
reward_std: 1018.6472322505919
reward_max: 3655.4442626908394
reward_min: 927.2696324305027
total_envstep_count: 23598424
total_train_sample_count: 17695057
total_episode_count: 51702
total_duration: 4689.790464361978
[2023-06-29 14:23:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2945
train_sample_count: 2945
avg_envstep_per_episode: 327.22222222222223
avg_sample_per_episode: 327.22222222222223
avg_envstep_per_sec: 2739.8855498413695
avg_train_sample_per_sec: 2739.8855498413695
avg_episode_per_sec: 8.373164668445611
collect_time: 1.0748624153919517
reward_mean: 2262.5240090809943
reward_std: 811.5509952066602
reward_max: 3541.4540648402685
reward_min: 1223.2595277795501
total_envstep_count: 23602880
total_train_sample_count: 17698402
total_episode_count: 51711
total_duration: 4690.86532677737
[2023-06-29 14:23:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1400
train_sample_count: 1400
avg_envstep_per_episode: 350.0
avg_sample_per_episode: 350.0
avg_envstep_per_sec: 2692.780550656652
avg_train_sample_per_sec: 2692.780550656652
avg_episode_per_sec: 7.693658716161862
collect_time: 0.5199086868250742
reward_mean: 2477.529267240721
reward_std: 652.0964982105135
reward_max: 3500.9332827173944
reward_min: 1863.073778985773
total_envstep_count: 23607712
total_train_sample_count: 17701802
total_episode_count: 51715
total_duration: 4691.385235464195
[2023-06-29 14:23:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2480
train_sample_count: 2480
avg_envstep_per_episode: 310.0
avg_sample_per_episode: 310.0
avg_envstep_per_sec: 2460.4336457550207
avg_train_sample_per_sec: 2460.4336457550207
avg_episode_per_sec: 7.936882728242002
collect_time: 1.0079524006992577
reward_mean: 2652.4332579160964
reward_std: 1103.322625863356
reward_max: 3578.906137154021
reward_min: 702.228644018069
total_envstep_count: 23612648
total_train_sample_count: 17705082
total_episode_count: 51723
total_duration: 4692.393187864895
[2023-06-29 14:23:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1619
train_sample_count: 1619
avg_envstep_per_episode: 269.8333333333333
avg_sample_per_episode: 269.8333333333333
avg_envstep_per_sec: 2687.736551099991
avg_train_sample_per_sec: 2687.736551099991
avg_episode_per_sec: 9.960728416676929
collect_time: 0.6023655850263312
reward_mean: 2086.7507596258483
reward_std: 848.5491707520995
reward_max: 3545.5131887334164
reward_min: 954.9297780180784
total_envstep_count: 23617424
total_train_sample_count: 17708301
total_episode_count: 51729
total_duration: 4692.995553449921
[2023-06-29 14:23:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1766
train_sample_count: 1766
avg_envstep_per_episode: 220.75
avg_sample_per_episode: 220.75
avg_envstep_per_sec: 2709.945548238999
avg_train_sample_per_sec: 2709.945548238999
avg_episode_per_sec: 12.276084023732723
collect_time: 0.6516736106183381
reward_mean: 2659.369482521968
reward_std: 973.5658974276763
reward_max: 3561.078369074168
reward_min: 924.1284287627865
total_envstep_count: 23621416
total_train_sample_count: 17711667
total_episode_count: 51737
total_duration: 4693.64722706054
[2023-06-29 14:23:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 350.42857142857144
avg_sample_per_episode: 350.42857142857144
avg_envstep_per_sec: 2708.408656544555
avg_train_sample_per_sec: 2708.408656544555
avg_episode_per_sec: 7.728846553531139
collect_time: 0.9056978879729285
reward_mean: 2307.2032343296178
reward_std: 705.0415550196731
reward_max: 3559.0572638177705
reward_min: 1296.1700938451675
total_envstep_count: 23625672
total_train_sample_count: 17714920
total_episode_count: 51744
total_duration: 4694.552924948513
[2023-06-29 14:23:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3258
train_sample_count: 3258
avg_envstep_per_episode: 325.8
avg_sample_per_episode: 325.8
avg_envstep_per_sec: 2531.2163741891386
avg_train_sample_per_sec: 2531.2163741891386
avg_episode_per_sec: 7.769233806596497
collect_time: 1.2871282096710055
reward_mean: 1886.1607437222233
reward_std: 949.1958811806772
reward_max: 3529.2710739870554
reward_min: 846.3114058076709
total_envstep_count: 23630184
total_train_sample_count: 17718178
total_episode_count: 51754
total_duration: 4695.840053158184
[2023-06-29 14:23:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1787
train_sample_count: 1787
avg_envstep_per_episode: 297.8333333333333
avg_sample_per_episode: 297.8333333333333
avg_envstep_per_sec: 2633.19941252216
avg_train_sample_per_sec: 2633.19941252216
avg_episode_per_sec: 8.841184373325664
collect_time: 0.6786421079626309
reward_mean: 1476.7135898652953
reward_std: 521.6772048193094
reward_max: 2532.3008074895592
reward_min: 1021.1082047527161
total_envstep_count: 23634832
total_train_sample_count: 17721565
total_episode_count: 51760
total_duration: 4696.518695266146
[2023-06-29 14:23:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2094
train_sample_count: 2094
avg_envstep_per_episode: 209.4
avg_sample_per_episode: 209.4
avg_envstep_per_sec: 2656.5314891552284
avg_train_sample_per_sec: 2656.5314891552284
avg_episode_per_sec: 12.686396796347795
collect_time: 0.7882458794666454
reward_mean: 1973.7554063438515
reward_std: 936.256670572064
reward_max: 3588.688538432845
reward_min: 998.0042426049462
total_envstep_count: 23639592
total_train_sample_count: 17724859
total_episode_count: 51770
total_duration: 4697.306941145613
[2023-06-29 14:23:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2329
train_sample_count: 2329
avg_envstep_per_episode: 291.125
avg_sample_per_episode: 291.125
avg_envstep_per_sec: 2555.1415085579133
avg_train_sample_per_sec: 2555.1415085579133
avg_episode_per_sec: 8.77678491561327
collect_time: 0.9114955051215365
reward_mean: 2150.7253004752765
reward_std: 719.5442803181935
reward_max: 3533.550117291066
reward_min: 1282.721617003371
total_envstep_count: 23644112
total_train_sample_count: 17728388
total_episode_count: 51778
total_duration: 4698.2184366507345
[2023-06-29 14:23:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1821
train_sample_count: 1821
avg_envstep_per_episode: 227.625
avg_sample_per_episode: 227.625
avg_envstep_per_sec: 2327.999020844946
avg_train_sample_per_sec: 2327.999020844946
avg_episode_per_sec: 10.2273433095879
collect_time: 0.7822168238451703
reward_mean: 1699.9409926355256
reward_std: 786.9384110289992
reward_max: 3569.3348550532596
reward_min: 845.8769049487282
total_envstep_count: 23648736
total_train_sample_count: 17731809
total_episode_count: 51786
total_duration: 4699.00065347458
[2023-06-29 14:24:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1935
train_sample_count: 1935
avg_envstep_per_episode: 193.5
avg_sample_per_episode: 193.5
avg_envstep_per_sec: 2391.557492052646
avg_train_sample_per_sec: 2391.557492052646
avg_episode_per_sec: 12.359470243166129
collect_time: 0.8090961670083925
reward_mean: 1844.1504916553702
reward_std: 1044.5648970193674
reward_max: 3566.240168395462
reward_min: 705.9677930309556
total_envstep_count: 23653560
total_train_sample_count: 17735344
total_episode_count: 51796
total_duration: 4699.8097496415885
[2023-06-29 14:24:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2067
train_sample_count: 2067
avg_envstep_per_episode: 229.66666666666666
avg_sample_per_episode: 229.66666666666666
avg_envstep_per_sec: 2571.593158224214
avg_train_sample_per_sec: 2571.593158224214
avg_episode_per_sec: 11.19706745235507
collect_time: 0.8037818864891305
reward_mean: 2003.9621143870058
reward_std: 731.4941876546061
reward_max: 3596.5691051585727
reward_min: 1018.5111169322034
total_envstep_count: 23657920
total_train_sample_count: 17739011
total_episode_count: 51805
total_duration: 4700.613531528078
[2023-06-29 14:24:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 919
train_sample_count: 919
avg_envstep_per_episode: 229.75
avg_sample_per_episode: 229.75
avg_envstep_per_sec: 2671.9820097060306
avg_train_sample_per_sec: 2671.9820097060306
avg_episode_per_sec: 11.629954340396216
collect_time: 0.3439394414564594
reward_mean: 2258.1433621455753
reward_std: 1031.926922738771
reward_max: 3620.2800140906234
reward_min: 713.2158032668677
total_envstep_count: 23662416
total_train_sample_count: 17742330
total_episode_count: 51809
total_duration: 4700.957470969534
[2023-06-29 14:24:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1641
train_sample_count: 1641
avg_envstep_per_episode: 182.33333333333334
avg_sample_per_episode: 182.33333333333334
avg_envstep_per_sec: 2598.4424832088584
avg_train_sample_per_sec: 2598.4424832088584
avg_episode_per_sec: 14.251055666593373
collect_time: 0.6315321622872725
reward_mean: 2480.3608052493937
reward_std: 1107.7109114930868
reward_max: 3588.5644271433202
reward_min: 1017.7885182006233
total_envstep_count: 23666704
total_train_sample_count: 17745571
total_episode_count: 51818
total_duration: 4701.589003131821
[2023-06-29 14:24:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1549
train_sample_count: 1549
avg_envstep_per_episode: 258.1666666666667
avg_sample_per_episode: 258.1666666666667
avg_envstep_per_sec: 2516.8805989196376
avg_train_sample_per_sec: 2516.8805989196376
avg_episode_per_sec: 9.749053320540881
collect_time: 0.6154443721584977
reward_mean: 2460.9426520432867
reward_std: 779.1049671992434
reward_max: 3547.5278013002085
reward_min: 1703.2583682349805
total_envstep_count: 23671328
total_train_sample_count: 17749120
total_episode_count: 51824
total_duration: 4702.20444750398
[2023-06-29 14:24:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2380
train_sample_count: 2380
avg_envstep_per_episode: 264.44444444444446
avg_sample_per_episode: 264.44444444444446
avg_envstep_per_sec: 2611.586431972803
avg_train_sample_per_sec: 2611.586431972803
avg_episode_per_sec: 9.875747011661861
collect_time: 0.9113234664043411
reward_mean: 2155.4042122394076
reward_std: 1111.7658088324786
reward_max: 3597.063028878785
reward_min: 651.1522757116618
total_envstep_count: 23676464
total_train_sample_count: 17752700
total_episode_count: 51833
total_duration: 4703.115770970385
[2023-06-29 14:24:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 269.55555555555554
avg_sample_per_episode: 269.55555555555554
avg_envstep_per_sec: 2761.865885885105
avg_train_sample_per_sec: 2761.865885885105
avg_episode_per_sec: 10.245998752253069
collect_time: 0.878391674410552
reward_mean: 1861.5481858577882
reward_std: 785.821368655777
reward_max: 3519.1836820059943
reward_min: 994.7735120651623
total_envstep_count: 23680896
total_train_sample_count: 17755926
total_episode_count: 51842
total_duration: 4703.994162644795
[2023-06-29 14:24:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1397
train_sample_count: 1397
avg_envstep_per_episode: 232.83333333333334
avg_sample_per_episode: 232.83333333333334
avg_envstep_per_sec: 2708.810130286645
avg_train_sample_per_sec: 2708.810130286645
avg_episode_per_sec: 11.634116522347794
collect_time: 0.51572459227778
reward_mean: 2119.921142810844
reward_std: 1053.7239497703556
reward_max: 3525.4723608662257
reward_min: 677.2143900299632
total_envstep_count: 23685816
total_train_sample_count: 17759323
total_episode_count: 51848
total_duration: 4704.509887237073
[2023-06-29 14:24:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2147
train_sample_count: 2147
avg_envstep_per_episode: 214.7
avg_sample_per_episode: 214.7
avg_envstep_per_sec: 2640.881497342458
avg_train_sample_per_sec: 2640.881497342458
avg_episode_per_sec: 12.30033301044461
collect_time: 0.8129861192789396
reward_mean: 2195.4793679175646
reward_std: 1204.3857462264716
reward_max: 3646.63894409942
reward_min: 426.03207032302953
total_envstep_count: 23690552
total_train_sample_count: 17762670
total_episode_count: 51858
total_duration: 4705.322873356352
[2023-06-29 14:24:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2076
train_sample_count: 2076
avg_envstep_per_episode: 296.57142857142856
avg_sample_per_episode: 296.57142857142856
avg_envstep_per_sec: 2539.1429826817493
avg_train_sample_per_sec: 2539.1429826817493
avg_episode_per_sec: 8.561657456055995
collect_time: 0.8175986993089319
reward_mean: 2183.0032228302457
reward_std: 897.4496584193319
reward_max: 3601.1745996663076
reward_min: 1048.3298612681285
total_envstep_count: 23695048
total_train_sample_count: 17765946
total_episode_count: 51865
total_duration: 4706.140472055661
[2023-06-29 14:24:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2545
train_sample_count: 2545
avg_envstep_per_episode: 282.77777777777777
avg_sample_per_episode: 282.77777777777777
avg_envstep_per_sec: 2699.6531537382048
avg_train_sample_per_sec: 2699.6531537382048
avg_episode_per_sec: 9.54690702697204
collect_time: 0.9427136950818824
reward_mean: 2100.7771796031548
reward_std: 1071.240248583315
reward_max: 3597.15061524688
reward_min: 852.504327260046
total_envstep_count: 23699816
total_train_sample_count: 17769291
total_episode_count: 51874
total_duration: 4707.083185750743
[2023-06-29 14:24:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 272.6666666666667
avg_sample_per_episode: 272.6666666666667
avg_envstep_per_sec: 2673.9876126416975
avg_train_sample_per_sec: 2673.9876126416975
avg_episode_per_sec: 9.806800535360749
collect_time: 0.6118203361397608
reward_mean: 1991.8582218975926
reward_std: 849.196355264049
reward_max: 3578.7070212498716
reward_min: 1024.2226286369234
total_envstep_count: 23704784
total_train_sample_count: 17772527
total_episode_count: 51880
total_duration: 4707.695006086882
[2023-06-29 14:24:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2505
train_sample_count: 2505
avg_envstep_per_episode: 227.72727272727272
avg_sample_per_episode: 227.72727272727272
avg_envstep_per_sec: 2404.987030721931
avg_train_sample_per_sec: 2404.987030721931
avg_episode_per_sec: 10.560821292591315
collect_time: 1.041585658467375
reward_mean: 2161.9120967956496
reward_std: 1094.0822875709334
reward_max: 3540.2787272470255
reward_min: 694.3140760099787
total_envstep_count: 23709144
total_train_sample_count: 17775832
total_episode_count: 51891
total_duration: 4708.73659174535
[2023-06-29 14:24:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2926
train_sample_count: 2926
avg_envstep_per_episode: 292.6
avg_sample_per_episode: 292.6
avg_envstep_per_sec: 2442.0020524855145
avg_train_sample_per_sec: 2442.0020524855145
avg_episode_per_sec: 8.34587167630046
collect_time: 1.1981971911210572
reward_mean: 1734.566006062311
reward_std: 818.9667607007731
reward_max: 3197.4742601948797
reward_min: 689.4790266918477
total_envstep_count: 23713448
total_train_sample_count: 17779158
total_episode_count: 51901
total_duration: 4709.934788936471
[2023-06-29 14:24:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2584
train_sample_count: 2584
avg_envstep_per_episode: 258.4
avg_sample_per_episode: 258.4
avg_envstep_per_sec: 2464.3487937567147
avg_train_sample_per_sec: 2464.3487937567147
avg_episode_per_sec: 9.536953536210197
collect_time: 1.0485528698479756
reward_mean: 1393.8422003560404
reward_std: 729.0528467096059
reward_max: 3508.793117521645
reward_min: 899.5645248676207
total_envstep_count: 23717592
total_train_sample_count: 17782542
total_episode_count: 51911
total_duration: 4710.983341806319
[2023-06-29 14:24:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3421
train_sample_count: 3421
avg_envstep_per_episode: 244.35714285714286
avg_sample_per_episode: 244.35714285714286
avg_envstep_per_sec: 2439.6994459057946
avg_train_sample_per_sec: 2439.6994459057946
avg_episode_per_sec: 9.984154411774664
collect_time: 1.4022219030876875
reward_mean: 1320.914464858049
reward_std: 673.4698805495258
reward_max: 2725.5675541902106
reward_min: 438.3751777587385
total_envstep_count: 23722008
total_train_sample_count: 17785963
total_episode_count: 51925
total_duration: 4712.385563709407
[2023-06-29 14:24:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2251
train_sample_count: 2251
avg_envstep_per_episode: 250.11111111111111
avg_sample_per_episode: 250.11111111111111
avg_envstep_per_sec: 2762.9239402506087
avg_train_sample_per_sec: 2762.9239402506087
avg_episode_per_sec: 11.046786078300967
collect_time: 0.8147166004851458
reward_mean: 1185.523421796959
reward_std: 272.66769496174413
reward_max: 1809.022841722654
reward_min: 904.2364205689096
total_envstep_count: 23726088
total_train_sample_count: 17789414
total_episode_count: 51934
total_duration: 4713.200280309892
[2023-06-29 14:24:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 230.35714285714286
avg_sample_per_episode: 230.35714285714286
avg_envstep_per_sec: 2550.4019024291574
avg_train_sample_per_sec: 2550.4019024291574
avg_episode_per_sec: 11.071512134576189
collect_time: 1.264506584992865
reward_mean: 1399.3874085254515
reward_std: 687.3433817940341
reward_max: 2832.634340598039
reward_min: 678.7962520453843
total_envstep_count: 23730632
total_train_sample_count: 17792639
total_episode_count: 51948
total_duration: 4714.464786894885
[2023-06-29 14:24:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2640
train_sample_count: 2640
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 2732.2398039108066
avg_train_sample_per_sec: 2732.2398039108066
avg_episode_per_sec: 8.279514557305475
collect_time: 0.9662402239441872
reward_mean: 1700.5264366636454
reward_std: 673.0954126672993
reward_max: 2721.390270270674
reward_min: 658.0121810568577
total_envstep_count: 23734904
total_train_sample_count: 17796079
total_episode_count: 51956
total_duration: 4715.43102711883
[2023-06-29 14:25:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 230.71428571428572
avg_sample_per_episode: 230.71428571428572
avg_envstep_per_sec: 2601.429623350025
avg_train_sample_per_sec: 2601.429623350025
avg_episode_per_sec: 11.275546355077507
collect_time: 0.6208124892190098
reward_mean: 1702.6532783706627
reward_std: 850.4774354291167
reward_max: 3152.928643472506
reward_min: 1019.4644649874308
total_envstep_count: 23739416
total_train_sample_count: 17799294
total_episode_count: 51963
total_duration: 4716.051839608049
[2023-06-29 14:25:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2767
train_sample_count: 2767
avg_envstep_per_episode: 212.84615384615384
avg_sample_per_episode: 212.84615384615384
avg_envstep_per_sec: 2709.3876043837167
avg_train_sample_per_sec: 2709.3876043837167
avg_episode_per_sec: 12.72932376472292
collect_time: 1.0212639917312192
reward_mean: 1633.427668172865
reward_std: 1013.8414512490531
reward_max: 3602.625032204023
reward_min: 20.770270481284896
total_envstep_count: 23744336
total_train_sample_count: 17802861
total_episode_count: 51976
total_duration: 4717.07310359978
[2023-06-29 14:25:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3055
train_sample_count: 3055
avg_envstep_per_episode: 277.72727272727275
avg_sample_per_episode: 277.72727272727275
avg_envstep_per_sec: 2484.0406410595756
avg_train_sample_per_sec: 2484.0406410595756
avg_episode_per_sec: 8.944172521000109
collect_time: 1.2298510537641123
reward_mean: 1701.957748837622
reward_std: 779.565935516241
reward_max: 3233.9448033931067
reward_min: 747.2463931432254
total_envstep_count: 23748736
total_train_sample_count: 17806316
total_episode_count: 51987
total_duration: 4718.302954653544
[2023-06-29 14:25:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2335
train_sample_count: 2335
avg_envstep_per_episode: 259.44444444444446
avg_sample_per_episode: 259.44444444444446
avg_envstep_per_sec: 2461.574172686942
avg_train_sample_per_sec: 2461.574172686942
avg_episode_per_sec: 9.487866190228042
collect_time: 0.9485799883296714
reward_mean: 1608.1575048084958
reward_std: 744.5272658760317
reward_max: 3534.8587298657244
reward_min: 1015.6908026979592
total_envstep_count: 23753560
total_train_sample_count: 17809851
total_episode_count: 51996
total_duration: 4719.251534641873
[2023-06-29 14:25:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2543
train_sample_count: 2543
avg_envstep_per_episode: 254.3
avg_sample_per_episode: 254.3
avg_envstep_per_sec: 2678.4425742240905
avg_train_sample_per_sec: 2678.4425742240905
avg_episode_per_sec: 10.532609414959067
collect_time: 0.9494323397008702
reward_mean: 1824.5151645231035
reward_std: 882.812951426952
reward_max: 3553.2189934200765
reward_min: 1069.1574872490196
total_envstep_count: 23757976
total_train_sample_count: 17813194
total_episode_count: 52006
total_duration: 4720.200966981574
[2023-06-29 14:25:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 310.375
avg_sample_per_episode: 310.375
avg_envstep_per_sec: 2737.4077160550646
avg_train_sample_per_sec: 2737.4077160550646
avg_episode_per_sec: 8.819678505211646
collect_time: 0.9070625414829703
reward_mean: 2037.502720095896
reward_std: 805.6897741620307
reward_max: 3756.418832102968
reward_min: 1008.9230116394444
total_envstep_count: 23761936
total_train_sample_count: 17816477
total_episode_count: 52014
total_duration: 4721.108029523058
[2023-06-29 14:25:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3107
train_sample_count: 3107
avg_envstep_per_episode: 310.7
avg_sample_per_episode: 310.7
avg_envstep_per_sec: 2573.3533443152965
avg_train_sample_per_sec: 2573.3533443152965
avg_episode_per_sec: 8.282437542051165
collect_time: 1.2073740308005363
reward_mean: 1705.2111190441508
reward_std: 946.0774615835371
reward_max: 3571.6285135182366
reward_min: 683.8074963077788
total_envstep_count: 23766504
total_train_sample_count: 17819984
total_episode_count: 52024
total_duration: 4722.315403553858
[2023-06-29 14:25:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2889
train_sample_count: 2889
avg_envstep_per_episode: 206.35714285714286
avg_sample_per_episode: 206.35714285714286
avg_envstep_per_sec: 2478.542813362926
avg_train_sample_per_sec: 2478.542813362926
avg_episode_per_sec: 12.010937828688462
collect_time: 1.165604235046543
reward_mean: 1123.0375564467934
reward_std: 618.1707067986008
reward_max: 3102.11109556531
reward_min: 683.8649779049342
total_envstep_count: 23771296
total_train_sample_count: 17823273
total_episode_count: 52038
total_duration: 4723.481007788905
[2023-06-29 14:25:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2226
train_sample_count: 2226
avg_envstep_per_episode: 202.36363636363637
avg_sample_per_episode: 202.36363636363637
avg_envstep_per_sec: 2671.0020644394463
avg_train_sample_per_sec: 2671.0020644394463
avg_episode_per_sec: 13.199021881776238
collect_time: 0.8333950877971945
reward_mean: 1239.0079286123962
reward_std: 592.1957334074226
reward_max: 2354.0218967808128
reward_min: 393.6291835422185
total_envstep_count: 23775840
total_train_sample_count: 17826699
total_episode_count: 52049
total_duration: 4724.314402876702
[2023-06-29 14:25:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3024
train_sample_count: 3024
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2749.6802091168706
avg_train_sample_per_sec: 2749.6802091168706
avg_episode_per_sec: 12.73000096813366
collect_time: 1.0997642525751146
reward_mean: 1409.1580016016953
reward_std: 841.0933583833579
reward_max: 3572.7512730660746
reward_min: 653.9284655088177
total_envstep_count: 23780224
total_train_sample_count: 17830123
total_episode_count: 52063
total_duration: 4725.414167129277
[2023-06-29 14:25:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2695
train_sample_count: 2695
avg_envstep_per_episode: 224.58333333333334
avg_sample_per_episode: 224.58333333333334
avg_envstep_per_sec: 2619.502786319018
avg_train_sample_per_sec: 2619.502786319018
avg_episode_per_sec: 11.663834299008615
collect_time: 1.028821199990809
reward_mean: 1318.6636770728144
reward_std: 712.0836790497725
reward_max: 3530.2774734085733
reward_min: 688.3679324052306
total_envstep_count: 23784624
total_train_sample_count: 17833618
total_episode_count: 52075
total_duration: 4726.442988329268
[2023-06-29 14:25:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2713
train_sample_count: 2713
avg_envstep_per_episode: 208.69230769230768
avg_sample_per_episode: 208.69230769230768
avg_envstep_per_sec: 2488.160726311406
avg_train_sample_per_sec: 2488.160726311406
avg_episode_per_sec: 11.922627881329996
collect_time: 1.090363645447418
reward_mean: 1234.1507583896275
reward_std: 503.268371316462
reward_max: 2475.9429896855186
reward_min: 407.00616762057535
total_envstep_count: 23789304
total_train_sample_count: 17837131
total_episode_count: 52088
total_duration: 4727.5333519747155
[2023-06-29 14:25:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2891
train_sample_count: 2891
avg_envstep_per_episode: 240.91666666666666
avg_sample_per_episode: 240.91666666666666
avg_envstep_per_sec: 2691.0899058432556
avg_train_sample_per_sec: 2691.0899058432556
avg_episode_per_sec: 11.170210608827073
collect_time: 1.0742859217459337
reward_mean: 1453.0342248049
reward_std: 642.0017316552505
reward_max: 3160.711606594171
reward_min: 905.598845627451
total_envstep_count: 23793832
total_train_sample_count: 17840422
total_episode_count: 52100
total_duration: 4728.607637896462
[2023-06-29 14:25:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 342.1666666666667
avg_sample_per_episode: 342.1666666666667
avg_envstep_per_sec: 2803.6099939789374
avg_train_sample_per_sec: 2803.6099939789374
avg_episode_per_sec: 8.19369701114156
collect_time: 0.7322701818045465
reward_mean: 2051.4084097669374
reward_std: 538.6947211135055
reward_max: 2881.861814011855
reward_min: 1344.750720868869
total_envstep_count: 23797872
total_train_sample_count: 17843675
total_episode_count: 52106
total_duration: 4729.3399080782665
[2023-06-29 14:25:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2640
train_sample_count: 2640
avg_envstep_per_episode: 264.0
avg_sample_per_episode: 264.0
avg_envstep_per_sec: 2564.837779803001
avg_train_sample_per_sec: 2564.837779803001
avg_episode_per_sec: 9.715294620465913
collect_time: 1.0293048631725832
reward_mean: 1849.3610211137282
reward_std: 904.6873960536093
reward_max: 3562.2163679115156
reward_min: 874.4826687629314
total_envstep_count: 23802616
total_train_sample_count: 17847115
total_episode_count: 52116
total_duration: 4730.369212941439
[2023-06-29 14:25:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2320
train_sample_count: 2320
avg_envstep_per_episode: 193.33333333333334
avg_sample_per_episode: 193.33333333333334
avg_envstep_per_sec: 2634.6918142003606
avg_train_sample_per_sec: 2634.6918142003606
avg_episode_per_sec: 13.627716280346693
collect_time: 0.8805583968097344
reward_mean: 1380.0007529175684
reward_std: 607.6781443127727
reward_max: 3111.365480282594
reward_min: 852.4684567377805
total_envstep_count: 23807232
total_train_sample_count: 17850635
total_episode_count: 52128
total_duration: 4731.249771338249
[2023-06-29 14:25:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 220.4
avg_sample_per_episode: 220.4
avg_envstep_per_sec: 2660.010357998393
avg_train_sample_per_sec: 2660.010357998393
avg_episode_per_sec: 12.069012513604322
collect_time: 0.8285682021398098
reward_mean: 1543.1233486459712
reward_std: 493.90513365827036
reward_max: 2402.6425056999337
reward_min: 900.9992382286772
total_envstep_count: 23812056
total_train_sample_count: 17854039
total_episode_count: 52138
total_duration: 4732.078339540389
[2023-06-29 14:25:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2042
train_sample_count: 2042
avg_envstep_per_episode: 226.88888888888889
avg_sample_per_episode: 226.88888888888889
avg_envstep_per_sec: 2624.006109531139
avg_train_sample_per_sec: 2624.006109531139
avg_episode_per_sec: 11.565159150724902
collect_time: 0.7781994076091795
reward_mean: 1865.7849441136107
reward_std: 1032.8274769638876
reward_max: 3754.5944305772127
reward_min: 899.0957184988034
total_envstep_count: 23816248
total_train_sample_count: 17857281
total_episode_count: 52147
total_duration: 4732.856538947998
[2023-06-29 14:25:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2445
train_sample_count: 2445
avg_envstep_per_episode: 244.5
avg_sample_per_episode: 244.5
avg_envstep_per_sec: 2519.552937765393
avg_train_sample_per_sec: 2519.552937765393
avg_episode_per_sec: 10.304919990860501
collect_time: 0.9704102514982225
reward_mean: 1837.2345926933278
reward_std: 931.5213833419034
reward_max: 3543.050431623815
reward_min: 874.034271891005
total_envstep_count: 23820944
total_train_sample_count: 17860526
total_episode_count: 52157
total_duration: 4733.826949199496
[2023-06-29 14:26:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 203.8
avg_sample_per_episode: 203.8
avg_envstep_per_sec: 2427.695777704976
avg_train_sample_per_sec: 2427.695777704976
avg_episode_per_sec: 11.912148075098019
collect_time: 0.8394791549732911
reward_mean: 1572.351333556666
reward_std: 644.7245056597208
reward_max: 2953.5193553572194
reward_min: 994.4984380495906
total_envstep_count: 23824592
total_train_sample_count: 17863764
total_episode_count: 52167
total_duration: 4734.66642835447
[2023-06-29 14:26:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2891
train_sample_count: 2891
avg_envstep_per_episode: 321.22222222222223
avg_sample_per_episode: 321.22222222222223
avg_envstep_per_sec: 2593.5147230835214
avg_train_sample_per_sec: 2593.5147230835214
avg_episode_per_sec: 8.073895713508023
collect_time: 1.114703523472883
reward_mean: 1822.6458480335011
reward_std: 841.8225009293944
reward_max: 3620.8198807157996
reward_min: 928.3379747906814
total_envstep_count: 23829128
total_train_sample_count: 17867055
total_episode_count: 52176
total_duration: 4735.781131877942
[2023-06-29 14:26:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1719
train_sample_count: 1719
avg_envstep_per_episode: 286.5
avg_sample_per_episode: 286.5
avg_envstep_per_sec: 2469.7763630291956
avg_train_sample_per_sec: 2469.7763630291956
avg_episode_per_sec: 8.620510865721451
collect_time: 0.6960144350444897
reward_mean: 1711.3756496065978
reward_std: 520.4467707157928
reward_max: 2332.384947697062
reward_min: 1019.0812948775604
total_envstep_count: 23833448
total_train_sample_count: 17870374
total_episode_count: 52182
total_duration: 4736.477146312986
[2023-06-29 14:26:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2198
train_sample_count: 2198
avg_envstep_per_episode: 219.8
avg_sample_per_episode: 219.8
avg_envstep_per_sec: 2529.6370346722406
avg_train_sample_per_sec: 2529.6370346722406
avg_episode_per_sec: 11.508812714614379
collect_time: 0.868899359818548
reward_mean: 1766.8854853172797
reward_std: 965.7886522114749
reward_max: 3488.2310936673534
reward_min: 1012.9321362777855
total_envstep_count: 23837952
total_train_sample_count: 17873772
total_episode_count: 52192
total_duration: 4737.346045672805
[2023-06-29 14:26:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2617
train_sample_count: 2617
avg_envstep_per_episode: 218.08333333333334
avg_sample_per_episode: 218.08333333333334
avg_envstep_per_sec: 2543.3741927365627
avg_train_sample_per_sec: 2543.3741927365627
avg_episode_per_sec: 11.662395992678164
collect_time: 1.0289480830125979
reward_mean: 1614.439475804921
reward_std: 793.5712057132172
reward_max: 3540.7524713455664
reward_min: 950.9430013917159
total_envstep_count: 23842952
total_train_sample_count: 17877189
total_episode_count: 52204
total_duration: 4738.374993755818
[2023-06-29 14:26:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2535
train_sample_count: 2535
avg_envstep_per_episode: 253.5
avg_sample_per_episode: 253.5
avg_envstep_per_sec: 2448.9895333010513
avg_train_sample_per_sec: 2448.9895333010513
avg_episode_per_sec: 9.660708218150104
collect_time: 1.035120797998272
reward_mean: 1620.2047696703526
reward_std: 719.0767287843003
reward_max: 2920.3941765237855
reward_min: 683.9230610725281
total_envstep_count: 23847664
total_train_sample_count: 17880524
total_episode_count: 52214
total_duration: 4739.410114553816
[2023-06-29 14:26:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2419
train_sample_count: 2419
avg_envstep_per_episode: 201.58333333333334
avg_sample_per_episode: 201.58333333333334
avg_envstep_per_sec: 2606.182535424141
avg_train_sample_per_sec: 2606.182535424141
avg_episode_per_sec: 12.928561564733235
collect_time: 0.928177503732033
reward_mean: 1554.7273323678853
reward_std: 1033.8337188550684
reward_max: 3638.9073821816673
reward_min: 389.9333683995431
total_envstep_count: 23851992
total_train_sample_count: 17883743
total_episode_count: 52226
total_duration: 4740.338292057548
[2023-06-29 14:26:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1699
train_sample_count: 1699
avg_envstep_per_episode: 154.45454545454547
avg_sample_per_episode: 154.45454545454547
avg_envstep_per_sec: 2503.616875886686
avg_train_sample_per_sec: 2503.616875886686
avg_episode_per_sec: 16.209408849178075
collect_time: 0.6786182088656351
reward_mean: 1057.41615302075
reward_std: 612.8825367023476
reward_max: 2223.333666434987
reward_min: 170.15611185787685
total_envstep_count: 23856456
total_train_sample_count: 17887042
total_episode_count: 52237
total_duration: 4741.016910266413
[2023-06-29 14:26:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2580
train_sample_count: 2580
avg_envstep_per_episode: 234.54545454545453
avg_sample_per_episode: 234.54545454545453
avg_envstep_per_sec: 2463.5328588217612
avg_train_sample_per_sec: 2463.5328588217612
avg_episode_per_sec: 10.503434669395107
collect_time: 1.0472764715766534
reward_mean: 1767.9425182446575
reward_std: 1082.5859315316277
reward_max: 3613.2434378431776
reward_min: 637.1405103921069
total_envstep_count: 23860408
total_train_sample_count: 17890422
total_episode_count: 52248
total_duration: 4742.06418673799
[2023-06-29 14:26:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2947
train_sample_count: 2947
avg_envstep_per_episode: 267.90909090909093
avg_sample_per_episode: 267.90909090909093
avg_envstep_per_sec: 2420.304376171611
avg_train_sample_per_sec: 2420.304376171611
avg_episode_per_sec: 9.034050946008726
collect_time: 1.2176154491202904
reward_mean: 1517.5141584679184
reward_std: 862.7987965098004
reward_max: 3566.3442581326926
reward_min: 358.72176585610896
total_envstep_count: 23864560
total_train_sample_count: 17893769
total_episode_count: 52259
total_duration: 4743.28180218711
[2023-06-29 14:26:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3041
train_sample_count: 3041
avg_envstep_per_episode: 253.41666666666666
avg_sample_per_episode: 253.41666666666666
avg_envstep_per_sec: 2513.067179854319
avg_train_sample_per_sec: 2513.067179854319
avg_episode_per_sec: 9.916739940234075
collect_time: 1.21007509245188
reward_mean: 1281.9805676025628
reward_std: 411.1075774959214
reward_max: 2277.5345964033836
reward_min: 755.9375246173048
total_envstep_count: 23868672
total_train_sample_count: 17897210
total_episode_count: 52271
total_duration: 4744.491877279562
[2023-06-29 14:26:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2730
train_sample_count: 2730
avg_envstep_per_episode: 303.3333333333333
avg_sample_per_episode: 303.3333333333333
avg_envstep_per_sec: 2603.3057386150026
avg_train_sample_per_sec: 2603.3057386150026
avg_episode_per_sec: 8.58232661081869
collect_time: 1.0486666854014621
reward_mean: 1554.7572670663028
reward_std: 611.0947010341288
reward_max: 2955.3168125597363
reward_min: 682.4188919856216
total_envstep_count: 23872976
total_train_sample_count: 17900740
total_episode_count: 52280
total_duration: 4745.540543964963
[2023-06-29 14:26:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3045
train_sample_count: 3045
avg_envstep_per_episode: 304.5
avg_sample_per_episode: 304.5
avg_envstep_per_sec: 2426.0562242555334
avg_train_sample_per_sec: 2426.0562242555334
avg_episode_per_sec: 7.967343922021457
collect_time: 1.255123426059261
reward_mean: 1700.98868283126
reward_std: 330.9191670380536
reward_max: 2327.4635365789513
reward_min: 1285.2746019953652
total_envstep_count: 23877608
total_train_sample_count: 17904185
total_episode_count: 52290
total_duration: 4746.795667391022
[2023-06-29 14:26:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2653
train_sample_count: 2653
avg_envstep_per_episode: 241.1818181818182
avg_sample_per_episode: 241.1818181818182
avg_envstep_per_sec: 2448.693006248802
avg_train_sample_per_sec: 2448.693006248802
avg_episode_per_sec: 10.152892223421341
collect_time: 1.0834351195637137
reward_mean: 1369.0387768768014
reward_std: 431.94812176759194
reward_max: 2067.819459815103
reward_min: 692.0705045425807
total_envstep_count: 23881552
total_train_sample_count: 17907638
total_episode_count: 52301
total_duration: 4747.879102510586
[2023-06-29 14:26:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 271.8888888888889
avg_sample_per_episode: 271.8888888888889
avg_envstep_per_sec: 2636.905910101537
avg_train_sample_per_sec: 2636.905910101537
avg_episode_per_sec: 9.698468815248807
collect_time: 0.9279815372349693
reward_mean: 1516.8687525148491
reward_std: 801.3311703321281
reward_max: 3222.7828121393327
reward_min: 687.1440723721184
total_envstep_count: 23885544
total_train_sample_count: 17910885
total_episode_count: 52310
total_duration: 4748.80708404782
[2023-06-29 14:26:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3189
train_sample_count: 3189
avg_envstep_per_episode: 318.9
avg_sample_per_episode: 318.9
avg_envstep_per_sec: 2682.2043973767145
avg_train_sample_per_sec: 2682.2043973767145
avg_episode_per_sec: 8.410800869792142
collect_time: 1.1889474206808954
reward_mean: 1788.8359764206646
reward_std: 869.592477901246
reward_max: 3234.234342665777
reward_min: 847.3548139784288
total_envstep_count: 23890664
total_train_sample_count: 17914474
total_episode_count: 52320
total_duration: 4749.996031468501
[2023-06-29 14:26:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2352
train_sample_count: 2352
avg_envstep_per_episode: 235.2
avg_sample_per_episode: 235.2
avg_envstep_per_sec: 2375.330825798792
avg_train_sample_per_sec: 2375.330825798792
avg_episode_per_sec: 10.099195687920034
collect_time: 0.9901778625758598
reward_mean: 1574.957680815392
reward_std: 476.75242068095446
reward_max: 2286.328268069669
reward_min: 968.7459693797261
total_envstep_count: 23894944
total_train_sample_count: 17918026
total_episode_count: 52330
total_duration: 4750.986209331078
[2023-06-29 14:26:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2781
train_sample_count: 2781
avg_envstep_per_episode: 252.8181818181818
avg_sample_per_episode: 252.8181818181818
avg_envstep_per_sec: 2484.942578148314
avg_train_sample_per_sec: 2484.942578148314
avg_episode_per_sec: 9.828971003103725
collect_time: 1.1191405485402792
reward_mean: 1562.574760644606
reward_std: 475.4377271689003
reward_max: 2570.3478809695766
reward_min: 945.8510131880573
total_envstep_count: 23899856
total_train_sample_count: 17921607
total_episode_count: 52341
total_duration: 4752.105349879618
[2023-06-29 14:26:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3072
train_sample_count: 3072
avg_envstep_per_episode: 236.30769230769232
avg_sample_per_episode: 236.30769230769232
avg_envstep_per_sec: 2765.6895928055687
avg_train_sample_per_sec: 2765.6895928055687
avg_episode_per_sec: 11.703764552888149
collect_time: 1.1107537187077108
reward_mean: 1364.1990207453673
reward_std: 606.5809171906474
reward_max: 2394.8789766938917
reward_min: 124.24883153232865
total_envstep_count: 23904488
total_train_sample_count: 17925079
total_episode_count: 52354
total_duration: 4753.216103598326
[2023-06-29 14:27:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2031
train_sample_count: 2031
avg_envstep_per_episode: 203.1
avg_sample_per_episode: 203.1
avg_envstep_per_sec: 2707.880078980234
avg_train_sample_per_sec: 2707.880078980234
avg_episode_per_sec: 13.332742880257182
collect_time: 0.7500332144564018
reward_mean: 1403.610714680462
reward_std: 861.7188193042698
reward_max: 3542.5611399259797
reward_min: 15.147930728509843
total_envstep_count: 23908896
total_train_sample_count: 17928310
total_episode_count: 52364
total_duration: 4753.966136812783
[2023-06-29 14:27:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 222.9090909090909
avg_sample_per_episode: 222.9090909090909
avg_envstep_per_sec: 2769.5890827234975
avg_train_sample_per_sec: 2769.5890827234975
avg_episode_per_sec: 12.424747108465935
collect_time: 0.8853298907391729
reward_mean: 1613.0262948758345
reward_std: 580.0524163082055
reward_max: 2829.3332714883472
reward_min: 782.5939992125807
total_envstep_count: 23912584
total_train_sample_count: 17931562
total_episode_count: 52375
total_duration: 4754.8514667035215
[2023-06-29 14:27:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1394
train_sample_count: 1394
avg_envstep_per_episode: 278.8
avg_sample_per_episode: 278.8
avg_envstep_per_sec: 2647.956596080858
avg_train_sample_per_sec: 2647.956596080858
avg_episode_per_sec: 9.497692238453581
collect_time: 0.5264436743650585
reward_mean: 1751.622979565628
reward_std: 1018.0531773071076
reward_max: 3645.3072707914157
reward_min: 649.629135781928
total_envstep_count: 23917200
total_train_sample_count: 17934956
total_episode_count: 52380
total_duration: 4755.377910377887
[2023-06-29 14:27:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2935
train_sample_count: 2935
avg_envstep_per_episode: 195.66666666666666
avg_sample_per_episode: 195.66666666666666
avg_envstep_per_sec: 2610.517976065519
avg_train_sample_per_sec: 2610.517976065519
avg_episode_per_sec: 13.341659162174716
collect_time: 1.1242979465797545
reward_mean: 1562.0021459801778
reward_std: 759.5940740660465
reward_max: 2947.382603863446
reward_min: 15.129480044245062
total_envstep_count: 23922384
total_train_sample_count: 17938291
total_episode_count: 52395
total_duration: 4756.502208324467
[2023-06-29 14:27:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2490
train_sample_count: 2490
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 2791.0443661253466
avg_train_sample_per_sec: 2791.0443661253466
avg_episode_per_sec: 11.20901351857569
collect_time: 0.8921391684850678
reward_mean: 1660.0923717882004
reward_std: 606.8040659770521
reward_max: 3019.899558407759
reward_min: 1030.9079051225501
total_envstep_count: 23926456
total_train_sample_count: 17941581
total_episode_count: 52405
total_duration: 4757.394347492952
[2023-06-29 14:27:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2661
train_sample_count: 2661
avg_envstep_per_episode: 241.9090909090909
avg_sample_per_episode: 241.9090909090909
avg_envstep_per_sec: 2763.1288471095672
avg_train_sample_per_sec: 2763.1288471095672
avg_episode_per_sec: 11.422178623902758
collect_time: 0.9630386953484267
reward_mean: 1445.052965963538
reward_std: 810.4386333627534
reward_max: 3397.813484081565
reward_min: 701.3247522073785
total_envstep_count: 23931496
total_train_sample_count: 17945042
total_episode_count: 52416
total_duration: 4758.357386188301
[2023-06-29 14:27:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2677
train_sample_count: 2677
avg_envstep_per_episode: 205.92307692307693
avg_sample_per_episode: 205.92307692307693
avg_envstep_per_sec: 2585.053548430368
avg_train_sample_per_sec: 2585.053548430368
avg_episode_per_sec: 12.553491269927079
collect_time: 1.0355684901094064
reward_mean: 1478.834964999682
reward_std: 787.6788927412985
reward_max: 3313.7891578160747
reward_min: 15.617550581795843
total_envstep_count: 23936000
total_train_sample_count: 17948519
total_episode_count: 52429
total_duration: 4759.39295467841
[2023-06-29 14:27:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2676
train_sample_count: 2676
avg_envstep_per_episode: 267.6
avg_sample_per_episode: 267.6
avg_envstep_per_sec: 2641.1779903873944
avg_train_sample_per_sec: 2641.1779903873944
avg_episode_per_sec: 9.869872908772027
collect_time: 1.0131842722222208
reward_mean: 1606.7957491056202
reward_std: 783.1556157862311
reward_max: 3653.9293768975463
reward_min: 958.2032916254929
total_envstep_count: 23940712
total_train_sample_count: 17951995
total_episode_count: 52439
total_duration: 4760.406138950632
[2023-06-29 14:27:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2411
train_sample_count: 2411
avg_envstep_per_episode: 241.1
avg_sample_per_episode: 241.1
avg_envstep_per_sec: 2513.978796544564
avg_train_sample_per_sec: 2513.978796544564
avg_episode_per_sec: 10.427120682474342
collect_time: 0.9590375238303095
reward_mean: 1679.318879811779
reward_std: 642.7357039044172
reward_max: 2959.567128808987
reward_min: 988.7666059779426
total_envstep_count: 23945384
total_train_sample_count: 17955206
total_episode_count: 52449
total_duration: 4761.365176474463
[2023-06-29 14:27:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1643
train_sample_count: 1643
avg_envstep_per_episode: 234.71428571428572
avg_sample_per_episode: 234.71428571428572
avg_envstep_per_sec: 2707.954037876108
avg_train_sample_per_sec: 2707.954037876108
avg_episode_per_sec: 11.537235706106364
collect_time: 0.6067311250558121
reward_mean: 1573.525425937363
reward_std: 848.5956613311778
reward_max: 3350.663875539951
reward_min: 954.354092759745
total_envstep_count: 23949248
total_train_sample_count: 17958449
total_episode_count: 52456
total_duration: 4761.971907599518
[2023-06-29 14:27:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2947
train_sample_count: 2947
avg_envstep_per_episode: 267.90909090909093
avg_sample_per_episode: 267.90909090909093
avg_envstep_per_sec: 2591.590835707062
avg_train_sample_per_sec: 2591.590835707062
avg_episode_per_sec: 9.673396400671082
collect_time: 1.1371393814934416
reward_mean: 1987.9837807507217
reward_std: 1058.3732858274818
reward_max: 3524.077559075979
reward_min: 975.6968671781586
total_envstep_count: 23954040
total_train_sample_count: 17961796
total_episode_count: 52467
total_duration: 4763.1090469810115
[2023-06-29 14:27:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2984
train_sample_count: 2984
avg_envstep_per_episode: 298.4
avg_sample_per_episode: 298.4
avg_envstep_per_sec: 2476.7069268799064
avg_train_sample_per_sec: 2476.7069268799064
avg_episode_per_sec: 8.299956189275825
collect_time: 1.2048256366606802
reward_mean: 1772.4511156781737
reward_std: 721.9205540809892
reward_max: 3148.2205168227274
reward_min: 935.286569620259
total_envstep_count: 23959040
total_train_sample_count: 17965180
total_episode_count: 52477
total_duration: 4764.313872617672
[2023-06-29 14:27:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1658
train_sample_count: 1658
avg_envstep_per_episode: 236.85714285714286
avg_sample_per_episode: 236.85714285714286
avg_envstep_per_sec: 2622.506199744193
avg_train_sample_per_sec: 2622.506199744193
avg_episode_per_sec: 11.07210096393809
collect_time: 0.6322196684079245
reward_mean: 1887.9961189789267
reward_std: 821.8258299517965
reward_max: 3574.050565150503
reward_min: 1007.6038210243154
total_envstep_count: 23963464
total_train_sample_count: 17968438
total_episode_count: 52484
total_duration: 4764.94609228608
[2023-06-29 14:27:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3061
train_sample_count: 3061
avg_envstep_per_episode: 278.27272727272725
avg_sample_per_episode: 278.27272727272725
avg_envstep_per_sec: 2624.6643868232763
avg_train_sample_per_sec: 2624.6643868232763
avg_episode_per_sec: 9.431985708936962
collect_time: 1.1662443455122413
reward_mean: 1953.2349722693064
reward_std: 912.0180733419394
reward_max: 3583.8135026143505
reward_min: 1015.4811974824497
total_envstep_count: 23968104
total_train_sample_count: 17971899
total_episode_count: 52495
total_duration: 4766.112336631592
[2023-06-29 14:27:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3400
train_sample_count: 3400
avg_envstep_per_episode: 309.09090909090907
avg_sample_per_episode: 309.09090909090907
avg_envstep_per_sec: 2655.3233440554195
avg_train_sample_per_sec: 2655.3233440554195
avg_episode_per_sec: 8.590751995473415
collect_time: 1.2804466949803754
reward_mean: 1655.726341808818
reward_std: 542.016732742621
reward_max: 2609.8418565290276
reward_min: 989.6204132838153
total_envstep_count: 23972384
total_train_sample_count: 17975299
total_episode_count: 52506
total_duration: 4767.3927833265725
[2023-06-29 14:27:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3061
train_sample_count: 3061
avg_envstep_per_episode: 278.27272727272725
avg_sample_per_episode: 278.27272727272725
avg_envstep_per_sec: 2499.2517457238177
avg_train_sample_per_sec: 2499.2517457238177
avg_episode_per_sec: 8.981303235204832
collect_time: 1.224766574730747
reward_mean: 1300.2395033905004
reward_std: 422.14527801594323
reward_max: 2271.6252152123166
reward_min: 641.9955892313234
total_envstep_count: 23977272
total_train_sample_count: 17978760
total_episode_count: 52517
total_duration: 4768.617549901303
[2023-06-29 14:27:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 246.23076923076923
avg_sample_per_episode: 246.23076923076923
avg_envstep_per_sec: 2459.824399194711
avg_train_sample_per_sec: 2459.824399194711
avg_episode_per_sec: 9.989914773361837
collect_time: 1.3013124030511822
reward_mean: 1406.2267485235718
reward_std: 422.76296733273296
reward_max: 2241.935954504767
reward_min: 700.1701045593683
total_envstep_count: 23981696
total_train_sample_count: 17981961
total_episode_count: 52530
total_duration: 4769.918862304355
[2023-06-29 14:27:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2949
train_sample_count: 2949
avg_envstep_per_episode: 268.09090909090907
avg_sample_per_episode: 268.09090909090907
avg_envstep_per_sec: 2470.3847016023237
avg_train_sample_per_sec: 2470.3847016023237
avg_episode_per_sec: 9.214727608553938
collect_time: 1.1937412007478998
reward_mean: 1309.9586183809236
reward_std: 436.73351250069464
reward_max: 2465.663573519163
reward_min: 876.5439094944926
total_envstep_count: 23986464
total_train_sample_count: 17985310
total_episode_count: 52541
total_duration: 4771.112603505103
[2023-06-29 14:27:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2830
train_sample_count: 2830
avg_envstep_per_episode: 283.0
avg_sample_per_episode: 283.0
avg_envstep_per_sec: 2656.73604927688
avg_train_sample_per_sec: 2656.73604927688
avg_episode_per_sec: 9.387759891437739
collect_time: 1.0652168478574602
reward_mean: 1641.0524004399908
reward_std: 814.4470039989833
reward_max: 3624.871923790945
reward_min: 988.0674488008012
total_envstep_count: 23990776
total_train_sample_count: 17988540
total_episode_count: 52551
total_duration: 4772.17782035296
[2023-06-29 14:27:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2046
train_sample_count: 2046
avg_envstep_per_episode: 292.2857142857143
avg_sample_per_episode: 292.2857142857143
avg_envstep_per_sec: 2488.105184677369
avg_train_sample_per_sec: 2488.105184677369
avg_episode_per_sec: 8.51257883320703
collect_time: 0.8223125021401793
reward_mean: 1817.857007994849
reward_std: 862.2494537615912
reward_max: 3586.61303457918
reward_min: 638.8549613757749
total_envstep_count: 23994936
total_train_sample_count: 17991786
total_episode_count: 52558
total_duration: 4773.000132855101
[2023-06-29 14:28:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3161
train_sample_count: 3161
avg_envstep_per_episode: 287.3636363636364
avg_sample_per_episode: 287.3636363636364
avg_envstep_per_sec: 2470.0748226331825
avg_train_sample_per_sec: 2470.0748226331825
avg_episode_per_sec: 8.595641584614048
collect_time: 1.2797183190711074
reward_mean: 1832.4768999833154
reward_std: 970.7355547557318
reward_max: 3556.079344183422
reward_min: 481.7369980473307
total_envstep_count: 23999848
total_train_sample_count: 17995347
total_episode_count: 52569
total_duration: 4774.279851174172
[2023-06-29 14:28:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2650
train_sample_count: 2650
avg_envstep_per_episode: 294.44444444444446
avg_sample_per_episode: 294.44444444444446
avg_envstep_per_sec: 2595.9631819956653
avg_train_sample_per_sec: 2595.9631819956653
avg_episode_per_sec: 8.816478731306034
collect_time: 1.0208157104765998
reward_mean: 1710.578408956554
reward_std: 607.7844052416475
reward_max: 2723.0657676241503
reward_min: 1023.6231875956248
total_envstep_count: 24005128
total_train_sample_count: 17998797
total_episode_count: 52578
total_duration: 4775.300666884648
[2023-06-29 14:28:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3261
train_sample_count: 3261
avg_envstep_per_episode: 232.92857142857142
avg_sample_per_episode: 232.92857142857142
avg_envstep_per_sec: 2676.1652320653184
avg_train_sample_per_sec: 2676.1652320653184
avg_episode_per_sec: 11.489209827940648
collect_time: 1.2185346259368814
reward_mean: 1607.189700091081
reward_std: 780.0757222892314
reward_max: 3682.929582590682
reward_min: 949.5180152337565
total_envstep_count: 24009760
total_train_sample_count: 18002058
total_episode_count: 52592
total_duration: 4776.519201510585
[2023-06-29 14:28:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2377
train_sample_count: 2377
avg_envstep_per_episode: 216.0909090909091
avg_sample_per_episode: 216.0909090909091
avg_envstep_per_sec: 2603.148780250411
avg_train_sample_per_sec: 2603.148780250411
avg_episode_per_sec: 12.046544628840774
collect_time: 0.913124911658466
reward_mean: 1162.0594009003873
reward_std: 181.1038115102085
reward_max: 1577.0282634259981
reward_min: 981.7853405552721
total_envstep_count: 24014264
total_train_sample_count: 18005635
total_episode_count: 52603
total_duration: 4777.432326422243
[2023-06-29 14:28:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2822
train_sample_count: 2822
avg_envstep_per_episode: 282.2
avg_sample_per_episode: 282.2
avg_envstep_per_sec: 2448.046266210958
avg_train_sample_per_sec: 2448.046266210958
avg_episode_per_sec: 8.674862743483198
collect_time: 1.1527559911552818
reward_mean: 1900.842663783169
reward_std: 759.6106268619798
reward_max: 3559.157024849777
reward_min: 1002.9871123199335
total_envstep_count: 24019376
total_train_sample_count: 18008857
total_episode_count: 52613
total_duration: 4778.585082413399
[2023-06-29 14:28:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2588
train_sample_count: 2588
avg_envstep_per_episode: 215.66666666666666
avg_sample_per_episode: 215.66666666666666
avg_envstep_per_sec: 2533.6886709915366
avg_train_sample_per_sec: 2533.6886709915366
avg_episode_per_sec: 11.748170035509442
collect_time: 1.0214356758311625
reward_mean: 1490.5413561048563
reward_std: 567.6430373147522
reward_max: 2543.0822846249052
reward_min: 1014.8573072652626
total_envstep_count: 24024016
total_train_sample_count: 18012245
total_episode_count: 52625
total_duration: 4779.60651808923
[2023-06-29 14:28:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2488
train_sample_count: 2488
avg_envstep_per_episode: 248.8
avg_sample_per_episode: 248.8
avg_envstep_per_sec: 2446.349613555327
avg_train_sample_per_sec: 2446.349613555327
avg_episode_per_sec: 9.832594909788291
collect_time: 1.0170255249756153
reward_mean: 1666.4448535112595
reward_std: 705.6892581146647
reward_max: 3612.141347380224
reward_min: 960.4621912831484
total_envstep_count: 24028528
total_train_sample_count: 18015533
total_episode_count: 52635
total_duration: 4780.623543614206
[2023-06-29 14:28:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2603
train_sample_count: 2603
avg_envstep_per_episode: 200.23076923076923
avg_sample_per_episode: 200.23076923076923
avg_envstep_per_sec: 2643.209128857345
avg_train_sample_per_sec: 2643.209128857345
avg_episode_per_sec: 13.20081393589915
collect_time: 0.984787761052139
reward_mean: 1290.8509251071794
reward_std: 404.1529620544902
reward_max: 2124.405124438086
reward_min: 822.8318442078784
total_envstep_count: 24033280
total_train_sample_count: 18018936
total_episode_count: 52648
total_duration: 4781.608331375258
[2023-06-29 14:28:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2955
train_sample_count: 2955
avg_envstep_per_episode: 227.30769230769232
avg_sample_per_episode: 227.30769230769232
avg_envstep_per_sec: 2754.668693057012
avg_train_sample_per_sec: 2754.668693057012
avg_episode_per_sec: 12.118677837475857
collect_time: 1.0727242834856734
reward_mean: 1439.4037931232835
reward_std: 367.9295611487498
reward_max: 2213.0369041331487
reward_min: 933.6493703070022
total_envstep_count: 24037576
total_train_sample_count: 18022291
total_episode_count: 52661
total_duration: 4782.681055658743
[2023-06-29 14:28:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3033
train_sample_count: 3033
avg_envstep_per_episode: 252.75
avg_sample_per_episode: 252.75
avg_envstep_per_sec: 2538.5970339788
avg_train_sample_per_sec: 2538.5970339788
avg_episode_per_sec: 10.043905178946785
collect_time: 1.1947544093858453
reward_mean: 1320.5679328948704
reward_std: 425.76227186066166
reward_max: 2447.428245081394
reward_min: 955.4267626727742
total_envstep_count: 24041688
total_train_sample_count: 18025724
total_episode_count: 52673
total_duration: 4783.875810068129
[2023-06-29 14:28:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2516
train_sample_count: 2516
avg_envstep_per_episode: 279.55555555555554
avg_sample_per_episode: 279.55555555555554
avg_envstep_per_sec: 2620.3462960625643
avg_train_sample_per_sec: 2620.3462960625643
avg_episode_per_sec: 9.373257815804084
collect_time: 0.9601784328203646
reward_mean: 1385.9829501170382
reward_std: 396.7542382641825
reward_max: 2257.284673285591
reward_min: 1011.2683594632178
total_envstep_count: 24046000
total_train_sample_count: 18029040
total_episode_count: 52682
total_duration: 4784.8359885009495
[2023-06-29 14:28:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2927
train_sample_count: 2927
avg_envstep_per_episode: 225.15384615384616
avg_sample_per_episode: 225.15384615384616
avg_envstep_per_sec: 2708.480497153387
avg_train_sample_per_sec: 2708.480497153387
avg_episode_per_sec: 12.029465822683305
collect_time: 1.0806797401998194
reward_mean: 1351.3816621961355
reward_std: 747.2914937635963
reward_max: 3458.6025810795904
reward_min: 778.6693183476403
total_envstep_count: 24050312
total_train_sample_count: 18032367
total_episode_count: 52695
total_duration: 4785.91666824115
[2023-06-29 14:28:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 284.9
avg_sample_per_episode: 284.9
avg_envstep_per_sec: 2643.182471583551
avg_train_sample_per_sec: 2643.182471583551
avg_episode_per_sec: 9.277579752838017
collect_time: 1.0778673173831779
reward_mean: 1548.763177143481
reward_std: 719.1695795954693
reward_max: 3506.164571134133
reward_min: 783.3255028309115
total_envstep_count: 24054960
total_train_sample_count: 18035616
total_episode_count: 52705
total_duration: 4786.994535558533
[2023-06-29 14:28:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3249
train_sample_count: 3249
avg_envstep_per_episode: 270.75
avg_sample_per_episode: 270.75
avg_envstep_per_sec: 2536.0994641349625
avg_train_sample_per_sec: 2536.0994641349625
avg_episode_per_sec: 9.366941695789336
collect_time: 1.281101173651405
reward_mean: 1538.4723542053373
reward_std: 520.2214151469946
reward_max: 2536.729776945992
reward_min: 1000.0221461434858
total_envstep_count: 24059400
total_train_sample_count: 18038865
total_episode_count: 52717
total_duration: 4788.2756367321845
[2023-06-29 14:28:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2846
train_sample_count: 2846
avg_envstep_per_episode: 237.16666666666666
avg_sample_per_episode: 237.16666666666666
avg_envstep_per_sec: 2708.012843419523
avg_train_sample_per_sec: 2708.012843419523
avg_episode_per_sec: 11.41818486332898
collect_time: 1.0509551337305456
reward_mean: 1185.493256878909
reward_std: 371.35187522533784
reward_max: 1861.6058964466947
reward_min: 362.92423216685853
total_envstep_count: 24063744
total_train_sample_count: 18042111
total_episode_count: 52729
total_duration: 4789.326591865915
[2023-06-29 14:28:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3325
train_sample_count: 3325
avg_envstep_per_episode: 302.27272727272725
avg_sample_per_episode: 302.27272727272725
avg_envstep_per_sec: 2664.2071805226865
avg_train_sample_per_sec: 2664.2071805226865
avg_episode_per_sec: 8.813918491954752
collect_time: 1.248026063553989
reward_mean: 1625.932420506068
reward_std: 716.4509135838666
reward_max: 3462.5722460804536
reward_min: 993.8679249595739
total_envstep_count: 24068216
total_train_sample_count: 18045436
total_episode_count: 52740
total_duration: 4790.574617929469
[2023-06-29 14:28:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2863
train_sample_count: 2863
avg_envstep_per_episode: 260.27272727272725
avg_sample_per_episode: 260.27272727272725
avg_envstep_per_sec: 2711.4858432413353
avg_train_sample_per_sec: 2711.4858432413353
avg_episode_per_sec: 10.417863875534294
collect_time: 1.0558786457013338
reward_mean: 1332.5600906296488
reward_std: 156.07264889407642
reward_max: 1650.7525080633834
reward_min: 1049.3027148310653
total_envstep_count: 24072680
total_train_sample_count: 18048699
total_episode_count: 52751
total_duration: 4791.630496575171
[2023-06-29 14:28:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3100
train_sample_count: 3100
avg_envstep_per_episode: 258.3333333333333
avg_sample_per_episode: 258.3333333333333
avg_envstep_per_sec: 2464.6652528099603
avg_train_sample_per_sec: 2464.6652528099603
avg_episode_per_sec: 9.54063968829662
collect_time: 1.2577772971261294
reward_mean: 1341.7164142304212
reward_std: 325.99347647459774
reward_max: 1948.2911630697226
reward_min: 986.1461239089765
total_envstep_count: 24077352
total_train_sample_count: 18052199
total_episode_count: 52763
total_duration: 4792.888273872297
[2023-06-29 14:28:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3366
train_sample_count: 3366
avg_envstep_per_episode: 240.42857142857142
avg_sample_per_episode: 240.42857142857142
avg_envstep_per_sec: 2565.8605377255326
avg_train_sample_per_sec: 2565.8605377255326
avg_episode_per_sec: 10.6720283803201
collect_time: 1.3118405893500895
reward_mean: 1347.7326277789834
reward_std: 765.3666976603212
reward_max: 3669.3185063990854
reward_min: 156.7493377285609
total_envstep_count: 24081728
total_train_sample_count: 18055565
total_episode_count: 52777
total_duration: 4794.200114461647
[2023-06-29 14:29:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 339.3333333333333
avg_sample_per_episode: 339.3333333333333
avg_envstep_per_sec: 2743.9584289147515
avg_train_sample_per_sec: 2743.9584289147515
avg_episode_per_sec: 8.086321499748776
collect_time: 0.7419937483547255
reward_mean: 1820.465839008416
reward_std: 539.6036077676158
reward_max: 2512.7017811938636
reward_min: 1037.5155286286752
total_envstep_count: 24085816
total_train_sample_count: 18058801
total_episode_count: 52783
total_duration: 4794.942108210002
[2023-06-29 14:29:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2686
train_sample_count: 2686
avg_envstep_per_episode: 268.6
avg_sample_per_episode: 268.6
avg_envstep_per_sec: 2726.4245185418495
avg_train_sample_per_sec: 2726.4245185418495
avg_episode_per_sec: 10.150500813633094
collect_time: 0.9851730652116241
reward_mean: 1750.9071099998969
reward_std: 759.0053785171391
reward_max: 3549.7534163566
reward_min: 1035.6400998230815
total_envstep_count: 24090480
total_train_sample_count: 18062287
total_episode_count: 52793
total_duration: 4795.927281275213
[2023-06-29 14:29:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2871
train_sample_count: 2871
avg_envstep_per_episode: 239.25
avg_sample_per_episode: 239.25
avg_envstep_per_sec: 2572.1917253170354
avg_train_sample_per_sec: 2572.1917253170354
avg_episode_per_sec: 10.751062592756679
collect_time: 1.1161687411330643
reward_mean: 1491.3492496954202
reward_std: 324.03027752466693
reward_max: 1917.8938430734793
reward_min: 719.4047420172657
total_envstep_count: 24095400
total_train_sample_count: 18065558
total_episode_count: 52805
total_duration: 4797.0434500163465
[2023-06-29 14:29:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 248.23076923076923
avg_sample_per_episode: 248.23076923076923
avg_envstep_per_sec: 2619.722426834493
avg_train_sample_per_sec: 2619.722426834493
avg_episode_per_sec: 10.553576556816985
collect_time: 1.231809892126359
reward_mean: 1487.4031352484403
reward_std: 358.58125653429175
reward_max: 2345.0904912655146
reward_min: 984.7149965989149
total_envstep_count: 24099664
total_train_sample_count: 18068785
total_episode_count: 52818
total_duration: 4798.275259908472
[2023-06-29 14:29:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1785
train_sample_count: 1785
avg_envstep_per_episode: 357.0
avg_sample_per_episode: 357.0
avg_envstep_per_sec: 2728.255331676237
avg_train_sample_per_sec: 2728.255331676237
avg_episode_per_sec: 7.642171797412428
collect_time: 0.6542642762484031
reward_mean: 1765.1227570264714
reward_std: 179.26095774766458
reward_max: 1993.0406826795495
reward_min: 1552.6039111547325
total_envstep_count: 24104072
total_train_sample_count: 18072170
total_episode_count: 52823
total_duration: 4798.929524184721
[2023-06-29 14:29:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3306
train_sample_count: 3306
avg_envstep_per_episode: 300.54545454545456
avg_sample_per_episode: 300.54545454545456
avg_envstep_per_sec: 2773.1064995650186
avg_train_sample_per_sec: 2773.1064995650186
avg_episode_per_sec: 9.226912128014279
collect_time: 1.1921648160712794
reward_mean: 2133.0454813488523
reward_std: 968.021019967403
reward_max: 3524.3179366585214
reward_min: 971.1448364819381
total_envstep_count: 24108488
total_train_sample_count: 18075876
total_episode_count: 52834
total_duration: 4800.121689000793
[2023-06-29 14:29:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2621
train_sample_count: 2621
avg_envstep_per_episode: 291.22222222222223
avg_sample_per_episode: 291.22222222222223
avg_envstep_per_sec: 2522.0330510821836
avg_train_sample_per_sec: 2522.0330510821836
avg_episode_per_sec: 8.660166905661828
collect_time: 1.0392409405084324
reward_mean: 1454.0682792881062
reward_std: 380.4336367951411
reward_max: 2203.124516176646
reward_min: 1001.6023503105746
total_envstep_count: 24113112
total_train_sample_count: 18079297
total_episode_count: 52843
total_duration: 4801.160929941301
[2023-06-29 14:29:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2760
train_sample_count: 2760
avg_envstep_per_episode: 345.0
avg_sample_per_episode: 345.0
avg_envstep_per_sec: 2632.2646288212904
avg_train_sample_per_sec: 2632.2646288212904
avg_episode_per_sec: 7.629752547308088
collect_time: 1.0485267969565464
reward_mean: 2204.992531859441
reward_std: 594.2594755981961
reward_max: 3547.598202249106
reward_min: 1470.110811253732
total_envstep_count: 24117992
total_train_sample_count: 18082857
total_episode_count: 52851
total_duration: 4802.209456738257
[2023-06-29 14:29:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1664
train_sample_count: 1664
avg_envstep_per_episode: 237.71428571428572
avg_sample_per_episode: 237.71428571428572
avg_envstep_per_sec: 2769.7066159730402
avg_train_sample_per_sec: 2769.7066159730402
avg_episode_per_sec: 11.651410043155819
collect_time: 0.6007856537597255
reward_mean: 1942.1710914710313
reward_std: 452.8536944542807
reward_max: 2745.2034273993368
reward_min: 1344.2477475477097
total_envstep_count: 24121840
total_train_sample_count: 18086121
total_episode_count: 52858
total_duration: 4802.810242392017
[2023-06-29 14:29:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2525
train_sample_count: 2525
avg_envstep_per_episode: 280.55555555555554
avg_sample_per_episode: 280.55555555555554
avg_envstep_per_sec: 2761.4849889083343
avg_train_sample_per_sec: 2761.4849889083343
avg_episode_per_sec: 9.842916792148518
collect_time: 0.9143631090307606
reward_mean: 1959.578999159694
reward_std: 963.2545396565059
reward_max: 3603.14846198456
reward_min: 130.83703974723605
total_envstep_count: 24126144
total_train_sample_count: 18089446
total_episode_count: 52867
total_duration: 4803.724605501048
[2023-06-29 14:29:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2818
train_sample_count: 2818
avg_envstep_per_episode: 313.1111111111111
avg_sample_per_episode: 313.1111111111111
avg_envstep_per_sec: 2520.945124155954
avg_train_sample_per_sec: 2520.945124155954
avg_episode_per_sec: 8.051279672605956
collect_time: 1.1178347251582892
reward_mean: 1902.0583079627113
reward_std: 1000.5112875869945
reward_max: 3586.260482004108
reward_min: 751.409763856342
total_envstep_count: 24130168
total_train_sample_count: 18092664
total_episode_count: 52876
total_duration: 4804.842440226206
[2023-06-29 14:29:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 348.57142857142856
avg_sample_per_episode: 348.57142857142856
avg_envstep_per_sec: 2478.6205352337065
avg_train_sample_per_sec: 2478.6205352337065
avg_episode_per_sec: 7.110796617473748
collect_time: 0.9844185365671292
reward_mean: 1676.6277341968157
reward_std: 294.89354833487175
reward_max: 2019.464037235642
reward_min: 1031.9785314150038
total_envstep_count: 24134136
total_train_sample_count: 18095904
total_episode_count: 52883
total_duration: 4805.826858762774
[2023-06-29 14:29:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1426
train_sample_count: 1426
avg_envstep_per_episode: 285.2
avg_sample_per_episode: 285.2
avg_envstep_per_sec: 2169.2575887786893
avg_train_sample_per_sec: 2169.2575887786893
avg_episode_per_sec: 7.606092527274506
collect_time: 0.657367759078741
reward_mean: 2312.4785177369176
reward_std: 871.4899381758997
reward_max: 3526.6385054935417
reward_min: 1285.9841363601613
total_envstep_count: 24138952
total_train_sample_count: 18099330
total_episode_count: 52888
total_duration: 4806.484226521852
[2023-06-29 14:29:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 239.33333333333334
avg_sample_per_episode: 239.33333333333334
avg_envstep_per_sec: 2643.261186124402
avg_train_sample_per_sec: 2643.261186124402
avg_episode_per_sec: 11.044266794391651
collect_time: 0.8149024437339976
reward_mean: 2193.21758119964
reward_std: 902.733360648869
reward_max: 3299.8899057508884
reward_min: 972.1716750490534
total_envstep_count: 24143376
total_train_sample_count: 18102684
total_episode_count: 52897
total_duration: 4807.2991289655865
[2023-06-29 14:29:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2959
train_sample_count: 2959
avg_envstep_per_episode: 227.6153846153846
avg_sample_per_episode: 227.6153846153846
avg_envstep_per_sec: 2664.1445316962822
avg_train_sample_per_sec: 2664.1445316962822
avg_episode_per_sec: 11.704589020632534
collect_time: 1.1106754775485026
reward_mean: 1566.3438750331904
reward_std: 687.7665520740467
reward_max: 3572.6864036018724
reward_min: 807.0940233920749
total_envstep_count: 24148768
total_train_sample_count: 18106043
total_episode_count: 52910
total_duration: 4808.409804443135
[2023-06-29 14:29:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1336
train_sample_count: 1336
avg_envstep_per_episode: 190.85714285714286
avg_sample_per_episode: 190.85714285714286
avg_envstep_per_sec: 2577.1970765957494
avg_train_sample_per_sec: 2577.1970765957494
avg_episode_per_sec: 13.503278095935812
collect_time: 0.5183926414214075
reward_mean: 1826.6197532739764
reward_std: 836.3921924618177
reward_max: 3548.168559171152
reward_min: 969.5879894322559
total_envstep_count: 24152936
total_train_sample_count: 18109379
total_episode_count: 52917
total_duration: 4808.928197084556
[2023-06-29 14:29:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3057
train_sample_count: 3057
avg_envstep_per_episode: 277.90909090909093
avg_sample_per_episode: 277.90909090909093
avg_envstep_per_sec: 2710.0242096728207
avg_train_sample_per_sec: 2710.0242096728207
avg_episode_per_sec: 9.751477365522089
collect_time: 1.1280342031959447
reward_mean: 2004.6169158515877
reward_std: 1024.724356544842
reward_max: 3595.4234678028924
reward_min: 800.0796893954623
total_envstep_count: 24157752
total_train_sample_count: 18112836
total_episode_count: 52928
total_duration: 4810.056231287752
[2023-06-29 14:29:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2060
train_sample_count: 2060
avg_envstep_per_episode: 294.2857142857143
avg_sample_per_episode: 294.2857142857143
avg_envstep_per_sec: 2681.6450691515247
avg_train_sample_per_sec: 2681.6450691515247
avg_episode_per_sec: 9.112386157311006
collect_time: 0.7681851799469444
reward_mean: 1867.388310855866
reward_std: 837.9344498676057
reward_max: 3594.613047037542
reward_min: 1104.4099132554836
total_envstep_count: 24162640
total_train_sample_count: 18116096
total_episode_count: 52935
total_duration: 4810.824416467699
[2023-06-29 14:29:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1630
train_sample_count: 1630
avg_envstep_per_episode: 232.85714285714286
avg_sample_per_episode: 232.85714285714286
avg_envstep_per_sec: 2713.614082283136
avg_train_sample_per_sec: 2713.614082283136
avg_episode_per_sec: 11.653557408577887
collect_time: 0.600674948822707
reward_mean: 2155.4955943198547
reward_std: 1193.6242088065876
reward_max: 3588.443126784743
reward_min: 662.6466658857532
total_envstep_count: 24166888
total_train_sample_count: 18119326
total_episode_count: 52942
total_duration: 4811.425091416521
[2023-06-29 14:30:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1782
train_sample_count: 1782
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 2451.6146877110614
avg_train_sample_per_sec: 2451.6146877110614
avg_episode_per_sec: 12.381892362177078
collect_time: 0.7268678919784723
reward_mean: 2091.2438684184935
reward_std: 1108.8844580909195
reward_max: 3571.9025919788146
reward_min: 678.7254084543492
total_envstep_count: 24171328
total_train_sample_count: 18122708
total_episode_count: 52951
total_duration: 4812.1519593084995
[2023-06-29 14:30:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2609
train_sample_count: 2609
avg_envstep_per_episode: 260.9
avg_sample_per_episode: 260.9
avg_envstep_per_sec: 2673.519454303127
avg_train_sample_per_sec: 2673.519454303127
avg_episode_per_sec: 10.247295723660892
collect_time: 0.9758672209400682
reward_mean: 1924.9965681365836
reward_std: 863.203396455004
reward_max: 3506.1718357430595
reward_min: 832.1419876646211
total_envstep_count: 24176248
total_train_sample_count: 18126117
total_episode_count: 52961
total_duration: 4813.1278265294395
[2023-06-29 14:30:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 239.5
avg_sample_per_episode: 239.5
avg_envstep_per_sec: 2315.8644747954872
avg_train_sample_per_sec: 2315.8644747954872
avg_episode_per_sec: 9.66958027054483
collect_time: 0.6205026311511173
reward_mean: 2126.957917449584
reward_std: 874.6269697182403
reward_max: 3507.578049004396
reward_min: 1141.5795600688732
total_envstep_count: 24180616
total_train_sample_count: 18129554
total_episode_count: 52967
total_duration: 4813.74832916059
[2023-06-29 14:30:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2873
train_sample_count: 2873
avg_envstep_per_episode: 287.3
avg_sample_per_episode: 287.3
avg_envstep_per_sec: 2814.7840427149035
avg_train_sample_per_sec: 2814.7840427149035
avg_episode_per_sec: 9.797368752923438
collect_time: 1.020682210926898
reward_mean: 2155.0398205686724
reward_std: 1023.1076026392863
reward_max: 3741.515029206491
reward_min: 1023.4595061229262
total_envstep_count: 24184752
total_train_sample_count: 18132827
total_episode_count: 52977
total_duration: 4814.769011371517
[2023-06-29 14:30:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2815
train_sample_count: 2815
avg_envstep_per_episode: 234.58333333333334
avg_sample_per_episode: 234.58333333333334
avg_envstep_per_sec: 2722.022936013408
avg_train_sample_per_sec: 2722.022936013408
avg_episode_per_sec: 11.603650171282734
collect_time: 1.0341573403943332
reward_mean: 1274.6433737920343
reward_std: 527.9843431035397
reward_max: 2935.0236091709007
reward_min: 827.4294241710279
total_envstep_count: 24189200
total_train_sample_count: 18136042
total_episode_count: 52989
total_duration: 4815.803168711911
[2023-06-29 14:30:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2695
train_sample_count: 2695
avg_envstep_per_episode: 336.875
avg_sample_per_episode: 336.875
avg_envstep_per_sec: 2781.2209077393322
avg_train_sample_per_sec: 2781.2209077393322
avg_episode_per_sec: 8.255943325385774
collect_time: 0.9689988999078051
reward_mean: 1806.86543952591
reward_std: 848.3300685354125
reward_max: 3521.94434181405
reward_min: 667.1303921809167
total_envstep_count: 24193592
total_train_sample_count: 18139537
total_episode_count: 52997
total_duration: 4816.772167611819
[2023-06-29 14:30:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2477
train_sample_count: 2477
avg_envstep_per_episode: 309.625
avg_sample_per_episode: 309.625
avg_envstep_per_sec: 2648.3270002545005
avg_train_sample_per_sec: 2648.3270002545005
avg_episode_per_sec: 8.55333710215422
collect_time: 0.935307460053824
reward_mean: 2054.8060162267197
reward_std: 869.3937595670209
reward_max: 3566.903909533081
reward_min: 804.8435742815692
total_envstep_count: 24198176
total_train_sample_count: 18142814
total_episode_count: 53005
total_duration: 4817.707475071873
[2023-06-29 14:30:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2194
train_sample_count: 2194
avg_envstep_per_episode: 313.42857142857144
avg_sample_per_episode: 313.42857142857144
avg_envstep_per_sec: 2643.514897822429
avg_train_sample_per_sec: 2643.514897822429
avg_episode_per_sec: 8.434186091502736
collect_time: 0.8299556025983766
reward_mean: 2022.6910571006554
reward_std: 1015.544775884819
reward_max: 3515.2354313366623
reward_min: 1020.8348433460858
total_envstep_count: 24202928
total_train_sample_count: 18146208
total_episode_count: 53012
total_duration: 4818.537430674472
[2023-06-29 14:30:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2236
train_sample_count: 2236
avg_envstep_per_episode: 248.44444444444446
avg_sample_per_episode: 248.44444444444446
avg_envstep_per_sec: 2639.449106145977
avg_train_sample_per_sec: 2639.449106145977
avg_episode_per_sec: 10.62390069557862
collect_time: 0.8471464726459235
reward_mean: 2094.394424701017
reward_std: 922.374578863529
reward_max: 3524.708743676813
reward_min: 990.7310776868491
total_envstep_count: 24207872
total_train_sample_count: 18149644
total_episode_count: 53021
total_duration: 4819.384577147118
[2023-06-29 14:30:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 293.90909090909093
avg_sample_per_episode: 293.90909090909093
avg_envstep_per_sec: 2629.343321137616
avg_train_sample_per_sec: 2629.343321137616
avg_episode_per_sec: 8.946110897777228
collect_time: 1.2295845787841828
reward_mean: 1961.7961645128103
reward_std: 851.9812268245316
reward_max: 3510.729499629226
reward_min: 1026.2746233653638
total_envstep_count: 24212184
total_train_sample_count: 18152877
total_episode_count: 53032
total_duration: 4820.614161725902
[2023-06-29 14:30:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1682
train_sample_count: 1682
avg_envstep_per_episode: 240.28571428571428
avg_sample_per_episode: 240.28571428571428
avg_envstep_per_sec: 2543.7568908027324
avg_train_sample_per_sec: 2543.7568908027324
avg_episode_per_sec: 10.586384206670111
collect_time: 0.6612267100214958
reward_mean: 1311.0285156684645
reward_std: 95.13831074883909
reward_max: 1426.592509771505
reward_min: 1168.5797410720631
total_envstep_count: 24217144
total_train_sample_count: 18156159
total_episode_count: 53039
total_duration: 4821.275388435924
[2023-06-29 14:30:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2085
train_sample_count: 2085
avg_envstep_per_episode: 260.625
avg_sample_per_episode: 260.625
avg_envstep_per_sec: 2539.1887041338764
avg_train_sample_per_sec: 2539.1887041338764
avg_episode_per_sec: 9.74269047149689
collect_time: 0.8211284165708348
reward_mean: 2340.533809620926
reward_std: 772.6169376896972
reward_max: 3533.7427020759433
reward_min: 1606.5040328463951
total_envstep_count: 24221904
total_train_sample_count: 18159444
total_episode_count: 53047
total_duration: 4822.0965168524945
[2023-06-29 14:30:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 256.3333333333333
avg_sample_per_episode: 256.3333333333333
avg_envstep_per_sec: 2664.28269158553
avg_train_sample_per_sec: 2664.28269158553
avg_episode_per_sec: 10.393820643376579
collect_time: 0.8658991057090459
reward_mean: 2008.2895579364163
reward_std: 971.0845216337907
reward_max: 3530.2619708056704
reward_min: 875.6991806242612
total_envstep_count: 24226496
total_train_sample_count: 18162951
total_episode_count: 53056
total_duration: 4822.962415958204
[2023-06-29 14:30:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 250.3
avg_sample_per_episode: 250.3
avg_envstep_per_sec: 2681.9667793754866
avg_train_sample_per_sec: 2681.9667793754866
avg_episode_per_sec: 10.715009106574058
collect_time: 0.9332703220816329
reward_mean: 1838.6383995709232
reward_std: 856.3058495655063
reward_max: 3462.3828558679616
reward_min: 949.4078005694557
total_envstep_count: 24230720
total_train_sample_count: 18166254
total_episode_count: 53066
total_duration: 4823.895686280285
[2023-06-29 14:30:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1895
train_sample_count: 1895
avg_envstep_per_episode: 315.8333333333333
avg_sample_per_episode: 315.8333333333333
avg_envstep_per_sec: 2453.3560059521806
avg_train_sample_per_sec: 2453.3560059521806
avg_episode_per_sec: 7.767881813041205
collect_time: 0.7724113399777562
reward_mean: 2095.994885043561
reward_std: 936.2457098277326
reward_max: 3620.476570892078
reward_min: 810.2289796466017
total_envstep_count: 24235648
total_train_sample_count: 18169749
total_episode_count: 53072
total_duration: 4824.668097620263
[2023-06-29 14:30:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2480
train_sample_count: 2480
avg_envstep_per_episode: 275.55555555555554
avg_sample_per_episode: 275.55555555555554
avg_envstep_per_sec: 2503.453130529513
avg_train_sample_per_sec: 2503.453130529513
avg_episode_per_sec: 9.085112167244201
collect_time: 0.9906316877901555
reward_mean: 2109.2964488318808
reward_std: 1131.1280906566012
reward_max: 3525.9428200471166
reward_min: 723.932372882561
total_envstep_count: 24239776
total_train_sample_count: 18173029
total_episode_count: 53081
total_duration: 4825.658729308054
[2023-06-29 14:30:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1622
train_sample_count: 1622
avg_envstep_per_episode: 202.75
avg_sample_per_episode: 202.75
avg_envstep_per_sec: 2720.823869136502
avg_train_sample_per_sec: 2720.823869136502
avg_episode_per_sec: 13.419599847775595
collect_time: 0.5961429618429392
reward_mean: 1568.250389300402
reward_std: 829.6816222049667
reward_max: 3502.0015460315612
reward_min: 641.3766694811163
total_envstep_count: 24244176
total_train_sample_count: 18176251
total_episode_count: 53089
total_duration: 4826.254872269897
[2023-06-29 14:30:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 292.6363636363636
avg_sample_per_episode: 292.6363636363636
avg_envstep_per_sec: 2715.0821475765865
avg_train_sample_per_sec: 2715.0821475765865
avg_episode_per_sec: 9.278006717409895
collect_time: 1.1855994865102693
reward_mean: 2044.2837718306755
reward_std: 873.6166304804906
reward_max: 3473.7784948026942
reward_min: 721.8370647829558
total_envstep_count: 24248656
total_train_sample_count: 18179470
total_episode_count: 53100
total_duration: 4827.440471756407
[2023-06-29 14:30:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2116
train_sample_count: 2116
avg_envstep_per_episode: 235.11111111111111
avg_sample_per_episode: 235.11111111111111
avg_envstep_per_sec: 2297.810116591445
avg_train_sample_per_sec: 2297.810116591445
avg_episode_per_sec: 9.773294446750002
collect_time: 0.9208767881738023
reward_mean: 1341.839182344535
reward_std: 463.40695734030976
reward_max: 2373.262628647823
reward_min: 658.9914338228119
total_envstep_count: 24253432
total_train_sample_count: 18182786
total_episode_count: 53109
total_duration: 4828.36134854458
[2023-06-29 14:31:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1652
train_sample_count: 1652
avg_envstep_per_episode: 183.55555555555554
avg_sample_per_episode: 183.55555555555554
avg_envstep_per_sec: 2227.5722931564087
avg_train_sample_per_sec: 2227.5722931564087
avg_episode_per_sec: 12.135684405815786
collect_time: 0.7416145393239568
reward_mean: 1627.0269736417204
reward_std: 831.4942297894049
reward_max: 3214.167390060023
reward_min: 664.733837028198
total_envstep_count: 24257248
total_train_sample_count: 18186038
total_episode_count: 53118
total_duration: 4829.102963083904
[2023-06-29 14:31:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1610
train_sample_count: 1610
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 2592.4213635287706
avg_train_sample_per_sec: 2592.4213635287706
avg_episode_per_sec: 11.271397232733785
collect_time: 0.62104101696203
reward_mean: 1877.512828338084
reward_std: 851.1888935742813
reward_max: 2860.8976619146056
reward_min: 400.79599057427447
total_envstep_count: 24261320
total_train_sample_count: 18189248
total_episode_count: 53125
total_duration: 4829.724004100866
[2023-06-29 14:31:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2017
train_sample_count: 2017
avg_envstep_per_episode: 224.11111111111111
avg_sample_per_episode: 224.11111111111111
avg_envstep_per_sec: 2369.5110622478605
avg_train_sample_per_sec: 2369.5110622478605
avg_episode_per_sec: 10.572929876167944
collect_time: 0.8512304635904728
reward_mean: 1948.0271145299787
reward_std: 775.781912429915
reward_max: 3565.420150893618
reward_min: 1011.834667507904
total_envstep_count: 24265288
total_train_sample_count: 18192465
total_episode_count: 53134
total_duration: 4830.575234564457
[2023-06-29 14:31:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2492
train_sample_count: 2492
avg_envstep_per_episode: 311.5
avg_sample_per_episode: 311.5
avg_envstep_per_sec: 2578.474006058955
avg_train_sample_per_sec: 2578.474006058955
avg_episode_per_sec: 8.277605155887496
collect_time: 0.9664631073046475
reward_mean: 1817.6673583309807
reward_std: 838.4813806372385
reward_max: 3500.2465325394123
reward_min: 990.7394045186587
total_envstep_count: 24269832
total_train_sample_count: 18195757
total_episode_count: 53142
total_duration: 4831.5416976717615
[2023-06-29 14:31:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1509
train_sample_count: 1509
avg_envstep_per_episode: 188.625
avg_sample_per_episode: 188.625
avg_envstep_per_sec: 2640.162316178593
avg_train_sample_per_sec: 2640.162316178593
avg_episode_per_sec: 13.996884380005794
collect_time: 0.5715557678984478
reward_mean: 1749.5928240280412
reward_std: 945.0283703170242
reward_max: 3539.936209115536
reward_min: 471.97186513518056
total_envstep_count: 24274568
total_train_sample_count: 18199266
total_episode_count: 53150
total_duration: 4832.11325343966
[2023-06-29 14:31:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 275.5
avg_sample_per_episode: 275.5
avg_envstep_per_sec: 2640.2004112426935
avg_train_sample_per_sec: 2640.2004112426935
avg_episode_per_sec: 9.583304578013406
collect_time: 0.834785113514401
reward_mean: 2296.4520433113876
reward_std: 1099.0656567528688
reward_max: 3533.674435796463
reward_min: 656.2066717558783
total_envstep_count: 24279112
total_train_sample_count: 18202670
total_episode_count: 53158
total_duration: 4832.948038553174
[2023-06-29 14:31:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3520
train_sample_count: 3520
avg_envstep_per_episode: 234.66666666666666
avg_sample_per_episode: 234.66666666666666
avg_envstep_per_sec: 2553.997982320489
avg_train_sample_per_sec: 2553.997982320489
avg_episode_per_sec: 10.88351412920663
collect_time: 1.3782313159080217
reward_mean: 1483.4063107274997
reward_std: 997.4983214421361
reward_max: 3467.9516349741834
reward_min: 639.1807051960475
total_envstep_count: 24283640
total_train_sample_count: 18206190
total_episode_count: 53173
total_duration: 4834.326269869082
[2023-06-29 14:31:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2855
train_sample_count: 2855
avg_envstep_per_episode: 259.54545454545456
avg_sample_per_episode: 259.54545454545456
avg_envstep_per_sec: 2524.440702174862
avg_train_sample_per_sec: 2524.440702174862
avg_episode_per_sec: 9.726391496995966
collect_time: 1.1309435779340564
reward_mean: 1272.5070222198824
reward_std: 457.73153043106095
reward_max: 2224.4652517810464
reward_min: 619.3163341247334
total_envstep_count: 24287624
total_train_sample_count: 18209445
total_episode_count: 53184
total_duration: 4835.457213447016
[2023-06-29 14:31:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3143
train_sample_count: 3143
avg_envstep_per_episode: 224.5
avg_sample_per_episode: 224.5
avg_envstep_per_sec: 2298.8685891055816
avg_train_sample_per_sec: 2298.8685891055816
avg_episode_per_sec: 10.239949171962502
collect_time: 1.367194286308833
reward_mean: 1076.74469525652
reward_std: 324.7607039811393
reward_max: 1969.6046110123075
reward_min: 624.6615076528171
total_envstep_count: 24291920
total_train_sample_count: 18212988
total_episode_count: 53198
total_duration: 4836.824407733325
[2023-06-29 14:31:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2643.508904946713
avg_train_sample_per_sec: 2643.508904946713
avg_episode_per_sec: 9.671374042487974
collect_time: 0.9305813176557421
reward_mean: 1272.4538684009026
reward_std: 619.8253503720875
reward_max: 2391.557848248728
reward_min: 620.0571871263279
total_envstep_count: 24296424
total_train_sample_count: 18216248
total_episode_count: 53207
total_duration: 4837.754989050981
[2023-06-29 14:31:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2536.4059516596158
avg_train_sample_per_sec: 2536.4059516596158
avg_episode_per_sec: 11.908009162721202
collect_time: 1.0077251231521371
reward_mean: 1426.210885639948
reward_std: 1014.5775919970722
reward_max: 3661.1072444011998
reward_min: 524.1034537592385
total_envstep_count: 24301056
total_train_sample_count: 18219604
total_episode_count: 53219
total_duration: 4838.762714174133
[2023-06-29 14:31:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3017
train_sample_count: 3017
avg_envstep_per_episode: 232.07692307692307
avg_sample_per_episode: 232.07692307692307
avg_envstep_per_sec: 2656.2555084350756
avg_train_sample_per_sec: 2656.2555084350756
avg_episode_per_sec: 11.445582237207816
collect_time: 1.1358094093054534
reward_mean: 1477.9606367730682
reward_std: 505.6073704906792
reward_max: 2838.0735635549217
reward_min: 946.4808393895995
total_envstep_count: 24305720
total_train_sample_count: 18223021
total_episode_count: 53232
total_duration: 4839.898523583439
[2023-06-29 14:31:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2445
train_sample_count: 2445
avg_envstep_per_episode: 188.07692307692307
avg_sample_per_episode: 188.07692307692307
avg_envstep_per_sec: 2715.0318392484605
avg_train_sample_per_sec: 2715.0318392484605
avg_episode_per_sec: 14.435752110523511
collect_time: 0.9005419253855943
reward_mean: 1027.068342449544
reward_std: 429.17137367646694
reward_max: 1940.1998045772054
reward_min: 597.972902210278
total_envstep_count: 24310080
total_train_sample_count: 18226266
total_episode_count: 53245
total_duration: 4840.799065508824
[2023-06-29 14:31:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3349
train_sample_count: 3349
avg_envstep_per_episode: 257.61538461538464
avg_sample_per_episode: 257.61538461538464
avg_envstep_per_sec: 2669.7951225336055
avg_train_sample_per_sec: 2669.7951225336055
avg_episode_per_sec: 10.363492562835733
collect_time: 1.2544033704061295
reward_mean: 1525.9814765282147
reward_std: 815.6320406799979
reward_max: 3494.181969296554
reward_min: 669.1808490255418
total_envstep_count: 24314720
total_train_sample_count: 18229615
total_episode_count: 53258
total_duration: 4842.05346887923
[2023-06-29 14:31:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2663
train_sample_count: 2663
avg_envstep_per_episode: 221.91666666666666
avg_sample_per_episode: 221.91666666666666
avg_envstep_per_sec: 2375.0710388574767
avg_train_sample_per_sec: 2375.0710388574767
avg_episode_per_sec: 10.70253566139306
collect_time: 1.121229620685801
reward_mean: 1089.9192139386194
reward_std: 252.10755034914317
reward_max: 1668.8716412139431
reward_min: 675.9575254605692
total_envstep_count: 24320000
total_train_sample_count: 18233078
total_episode_count: 53270
total_duration: 4843.174698499916
[2023-06-29 14:31:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 230.35714285714286
avg_sample_per_episode: 230.35714285714286
avg_envstep_per_sec: 2410.8048457417276
avg_train_sample_per_sec: 2410.8048457417276
avg_episode_per_sec: 10.465509407871064
collect_time: 1.3377275251857936
reward_mean: 1575.2251535076246
reward_std: 778.9203774094784
reward_max: 3581.982150554344
reward_min: 679.6075380820803
total_envstep_count: 24324560
total_train_sample_count: 18236303
total_episode_count: 53284
total_duration: 4844.512426025102
[2023-06-29 14:31:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2595
train_sample_count: 2595
avg_envstep_per_episode: 259.5
avg_sample_per_episode: 259.5
avg_envstep_per_sec: 2566.5923775180904
avg_train_sample_per_sec: 2566.5923775180904
avg_episode_per_sec: 9.890529393133296
collect_time: 1.0110682252198457
reward_mean: 1401.4229597972408
reward_std: 517.6363766292025
reward_max: 2233.7626438282396
reward_min: 693.1890426297153
total_envstep_count: 24328720
total_train_sample_count: 18239698
total_episode_count: 53294
total_duration: 4845.523494250322
[2023-06-29 14:31:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 2394.326337510429
avg_train_sample_per_sec: 2394.326337510429
avg_episode_per_sec: 10.01810183058757
collect_time: 1.3974703228963774
reward_mean: 1251.2373128400118
reward_std: 468.71083100412983
reward_max: 2590.99194940686
reward_min: 664.633926701205
total_envstep_count: 24333216
total_train_sample_count: 18243044
total_episode_count: 53308
total_duration: 4846.920964573218
[2023-06-29 14:31:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2125
train_sample_count: 2125
avg_envstep_per_episode: 212.5
avg_sample_per_episode: 212.5
avg_envstep_per_sec: 2377.70628971051
avg_train_sample_per_sec: 2377.70628971051
avg_episode_per_sec: 11.18920606922593
collect_time: 0.8937184584975474
reward_mean: 1051.0994793775196
reward_std: 257.8961109644527
reward_max: 1578.6891354253341
reward_min: 670.7848363134611
total_envstep_count: 24338136
total_train_sample_count: 18246369
total_episode_count: 53318
total_duration: 4847.8146830317155
[2023-06-29 14:32:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2460
train_sample_count: 2460
avg_envstep_per_episode: 189.23076923076923
avg_sample_per_episode: 189.23076923076923
avg_envstep_per_sec: 2665.2681359757885
avg_train_sample_per_sec: 2665.2681359757885
avg_episode_per_sec: 14.084750312067175
collect_time: 0.9229840580746532
reward_mean: 1465.0656153638652
reward_std: 703.877789225187
reward_max: 3097.9934869099925
reward_min: 581.5327625205668
total_envstep_count: 24342504
total_train_sample_count: 18249629
total_episode_count: 53331
total_duration: 4848.73766708979
[2023-06-29 14:32:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2358
train_sample_count: 2358
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 2553.376484410343
avg_train_sample_per_sec: 2553.376484410343
avg_episode_per_sec: 9.745711772558561
collect_time: 0.9234830877454949
reward_mean: 1771.3208643158146
reward_std: 989.6025115730846
reward_max: 3538.4565566491833
reward_min: 634.216797273503
total_envstep_count: 24347352
total_train_sample_count: 18253187
total_episode_count: 53340
total_duration: 4849.661150177536
[2023-06-29 14:32:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2441
train_sample_count: 2441
avg_envstep_per_episode: 305.125
avg_sample_per_episode: 305.125
avg_envstep_per_sec: 2693.704613984591
avg_train_sample_per_sec: 2693.704613984591
avg_episode_per_sec: 8.828200291633236
collect_time: 0.9061869617505
reward_mean: 2038.298569988932
reward_std: 803.8833914131429
reward_max: 3526.047131159113
reward_min: 1044.706011548782
total_envstep_count: 24351592
total_train_sample_count: 18256428
total_episode_count: 53348
total_duration: 4850.567337139287
[2023-06-29 14:32:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2986
train_sample_count: 2986
avg_envstep_per_episode: 271.45454545454544
avg_sample_per_episode: 271.45454545454544
avg_envstep_per_sec: 2723.457693296671
avg_train_sample_per_sec: 2723.457693296671
avg_episode_per_sec: 10.032831422057395
collect_time: 1.0964003616981208
reward_mean: 1636.0229499932423
reward_std: 784.2331663805573
reward_max: 3531.995281997625
reward_min: 970.1822922429802
total_envstep_count: 24355712
total_train_sample_count: 18259814
total_episode_count: 53359
total_duration: 4851.663737500985
[2023-06-29 14:32:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2649
train_sample_count: 2649
avg_envstep_per_episode: 331.125
avg_sample_per_episode: 331.125
avg_envstep_per_sec: 2473.846213733649
avg_train_sample_per_sec: 2473.846213733649
avg_episode_per_sec: 7.471034243061228
collect_time: 1.0708022128837185
reward_mean: 1744.9852238620274
reward_std: 811.6776019566609
reward_max: 3660.7484674028165
reward_min: 1185.1800465947472
total_envstep_count: 24360136
total_train_sample_count: 18263263
total_episode_count: 53367
total_duration: 4852.734539713869
[2023-06-29 14:32:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3251
train_sample_count: 3251
avg_envstep_per_episode: 270.9166666666667
avg_sample_per_episode: 270.9166666666667
avg_envstep_per_sec: 2605.5876484205673
avg_train_sample_per_sec: 2605.5876484205673
avg_episode_per_sec: 9.617672033542542
collect_time: 1.2477031820329143
reward_mean: 1513.0583071863377
reward_std: 863.6885502998325
reward_max: 3540.109851604526
reward_min: 640.8044253568586
total_envstep_count: 24364936
total_train_sample_count: 18266514
total_episode_count: 53379
total_duration: 4853.982242895901
[2023-06-29 14:32:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3017
train_sample_count: 3017
avg_envstep_per_episode: 232.07692307692307
avg_sample_per_episode: 232.07692307692307
avg_envstep_per_sec: 2534.451039762674
avg_train_sample_per_sec: 2534.451039762674
avg_episode_per_sec: 10.920736995994288
collect_time: 1.1903958500940353
reward_mean: 1251.3073034953682
reward_std: 268.09389653986057
reward_max: 1911.6996352054207
reward_min: 969.1217390565962
total_envstep_count: 24369592
total_train_sample_count: 18269931
total_episode_count: 53392
total_duration: 4855.172638745996
[2023-06-29 14:32:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2223
train_sample_count: 2223
avg_envstep_per_episode: 222.3
avg_sample_per_episode: 222.3
avg_envstep_per_sec: 2683.8848202742333
avg_train_sample_per_sec: 2683.8848202742333
avg_episode_per_sec: 12.073256051615985
collect_time: 0.8282769749310102
reward_mean: 1374.4190185186003
reward_std: 502.2726960724251
reward_max: 2410.143234150912
reward_min: 979.5571173797865
total_envstep_count: 24374144
total_train_sample_count: 18273354
total_episode_count: 53402
total_duration: 4856.000915720927
[2023-06-29 14:32:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2724
train_sample_count: 2724
avg_envstep_per_episode: 272.4
avg_sample_per_episode: 272.4
avg_envstep_per_sec: 2756.586672705635
avg_train_sample_per_sec: 2756.586672705635
avg_episode_per_sec: 10.119628020211582
collect_time: 0.9881786148687823
reward_mean: 1731.14733730736
reward_std: 750.5489333448663
reward_max: 3182.3797358412658
reward_min: 1019.228276840131
total_envstep_count: 24379504
total_train_sample_count: 18276878
total_episode_count: 53412
total_duration: 4856.989094335796
[2023-06-29 14:32:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2727
train_sample_count: 2727
avg_envstep_per_episode: 272.7
avg_sample_per_episode: 272.7
avg_envstep_per_sec: 2453.4982212019636
avg_train_sample_per_sec: 2453.4982212019636
avg_episode_per_sec: 8.997059850392239
collect_time: 1.1114742111628875
reward_mean: 1948.016478077339
reward_std: 938.3113345362362
reward_max: 3607.327153617371
reward_min: 914.0371688188909
total_envstep_count: 24384192
total_train_sample_count: 18280405
total_episode_count: 53422
total_duration: 4858.100568546959
[2023-06-29 14:32:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1756
train_sample_count: 1756
avg_envstep_per_episode: 250.85714285714286
avg_sample_per_episode: 250.85714285714286
avg_envstep_per_sec: 2291.1455149013204
avg_train_sample_per_sec: 2291.1455149013204
avg_episode_per_sec: 9.133267997898201
collect_time: 0.7664288403242825
reward_mean: 1854.4838546836702
reward_std: 800.3930541065716
reward_max: 3437.376451537261
reward_min: 1009.4081202517586
total_envstep_count: 24388944
total_train_sample_count: 18283761
total_episode_count: 53429
total_duration: 4858.866997387283
[2023-06-29 14:32:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 278.1111111111111
avg_sample_per_episode: 278.1111111111111
avg_envstep_per_sec: 2534.6616409767553
avg_train_sample_per_sec: 2534.6616409767553
avg_episode_per_sec: 9.113845293164522
collect_time: 0.9875085335001346
reward_mean: 2101.291886509066
reward_std: 1081.3308785784131
reward_max: 3492.714501886124
reward_min: 969.6840758762264
total_envstep_count: 24393744
total_train_sample_count: 18287064
total_episode_count: 53438
total_duration: 4859.854505920783
[2023-06-29 14:32:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2175
train_sample_count: 2175
avg_envstep_per_episode: 271.875
avg_sample_per_episode: 271.875
avg_envstep_per_sec: 2475.343835500816
avg_train_sample_per_sec: 2475.343835500816
avg_episode_per_sec: 9.104712958163923
collect_time: 0.8786658115154131
reward_mean: 1804.8476857067467
reward_std: 863.7768856675442
reward_max: 3523.1608512460866
reward_min: 1012.06192449626
total_envstep_count: 24398376
total_train_sample_count: 18290439
total_episode_count: 53446
total_duration: 4860.733171732298
[2023-06-29 14:32:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2040
train_sample_count: 2040
avg_envstep_per_episode: 226.66666666666666
avg_sample_per_episode: 226.66666666666666
avg_envstep_per_sec: 2345.511596077076
avg_train_sample_per_sec: 2345.511596077076
avg_episode_per_sec: 10.347845276810629
collect_time: 0.869746286231093
reward_mean: 2036.941907458794
reward_std: 1078.566932225878
reward_max: 3487.5347557078567
reward_min: 971.6486227511018
total_envstep_count: 24402264
total_train_sample_count: 18293679
total_episode_count: 53455
total_duration: 4861.602918018529
[2023-06-29 14:32:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3341
train_sample_count: 3341
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 2282.4224837274255
avg_train_sample_per_sec: 2282.4224837274255
avg_episode_per_sec: 8.8810213374608
collect_time: 1.4637956048101186
reward_mean: 1432.525669423467
reward_std: 729.9859032901124
reward_max: 2974.4951936976067
reward_min: 151.81601230623698
total_envstep_count: 24406872
total_train_sample_count: 18297020
total_episode_count: 53468
total_duration: 4863.066713623339
[2023-06-29 14:32:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1619
train_sample_count: 1619
avg_envstep_per_episode: 202.375
avg_sample_per_episode: 202.375
avg_envstep_per_sec: 2709.1798043746667
avg_train_sample_per_sec: 2709.1798043746667
avg_episode_per_sec: 13.3869292371818
collect_time: 0.597597840270959
reward_mean: 1133.1797436464649
reward_std: 266.69411694651546
reward_max: 1607.4913108928638
reward_min: 664.3017579137838
total_envstep_count: 24410688
total_train_sample_count: 18300239
total_episode_count: 53476
total_duration: 4863.66431146361
[2023-06-29 14:32:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3353
train_sample_count: 3353
avg_envstep_per_episode: 257.9230769230769
avg_sample_per_episode: 257.9230769230769
avg_envstep_per_sec: 2429.471210745366
avg_train_sample_per_sec: 2429.471210745366
avg_episode_per_sec: 9.419363477390325
collect_time: 1.3801357205510139
reward_mean: 1625.8524882526335
reward_std: 884.0604149984035
reward_max: 3668.135458032981
reward_min: 918.5235787379372
total_envstep_count: 24415048
total_train_sample_count: 18303592
total_episode_count: 53489
total_duration: 4865.044447184161
[2023-06-29 14:32:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2524
train_sample_count: 2524
avg_envstep_per_episode: 315.5
avg_sample_per_episode: 315.5
avg_envstep_per_sec: 2437.1190097830636
avg_train_sample_per_sec: 2437.1190097830636
avg_episode_per_sec: 7.724624436713355
collect_time: 1.035649055244401
reward_mean: 1419.7212583167184
reward_std: 660.8781877933199
reward_max: 2834.156859081792
reward_min: 913.5343619031081
total_envstep_count: 24419432
total_train_sample_count: 18306916
total_episode_count: 53497
total_duration: 4866.080096239405
[2023-06-29 14:32:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2223
train_sample_count: 2223
avg_envstep_per_episode: 202.0909090909091
avg_sample_per_episode: 202.0909090909091
avg_envstep_per_sec: 2311.23284926305
avg_train_sample_per_sec: 2311.23284926305
avg_episode_per_sec: 11.436599793924225
collect_time: 0.9618243357473983
reward_mean: 1426.8191174825752
reward_std: 900.0083273356048
reward_max: 3567.019903591352
reward_min: 932.5662546078603
total_envstep_count: 24424104
total_train_sample_count: 18310339
total_episode_count: 53508
total_duration: 4867.041920575152
[2023-06-29 14:32:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2867
train_sample_count: 2867
avg_envstep_per_episode: 204.78571428571428
avg_sample_per_episode: 204.78571428571428
avg_envstep_per_sec: 2571.8988172522177
avg_train_sample_per_sec: 2571.8988172522177
avg_episode_per_sec: 12.558975738238942
collect_time: 1.1147405880698933
reward_mean: 1308.7932845675202
reward_std: 526.0082183977224
reward_max: 2598.184515832734
reward_min: 950.8168339010448
total_envstep_count: 24428664
total_train_sample_count: 18313606
total_episode_count: 53522
total_duration: 4868.156661163222
[2023-06-29 14:33:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2572
train_sample_count: 2572
avg_envstep_per_episode: 214.33333333333334
avg_sample_per_episode: 214.33333333333334
avg_envstep_per_sec: 2526.109800412452
avg_train_sample_per_sec: 2526.109800412452
avg_episode_per_sec: 11.785893314521548
collect_time: 1.0181663519060238
reward_mean: 1265.1646545674737
reward_std: 594.7826189058275
reward_max: 3096.232234083502
reward_min: 874.9068496210571
total_envstep_count: 24432768
total_train_sample_count: 18316978
total_episode_count: 53534
total_duration: 4869.1748275151285
[2023-06-29 14:33:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3099
train_sample_count: 3099
avg_envstep_per_episode: 238.3846153846154
avg_sample_per_episode: 238.3846153846154
avg_envstep_per_sec: 2782.327451584443
avg_train_sample_per_sec: 2782.327451584443
avg_episode_per_sec: 11.671589825943132
collect_time: 1.1138157006772234
reward_mean: 1252.4145576544606
reward_std: 626.3732366211183
reward_max: 3139.6152072013647
reward_min: 683.8201185463278
total_envstep_count: 24437272
total_train_sample_count: 18320477
total_episode_count: 53547
total_duration: 4870.288643215806
[2023-06-29 14:33:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2074
train_sample_count: 2074
avg_envstep_per_episode: 188.54545454545453
avg_sample_per_episode: 188.54545454545453
avg_envstep_per_sec: 2503.938396178778
avg_train_sample_per_sec: 2503.938396178778
avg_episode_per_sec: 13.280290432963625
collect_time: 0.8282951382370667
reward_mean: 1187.030096035433
reward_std: 665.8813149666472
reward_max: 3288.1335642011436
reward_min: 894.3526468169118
total_envstep_count: 24441608
total_train_sample_count: 18323751
total_episode_count: 53558
total_duration: 4871.116938354043
[2023-06-29 14:33:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2963
train_sample_count: 2963
avg_envstep_per_episode: 296.3
avg_sample_per_episode: 296.3
avg_envstep_per_sec: 2511.4957555466635
avg_train_sample_per_sec: 2511.4957555466635
avg_episode_per_sec: 8.476192222567207
collect_time: 1.1797750378260385
reward_mean: 1884.4052186192916
reward_std: 790.9463905744105
reward_max: 3520.7354964457522
reward_min: 984.9753972196174
total_envstep_count: 24446072
total_train_sample_count: 18327114
total_episode_count: 53568
total_duration: 4872.296713391869
[2023-06-29 14:33:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2813
train_sample_count: 2813
avg_envstep_per_episode: 281.3
avg_sample_per_episode: 281.3
avg_envstep_per_sec: 2414.260255897129
avg_train_sample_per_sec: 2414.260255897129
avg_episode_per_sec: 8.58251068573455
collect_time: 1.165160215485841
reward_mean: 1529.20327620614
reward_std: 531.5645213263391
reward_max: 2250.2901008527474
reward_min: 644.139385290031
total_envstep_count: 24451056
total_train_sample_count: 18330327
total_episode_count: 53578
total_duration: 4873.461873607355
[2023-06-29 14:33:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3256
train_sample_count: 3256
avg_envstep_per_episode: 232.57142857142858
avg_sample_per_episode: 232.57142857142858
avg_envstep_per_sec: 2776.8572961330497
avg_train_sample_per_sec: 2776.8572961330497
avg_episode_per_sec: 11.939804098852179
collect_time: 1.1725485513908789
reward_mean: 1380.2777841025356
reward_std: 817.6752639471051
reward_max: 3533.369086327471
reward_min: 431.47177870176967
total_envstep_count: 24455504
total_train_sample_count: 18333583
total_episode_count: 53592
total_duration: 4874.634422158746
[2023-06-29 14:33:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3337
train_sample_count: 3337
avg_envstep_per_episode: 222.46666666666667
avg_sample_per_episode: 222.46666666666667
avg_envstep_per_sec: 2527.111784666119
avg_train_sample_per_sec: 2527.111784666119
avg_episode_per_sec: 11.359507572667601
collect_time: 1.3204797746771946
reward_mean: 1066.7909064348773
reward_std: 281.8952873634968
reward_max: 1643.1982617065655
reward_min: 343.1384853156059
total_envstep_count: 24459976
total_train_sample_count: 18336920
total_episode_count: 53607
total_duration: 4875.954901933424
[2023-06-29 14:33:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3367
train_sample_count: 3367
avg_envstep_per_episode: 224.46666666666667
avg_sample_per_episode: 224.46666666666667
avg_envstep_per_sec: 2617.345801602768
avg_train_sample_per_sec: 2617.345801602768
avg_episode_per_sec: 11.660287206427537
collect_time: 1.2864177129128949
reward_mean: 1062.2705061171357
reward_std: 263.7212087969098
reward_max: 1561.0021085450455
reward_min: 339.8731111147383
total_envstep_count: 24464584
total_train_sample_count: 18340287
total_episode_count: 53622
total_duration: 4877.241319646337
[2023-06-29 14:33:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2662
train_sample_count: 2662
avg_envstep_per_episode: 221.83333333333334
avg_sample_per_episode: 221.83333333333334
avg_envstep_per_sec: 2703.0386689306383
avg_train_sample_per_sec: 2703.0386689306383
avg_episode_per_sec: 12.18499775626133
collect_time: 0.9848175797844305
reward_mean: 1073.8896182084134
reward_std: 292.8011007679132
reward_max: 1367.3237409636015
reward_min: 204.7536371440176
total_envstep_count: 24469496
total_train_sample_count: 18343749
total_episode_count: 53634
total_duration: 4878.226137226121
[2023-06-29 14:33:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 205.75
avg_sample_per_episode: 205.75
avg_envstep_per_sec: 2756.6451993150995
avg_train_sample_per_sec: 2756.6451993150995
avg_episode_per_sec: 13.398032560462209
collect_time: 0.895653891408816
reward_mean: 1489.586723359095
reward_std: 848.5605572999693
reward_max: 3532.4411192242496
reward_min: 911.078339835755
total_envstep_count: 24473568
total_train_sample_count: 18347018
total_episode_count: 53646
total_duration: 4879.12179111753
[2023-06-29 14:33:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3334
train_sample_count: 3334
avg_envstep_per_episode: 222.26666666666668
avg_sample_per_episode: 222.26666666666668
avg_envstep_per_sec: 2687.703154119457
avg_train_sample_per_sec: 2687.703154119457
avg_episode_per_sec: 12.092245744388679
collect_time: 1.2404643700663
reward_mean: 1167.2500804053175
reward_std: 497.3844246884568
reward_max: 2795.0033196966538
reward_min: 726.0810338581733
total_envstep_count: 24477752
total_train_sample_count: 18350352
total_episode_count: 53661
total_duration: 4880.3622554875965
[2023-06-29 14:33:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3445
train_sample_count: 3445
avg_envstep_per_episode: 229.66666666666666
avg_sample_per_episode: 229.66666666666666
avg_envstep_per_sec: 2585.9978693442567
avg_train_sample_per_sec: 2585.9978693442567
avg_episode_per_sec: 11.259787529800828
collect_time: 1.3321743381302802
reward_mean: 1004.978615948721
reward_std: 172.97476981231085
reward_max: 1368.0314116533405
reward_min: 674.3340315200279
total_envstep_count: 24482184
total_train_sample_count: 18353797
total_episode_count: 53676
total_duration: 4881.694429825727
[2023-06-29 14:33:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3292
train_sample_count: 3292
avg_envstep_per_episode: 219.46666666666667
avg_sample_per_episode: 219.46666666666667
avg_envstep_per_sec: 2672.0826008274485
avg_train_sample_per_sec: 2672.0826008274485
avg_episode_per_sec: 12.175345994049735
collect_time: 1.2319978427989409
reward_mean: 1006.3434678578108
reward_std: 79.45182287226918
reward_max: 1153.0269672603617
reward_min: 804.5540231217066
total_envstep_count: 24486752
total_train_sample_count: 18357089
total_episode_count: 53691
total_duration: 4882.926427668525
[2023-06-29 14:33:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 213.375
avg_sample_per_episode: 213.375
avg_envstep_per_sec: 2752.1437454946144
avg_train_sample_per_sec: 2752.1437454946144
avg_episode_per_sec: 12.898154636178626
collect_time: 1.2404875310705972
reward_mean: 1035.5021183467175
reward_std: 212.54113648640563
reward_max: 1489.0338869938896
reward_min: 604.1225099719576
total_envstep_count: 24491416
total_train_sample_count: 18360503
total_episode_count: 53707
total_duration: 4884.166915199596
[2023-06-29 14:33:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3409
train_sample_count: 3409
avg_envstep_per_episode: 227.26666666666668
avg_sample_per_episode: 227.26666666666668
avg_envstep_per_sec: 2596.9355164149024
avg_train_sample_per_sec: 2596.9355164149024
avg_episode_per_sec: 11.426820987451903
collect_time: 1.31270105801709
reward_mean: 1096.5272756970853
reward_std: 266.7191560446006
reward_max: 1644.964711325511
reward_min: 582.102196472448
total_envstep_count: 24495792
total_train_sample_count: 18363912
total_episode_count: 53722
total_duration: 4885.479616257613
[2023-06-29 14:33:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3273
train_sample_count: 3273
avg_envstep_per_episode: 218.2
avg_sample_per_episode: 218.2
avg_envstep_per_sec: 2511.5236030373576
avg_train_sample_per_sec: 2511.5236030373576
avg_episode_per_sec: 11.510190664699163
collect_time: 1.30319300843589
reward_mean: 982.3327310425175
reward_std: 212.00854702635246
reward_max: 1478.8499324661616
reward_min: 616.0319075728938
total_envstep_count: 24500160
total_train_sample_count: 18367185
total_episode_count: 53737
total_duration: 4886.782809266049
[2023-06-29 14:33:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3259
train_sample_count: 3259
avg_envstep_per_episode: 217.26666666666668
avg_sample_per_episode: 217.26666666666668
avg_envstep_per_sec: 2579.0950088349446
avg_train_sample_per_sec: 2579.0950088349446
avg_episode_per_sec: 11.870642875889589
collect_time: 1.2636215373361483
reward_mean: 1022.4816167162433
reward_std: 277.31013008595573
reward_max: 1466.6958334613375
reward_min: 470.74812100643015
total_envstep_count: 24505080
total_train_sample_count: 18370444
total_episode_count: 53752
total_duration: 4888.046430803385
[2023-06-29 14:33:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3343
train_sample_count: 3343
avg_envstep_per_episode: 196.64705882352942
avg_sample_per_episode: 196.64705882352942
avg_envstep_per_sec: 2508.1722607451834
avg_train_sample_per_sec: 2508.1722607451834
avg_episode_per_sec: 12.754689929006316
collect_time: 1.3328430635808035
reward_mean: 1043.1879459584354
reward_std: 238.79300054341059
reward_max: 1571.15808479377
reward_min: 578.2467911498888
total_envstep_count: 24509768
total_train_sample_count: 18373787
total_episode_count: 53769
total_duration: 4889.379273866966
[2023-06-29 14:33:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3042
train_sample_count: 3042
avg_envstep_per_episode: 202.8
avg_sample_per_episode: 202.8
avg_envstep_per_sec: 2709.8694855321037
avg_train_sample_per_sec: 2709.8694855321037
avg_episode_per_sec: 13.362275569684929
collect_time: 1.1225632880997145
reward_mean: 1031.730463207092
reward_std: 212.56267330584728
reward_max: 1704.4697071224875
reward_min: 665.7630698055355
total_envstep_count: 24514424
total_train_sample_count: 18377229
total_episode_count: 53784
total_duration: 4890.501837155066
[2023-06-29 14:33:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3232
train_sample_count: 3232
avg_envstep_per_episode: 215.46666666666667
avg_sample_per_episode: 215.46666666666667
avg_envstep_per_sec: 2623.7086523315347
avg_train_sample_per_sec: 2623.7086523315347
avg_episode_per_sec: 12.176865651291157
collect_time: 1.2318440910456703
reward_mean: 1154.4894840741933
reward_std: 358.2764672397333
reward_max: 2160.8953598219814
reward_min: 639.0028847751978
total_envstep_count: 24518720
total_train_sample_count: 18380461
total_episode_count: 53799
total_duration: 4891.733681246112
[2023-06-29 14:34:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3122
train_sample_count: 3122
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2523.0888673595678
avg_train_sample_per_sec: 2523.0888673595678
avg_episode_per_sec: 11.31429985363035
collect_time: 1.2373721910426394
reward_mean: 1060.1453155248
reward_std: 206.0542059038495
reward_max: 1348.3242105122265
reward_min: 655.2550119852755
total_envstep_count: 24523792
total_train_sample_count: 18383983
total_episode_count: 53813
total_duration: 4892.971053437154
[2023-06-29 14:34:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 188.69230769230768
avg_sample_per_episode: 188.69230769230768
avg_envstep_per_sec: 2487.7487272437093
avg_train_sample_per_sec: 2487.7487272437093
avg_episode_per_sec: 13.18415550516438
collect_time: 0.9860320590808987
reward_mean: 1217.5133892072085
reward_std: 341.6926525687143
reward_max: 1890.8744542310124
reward_min: 675.5023664831361
total_envstep_count: 24527920
total_train_sample_count: 18387236
total_episode_count: 53826
total_duration: 4893.957085496235
[2023-06-29 14:34:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3301
train_sample_count: 3301
avg_envstep_per_episode: 235.78571428571428
avg_sample_per_episode: 235.78571428571428
avg_envstep_per_sec: 2742.5319558988313
avg_train_sample_per_sec: 2742.5319558988313
avg_episode_per_sec: 11.631459370670596
collect_time: 1.2036322832629083
reward_mean: 1279.9917753016432
reward_std: 474.99085628905704
reward_max: 2759.7138209550703
reward_min: 624.6823524677309
total_envstep_count: 24532520
total_train_sample_count: 18390537
total_episode_count: 53840
total_duration: 4895.160717779498
[2023-06-29 14:34:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 215.4
avg_sample_per_episode: 215.4
avg_envstep_per_sec: 2690.1857899668566
avg_train_sample_per_sec: 2690.1857899668566
avg_episode_per_sec: 12.489256220830345
collect_time: 1.2010322900559989
reward_mean: 1073.1463308587845
reward_std: 336.38752411433967
reward_max: 1609.0419764740939
reward_min: 525.0118495677499
total_envstep_count: 24536928
total_train_sample_count: 18393768
total_episode_count: 53855
total_duration: 4896.361750069554
[2023-06-29 14:34:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2513
train_sample_count: 2513
avg_envstep_per_episode: 209.41666666666666
avg_sample_per_episode: 209.41666666666666
avg_envstep_per_sec: 2379.1232697150676
avg_train_sample_per_sec: 2379.1232697150676
avg_episode_per_sec: 11.360715971580108
collect_time: 1.0562714559556916
reward_mean: 1102.065152426809
reward_std: 218.96401463339186
reward_max: 1388.6724007907185
reward_min: 528.0863771212149
total_envstep_count: 24541712
total_train_sample_count: 18397081
total_episode_count: 53867
total_duration: 4897.418021525509
[2023-06-29 14:34:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2487
train_sample_count: 2487
avg_envstep_per_episode: 191.30769230769232
avg_sample_per_episode: 191.30769230769232
avg_envstep_per_sec: 2559.8008336495423
avg_train_sample_per_sec: 2559.8008336495423
avg_episode_per_sec: 13.380543159406534
collect_time: 0.9715599617389963
reward_mean: 1330.0395122662917
reward_std: 283.17075955048955
reward_max: 1805.8439914569367
reward_min: 854.0080874504181
total_envstep_count: 24545880
total_train_sample_count: 18400368
total_episode_count: 53880
total_duration: 4898.3895814872485
[2023-06-29 14:34:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3280
train_sample_count: 3280
avg_envstep_per_episode: 252.30769230769232
avg_sample_per_episode: 252.30769230769232
avg_envstep_per_sec: 2747.0649762860526
avg_train_sample_per_sec: 2747.0649762860526
avg_episode_per_sec: 10.887757527963013
collect_time: 1.1940016083763914
reward_mean: 1384.694272064886
reward_std: 541.9164533144223
reward_max: 3005.947914533599
reward_min: 946.1547277979766
total_envstep_count: 24549984
total_train_sample_count: 18403648
total_episode_count: 53893
total_duration: 4899.583583095625
[2023-06-29 14:34:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 247.53846153846155
avg_sample_per_episode: 247.53846153846155
avg_envstep_per_sec: 2583.163393103927
avg_train_sample_per_sec: 2583.163393103927
avg_episode_per_sec: 10.435402147405547
collect_time: 1.245759369535372
reward_mean: 1107.438662050365
reward_std: 245.4933679734989
reward_max: 1653.7808973720744
reward_min: 655.0844429399243
total_envstep_count: 24554408
total_train_sample_count: 18406866
total_episode_count: 53906
total_duration: 4900.82934246516
[2023-06-29 14:34:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3394
train_sample_count: 3394
avg_envstep_per_episode: 242.42857142857142
avg_sample_per_episode: 242.42857142857142
avg_envstep_per_sec: 2539.59460841281
avg_train_sample_per_sec: 2539.59460841281
avg_episode_per_sec: 10.475640694690435
collect_time: 1.3364337712628767
reward_mean: 1187.6487437579167
reward_std: 242.34066006078845
reward_max: 1599.5095752044285
reward_min: 739.5108021829794
total_envstep_count: 24559160
total_train_sample_count: 18410260
total_episode_count: 53920
total_duration: 4902.165776236423
[2023-06-29 14:34:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2723
train_sample_count: 2723
avg_envstep_per_episode: 226.91666666666666
avg_sample_per_episode: 226.91666666666666
avg_envstep_per_sec: 2727.671643210486
avg_train_sample_per_sec: 2727.671643210486
avg_episode_per_sec: 12.020587483850838
collect_time: 0.9982873146692293
reward_mean: 1226.7823204918266
reward_std: 305.85657548031577
reward_max: 1872.8248959096322
reward_min: 843.3414182123533
total_envstep_count: 24564072
total_train_sample_count: 18413783
total_episode_count: 53932
total_duration: 4903.164063551092
[2023-06-29 14:34:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2160
train_sample_count: 2160
avg_envstep_per_episode: 270.0
avg_sample_per_episode: 270.0
avg_envstep_per_sec: 2756.7775546175762
avg_train_sample_per_sec: 2756.7775546175762
avg_episode_per_sec: 10.210287239324357
collect_time: 0.7835235006110741
reward_mean: 2007.0804065343968
reward_std: 793.8817765511025
reward_max: 3656.3067287269655
reward_min: 1058.937181245739
total_envstep_count: 24568456
total_train_sample_count: 18417143
total_episode_count: 53940
total_duration: 4903.9475870517035
[2023-06-29 14:34:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3079
train_sample_count: 3079
avg_envstep_per_episode: 219.92857142857142
avg_sample_per_episode: 219.92857142857142
avg_envstep_per_sec: 2589.6376356515225
avg_train_sample_per_sec: 2589.6376356515225
avg_episode_per_sec: 11.774903182566195
collect_time: 1.188969436345622
reward_mean: 1374.0022326904138
reward_std: 449.1558472616284
reward_max: 2496.2328629554604
reward_min: 745.984915629508
total_envstep_count: 24572880
total_train_sample_count: 18420622
total_episode_count: 53954
total_duration: 4905.136556488049
[2023-06-29 14:34:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2820
train_sample_count: 2820
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 2584.2760390006238
avg_train_sample_per_sec: 2584.2760390006238
avg_episode_per_sec: 10.996919314896271
collect_time: 1.091214698988013
reward_mean: 1248.2998443790927
reward_std: 432.70671453680234
reward_max: 2430.0001743069106
reward_min: 640.3108277707446
total_envstep_count: 24577736
total_train_sample_count: 18423842
total_episode_count: 53966
total_duration: 4906.2277711870365
[2023-06-29 14:34:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3101
train_sample_count: 3101
avg_envstep_per_episode: 238.53846153846155
avg_sample_per_episode: 238.53846153846155
avg_envstep_per_sec: 2591.8024136538065
avg_train_sample_per_sec: 2591.8024136538065
avg_episode_per_sec: 10.865343881812151
collect_time: 1.196464662454091
reward_mean: 1434.459729566485
reward_std: 414.49061655465096
reward_max: 2570.745504298408
reward_min: 914.8638010292219
total_envstep_count: 24582672
total_train_sample_count: 18427343
total_episode_count: 53979
total_duration: 4907.42423584949
[2023-06-29 14:34:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2231
train_sample_count: 2231
avg_envstep_per_episode: 223.1
avg_sample_per_episode: 223.1
avg_envstep_per_sec: 2749.5175556550503
avg_train_sample_per_sec: 2749.5175556550503
avg_episode_per_sec: 12.324148613424699
collect_time: 0.8114150773147117
reward_mean: 1477.6008413874656
reward_std: 568.5341264881572
reward_max: 2950.610682772483
reward_min: 965.5592028712706
total_envstep_count: 24587184
total_train_sample_count: 18430774
total_episode_count: 53989
total_duration: 4908.235650926805
[2023-06-29 14:34:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2789
train_sample_count: 2789
avg_envstep_per_episode: 253.54545454545453
avg_sample_per_episode: 253.54545454545453
avg_envstep_per_sec: 2733.2356927760443
avg_train_sample_per_sec: 2733.2356927760443
avg_episode_per_sec: 10.780061893344026
collect_time: 1.0204023046279327
reward_mean: 1615.3239218137708
reward_std: 576.961250560177
reward_max: 2505.093560646776
reward_min: 644.7189281443156
total_envstep_count: 24591896
total_train_sample_count: 18434363
total_episode_count: 54000
total_duration: 4909.256053231433
[2023-06-29 14:34:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3462
train_sample_count: 3462
avg_envstep_per_episode: 230.8
avg_sample_per_episode: 230.8
avg_envstep_per_sec: 2549.9008083476365
avg_train_sample_per_sec: 2549.9008083476365
avg_episode_per_sec: 11.048097089894439
collect_time: 1.3576998715661468
reward_mean: 1345.050346760914
reward_std: 582.477751464083
reward_max: 3072.57202491375
reward_min: 891.0653001398877
total_envstep_count: 24596496
total_train_sample_count: 18437825
total_episode_count: 54015
total_duration: 4910.613753102999
[2023-06-29 14:34:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2167
train_sample_count: 2167
avg_envstep_per_episode: 216.7
avg_sample_per_episode: 216.7
avg_envstep_per_sec: 2527.9511847521653
avg_train_sample_per_sec: 2527.9511847521653
avg_episode_per_sec: 11.665672287734958
collect_time: 0.8572159197814763
reward_mean: 1183.3025626438607
reward_std: 361.54116155890637
reward_max: 1930.540366856828
reward_min: 756.423550462082
total_envstep_count: 24601144
total_train_sample_count: 18441192
total_episode_count: 54025
total_duration: 4911.47096902278
[2023-06-29 14:34:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2887
train_sample_count: 2887
avg_envstep_per_episode: 222.07692307692307
avg_sample_per_episode: 222.07692307692307
avg_envstep_per_sec: 2513.3069300317766
avg_train_sample_per_sec: 2513.3069300317766
avg_episode_per_sec: 11.317280945761379
collect_time: 1.1486858073333281
reward_mean: 1502.0130067141051
reward_std: 574.4735720250993
reward_max: 2579.8776149426026
reward_min: 771.3771205626329
total_envstep_count: 24605352
total_train_sample_count: 18444479
total_episode_count: 54038
total_duration: 4912.619654830113
[2023-06-29 14:34:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 289.5
avg_sample_per_episode: 289.5
avg_envstep_per_sec: 2736.9758460033413
avg_train_sample_per_sec: 2736.9758460033413
avg_episode_per_sec: 9.454148000011541
collect_time: 1.0577367733176795
reward_mean: 1531.8775233385354
reward_std: 617.4167098470413
reward_max: 2915.0849045408586
reward_min: 979.4374459865298
total_envstep_count: 24609744
total_train_sample_count: 18447774
total_episode_count: 54048
total_duration: 4913.677391603431
[2023-06-29 14:35:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2821
train_sample_count: 2821
avg_envstep_per_episode: 256.45454545454544
avg_sample_per_episode: 256.45454545454544
avg_envstep_per_sec: 2604.2414523164466
avg_train_sample_per_sec: 2604.2414523164466
avg_episode_per_sec: 10.154787655257325
collect_time: 1.083232892054133
reward_mean: 1350.4743623916359
reward_std: 601.4027520961541
reward_max: 2951.018187180866
reward_min: 655.7497528790853
total_envstep_count: 24614408
total_train_sample_count: 18450995
total_episode_count: 54059
total_duration: 4914.760624495485
[2023-06-29 14:35:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2719
train_sample_count: 2719
avg_envstep_per_episode: 271.9
avg_sample_per_episode: 271.9
avg_envstep_per_sec: 2534.068714672452
avg_train_sample_per_sec: 2534.068714672452
avg_episode_per_sec: 9.31985551552943
collect_time: 1.0729780073668806
reward_mean: 1573.1658131052359
reward_std: 761.4369975144205
reward_max: 3372.618583340613
reward_min: 836.7435205983602
total_envstep_count: 24618736
total_train_sample_count: 18454514
total_episode_count: 54069
total_duration: 4915.833602502852
[2023-06-29 14:35:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2909
train_sample_count: 2909
avg_envstep_per_episode: 264.45454545454544
avg_sample_per_episode: 264.45454545454544
avg_envstep_per_sec: 2770.876990121586
avg_train_sample_per_sec: 2770.876990121586
avg_episode_per_sec: 10.477706047211223
collect_time: 1.0498481204221026
reward_mean: 1593.9935620796155
reward_std: 782.6092567137417
reward_max: 3546.8454001828486
reward_min: 974.3816859999246
total_envstep_count: 24623592
total_train_sample_count: 18457823
total_episode_count: 54080
total_duration: 4916.883450623274
[2023-06-29 14:35:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2959
train_sample_count: 2959
avg_envstep_per_episode: 246.58333333333334
avg_sample_per_episode: 246.58333333333334
avg_envstep_per_sec: 2687.6435343214043
avg_train_sample_per_sec: 2687.6435343214043
avg_episode_per_sec: 10.899534441316948
collect_time: 1.100964455372654
reward_mean: 1508.1325741238707
reward_std: 763.9886593010235
reward_max: 3655.0006481914074
reward_min: 649.6327302649331
total_envstep_count: 24627936
total_train_sample_count: 18461182
total_episode_count: 54092
total_duration: 4917.984415078647
[2023-06-29 14:35:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 282.9
avg_sample_per_episode: 282.9
avg_envstep_per_sec: 2756.592375054413
avg_train_sample_per_sec: 2756.592375054413
avg_episode_per_sec: 9.744052227127652
collect_time: 1.0262670772802083
reward_mean: 1424.0051174503633
reward_std: 573.2371328046901
reward_max: 2442.9148135443443
reward_min: 760.9484914147672
total_envstep_count: 24632248
total_train_sample_count: 18464411
total_episode_count: 54102
total_duration: 4919.010682155927
[2023-06-29 14:35:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1731
train_sample_count: 1731
avg_envstep_per_episode: 216.375
avg_sample_per_episode: 216.375
avg_envstep_per_sec: 2450.560976642942
avg_train_sample_per_sec: 2450.560976642942
avg_episode_per_sec: 11.325527332838554
collect_time: 0.7063688749223948
reward_mean: 1537.3230702304672
reward_std: 559.5094734663958
reward_max: 2770.31604267007
reward_min: 776.6623088065257
total_envstep_count: 24635888
total_train_sample_count: 18467742
total_episode_count: 54110
total_duration: 4919.717051030849
[2023-06-29 14:35:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1741
train_sample_count: 1741
avg_envstep_per_episode: 348.2
avg_sample_per_episode: 348.2
avg_envstep_per_sec: 2380.640362437058
avg_train_sample_per_sec: 2380.640362437058
avg_episode_per_sec: 6.836991276384428
collect_time: 0.7313158373143523
reward_mean: 2337.578457370145
reward_std: 777.9358404351034
reward_max: 3264.7292818371193
reward_min: 1137.8103912693548
total_envstep_count: 24640192
total_train_sample_count: 18471083
total_episode_count: 54115
total_duration: 4920.448366868163
[2023-06-29 14:35:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2297
train_sample_count: 2297
avg_envstep_per_episode: 191.41666666666666
avg_sample_per_episode: 191.41666666666666
avg_envstep_per_sec: 2675.9617644603773
avg_train_sample_per_sec: 2675.9617644603773
avg_episode_per_sec: 13.979774128656738
collect_time: 0.85838296739012
reward_mean: 1609.1372950369998
reward_std: 817.5337373869347
reward_max: 3591.027114053984
reward_min: 683.2738756324533
total_envstep_count: 24644232
total_train_sample_count: 18474580
total_episode_count: 54127
total_duration: 4921.306749835553
[2023-06-29 14:35:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3156
train_sample_count: 3156
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2565.0503553954295
avg_train_sample_per_sec: 2565.0503553954295
avg_episode_per_sec: 9.753043176408477
collect_time: 1.2303852021312343
reward_mean: 1490.5403680908876
reward_std: 647.9908057593556
reward_max: 3118.0597774581815
reward_min: 867.371080253271
total_envstep_count: 24648984
total_train_sample_count: 18478136
total_episode_count: 54139
total_duration: 4922.5371350376845
[2023-06-29 14:35:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2063
train_sample_count: 2063
avg_envstep_per_episode: 257.875
avg_sample_per_episode: 257.875
avg_envstep_per_sec: 2629.0164478201314
avg_train_sample_per_sec: 2629.0164478201314
avg_episode_per_sec: 10.194925633815341
collect_time: 0.7847041054880246
reward_mean: 1394.7423340046641
reward_std: 347.8313867468879
reward_max: 1913.8728154822013
reward_min: 937.607933143753
total_envstep_count: 24652944
total_train_sample_count: 18481399
total_episode_count: 54147
total_duration: 4923.321839143173
[2023-06-29 14:35:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1879
train_sample_count: 1879
avg_envstep_per_episode: 208.77777777777777
avg_sample_per_episode: 208.77777777777777
avg_envstep_per_sec: 2623.6039655975364
avg_train_sample_per_sec: 2623.6039655975364
avg_episode_per_sec: 12.566490521755098
collect_time: 0.7161904100766405
reward_mean: 1750.1931159762885
reward_std: 938.3525725058222
reward_max: 3505.3811693933653
reward_min: 705.0645591671904
total_envstep_count: 24657384
total_train_sample_count: 18484878
total_episode_count: 54156
total_duration: 4924.0380295532495
[2023-06-29 14:35:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2200
train_sample_count: 2200
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2489.6540967690357
avg_train_sample_per_sec: 2489.6540967690357
avg_episode_per_sec: 9.053287624614676
collect_time: 0.8836568914754318
reward_mean: 1756.0172578539737
reward_std: 955.2733018612583
reward_max: 3494.858438572565
reward_min: 809.0315345072983
total_envstep_count: 24661688
total_train_sample_count: 18488278
total_episode_count: 54164
total_duration: 4924.921686444725
[2023-06-29 14:35:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2977
train_sample_count: 2977
avg_envstep_per_episode: 212.64285714285714
avg_sample_per_episode: 212.64285714285714
avg_envstep_per_sec: 2722.7706475953555
avg_train_sample_per_sec: 2722.7706475953555
avg_episode_per_sec: 12.804430321241174
collect_time: 1.0933715634951369
reward_mean: 1479.6790836860278
reward_std: 1048.930800671524
reward_max: 3573.251426618618
reward_min: 15.600102259294957
total_envstep_count: 24666112
total_train_sample_count: 18491655
total_episode_count: 54178
total_duration: 4926.015058008221
[2023-06-29 14:35:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2163
train_sample_count: 2163
avg_envstep_per_episode: 309.0
avg_sample_per_episode: 309.0
avg_envstep_per_sec: 2518.7685590600495
avg_train_sample_per_sec: 2518.7685590600495
avg_episode_per_sec: 8.151354560064885
collect_time: 0.8587529776087031
reward_mean: 1509.648685927242
reward_std: 857.0309152949893
reward_max: 3479.1659497720484
reward_min: 860.5610952907866
total_envstep_count: 24670760
total_train_sample_count: 18495018
total_episode_count: 54185
total_duration: 4926.87381098583
[2023-06-29 14:35:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2044
train_sample_count: 2044
avg_envstep_per_episode: 185.8181818181818
avg_sample_per_episode: 185.8181818181818
avg_envstep_per_sec: 2743.0109775410774
avg_train_sample_per_sec: 2743.0109775410774
avg_episode_per_sec: 14.76180075976118
collect_time: 0.7451665402492508
reward_mean: 1645.561433768076
reward_std: 1000.4797886707436
reward_max: 3527.57603364134
reward_min: 822.7242838789209
total_envstep_count: 24674984
total_train_sample_count: 18498262
total_episode_count: 54196
total_duration: 4927.618977526079
[2023-06-29 14:35:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2637
train_sample_count: 2637
avg_envstep_per_episode: 219.75
avg_sample_per_episode: 219.75
avg_envstep_per_sec: 2547.047471145425
avg_train_sample_per_sec: 2547.047471145425
avg_episode_per_sec: 11.590659709421729
collect_time: 1.0353163927542044
reward_mean: 1457.654671626895
reward_std: 501.8400694740585
reward_max: 2468.434223309851
reward_min: 813.0468185000284
total_envstep_count: 24679184
total_train_sample_count: 18501699
total_episode_count: 54208
total_duration: 4928.654293918833
[2023-06-29 14:35:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2655
train_sample_count: 2655
avg_envstep_per_episode: 265.5
avg_sample_per_episode: 265.5
avg_envstep_per_sec: 2781.218520019047
avg_train_sample_per_sec: 2781.218520019047
avg_episode_per_sec: 10.475399322105638
collect_time: 0.9546175465499983
reward_mean: 1520.512409305317
reward_std: 482.45553502940066
reward_max: 2370.1858713089014
reward_min: 972.5129499780672
total_envstep_count: 24683864
total_train_sample_count: 18505154
total_episode_count: 54218
total_duration: 4929.608911465383
[2023-06-29 14:35:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2071
train_sample_count: 2071
avg_envstep_per_episode: 207.1
avg_sample_per_episode: 207.1
avg_envstep_per_sec: 2489.1877862707865
avg_train_sample_per_sec: 2489.1877862707865
avg_episode_per_sec: 12.019255365865702
collect_time: 0.8319982973653824
reward_mean: 1462.1509666527625
reward_std: 588.9916291875666
reward_max: 2664.95904104167
reward_min: 988.5402929713849
total_envstep_count: 24688648
total_train_sample_count: 18508425
total_episode_count: 54228
total_duration: 4930.440909762749
[2023-06-29 14:35:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2879
train_sample_count: 2879
avg_envstep_per_episode: 221.46153846153845
avg_sample_per_episode: 221.46153846153845
avg_envstep_per_sec: 2572.378321609516
avg_train_sample_per_sec: 2572.378321609516
avg_episode_per_sec: 11.615463070831439
collect_time: 1.1191977384565397
reward_mean: 1545.447405595057
reward_std: 781.5711677517611
reward_max: 3520.58943181631
reward_min: 985.5361801373214
total_envstep_count: 24692824
total_train_sample_count: 18511704
total_episode_count: 54241
total_duration: 4931.5601075012055
[2023-06-29 14:36:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2907
train_sample_count: 2907
avg_envstep_per_episode: 223.6153846153846
avg_sample_per_episode: 223.6153846153846
avg_envstep_per_sec: 2782.6760564644765
avg_train_sample_per_sec: 2782.6760564644765
avg_episode_per_sec: 12.44402777228696
collect_time: 1.0446778356563298
reward_mean: 1142.0012831269246
reward_std: 168.98634436375357
reward_max: 1588.2060527568844
reward_min: 983.9426798207353
total_envstep_count: 24697392
total_train_sample_count: 18515011
total_episode_count: 54254
total_duration: 4932.604785336862
[2023-06-29 14:36:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 205.5625
avg_sample_per_episode: 205.5625
avg_envstep_per_sec: 2738.0353709956166
avg_train_sample_per_sec: 2738.0353709956166
avg_episode_per_sec: 13.319722084502846
collect_time: 1.2012262642187999
reward_mean: 1102.4822280779804
reward_std: 241.69695377163936
reward_max: 1620.2527232976997
reward_min: 536.664043987723
total_envstep_count: 24702032
total_train_sample_count: 18518300
total_episode_count: 54270
total_duration: 4933.80601160108
[2023-06-29 14:36:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3017
train_sample_count: 3017
avg_envstep_per_episode: 232.07692307692307
avg_sample_per_episode: 232.07692307692307
avg_envstep_per_sec: 2619.6500665131534
avg_train_sample_per_sec: 2619.6500665131534
avg_episode_per_sec: 11.287852457630427
collect_time: 1.1516805387735367
reward_mean: 1146.5015335290793
reward_std: 177.14998403219008
reward_max: 1507.8377604736131
reward_min: 945.9297821086651
total_envstep_count: 24705760
total_train_sample_count: 18521717
total_episode_count: 54283
total_duration: 4934.957692139854
[2023-06-29 14:36:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3030
train_sample_count: 3030
avg_envstep_per_episode: 275.45454545454544
avg_sample_per_episode: 275.45454545454544
avg_envstep_per_sec: 2629.259670447565
avg_train_sample_per_sec: 2629.259670447565
avg_episode_per_sec: 9.545167120436703
collect_time: 1.1524156529903413
reward_mean: 1274.7965337397318
reward_std: 420.26510109037525
reward_max: 2529.4626008419423
reward_min: 1030.3279062879587
total_envstep_count: 24710472
total_train_sample_count: 18525147
total_episode_count: 54294
total_duration: 4936.110107792844
[2023-06-29 14:36:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3258
train_sample_count: 3258
avg_envstep_per_episode: 250.6153846153846
avg_sample_per_episode: 250.6153846153846
avg_envstep_per_sec: 2700.2002306504005
avg_train_sample_per_sec: 2700.2002306504005
avg_episode_per_sec: 10.77427961892425
collect_time: 1.2065771875055509
reward_mean: 1368.5006675038424
reward_std: 660.919733207775
reward_max: 3300.943927674423
reward_min: 718.751895845698
total_envstep_count: 24715104
total_train_sample_count: 18528405
total_episode_count: 54307
total_duration: 4937.31668498035
[2023-06-29 14:36:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2106
train_sample_count: 2106
avg_envstep_per_episode: 191.45454545454547
avg_sample_per_episode: 191.45454545454547
avg_envstep_per_sec: 2498.932760366961
avg_train_sample_per_sec: 2498.932760366961
avg_episode_per_sec: 13.052355348545378
collect_time: 0.8427597706513481
reward_mean: 1129.0115895828612
reward_std: 342.1297463685504
reward_max: 1880.6565689105887
reward_min: 729.9902011421387
total_envstep_count: 24719568
total_train_sample_count: 18531711
total_episode_count: 54318
total_duration: 4938.1594447510015
[2023-06-29 14:36:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2553
train_sample_count: 2553
avg_envstep_per_episode: 255.3
avg_sample_per_episode: 255.3
avg_envstep_per_sec: 2478.659586698652
avg_train_sample_per_sec: 2478.659586698652
avg_episode_per_sec: 9.708811542102046
collect_time: 1.0299921835577117
reward_mean: 1607.0061349042203
reward_std: 705.5460228125969
reward_max: 2986.0232432680973
reward_min: 994.6243781108561
total_envstep_count: 24724072
total_train_sample_count: 18535064
total_episode_count: 54328
total_duration: 4939.189436934559
[2023-06-29 14:36:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2933
train_sample_count: 2933
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 2529.2216260631394
avg_train_sample_per_sec: 2529.2216260631394
avg_episode_per_sec: 12.0726569263157
collect_time: 1.1596453113384777
reward_mean: 1342.7297055288675
reward_std: 685.0911146064761
reward_max: 3500.1596688793875
reward_min: 865.888997524492
total_envstep_count: 24728336
total_train_sample_count: 18538397
total_episode_count: 54342
total_duration: 4940.349082245898
[2023-06-29 14:36:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3261
train_sample_count: 3261
avg_envstep_per_episode: 250.84615384615384
avg_sample_per_episode: 250.84615384615384
avg_envstep_per_sec: 2544.3618694485767
avg_train_sample_per_sec: 2544.3618694485767
avg_episode_per_sec: 10.143116928191198
collect_time: 1.2816573142195122
reward_mean: 1245.1666883012297
reward_std: 342.13509603890475
reward_max: 1897.5082935695834
reward_min: 596.9108723354848
total_envstep_count: 24732944
total_train_sample_count: 18541658
total_episode_count: 54355
total_duration: 4941.630739560118
[2023-06-29 14:36:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3427
train_sample_count: 3427
avg_envstep_per_episode: 244.78571428571428
avg_sample_per_episode: 244.78571428571428
avg_envstep_per_sec: 2683.197140992366
avg_train_sample_per_sec: 2683.197140992366
avg_episode_per_sec: 10.961412306359241
collect_time: 1.2772076817033813
reward_mean: 1176.0685613752992
reward_std: 396.07489105925106
reward_max: 2028.2622551480858
reward_min: 550.3250494372625
total_envstep_count: 24737320
total_train_sample_count: 18545085
total_episode_count: 54369
total_duration: 4942.907947241822
[2023-06-29 14:36:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2993
train_sample_count: 2993
avg_envstep_per_episode: 249.41666666666666
avg_sample_per_episode: 249.41666666666666
avg_envstep_per_sec: 2500.857377089802
avg_train_sample_per_sec: 2500.857377089802
avg_episode_per_sec: 10.026825434372745
collect_time: 1.1967895600199698
reward_mean: 1178.364082997354
reward_std: 258.81375032278834
reward_max: 1743.8594915071435
reward_min: 895.2674925771772
total_envstep_count: 24741920
total_train_sample_count: 18548478
total_episode_count: 54381
total_duration: 4944.104736801842
[2023-06-29 14:36:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3024
train_sample_count: 3024
avg_envstep_per_episode: 232.6153846153846
avg_sample_per_episode: 232.6153846153846
avg_envstep_per_sec: 2451.5109622488076
avg_train_sample_per_sec: 2451.5109622488076
avg_episode_per_sec: 10.53890294617543
collect_time: 1.2335249756444244
reward_mean: 1277.8896594847813
reward_std: 433.99800120498224
reward_max: 2263.5872816544206
reward_min: 650.6275179657622
total_envstep_count: 24746616
total_train_sample_count: 18551902
total_episode_count: 54394
total_duration: 4945.338261777486
[2023-06-29 14:36:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3262
train_sample_count: 3262
avg_envstep_per_episode: 233.0
avg_sample_per_episode: 233.0
avg_envstep_per_sec: 2494.9360369459064
avg_train_sample_per_sec: 2494.9360369459064
avg_episode_per_sec: 10.707879986892301
collect_time: 1.3074483480518682
reward_mean: 1265.2720591441544
reward_std: 529.6826630209953
reward_max: 2796.0269444575665
reward_min: 375.8872584033182
total_envstep_count: 24750248
total_train_sample_count: 18555164
total_episode_count: 54408
total_duration: 4946.645710125538
[2023-06-29 14:36:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3292
train_sample_count: 3292
avg_envstep_per_episode: 253.23076923076923
avg_sample_per_episode: 253.23076923076923
avg_envstep_per_sec: 2732.4734535720254
avg_train_sample_per_sec: 2732.4734535720254
avg_episode_per_sec: 10.790448024433879
collect_time: 1.2047692524502054
reward_mean: 987.0163479978369
reward_std: 359.86314439477644
reward_max: 1785.8152322974627
reward_min: 522.2618807061868
total_envstep_count: 24754808
total_train_sample_count: 18558456
total_episode_count: 54421
total_duration: 4947.850479377988
[2023-06-29 14:36:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2874
train_sample_count: 2874
avg_envstep_per_episode: 261.27272727272725
avg_sample_per_episode: 261.27272727272725
avg_envstep_per_sec: 2679.889767257038
avg_train_sample_per_sec: 2679.889767257038
avg_episode_per_sec: 10.257058956098614
collect_time: 1.0724321705745534
reward_mean: 1359.7644829370106
reward_std: 444.3074960424618
reward_max: 2196.7946689345426
reward_min: 689.8785389192446
total_envstep_count: 24758840
total_train_sample_count: 18561730
total_episode_count: 54432
total_duration: 4948.922911548563
[2023-06-29 14:36:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3357
train_sample_count: 3357
avg_envstep_per_episode: 279.75
avg_sample_per_episode: 279.75
avg_envstep_per_sec: 2578.7567202377636
avg_train_sample_per_sec: 2578.7567202377636
avg_episode_per_sec: 9.218075854290486
collect_time: 1.3017901121322069
reward_mean: 1352.7978620218744
reward_std: 542.7065606923347
reward_max: 2719.7372753762743
reward_min: 726.7266665361516
total_envstep_count: 24763560
total_train_sample_count: 18565087
total_episode_count: 54444
total_duration: 4950.224701660695
[2023-06-29 14:36:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2791
train_sample_count: 2791
avg_envstep_per_episode: 232.58333333333334
avg_sample_per_episode: 232.58333333333334
avg_envstep_per_sec: 2530.4094125776924
avg_train_sample_per_sec: 2530.4094125776924
avg_episode_per_sec: 10.879581852716699
collect_time: 1.1029835670571775
reward_mean: 1246.742049134636
reward_std: 270.1382636405174
reward_max: 1899.6239826072162
reward_min: 939.9715771403122
total_envstep_count: 24768384
total_train_sample_count: 18568678
total_episode_count: 54456
total_duration: 4951.327685227752
[2023-06-29 14:36:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2118
train_sample_count: 2118
avg_envstep_per_episode: 192.54545454545453
avg_sample_per_episode: 192.54545454545453
avg_envstep_per_sec: 2740.7359377298903
avg_train_sample_per_sec: 2740.7359377298903
avg_episode_per_sec: 14.234228194064587
collect_time: 0.7727851380510254
reward_mean: 1352.9844766296917
reward_std: 765.6592298983466
reward_max: 3585.955654324795
reward_min: 648.6384202099273
total_envstep_count: 24772488
total_train_sample_count: 18571996
total_episode_count: 54467
total_duration: 4952.100470365804
[2023-06-29 14:36:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3011
train_sample_count: 3011
avg_envstep_per_episode: 273.72727272727275
avg_sample_per_episode: 273.72727272727275
avg_envstep_per_sec: 2784.617679777291
avg_train_sample_per_sec: 2784.617679777291
avg_episode_per_sec: 10.172963958004052
collect_time: 1.081297451304272
reward_mean: 1603.8706169276425
reward_std: 725.72247217735
reward_max: 3032.0255498101537
reward_min: 642.2763752132194
total_envstep_count: 24777392
total_train_sample_count: 18575407
total_episode_count: 54478
total_duration: 4953.181767817108
[2023-06-29 14:37:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2472
train_sample_count: 2472
avg_envstep_per_episode: 224.72727272727272
avg_sample_per_episode: 224.72727272727272
avg_envstep_per_sec: 2535.0745026056907
avg_train_sample_per_sec: 2535.0745026056907
avg_episode_per_sec: 11.280671330365129
collect_time: 0.9751192706404253
reward_mean: 1313.6766783540404
reward_std: 671.9908891965357
reward_max: 3336.2043201606543
reward_min: 658.7732240831994
total_envstep_count: 24781400
total_train_sample_count: 18578679
total_episode_count: 54489
total_duration: 4954.156887087749
[2023-06-29 14:37:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2112
train_sample_count: 2112
avg_envstep_per_episode: 301.7142857142857
avg_sample_per_episode: 301.7142857142857
avg_envstep_per_sec: 2517.6282966508566
avg_train_sample_per_sec: 2517.6282966508566
avg_episode_per_sec: 8.344411968066286
collect_time: 0.8388847562642767
reward_mean: 2086.7175962739116
reward_std: 812.849191118757
reward_max: 3408.21079629614
reward_min: 1048.8846841075635
total_envstep_count: 24786056
total_train_sample_count: 18581991
total_episode_count: 54496
total_duration: 4954.995771844014
[2023-06-29 14:37:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2130
train_sample_count: 2130
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2622.772252414374
avg_train_sample_per_sec: 2622.772252414374
avg_episode_per_sec: 12.313484753119127
collect_time: 0.8121177879776804
reward_mean: 1601.3886821206709
reward_std: 747.5502544207027
reward_max: 3464.662150827091
reward_min: 864.6346759430884
total_envstep_count: 24790160
total_train_sample_count: 18585321
total_episode_count: 54506
total_duration: 4955.807889631991
[2023-06-29 14:37:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2952
train_sample_count: 2952
avg_envstep_per_episode: 268.3636363636364
avg_sample_per_episode: 268.3636363636364
avg_envstep_per_sec: 2701.5182528448872
avg_train_sample_per_sec: 2701.5182528448872
avg_episode_per_sec: 10.06663305599382
collect_time: 1.0927188801672312
reward_mean: 1710.66411397453
reward_std: 1038.9839953350877
reward_max: 3612.042243541401
reward_min: 563.718773164434
total_envstep_count: 24794592
total_train_sample_count: 18588673
total_episode_count: 54517
total_duration: 4956.900608512158
[2023-06-29 14:37:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2473
train_sample_count: 2473
avg_envstep_per_episode: 247.3
avg_sample_per_episode: 247.3
avg_envstep_per_sec: 2629.9341806950147
avg_train_sample_per_sec: 2629.9341806950147
avg_episode_per_sec: 10.634590297998441
collect_time: 0.9403277154816317
reward_mean: 1326.5646722865067
reward_std: 669.9460995251089
reward_max: 2979.3436067158004
reward_min: 633.6904203138808
total_envstep_count: 24799640
total_train_sample_count: 18591946
total_episode_count: 54527
total_duration: 4957.84093622764
[2023-06-29 14:37:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2135
train_sample_count: 2135
avg_envstep_per_episode: 194.0909090909091
avg_sample_per_episode: 194.0909090909091
avg_envstep_per_sec: 2637.4865344003138
avg_train_sample_per_sec: 2637.4865344003138
avg_episode_per_sec: 13.588923596441898
collect_time: 0.8094828057521953
reward_mean: 1415.1661826390052
reward_std: 952.6756734953283
reward_max: 3512.3757818946806
reward_min: 407.3735195199189
total_envstep_count: 24803936
total_train_sample_count: 18595281
total_episode_count: 54538
total_duration: 4958.650419033392
[2023-06-29 14:37:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2565
train_sample_count: 2565
avg_envstep_per_episode: 285.0
avg_sample_per_episode: 285.0
avg_envstep_per_sec: 2754.5668283131995
avg_train_sample_per_sec: 2754.5668283131995
avg_episode_per_sec: 9.665146766011226
collect_time: 0.9311808933569117
reward_mean: 2040.9211427191772
reward_std: 907.0783034739559
reward_max: 3536.5090008592724
reward_min: 1133.3523130922897
total_envstep_count: 24808416
total_train_sample_count: 18598646
total_episode_count: 54547
total_duration: 4959.581599926749
[2023-06-29 14:37:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 222.72727272727272
avg_sample_per_episode: 222.72727272727272
avg_envstep_per_sec: 2600.0748081028687
avg_train_sample_per_sec: 2600.0748081028687
avg_episode_per_sec: 11.673805260870024
collect_time: 0.9422805806836111
reward_mean: 1507.796053765288
reward_std: 745.1919685822766
reward_max: 2919.2185546726014
reward_min: 395.1652922966589
total_envstep_count: 24812304
total_train_sample_count: 18601896
total_episode_count: 54558
total_duration: 4960.523880507432
[2023-06-29 14:37:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3299
train_sample_count: 3299
avg_envstep_per_episode: 253.76923076923077
avg_sample_per_episode: 253.76923076923077
avg_envstep_per_sec: 2486.8859209820757
avg_train_sample_per_sec: 2486.8859209820757
avg_episode_per_sec: 9.799792959310999
collect_time: 1.3265586379198362
reward_mean: 1304.310341584704
reward_std: 602.965633053759
reward_max: 2542.873777562592
reward_min: 390.1895778624114
total_envstep_count: 24817104
total_train_sample_count: 18605195
total_episode_count: 54571
total_duration: 4961.8504391453525
[2023-06-29 14:37:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2881
train_sample_count: 2881
avg_envstep_per_episode: 261.90909090909093
avg_sample_per_episode: 261.90909090909093
avg_envstep_per_sec: 2554.4722442209704
avg_train_sample_per_sec: 2554.4722442209704
avg_episode_per_sec: 9.753278266723594
collect_time: 1.127825916495174
reward_mean: 1317.9443755263164
reward_std: 368.8639596285603
reward_max: 1911.143695836552
reward_min: 706.669176443285
total_envstep_count: 24821712
total_train_sample_count: 18608476
total_episode_count: 54582
total_duration: 4962.978265061848
[2023-06-29 14:37:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2173
train_sample_count: 2173
avg_envstep_per_episode: 167.15384615384616
avg_sample_per_episode: 167.15384615384616
avg_envstep_per_sec: 2742.8743083456084
avg_train_sample_per_sec: 2742.8743083456084
avg_episode_per_sec: 16.409280261616615
collect_time: 0.7922346253301947
reward_mean: 1013.3113611271875
reward_std: 778.4269984582444
reward_max: 3562.0081082016536
reward_min: 551.9429135194362
total_envstep_count: 24825784
total_train_sample_count: 18611849
total_episode_count: 54595
total_duration: 4963.770499687178
[2023-06-29 14:37:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3031
train_sample_count: 3031
avg_envstep_per_episode: 275.54545454545456
avg_sample_per_episode: 275.54545454545456
avg_envstep_per_sec: 2633.486819363973
avg_train_sample_per_sec: 2633.486819363973
avg_episode_per_sec: 9.557358961730024
collect_time: 1.1509455744046717
reward_mean: 1647.880459397885
reward_std: 1152.5868059480506
reward_max: 3598.2306348756774
reward_min: 634.2141656620114
total_envstep_count: 24830376
total_train_sample_count: 18615280
total_episode_count: 54606
total_duration: 4964.921445261582
[2023-06-29 14:37:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3325
train_sample_count: 3325
avg_envstep_per_episode: 237.5
avg_sample_per_episode: 237.5
avg_envstep_per_sec: 2517.543347621401
avg_train_sample_per_sec: 2517.543347621401
avg_episode_per_sec: 10.600182516300636
collect_time: 1.3207319759326057
reward_mean: 1332.9095365034902
reward_std: 803.8472791247855
reward_max: 3532.979993600816
reward_min: 556.6230690648583
total_envstep_count: 24834528
total_train_sample_count: 18618605
total_episode_count: 54620
total_duration: 4966.242177237515
[2023-06-29 14:37:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3141
train_sample_count: 3141
avg_envstep_per_episode: 224.35714285714286
avg_sample_per_episode: 224.35714285714286
avg_envstep_per_sec: 2615.655344458906
avg_train_sample_per_sec: 2615.655344458906
avg_episode_per_sec: 11.658444706279747
collect_time: 1.2008462837636473
reward_mean: 1001.9343381250495
reward_std: 427.6723696528628
reward_max: 2125.967959284322
reward_min: 505.9637866812132
total_envstep_count: 24839000
total_train_sample_count: 18622146
total_episode_count: 54634
total_duration: 4967.4430235212785
[2023-06-29 14:37:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3036
train_sample_count: 3036
avg_envstep_per_episode: 202.4
avg_sample_per_episode: 202.4
avg_envstep_per_sec: 2750.232547145255
avg_train_sample_per_sec: 2750.232547145255
avg_episode_per_sec: 13.588105470085253
collect_time: 1.103906650785357
reward_mean: 1017.1628022773253
reward_std: 464.9863469084126
reward_max: 2255.581217263313
reward_min: 379.78446054507765
total_envstep_count: 24843408
total_train_sample_count: 18625582
total_episode_count: 54649
total_duration: 4968.546930172064
[2023-06-29 14:37:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3113
train_sample_count: 3113
avg_envstep_per_episode: 259.4166666666667
avg_sample_per_episode: 259.4166666666667
avg_envstep_per_sec: 2633.635901485655
avg_train_sample_per_sec: 2633.635901485655
avg_episode_per_sec: 10.152146102739433
collect_time: 1.1820160859152673
reward_mean: 1212.3019589158705
reward_std: 375.3418275971398
reward_max: 2023.2144766757733
reward_min: 589.5834370596509
total_envstep_count: 24847976
total_train_sample_count: 18629095
total_episode_count: 54661
total_duration: 4969.728946257979
[2023-06-29 14:37:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3455
train_sample_count: 3455
avg_envstep_per_episode: 265.7692307692308
avg_sample_per_episode: 265.7692307692308
avg_envstep_per_sec: 2646.8739706957044
avg_train_sample_per_sec: 2646.8739706957044
avg_episode_per_sec: 9.959294245743607
collect_time: 1.3053133765533564
reward_mean: 1472.2997215242792
reward_std: 763.3529046043993
reward_max: 3531.6813759835686
reward_min: 856.997691048519
total_envstep_count: 24853176
total_train_sample_count: 18632550
total_episode_count: 54674
total_duration: 4971.034259634533
[2023-06-29 14:37:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2160
train_sample_count: 2160
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2603.4029233576
avg_train_sample_per_sec: 2603.4029233576
avg_episode_per_sec: 12.05279131184074
collect_time: 0.8296833273945377
reward_mean: 1207.9849585916882
reward_std: 582.3567468004115
reward_max: 2773.778405339677
reward_min: 659.8228987004885
total_envstep_count: 24857280
total_train_sample_count: 18635910
total_episode_count: 54684
total_duration: 4971.863942961927
[2023-06-29 14:37:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2758
train_sample_count: 2758
avg_envstep_per_episode: 212.15384615384616
avg_sample_per_episode: 212.15384615384616
avg_envstep_per_sec: 2681.670230076652
avg_train_sample_per_sec: 2681.670230076652
avg_episode_per_sec: 12.640215007612936
collect_time: 1.0284635183950885
reward_mean: 1424.7942651021272
reward_std: 926.2098363501659
reward_max: 3642.2617073175097
reward_min: 606.019852972816
total_envstep_count: 24862080
total_train_sample_count: 18639468
total_episode_count: 54697
total_duration: 4972.892406480322
[2023-06-29 14:38:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 352.7142857142857
avg_sample_per_episode: 352.7142857142857
avg_envstep_per_sec: 2697.914067910271
avg_train_sample_per_sec: 2697.914067910271
avg_episode_per_sec: 7.649007077914903
collect_time: 0.9151514606662097
reward_mean: 2017.359658964338
reward_std: 850.8181237511341
reward_max: 3648.9421188551514
reward_min: 929.7864310540859
total_envstep_count: 24865864
total_train_sample_count: 18642737
total_episode_count: 54704
total_duration: 4973.807557940989
[2023-06-29 14:38:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1511
train_sample_count: 1511
avg_envstep_per_episode: 188.875
avg_sample_per_episode: 188.875
avg_envstep_per_sec: 2428.0357815226503
avg_train_sample_per_sec: 2428.0357815226503
avg_episode_per_sec: 12.85525231779034
collect_time: 0.6223137284461409
reward_mean: 1526.5684050883583
reward_std: 1181.768384933944
reward_max: 3581.8723571516102
reward_min: 575.9475107389273
total_envstep_count: 24870912
total_train_sample_count: 18646248
total_episode_count: 54712
total_duration: 4974.429871669435
[2023-06-29 14:38:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2883
train_sample_count: 2883
avg_envstep_per_episode: 221.76923076923077
avg_sample_per_episode: 221.76923076923077
avg_envstep_per_sec: 2631.933810804237
avg_train_sample_per_sec: 2631.933810804237
avg_episode_per_sec: 11.867894394885564
collect_time: 1.095392288425006
reward_mean: 1813.4381138159645
reward_std: 760.6042814153292
reward_max: 3284.2732766589647
reward_min: 719.2823328613157
total_envstep_count: 24875672
total_train_sample_count: 18649531
total_episode_count: 54725
total_duration: 4975.525263957859
[2023-06-29 14:38:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 296.8
avg_sample_per_episode: 296.8
avg_envstep_per_sec: 2460.120245594197
avg_train_sample_per_sec: 2460.120245594197
avg_episode_per_sec: 8.288814843646216
collect_time: 1.2064450936149806
reward_mean: 1619.2780620821177
reward_std: 934.1052402435614
reward_max: 3127.024434103954
reward_min: 390.88039200540385
total_envstep_count: 24879816
total_train_sample_count: 18652899
total_episode_count: 54735
total_duration: 4976.731709051474
[2023-06-29 14:38:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 3253
train_sample_count: 3253
avg_envstep_per_episode: 191.35294117647058
avg_sample_per_episode: 191.35294117647058
avg_envstep_per_sec: 2735.127132946777
avg_train_sample_per_sec: 2735.127132946777
avg_episode_per_sec: 14.293624734120874
collect_time: 1.189341424321756
reward_mean: 994.3915159259142
reward_std: 742.2532213624924
reward_max: 3678.3467149462167
reward_min: 313.61671193383637
total_envstep_count: 24883840
total_train_sample_count: 18656152
total_episode_count: 54752
total_duration: 4977.921050475796
[2023-06-29 14:38:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 2853
train_sample_count: 2853
avg_envstep_per_episode: 190.2
avg_sample_per_episode: 190.2
avg_envstep_per_sec: 2553.481283761617
avg_train_sample_per_sec: 2553.481283761617
avg_episode_per_sec: 13.425243342595252
collect_time: 1.1172981835203242
reward_mean: 837.3859722952092
reward_std: 343.2244933509775
reward_max: 2050.74183700778
reward_min: 607.9913308427768
total_envstep_count: 24888000
total_train_sample_count: 18659405
total_episode_count: 54767
total_duration: 4979.038348659316
[2023-06-29 14:38:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2604
train_sample_count: 2604
avg_envstep_per_episode: 200.30769230769232
avg_sample_per_episode: 200.30769230769232
avg_envstep_per_sec: 2774.295669305856
avg_train_sample_per_sec: 2774.295669305856
avg_episode_per_sec: 13.850170392079924
collect_time: 0.9386166113475336
reward_mean: 992.8193999638753
reward_std: 523.8080864211429
reward_max: 2565.0631596863104
reward_min: 616.850464582189
total_envstep_count: 24892320
total_train_sample_count: 18662809
total_episode_count: 54780
total_duration: 4979.976965270664
[2023-06-29 14:38:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3308
train_sample_count: 3308
avg_envstep_per_episode: 275.6666666666667
avg_sample_per_episode: 275.6666666666667
avg_envstep_per_sec: 2761.314359124023
avg_train_sample_per_sec: 2761.314359124023
avg_episode_per_sec: 10.016859827535756
collect_time: 1.1979802259998398
reward_mean: 1589.3111638318567
reward_std: 816.0213493580286
reward_max: 3541.7412244706916
reward_min: 458.36566075477924
total_envstep_count: 24896536
total_train_sample_count: 18666117
total_episode_count: 54792
total_duration: 4981.174945496664
[2023-06-29 14:38:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2457
train_sample_count: 2457
avg_envstep_per_episode: 245.7
avg_sample_per_episode: 245.7
avg_envstep_per_sec: 2705.2384149181376
avg_train_sample_per_sec: 2705.2384149181376
avg_episode_per_sec: 11.010331359048179
collect_time: 0.9082378789428622
reward_mean: 1190.5175917494848
reward_std: 374.49498003668094
reward_max: 1902.3790975375894
reward_min: 644.7403500029571
total_envstep_count: 24900744
total_train_sample_count: 18669374
total_episode_count: 54802
total_duration: 4982.0831833756065
[2023-06-29 14:38:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2958
train_sample_count: 2958
avg_envstep_per_episode: 227.53846153846155
avg_sample_per_episode: 227.53846153846155
avg_envstep_per_sec: 2534.2293491351375
avg_train_sample_per_sec: 2534.2293491351375
avg_episode_per_sec: 11.137586727098304
collect_time: 1.1672187448265028
reward_mean: 1325.2382090065403
reward_std: 556.6808942061895
reward_max: 2773.5884312934395
reward_min: 642.8694328806984
total_envstep_count: 24905864
total_train_sample_count: 18672732
total_episode_count: 54815
total_duration: 4983.250402120433
[2023-06-29 14:38:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3120
train_sample_count: 3120
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 2611.465899122464
avg_train_sample_per_sec: 2611.465899122464
avg_episode_per_sec: 10.881107913010268
collect_time: 1.194731281403452
reward_mean: 1383.6570909068398
reward_std: 689.4822486189354
reward_max: 3441.270328015304
reward_min: 648.8443580818505
total_envstep_count: 24910920
total_train_sample_count: 18676252
total_episode_count: 54828
total_duration: 4984.445133401837
[2023-06-29 14:38:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2293
train_sample_count: 2293
avg_envstep_per_episode: 191.08333333333334
avg_sample_per_episode: 191.08333333333334
avg_envstep_per_sec: 2681.3631680832955
avg_train_sample_per_sec: 2681.3631680832955
avg_episode_per_sec: 14.032428267335172
collect_time: 0.8551620411938055
reward_mean: 1334.9438592395225
reward_std: 809.5045528765477
reward_max: 3707.6640189892637
reward_min: 644.1432274030278
total_envstep_count: 24915672
total_train_sample_count: 18679745
total_episode_count: 54840
total_duration: 4985.30029544303
[2023-06-29 14:38:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 1785
train_sample_count: 1785
avg_envstep_per_episode: 162.27272727272728
avg_sample_per_episode: 162.27272727272728
avg_envstep_per_sec: 2700.938488586517
avg_train_sample_per_sec: 2700.938488586517
avg_episode_per_sec: 16.64443886523904
collect_time: 0.6608813964268193
reward_mean: 1356.3538580124955
reward_std: 552.7505243645271
reward_max: 2564.324108405691
reward_min: 658.8535645076976
total_envstep_count: 24920536
total_train_sample_count: 18683130
total_episode_count: 54851
total_duration: 4985.961176839457
[2023-06-29 14:38:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2842
train_sample_count: 2842
avg_envstep_per_episode: 258.3636363636364
avg_sample_per_episode: 258.3636363636364
avg_envstep_per_sec: 2786.499893686275
avg_train_sample_per_sec: 2786.499893686275
avg_episode_per_sec: 10.785186076899727
collect_time: 1.0199174980912358
reward_mean: 1849.6905414085415
reward_std: 936.956018449126
reward_max: 3556.897941380643
reward_min: 659.33785951713
total_envstep_count: 24925176
total_train_sample_count: 18686372
total_episode_count: 54862
total_duration: 4986.981094337549
[2023-06-29 14:38:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2780
train_sample_count: 2780
avg_envstep_per_episode: 252.72727272727272
avg_sample_per_episode: 252.72727272727272
avg_envstep_per_sec: 2636.5585784463783
avg_train_sample_per_sec: 2636.5585784463783
avg_episode_per_sec: 10.432426029823798
collect_time: 1.0544047921886668
reward_mean: 1563.0372061332862
reward_std: 974.0981821464281
reward_max: 3547.59175531425
reward_min: 633.004240319382
total_envstep_count: 24930056
total_train_sample_count: 18689952
total_episode_count: 54873
total_duration: 4988.035499129737
[2023-06-29 14:38:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2498
train_sample_count: 2498
avg_envstep_per_episode: 312.25
avg_sample_per_episode: 312.25
avg_envstep_per_sec: 2442.1605552919555
avg_train_sample_per_sec: 2442.1605552919555
avg_episode_per_sec: 7.8211707135050625
collect_time: 1.022864772173576
reward_mean: 1939.3006612795798
reward_std: 786.0575539111178
reward_max: 3479.0679348545523
reward_min: 1138.3165133929986
total_envstep_count: 24934704
total_train_sample_count: 18693250
total_episode_count: 54881
total_duration: 4989.0583639019105
[2023-06-29 14:38:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2481
train_sample_count: 2481
avg_envstep_per_episode: 275.6666666666667
avg_sample_per_episode: 275.6666666666667
avg_envstep_per_sec: 2695.8276648377923
avg_train_sample_per_sec: 2695.8276648377923
avg_episode_per_sec: 9.779302290826333
collect_time: 0.9203110541375357
reward_mean: 1810.06349816497
reward_std: 1005.7328607391267
reward_max: 3514.377441896169
reward_min: 615.9437339737825
total_envstep_count: 24939352
total_train_sample_count: 18696531
total_episode_count: 54890
total_duration: 4989.978674956048
[2023-06-29 14:38:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2666
train_sample_count: 2666
avg_envstep_per_episode: 266.6
avg_sample_per_episode: 266.6
avg_envstep_per_sec: 2749.514491317216
avg_train_sample_per_sec: 2749.514491317216
avg_episode_per_sec: 10.313257656853773
collect_time: 0.9696257315315306
reward_mean: 1708.0363158955606
reward_std: 943.3705127602569
reward_max: 3407.371918801447
reward_min: 670.1207219779038
total_envstep_count: 24944152
total_train_sample_count: 18699997
total_episode_count: 54900
total_duration: 4990.94830068758
[2023-06-29 14:38:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2558
train_sample_count: 2558
avg_envstep_per_episode: 255.8
avg_sample_per_episode: 255.8
avg_envstep_per_sec: 2702.7070851148146
avg_train_sample_per_sec: 2702.7070851148146
avg_episode_per_sec: 10.565704007485593
collect_time: 0.9464584653247146
reward_mean: 1817.7117318676076
reward_std: 797.9059552638032
reward_max: 3406.8529560384477
reward_min: 908.2440952285631
total_envstep_count: 24948416
total_train_sample_count: 18703355
total_episode_count: 54910
total_duration: 4991.894759152905
[2023-06-29 14:38:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2067
train_sample_count: 2067
avg_envstep_per_episode: 229.66666666666666
avg_sample_per_episode: 229.66666666666666
avg_envstep_per_sec: 2564.2911579656184
avg_train_sample_per_sec: 2564.2911579656184
avg_episode_per_sec: 11.165273547020108
collect_time: 0.8060707122040913
reward_mean: 1501.3319095408099
reward_std: 458.1483943522855
reward_max: 2141.9729170457053
reward_min: 878.8096518805374
total_envstep_count: 24953312
total_train_sample_count: 18706622
total_episode_count: 54919
total_duration: 4992.700829865109
[2023-06-29 14:39:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2046
train_sample_count: 2046
avg_envstep_per_episode: 255.75
avg_sample_per_episode: 255.75
avg_envstep_per_sec: 2529.276470088581
avg_train_sample_per_sec: 2529.276470088581
avg_episode_per_sec: 9.889644066817521
collect_time: 0.8089269892778248
reward_mean: 1989.2133995494942
reward_std: 736.7092421325198
reward_max: 3560.6083231750636
reward_min: 1268.7400097570896
total_envstep_count: 24958256
total_train_sample_count: 18709868
total_episode_count: 54927
total_duration: 4993.509756854387
[2023-06-29 14:39:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2788
train_sample_count: 2788
avg_envstep_per_episode: 253.45454545454547
avg_sample_per_episode: 253.45454545454547
avg_envstep_per_sec: 2578.630745006238
avg_train_sample_per_sec: 2578.630745006238
avg_episode_per_sec: 10.173937659637238
collect_time: 1.0811939652077853
reward_mean: 1979.5856161696322
reward_std: 935.610243058981
reward_max: 3604.722848306544
reward_min: 573.7210871492883
total_envstep_count: 24962496
total_train_sample_count: 18713456
total_episode_count: 54938
total_duration: 4994.590950819595
[2023-06-29 14:39:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2685
train_sample_count: 2685
avg_envstep_per_episode: 223.75
avg_sample_per_episode: 223.75
avg_envstep_per_sec: 2739.3097767299605
avg_train_sample_per_sec: 2739.3097767299605
avg_episode_per_sec: 12.242725259128315
collect_time: 0.9801739192875102
reward_mean: 1309.7477849129102
reward_std: 792.307694094793
reward_max: 3542.3416492934666
reward_min: 313.817169010812
total_envstep_count: 24967152
total_train_sample_count: 18716941
total_episode_count: 54950
total_duration: 4995.571124738882
[2023-06-29 14:39:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2228
train_sample_count: 2228
avg_envstep_per_episode: 185.66666666666666
avg_sample_per_episode: 185.66666666666666
avg_envstep_per_sec: 2743.697751692377
avg_train_sample_per_sec: 2743.697751692377
avg_episode_per_sec: 14.77754623891765
collect_time: 0.8120427983095869
reward_mean: 1237.1680771229314
reward_std: 436.96841568992124
reward_max: 1959.4416460821299
reward_min: 327.7146621081009
total_envstep_count: 24971552
total_train_sample_count: 18720369
total_episode_count: 54962
total_duration: 4996.383167537191
[2023-06-29 14:39:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3079
train_sample_count: 3079
avg_envstep_per_episode: 236.84615384615384
avg_sample_per_episode: 236.84615384615384
avg_envstep_per_sec: 2534.1812240471036
avg_train_sample_per_sec: 2534.1812240471036
avg_episode_per_sec: 10.699693378568478
collect_time: 1.2149880879800765
reward_mean: 1487.6550778688224
reward_std: 454.82348379602774
reward_max: 2293.9313914408685
reward_min: 945.7127225899212
total_envstep_count: 24976032
total_train_sample_count: 18723848
total_episode_count: 54975
total_duration: 4997.598155625171
[2023-06-29 14:39:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2608
train_sample_count: 2608
avg_envstep_per_episode: 217.33333333333334
avg_sample_per_episode: 217.33333333333334
avg_envstep_per_sec: 2576.189290009624
avg_train_sample_per_sec: 2576.189290009624
avg_episode_per_sec: 11.85363170249827
collect_time: 1.0123479707464575
reward_mean: 1204.7958300370012
reward_std: 494.2130966813309
reward_max: 2539.583430529627
reward_min: 657.4390089190481
total_envstep_count: 24980648
total_train_sample_count: 18727256
total_episode_count: 54987
total_duration: 4998.610503595917
[2023-06-29 14:39:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2173
train_sample_count: 2173
avg_envstep_per_episode: 217.3
avg_sample_per_episode: 217.3
avg_envstep_per_sec: 2716.4063723884296
avg_train_sample_per_sec: 2716.4063723884296
avg_episode_per_sec: 12.50071961522517
collect_time: 0.7999539472768084
reward_mean: 1523.8355279298903
reward_std: 556.0606852873367
reward_max: 2552.160718027607
reward_min: 653.6530035563513
total_envstep_count: 24984608
total_train_sample_count: 18730629
total_episode_count: 54997
total_duration: 4999.410457543194
[2023-06-29 14:39:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2849
train_sample_count: 2849
avg_envstep_per_episode: 237.41666666666666
avg_sample_per_episode: 237.41666666666666
avg_envstep_per_sec: 2718.7072224716644
avg_train_sample_per_sec: 2718.7072224716644
avg_episode_per_sec: 11.451206272256924
collect_time: 1.0479245342975483
reward_mean: 1397.1563578926396
reward_std: 520.0492720125516
reward_max: 2575.5985077076775
reward_min: 713.3650515129018
total_envstep_count: 24988736
total_train_sample_count: 18733878
total_episode_count: 55009
total_duration: 5000.4583820774915
[2023-06-29 14:39:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3332
train_sample_count: 3332
avg_envstep_per_episode: 277.6666666666667
avg_sample_per_episode: 277.6666666666667
avg_envstep_per_sec: 2511.4285224699356
avg_train_sample_per_sec: 2511.4285224699356
avg_episode_per_sec: 9.044760585125818
collect_time: 1.3267349519161509
reward_mean: 1393.588733217736
reward_std: 389.8622557433812
reward_max: 2540.9412957666773
reward_min: 1020.2006083590966
total_envstep_count: 24993152
total_train_sample_count: 18737210
total_episode_count: 55021
total_duration: 5001.785117029408
[2023-06-29 14:39:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2758
train_sample_count: 2758
avg_envstep_per_episode: 275.8
avg_sample_per_episode: 275.8
avg_envstep_per_sec: 2665.4328499457124
avg_train_sample_per_sec: 2665.4328499457124
avg_episode_per_sec: 9.664368563980101
collect_time: 1.0347287496123465
reward_mean: 1377.4133303023343
reward_std: 185.70737904906457
reward_max: 1607.1784141774897
reward_min: 1026.6609311734019
total_envstep_count: 24997640
total_train_sample_count: 18740768
total_episode_count: 55031
total_duration: 5002.81984577902
[2023-06-29 14:39:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2030
train_sample_count: 2030
avg_envstep_per_episode: 225.55555555555554
avg_sample_per_episode: 225.55555555555554
avg_envstep_per_sec: 2786.113465599425
avg_train_sample_per_sec: 2786.113465599425
avg_episode_per_sec: 12.352227187386614
collect_time: 0.7286135417902841
reward_mean: 1558.2929228214166
reward_std: 565.0338262629376
reward_max: 2378.242613762695
reward_min: 650.4074648347918
total_envstep_count: 25002320
total_train_sample_count: 18743998
total_episode_count: 55040
total_duration: 5003.54845932081
[2023-06-29 14:39:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2511
train_sample_count: 2511
avg_envstep_per_episode: 251.1
avg_sample_per_episode: 251.1
avg_envstep_per_sec: 2601.184867198677
avg_train_sample_per_sec: 2601.184867198677
avg_episode_per_sec: 10.35915916845351
collect_time: 0.9653293126774951
reward_mean: 1870.5184145631931
reward_std: 803.7178097259537
reward_max: 3254.384442451533
reward_min: 757.8986400895315
total_envstep_count: 25006288
total_train_sample_count: 18747309
total_episode_count: 55050
total_duration: 5004.513788633488
[2023-06-29 14:39:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2613
train_sample_count: 2613
avg_envstep_per_episode: 237.54545454545453
avg_sample_per_episode: 237.54545454545453
avg_envstep_per_sec: 2595.1707627985998
avg_train_sample_per_sec: 2595.1707627985998
avg_episode_per_sec: 10.924943892378337
collect_time: 1.0068701595505698
reward_mean: 1319.9575239249482
reward_std: 550.4699778014351
reward_max: 2694.5154914268574
reward_min: 651.3092016609646
total_envstep_count: 25010608
total_train_sample_count: 18750722
total_episode_count: 55061
total_duration: 5005.520658793039
[2023-06-29 14:39:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1508
train_sample_count: 1508
avg_envstep_per_episode: 251.33333333333334
avg_sample_per_episode: 251.33333333333334
avg_envstep_per_sec: 2336.4776238536383
avg_train_sample_per_sec: 2336.4776238536383
avg_episode_per_sec: 9.296330068383176
collect_time: 0.6454159819912164
reward_mean: 1876.1310170033996
reward_std: 636.192462338385
reward_max: 2791.9155941058825
reward_min: 1187.2869875750628
total_envstep_count: 25015152
total_train_sample_count: 18754230
total_episode_count: 55067
total_duration: 5006.16607477503
[2023-06-29 14:39:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1924
train_sample_count: 1924
avg_envstep_per_episode: 213.77777777777777
avg_sample_per_episode: 213.77777777777777
avg_envstep_per_sec: 2784.05501767584
avg_train_sample_per_sec: 2784.05501767584
avg_episode_per_sec: 13.023126382059544
collect_time: 0.6910782968671992
reward_mean: 1909.9743015895801
reward_std: 814.3803558277563
reward_max: 3306.42650418004
reward_min: 937.1334509204545
total_envstep_count: 25019728
total_train_sample_count: 18757754
total_episode_count: 55076
total_duration: 5006.857153071897
[2023-06-29 14:39:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2512
train_sample_count: 2512
avg_envstep_per_episode: 209.33333333333334
avg_sample_per_episode: 209.33333333333334
avg_envstep_per_sec: 2802.146339091172
avg_train_sample_per_sec: 2802.146339091172
avg_episode_per_sec: 13.386049390562926
collect_time: 0.8964556793328373
reward_mean: 1700.4354132072287
reward_std: 977.4842621168552
reward_max: 3567.359529715759
reward_min: 661.0151395262446
total_envstep_count: 25024288
total_train_sample_count: 18761066
total_episode_count: 55088
total_duration: 5007.75360875123
[2023-06-29 14:39:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2095
train_sample_count: 2095
avg_envstep_per_episode: 261.875
avg_sample_per_episode: 261.875
avg_envstep_per_sec: 2631.275454481439
avg_train_sample_per_sec: 2631.275454481439
avg_episode_per_sec: 10.04782989778115
collect_time: 0.7961918226508422
reward_mean: 1710.848252175664
reward_std: 796.7422111401147
reward_max: 2772.098959863934
reward_min: 350.78900205453823
total_envstep_count: 25028816
total_train_sample_count: 18764361
total_episode_count: 55096
total_duration: 5008.549800573881
[2023-06-29 14:39:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1853
train_sample_count: 1853
avg_envstep_per_episode: 231.625
avg_sample_per_episode: 231.625
avg_envstep_per_sec: 2696.6243588501534
avg_train_sample_per_sec: 2696.6243588501534
avg_episode_per_sec: 11.64219906681124
collect_time: 0.6871554037248715
reward_mean: 2101.638498374963
reward_std: 814.6868215029223
reward_max: 3503.1402087500383
reward_min: 1453.30607993524
total_envstep_count: 25033256
total_train_sample_count: 18767814
total_episode_count: 55104
total_duration: 5009.236955977606
[2023-06-29 14:39:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2019
train_sample_count: 2019
avg_envstep_per_episode: 224.33333333333334
avg_sample_per_episode: 224.33333333333334
avg_envstep_per_sec: 2746.044832158207
avg_train_sample_per_sec: 2746.044832158207
avg_episode_per_sec: 12.240913070541785
collect_time: 0.7352392708072437
reward_mean: 1907.6499849533934
reward_std: 907.6075334562935
reward_max: 3615.7827724858876
reward_min: 191.14845586486499
total_envstep_count: 25037680
total_train_sample_count: 18771033
total_episode_count: 55113
total_duration: 5009.972195248413
[2023-06-29 14:40:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2400
train_sample_count: 2400
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 2680.0071824908287
avg_train_sample_per_sec: 2680.0071824908287
avg_episode_per_sec: 11.166696593711785
collect_time: 0.8955199880357833
reward_mean: 1755.2801675258547
reward_std: 687.432678100909
reward_max: 3130.126562306679
reward_min: 914.1550316455863
total_envstep_count: 25042440
total_train_sample_count: 18774233
total_episode_count: 55123
total_duration: 5010.867715236449
[2023-06-29 14:40:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 190.14285714285714
avg_sample_per_episode: 190.14285714285714
avg_envstep_per_sec: 2645.1831014395593
avg_train_sample_per_sec: 2645.1831014395593
avg_episode_per_sec: 13.911556506443963
collect_time: 0.5031787777850404
reward_mean: 1801.1007526199537
reward_std: 624.0575368304079
reward_max: 2998.960224499792
reward_min: 1156.2826350698192
total_envstep_count: 25046792
total_train_sample_count: 18777564
total_episode_count: 55130
total_duration: 5011.370894014234
[2023-06-29 14:40:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2434
train_sample_count: 2434
avg_envstep_per_episode: 270.44444444444446
avg_sample_per_episode: 270.44444444444446
avg_envstep_per_sec: 2434.3749776622394
avg_train_sample_per_sec: 2434.3749776622394
avg_episode_per_sec: 9.001386523812718
collect_time: 0.9998459655288605
reward_mean: 2324.603929852454
reward_std: 764.6798323520507
reward_max: 3655.738922824269
reward_min: 1181.1022524798288
total_envstep_count: 25051640
total_train_sample_count: 18780798
total_episode_count: 55139
total_duration: 5012.370739979763
[2023-06-29 14:40:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2294
train_sample_count: 2294
avg_envstep_per_episode: 208.54545454545453
avg_sample_per_episode: 208.54545454545453
avg_envstep_per_sec: 2686.567642648629
avg_train_sample_per_sec: 2686.567642648629
avg_episode_per_sec: 12.882408051061429
collect_time: 0.8538776257047431
reward_mean: 1543.767174983032
reward_std: 513.6179711123564
reward_max: 2568.719293774104
reward_min: 632.261119657352
total_envstep_count: 25055488
total_train_sample_count: 18784292
total_episode_count: 55150
total_duration: 5013.224617605468
[2023-06-29 14:40:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1690
train_sample_count: 1690
avg_envstep_per_episode: 281.6666666666667
avg_sample_per_episode: 281.6666666666667
avg_envstep_per_sec: 2693.367435120576
avg_train_sample_per_sec: 2693.367435120576
avg_episode_per_sec: 9.56225124894879
collect_time: 0.6274673028131947
reward_mean: 1868.4190605254607
reward_std: 1044.609134977228
reward_max: 3593.0590905858453
reward_min: 667.2349939779454
total_envstep_count: 25060112
total_train_sample_count: 18787582
total_episode_count: 55156
total_duration: 5013.852084908281
[2023-06-29 14:40:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 323.77777777777777
avg_sample_per_episode: 323.77777777777777
avg_envstep_per_sec: 2606.9946450143034
avg_train_sample_per_sec: 2606.9946450143034
avg_episode_per_sec: 8.051802266687965
collect_time: 1.1177621732261027
reward_mean: 2324.885522491269
reward_std: 1016.4947221483279
reward_max: 3537.129138254191
reward_min: 1162.2088207265936
total_envstep_count: 25064784
total_train_sample_count: 18790896
total_episode_count: 55165
total_duration: 5014.9698470815065
[2023-06-29 14:40:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1908
train_sample_count: 1908
avg_envstep_per_episode: 381.6
avg_sample_per_episode: 381.6
avg_envstep_per_sec: 2790.169413693547
avg_train_sample_per_sec: 2790.169413693547
avg_episode_per_sec: 7.311764710936968
collect_time: 0.6838294444186612
reward_mean: 2479.7233814562155
reward_std: 637.9129579518648
reward_max: 3511.5793022406265
reward_min: 1529.0043931612327
total_envstep_count: 25069760
total_train_sample_count: 18794404
total_episode_count: 55170
total_duration: 5015.653676525925
[2023-06-29 14:40:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2634
train_sample_count: 2634
avg_envstep_per_episode: 239.45454545454547
avg_sample_per_episode: 239.45454545454547
avg_envstep_per_sec: 2704.3099293157416
avg_train_sample_per_sec: 2704.3099293157416
avg_episode_per_sec: 11.293625369200136
collect_time: 0.9740007872050628
reward_mean: 1928.3822389010345
reward_std: 1032.9823228709638
reward_max: 3525.079316750691
reward_min: 189.30958836384576
total_envstep_count: 25074720
total_train_sample_count: 18797838
total_episode_count: 55181
total_duration: 5016.62767731313
[2023-06-29 14:40:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1684
train_sample_count: 1684
avg_envstep_per_episode: 280.6666666666667
avg_sample_per_episode: 280.6666666666667
avg_envstep_per_sec: 2716.738685352809
avg_train_sample_per_sec: 2716.738685352809
avg_episode_per_sec: 9.679591515508822
collect_time: 0.6198608681354671
reward_mean: 1928.7307194958064
reward_std: 506.22616856614997
reward_max: 2606.3710087938593
reward_min: 1264.4832389276532
total_envstep_count: 25078752
total_train_sample_count: 18801122
total_episode_count: 55187
total_duration: 5017.247538181266
[2023-06-29 14:40:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1417
train_sample_count: 1417
avg_envstep_per_episode: 236.16666666666666
avg_sample_per_episode: 236.16666666666666
avg_envstep_per_sec: 2678.4657163656702
avg_train_sample_per_sec: 2678.4657163656702
avg_episode_per_sec: 11.341421523072704
collect_time: 0.5290342121394351
reward_mean: 2580.2008771929463
reward_std: 552.6104812446856
reward_max: 3615.8459807021623
reward_min: 1897.0771740470518
total_envstep_count: 25083496
total_train_sample_count: 18804539
total_episode_count: 55193
total_duration: 5017.776572393405
[2023-06-29 14:40:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2589
train_sample_count: 2589
avg_envstep_per_episode: 287.6666666666667
avg_sample_per_episode: 287.6666666666667
avg_envstep_per_sec: 2502.4291171653304
avg_train_sample_per_sec: 2502.4291171653304
avg_episode_per_sec: 8.69905834472305
collect_time: 1.0345947392638775
reward_mean: 2459.9052411224075
reward_std: 907.5633742876447
reward_max: 3702.8766847691413
reward_min: 1017.1576730866167
total_envstep_count: 25088456
total_train_sample_count: 18807928
total_episode_count: 55202
total_duration: 5018.81116713267
[2023-06-29 14:40:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 187.8
avg_sample_per_episode: 187.8
avg_envstep_per_sec: 1965.807767108202
avg_train_sample_per_sec: 1965.807767108202
avg_episode_per_sec: 10.467559995251342
collect_time: 0.47766623762063687
reward_mean: 2181.8792652739953
reward_std: 577.1437739337505
reward_max: 2935.6447647915197
reward_min: 1420.2973927267828
total_envstep_count: 25092376
total_train_sample_count: 18811267
total_episode_count: 55207
total_duration: 5019.28883337029
[2023-06-29 14:40:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 312.875
avg_sample_per_episode: 312.875
avg_envstep_per_sec: 2659.3599902429887
avg_train_sample_per_sec: 2659.3599902429887
avg_episode_per_sec: 8.499752266058293
collect_time: 0.941203902135603
reward_mean: 2577.066453282824
reward_std: 909.4398105395484
reward_max: 3534.7595462720838
reward_min: 874.4100393050314
total_envstep_count: 25097104
total_train_sample_count: 18814570
total_episode_count: 55215
total_duration: 5020.230037272426
[2023-06-29 14:40:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1196
train_sample_count: 1196
avg_envstep_per_episode: 199.33333333333334
avg_sample_per_episode: 199.33333333333334
avg_envstep_per_sec: 2688.3624767132287
avg_train_sample_per_sec: 2688.3624767132287
avg_episode_per_sec: 13.486768277825561
collect_time: 0.44488048407156033
reward_mean: 1791.3263378349395
reward_std: 651.99838263276
reward_max: 2791.078101252546
reward_min: 899.8835568212374
total_envstep_count: 25101552
total_train_sample_count: 18818166
total_episode_count: 55221
total_duration: 5020.674917756497
[2023-06-29 14:40:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 224.54545454545453
avg_sample_per_episode: 224.54545454545453
avg_envstep_per_sec: 2647.5770734302887
avg_train_sample_per_sec: 2647.5770734302887
avg_episode_per_sec: 11.790829071956752
collect_time: 0.9329284593025222
reward_mean: 1958.5534789328597
reward_std: 784.3604320850176
reward_max: 3657.3691525238623
reward_min: 686.9668566907432
total_envstep_count: 25105744
total_train_sample_count: 18821436
total_episode_count: 55232
total_duration: 5021.607846215799
[2023-06-29 14:40:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2252
train_sample_count: 2252
avg_envstep_per_episode: 281.5
avg_sample_per_episode: 281.5
avg_envstep_per_sec: 2613.4845126494943
avg_train_sample_per_sec: 2613.4845126494943
avg_episode_per_sec: 9.284136812253976
collect_time: 0.8616848460743205
reward_mean: 1962.4828082803388
reward_std: 707.729545744219
reward_max: 3532.967675147352
reward_min: 1258.2462248262614
total_envstep_count: 25109872
total_train_sample_count: 18824888
total_episode_count: 55240
total_duration: 5022.469531061874
[2023-06-29 14:40:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 286.85714285714283
avg_sample_per_episode: 286.85714285714283
avg_envstep_per_sec: 2817.8755541147884
avg_train_sample_per_sec: 2817.8755541147884
avg_episode_per_sec: 9.823271353985817
collect_time: 0.7125935696726664
reward_mean: 1804.237084439043
reward_std: 763.5415846048575
reward_max: 2730.3646718945092
reward_min: 196.23524990327968
total_envstep_count: 25114080
total_train_sample_count: 18828096
total_episode_count: 55247
total_duration: 5023.182124631547
[2023-06-29 14:40:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2960
train_sample_count: 2960
avg_envstep_per_episode: 227.69230769230768
avg_sample_per_episode: 227.69230769230768
avg_envstep_per_sec: 2720.2695114295007
avg_train_sample_per_sec: 2720.2695114295007
avg_episode_per_sec: 11.947129611007941
collect_time: 1.088127476914786
reward_mean: 1558.6363788383583
reward_std: 890.7476227223367
reward_max: 3576.4949116578236
reward_min: 375.35850254569976
total_envstep_count: 25118384
total_train_sample_count: 18831456
total_episode_count: 55260
total_duration: 5024.270252108461
[2023-06-29 14:40:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2343
train_sample_count: 2343
avg_envstep_per_episode: 292.875
avg_sample_per_episode: 292.875
avg_envstep_per_sec: 2745.3808588245115
avg_train_sample_per_sec: 2745.3808588245115
avg_episode_per_sec: 9.373899646007722
collect_time: 0.8534335017558188
reward_mean: 1583.0017761016595
reward_std: 760.0585875054461
reward_max: 3537.4802602270474
reward_min: 974.5391096951076
total_envstep_count: 25123296
total_train_sample_count: 18835399
total_episode_count: 55268
total_duration: 5025.123685610217
[2023-06-29 14:41:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2929
train_sample_count: 2929
avg_envstep_per_episode: 325.44444444444446
avg_sample_per_episode: 325.44444444444446
avg_envstep_per_sec: 2627.9634645409965
avg_train_sample_per_sec: 2627.9634645409965
avg_episode_per_sec: 8.074998696097293
collect_time: 1.1145512635624037
reward_mean: 2159.3093102542307
reward_std: 822.1105475876836
reward_max: 3170.516775573583
reward_min: 497.2145690133422
total_envstep_count: 25127528
total_train_sample_count: 18838728
total_episode_count: 55277
total_duration: 5026.238236873779
[2023-06-29 14:41:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 217.16666666666666
avg_sample_per_episode: 217.16666666666666
avg_envstep_per_sec: 2535.7621418224
avg_train_sample_per_sec: 2535.7621418224
avg_episode_per_sec: 11.676571643080889
collect_time: 1.027698914270848
reward_mean: 1085.856104480286
reward_std: 661.0008562680875
reward_max: 2942.696971364125
reward_min: 236.91029734664892
total_envstep_count: 25131864
total_train_sample_count: 18842134
total_episode_count: 55289
total_duration: 5027.26593578805
[2023-06-29 14:41:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1913
train_sample_count: 1913
avg_envstep_per_episode: 239.125
avg_sample_per_episode: 239.125
avg_envstep_per_sec: 2700.6511834415996
avg_train_sample_per_sec: 2700.6511834415996
avg_episode_per_sec: 11.293888900958075
collect_time: 0.70834767989628
reward_mean: 1711.401485346293
reward_std: 827.561386176082
reward_max: 3490.2555473507796
reward_min: 660.703408197316
total_envstep_count: 25136384
total_train_sample_count: 18845647
total_episode_count: 55297
total_duration: 5027.974283467946
[2023-06-29 14:41:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3096
train_sample_count: 3096
avg_envstep_per_episode: 258.0
avg_sample_per_episode: 258.0
avg_envstep_per_sec: 2764.562200527937
avg_train_sample_per_sec: 2764.562200527937
avg_episode_per_sec: 10.715357366387353
collect_time: 1.1198879878371952
reward_mean: 1738.5223011961295
reward_std: 677.0690454535613
reward_max: 3179.2389391323295
reward_min: 584.9845264442556
total_envstep_count: 25141008
total_train_sample_count: 18849143
total_episode_count: 55309
total_duration: 5029.094171455784
[2023-06-29 14:41:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2107
train_sample_count: 2107
avg_envstep_per_episode: 210.7
avg_sample_per_episode: 210.7
avg_envstep_per_sec: 2277.940190768118
avg_train_sample_per_sec: 2277.940190768118
avg_episode_per_sec: 10.811296586464728
collect_time: 0.924958437688183
reward_mean: 1307.9963357325958
reward_std: 768.9820744463783
reward_max: 2553.621494051963
reward_min: 364.86034424059255
total_envstep_count: 25145736
total_train_sample_count: 18852450
total_episode_count: 55319
total_duration: 5030.019129893472
[2023-06-29 14:41:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2587
train_sample_count: 2587
avg_envstep_per_episode: 199.0
avg_sample_per_episode: 199.0
avg_envstep_per_sec: 2337.233809300826
avg_train_sample_per_sec: 2337.233809300826
avg_episode_per_sec: 11.744893514074503
collect_time: 1.1068640157887715
reward_mean: 1399.728367755131
reward_std: 552.8335418438094
reward_max: 2222.4248301790526
reward_min: 193.34973226963925
total_envstep_count: 25150352
total_train_sample_count: 18855837
total_episode_count: 55332
total_duration: 5031.1259939092615
[2023-06-29 14:41:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2231
train_sample_count: 2231
avg_envstep_per_episode: 247.88888888888889
avg_sample_per_episode: 247.88888888888889
avg_envstep_per_sec: 2512.610254066986
avg_train_sample_per_sec: 2512.610254066986
avg_episode_per_sec: 10.136034193905365
collect_time: 0.8879212350537999
reward_mean: 1708.3267566050304
reward_std: 472.64137833197685
reward_max: 2625.632510507067
reward_min: 1071.707480233127
total_envstep_count: 25155344
total_train_sample_count: 18859268
total_episode_count: 55341
total_duration: 5032.013915144315
[2023-06-29 14:41:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2918
train_sample_count: 2918
avg_envstep_per_episode: 265.27272727272725
avg_sample_per_episode: 265.27272727272725
avg_envstep_per_sec: 2697.730366931361
avg_train_sample_per_sec: 2697.730366931361
avg_episode_per_sec: 10.169648401728914
collect_time: 1.0816499809501694
reward_mean: 1888.6544416173017
reward_std: 924.5381522078361
reward_max: 3534.568224562783
reward_min: 628.9788916232394
total_envstep_count: 25160160
total_train_sample_count: 18862586
total_episode_count: 55352
total_duration: 5033.095565125265
[2023-06-29 14:41:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 160.28571428571428
avg_sample_per_episode: 160.28571428571428
avg_envstep_per_sec: 2585.343744091995
avg_train_sample_per_sec: 2585.343744091995
avg_episode_per_sec: 16.129595551376084
collect_time: 0.4339848434329031
reward_mean: 1507.0065312807321
reward_std: 220.15793628776916
reward_max: 1901.1709480063137
reward_min: 1270.3841610004085
total_envstep_count: 25164392
total_train_sample_count: 18866108
total_episode_count: 55359
total_duration: 5033.529549968698
[2023-06-29 14:41:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3413
train_sample_count: 3413
avg_envstep_per_episode: 262.53846153846155
avg_sample_per_episode: 262.53846153846155
avg_envstep_per_sec: 2486.073291890933
avg_train_sample_per_sec: 2486.073291890933
avg_episode_per_sec: 9.469367944501062
collect_time: 1.3728476996766403
reward_mean: 1846.4097800958832
reward_std: 881.0969090058312
reward_max: 3533.085305117407
reward_min: 716.3442648619136
total_envstep_count: 25168552
total_train_sample_count: 18869521
total_episode_count: 55372
total_duration: 5034.902397668375
[2023-06-29 14:41:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2341
train_sample_count: 2341
avg_envstep_per_episode: 390.1666666666667
avg_sample_per_episode: 390.1666666666667
avg_envstep_per_sec: 2698.6332662783548
avg_train_sample_per_sec: 2698.6332662783548
avg_episode_per_sec: 6.916616658551956
collect_time: 0.8674761514477431
reward_mean: 1774.6375496593844
reward_std: 728.9101646073416
reward_max: 2667.0014094169337
reward_min: 802.650073997949
total_envstep_count: 25172976
total_train_sample_count: 18873062
total_episode_count: 55378
total_duration: 5035.769873819822
[2023-06-29 14:41:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3016
train_sample_count: 3016
avg_envstep_per_episode: 274.1818181818182
avg_sample_per_episode: 274.1818181818182
avg_envstep_per_sec: 2757.363834912138
avg_train_sample_per_sec: 2757.363834912138
avg_episode_per_sec: 10.05669833688114
collect_time: 1.0937983452938496
reward_mean: 1746.1894273966327
reward_std: 832.4499092878276
reward_max: 3246.5807015661817
reward_min: 927.7429744950263
total_envstep_count: 25177736
total_train_sample_count: 18876478
total_episode_count: 55389
total_duration: 5036.863672165116
[2023-06-29 14:41:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2270
train_sample_count: 2270
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 2801.5964048455207
avg_train_sample_per_sec: 2801.5964048455207
avg_episode_per_sec: 12.341834382579387
collect_time: 0.8102523247366771
reward_mean: 1447.7794071091305
reward_std: 547.3473251437508
reward_max: 2952.6472479754125
reward_min: 1026.1985236221824
total_envstep_count: 25182656
total_train_sample_count: 18879948
total_episode_count: 55399
total_duration: 5037.673924489854
[2023-06-29 14:41:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2362
train_sample_count: 2362
avg_envstep_per_episode: 262.44444444444446
avg_sample_per_episode: 262.44444444444446
avg_envstep_per_sec: 2591.2980415351935
avg_train_sample_per_sec: 2591.2980415351935
avg_episode_per_sec: 9.87370125902487
collect_time: 0.911512285402976
reward_mean: 1877.297797092182
reward_std: 787.7453060262789
reward_max: 3426.743224332932
reward_min: 855.7831646824328
total_envstep_count: 25187264
total_train_sample_count: 18883510
total_episode_count: 55408
total_duration: 5038.585436775256
[2023-06-29 14:41:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2938
train_sample_count: 2938
avg_envstep_per_episode: 244.83333333333334
avg_sample_per_episode: 244.83333333333334
avg_envstep_per_sec: 2596.167488562782
avg_train_sample_per_sec: 2596.167488562782
avg_episode_per_sec: 10.603815474048124
collect_time: 1.1316681273235007
reward_mean: 1606.1681159575958
reward_std: 746.3388117925397
reward_max: 3504.445325239853
reward_min: 639.3380853019606
total_envstep_count: 25192112
total_train_sample_count: 18886848
total_episode_count: 55420
total_duration: 5039.71710490258
[2023-06-29 14:41:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2656
train_sample_count: 2656
avg_envstep_per_episode: 265.6
avg_sample_per_episode: 265.6
avg_envstep_per_sec: 2551.599542206409
avg_train_sample_per_sec: 2551.599542206409
avg_episode_per_sec: 9.606925987222926
collect_time: 1.0409156907526775
reward_mean: 1701.711580167502
reward_std: 682.8580580140541
reward_max: 3250.61931087476
reward_min: 984.2499998503624
total_envstep_count: 25196824
total_train_sample_count: 18890304
total_episode_count: 55430
total_duration: 5040.758020593333
[2023-06-29 14:41:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3396
train_sample_count: 3396
avg_envstep_per_episode: 308.72727272727275
avg_sample_per_episode: 308.72727272727275
avg_envstep_per_sec: 2689.6530022502925
avg_train_sample_per_sec: 2689.6530022502925
avg_episode_per_sec: 8.712068028490348
collect_time: 1.2626164033645766
reward_mean: 1801.8273675895061
reward_std: 702.8336083554492
reward_max: 2680.828823881899
reward_min: 769.9519366388536
total_envstep_count: 25201384
total_train_sample_count: 18893700
total_episode_count: 55441
total_duration: 5042.020636996697
[2023-06-29 14:41:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2145
train_sample_count: 2145
avg_envstep_per_episode: 306.42857142857144
avg_sample_per_episode: 306.42857142857144
avg_envstep_per_sec: 2729.4624938166935
avg_train_sample_per_sec: 2729.4624938166935
avg_episode_per_sec: 8.907336809658208
collect_time: 0.7858690144522114
reward_mean: 1623.685326602205
reward_std: 677.012759569591
reward_max: 3002.7801903036857
reward_min: 987.1308244849374
total_envstep_count: 25205920
total_train_sample_count: 18897045
total_episode_count: 55448
total_duration: 5042.806506011149
[2023-06-29 14:41:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2406
train_sample_count: 2406
avg_envstep_per_episode: 240.6
avg_sample_per_episode: 240.6
avg_envstep_per_sec: 2593.7808968027375
avg_train_sample_per_sec: 2593.7808968027375
avg_episode_per_sec: 10.780469230269068
collect_time: 0.9276034082006662
reward_mean: 1727.4341729980438
reward_std: 701.0798943841955
reward_max: 3525.796753707623
reward_min: 1048.837886465534
total_envstep_count: 25210528
total_train_sample_count: 18900251
total_episode_count: 55458
total_duration: 5043.73410941935
[2023-06-29 14:41:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3344
train_sample_count: 3344
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 2594.7305455161263
avg_train_sample_per_sec: 2594.7305455161263
avg_episode_per_sec: 8.53529784709252
collect_time: 1.2887658049035817
reward_mean: 1899.8934132284085
reward_std: 821.7133907383512
reward_max: 3543.0662678473172
reward_min: 1009.6433125696506
total_envstep_count: 25215328
total_train_sample_count: 18903595
total_episode_count: 55469
total_duration: 5045.022875224254
[2023-06-29 14:42:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2277
train_sample_count: 2277
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2374.674530712231
avg_train_sample_per_sec: 2374.674530712231
avg_episode_per_sec: 9.38606533878352
collect_time: 0.9588682451220228
reward_mean: 1497.8300467469146
reward_std: 435.1874987520167
reward_max: 2358.6425442604004
reward_min: 1045.2212142103715
total_envstep_count: 25219936
total_train_sample_count: 18907072
total_episode_count: 55478
total_duration: 5045.981743469376
[2023-06-29 14:42:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3404
train_sample_count: 3404
avg_envstep_per_episode: 261.84615384615387
avg_sample_per_episode: 261.84615384615387
avg_envstep_per_sec: 2575.694297436287
avg_train_sample_per_sec: 2575.694297436287
avg_episode_per_sec: 9.836670348610966
collect_time: 1.3215854084035383
reward_mean: 1593.9616936694617
reward_std: 782.5483447211307
reward_max: 3558.2849202340467
reward_min: 482.4220973645264
total_envstep_count: 25224136
total_train_sample_count: 18910476
total_episode_count: 55491
total_duration: 5047.30332887778
[2023-06-29 14:42:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3267
train_sample_count: 3267
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 2731.044391897381
avg_train_sample_per_sec: 2731.044391897381
avg_episode_per_sec: 9.195435662954145
collect_time: 1.196245659606531
reward_mean: 1328.7386363312542
reward_std: 389.43761467818064
reward_max: 1985.8482332698509
reward_min: 831.3535923940248
total_envstep_count: 25229056
total_train_sample_count: 18913743
total_episode_count: 55502
total_duration: 5048.499574537386
[2023-06-29 14:42:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2429
train_sample_count: 2429
avg_envstep_per_episode: 242.9
avg_sample_per_episode: 242.9
avg_envstep_per_sec: 2529.3034914592704
avg_train_sample_per_sec: 2529.3034914592704
avg_episode_per_sec: 10.41294150456678
collect_time: 0.9603434337563813
reward_mean: 1491.3549553273972
reward_std: 270.7316949484441
reward_max: 2182.86235424465
reward_min: 1234.434263428848
total_envstep_count: 25233552
total_train_sample_count: 18916972
total_episode_count: 55512
total_duration: 5049.459917971142
[2023-06-29 14:42:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2010
train_sample_count: 2010
avg_envstep_per_episode: 287.14285714285717
avg_sample_per_episode: 287.14285714285717
avg_envstep_per_sec: 2727.3132923034286
avg_train_sample_per_sec: 2727.3132923034286
avg_episode_per_sec: 9.498105993096518
collect_time: 0.7369890381395818
reward_mean: 1937.8408112315694
reward_std: 770.1732079918364
reward_max: 3549.3546556030738
reward_min: 1134.193864217522
total_envstep_count: 25237152
total_train_sample_count: 18920182
total_episode_count: 55519
total_duration: 5050.196907009282
[2023-06-29 14:42:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3083
train_sample_count: 3083
avg_envstep_per_episode: 342.55555555555554
avg_sample_per_episode: 342.55555555555554
avg_envstep_per_sec: 2407.8449906506253
avg_train_sample_per_sec: 2407.8449906506253
avg_episode_per_sec: 7.029064195866242
collect_time: 1.2803980372369987
reward_mean: 1978.931146211465
reward_std: 1022.4995050988962
reward_max: 3544.3572459837605
reward_min: 661.9995641670056
total_envstep_count: 25242008
total_train_sample_count: 18923665
total_episode_count: 55528
total_duration: 5051.477305046519
[2023-06-29 14:42:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2929
train_sample_count: 2929
avg_envstep_per_episode: 244.08333333333334
avg_sample_per_episode: 244.08333333333334
avg_envstep_per_sec: 2614.4423204643285
avg_train_sample_per_sec: 2614.4423204643285
avg_episode_per_sec: 10.711269322489567
collect_time: 1.1203154022842645
reward_mean: 1419.7676653322296
reward_std: 525.3480709062977
reward_max: 2511.6274981942097
reward_min: 891.8606083296945
total_envstep_count: 25246576
total_train_sample_count: 18926994
total_episode_count: 55540
total_duration: 5052.597620448803
[2023-06-29 14:42:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2928
train_sample_count: 2928
avg_envstep_per_episode: 266.1818181818182
avg_sample_per_episode: 266.1818181818182
avg_envstep_per_sec: 2476.072907328128
avg_train_sample_per_sec: 2476.072907328128
avg_episode_per_sec: 9.302186468787367
collect_time: 1.1825176840852945
reward_mean: 1510.2632529282112
reward_std: 570.112750296293
reward_max: 2574.526587357
reward_min: 997.5184159004725
total_envstep_count: 25250960
total_train_sample_count: 18930322
total_episode_count: 55551
total_duration: 5053.780138132889
[2023-06-29 14:42:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2582
train_sample_count: 2582
avg_envstep_per_episode: 258.2
avg_sample_per_episode: 258.2
avg_envstep_per_sec: 2431.4664298340736
avg_train_sample_per_sec: 2431.4664298340736
avg_episode_per_sec: 9.416988496646296
collect_time: 1.0619106101235374
reward_mean: 1390.9050944299238
reward_std: 548.913845622585
reward_max: 2883.3899459191107
reward_min: 933.8645651869265
total_envstep_count: 25255680
total_train_sample_count: 18933704
total_episode_count: 55561
total_duration: 5054.842048743013
[2023-06-29 14:42:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2607
train_sample_count: 2607
avg_envstep_per_episode: 237.0
avg_sample_per_episode: 237.0
avg_envstep_per_sec: 2428.7049171821204
avg_train_sample_per_sec: 2428.7049171821204
avg_episode_per_sec: 10.247700072498398
collect_time: 1.0734115872029215
reward_mean: 1653.4954532313902
reward_std: 684.066345599007
reward_max: 3035.6328141008066
reward_min: 914.3123932588855
total_envstep_count: 25260576
total_train_sample_count: 18937111
total_episode_count: 55572
total_duration: 5055.915460330216
[2023-06-29 14:42:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2559
train_sample_count: 2559
avg_envstep_per_episode: 196.84615384615384
avg_sample_per_episode: 196.84615384615384
avg_envstep_per_sec: 2520.917267130401
avg_train_sample_per_sec: 2520.917267130401
avg_episode_per_sec: 12.806535550095822
collect_time: 1.0151066968226805
reward_mean: 1280.6839679033799
reward_std: 409.189102698675
reward_max: 2249.5519818799835
reward_min: 902.9668752471614
total_envstep_count: 25264760
total_train_sample_count: 18940470
total_episode_count: 55585
total_duration: 5056.930567027039
[2023-06-29 14:42:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3399
train_sample_count: 3399
avg_envstep_per_episode: 242.78571428571428
avg_sample_per_episode: 242.78571428571428
avg_envstep_per_sec: 2548.4665240611876
avg_train_sample_per_sec: 2548.4665240611876
avg_episode_per_sec: 10.496772973479443
collect_time: 1.3337432404579592
reward_mean: 1359.4816478739583
reward_std: 526.3043196149795
reward_max: 2846.9673034544653
reward_min: 953.3519546159168
total_envstep_count: 25269288
total_train_sample_count: 18943869
total_episode_count: 55599
total_duration: 5058.2643102674965
[2023-06-29 14:42:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 258.125
avg_sample_per_episode: 258.125
avg_envstep_per_sec: 2303.0826232594954
avg_train_sample_per_sec: 2303.0826232594954
avg_episode_per_sec: 8.92235398841451
collect_time: 0.8966243673348796
reward_mean: 1432.9199137777005
reward_std: 455.0213309590077
reward_max: 2468.9496802482736
reward_min: 1092.7529225222129
total_envstep_count: 25273840
total_train_sample_count: 18947134
total_episode_count: 55607
total_duration: 5059.160934634831
[2023-06-29 14:42:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2841
train_sample_count: 2841
avg_envstep_per_episode: 236.75
avg_sample_per_episode: 236.75
avg_envstep_per_sec: 2488.9311285289878
avg_train_sample_per_sec: 2488.9311285289878
avg_episode_per_sec: 10.512908673828882
collect_time: 1.141453842348419
reward_mean: 1622.6273844878722
reward_std: 564.4081830533723
reward_max: 3058.5621304129586
reward_min: 998.6103381086872
total_envstep_count: 25278136
total_train_sample_count: 18950375
total_episode_count: 55619
total_duration: 5060.30238847718
[2023-06-29 14:42:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2826
train_sample_count: 2826
avg_envstep_per_episode: 353.25
avg_sample_per_episode: 353.25
avg_envstep_per_sec: 2676.6694941614896
avg_train_sample_per_sec: 2676.6694941614896
avg_episode_per_sec: 7.577266791681499
collect_time: 1.0557896692752837
reward_mean: 1861.055713433566
reward_std: 798.8663648167366
reward_max: 3380.2438192947584
reward_min: 1059.674763242358
total_envstep_count: 25282360
total_train_sample_count: 18953601
total_episode_count: 55627
total_duration: 5061.358178146455
[2023-06-29 14:42:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2518
train_sample_count: 2518
avg_envstep_per_episode: 279.77777777777777
avg_sample_per_episode: 279.77777777777777
avg_envstep_per_sec: 2546.162433150533
avg_train_sample_per_sec: 2546.162433150533
avg_episode_per_sec: 9.100660007289436
collect_time: 0.9889392629535869
reward_mean: 1668.22754854416
reward_std: 827.2273083007763
reward_max: 3633.396168391708
reward_min: 966.4760273517485
total_envstep_count: 25287168
total_train_sample_count: 18956919
total_episode_count: 55636
total_duration: 5062.347117409409
[2023-06-29 14:42:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2980
train_sample_count: 2980
avg_envstep_per_episode: 331.1111111111111
avg_sample_per_episode: 331.1111111111111
avg_envstep_per_sec: 2457.380349497546
avg_train_sample_per_sec: 2457.380349497546
avg_episode_per_sec: 7.42161850519393
collect_time: 1.2126734880944714
reward_mean: 2074.044804031363
reward_std: 781.3722804343632
reward_max: 3349.330680344209
reward_min: 912.6813414910333
total_envstep_count: 25291480
total_train_sample_count: 18960299
total_episode_count: 55645
total_duration: 5063.559790897504
[2023-06-29 14:42:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1919
train_sample_count: 1919
avg_envstep_per_episode: 239.875
avg_sample_per_episode: 239.875
avg_envstep_per_sec: 2708.2939588903723
avg_train_sample_per_sec: 2708.2939588903723
avg_episode_per_sec: 11.290438598813433
collect_time: 0.7085641474407167
reward_mean: 1476.2976433322942
reward_std: 903.0814136782827
reward_max: 3362.2566732254013
reward_min: 605.8535665469647
total_envstep_count: 25296048
total_train_sample_count: 18963818
total_episode_count: 55653
total_duration: 5064.268355044945
[2023-06-29 14:43:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2418
train_sample_count: 2418
avg_envstep_per_episode: 219.8181818181818
avg_sample_per_episode: 219.8181818181818
avg_envstep_per_sec: 2672.8759848260884
avg_train_sample_per_sec: 2672.8759848260884
avg_episode_per_sec: 12.159485456198086
collect_time: 0.9046435426585375
reward_mean: 1577.654914397968
reward_std: 543.8338220834922
reward_max: 2511.965234049012
reward_min: 693.92324179007
total_envstep_count: 25300176
total_train_sample_count: 18967036
total_episode_count: 55664
total_duration: 5065.172998587604
[2023-06-29 14:43:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2871
train_sample_count: 2871
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 2760.460751713057
avg_train_sample_per_sec: 2760.460751713057
avg_episode_per_sec: 10.576477975912097
collect_time: 1.0400437674103302
reward_mean: 1647.4457494207054
reward_std: 651.6478464381669
reward_max: 3427.6471223476833
reward_min: 977.6654470410559
total_envstep_count: 25304656
total_train_sample_count: 18970307
total_episode_count: 55675
total_duration: 5066.213042355014
[2023-06-29 14:43:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1994
train_sample_count: 1994
avg_envstep_per_episode: 249.25
avg_sample_per_episode: 249.25
avg_envstep_per_sec: 2596.7497629223894
avg_train_sample_per_sec: 2596.7497629223894
avg_episode_per_sec: 10.418253813128945
collect_time: 0.7678830006923527
reward_mean: 1470.207256616772
reward_std: 617.3831291642099
reward_max: 2732.59304956288
reward_min: 634.9445403232547
total_envstep_count: 25309400
total_train_sample_count: 18973901
total_episode_count: 55683
total_duration: 5066.980925355707
[2023-06-29 14:43:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2622
train_sample_count: 2622
avg_envstep_per_episode: 238.36363636363637
avg_sample_per_episode: 238.36363636363637
avg_envstep_per_sec: 2550.9158874307864
avg_train_sample_per_sec: 2550.9158874307864
avg_episode_per_sec: 10.701782899213825
collect_time: 1.0278661138610916
reward_mean: 1848.4965145466158
reward_std: 851.952569329842
reward_max: 3524.326064791355
reward_min: 901.847107441019
total_envstep_count: 25313760
total_train_sample_count: 18977323
total_episode_count: 55694
total_duration: 5068.008791469568
[2023-06-29 14:43:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2271
train_sample_count: 2271
avg_envstep_per_episode: 252.33333333333334
avg_sample_per_episode: 252.33333333333334
avg_envstep_per_sec: 2752.3777992773225
avg_train_sample_per_sec: 2752.3777992773225
avg_episode_per_sec: 10.907705941653854
collect_time: 0.8251047514611856
reward_mean: 1483.3309724446647
reward_std: 530.7184753902419
reward_max: 2847.083387351043
reward_min: 974.9139916735774
total_envstep_count: 25318592
total_train_sample_count: 18980794
total_episode_count: 55703
total_duration: 5068.833896221029
[2023-06-29 14:43:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2142
train_sample_count: 2142
avg_envstep_per_episode: 214.2
avg_sample_per_episode: 214.2
avg_envstep_per_sec: 2741.596024322922
avg_train_sample_per_sec: 2741.596024322922
avg_episode_per_sec: 12.799234473963221
collect_time: 0.7812967267958447
reward_mean: 1841.8925353815944
reward_std: 1087.0293489416067
reward_max: 3590.659005550037
reward_min: 648.0871216192736
total_envstep_count: 25323016
total_train_sample_count: 18984136
total_episode_count: 55713
total_duration: 5069.615192947825
[2023-06-29 14:43:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2446
train_sample_count: 2446
avg_envstep_per_episode: 305.75
avg_sample_per_episode: 305.75
avg_envstep_per_sec: 2763.649753357095
avg_train_sample_per_sec: 2763.649753357095
avg_episode_per_sec: 9.038919880154031
collect_time: 0.8850615013819187
reward_mean: 2039.2470073007682
reward_std: 788.8488649495806
reward_max: 3627.263883297048
reward_min: 1181.5927514821426
total_envstep_count: 25327200
total_train_sample_count: 18987382
total_episode_count: 55721
total_duration: 5070.500254449206
[2023-06-29 14:43:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2188
train_sample_count: 2188
avg_envstep_per_episode: 273.5
avg_sample_per_episode: 273.5
avg_envstep_per_sec: 2627.237492666375
avg_train_sample_per_sec: 2627.237492666375
avg_episode_per_sec: 9.60598717611106
collect_time: 0.8328139371136203
reward_mean: 1900.5376720306758
reward_std: 716.5830776969295
reward_max: 3501.423160184524
reward_min: 1239.3583140091998
total_envstep_count: 25331840
total_train_sample_count: 18990770
total_episode_count: 55729
total_duration: 5071.33306838632
[2023-06-29 14:43:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2513
train_sample_count: 2513
avg_envstep_per_episode: 314.125
avg_sample_per_episode: 314.125
avg_envstep_per_sec: 2550.3309691232953
avg_train_sample_per_sec: 2550.3309691232953
avg_episode_per_sec: 8.118841127332416
collect_time: 0.9853623041184618
reward_mean: 2139.4068456221726
reward_std: 697.1202879529718
reward_max: 3100.224409106159
reward_min: 922.3756827717367
total_envstep_count: 25337200
total_train_sample_count: 18994083
total_episode_count: 55737
total_duration: 5072.318430690438
[2023-06-29 14:43:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1687
train_sample_count: 1687
avg_envstep_per_episode: 168.7
avg_sample_per_episode: 168.7
avg_envstep_per_sec: 2794.043818097277
avg_train_sample_per_sec: 2794.043818097277
avg_episode_per_sec: 16.56220401954521
collect_time: 0.6037843748452143
reward_mean: 1587.8699857533138
reward_std: 661.7277570424023
reward_max: 3385.687109974403
reward_min: 1022.5471043188599
total_envstep_count: 25341064
total_train_sample_count: 18997370
total_episode_count: 55747
total_duration: 5072.922215065283
[2023-06-29 14:43:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2934
train_sample_count: 2934
avg_envstep_per_episode: 225.69230769230768
avg_sample_per_episode: 225.69230769230768
avg_envstep_per_sec: 2756.4967208927756
avg_train_sample_per_sec: 2756.4967208927756
avg_episode_per_sec: 12.213516486573306
collect_time: 1.0643945185067134
reward_mean: 1486.7469225737236
reward_std: 691.6332139655295
reward_max: 2915.3076612500913
reward_min: 13.016811369920571
total_envstep_count: 25346464
total_train_sample_count: 19000704
total_episode_count: 55760
total_duration: 5073.98660958379
[2023-06-29 14:43:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2011
train_sample_count: 2011
avg_envstep_per_episode: 201.1
avg_sample_per_episode: 201.1
avg_envstep_per_sec: 2517.576714680796
avg_train_sample_per_sec: 2517.576714680796
avg_episode_per_sec: 12.519028914374918
collect_time: 0.7987840006118642
reward_mean: 1603.18142318793
reward_std: 704.5126211743301
reward_max: 3091.442337707484
reward_min: 878.1519877452208
total_envstep_count: 25350696
total_train_sample_count: 19003915
total_episode_count: 55770
total_duration: 5074.785393584401
[2023-06-29 14:43:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2933
train_sample_count: 2933
avg_envstep_per_episode: 225.6153846153846
avg_sample_per_episode: 225.6153846153846
avg_envstep_per_sec: 2582.798086122351
avg_train_sample_per_sec: 2582.798086122351
avg_episode_per_sec: 11.447792403542639
collect_time: 1.1355901244310662
reward_mean: 1372.5271326135007
reward_std: 538.4614423502032
reward_max: 1919.9524384343645
reward_min: 15.495665785252061
total_envstep_count: 25355472
total_train_sample_count: 19007248
total_episode_count: 55783
total_duration: 5075.920983708833
[2023-06-29 14:43:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2769
train_sample_count: 2769
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 2774.0029417457768
avg_train_sample_per_sec: 2774.0029417457768
avg_episode_per_sec: 13.023487989416791
collect_time: 0.9981964901080357
reward_mean: 1254.673615794085
reward_std: 477.5098993947069
reward_max: 1854.6574728056437
reward_min: 11.778095820448957
total_envstep_count: 25360584
total_train_sample_count: 19010817
total_episode_count: 55796
total_duration: 5076.919180198941
[2023-06-29 14:43:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2932
train_sample_count: 2932
avg_envstep_per_episode: 209.42857142857142
avg_sample_per_episode: 209.42857142857142
avg_envstep_per_sec: 2738.996022855947
avg_train_sample_per_sec: 2738.996022855947
avg_episode_per_sec: 13.078425757156637
collect_time: 1.0704652272341775
reward_mean: 1370.365663381716
reward_std: 540.3985740192202
reward_max: 2587.3051339990943
reward_min: 14.910893397034066
total_envstep_count: 25365416
total_train_sample_count: 19014149
total_episode_count: 55810
total_duration: 5077.989645426175
[2023-06-29 14:43:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 226.27272727272728
avg_sample_per_episode: 226.27272727272728
avg_envstep_per_sec: 2581.0374971560213
avg_train_sample_per_sec: 2581.0374971560213
avg_episode_per_sec: 11.406754708202586
collect_time: 0.9643408911116421
reward_mean: 1311.8219824973849
reward_std: 658.8909409106031
reward_max: 2926.10524668889
reward_min: 18.583192974471206
total_envstep_count: 25369864
total_train_sample_count: 19017438
total_episode_count: 55821
total_duration: 5078.953986317287
[2023-06-29 14:43:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1602
train_sample_count: 1602
avg_envstep_per_episode: 200.25
avg_sample_per_episode: 200.25
avg_envstep_per_sec: 2611.84379604114
avg_train_sample_per_sec: 2611.84379604114
avg_episode_per_sec: 13.042915336035655
collect_time: 0.613359804452397
reward_mean: 1642.7087794940876
reward_std: 811.2838222285803
reward_max: 3458.137093709617
reward_min: 850.6287855625167
total_envstep_count: 25373728
total_train_sample_count: 19020640
total_episode_count: 55829
total_duration: 5079.567346121739
[2023-06-29 14:43:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1838
train_sample_count: 1838
avg_envstep_per_episode: 229.75
avg_sample_per_episode: 229.75
avg_envstep_per_sec: 2631.779950401782
avg_train_sample_per_sec: 2631.779950401782
avg_episode_per_sec: 11.454972580638877
collect_time: 0.6983866564221681
reward_mean: 2031.1149926072712
reward_std: 887.1338303168317
reward_max: 3592.915567868178
reward_min: 1010.5096636031172
total_envstep_count: 25378600
total_train_sample_count: 19024078
total_episode_count: 55837
total_duration: 5080.265732778162
[2023-06-29 14:43:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2585
train_sample_count: 2585
avg_envstep_per_episode: 198.84615384615384
avg_sample_per_episode: 198.84615384615384
avg_envstep_per_sec: 2595.5493238444888
avg_train_sample_per_sec: 2595.5493238444888
avg_episode_per_sec: 13.053052692448107
collect_time: 0.9959356103359025
reward_mean: 1573.1259734119922
reward_std: 1024.00200302297
reward_max: 2952.2005286763056
reward_min: 12.681842500563686
total_envstep_count: 25383704
total_train_sample_count: 19027463
total_episode_count: 55850
total_duration: 5081.261668388498
[2023-06-29 14:43:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1440
train_sample_count: 1440
avg_envstep_per_episode: 205.71428571428572
avg_sample_per_episode: 205.71428571428572
avg_envstep_per_sec: 2657.609612263086
avg_train_sample_per_sec: 2657.609612263086
avg_episode_per_sec: 12.91893561516778
collect_time: 0.5418403039164841
reward_mean: 1686.101336809366
reward_std: 589.1180686444485
reward_max: 2605.084971056495
reward_min: 954.3835400567999
total_envstep_count: 25387664
total_train_sample_count: 19030903
total_episode_count: 55857
total_duration: 5081.803508692415
[2023-06-29 14:44:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2352
train_sample_count: 2352
avg_envstep_per_episode: 235.2
avg_sample_per_episode: 235.2
avg_envstep_per_sec: 2414.6123201811033
avg_train_sample_per_sec: 2414.6123201811033
avg_episode_per_sec: 10.266208844307412
collect_time: 0.9740694107878953
reward_mean: 1980.7925824091642
reward_std: 908.2366097910337
reward_max: 3602.5070713111504
reward_min: 1047.8297451759654
total_envstep_count: 25391800
total_train_sample_count: 19034455
total_episode_count: 55867
total_duration: 5082.777578103202
[2023-06-29 14:44:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1842
train_sample_count: 1842
avg_envstep_per_episode: 307.0
avg_sample_per_episode: 307.0
avg_envstep_per_sec: 2672.6010871631993
avg_train_sample_per_sec: 2672.6010871631993
avg_episode_per_sec: 8.705541000531595
collect_time: 0.6892162129422648
reward_mean: 2207.677078730668
reward_std: 778.1598067299958
reward_max: 3544.945950621454
reward_min: 1286.1025348526737
total_envstep_count: 25395880
total_train_sample_count: 19037897
total_episode_count: 55873
total_duration: 5083.466794316145
[2023-06-29 14:44:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 350.0
avg_sample_per_episode: 350.0
avg_envstep_per_sec: 2528.361882296065
avg_train_sample_per_sec: 2528.361882296065
avg_episode_per_sec: 7.22389109227447
collect_time: 0.969006856635213
reward_mean: 2174.968939003043
reward_std: 881.4364114932803
reward_max: 3519.665450148438
reward_min: 1198.2781108902107
total_envstep_count: 25399792
total_train_sample_count: 19041147
total_episode_count: 55880
total_duration: 5084.43580117278
[2023-06-29 14:44:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2322
train_sample_count: 2322
avg_envstep_per_episode: 290.25
avg_sample_per_episode: 290.25
avg_envstep_per_sec: 2760.7159201897043
avg_train_sample_per_sec: 2760.7159201897043
avg_episode_per_sec: 9.511510491609663
collect_time: 0.8410861773276702
reward_mean: 1872.5335211762238
reward_std: 797.5297893765153
reward_max: 3418.7950992885185
reward_min: 631.5031721703261
total_envstep_count: 25404520
total_train_sample_count: 19044669
total_episode_count: 55888
total_duration: 5085.276887350107
[2023-06-29 14:44:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2807
train_sample_count: 2807
avg_envstep_per_episode: 311.8888888888889
avg_sample_per_episode: 311.8888888888889
avg_envstep_per_sec: 2585.4384177910074
avg_train_sample_per_sec: 2585.4384177910074
avg_episode_per_sec: 8.289613737128274
collect_time: 1.0856959425853563
reward_mean: 1923.0673573087033
reward_std: 1001.5903677894921
reward_max: 3510.941207413216
reward_min: 180.7454100300782
total_envstep_count: 25408680
total_train_sample_count: 19047876
total_episode_count: 55897
total_duration: 5086.362583292693
[2023-06-29 14:44:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 271.6666666666667
avg_sample_per_episode: 271.6666666666667
avg_envstep_per_sec: 2653.7528679348843
avg_train_sample_per_sec: 2653.7528679348843
avg_episode_per_sec: 9.768415464790985
collect_time: 0.3071122446432709
reward_mean: 2458.9930804426726
reward_std: 892.5472070499605
reward_max: 3408.9701610022857
reward_min: 1264.2000979512309
total_envstep_count: 25412392
total_train_sample_count: 19051091
total_episode_count: 55900
total_duration: 5086.669695537336
[2023-06-29 14:44:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2367
train_sample_count: 2367
avg_envstep_per_episode: 263.0
avg_sample_per_episode: 263.0
avg_envstep_per_sec: 2704.1384955345375
avg_train_sample_per_sec: 2704.1384955345375
avg_episode_per_sec: 10.281895420283412
collect_time: 0.8753249894222248
reward_mean: 2311.8743855873304
reward_std: 782.1359355999746
reward_max: 3637.961157238456
reward_min: 1161.5811195519946
total_envstep_count: 25416768
total_train_sample_count: 19054658
total_episode_count: 55909
total_duration: 5087.545020526759
[2023-06-29 14:44:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 148.0
avg_sample_per_episode: 148.0
avg_envstep_per_sec: 2478.652880746546
avg_train_sample_per_sec: 2478.652880746546
avg_episode_per_sec: 16.747654599638825
collect_time: 0.35825912006385624
reward_mean: 1626.042346225684
reward_std: 287.014567639285
reward_max: 1974.3537618539362
reward_min: 1302.1284885969255
total_envstep_count: 25420848
total_train_sample_count: 19057946
total_episode_count: 55915
total_duration: 5087.903279646823
[2023-06-29 14:44:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2988
train_sample_count: 2988
avg_envstep_per_episode: 373.5
avg_sample_per_episode: 373.5
avg_envstep_per_sec: 2560.1687616249123
avg_train_sample_per_sec: 2560.1687616249123
avg_episode_per_sec: 6.854534837014491
collect_time: 1.1671105611426755
reward_mean: 2865.095244686704
reward_std: 757.9139439542649
reward_max: 3534.8494400385794
reward_min: 1531.5079599571488
total_envstep_count: 25425176
total_train_sample_count: 19061334
total_episode_count: 55923
total_duration: 5089.070390207966
[2023-06-29 14:44:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1382
train_sample_count: 1382
avg_envstep_per_episode: 345.5
avg_sample_per_episode: 345.5
avg_envstep_per_sec: 2238.6602669257327
avg_train_sample_per_sec: 2238.6602669257327
avg_episode_per_sec: 6.479479788497056
collect_time: 0.6173335098754614
reward_mean: 2138.8644845128833
reward_std: 540.770131850692
reward_max: 2950.126227805175
reward_min: 1637.5508593861696
total_envstep_count: 25430168
total_train_sample_count: 19064716
total_episode_count: 55927
total_duration: 5089.687723717841
[2023-06-29 14:44:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2073
train_sample_count: 2073
avg_envstep_per_episode: 230.33333333333334
avg_sample_per_episode: 230.33333333333334
avg_envstep_per_sec: 2643.6284687246684
avg_train_sample_per_sec: 2643.6284687246684
avg_episode_per_sec: 11.47740290329089
collect_time: 0.7841495219636708
reward_mean: 2315.842203504779
reward_std: 1009.1806273572021
reward_max: 3634.861251538139
reward_min: 584.9616333029118
total_envstep_count: 25434512
total_train_sample_count: 19067989
total_episode_count: 55936
total_duration: 5090.471873239805
[2023-06-29 14:44:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 234.2
avg_sample_per_episode: 234.2
avg_envstep_per_sec: 2596.2721031691713
avg_train_sample_per_sec: 2596.2721031691713
avg_episode_per_sec: 11.085704966563497
collect_time: 0.45103130699228505
reward_mean: 2277.814478765578
reward_std: 874.2064304516854
reward_max: 3431.556094867502
reward_min: 1192.945480401452
total_envstep_count: 25438976
total_train_sample_count: 19071560
total_episode_count: 55941
total_duration: 5090.922904546797
[2023-06-29 14:44:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1820
train_sample_count: 1820
avg_envstep_per_episode: 227.5
avg_sample_per_episode: 227.5
avg_envstep_per_sec: 2488.9743914329238
avg_train_sample_per_sec: 2488.9743914329238
avg_episode_per_sec: 10.940546775529334
collect_time: 0.731224879719317
reward_mean: 2301.6489046606102
reward_std: 1175.521263368043
reward_max: 3499.316159932434
reward_min: 185.04127368290037
total_envstep_count: 25443528
total_train_sample_count: 19074980
total_episode_count: 55949
total_duration: 5091.654129426516
[2023-06-29 14:44:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2861
train_sample_count: 2861
avg_envstep_per_episode: 260.09090909090907
avg_sample_per_episode: 260.09090909090907
avg_envstep_per_sec: 2507.457957154571
avg_train_sample_per_sec: 2507.457957154571
avg_episode_per_sec: 9.640698192485244
collect_time: 1.1409961996916684
reward_mean: 1947.1212446672419
reward_std: 799.0295003573489
reward_max: 3440.0306039908132
reward_min: 973.461646733659
total_envstep_count: 25447648
total_train_sample_count: 19078241
total_episode_count: 55960
total_duration: 5092.795125626208
[2023-06-29 14:44:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2742
train_sample_count: 2742
avg_envstep_per_episode: 342.75
avg_sample_per_episode: 342.75
avg_envstep_per_sec: 2544.6849369096058
avg_train_sample_per_sec: 2544.6849369096058
avg_episode_per_sec: 7.42431783197551
collect_time: 1.0775400758767502
reward_mean: 1710.9463785077096
reward_std: 834.1586360367236
reward_max: 3490.5056848964764
reward_min: 955.1674156517219
total_envstep_count: 25451880
total_train_sample_count: 19081783
total_episode_count: 55968
total_duration: 5093.872665702084
[2023-06-29 14:44:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2620
train_sample_count: 2620
avg_envstep_per_episode: 327.5
avg_sample_per_episode: 327.5
avg_envstep_per_sec: 2708.664070083139
avg_train_sample_per_sec: 2708.664070083139
avg_episode_per_sec: 8.270729984986684
collect_time: 0.9672664945563303
reward_mean: 1903.5915065268653
reward_std: 702.2208872611913
reward_max: 2962.8759682804243
reward_min: 1147.7908836424172
total_envstep_count: 25456776
total_train_sample_count: 19085203
total_episode_count: 55976
total_duration: 5094.839932196641
[2023-06-29 14:44:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2303
train_sample_count: 2303
avg_envstep_per_episode: 209.36363636363637
avg_sample_per_episode: 209.36363636363637
avg_envstep_per_sec: 2491.4120171617574
avg_train_sample_per_sec: 2491.4120171617574
avg_episode_per_sec: 11.899927133642782
collect_time: 0.9243754080561921
reward_mean: 1373.1494378719801
reward_std: 673.571355049318
reward_max: 3225.153350449943
reward_min: 652.9100219140356
total_envstep_count: 25461056
total_train_sample_count: 19088706
total_episode_count: 55987
total_duration: 5095.764307604697
[2023-06-29 14:44:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3162
train_sample_count: 3162
avg_envstep_per_episode: 287.45454545454544
avg_sample_per_episode: 287.45454545454544
avg_envstep_per_sec: 2564.1087945773897
avg_train_sample_per_sec: 2564.1087945773897
avg_episode_per_sec: 8.920049570003568
collect_time: 1.2331770035214724
reward_mean: 1825.7745823800142
reward_std: 773.3992714061119
reward_max: 3533.0635379030514
reward_min: 996.763057852921
total_envstep_count: 25465976
total_train_sample_count: 19092268
total_episode_count: 55998
total_duration: 5096.997484608219
[2023-06-29 14:44:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2627
train_sample_count: 2627
avg_envstep_per_episode: 202.07692307692307
avg_sample_per_episode: 202.07692307692307
avg_envstep_per_sec: 2578.3859170895344
avg_train_sample_per_sec: 2578.3859170895344
avg_episode_per_sec: 12.759427834854947
collect_time: 1.0188544634021819
reward_mean: 1154.392658271019
reward_std: 460.9462513500294
reward_max: 2645.294009639133
reward_min: 651.8077577612261
total_envstep_count: 25470848
total_train_sample_count: 19095695
total_episode_count: 56011
total_duration: 5098.016339071621
[2023-06-29 14:45:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2840
train_sample_count: 2840
avg_envstep_per_episode: 218.46153846153845
avg_sample_per_episode: 218.46153846153845
avg_envstep_per_sec: 2640.06635959158
avg_train_sample_per_sec: 2640.06635959158
avg_episode_per_sec: 12.084810800947373
collect_time: 1.0757305359700693
reward_mean: 1466.6526884402485
reward_std: 807.6116617563356
reward_max: 3560.9787050943837
reward_min: 946.031674911292
total_envstep_count: 25475296
total_train_sample_count: 19098935
total_episode_count: 56024
total_duration: 5099.092069607591
[2023-06-29 14:45:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 204.0
avg_sample_per_episode: 204.0
avg_envstep_per_sec: 2705.680346091206
avg_train_sample_per_sec: 2705.680346091206
avg_episode_per_sec: 13.26313895142748
collect_time: 0.9047631970038638
reward_mean: 1169.0090314582048
reward_std: 352.0014351680728
reward_max: 2253.3786875186765
reward_min: 875.1783637875069
total_envstep_count: 25480208
total_train_sample_count: 19102183
total_episode_count: 56036
total_duration: 5099.996832804595
[2023-06-29 14:45:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3305
train_sample_count: 3305
avg_envstep_per_episode: 220.33333333333334
avg_sample_per_episode: 220.33333333333334
avg_envstep_per_sec: 2614.223490192595
avg_train_sample_per_sec: 2614.223490192595
avg_episode_per_sec: 11.864856990284093
collect_time: 1.2642377411108467
reward_mean: 1419.6358122867632
reward_std: 758.6892390449348
reward_max: 3540.6516176794175
reward_min: 669.4630709330689
total_envstep_count: 25484784
total_train_sample_count: 19105488
total_episode_count: 56051
total_duration: 5101.261070545706
[2023-06-29 14:45:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2435
train_sample_count: 2435
avg_envstep_per_episode: 221.36363636363637
avg_sample_per_episode: 221.36363636363637
avg_envstep_per_sec: 2512.269272948394
avg_train_sample_per_sec: 2512.269272948394
avg_episode_per_sec: 11.349060370608761
collect_time: 0.9692432360732929
reward_mean: 1205.2171135638873
reward_std: 443.4830620519845
reward_max: 2328.7674475206154
reward_min: 680.5325870863397
total_envstep_count: 25489272
total_train_sample_count: 19108723
total_episode_count: 56062
total_duration: 5102.23031378178
[2023-06-29 14:45:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2872
train_sample_count: 2872
avg_envstep_per_episode: 261.09090909090907
avg_sample_per_episode: 261.09090909090907
avg_envstep_per_sec: 2637.1119003021863
avg_train_sample_per_sec: 2637.1119003021863
avg_episode_per_sec: 10.100358949625365
collect_time: 1.089070205807686
reward_mean: 1459.7555042265324
reward_std: 718.4148983191135
reward_max: 3518.3547847131904
reward_min: 954.3832007234834
total_envstep_count: 25493280
total_train_sample_count: 19111995
total_episode_count: 56073
total_duration: 5103.319383987588
[2023-06-29 14:45:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2818
train_sample_count: 2818
avg_envstep_per_episode: 234.83333333333334
avg_sample_per_episode: 234.83333333333334
avg_envstep_per_sec: 2762.335701582454
avg_train_sample_per_sec: 2762.335701582454
avg_episode_per_sec: 11.762962533353246
collect_time: 1.020151170759462
reward_mean: 1280.7205926064378
reward_std: 679.0005386320676
reward_max: 3419.2456161797563
reward_min: 654.1775321966296
total_envstep_count: 25497920
total_train_sample_count: 19115213
total_episode_count: 56085
total_duration: 5104.339535158347
[2023-06-29 14:45:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2569
train_sample_count: 2569
avg_envstep_per_episode: 256.9
avg_sample_per_episode: 256.9
avg_envstep_per_sec: 2509.299929002745
avg_train_sample_per_sec: 2509.299929002745
avg_episode_per_sec: 9.76761358117067
collect_time: 1.0237915246030318
reward_mean: 1499.2335613563953
reward_std: 770.0490038573006
reward_max: 3529.4225180763374
reward_min: 954.065422521419
total_envstep_count: 25502720
total_train_sample_count: 19118582
total_episode_count: 56095
total_duration: 5105.36332668295
[2023-06-29 14:45:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2302
train_sample_count: 2302
avg_envstep_per_episode: 209.27272727272728
avg_sample_per_episode: 209.27272727272728
avg_envstep_per_sec: 2672.2445165243626
avg_train_sample_per_sec: 2672.2445165243626
avg_episode_per_sec: 12.769196212757597
collect_time: 0.8614481144091115
reward_mean: 1573.0368227232013
reward_std: 786.5240152200585
reward_max: 3520.904480531908
reward_min: 971.7933811158568
total_envstep_count: 25507488
total_train_sample_count: 19122084
total_episode_count: 56106
total_duration: 5106.22477479736
[2023-06-29 14:45:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3165
train_sample_count: 3165
avg_envstep_per_episode: 211.0
avg_sample_per_episode: 211.0
avg_envstep_per_sec: 2593.2529521831793
avg_train_sample_per_sec: 2593.2529521831793
avg_episode_per_sec: 12.290298351579048
collect_time: 1.2204748469814657
reward_mean: 1357.9130664907816
reward_std: 517.5858692841098
reward_max: 2482.081927161965
reward_min: 743.7062390789398
total_envstep_count: 25512136
total_train_sample_count: 19125649
total_episode_count: 56121
total_duration: 5107.445249644341
[2023-06-29 14:45:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3275
train_sample_count: 3275
avg_envstep_per_episode: 251.92307692307693
avg_sample_per_episode: 251.92307692307693
avg_envstep_per_sec: 2598.137418979497
avg_train_sample_per_sec: 2598.137418979497
avg_episode_per_sec: 10.313217235643805
collect_time: 1.2605183913968503
reward_mean: 1321.4653142299348
reward_std: 584.2326197942114
reward_max: 3126.4543905169303
reward_min: 888.2609415727434
total_envstep_count: 25516904
total_train_sample_count: 19128924
total_episode_count: 56134
total_duration: 5108.7057680357375
[2023-06-29 14:45:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2166
train_sample_count: 2166
avg_envstep_per_episode: 216.6
avg_sample_per_episode: 216.6
avg_envstep_per_sec: 2749.9164742561024
avg_train_sample_per_sec: 2749.9164742561024
avg_episode_per_sec: 12.695828597673604
collect_time: 0.7876602872405201
reward_mean: 1310.3990276602797
reward_std: 478.23390069413426
reward_max: 2570.9247591927906
reward_min: 940.7423756126525
total_envstep_count: 25521352
total_train_sample_count: 19132290
total_episode_count: 56144
total_duration: 5109.493428322978
[2023-06-29 14:45:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2902
train_sample_count: 2902
avg_envstep_per_episode: 241.83333333333334
avg_sample_per_episode: 241.83333333333334
avg_envstep_per_sec: 2682.3996434704027
avg_train_sample_per_sec: 2682.3996434704027
avg_episode_per_sec: 11.091935121173272
collect_time: 1.081867128585465
reward_mean: 1457.2418078537091
reward_std: 583.298278963203
reward_max: 2391.0469993148145
reward_min: 189.03868089022632
total_envstep_count: 25525120
total_train_sample_count: 19135592
total_episode_count: 56156
total_duration: 5110.575295451563
[2023-06-29 14:45:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2294
train_sample_count: 2294
avg_envstep_per_episode: 286.75
avg_sample_per_episode: 286.75
avg_envstep_per_sec: 2331.092196106538
avg_train_sample_per_sec: 2331.092196106538
avg_episode_per_sec: 8.129353778924282
collect_time: 0.9840880613094196
reward_mean: 1538.7228692961382
reward_std: 785.2510121325054
reward_max: 3546.6430745825014
reward_min: 1050.7868011865467
total_envstep_count: 25530136
total_train_sample_count: 19139086
total_episode_count: 56164
total_duration: 5111.559383512872
[2023-06-29 14:45:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2464
train_sample_count: 2464
avg_envstep_per_episode: 246.4
avg_sample_per_episode: 246.4
avg_envstep_per_sec: 2514.3864192423434
avg_train_sample_per_sec: 2514.3864192423434
avg_episode_per_sec: 10.204490337834187
collect_time: 0.9799607495265081
reward_mean: 1910.5026420489216
reward_std: 926.3333271472627
reward_max: 3535.1016406902127
reward_min: 972.2565866134977
total_envstep_count: 25534808
total_train_sample_count: 19142350
total_episode_count: 56174
total_duration: 5112.539344262398
[2023-06-29 14:45:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2917
train_sample_count: 2917
avg_envstep_per_episode: 265.1818181818182
avg_sample_per_episode: 265.1818181818182
avg_envstep_per_sec: 2711.7147218396794
avg_train_sample_per_sec: 2711.7147218396794
avg_episode_per_sec: 10.2258697086858
collect_time: 1.0757031248556452
reward_mean: 1692.831934776087
reward_std: 708.4026473046155
reward_max: 3521.9511035588093
reward_min: 1014.0444206927459
total_envstep_count: 25539400
total_train_sample_count: 19145667
total_episode_count: 56185
total_duration: 5113.615047387254
[2023-06-29 14:45:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2203
train_sample_count: 2203
avg_envstep_per_episode: 200.27272727272728
avg_sample_per_episode: 200.27272727272728
avg_envstep_per_sec: 2788.602460180589
avg_train_sample_per_sec: 2788.602460180589
avg_episode_per_sec: 13.924024994092818
collect_time: 0.7900014546560123
reward_mean: 1205.6629842286975
reward_std: 269.8519428372704
reward_max: 1809.2827304114924
reward_min: 963.7898963059613
total_envstep_count: 25543576
total_train_sample_count: 19149070
total_episode_count: 56196
total_duration: 5114.40504884191
[2023-06-29 14:45:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2622
train_sample_count: 2622
avg_envstep_per_episode: 218.5
avg_sample_per_episode: 218.5
avg_envstep_per_sec: 2772.0464411563075
avg_train_sample_per_sec: 2772.0464411563075
avg_episode_per_sec: 12.686711401173032
collect_time: 0.9458715990725904
reward_mean: 1446.1183327125173
reward_std: 759.6064796847621
reward_max: 3624.4689869972285
reward_min: 576.5785634527612
total_envstep_count: 25548200
total_train_sample_count: 19152492
total_episode_count: 56208
total_duration: 5115.350920440982
[2023-06-29 14:45:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1311
train_sample_count: 1311
avg_envstep_per_episode: 187.28571428571428
avg_sample_per_episode: 187.28571428571428
avg_envstep_per_sec: 2291.970571848334
avg_train_sample_per_sec: 2291.970571848334
avg_episode_per_sec: 12.237829140303845
collect_time: 0.5719968729540705
reward_mean: 1522.0427332703896
reward_std: 626.9447134398341
reward_max: 2450.330264658571
reward_min: 942.6113461168896
total_envstep_count: 25552424
total_train_sample_count: 19155803
total_episode_count: 56215
total_duration: 5115.9229173139365
[2023-06-29 14:45:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3079
train_sample_count: 3079
avg_envstep_per_episode: 256.5833333333333
avg_sample_per_episode: 256.5833333333333
avg_envstep_per_sec: 2560.5977315345986
avg_train_sample_per_sec: 2560.5977315345986
avg_episode_per_sec: 9.979594926409607
collect_time: 1.2024536154512315
reward_mean: 1917.0101406017873
reward_std: 924.2911154914202
reward_max: 3521.1865731810035
reward_min: 188.18282836782316
total_envstep_count: 25556656
total_train_sample_count: 19159282
total_episode_count: 56227
total_duration: 5117.125370929388
[2023-06-29 14:46:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2964
train_sample_count: 2964
avg_envstep_per_episode: 329.3333333333333
avg_sample_per_episode: 329.3333333333333
avg_envstep_per_sec: 2750.558041279946
avg_train_sample_per_sec: 2750.558041279946
avg_episode_per_sec: 8.351896886477569
collect_time: 1.077599510905333
reward_mean: 1610.8733365168007
reward_std: 480.27841994974716
reward_max: 2216.4466784306924
reward_min: 783.2070853205031
total_envstep_count: 25561320
total_train_sample_count: 19162646
total_episode_count: 56236
total_duration: 5118.202970440293
[2023-06-29 14:46:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3287
train_sample_count: 3287
avg_envstep_per_episode: 252.84615384615384
avg_sample_per_episode: 252.84615384615384
avg_envstep_per_sec: 2468.5432644087564
avg_train_sample_per_sec: 2468.5432644087564
avg_episode_per_sec: 9.763024775574637
collect_time: 1.3315545436823741
reward_mean: 1428.3273675311866
reward_std: 550.9039291423176
reward_max: 3063.085814116409
reward_min: 1022.2692542075755
total_envstep_count: 25565672
total_train_sample_count: 19165933
total_episode_count: 56249
total_duration: 5119.534524983976
[2023-06-29 14:46:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2683
train_sample_count: 2683
avg_envstep_per_episode: 298.1111111111111
avg_sample_per_episode: 298.1111111111111
avg_envstep_per_sec: 2461.3528467729593
avg_train_sample_per_sec: 2461.3528467729593
avg_episode_per_sec: 8.256494827043099
collect_time: 1.0900509463800117
reward_mean: 1525.0534013040838
reward_std: 531.8141437060298
reward_max: 2606.9278666361342
reward_min: 1058.1744199716568
total_envstep_count: 25570288
total_train_sample_count: 19169416
total_episode_count: 56258
total_duration: 5120.624575930356
[2023-06-29 14:46:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2197
train_sample_count: 2197
avg_envstep_per_episode: 244.11111111111111
avg_sample_per_episode: 244.11111111111111
avg_envstep_per_sec: 2506.7454453518517
avg_train_sample_per_sec: 2506.7454453518517
avg_episode_per_sec: 10.268870736534668
collect_time: 0.8764352216431872
reward_mean: 1535.5732572067175
reward_std: 660.0101104682016
reward_max: 2648.901178812632
reward_min: 652.3996492748961
total_envstep_count: 25574784
total_train_sample_count: 19172813
total_episode_count: 56267
total_duration: 5121.501011151999
[2023-06-29 14:46:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2116
train_sample_count: 2116
avg_envstep_per_episode: 264.5
avg_sample_per_episode: 264.5
avg_envstep_per_sec: 2694.4580002944995
avg_train_sample_per_sec: 2694.4580002944995
avg_episode_per_sec: 10.186986768599242
collect_time: 0.7853156366767361
reward_mean: 2156.7989596044117
reward_std: 776.5428726226078
reward_max: 3399.7389118680135
reward_min: 1062.3588779367396
total_envstep_count: 25579792
total_train_sample_count: 19176129
total_episode_count: 56275
total_duration: 5122.286326788675
[2023-06-29 14:46:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 200.7
avg_sample_per_episode: 200.7
avg_envstep_per_sec: 2741.4981085966147
avg_train_sample_per_sec: 2741.4981085966147
avg_episode_per_sec: 13.659681657182933
collect_time: 0.7320814826413987
reward_mean: 1575.0224396601664
reward_std: 570.1460964244977
reward_max: 2628.7010629434512
reward_min: 710.6652508927034
total_envstep_count: 25583880
total_train_sample_count: 19179336
total_episode_count: 56285
total_duration: 5123.018408271317
[2023-06-29 14:46:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1305
train_sample_count: 1305
avg_envstep_per_episode: 217.5
avg_sample_per_episode: 217.5
avg_envstep_per_sec: 2719.912335955979
avg_train_sample_per_sec: 2719.912335955979
avg_episode_per_sec: 12.505344073360822
collect_time: 0.47979487527906894
reward_mean: 2038.7863796455838
reward_std: 973.129912012034
reward_max: 3506.902499284592
reward_min: 1143.9352615282598
total_envstep_count: 25588968
total_train_sample_count: 19182641
total_episode_count: 56291
total_duration: 5123.498203146596
[2023-06-29 14:46:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2954
train_sample_count: 2954
avg_envstep_per_episode: 268.54545454545456
avg_sample_per_episode: 268.54545454545456
avg_envstep_per_sec: 2518.778855578571
avg_train_sample_per_sec: 2518.778855578571
avg_episode_per_sec: 9.37933900181594
collect_time: 1.1727905343724419
reward_mean: 2354.374742031426
reward_std: 1086.2899070691337
reward_max: 3544.008192040719
reward_min: 712.8839332167516
total_envstep_count: 25593544
total_train_sample_count: 19185995
total_episode_count: 56302
total_duration: 5124.670993680968
[2023-06-29 14:46:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2517
train_sample_count: 2517
avg_envstep_per_episode: 209.75
avg_sample_per_episode: 209.75
avg_envstep_per_sec: 2791.658306331026
avg_train_sample_per_sec: 2791.658306331026
avg_episode_per_sec: 13.309455572495953
collect_time: 0.9016146404063328
reward_mean: 1254.8976600952399
reward_std: 266.354138362383
reward_max: 1931.6206391712838
reward_min: 961.9006298664817
total_envstep_count: 25597648
total_train_sample_count: 19189312
total_episode_count: 56314
total_duration: 5125.572608321375
[2023-06-29 14:46:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2859
train_sample_count: 2859
avg_envstep_per_episode: 285.9
avg_sample_per_episode: 285.9
avg_envstep_per_sec: 2627.285396668542
avg_train_sample_per_sec: 2627.285396668542
avg_episode_per_sec: 9.189525696637082
collect_time: 1.0881954444786537
reward_mean: 1618.9828334587137
reward_std: 566.3181195061782
reward_max: 2816.4463595921934
reward_min: 964.9179287308004
total_envstep_count: 25602536
total_train_sample_count: 19192571
total_episode_count: 56324
total_duration: 5126.660803765853
[2023-06-29 14:46:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2404
train_sample_count: 2404
avg_envstep_per_episode: 267.1111111111111
avg_sample_per_episode: 267.1111111111111
avg_envstep_per_sec: 2446.414828690282
avg_train_sample_per_sec: 2446.414828690282
avg_episode_per_sec: 9.158790955995231
collect_time: 0.9826624543830986
reward_mean: 1628.237957765855
reward_std: 738.9460130581837
reward_max: 3534.1375696087534
reward_min: 900.3236050334132
total_envstep_count: 25606752
total_train_sample_count: 19195775
total_episode_count: 56333
total_duration: 5127.643466220236
[2023-06-29 14:46:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1913
train_sample_count: 1913
avg_envstep_per_episode: 212.55555555555554
avg_sample_per_episode: 212.55555555555554
avg_envstep_per_sec: 2464.6924885527314
avg_train_sample_per_sec: 2464.6924885527314
avg_episode_per_sec: 11.595521378449861
collect_time: 0.7761617357479409
reward_mean: 1487.5421590610993
reward_std: 770.7272230267897
reward_max: 3474.0744409366484
reward_min: 620.4654602552353
total_envstep_count: 25610680
total_train_sample_count: 19199288
total_episode_count: 56342
total_duration: 5128.419627955985
[2023-06-29 14:46:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2495
train_sample_count: 2495
avg_envstep_per_episode: 249.5
avg_sample_per_episode: 249.5
avg_envstep_per_sec: 2659.2139449232945
avg_train_sample_per_sec: 2659.2139449232945
avg_episode_per_sec: 10.65817212394106
collect_time: 0.9382471857005731
reward_mean: 1548.0595235084627
reward_std: 642.839498230597
reward_max: 2634.691745088281
reward_min: 928.9837730189419
total_envstep_count: 25615016
total_train_sample_count: 19202583
total_episode_count: 56352
total_duration: 5129.357875141685
[2023-06-29 14:46:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 266.9166666666667
avg_sample_per_episode: 266.9166666666667
avg_envstep_per_sec: 2466.842827134086
avg_train_sample_per_sec: 2466.842827134086
avg_episode_per_sec: 9.241996230286928
collect_time: 1.2984207849679514
reward_mean: 1667.0627073430708
reward_std: 713.3160273332405
reward_max: 3568.578149346183
reward_min: 979.5741989978641
total_envstep_count: 25620024
total_train_sample_count: 19205786
total_episode_count: 56364
total_duration: 5130.656295926653
[2023-06-29 14:46:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2933
train_sample_count: 2933
avg_envstep_per_episode: 325.8888888888889
avg_sample_per_episode: 325.8888888888889
avg_envstep_per_sec: 2540.410318501048
avg_train_sample_per_sec: 2540.410318501048
avg_episode_per_sec: 7.795326582512593
collect_time: 1.1545379022592683
reward_mean: 1893.5210895927032
reward_std: 746.0739434140107
reward_max: 3160.402896159304
reward_min: 992.5491369322966
total_envstep_count: 25624320
total_train_sample_count: 19209119
total_episode_count: 56373
total_duration: 5131.810833828912
[2023-06-29 14:46:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 268.25
avg_sample_per_episode: 268.25
avg_envstep_per_sec: 2620.2187930662512
avg_train_sample_per_sec: 2620.2187930662512
avg_episode_per_sec: 9.767824018886305
collect_time: 1.2285233616819604
reward_mean: 1367.749291855627
reward_std: 398.47636202045663
reward_max: 2149.6251824441574
reward_min: 923.6144417686826
total_envstep_count: 25628664
total_train_sample_count: 19212338
total_episode_count: 56385
total_duration: 5133.039357190594
[2023-06-29 14:46:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 352.85714285714283
avg_sample_per_episode: 352.85714285714283
avg_envstep_per_sec: 2774.824200646972
avg_train_sample_per_sec: 2774.824200646972
avg_episode_per_sec: 7.863874252845669
collect_time: 0.8901464818650855
reward_mean: 1790.2128133260128
reward_std: 622.6867061797336
reward_max: 2985.567536852707
reward_min: 949.9589028189882
total_envstep_count: 25633368
total_train_sample_count: 19215608
total_episode_count: 56392
total_duration: 5133.92950367246
[2023-06-29 14:46:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2297
train_sample_count: 2297
avg_envstep_per_episode: 255.22222222222223
avg_sample_per_episode: 255.22222222222223
avg_envstep_per_sec: 2455.5892485332674
avg_train_sample_per_sec: 2455.5892485332674
avg_episode_per_sec: 9.621377116586594
collect_time: 0.9354170292820783
reward_mean: 1773.992523550427
reward_std: 859.5760592636962
reward_max: 3477.2786371524244
reward_min: 1047.2248117280856
total_envstep_count: 25638056
total_train_sample_count: 19219105
total_episode_count: 56401
total_duration: 5134.8649207017415
[2023-06-29 14:46:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1607
train_sample_count: 1607
avg_envstep_per_episode: 229.57142857142858
avg_sample_per_episode: 229.57142857142858
avg_envstep_per_sec: 2302.3804961359297
avg_train_sample_per_sec: 2302.3804961359297
avg_episode_per_sec: 10.029037630959246
collect_time: 0.6979732510317116
reward_mean: 1799.1543988896108
reward_std: 630.0423536057363
reward_max: 3033.777995028124
reward_min: 1124.6278118152168
total_envstep_count: 25642120
total_train_sample_count: 19222312
total_episode_count: 56408
total_duration: 5135.562893952773
[2023-06-29 14:47:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2350
train_sample_count: 2350
avg_envstep_per_episode: 261.1111111111111
avg_sample_per_episode: 261.1111111111111
avg_envstep_per_sec: 2724.9314671769803
avg_train_sample_per_sec: 2724.9314671769803
avg_episode_per_sec: 10.435907746635245
collect_time: 0.8624070103438571
reward_mean: 2175.37546835622
reward_std: 1002.3662439288967
reward_max: 3471.1590121330555
reward_min: 845.3377317054268
total_envstep_count: 25647008
total_train_sample_count: 19225862
total_episode_count: 56417
total_duration: 5136.4253009631175
[2023-06-29 14:47:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2954
train_sample_count: 2954
avg_envstep_per_episode: 268.54545454545456
avg_sample_per_episode: 268.54545454545456
avg_envstep_per_sec: 2727.231278755587
avg_train_sample_per_sec: 2727.231278755587
avg_episode_per_sec: 10.155566711682958
collect_time: 1.0831497948160398
reward_mean: 1793.7513652933187
reward_std: 718.8754999349686
reward_max: 3274.023192532831
reward_min: 789.04505571452
total_envstep_count: 25651720
total_train_sample_count: 19229216
total_episode_count: 56428
total_duration: 5137.508450757933
[2023-06-29 14:47:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2480
train_sample_count: 2480
avg_envstep_per_episode: 225.45454545454547
avg_sample_per_episode: 225.45454545454547
avg_envstep_per_sec: 2739.532921864292
avg_train_sample_per_sec: 2739.532921864292
avg_episode_per_sec: 12.151154088914197
collect_time: 0.9052638061791658
reward_mean: 1206.6084500206844
reward_std: 394.75206506983824
reward_max: 1768.7620888721474
reward_min: 571.2364413464517
total_envstep_count: 25655808
total_train_sample_count: 19232496
total_episode_count: 56439
total_duration: 5138.4137145641125
[2023-06-29 14:47:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3557
train_sample_count: 3557
avg_envstep_per_episode: 296.4166666666667
avg_sample_per_episode: 296.4166666666667
avg_envstep_per_sec: 2578.154811420308
avg_train_sample_per_sec: 2578.154811420308
avg_episode_per_sec: 8.697739032061763
collect_time: 1.3796688950732348
reward_mean: 1610.2373713804716
reward_std: 661.1468742011663
reward_max: 3319.130043382544
reward_min: 1013.1102584397688
total_envstep_count: 25660280
total_train_sample_count: 19236053
total_episode_count: 56451
total_duration: 5139.793383459186
[2023-06-29 14:47:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2260
train_sample_count: 2260
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 2762.355431804795
avg_train_sample_per_sec: 2762.355431804795
avg_episode_per_sec: 12.222811645153959
collect_time: 0.8181423628469928
reward_mean: 1038.8027444690756
reward_std: 368.9226915843538
reward_max: 1544.704196043826
reward_min: 566.9399087755422
total_envstep_count: 25664824
total_train_sample_count: 19239513
total_episode_count: 56461
total_duration: 5140.6115258220325
[2023-06-29 14:47:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2968
train_sample_count: 2968
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2743.1347147521906
avg_train_sample_per_sec: 2743.1347147521906
avg_episode_per_sec: 12.939314692227315
collect_time: 1.081973839650862
reward_mean: 1288.3458733146365
reward_std: 579.0916298844699
reward_max: 2359.0261693229604
reward_min: 568.4551163336407
total_envstep_count: 25669456
total_train_sample_count: 19242881
total_episode_count: 56475
total_duration: 5141.693499661684
[2023-06-29 14:47:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 222.55555555555554
avg_sample_per_episode: 222.55555555555554
avg_envstep_per_sec: 2798.2802357648557
avg_train_sample_per_sec: 2798.2802357648557
avg_episode_per_sec: 12.573400959502598
collect_time: 0.7157967863259838
reward_mean: 1424.8622677021401
reward_std: 480.7045863957026
reward_max: 1953.3295241308865
reward_min: 581.3373413724789
total_envstep_count: 25674048
total_train_sample_count: 19246084
total_episode_count: 56484
total_duration: 5142.40929644801
[2023-06-29 14:47:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1466
train_sample_count: 1466
avg_envstep_per_episode: 244.33333333333334
avg_sample_per_episode: 244.33333333333334
avg_envstep_per_sec: 2624.112873525229
avg_train_sample_per_sec: 2624.112873525229
avg_episode_per_sec: 10.739888977593026
collect_time: 0.5586649929545819
reward_mean: 1935.6376226499012
reward_std: 718.0361877432822
reward_max: 3472.2887993481518
reward_min: 1330.0075591955235
total_envstep_count: 25679296
total_train_sample_count: 19249550
total_episode_count: 56490
total_duration: 5142.967961440964
[2023-06-29 14:47:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2258
train_sample_count: 2258
avg_envstep_per_episode: 205.27272727272728
avg_sample_per_episode: 205.27272727272728
avg_envstep_per_sec: 2588.6325237143355
avg_train_sample_per_sec: 2588.6325237143355
avg_episode_per_sec: 12.610698742629625
collect_time: 0.8722752184076236
reward_mean: 2206.8194939099035
reward_std: 1083.4201713755042
reward_max: 3610.651001142299
reward_min: 655.7783993473384
total_envstep_count: 25683320
total_train_sample_count: 19253008
total_episode_count: 56501
total_duration: 5143.840236659372
[2023-06-29 14:47:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 321.0
avg_sample_per_episode: 321.0
avg_envstep_per_sec: 2608.323009175105
avg_train_sample_per_sec: 2608.323009175105
avg_episode_per_sec: 8.12561685101279
collect_time: 1.2306757977092637
reward_mean: 1810.85791141661
reward_std: 593.2274779815405
reward_max: 2833.490999821914
reward_min: 919.3376463971526
total_envstep_count: 25688296
total_train_sample_count: 19256218
total_episode_count: 56511
total_duration: 5145.070912457081
[2023-06-29 14:47:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1696
train_sample_count: 1696
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2804.0216663239335
avg_train_sample_per_sec: 2804.0216663239335
avg_episode_per_sec: 13.226517293980818
collect_time: 0.6048455403782427
reward_mean: 1532.0720137848596
reward_std: 403.05899758225655
reward_max: 2259.1986354237965
reward_min: 986.9378092525045
total_envstep_count: 25693224
total_train_sample_count: 19259514
total_episode_count: 56519
total_duration: 5145.675757997459
[2023-06-29 14:47:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1779
train_sample_count: 1779
avg_envstep_per_episode: 254.14285714285714
avg_sample_per_episode: 254.14285714285714
avg_envstep_per_sec: 2748.245070099443
avg_train_sample_per_sec: 2748.245070099443
avg_episode_per_sec: 10.813780489430075
collect_time: 0.6473221836565064
reward_mean: 2301.2404855098603
reward_std: 759.9304100134009
reward_max: 3481.981657505074
reward_min: 1179.4631099233357
total_envstep_count: 25697928
total_train_sample_count: 19262893
total_episode_count: 56526
total_duration: 5146.323080181116
[2023-06-29 14:47:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2917
train_sample_count: 2917
avg_envstep_per_episode: 324.1111111111111
avg_sample_per_episode: 324.1111111111111
avg_envstep_per_sec: 2507.7578609498537
avg_train_sample_per_sec: 2507.7578609498537
avg_episode_per_sec: 7.737339989217924
collect_time: 1.1631904520858083
reward_mean: 2559.127798623844
reward_std: 1086.034900937052
reward_max: 3664.9337093588447
reward_min: 1033.7691233550229
total_envstep_count: 25703032
total_train_sample_count: 19266210
total_episode_count: 56535
total_duration: 5147.4862706332015
[2023-06-29 14:47:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1626
train_sample_count: 1626
avg_envstep_per_episode: 232.28571428571428
avg_sample_per_episode: 232.28571428571428
avg_envstep_per_sec: 2708.9650359567645
avg_train_sample_per_sec: 2708.9650359567645
avg_episode_per_sec: 11.662211101904889
collect_time: 0.6002292308751493
reward_mean: 1723.4877732362024
reward_std: 630.306530203637
reward_max: 2826.6724769891603
reward_min: 1082.430165823488
total_envstep_count: 25707200
total_train_sample_count: 19269436
total_episode_count: 56542
total_duration: 5148.086499864076
[2023-06-29 14:47:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2366
train_sample_count: 2366
avg_envstep_per_episode: 262.8888888888889
avg_sample_per_episode: 262.8888888888889
avg_envstep_per_sec: 2780.656664739364
avg_train_sample_per_sec: 2780.656664739364
avg_episode_per_sec: 10.577307684976448
collect_time: 0.8508781504752114
reward_mean: 2161.0089728720895
reward_std: 986.2499438454197
reward_max: 3483.5466908342437
reward_min: 972.1595384693812
total_envstep_count: 25712104
total_train_sample_count: 19273002
total_episode_count: 56551
total_duration: 5148.9373780145515
[2023-06-29 14:47:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1757
train_sample_count: 1757
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2778.7869330570006
avg_train_sample_per_sec: 2778.7869330570006
avg_episode_per_sec: 11.070864275127493
collect_time: 0.6322902915291487
reward_mean: 1666.2811225965347
reward_std: 589.3657925066567
reward_max: 2785.4108123809447
reward_min: 1016.186566310771
total_envstep_count: 25716304
total_train_sample_count: 19276359
total_episode_count: 56558
total_duration: 5149.5696683060805
[2023-06-29 14:47:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2628
train_sample_count: 2628
avg_envstep_per_episode: 262.8
avg_sample_per_episode: 262.8
avg_envstep_per_sec: 2653.989023345607
avg_train_sample_per_sec: 2653.989023345607
avg_episode_per_sec: 10.098892782898048
collect_time: 0.9902075618561356
reward_mean: 2231.0627423787705
reward_std: 992.4770816942641
reward_max: 3611.2459754945717
reward_min: 1184.618798331659
total_envstep_count: 25720632
total_train_sample_count: 19279787
total_episode_count: 56568
total_duration: 5150.559875867937
[2023-06-29 14:47:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 248.9
avg_sample_per_episode: 248.9
avg_envstep_per_sec: 2555.230784752493
avg_train_sample_per_sec: 2555.230784752493
avg_episode_per_sec: 10.266093952400533
collect_time: 0.9740803119828927
reward_mean: 1527.11808142776
reward_std: 549.9233915701154
reward_max: 2472.9400355565062
reward_min: 654.278090512412
total_envstep_count: 25725104
total_train_sample_count: 19283076
total_episode_count: 56578
total_duration: 5151.53395617992
[2023-06-29 14:47:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3122
train_sample_count: 3122
avg_envstep_per_episode: 260.1666666666667
avg_sample_per_episode: 260.1666666666667
avg_envstep_per_sec: 2695.4616396520323
avg_train_sample_per_sec: 2695.4616396520323
avg_episode_per_sec: 10.360518794306339
collect_time: 1.1582431573402139
reward_mean: 1550.891881659073
reward_std: 430.54370732120015
reward_max: 2462.187054071477
reward_min: 966.4946955927876
total_envstep_count: 25729864
total_train_sample_count: 19286598
total_episode_count: 56590
total_duration: 5152.692199337261
[2023-06-29 14:47:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2962
train_sample_count: 2962
avg_envstep_per_episode: 269.27272727272725
avg_sample_per_episode: 269.27272727272725
avg_envstep_per_sec: 2712.475131749344
avg_train_sample_per_sec: 2712.475131749344
avg_episode_per_sec: 10.073337761391892
collect_time: 1.0919915782194585
reward_mean: 1497.560022036985
reward_std: 533.899372027552
reward_max: 3044.9818833884656
reward_min: 970.2116486384699
total_envstep_count: 25734352
total_train_sample_count: 19289960
total_episode_count: 56601
total_duration: 5153.78419091548
[2023-06-29 14:48:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2562.3100143898178
avg_train_sample_per_sec: 2562.3100143898178
avg_episode_per_sec: 9.022218360527528
collect_time: 0.9975373727791013
reward_mean: 1655.720888075989
reward_std: 479.3873629214864
reward_max: 2896.952931206221
reward_min: 1109.5247668116215
total_envstep_count: 25739160
total_train_sample_count: 19293316
total_episode_count: 56610
total_duration: 5154.78172828826
[2023-06-29 14:48:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 222.9090909090909
avg_sample_per_episode: 222.9090909090909
avg_envstep_per_sec: 2669.72694267888
avg_train_sample_per_sec: 2669.72694267888
avg_episode_per_sec: 11.976752189831842
collect_time: 0.9184459881652143
reward_mean: 1551.9476719524891
reward_std: 453.924276842597
reward_max: 2282.5760768060923
reward_min: 702.2971551303755
total_envstep_count: 25744072
total_train_sample_count: 19296568
total_episode_count: 56621
total_duration: 5155.700174276425
[2023-06-29 14:48:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2387
train_sample_count: 2387
avg_envstep_per_episode: 238.7
avg_sample_per_episode: 238.7
avg_envstep_per_sec: 2570.825797814287
avg_train_sample_per_sec: 2570.825797814287
avg_episode_per_sec: 10.770112265665215
collect_time: 0.9284954282119872
reward_mean: 1643.6640088363597
reward_std: 346.8187792914836
reward_max: 2010.9969751275353
reward_min: 1053.1920892885591
total_envstep_count: 25748576
total_train_sample_count: 19300155
total_episode_count: 56631
total_duration: 5156.628669704637
[2023-06-29 14:48:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 339.3333333333333
avg_sample_per_episode: 339.3333333333333
avg_envstep_per_sec: 2815.679430312817
avg_train_sample_per_sec: 2815.679430312817
avg_episode_per_sec: 8.297680050037771
collect_time: 0.7230936796572058
reward_mean: 2330.2209523783754
reward_std: 981.7425280818842
reward_max: 3551.477013603894
reward_min: 1148.4792698977064
total_envstep_count: 25752904
total_train_sample_count: 19303391
total_episode_count: 56637
total_duration: 5157.351763384294
[2023-06-29 14:48:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1840
train_sample_count: 1840
avg_envstep_per_episode: 262.85714285714283
avg_sample_per_episode: 262.85714285714283
avg_envstep_per_sec: 2403.8541173256644
avg_train_sample_per_sec: 2403.8541173256644
avg_episode_per_sec: 9.145097185478072
collect_time: 0.7654374642530457
reward_mean: 2278.1754392922116
reward_std: 758.6771829481752
reward_max: 3575.402542743305
reward_min: 1338.057204672008
total_envstep_count: 25757528
total_train_sample_count: 19306831
total_episode_count: 56644
total_duration: 5158.117200848547
[2023-06-29 14:48:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1745
train_sample_count: 1745
avg_envstep_per_episode: 249.28571428571428
avg_sample_per_episode: 249.28571428571428
avg_envstep_per_sec: 2578.1249437089996
avg_train_sample_per_sec: 2578.1249437089996
avg_episode_per_sec: 10.342048484792548
collect_time: 0.6768484996268526
reward_mean: 2389.7436907977817
reward_std: 1011.109886002858
reward_max: 3583.3824984234525
reward_min: 1205.5582250223408
total_envstep_count: 25761304
total_train_sample_count: 19310176
total_episode_count: 56651
total_duration: 5158.794049348174
[2023-06-29 14:48:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2266
train_sample_count: 2266
avg_envstep_per_episode: 283.25
avg_sample_per_episode: 283.25
avg_envstep_per_sec: 2488.6774365517726
avg_train_sample_per_sec: 2488.6774365517726
avg_episode_per_sec: 8.78615158535489
collect_time: 0.9105237853322177
reward_mean: 2016.737388488335
reward_std: 809.8698833152288
reward_max: 3513.0785768689625
reward_min: 885.855928555699
total_envstep_count: 25765848
total_train_sample_count: 19313642
total_episode_count: 56659
total_duration: 5159.704573133506
[2023-06-29 14:48:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 223.9
avg_sample_per_episode: 223.9
avg_envstep_per_sec: 2770.9974363174333
avg_train_sample_per_sec: 2770.9974363174333
avg_episode_per_sec: 12.376049291279292
collect_time: 0.8080122957369311
reward_mean: 1664.2559608869778
reward_std: 709.80784131282
reward_max: 2606.407170758902
reward_min: 187.46984080403246
total_envstep_count: 25770928
total_train_sample_count: 19317081
total_episode_count: 56669
total_duration: 5160.512585429243
[2023-06-29 14:48:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2530
train_sample_count: 2530
avg_envstep_per_episode: 281.1111111111111
avg_sample_per_episode: 281.1111111111111
avg_envstep_per_sec: 2698.8582925248606
avg_train_sample_per_sec: 2698.8582925248606
avg_episode_per_sec: 9.600681673013337
collect_time: 0.9374334350964056
reward_mean: 2079.193590229162
reward_std: 925.8445820515856
reward_max: 3588.123172299808
reward_min: 1113.0255914648553
total_envstep_count: 25774616
total_train_sample_count: 19320411
total_episode_count: 56678
total_duration: 5161.450018864339
[2023-06-29 14:48:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2651.3899219291607
avg_train_sample_per_sec: 2651.3899219291607
avg_episode_per_sec: 11.94319784652775
collect_time: 0.33491867516562335
reward_mean: 1636.6055860440272
reward_std: 724.9862601535494
reward_max: 2882.9510291844063
reward_min: 1131.9733372771577
total_envstep_count: 25778752
total_train_sample_count: 19323699
total_episode_count: 56682
total_duration: 5161.784937539504
[2023-06-29 14:48:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1617
train_sample_count: 1617
avg_envstep_per_episode: 202.125
avg_sample_per_episode: 202.125
avg_envstep_per_sec: 2305.007944839324
avg_train_sample_per_sec: 2305.007944839324
avg_episode_per_sec: 11.40387356754149
collect_time: 0.7015160202030093
reward_mean: 2102.2062656483236
reward_std: 872.0176953906181
reward_max: 3521.6808246579417
reward_min: 1227.110064062834
total_envstep_count: 25782544
total_train_sample_count: 19326916
total_episode_count: 56690
total_duration: 5162.486453559707
[2023-06-29 14:48:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 184.5
avg_sample_per_episode: 184.5
avg_envstep_per_sec: 2637.5627763523307
avg_train_sample_per_sec: 2637.5627763523307
avg_episode_per_sec: 14.295733205161683
collect_time: 0.41970565020292994
reward_mean: 2047.989261777676
reward_std: 805.4552592088421
reward_max: 3471.6432935217044
reward_min: 1233.1705254847107
total_envstep_count: 25786640
total_train_sample_count: 19330423
total_episode_count: 56696
total_duration: 5162.90615920991
[2023-06-29 14:48:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1300
train_sample_count: 1300
avg_envstep_per_episode: 144.44444444444446
avg_sample_per_episode: 144.44444444444446
avg_envstep_per_sec: 2629.5654422299544
avg_train_sample_per_sec: 2629.5654422299544
avg_episode_per_sec: 18.20468383082276
collect_time: 0.4943782646069303
reward_mean: 1929.3403051077248
reward_std: 688.6351453677411
reward_max: 3712.058242647247
reward_min: 1267.882284493109
total_envstep_count: 25790976
total_train_sample_count: 19333723
total_episode_count: 56705
total_duration: 5163.400537474517
[2023-06-29 14:48:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2836
train_sample_count: 2836
avg_envstep_per_episode: 283.6
avg_sample_per_episode: 283.6
avg_envstep_per_sec: 2592.149973797067
avg_train_sample_per_sec: 2592.149973797067
avg_episode_per_sec: 9.140162107888107
collect_time: 1.0940724991485478
reward_mean: 2144.6826597556123
reward_std: 883.7276490072246
reward_max: 3618.36364408565
reward_min: 1228.9494143214063
total_envstep_count: 25794912
total_train_sample_count: 19336959
total_episode_count: 56715
total_duration: 5164.494609973665
[2023-06-29 14:48:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2906
train_sample_count: 2906
avg_envstep_per_episode: 322.8888888888889
avg_sample_per_episode: 322.8888888888889
avg_envstep_per_sec: 2402.0038853389096
avg_train_sample_per_sec: 2402.0038853389096
avg_episode_per_sec: 7.439103567808048
collect_time: 1.2098231887705624
reward_mean: 1609.1013660201666
reward_std: 488.5535719459899
reward_max: 2575.742593787475
reward_min: 1016.3000688949378
total_envstep_count: 25799376
total_train_sample_count: 19340265
total_episode_count: 56724
total_duration: 5165.704433162436
[2023-06-29 14:48:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 271.1111111111111
avg_sample_per_episode: 271.1111111111111
avg_envstep_per_sec: 2669.1174248258603
avg_train_sample_per_sec: 2669.1174248258603
avg_episode_per_sec: 9.845105255505223
collect_time: 0.9141598557280377
reward_mean: 1641.361097984503
reward_std: 428.68520161265934
reward_max: 2609.6591243700705
reward_min: 1104.7486365459506
total_envstep_count: 25803584
total_train_sample_count: 19343505
total_episode_count: 56733
total_duration: 5166.618593018164
[2023-06-29 14:48:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 275.44444444444446
avg_sample_per_episode: 275.44444444444446
avg_envstep_per_sec: 2556.3837647749933
avg_train_sample_per_sec: 2556.3837647749933
avg_episode_per_sec: 9.280941461466293
collect_time: 0.9697292066076768
reward_mean: 1714.082874801968
reward_std: 531.5823880232779
reward_max: 2906.17359114383
reward_min: 1006.7882371051904
total_envstep_count: 25807752
total_train_sample_count: 19346784
total_episode_count: 56742
total_duration: 5167.588322224771
[2023-06-29 14:48:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3508
train_sample_count: 3508
avg_envstep_per_episode: 292.3333333333333
avg_sample_per_episode: 292.3333333333333
avg_envstep_per_sec: 2629.6503324901337
avg_train_sample_per_sec: 2629.6503324901337
avg_episode_per_sec: 8.995383121402966
collect_time: 1.3340176664013415
reward_mean: 1587.728387445104
reward_std: 350.3250441131731
reward_max: 2257.254462617886
reward_min: 1230.9972278378673
total_envstep_count: 25812440
total_train_sample_count: 19350292
total_episode_count: 56754
total_duration: 5168.922339891173
[2023-06-29 14:48:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2749
train_sample_count: 2749
avg_envstep_per_episode: 305.44444444444446
avg_sample_per_episode: 305.44444444444446
avg_envstep_per_sec: 2542.4073356660656
avg_train_sample_per_sec: 2542.4073356660656
avg_episode_per_sec: 8.3236326013076
collect_time: 1.0812586800847201
reward_mean: 1588.3723016546728
reward_std: 596.5902613343429
reward_max: 3215.909632499424
reward_min: 1159.262047064689
total_envstep_count: 25817488
total_train_sample_count: 19353841
total_episode_count: 56763
total_duration: 5170.0035985712575
[2023-06-29 14:48:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2082
train_sample_count: 2082
avg_envstep_per_episode: 231.33333333333334
avg_sample_per_episode: 231.33333333333334
avg_envstep_per_sec: 2758.6701506897293
avg_train_sample_per_sec: 2758.6701506897293
avg_episode_per_sec: 11.925087106727936
collect_time: 0.7547114683063698
reward_mean: 1601.4182457629463
reward_std: 563.1829401589908
reward_max: 3034.6816452399116
reward_min: 1137.5596887176418
total_envstep_count: 25821768
total_train_sample_count: 19357123
total_episode_count: 56772
total_duration: 5170.758310039564
[2023-06-29 14:49:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2855
train_sample_count: 2855
avg_envstep_per_episode: 259.54545454545456
avg_sample_per_episode: 259.54545454545456
avg_envstep_per_sec: 2788.3416887403687
avg_train_sample_per_sec: 2788.3416887403687
avg_episode_per_sec: 10.743172881311402
collect_time: 1.0239060770524664
reward_mean: 1792.5090670479913
reward_std: 678.7172811982067
reward_max: 3559.236842081032
reward_min: 1061.823309577923
total_envstep_count: 25826224
total_train_sample_count: 19360378
total_episode_count: 56783
total_duration: 5171.782216116617
[2023-06-29 14:49:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1966
train_sample_count: 1966
avg_envstep_per_episode: 245.75
avg_sample_per_episode: 245.75
avg_envstep_per_sec: 2459.753595021777
avg_train_sample_per_sec: 2459.753595021777
avg_episode_per_sec: 10.009170274757993
collect_time: 0.7992670501545072
reward_mean: 1616.1945169527498
reward_std: 510.09319379977387
reward_max: 2670.0847139184953
reward_min: 1140.4601905886593
total_envstep_count: 25830552
total_train_sample_count: 19363944
total_episode_count: 56791
total_duration: 5172.581483166771
[2023-06-29 14:49:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 250.3
avg_sample_per_episode: 250.3
avg_envstep_per_sec: 2651.864547278386
avg_train_sample_per_sec: 2651.864547278386
avg_episode_per_sec: 10.59474449571868
collect_time: 0.9438641964457929
reward_mean: 1744.3261285075575
reward_std: 605.2852790335062
reward_max: 2708.02522645086
reward_min: 1233.7942891127564
total_envstep_count: 25834992
total_train_sample_count: 19367247
total_episode_count: 56801
total_duration: 5173.525347363217
[2023-06-29 14:49:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1947
train_sample_count: 1947
avg_envstep_per_episode: 243.375
avg_sample_per_episode: 243.375
avg_envstep_per_sec: 2687.6641979353235
avg_train_sample_per_sec: 2687.6641979353235
avg_episode_per_sec: 11.043304357207287
collect_time: 0.7244208564059806
reward_mean: 1777.486331948118
reward_std: 563.6889743099125
reward_max: 2885.5653502663363
reward_min: 1160.990038525474
total_envstep_count: 25840360
total_train_sample_count: 19370794
total_episode_count: 56809
total_duration: 5174.249768219624
[2023-06-29 14:49:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2475
train_sample_count: 2475
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 2596.707566244808
avg_train_sample_per_sec: 2596.707566244808
avg_episode_per_sec: 9.442572968162937
collect_time: 0.9531300452053546
reward_mean: 2188.2808010720805
reward_std: 1098.3684431956183
reward_max: 3508.8050633038442
reward_min: 192.44515847902005
total_envstep_count: 25844544
total_train_sample_count: 19374069
total_episode_count: 56818
total_duration: 5175.202898264829
[2023-06-29 14:49:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3369
train_sample_count: 3369
avg_envstep_per_episode: 306.27272727272725
avg_sample_per_episode: 306.27272727272725
avg_envstep_per_sec: 2661.896689792036
avg_train_sample_per_sec: 2661.896689792036
avg_episode_per_sec: 8.69126256684844
collect_time: 1.2656389006078246
reward_mean: 1802.289843129597
reward_std: 690.9615610725676
reward_max: 3481.6480187637317
reward_min: 1048.35672879287
total_envstep_count: 25849336
total_train_sample_count: 19377438
total_episode_count: 56829
total_duration: 5176.468537165437
[2023-06-29 14:49:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 243.9
avg_sample_per_episode: 243.9
avg_envstep_per_sec: 2651.28601049328
avg_train_sample_per_sec: 2651.28601049328
avg_episode_per_sec: 10.870381346835917
collect_time: 0.9199309279900045
reward_mean: 1413.0849806709207
reward_std: 343.0304253725712
reward_max: 2068.880277902648
reward_min: 1016.4773408464235
total_envstep_count: 25853352
total_train_sample_count: 19380677
total_episode_count: 56839
total_duration: 5177.388468093427
[2023-06-29 14:49:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2964
train_sample_count: 2964
avg_envstep_per_episode: 296.4
avg_sample_per_episode: 296.4
avg_envstep_per_sec: 2540.230978359
avg_train_sample_per_sec: 2540.230978359
avg_episode_per_sec: 8.570279953977733
collect_time: 1.1668230272172952
reward_mean: 1667.3930250394958
reward_std: 580.9633417825
reward_max: 3069.64308842306
reward_min: 1111.2821500451766
total_envstep_count: 25858184
total_train_sample_count: 19384041
total_episode_count: 56849
total_duration: 5178.555291120644
[2023-06-29 14:49:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1629
train_sample_count: 1629
avg_envstep_per_episode: 271.5
avg_sample_per_episode: 271.5
avg_envstep_per_sec: 2416.230077461545
avg_train_sample_per_sec: 2416.230077461545
avg_episode_per_sec: 8.899558296359281
collect_time: 0.6741907632038928
reward_mean: 1603.8872391882976
reward_std: 415.26979228875257
reward_max: 2415.4311435816808
reward_min: 1227.975458559207
total_envstep_count: 25862696
total_train_sample_count: 19387270
total_episode_count: 56855
total_duration: 5179.229481883848
[2023-06-29 14:49:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1504
train_sample_count: 1504
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 2061.3791538638857
avg_train_sample_per_sec: 2061.3791538638857
avg_episode_per_sec: 10.96478273331854
collect_time: 0.7296086201225407
reward_mean: 2385.628481520991
reward_std: 834.2272145096268
reward_max: 3519.3955758025213
reward_min: 1243.8135074133475
total_envstep_count: 25866784
total_train_sample_count: 19390774
total_episode_count: 56863
total_duration: 5179.95909050397
[2023-06-29 14:49:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2505
train_sample_count: 2505
avg_envstep_per_episode: 313.125
avg_sample_per_episode: 313.125
avg_envstep_per_sec: 2730.0738507150854
avg_train_sample_per_sec: 2730.0738507150854
avg_episode_per_sec: 8.718798724838596
collect_time: 0.9175575962327422
reward_mean: 2263.1393604762416
reward_std: 795.3998248537328
reward_max: 3580.5570527223394
reward_min: 1327.4347663708934
total_envstep_count: 25871408
total_train_sample_count: 19394079
total_episode_count: 56871
total_duration: 5180.876648100203
[2023-06-29 14:49:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2036
train_sample_count: 2036
avg_envstep_per_episode: 254.5
avg_sample_per_episode: 254.5
avg_envstep_per_sec: 2220.150223907766
avg_train_sample_per_sec: 2220.150223907766
avg_episode_per_sec: 8.723576518301634
collect_time: 0.9170550614437087
reward_mean: 1760.366036359307
reward_std: 603.2268319164016
reward_max: 2890.2959360638665
reward_min: 1081.0653877361694
total_envstep_count: 25875848
total_train_sample_count: 19397315
total_episode_count: 56879
total_duration: 5181.793703161647
[2023-06-29 14:49:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2213
train_sample_count: 2213
avg_envstep_per_episode: 221.3
avg_sample_per_episode: 221.3
avg_envstep_per_sec: 2422.9564499344046
avg_train_sample_per_sec: 2422.9564499344046
avg_episode_per_sec: 10.948741301104404
collect_time: 0.9133469980692024
reward_mean: 1804.279396860625
reward_std: 785.4867720915121
reward_max: 3655.2380153001104
reward_min: 995.1832120314845
total_envstep_count: 25880072
total_train_sample_count: 19400728
total_episode_count: 56889
total_duration: 5182.707050159715
[2023-06-29 14:49:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2518
train_sample_count: 2518
avg_envstep_per_episode: 251.8
avg_sample_per_episode: 251.8
avg_envstep_per_sec: 2426.342780678014
avg_train_sample_per_sec: 2426.342780678014
avg_episode_per_sec: 9.635991980452797
collect_time: 1.0377758740652354
reward_mean: 1627.4670376689962
reward_std: 872.7831403655199
reward_max: 3420.1723696396684
reward_min: 184.55716769458274
total_envstep_count: 25884640
total_train_sample_count: 19404046
total_episode_count: 56899
total_duration: 5183.744826033781
[2023-06-29 14:49:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1322
train_sample_count: 1322
avg_envstep_per_episode: 220.33333333333334
avg_sample_per_episode: 220.33333333333334
avg_envstep_per_sec: 2770.6476352938284
avg_train_sample_per_sec: 2770.6476352938284
avg_episode_per_sec: 12.574800160183791
collect_time: 0.47714475964382286
reward_mean: 1413.984843725468
reward_std: 123.71832048198571
reward_max: 1628.536445690174
reward_min: 1298.0029757409754
total_envstep_count: 25888824
total_train_sample_count: 19407368
total_episode_count: 56905
total_duration: 5184.221970793425
[2023-06-29 14:49:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2675
train_sample_count: 2675
avg_envstep_per_episode: 243.1818181818182
avg_sample_per_episode: 243.1818181818182
avg_envstep_per_sec: 2560.48483822384
avg_train_sample_per_sec: 2560.48483822384
avg_episode_per_sec: 10.529096531013922
collect_time: 1.0447240147907288
reward_mean: 2111.2812621242338
reward_std: 936.6284617072548
reward_max: 3542.2412018586733
reward_min: 1099.5853039313552
total_envstep_count: 25893616
total_train_sample_count: 19410843
total_episode_count: 56916
total_duration: 5185.266694808215
[2023-06-29 14:49:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2637
train_sample_count: 2637
avg_envstep_per_episode: 239.72727272727272
avg_sample_per_episode: 239.72727272727272
avg_envstep_per_sec: 2721.848384905474
avg_train_sample_per_sec: 2721.848384905474
avg_episode_per_sec: 11.353937138399779
collect_time: 0.9688269246090204
reward_mean: 1557.570140784691
reward_std: 922.8531117579395
reward_max: 3598.7406663712695
reward_min: 192.70826112411345
total_envstep_count: 25898712
total_train_sample_count: 19414280
total_episode_count: 56927
total_duration: 5186.235521732824
[2023-06-29 14:49:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1815
train_sample_count: 1815
avg_envstep_per_episode: 259.2857142857143
avg_sample_per_episode: 259.2857142857143
avg_envstep_per_sec: 2612.577610326972
avg_train_sample_per_sec: 2612.577610326972
avg_episode_per_sec: 10.076056899332674
collect_time: 0.6947162039610557
reward_mean: 1827.9470799835528
reward_std: 552.5443278359212
reward_max: 2895.8391018902907
reward_min: 1107.2680643690157
total_envstep_count: 25903248
total_train_sample_count: 19417695
total_episode_count: 56934
total_duration: 5186.9302379367855
[2023-06-29 14:49:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2876
train_sample_count: 2876
avg_envstep_per_episode: 287.6
avg_sample_per_episode: 287.6
avg_envstep_per_sec: 2579.6866472738375
avg_train_sample_per_sec: 2579.6866472738375
avg_episode_per_sec: 8.96970322417885
collect_time: 1.1148640874810516
reward_mean: 2278.4874633772806
reward_std: 751.3506488316623
reward_max: 3551.957550916067
reward_min: 1135.5121544420983
total_envstep_count: 25907736
total_train_sample_count: 19420971
total_episode_count: 56944
total_duration: 5188.045102024266
[2023-06-29 14:50:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2913
train_sample_count: 2913
avg_envstep_per_episode: 291.3
avg_sample_per_episode: 291.3
avg_envstep_per_sec: 2653.5315896984553
avg_train_sample_per_sec: 2653.5315896984553
avg_episode_per_sec: 9.109274252311895
collect_time: 1.0977822956051677
reward_mean: 1697.4872840648236
reward_std: 838.3522383415508
reward_max: 3640.3282516728013
reward_min: 948.1678492578511
total_envstep_count: 25912776
total_train_sample_count: 19424284
total_episode_count: 56954
total_duration: 5189.142884319872
[2023-06-29 14:50:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 274.44444444444446
avg_sample_per_episode: 274.44444444444446
avg_envstep_per_sec: 2767.25612687962
avg_train_sample_per_sec: 2767.25612687962
avg_episode_per_sec: 10.083119490654486
collect_time: 0.8925809129150585
reward_mean: 1862.4603383740246
reward_std: 459.7860235674761
reward_max: 2532.751047031604
reward_min: 1102.2685066010613
total_envstep_count: 25917064
total_train_sample_count: 19427554
total_episode_count: 56963
total_duration: 5190.035465232787
[2023-06-29 14:50:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2354
train_sample_count: 2354
avg_envstep_per_episode: 261.55555555555554
avg_sample_per_episode: 261.55555555555554
avg_envstep_per_sec: 2582.562129144338
avg_train_sample_per_sec: 2582.562129144338
avg_episode_per_sec: 9.873856908368328
collect_time: 0.9114979165205733
reward_mean: 1696.6601089928752
reward_std: 494.23000685381953
reward_max: 2589.116336776272
reward_min: 1042.073288821227
total_envstep_count: 25921680
total_train_sample_count: 19431108
total_episode_count: 56972
total_duration: 5190.9469631493075
[2023-06-29 14:50:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2588
train_sample_count: 2588
avg_envstep_per_episode: 258.8
avg_sample_per_episode: 258.8
avg_envstep_per_sec: 2496.7191247610735
avg_train_sample_per_sec: 2496.7191247610735
avg_episode_per_sec: 9.647291826742943
collect_time: 1.0365603300482034
reward_mean: 1653.1142604160977
reward_std: 738.2678647900902
reward_max: 3573.150550290233
reward_min: 986.2717194843736
total_envstep_count: 25926144
total_train_sample_count: 19434496
total_episode_count: 56982
total_duration: 5191.983523479355
[2023-06-29 14:50:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2870
train_sample_count: 2870
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 2502.9432753887677
avg_train_sample_per_sec: 2502.9432753887677
avg_episode_per_sec: 8.721056708671664
collect_time: 1.1466500372663138
reward_mean: 1804.5710601068463
reward_std: 937.4332937641143
reward_max: 3611.5056328096207
reward_min: 1020.928879868062
total_envstep_count: 25930960
total_train_sample_count: 19437766
total_episode_count: 56992
total_duration: 5193.130173516622
[2023-06-29 14:50:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2826
train_sample_count: 2826
avg_envstep_per_episode: 256.90909090909093
avg_sample_per_episode: 256.90909090909093
avg_envstep_per_sec: 2609.793939546403
avg_train_sample_per_sec: 2609.793939546403
avg_episode_per_sec: 10.158433593421952
collect_time: 1.082844111627899
reward_mean: 1448.2553696414375
reward_std: 542.1625043665094
reward_max: 2497.2840222336417
reward_min: 406.9990356549858
total_envstep_count: 25935464
total_train_sample_count: 19440992
total_episode_count: 57003
total_duration: 5194.21301762825
[2023-06-29 14:50:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2407
train_sample_count: 2407
avg_envstep_per_episode: 218.8181818181818
avg_sample_per_episode: 218.8181818181818
avg_envstep_per_sec: 2765.2539509073354
avg_train_sample_per_sec: 2765.2539509073354
avg_episode_per_sec: 12.6372220440302
collect_time: 0.8704444664875046
reward_mean: 1474.1046411308632
reward_std: 743.2376179268605
reward_max: 3660.2716043879627
reward_min: 964.4127701620507
total_envstep_count: 25940192
total_train_sample_count: 19444199
total_episode_count: 57014
total_duration: 5195.083462094737
[2023-06-29 14:50:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2066
train_sample_count: 2066
avg_envstep_per_episode: 206.6
avg_sample_per_episode: 206.6
avg_envstep_per_sec: 2513.1140824662957
avg_train_sample_per_sec: 2513.1140824662957
avg_episode_per_sec: 12.164153351724568
collect_time: 0.8220876300102098
reward_mean: 1416.467753667949
reward_std: 285.0257571560145
reward_max: 1983.2130240709666
reward_min: 1075.8890573732572
total_envstep_count: 25943768
total_train_sample_count: 19447465
total_episode_count: 57024
total_duration: 5195.905549724747
[2023-06-29 14:50:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2451
train_sample_count: 2451
avg_envstep_per_episode: 272.3333333333333
avg_sample_per_episode: 272.3333333333333
avg_envstep_per_sec: 2544.7345306275815
avg_train_sample_per_sec: 2544.7345306275815
avg_episode_per_sec: 9.344190442940935
collect_time: 0.9631653009383008
reward_mean: 1813.2447350053937
reward_std: 801.3955359256819
reward_max: 3546.654911463328
reward_min: 1058.0215295693733
total_envstep_count: 25948264
total_train_sample_count: 19450716
total_episode_count: 57033
total_duration: 5196.868715025686
[2023-06-29 14:50:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3325
train_sample_count: 3325
avg_envstep_per_episode: 277.0833333333333
avg_sample_per_episode: 277.0833333333333
avg_envstep_per_sec: 2808.540307390805
avg_train_sample_per_sec: 2808.540307390805
avg_episode_per_sec: 10.136085319906664
collect_time: 1.1838890085536986
reward_mean: 1629.029195001903
reward_std: 837.4765335585241
reward_max: 3437.922889023025
reward_min: 184.82852652728505
total_envstep_count: 25952432
total_train_sample_count: 19454041
total_episode_count: 57045
total_duration: 5198.052604034239
[2023-06-29 14:50:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3247
train_sample_count: 3247
avg_envstep_per_episode: 295.1818181818182
avg_sample_per_episode: 295.1818181818182
avg_envstep_per_sec: 2716.3616980626734
avg_train_sample_per_sec: 2716.3616980626734
avg_episode_per_sec: 9.202334055648109
collect_time: 1.1953489118609577
reward_mean: 1348.8196168509085
reward_std: 444.0403078431796
reward_max: 2289.721473508922
reward_min: 901.7118324703301
total_envstep_count: 25957224
total_train_sample_count: 19457288
total_episode_count: 57056
total_duration: 5199.247952946101
[2023-06-29 14:50:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2233
train_sample_count: 2233
avg_envstep_per_episode: 248.11111111111111
avg_sample_per_episode: 248.11111111111111
avg_envstep_per_sec: 2389.2754008962957
avg_train_sample_per_sec: 2389.2754008962957
avg_episode_per_sec: 9.629860549962679
collect_time: 0.9345929728997873
reward_mean: 1525.8005231587422
reward_std: 367.0951201756033
reward_max: 2212.24482746205
reward_min: 946.1654674172014
total_envstep_count: 25961552
total_train_sample_count: 19460721
total_episode_count: 57065
total_duration: 5200.182545919
[2023-06-29 14:50:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2024
train_sample_count: 2024
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2604.8633010048434
avg_train_sample_per_sec: 2604.8633010048434
avg_episode_per_sec: 10.295902375513215
collect_time: 0.7770081444270909
reward_mean: 1562.4843963019398
reward_std: 580.3624886369264
reward_max: 2884.4513392411745
reward_min: 1061.931468030788
total_envstep_count: 25965648
total_train_sample_count: 19463945
total_episode_count: 57073
total_duration: 5200.959554063427
[2023-06-29 14:50:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 228.4
avg_sample_per_episode: 228.4
avg_envstep_per_sec: 2685.213563087175
avg_train_sample_per_sec: 2685.213563087175
avg_episode_per_sec: 11.75662680861285
collect_time: 0.4252920571006833
reward_mean: 2583.1630408770675
reward_std: 1159.4155667403286
reward_max: 3591.478912610656
reward_min: 1009.0835021243038
total_envstep_count: 25970248
total_train_sample_count: 19467487
total_episode_count: 57078
total_duration: 5201.384846120528
[2023-06-29 14:50:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 271.44444444444446
avg_sample_per_episode: 271.44444444444446
avg_envstep_per_sec: 2619.959366890084
avg_train_sample_per_sec: 2619.959366890084
avg_episode_per_sec: 9.651917438399817
collect_time: 0.932457209403161
reward_mean: 2260.892899573956
reward_std: 926.1012896047005
reward_max: 3507.98863656123
reward_min: 1301.050094168169
total_envstep_count: 25974496
total_train_sample_count: 19470730
total_episode_count: 57087
total_duration: 5202.317303329931
[2023-06-29 14:50:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2668
train_sample_count: 2668
avg_envstep_per_episode: 296.44444444444446
avg_sample_per_episode: 296.44444444444446
avg_envstep_per_sec: 2448.981642371576
avg_train_sample_per_sec: 2448.981642371576
avg_episode_per_sec: 8.261182451778181
collect_time: 1.0894324211496857
reward_mean: 1966.3627288218465
reward_std: 919.9888038423712
reward_max: 3507.637662596172
reward_min: 583.2000759815223
total_envstep_count: 25979416
total_train_sample_count: 19474198
total_episode_count: 57096
total_duration: 5203.40673575108
[2023-06-29 14:50:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2269
train_sample_count: 2269
avg_envstep_per_episode: 283.625
avg_sample_per_episode: 283.625
avg_envstep_per_sec: 2714.1223008094757
avg_train_sample_per_sec: 2714.1223008094757
avg_episode_per_sec: 9.569404321937332
collect_time: 0.8359976996332406
reward_mean: 1757.0666025472738
reward_std: 589.9623081575302
reward_max: 2839.7340575139815
reward_min: 1202.2963463955716
total_envstep_count: 25983536
total_train_sample_count: 19477667
total_episode_count: 57104
total_duration: 5204.242733450714
[2023-06-29 14:50:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3185
train_sample_count: 3185
avg_envstep_per_episode: 318.5
avg_sample_per_episode: 318.5
avg_envstep_per_sec: 2589.519176632571
avg_train_sample_per_sec: 2589.519176632571
avg_episode_per_sec: 8.13035848236286
collect_time: 1.229958066632971
reward_mean: 2082.914152261959
reward_std: 979.7090983529813
reward_max: 3565.31324866788
reward_min: 1178.4737696291882
total_envstep_count: 25988512
total_train_sample_count: 19481252
total_episode_count: 57114
total_duration: 5205.472691517347
[2023-06-29 14:50:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2467
train_sample_count: 2467
avg_envstep_per_episode: 352.42857142857144
avg_sample_per_episode: 352.42857142857144
avg_envstep_per_sec: 2709.370994968979
avg_train_sample_per_sec: 2709.370994968979
avg_episode_per_sec: 7.687716645635531
collect_time: 0.9105434451689942
reward_mean: 2000.2753853383417
reward_std: 787.7992166187856
reward_max: 3221.603428603299
reward_min: 1116.7570409781008
total_envstep_count: 25992920
total_train_sample_count: 19484519
total_episode_count: 57121
total_duration: 5206.383234962516
[2023-06-29 14:51:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2885
train_sample_count: 2885
avg_envstep_per_episode: 262.27272727272725
avg_sample_per_episode: 262.27272727272725
avg_envstep_per_sec: 2534.640288632363
avg_train_sample_per_sec: 2534.640288632363
avg_episode_per_sec: 9.664139748684919
collect_time: 1.1382285734741018
reward_mean: 1761.4478734028244
reward_std: 835.1291687223004
reward_max: 3623.7136671614976
reward_min: 978.4305449277803
total_envstep_count: 25997664
total_train_sample_count: 19487804
total_episode_count: 57132
total_duration: 5207.521463535991
[2023-06-29 14:51:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2978
train_sample_count: 2978
avg_envstep_per_episode: 248.16666666666666
avg_sample_per_episode: 248.16666666666666
avg_envstep_per_sec: 2568.270468853917
avg_train_sample_per_sec: 2568.270468853917
avg_episode_per_sec: 10.348974354011753
collect_time: 1.159535195422359
reward_mean: 1380.2920636299689
reward_std: 448.3008116424381
reward_max: 2445.551914156429
reward_min: 649.1125900313557
total_envstep_count: 26002752
total_train_sample_count: 19491182
total_episode_count: 57144
total_duration: 5208.680998731413
[2023-06-29 14:51:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2794
train_sample_count: 2794
avg_envstep_per_episode: 279.4
avg_sample_per_episode: 279.4
avg_envstep_per_sec: 2536.256109859254
avg_train_sample_per_sec: 2536.256109859254
avg_episode_per_sec: 9.077509340942212
collect_time: 1.1016237631281838
reward_mean: 1886.1513529700137
reward_std: 791.8775269788551
reward_max: 3515.461861285751
reward_min: 998.9907950447308
total_envstep_count: 26007616
total_train_sample_count: 19494776
total_episode_count: 57154
total_duration: 5209.782622494541
[2023-06-29 14:51:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2829
train_sample_count: 2829
avg_envstep_per_episode: 282.9
avg_sample_per_episode: 282.9
avg_envstep_per_sec: 2502.0834237271156
avg_train_sample_per_sec: 2502.0834237271156
avg_episode_per_sec: 8.844409415790441
collect_time: 1.1306577443312853
reward_mean: 1659.3220002307746
reward_std: 600.4449995737522
reward_max: 2919.124119502773
reward_min: 946.1196652973669
total_envstep_count: 26011952
total_train_sample_count: 19498005
total_episode_count: 57164
total_duration: 5210.913280238872
[2023-06-29 14:51:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2401
train_sample_count: 2401
avg_envstep_per_episode: 266.77777777777777
avg_sample_per_episode: 266.77777777777777
avg_envstep_per_sec: 2667.3511768987637
avg_train_sample_per_sec: 2667.3511768987637
avg_episode_per_sec: 9.998400912989952
collect_time: 0.9001439408482984
reward_mean: 1617.3152765780303
reward_std: 814.473700357102
reward_max: 3537.738505572365
reward_min: 1010.5332020684067
total_envstep_count: 26016952
total_train_sample_count: 19501206
total_episode_count: 57173
total_duration: 5211.813424179721
[2023-06-29 14:51:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1375
train_sample_count: 1375
avg_envstep_per_episode: 171.875
avg_sample_per_episode: 171.875
avg_envstep_per_sec: 2465.97662041724
avg_train_sample_per_sec: 2465.97662041724
avg_episode_per_sec: 14.347500336973033
collect_time: 0.5575884169442579
reward_mean: 1660.1966135683224
reward_std: 881.341407865495
reward_max: 3562.947522432566
reward_min: 998.4951531171788
total_envstep_count: 26020896
total_train_sample_count: 19504581
total_episode_count: 57181
total_duration: 5212.3710125966645
[2023-06-29 14:51:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3113
train_sample_count: 3113
avg_envstep_per_episode: 239.46153846153845
avg_sample_per_episode: 239.46153846153845
avg_envstep_per_sec: 2493.674242252553
avg_train_sample_per_sec: 2493.674242252553
avg_episode_per_sec: 10.41367335344786
collect_time: 1.2483587259529159
reward_mean: 1762.1112597122528
reward_std: 814.2157054194254
reward_max: 3576.6792761658658
reward_min: 983.7502597644633
total_envstep_count: 26025232
total_train_sample_count: 19508094
total_episode_count: 57194
total_duration: 5213.619371322618
[2023-06-29 14:51:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2361
train_sample_count: 2361
avg_envstep_per_episode: 262.3333333333333
avg_sample_per_episode: 262.3333333333333
avg_envstep_per_sec: 2531.819915424356
avg_train_sample_per_sec: 2531.819915424356
avg_episode_per_sec: 9.651155967310125
collect_time: 0.9325307797826825
reward_mean: 1426.7867343063072
reward_std: 525.4696220321674
reward_max: 2671.668919286663
reward_min: 928.5027983692468
total_envstep_count: 26029656
total_train_sample_count: 19511655
total_episode_count: 57203
total_duration: 5214.5519021024
[2023-06-29 14:51:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2924
train_sample_count: 2924
avg_envstep_per_episode: 265.8181818181818
avg_sample_per_episode: 265.8181818181818
avg_envstep_per_sec: 2447.9830371427065
avg_train_sample_per_sec: 2447.9830371427065
avg_episode_per_sec: 9.209238511822768
collect_time: 1.1944527211319658
reward_mean: 1687.3979744128849
reward_std: 821.563109857916
reward_max: 3552.725533214447
reward_min: 311.9556871832873
total_envstep_count: 26034248
total_train_sample_count: 19514979
total_episode_count: 57214
total_duration: 5215.746354823532
[2023-06-29 14:51:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2617
train_sample_count: 2617
avg_envstep_per_episode: 261.7
avg_sample_per_episode: 261.7
avg_envstep_per_sec: 2732.5409320926224
avg_train_sample_per_sec: 2732.5409320926224
avg_episode_per_sec: 10.44150146004059
collect_time: 0.9577166692232715
reward_mean: 1566.498537478187
reward_std: 514.7119309549947
reward_max: 2543.898447583776
reward_min: 1071.8365870533426
total_envstep_count: 26038912
total_train_sample_count: 19518396
total_episode_count: 57224
total_duration: 5216.704071492755
[2023-06-29 14:51:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2060
train_sample_count: 2060
avg_envstep_per_episode: 257.5
avg_sample_per_episode: 257.5
avg_envstep_per_sec: 2639.2118535083982
avg_train_sample_per_sec: 2639.2118535083982
avg_episode_per_sec: 10.249366421391839
collect_time: 0.7805360517995433
reward_mean: 1809.3889602806632
reward_std: 1047.1409933795762
reward_max: 3506.733684302627
reward_min: 526.4515470537938
total_envstep_count: 26043432
total_train_sample_count: 19521656
total_episode_count: 57232
total_duration: 5217.484607544555
[2023-06-29 14:51:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3453
train_sample_count: 3453
avg_envstep_per_episode: 265.61538461538464
avg_sample_per_episode: 265.61538461538464
avg_envstep_per_sec: 2578.604389624292
avg_train_sample_per_sec: 2578.604389624292
avg_episode_per_sec: 9.708038536089138
collect_time: 1.3390964561660075
reward_mean: 1723.2559517777643
reward_std: 854.3053382629172
reward_max: 3185.768834324721
reward_min: 917.3546027458274
total_envstep_count: 26047816
total_train_sample_count: 19525109
total_episode_count: 57245
total_duration: 5218.823704000721
[2023-06-29 14:51:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2919
train_sample_count: 2919
avg_envstep_per_episode: 243.25
avg_sample_per_episode: 243.25
avg_envstep_per_sec: 2540.8000796421156
avg_train_sample_per_sec: 2540.8000796421156
avg_episode_per_sec: 10.445221293492766
collect_time: 1.1488507196564461
reward_mean: 1169.6972774641629
reward_std: 350.5688661629197
reward_max: 2136.861943909437
reward_min: 855.0451156213943
total_envstep_count: 26052392
total_train_sample_count: 19528428
total_episode_count: 57257
total_duration: 5219.972554720377
[2023-06-29 14:51:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2680
train_sample_count: 2680
avg_envstep_per_episode: 223.33333333333334
avg_sample_per_episode: 223.33333333333334
avg_envstep_per_sec: 2679.718642648648
avg_train_sample_per_sec: 2679.718642648648
avg_episode_per_sec: 11.998740190964096
collect_time: 1.000104995109141
reward_mean: 1319.590698555255
reward_std: 378.459420709981
reward_max: 2130.117915944162
reward_min: 880.8013017046698
total_envstep_count: 26056680
total_train_sample_count: 19531908
total_episode_count: 57269
total_duration: 5220.972659715486
[2023-06-29 14:51:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2378
train_sample_count: 2378
avg_envstep_per_episode: 198.16666666666666
avg_sample_per_episode: 198.16666666666666
avg_envstep_per_sec: 2545.1985102646827
avg_train_sample_per_sec: 2545.1985102646827
avg_episode_per_sec: 12.843726712857945
collect_time: 0.9343082633474843
reward_mean: 1208.2587202864995
reward_std: 565.4412711471548
reward_max: 2576.734426679281
reward_min: 471.86257848336476
total_envstep_count: 26061136
total_train_sample_count: 19535486
total_episode_count: 57281
total_duration: 5221.906967978834
[2023-06-29 14:51:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 18
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 179.44444444444446
avg_sample_per_episode: 179.44444444444446
avg_envstep_per_sec: 2575.690822610035
avg_train_sample_per_sec: 2575.690822610035
avg_episode_per_sec: 14.35369498668131
collect_time: 1.2540324994157999
reward_mean: 1044.9958929263637
reward_std: 680.1777137282876
reward_max: 2853.0300329611164
reward_min: 308.4840448443836
total_envstep_count: 26065392
total_train_sample_count: 19538716
total_episode_count: 57299
total_duration: 5223.16100047825
[2023-06-29 14:51:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2664
train_sample_count: 2664
avg_envstep_per_episode: 204.92307692307693
avg_sample_per_episode: 204.92307692307693
avg_envstep_per_sec: 2784.383738954597
avg_train_sample_per_sec: 2784.383738954597
avg_episode_per_sec: 13.58745818558925
collect_time: 0.9567646738952026
reward_mean: 1007.135513384557
reward_std: 349.1870917870539
reward_max: 1625.1703358331888
reward_min: 515.9791390967431
total_envstep_count: 26070048
total_train_sample_count: 19542180
total_episode_count: 57312
total_duration: 5224.117765152145
[2023-06-29 14:51:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3453
train_sample_count: 3453
avg_envstep_per_episode: 215.8125
avg_sample_per_episode: 215.8125
avg_envstep_per_sec: 2652.105005903298
avg_train_sample_per_sec: 2652.105005903298
avg_episode_per_sec: 12.288931391385105
collect_time: 1.301984647030942
reward_mean: 1246.477266785746
reward_std: 567.521695922091
reward_max: 2453.337038425281
reward_min: 514.8259730639987
total_envstep_count: 26074640
total_train_sample_count: 19545633
total_episode_count: 57328
total_duration: 5225.419749799175
[2023-06-29 14:51:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 300.25
avg_sample_per_episode: 300.25
avg_envstep_per_sec: 2319.816803697733
avg_train_sample_per_sec: 2319.816803697733
avg_episode_per_sec: 7.726284108901693
collect_time: 0.5177132944660261
reward_mean: 1255.314297780412
reward_std: 275.81158419116355
reward_max: 1680.3871976068174
reward_min: 971.1553917354764
total_envstep_count: 26078256
total_train_sample_count: 19548834
total_episode_count: 57332
total_duration: 5225.937463093642
[2023-06-29 14:52:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3039
train_sample_count: 3039
avg_envstep_per_episode: 303.9
avg_sample_per_episode: 303.9
avg_envstep_per_sec: 2554.8806991912347
avg_train_sample_per_sec: 2554.8806991912347
avg_episode_per_sec: 8.406978279668426
collect_time: 1.1894880261775107
reward_mean: 2282.709278732377
reward_std: 1104.1537836539717
reward_max: 3527.4331806967584
reward_min: 662.7672226847105
total_envstep_count: 26082792
total_train_sample_count: 19552273
total_episode_count: 57342
total_duration: 5227.126951119819
[2023-06-29 14:52:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 2677.9971131940224
avg_train_sample_per_sec: 2677.9971131940224
avg_episode_per_sec: 11.849544748646117
collect_time: 0.7595228501101956
reward_mean: 1408.4840383861724
reward_std: 880.2860753999862
reward_max: 3667.9354511443307
reward_min: 325.5482242741522
total_envstep_count: 26086432
total_train_sample_count: 19555507
total_episode_count: 57351
total_duration: 5227.886473969929
[2023-06-29 14:52:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2733
train_sample_count: 2733
avg_envstep_per_episode: 227.75
avg_sample_per_episode: 227.75
avg_envstep_per_sec: 2548.9389680337104
avg_train_sample_per_sec: 2548.9389680337104
avg_episode_per_sec: 11.191828619247904
collect_time: 1.0722108431290833
reward_mean: 1309.2130490854254
reward_std: 880.5456110479637
reward_max: 3515.1960620795016
reward_min: 222.5701852717667
total_envstep_count: 26090920
total_train_sample_count: 19559040
total_episode_count: 57363
total_duration: 5228.958684813058
[2023-06-29 14:52:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2337
train_sample_count: 2337
avg_envstep_per_episode: 292.125
avg_sample_per_episode: 292.125
avg_envstep_per_sec: 2536.3029074215024
avg_train_sample_per_sec: 2536.3029074215024
avg_episode_per_sec: 8.682252143505357
collect_time: 0.9214199113054202
reward_mean: 1449.8257116015438
reward_std: 826.58647079883
reward_max: 3510.546717744776
reward_min: 585.7282753698184
total_envstep_count: 26095552
total_train_sample_count: 19562577
total_episode_count: 57371
total_duration: 5229.880104724364
[2023-06-29 14:52:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2093
train_sample_count: 2093
avg_envstep_per_episode: 261.625
avg_sample_per_episode: 261.625
avg_envstep_per_sec: 2381.4814276939765
avg_train_sample_per_sec: 2381.4814276939765
avg_episode_per_sec: 9.10265237532337
collect_time: 0.878864716583863
reward_mean: 2250.684884003898
reward_std: 1057.5567263447278
reward_max: 3623.814183855541
reward_min: 1052.037459890265
total_envstep_count: 26100400
total_train_sample_count: 19565870
total_episode_count: 57379
total_duration: 5230.758969440948
[2023-06-29 14:52:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2098
train_sample_count: 2098
avg_envstep_per_episode: 209.8
avg_sample_per_episode: 209.8
avg_envstep_per_sec: 2514.275406946345
avg_train_sample_per_sec: 2514.275406946345
avg_episode_per_sec: 11.984153512613656
collect_time: 0.834435238957405
reward_mean: 1638.8508682420593
reward_std: 1069.7053986904934
reward_max: 3503.633819925948
reward_min: 536.2263834617655
total_envstep_count: 26104800
total_train_sample_count: 19569168
total_episode_count: 57389
total_duration: 5231.593404679906
[2023-06-29 14:52:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2555
train_sample_count: 2555
avg_envstep_per_episode: 196.53846153846155
avg_sample_per_episode: 196.53846153846155
avg_envstep_per_sec: 2500.2215723918493
avg_train_sample_per_sec: 2500.2215723918493
avg_episode_per_sec: 12.721283929978098
collect_time: 1.0219094292334046
reward_mean: 1511.689092556255
reward_std: 864.6558525894071
reward_max: 3545.2820837746713
reward_min: 597.5622420423763
total_envstep_count: 26109328
total_train_sample_count: 19572523
total_episode_count: 57402
total_duration: 5232.615314109139
[2023-06-29 14:52:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1828
train_sample_count: 1828
avg_envstep_per_episode: 261.14285714285717
avg_sample_per_episode: 261.14285714285717
avg_envstep_per_sec: 2474.3274059659684
avg_train_sample_per_sec: 2474.3274059659684
avg_episode_per_sec: 9.474995537068807
collect_time: 0.7387866276679562
reward_mean: 1922.513107108481
reward_std: 939.4758394809545
reward_max: 3496.0354621526963
reward_min: 856.1137694601244
total_envstep_count: 26113752
total_train_sample_count: 19575951
total_episode_count: 57409
total_duration: 5233.354100736807
[2023-06-29 14:52:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2594
train_sample_count: 2594
avg_envstep_per_episode: 288.22222222222223
avg_sample_per_episode: 288.22222222222223
avg_envstep_per_sec: 2564.158712929155
avg_train_sample_per_sec: 2564.158712929155
avg_episode_per_sec: 8.896464308543715
collect_time: 1.0116378471115604
reward_mean: 1814.8497554326282
reward_std: 824.451000822332
reward_max: 3527.083121283912
reward_min: 1195.7073634486833
total_envstep_count: 26118424
total_train_sample_count: 19579345
total_episode_count: 57418
total_duration: 5234.365738583918
[2023-06-29 14:52:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 158.625
avg_sample_per_episode: 158.625
avg_envstep_per_sec: 2256.5209766948137
avg_train_sample_per_sec: 2256.5209766948137
avg_episode_per_sec: 14.225506551267541
collect_time: 0.5623701322106645
reward_mean: 1858.0987295054726
reward_std: 980.7012099903566
reward_max: 3543.868386870549
reward_min: 1031.703619421863
total_envstep_count: 26122992
total_train_sample_count: 19582614
total_episode_count: 57426
total_duration: 5234.928108716129
[2023-06-29 14:52:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3364
train_sample_count: 3364
avg_envstep_per_episode: 258.7692307692308
avg_sample_per_episode: 258.7692307692308
avg_envstep_per_sec: 2633.47630817925
avg_train_sample_per_sec: 2633.47630817925
avg_episode_per_sec: 10.176929847303878
collect_time: 1.2773989990158008
reward_mean: 1849.7658951727703
reward_std: 972.9526519034608
reward_max: 3510.0675958205743
reward_min: 749.7859323898703
total_envstep_count: 26127848
total_train_sample_count: 19585978
total_episode_count: 57439
total_duration: 5236.205507715144
[2023-06-29 14:52:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 305.0
avg_sample_per_episode: 305.0
avg_envstep_per_sec: 2702.5736534373145
avg_train_sample_per_sec: 2702.5736534373145
avg_episode_per_sec: 8.860897224384638
collect_time: 0.9028431091587992
reward_mean: 1609.659995860203
reward_std: 657.2767804776124
reward_max: 2824.915769871977
reward_min: 965.5803369786847
total_envstep_count: 26132232
total_train_sample_count: 19589218
total_episode_count: 57447
total_duration: 5237.108350824304
[2023-06-29 14:52:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2758
train_sample_count: 2758
avg_envstep_per_episode: 250.72727272727272
avg_sample_per_episode: 250.72727272727272
avg_envstep_per_sec: 2734.132304182427
avg_train_sample_per_sec: 2734.132304182427
avg_episode_per_sec: 10.904806144309898
collect_time: 1.008729532137513
reward_mean: 1685.0148554263353
reward_std: 786.1099088762345
reward_max: 3557.401986679019
reward_min: 1002.539364766455
total_envstep_count: 26136864
total_train_sample_count: 19592776
total_episode_count: 57458
total_duration: 5238.117080356441
[2023-06-29 14:52:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2889
train_sample_count: 2889
avg_envstep_per_episode: 361.125
avg_sample_per_episode: 361.125
avg_envstep_per_sec: 2504.377753291535
avg_train_sample_per_sec: 2504.377753291535
avg_episode_per_sec: 6.93493320399179
collect_time: 1.1535799646051603
reward_mean: 2107.8301275224258
reward_std: 809.0117389602724
reward_max: 3235.8281752891903
reward_min: 1177.9500582482083
total_envstep_count: 26142160
total_train_sample_count: 19596065
total_episode_count: 57466
total_duration: 5239.270660321046
[2023-06-29 14:52:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2650
train_sample_count: 2650
avg_envstep_per_episode: 220.83333333333334
avg_sample_per_episode: 220.83333333333334
avg_envstep_per_sec: 2588.318333758337
avg_train_sample_per_sec: 2588.318333758337
avg_episode_per_sec: 11.720686794377375
collect_time: 1.0238307882910596
reward_mean: 1573.597176292347
reward_std: 640.6949494577365
reward_max: 3558.267703503329
reward_min: 958.6303150838745
total_envstep_count: 26146784
total_train_sample_count: 19599515
total_episode_count: 57478
total_duration: 5240.294491109337
[2023-06-29 14:52:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2598
train_sample_count: 2598
avg_envstep_per_episode: 288.6666666666667
avg_sample_per_episode: 288.6666666666667
avg_envstep_per_sec: 2768.6145351160794
avg_train_sample_per_sec: 2768.6145351160794
avg_episode_per_sec: 9.591043424189651
collect_time: 0.9383754824111237
reward_mean: 1847.5118506837034
reward_std: 787.7755885503442
reward_max: 3590.9421519140196
reward_min: 1187.6471810759103
total_envstep_count: 26151776
total_train_sample_count: 19602913
total_episode_count: 57487
total_duration: 5241.2328665917485
[2023-06-29 14:52:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2680
train_sample_count: 2680
avg_envstep_per_episode: 243.63636363636363
avg_sample_per_episode: 243.63636363636363
avg_envstep_per_sec: 2760.045213587084
avg_train_sample_per_sec: 2760.045213587084
avg_episode_per_sec: 11.328543787111167
collect_time: 0.9709985861126333
reward_mean: 1684.6473192575183
reward_std: 518.0677434188301
reward_max: 2679.3453000782915
reward_min: 1035.9790873242057
total_envstep_count: 26156560
total_train_sample_count: 19606393
total_episode_count: 57498
total_duration: 5242.203865177861
[2023-06-29 14:52:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3117
train_sample_count: 3117
avg_envstep_per_episode: 283.3636363636364
avg_sample_per_episode: 283.3636363636364
avg_envstep_per_sec: 2686.2458749405087
avg_train_sample_per_sec: 2686.2458749405087
avg_episode_per_sec: 9.479853905789412
collect_time: 1.1603554347269238
reward_mean: 1721.5269141663075
reward_std: 937.0879909910817
reward_max: 3534.5416963234907
reward_min: 613.1507415977392
total_envstep_count: 26161288
total_train_sample_count: 19609910
total_episode_count: 57509
total_duration: 5243.364220612588
[2023-06-29 14:52:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1763
train_sample_count: 1763
avg_envstep_per_episode: 352.6
avg_sample_per_episode: 352.6
avg_envstep_per_sec: 2647.100229276604
avg_train_sample_per_sec: 2647.100229276604
avg_episode_per_sec: 7.507374444913794
collect_time: 0.666011804351583
reward_mean: 1940.5096427946514
reward_std: 918.1339484214394
reward_max: 3514.6677087135877
reward_min: 989.1183553383196
total_envstep_count: 26166024
total_train_sample_count: 19613273
total_episode_count: 57514
total_duration: 5244.03023241694
[2023-06-29 14:53:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2926
train_sample_count: 2926
avg_envstep_per_episode: 243.83333333333334
avg_sample_per_episode: 243.83333333333334
avg_envstep_per_sec: 2562.043128353994
avg_train_sample_per_sec: 2562.043128353994
avg_episode_per_sec: 10.507353909859168
collect_time: 1.1420572774978357
reward_mean: 1966.6453115234374
reward_std: 1023.125465847694
reward_max: 3543.338576269864
reward_min: 1043.1538195217483
total_envstep_count: 26170640
total_train_sample_count: 19616599
total_episode_count: 57526
total_duration: 5245.1722896944375
[2023-06-29 14:53:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 248.3
avg_sample_per_episode: 248.3
avg_envstep_per_sec: 2485.6182939417913
avg_train_sample_per_sec: 2485.6182939417913
avg_episode_per_sec: 10.010544880957678
collect_time: 0.9989466226780785
reward_mean: 1496.206422814964
reward_std: 623.4958842424433
reward_max: 3228.616331759172
reward_min: 967.7064386268261
total_envstep_count: 26174888
total_train_sample_count: 19619882
total_episode_count: 57536
total_duration: 5246.1712363171155
[2023-06-29 14:53:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3398
train_sample_count: 3398
avg_envstep_per_episode: 242.71428571428572
avg_sample_per_episode: 242.71428571428572
avg_envstep_per_sec: 2546.108444836694
avg_train_sample_per_sec: 2546.108444836694
avg_episode_per_sec: 10.49014662381216
collect_time: 1.3345857309773566
reward_mean: 1364.7623097893968
reward_std: 385.32505776249405
reward_max: 2299.990212745522
reward_min: 793.6926640188427
total_envstep_count: 26179448
total_train_sample_count: 19623280
total_episode_count: 57550
total_duration: 5247.505822048093
[2023-06-29 14:53:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2093
train_sample_count: 2093
avg_envstep_per_episode: 232.55555555555554
avg_sample_per_episode: 232.55555555555554
avg_envstep_per_sec: 2668.0148518028577
avg_train_sample_per_sec: 2668.0148518028577
avg_episode_per_sec: 11.472591335989355
collect_time: 0.7844783917097377
reward_mean: 1266.852041657912
reward_std: 317.7052831024854
reward_max: 2049.6662338576584
reward_min: 968.2994150665279
total_envstep_count: 26183992
total_train_sample_count: 19626573
total_episode_count: 57559
total_duration: 5248.290300439803
[2023-06-29 14:53:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2090
train_sample_count: 2090
avg_envstep_per_episode: 232.22222222222223
avg_sample_per_episode: 232.22222222222223
avg_envstep_per_sec: 2631.1556299194813
avg_train_sample_per_sec: 2631.1556299194813
avg_episode_per_sec: 11.330335248457096
collect_time: 0.7943277760669589
reward_mean: 1819.9027694916995
reward_std: 684.8342299043894
reward_max: 2775.0537637509296
reward_min: 1007.4911242134784
total_envstep_count: 26188232
total_train_sample_count: 19629863
total_episode_count: 57568
total_duration: 5249.08462821587
[2023-06-29 14:53:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2819
train_sample_count: 2819
avg_envstep_per_episode: 234.91666666666666
avg_sample_per_episode: 234.91666666666666
avg_envstep_per_sec: 2810.066604804949
avg_train_sample_per_sec: 2810.066604804949
avg_episode_per_sec: 11.961972067278959
collect_time: 1.0031790688447655
reward_mean: 1543.1060607655697
reward_std: 461.99767800485154
reward_max: 2662.314226737514
reward_min: 954.1263426644638
total_envstep_count: 26192496
total_train_sample_count: 19633082
total_episode_count: 57580
total_duration: 5250.0878072847145
[2023-06-29 14:53:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2469
train_sample_count: 2469
avg_envstep_per_episode: 308.625
avg_sample_per_episode: 308.625
avg_envstep_per_sec: 2705.5608177308204
avg_train_sample_per_sec: 2705.5608177308204
avg_episode_per_sec: 8.76649920690424
collect_time: 0.9125649602180348
reward_mean: 1817.7390510394239
reward_std: 479.78802658711464
reward_max: 2792.865392107054
reward_min: 1082.7063816717816
total_envstep_count: 26197472
total_train_sample_count: 19636351
total_episode_count: 57588
total_duration: 5251.000372244933
[2023-06-29 14:53:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2470
train_sample_count: 2470
avg_envstep_per_episode: 224.54545454545453
avg_sample_per_episode: 224.54545454545453
avg_envstep_per_sec: 2727.2778238357428
avg_train_sample_per_sec: 2727.2778238357428
avg_episode_per_sec: 12.145771685098449
collect_time: 0.905664974214509
reward_mean: 1637.2390602308349
reward_std: 418.9669081816201
reward_max: 2430.0274130152493
reward_min: 929.1185992869272
total_envstep_count: 26202072
total_train_sample_count: 19639621
total_episode_count: 57599
total_duration: 5251.906037219147
[2023-06-29 14:53:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1932
train_sample_count: 1932
avg_envstep_per_episode: 193.2
avg_sample_per_episode: 193.2
avg_envstep_per_sec: 2598.7984611609027
avg_train_sample_per_sec: 2598.7984611609027
avg_episode_per_sec: 13.451337790687901
collect_time: 0.7434204802233726
reward_mean: 1458.5008499723717
reward_std: 489.58964891140545
reward_max: 2532.7889583167384
reward_min: 879.2455793774328
total_envstep_count: 26206760
total_train_sample_count: 19643153
total_episode_count: 57609
total_duration: 5252.64945769937
[2023-06-29 14:53:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2694
train_sample_count: 2694
avg_envstep_per_episode: 224.5
avg_sample_per_episode: 224.5
avg_envstep_per_sec: 2606.340643652507
avg_train_sample_per_sec: 2606.340643652507
avg_episode_per_sec: 11.609535161035666
collect_time: 1.0336331156715755
reward_mean: 1682.1421003431471
reward_std: 437.7229739431283
reward_max: 2472.8008903337104
reward_min: 1170.4807012969977
total_envstep_count: 26211424
total_train_sample_count: 19646647
total_episode_count: 57621
total_duration: 5253.683090815041
[2023-06-29 14:53:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1552
train_sample_count: 1552
avg_envstep_per_episode: 172.44444444444446
avg_sample_per_episode: 172.44444444444446
avg_envstep_per_sec: 2712.233928062192
avg_train_sample_per_sec: 2712.233928062192
avg_episode_per_sec: 15.728160665309103
collect_time: 0.5722220284696669
reward_mean: 1345.4904384634708
reward_std: 223.42137393690638
reward_max: 1692.8746073438722
reward_min: 977.485462288279
total_envstep_count: 26215960
total_train_sample_count: 19650199
total_episode_count: 57630
total_duration: 5254.255312843511
[2023-06-29 14:53:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2814
train_sample_count: 2814
avg_envstep_per_episode: 234.5
avg_sample_per_episode: 234.5
avg_envstep_per_sec: 2798.4426211009295
avg_train_sample_per_sec: 2798.4426211009295
avg_episode_per_sec: 11.933657232839783
collect_time: 1.0055592988692226
reward_mean: 1818.187076217534
reward_std: 770.8459149218239
reward_max: 3445.104414275653
reward_min: 1017.7131670854452
total_envstep_count: 26220480
total_train_sample_count: 19653413
total_episode_count: 57642
total_duration: 5255.26087214238
[2023-06-29 14:53:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2165
train_sample_count: 2165
avg_envstep_per_episode: 270.625
avg_sample_per_episode: 270.625
avg_envstep_per_sec: 2808.3133399020626
avg_train_sample_per_sec: 2808.3133399020626
avg_episode_per_sec: 10.377139362224712
collect_time: 0.7709253697721289
reward_mean: 1730.4824865714463
reward_std: 758.7871710895022
reward_max: 3522.2806305118725
reward_min: 1000.8639379436923
total_envstep_count: 26225456
total_train_sample_count: 19656778
total_episode_count: 57650
total_duration: 5256.0317975121525
[2023-06-29 14:53:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2474
train_sample_count: 2474
avg_envstep_per_episode: 224.9090909090909
avg_sample_per_episode: 224.9090909090909
avg_envstep_per_sec: 2671.902823363529
avg_train_sample_per_sec: 2671.902823363529
avg_episode_per_sec: 11.879923628536305
collect_time: 0.9259318783478814
reward_mean: 1772.9513151270442
reward_std: 865.9436144370027
reward_max: 3230.9811568566533
reward_min: 924.4306870472517
total_envstep_count: 26229944
total_train_sample_count: 19660052
total_episode_count: 57661
total_duration: 5256.9577293905
[2023-06-29 14:53:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1753
train_sample_count: 1753
avg_envstep_per_episode: 194.77777777777777
avg_sample_per_episode: 194.77777777777777
avg_envstep_per_sec: 2404.277445543157
avg_train_sample_per_sec: 2404.277445543157
avg_episode_per_sec: 12.34369481453988
collect_time: 0.7291171837300063
reward_mean: 1529.407864874097
reward_std: 324.9228816587111
reward_max: 2014.1671028604023
reward_min: 1004.876131345322
total_envstep_count: 26234240
total_train_sample_count: 19663405
total_episode_count: 57670
total_duration: 5257.68684657423
[2023-06-29 14:53:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2479
train_sample_count: 2479
avg_envstep_per_episode: 247.9
avg_sample_per_episode: 247.9
avg_envstep_per_sec: 2742.734267521717
avg_train_sample_per_sec: 2742.734267521717
avg_episode_per_sec: 11.063873608397406
collect_time: 0.9038425739435478
reward_mean: 1716.7219081263224
reward_std: 982.0763721035875
reward_max: 3492.590919915654
reward_min: 118.10058121701421
total_envstep_count: 26238776
total_train_sample_count: 19666684
total_episode_count: 57680
total_duration: 5258.590689148174
[2023-06-29 14:53:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2366
train_sample_count: 2366
avg_envstep_per_episode: 295.75
avg_sample_per_episode: 295.75
avg_envstep_per_sec: 2513.673886221375
avg_train_sample_per_sec: 2513.673886221375
avg_episode_per_sec: 8.499319987223585
collect_time: 0.9412517721448096
reward_mean: 2014.6047660684033
reward_std: 943.0292166869203
reward_max: 3647.1043847126325
reward_min: 1087.2111567679854
total_envstep_count: 26243888
total_train_sample_count: 19670250
total_episode_count: 57688
total_duration: 5259.531940920318
[2023-06-29 14:53:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3023
train_sample_count: 3023
avg_envstep_per_episode: 232.53846153846155
avg_sample_per_episode: 232.53846153846155
avg_envstep_per_sec: 2603.215482880315
avg_train_sample_per_sec: 2603.215482880315
avg_episode_per_sec: 11.194773826478364
collect_time: 1.1612561541218311
reward_mean: 1640.6534490622662
reward_std: 949.5861841357541
reward_max: 3512.1669969955074
reward_min: 129.8556399071284
total_envstep_count: 26248888
total_train_sample_count: 19673673
total_episode_count: 57701
total_duration: 5260.69319707444
[2023-06-29 14:53:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 282.5
avg_sample_per_episode: 282.5
avg_envstep_per_sec: 2776.865696903532
avg_train_sample_per_sec: 2776.865696903532
avg_episode_per_sec: 9.829613086384184
collect_time: 0.406933616292663
reward_mean: 2027.3852954188212
reward_std: 775.4600359191442
reward_max: 3170.247412775186
reward_min: 1001.0671472262834
total_envstep_count: 26253912
total_train_sample_count: 19677203
total_episode_count: 57705
total_duration: 5261.100130690733
[2023-06-29 14:54:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2852
train_sample_count: 2852
avg_envstep_per_episode: 203.71428571428572
avg_sample_per_episode: 203.71428571428572
avg_envstep_per_sec: 2596.88093065774
avg_train_sample_per_sec: 2596.88093065774
avg_episode_per_sec: 12.74766235245735
collect_time: 1.0982405725000426
reward_mean: 1846.699965269316
reward_std: 1152.426641017564
reward_max: 3663.38050006448
reward_min: 120.31255850103676
total_envstep_count: 26258080
total_train_sample_count: 19680455
total_episode_count: 57719
total_duration: 5262.198371263233
[2023-06-29 14:54:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1699
train_sample_count: 1699
avg_envstep_per_episode: 242.71428571428572
avg_sample_per_episode: 242.71428571428572
avg_envstep_per_sec: 2684.162824822643
avg_train_sample_per_sec: 2684.162824822643
avg_episode_per_sec: 11.058940420105062
collect_time: 0.6329720329511911
reward_mean: 1634.823175195455
reward_std: 737.5861646659409
reward_max: 3382.7903804437124
reward_min: 1096.265638896267
total_envstep_count: 26262984
total_train_sample_count: 19683754
total_episode_count: 57726
total_duration: 5262.831343296184
[2023-06-29 14:54:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2634
train_sample_count: 2634
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 2760.3830943428165
avg_train_sample_per_sec: 2760.3830943428165
avg_episode_per_sec: 12.575777195183674
collect_time: 0.9542153787994758
reward_mean: 1849.8485351743857
reward_std: 745.3746190458606
reward_max: 3516.3255440129224
reward_min: 1027.0773234133037
total_envstep_count: 26267024
total_train_sample_count: 19687188
total_episode_count: 57738
total_duration: 5263.785558674984
[2023-06-29 14:54:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1616
train_sample_count: 1616
avg_envstep_per_episode: 269.3333333333333
avg_sample_per_episode: 269.3333333333333
avg_envstep_per_sec: 2669.4771933370153
avg_train_sample_per_sec: 2669.4771933370153
avg_episode_per_sec: 9.911425222785947
collect_time: 0.605361980253481
reward_mean: 1731.3099924208461
reward_std: 505.10756680065583
reward_max: 2784.200730195702
reward_min: 1236.7008388090362
total_envstep_count: 26271048
total_train_sample_count: 19690404
total_episode_count: 57744
total_duration: 5264.390920655237
[2023-06-29 14:54:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2454
train_sample_count: 2454
avg_envstep_per_episode: 223.0909090909091
avg_sample_per_episode: 223.0909090909091
avg_envstep_per_sec: 2699.985653143101
avg_train_sample_per_sec: 2699.985653143101
avg_episode_per_sec: 12.102625177088065
collect_time: 0.9088937184326351
reward_mean: 1669.6860788318127
reward_std: 883.3768852335194
reward_max: 3105.508076416333
reward_min: 119.02114880007431
total_envstep_count: 26275696
total_train_sample_count: 19693658
total_episode_count: 57755
total_duration: 5265.2998143736695
[2023-06-29 14:54:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1751
train_sample_count: 1751
avg_envstep_per_episode: 175.1
avg_sample_per_episode: 175.1
avg_envstep_per_sec: 2622.494712504491
avg_train_sample_per_sec: 2622.494712504491
avg_episode_per_sec: 14.977125713903432
collect_time: 0.6676848542919613
reward_mean: 1371.9625053354616
reward_std: 775.2904248708121
reward_max: 3140.0418833473896
reward_min: 124.72971302531859
total_envstep_count: 26279960
total_train_sample_count: 19697009
total_episode_count: 57765
total_duration: 5265.9674992279615
[2023-06-29 14:54:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 227.5
avg_sample_per_episode: 227.5
avg_envstep_per_sec: 2451.262634269315
avg_train_sample_per_sec: 2451.262634269315
avg_episode_per_sec: 10.774780809975013
collect_time: 0.37123725025542087
reward_mean: 1741.9871216163579
reward_std: 690.9146231645419
reward_max: 2923.0307724029362
reward_min: 1176.7453121980795
total_envstep_count: 26283824
total_train_sample_count: 19700319
total_episode_count: 57769
total_duration: 5266.338736478217
[2023-06-29 14:54:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 196.33333333333334
avg_sample_per_episode: 196.33333333333334
avg_envstep_per_sec: 2463.347174940002
avg_train_sample_per_sec: 2463.347174940002
avg_episode_per_sec: 12.546759804448225
collect_time: 0.4782111153409352
reward_mean: 3110.8900223109727
reward_std: 899.1816887861628
reward_max: 3618.0362335874465
reward_min: 1104.3479818511155
total_envstep_count: 26287960
total_train_sample_count: 19703897
total_episode_count: 57775
total_duration: 5266.816947593557
[2023-06-29 14:54:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 227.75
avg_sample_per_episode: 227.75
avg_envstep_per_sec: 2733.9394199232065
avg_train_sample_per_sec: 2733.9394199232065
avg_episode_per_sec: 12.004124785612323
collect_time: 0.3332187953256071
reward_mean: 3072.7079640121574
reward_std: 755.5235859557691
reward_max: 3543.182206660095
reward_min: 1764.6400876618277
total_envstep_count: 26291824
total_train_sample_count: 19707208
total_episode_count: 57779
total_duration: 5267.150166388883
[2023-06-29 14:54:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1956
train_sample_count: 1956
avg_envstep_per_episode: 244.5
avg_sample_per_episode: 244.5
avg_envstep_per_sec: 2734.2169594104726
avg_train_sample_per_sec: 2734.2169594104726
avg_episode_per_sec: 11.182891449531585
collect_time: 0.7153784900894388
reward_mean: 2577.918427828452
reward_std: 1014.6433489639554
reward_max: 3539.461005780957
reward_min: 1134.1987724588905
total_envstep_count: 26296560
total_train_sample_count: 19710764
total_episode_count: 57787
total_duration: 5267.865544878972
[2023-06-29 14:54:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2073
train_sample_count: 2073
avg_envstep_per_episode: 345.5
avg_sample_per_episode: 345.5
avg_envstep_per_sec: 2511.3487062459517
avg_train_sample_per_sec: 2511.3487062459517
avg_episode_per_sec: 7.268737210552682
collect_time: 0.82545287113823
reward_mean: 2645.7850797403335
reward_std: 964.6411229346298
reward_max: 3659.430145243255
reward_min: 1384.5392821075436
total_envstep_count: 26301184
total_train_sample_count: 19714037
total_episode_count: 57793
total_duration: 5268.690997750111
[2023-06-29 14:54:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2807.6721480568194
avg_train_sample_per_sec: 2807.6721480568194
avg_episode_per_sec: 12.879230036957887
collect_time: 0.31057757245749235
reward_mean: 2826.3311200858734
reward_std: 936.5855256930532
reward_max: 3591.305648874739
reward_min: 1260.1950359611471
total_envstep_count: 26305424
total_train_sample_count: 19717309
total_episode_count: 57797
total_duration: 5269.001575322568
[2023-06-29 14:54:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 252.4
avg_sample_per_episode: 252.4
avg_envstep_per_sec: 2650.529655703831
avg_train_sample_per_sec: 2650.529655703831
avg_episode_per_sec: 10.501306084405035
collect_time: 0.4761312507046386
reward_mean: 2949.4564447210228
reward_std: 889.2767095058246
reward_max: 3559.0433290604597
reward_min: 1205.0720181249071
total_envstep_count: 26309192
total_train_sample_count: 19720571
total_episode_count: 57802
total_duration: 5269.477706573272
[2023-06-29 14:54:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1203
train_sample_count: 1203
avg_envstep_per_episode: 240.6
avg_sample_per_episode: 240.6
avg_envstep_per_sec: 2743.7250028136655
avg_train_sample_per_sec: 2743.7250028136655
avg_episode_per_sec: 11.403678315933771
collect_time: 0.43845501964166755
reward_mean: 3332.0674099529365
reward_std: 296.5703788770644
reward_max: 3571.9309846638826
reward_min: 2749.025544088727
total_envstep_count: 26313424
total_train_sample_count: 19723774
total_episode_count: 57807
total_duration: 5269.916161592914
[2023-06-29 14:54:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 306.5
avg_sample_per_episode: 306.5
avg_envstep_per_sec: 2597.04627474163
avg_train_sample_per_sec: 2597.04627474163
avg_episode_per_sec: 8.473234175339739
collect_time: 0.47207476121000963
reward_mean: 2980.257062781412
reward_std: 883.169662822729
reward_max: 3509.1756933963857
reward_min: 1450.7213985283893
total_envstep_count: 26317192
total_train_sample_count: 19727000
total_episode_count: 57811
total_duration: 5270.388236354124
[2023-06-29 14:54:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1613
train_sample_count: 1613
avg_envstep_per_episode: 322.6
avg_sample_per_episode: 322.6
avg_envstep_per_sec: 2787.8605312977206
avg_train_sample_per_sec: 2787.8605312977206
avg_episode_per_sec: 8.641849136074768
collect_time: 0.5785798758193851
reward_mean: 3495.7759631988533
reward_std: 28.064601445642744
reward_max: 3532.3669247558937
reward_min: 3447.9381722490116
total_envstep_count: 26321504
total_train_sample_count: 19730213
total_episode_count: 57816
total_duration: 5270.966816229944
[2023-06-29 14:54:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1786
train_sample_count: 1786
avg_envstep_per_episode: 357.2
avg_sample_per_episode: 357.2
avg_envstep_per_sec: 2768.9204306123456
avg_train_sample_per_sec: 2768.9204306123456
avg_episode_per_sec: 7.751736927806119
collect_time: 0.6450167293557897
reward_mean: 3049.7438343269046
reward_std: 674.2862383193865
reward_max: 3543.6962762873613
reward_min: 1743.16147773498
total_envstep_count: 26326024
total_train_sample_count: 19733599
total_episode_count: 57821
total_duration: 5271.6118329593
[2023-06-29 14:54:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2181
train_sample_count: 2181
avg_envstep_per_episode: 363.5
avg_sample_per_episode: 363.5
avg_envstep_per_sec: 2753.9441200122283
avg_train_sample_per_sec: 2753.9441200122283
avg_episode_per_sec: 7.5761874003087435
collect_time: 0.7919550669714808
reward_mean: 2716.2924389274526
reward_std: 634.3513011332619
reward_max: 3532.2756347462328
reward_min: 1789.3431291147797
total_envstep_count: 26330704
total_train_sample_count: 19736980
total_episode_count: 57827
total_duration: 5272.403788026271
[2023-06-29 14:54:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 935
train_sample_count: 935
avg_envstep_per_episode: 233.75
avg_sample_per_episode: 233.75
avg_envstep_per_sec: 2661.07346944206
avg_train_sample_per_sec: 2661.07346944206
avg_episode_per_sec: 11.384271527024856
collect_time: 0.35136196378525353
reward_mean: 2963.837854170053
reward_std: 950.8799912298771
reward_max: 3538.9749459054246
reward_min: 1317.1246485043962
total_envstep_count: 26334472
total_train_sample_count: 19740315
total_episode_count: 57831
total_duration: 5272.755149990056
[2023-06-29 14:54:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2044
train_sample_count: 2044
avg_envstep_per_episode: 255.5
avg_sample_per_episode: 255.5
avg_envstep_per_sec: 2506.829421014545
avg_train_sample_per_sec: 2506.829421014545
avg_episode_per_sec: 9.811465444283934
collect_time: 0.8153725909171625
reward_mean: 2340.047319364733
reward_std: 1077.9255062265327
reward_max: 3526.7316314301806
reward_min: 564.884459948742
total_envstep_count: 26338472
total_train_sample_count: 19743559
total_episode_count: 57839
total_duration: 5273.570522580973
[2023-06-29 14:55:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2048
train_sample_count: 2048
avg_envstep_per_episode: 227.55555555555554
avg_sample_per_episode: 227.55555555555554
avg_envstep_per_sec: 2783.536398441283
avg_train_sample_per_sec: 2783.536398441283
avg_episode_per_sec: 12.23233768846267
collect_time: 0.7357547043921658
reward_mean: 1770.155496653488
reward_std: 725.6182745277002
reward_max: 3528.751422979796
reward_min: 1136.3058147904526
total_envstep_count: 26342312
total_train_sample_count: 19746807
total_episode_count: 57848
total_duration: 5274.3062772853655
[2023-06-29 14:55:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1761
train_sample_count: 1761
avg_envstep_per_episode: 440.25
avg_sample_per_episode: 440.25
avg_envstep_per_sec: 2558.877981514188
avg_train_sample_per_sec: 2558.877981514188
avg_episode_per_sec: 5.812329316329785
collect_time: 0.6881922517297787
reward_mean: 2831.927297641266
reward_std: 781.4098344925434
reward_max: 3500.1244491187745
reward_min: 1584.4614123875049
total_envstep_count: 26346824
total_train_sample_count: 19750168
total_episode_count: 57852
total_duration: 5274.994469537095
[2023-06-29 14:55:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1695
train_sample_count: 1695
avg_envstep_per_episode: 282.5
avg_sample_per_episode: 282.5
avg_envstep_per_sec: 2344.551945643229
avg_train_sample_per_sec: 2344.551945643229
avg_episode_per_sec: 8.2992989226309
collect_time: 0.7229526320155708
reward_mean: 2796.3121907634904
reward_std: 1022.0454198568116
reward_max: 3622.1088688551736
reward_min: 1317.9180902488272
total_envstep_count: 26350552
total_train_sample_count: 19753463
total_episode_count: 57858
total_duration: 5275.71742216911
[2023-06-29 14:55:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 1236
train_sample_count: 1236
avg_envstep_per_episode: 412.0
avg_sample_per_episode: 412.0
avg_envstep_per_sec: 2794.20877739807
avg_train_sample_per_sec: 2794.20877739807
avg_episode_per_sec: 6.782060139315704
collect_time: 0.44234346767421817
reward_mean: 2810.662266568927
reward_std: 986.6309478187792
reward_max: 3528.2952318083767
reward_min: 1415.547981099124
total_envstep_count: 26354824
total_train_sample_count: 19756699
total_episode_count: 57861
total_duration: 5276.159765636785
[2023-06-29 14:55:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 248.4
avg_sample_per_episode: 248.4
avg_envstep_per_sec: 2684.5189018486235
avg_train_sample_per_sec: 2684.5189018486235
avg_episode_per_sec: 10.807241955912334
collect_time: 0.462652730492875
reward_mean: 3515.2136776658326
reward_std: 30.537638003077735
reward_max: 3570.197612853471
reward_min: 3481.913670830608
total_envstep_count: 26358552
total_train_sample_count: 19759941
total_episode_count: 57866
total_duration: 5276.6224183672775
[2023-06-29 14:55:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2910
train_sample_count: 2910
avg_envstep_per_episode: 415.7142857142857
avg_sample_per_episode: 415.7142857142857
avg_envstep_per_sec: 2763.5857063953604
avg_train_sample_per_sec: 2763.5857063953604
avg_episode_per_sec: 6.64780066830499
collect_time: 1.0529798273546627
reward_mean: 2834.2218291595723
reward_std: 1038.6093059964007
reward_max: 3529.831935717468
reward_min: 1168.4114724443316
total_envstep_count: 26363352
total_train_sample_count: 19763251
total_episode_count: 57873
total_duration: 5277.675398194632
[2023-06-29 14:55:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1847
train_sample_count: 1847
avg_envstep_per_episode: 230.875
avg_sample_per_episode: 230.875
avg_envstep_per_sec: 2615.2655498928293
avg_train_sample_per_sec: 2615.2655498928293
avg_episode_per_sec: 11.327625554489785
collect_time: 0.7062380338683726
reward_mean: 1654.4542751602232
reward_std: 593.4658295906913
reward_max: 2893.1464699126022
reward_min: 976.2329773370351
total_envstep_count: 26368048
total_train_sample_count: 19766698
total_episode_count: 57881
total_duration: 5278.381636228501
[2023-06-29 14:55:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 922
train_sample_count: 922
avg_envstep_per_episode: 184.4
avg_sample_per_episode: 184.4
avg_envstep_per_sec: 2070.496053312733
avg_train_sample_per_sec: 2070.496053312733
avg_episode_per_sec: 11.228286623171003
collect_time: 0.44530391570890804
reward_mean: 2580.811967281704
reward_std: 786.8674811397599
reward_max: 3480.048712558808
reward_min: 1460.4867373816828
total_envstep_count: 26372680
total_train_sample_count: 19770020
total_episode_count: 57886
total_duration: 5278.826940144209
[2023-06-29 14:55:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2313
train_sample_count: 2313
avg_envstep_per_episode: 231.3
avg_sample_per_episode: 231.3
avg_envstep_per_sec: 2594.2394952001255
avg_train_sample_per_sec: 2594.2394952001255
avg_episode_per_sec: 11.215907891051126
collect_time: 0.8915907742055134
reward_mean: 2229.209596613353
reward_std: 1053.2333603371985
reward_max: 3493.775377836041
reward_min: 395.80962759061987
total_envstep_count: 26377616
total_train_sample_count: 19773533
total_episode_count: 57896
total_duration: 5279.718530918415
[2023-06-29 14:55:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2531
train_sample_count: 2531
avg_envstep_per_episode: 253.1
avg_sample_per_episode: 253.1
avg_envstep_per_sec: 2716.250256776704
avg_train_sample_per_sec: 2716.250256776704
avg_episode_per_sec: 10.731925155182552
collect_time: 0.9317992676431313
reward_mean: 1926.3108981416474
reward_std: 1039.3353638726774
reward_max: 3595.6748321203304
reward_min: 125.74514129121778
total_envstep_count: 26382368
total_train_sample_count: 19776864
total_episode_count: 57906
total_duration: 5280.650330186058
[2023-06-29 14:55:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2053
train_sample_count: 2053
avg_envstep_per_episode: 256.625
avg_sample_per_episode: 256.625
avg_envstep_per_sec: 2743.009611467812
avg_train_sample_per_sec: 2743.009611467812
avg_episode_per_sec: 10.688785626762053
collect_time: 0.7484479789705947
reward_mean: 1925.3270836315783
reward_std: 795.9847903293356
reward_max: 3419.164216642756
reward_min: 808.636152045686
total_envstep_count: 26386728
total_train_sample_count: 19780117
total_episode_count: 57914
total_duration: 5281.398778165029
[2023-06-29 14:55:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2058
train_sample_count: 2058
avg_envstep_per_episode: 228.66666666666666
avg_sample_per_episode: 228.66666666666666
avg_envstep_per_sec: 2500.7304913138128
avg_train_sample_per_sec: 2500.7304913138128
avg_episode_per_sec: 10.936139174841745
collect_time: 0.8229595340834931
reward_mean: 1615.6109748818276
reward_std: 778.0597795758918
reward_max: 3003.1950135643733
reward_min: 142.4929220310285
total_envstep_count: 26391432
total_train_sample_count: 19783375
total_episode_count: 57923
total_duration: 5282.221737699113
[2023-06-29 14:55:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1665
train_sample_count: 1665
avg_envstep_per_episode: 277.5
avg_sample_per_episode: 277.5
avg_envstep_per_sec: 2438.992023611853
avg_train_sample_per_sec: 2438.992023611853
avg_episode_per_sec: 8.789160445448118
collect_time: 0.6826590591035784
reward_mean: 2233.846928955185
reward_std: 1020.6523572477904
reward_max: 3662.0961955201283
reward_min: 925.4454768486751
total_envstep_count: 26395824
total_train_sample_count: 19786640
total_episode_count: 57929
total_duration: 5282.9043967582165
[2023-06-29 14:55:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1493
train_sample_count: 1493
avg_envstep_per_episode: 186.625
avg_sample_per_episode: 186.625
avg_envstep_per_sec: 2617.3649607475504
avg_train_sample_per_sec: 2617.3649607475504
avg_episode_per_sec: 14.024728523764503
collect_time: 0.5704210235830396
reward_mean: 2183.6640828347363
reward_std: 1029.5669244419014
reward_max: 3531.56409331553
reward_min: 604.3859902653351
total_envstep_count: 26400256
total_train_sample_count: 19790133
total_episode_count: 57937
total_duration: 5283.474817781799
[2023-06-29 14:55:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1932
train_sample_count: 1932
avg_envstep_per_episode: 241.5
avg_sample_per_episode: 241.5
avg_envstep_per_sec: 2763.9726020002468
avg_train_sample_per_sec: 2763.9726020002468
avg_episode_per_sec: 11.445021126295018
collect_time: 0.6989939041370525
reward_mean: 2113.318737223017
reward_std: 884.805134936069
reward_max: 3544.457400220529
reward_min: 1168.5446623100622
total_envstep_count: 26404720
total_train_sample_count: 19793665
total_episode_count: 57945
total_duration: 5284.173811685936
[2023-06-29 14:55:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 195.85714285714286
avg_sample_per_episode: 195.85714285714286
avg_envstep_per_sec: 2736.840324195521
avg_train_sample_per_sec: 2736.840324195521
avg_episode_per_sec: 13.973655922223669
collect_time: 0.5009426336931065
reward_mean: 2127.8061352610594
reward_std: 920.9466431944152
reward_max: 3504.0850458481386
reward_min: 1092.4241826967634
total_envstep_count: 26408544
total_train_sample_count: 19797036
total_episode_count: 57952
total_duration: 5284.674754319629
[2023-06-29 14:55:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2302.5429882755343
avg_train_sample_per_sec: 2302.5429882755343
avg_episode_per_sec: 7.263542549765092
collect_time: 0.5506954729864373
reward_mean: 2248.882674356556
reward_std: 917.224002766942
reward_max: 3651.774963366156
reward_min: 1226.7388172709884
total_envstep_count: 26412736
total_train_sample_count: 19800304
total_episode_count: 57956
total_duration: 5285.225449792615
[2023-06-29 14:55:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 166.16666666666666
avg_sample_per_episode: 166.16666666666666
avg_envstep_per_sec: 2600.250179277483
avg_train_sample_per_sec: 2600.250179277483
avg_episode_per_sec: 15.648446414909627
collect_time: 0.3834246442690491
reward_mean: 2705.1879649184934
reward_std: 1139.5685299192323
reward_max: 3529.950754801537
reward_min: 1083.507353316342
total_envstep_count: 26416544
total_train_sample_count: 19803701
total_episode_count: 57962
total_duration: 5285.608874436884
[2023-06-29 14:55:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1720
train_sample_count: 1720
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 2724.0328850546407
avg_train_sample_per_sec: 2724.0328850546407
avg_episode_per_sec: 12.669920395602981
collect_time: 0.6314167532399297
reward_mean: 2134.203821262584
reward_std: 1175.0827580288505
reward_max: 3518.6827533079186
reward_min: 492.18108189621955
total_envstep_count: 26420944
total_train_sample_count: 19807021
total_episode_count: 57970
total_duration: 5286.2402911901245
[2023-06-29 14:55:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2929
train_sample_count: 2929
avg_envstep_per_episode: 266.27272727272725
avg_sample_per_episode: 266.27272727272725
avg_envstep_per_sec: 2740.105184895908
avg_train_sample_per_sec: 2740.105184895908
avg_episode_per_sec: 10.290596460858652
collect_time: 1.068937067140825
reward_mean: 1862.1556702867085
reward_std: 1067.992000140746
reward_max: 3586.6895476437385
reward_min: 406.75605457268676
total_envstep_count: 26425536
total_train_sample_count: 19810350
total_episode_count: 57981
total_duration: 5287.309228257265
[2023-06-29 14:56:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2470.4447210006338
avg_train_sample_per_sec: 2470.4447210006338
avg_episode_per_sec: 11.078227448433335
collect_time: 0.8124043347090482
reward_mean: 1491.3436367147547
reward_std: 805.5333826719624
reward_max: 3256.98490337291
reward_min: 137.87065459648227
total_envstep_count: 26429688
total_train_sample_count: 19813557
total_episode_count: 57990
total_duration: 5288.121632591974
[2023-06-29 14:56:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1980
train_sample_count: 1980
avg_envstep_per_episode: 282.85714285714283
avg_sample_per_episode: 282.85714285714283
avg_envstep_per_sec: 2667.5677455275522
avg_train_sample_per_sec: 2667.5677455275522
avg_episode_per_sec: 9.430795059945892
collect_time: 0.7422491906043139
reward_mean: 2108.811219259765
reward_std: 1024.223363772294
reward_max: 3474.5282787563756
reward_min: 636.3245928745282
total_envstep_count: 26434408
total_train_sample_count: 19817137
total_episode_count: 57997
total_duration: 5288.863881782579
[2023-06-29 14:56:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 244.33333333333334
avg_sample_per_episode: 244.33333333333334
avg_envstep_per_sec: 2467.5232992111314
avg_train_sample_per_sec: 2467.5232992111314
avg_episode_per_sec: 10.099003953115135
collect_time: 0.8911769954524934
reward_mean: 2014.2404188194005
reward_std: 900.140584660786
reward_max: 3539.4389009683982
reward_min: 937.7248566537412
total_envstep_count: 26438920
total_train_sample_count: 19820536
total_episode_count: 58006
total_duration: 5289.755058778031
[2023-06-29 14:56:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1729
train_sample_count: 1729
avg_envstep_per_episode: 288.1666666666667
avg_sample_per_episode: 288.1666666666667
avg_envstep_per_sec: 2665.901501176496
avg_train_sample_per_sec: 2665.901501176496
avg_episode_per_sec: 9.251248702752445
collect_time: 0.6485610962134086
reward_mean: 2309.5502950427467
reward_std: 793.4110028250551
reward_max: 3614.684514065815
reward_min: 1451.7298492850541
total_envstep_count: 26443832
total_train_sample_count: 19823865
total_episode_count: 58012
total_duration: 5290.403619874244
[2023-06-29 14:56:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2441
train_sample_count: 2441
avg_envstep_per_episode: 244.1
avg_sample_per_episode: 244.1
avg_envstep_per_sec: 2567.7944468595592
avg_train_sample_per_sec: 2567.7944468595592
avg_episode_per_sec: 10.519436488568452
collect_time: 0.950621262922883
reward_mean: 1987.2671150348524
reward_std: 982.4584072289002
reward_max: 3504.761110266663
reward_min: 409.24382226123396
total_envstep_count: 26448376
total_train_sample_count: 19827106
total_episode_count: 58022
total_duration: 5291.354241137167
[2023-06-29 14:56:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 190.14285714285714
avg_sample_per_episode: 190.14285714285714
avg_envstep_per_sec: 2406.6707977477854
avg_train_sample_per_sec: 2406.6707977477854
avg_episode_per_sec: 12.65717173871863
collect_time: 0.5530461421003565
reward_mean: 1697.380004710136
reward_std: 987.0430632516731
reward_max: 3540.8404481804478
reward_min: 312.1756153443282
total_envstep_count: 26452576
total_train_sample_count: 19830437
total_episode_count: 58029
total_duration: 5291.907287279268
[2023-06-29 14:56:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 2527.4885809300836
avg_train_sample_per_sec: 2527.4885809300836
avg_episode_per_sec: 8.314107174112118
collect_time: 0.841942478417419
reward_mean: 2464.0644585641808
reward_std: 1205.0712627287187
reward_max: 3483.3324831841064
reward_min: 661.8489598020906
total_envstep_count: 26457088
total_train_sample_count: 19833765
total_episode_count: 58036
total_duration: 5292.749229757685
[2023-06-29 14:56:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2680
train_sample_count: 2680
avg_envstep_per_episode: 268.0
avg_sample_per_episode: 268.0
avg_envstep_per_sec: 2779.8595195824632
avg_train_sample_per_sec: 2779.8595195824632
avg_episode_per_sec: 10.372610147695758
collect_time: 0.9640774942478165
reward_mean: 1957.6846323882448
reward_std: 1035.562525120033
reward_max: 3532.390785749757
reward_min: 320.7584378270725
total_envstep_count: 26462000
total_train_sample_count: 19837245
total_episode_count: 58046
total_duration: 5293.713307251933
[2023-06-29 14:56:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1619
train_sample_count: 1619
avg_envstep_per_episode: 202.375
avg_sample_per_episode: 202.375
avg_envstep_per_sec: 2670.953688246129
avg_train_sample_per_sec: 2670.953688246129
avg_episode_per_sec: 13.19804169608958
collect_time: 0.6061505323452875
reward_mean: 1624.8061655552992
reward_std: 899.9710458467082
reward_max: 3530.4849349577566
reward_min: 323.22677696056354
total_envstep_count: 26465984
total_train_sample_count: 19840464
total_episode_count: 58054
total_duration: 5294.319457784278
[2023-06-29 14:56:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2772.519361515808
avg_train_sample_per_sec: 2772.519361515808
avg_episode_per_sec: 12.432822248949813
collect_time: 0.3217290426827968
reward_mean: 1991.2999028725503
reward_std: 1133.8349795435909
reward_max: 3501.931122368562
reward_min: 505.19546410753486
total_envstep_count: 26470544
total_train_sample_count: 19843756
total_episode_count: 58058
total_duration: 5294.641186826961
[2023-06-29 14:56:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2216
train_sample_count: 2216
avg_envstep_per_episode: 221.6
avg_sample_per_episode: 221.6
avg_envstep_per_sec: 2713.7338047339485
avg_train_sample_per_sec: 2713.7338047339485
avg_episode_per_sec: 12.24609117659724
collect_time: 0.8165870934482663
reward_mean: 2433.4769469684356
reward_std: 1147.629789180114
reward_max: 3605.2001766470667
reward_min: 583.8144210196768
total_envstep_count: 26475080
total_train_sample_count: 19847172
total_episode_count: 58068
total_duration: 5295.457773920409
[2023-06-29 14:56:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1736
train_sample_count: 1736
avg_envstep_per_episode: 248.0
avg_sample_per_episode: 248.0
avg_envstep_per_sec: 2762.8355772122827
avg_train_sample_per_sec: 2762.8355772122827
avg_episode_per_sec: 11.1404660371463
collect_time: 0.6283399614216761
reward_mean: 1849.9526862336913
reward_std: 1073.288789647092
reward_max: 3567.334621976942
reward_min: 953.0436748900111
total_envstep_count: 26479344
total_train_sample_count: 19850508
total_episode_count: 58075
total_duration: 5296.08611388183
[2023-06-29 14:56:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2014
train_sample_count: 2014
avg_envstep_per_episode: 223.77777777777777
avg_sample_per_episode: 223.77777777777777
avg_envstep_per_sec: 2597.404951637768
avg_train_sample_per_sec: 2597.404951637768
avg_episode_per_sec: 11.607072772959242
collect_time: 0.7753892972022295
reward_mean: 2021.729667347135
reward_std: 1233.8944402055843
reward_max: 3552.4898818223933
reward_min: 280.4959652674617
total_envstep_count: 26483688
total_train_sample_count: 19853722
total_episode_count: 58084
total_duration: 5296.861503179032
[2023-06-29 14:56:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2901
train_sample_count: 2901
avg_envstep_per_episode: 290.1
avg_sample_per_episode: 290.1
avg_envstep_per_sec: 2608.5877499745316
avg_train_sample_per_sec: 2608.5877499745316
avg_episode_per_sec: 8.992029472507864
collect_time: 1.1120959990816193
reward_mean: 1953.0297865284174
reward_std: 729.3133754757529
reward_max: 3483.498245714872
reward_min: 995.7357710562936
total_envstep_count: 26488064
total_train_sample_count: 19857023
total_episode_count: 58094
total_duration: 5297.973599178114
[2023-06-29 14:56:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2414
train_sample_count: 2414
avg_envstep_per_episode: 268.22222222222223
avg_sample_per_episode: 268.22222222222223
avg_envstep_per_sec: 2670.221450619916
avg_train_sample_per_sec: 2670.221450619916
avg_episode_per_sec: 9.955258100902753
collect_time: 0.9040448684282602
reward_mean: 1564.1825237339872
reward_std: 569.4262961258737
reward_max: 2975.5020518907013
reward_min: 998.4091525900196
total_envstep_count: 26492680
total_train_sample_count: 19860237
total_episode_count: 58103
total_duration: 5298.877644046542
[2023-06-29 14:56:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 226.66666666666666
avg_sample_per_episode: 226.66666666666666
avg_envstep_per_sec: 2773.8529876351204
avg_train_sample_per_sec: 2773.8529876351204
avg_episode_per_sec: 12.237586710154943
collect_time: 0.4902927466100081
reward_mean: 1898.817553150855
reward_std: 549.8620590655586
reward_max: 2778.447664990971
reward_min: 1266.1623619953964
total_envstep_count: 26496984
total_train_sample_count: 19863597
total_episode_count: 58109
total_duration: 5299.367936793152
[2023-06-29 14:56:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2899
train_sample_count: 2899
avg_envstep_per_episode: 322.1111111111111
avg_sample_per_episode: 322.1111111111111
avg_envstep_per_sec: 2734.63332716816
avg_train_sample_per_sec: 2734.63332716816
avg_episode_per_sec: 8.48972057416814
collect_time: 1.060105561940931
reward_mean: 2471.2908308706415
reward_std: 1160.6920093216747
reward_max: 3625.6123185209867
reward_min: 881.0336680680615
total_envstep_count: 26501784
total_train_sample_count: 19866896
total_episode_count: 58118
total_duration: 5300.428042355093
[2023-06-29 14:56:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 287.42857142857144
avg_sample_per_episode: 287.42857142857144
avg_envstep_per_sec: 2413.4204382574003
avg_train_sample_per_sec: 2413.4204382574003
avg_episode_per_sec: 8.396591982008848
collect_time: 0.8336715675834567
reward_mean: 1872.893373500948
reward_std: 777.3258157664442
reward_max: 3256.5766849340894
reward_min: 953.888419762004
total_envstep_count: 26506504
total_train_sample_count: 19870108
total_episode_count: 58125
total_duration: 5301.261713922676
[2023-06-29 14:56:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2082
train_sample_count: 2082
avg_envstep_per_episode: 260.25
avg_sample_per_episode: 260.25
avg_envstep_per_sec: 2689.4221732454293
avg_train_sample_per_sec: 2689.4221732454293
avg_episode_per_sec: 10.333994901999729
collect_time: 0.7741439855415375
reward_mean: 2242.0332521532487
reward_std: 899.0227151667739
reward_max: 3470.918321670942
reward_min: 628.7945787306629
total_envstep_count: 26511080
total_train_sample_count: 19873390
total_episode_count: 58133
total_duration: 5302.035857908218
[2023-06-29 14:57:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1203
train_sample_count: 1203
avg_envstep_per_episode: 171.85714285714286
avg_sample_per_episode: 171.85714285714286
avg_envstep_per_sec: 2705.879966819962
avg_train_sample_per_sec: 2705.879966819962
avg_episode_per_sec: 15.744937462792798
collect_time: 0.44458734857104715
reward_mean: 1351.295747447061
reward_std: 481.88326766644434
reward_max: 2149.747400516127
reward_min: 567.0370612974845
total_envstep_count: 26514896
total_train_sample_count: 19876593
total_episode_count: 58140
total_duration: 5302.480445256789
[2023-06-29 14:57:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2456
train_sample_count: 2456
avg_envstep_per_episode: 223.27272727272728
avg_sample_per_episode: 223.27272727272728
avg_envstep_per_sec: 2562.203715544701
avg_train_sample_per_sec: 2562.203715544701
avg_episode_per_sec: 11.475668107081317
collect_time: 0.95854985499382
reward_mean: 1991.2491854038215
reward_std: 952.5284013156781
reward_max: 3599.20977751902
reward_min: 996.7829604295588
total_envstep_count: 26518792
total_train_sample_count: 19879849
total_episode_count: 58151
total_duration: 5303.438995111783
[2023-06-29 14:57:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 258.45454545454544
avg_sample_per_episode: 258.45454545454544
avg_envstep_per_sec: 2545.6397256457376
avg_train_sample_per_sec: 2545.6397256457376
avg_episode_per_sec: 9.849467809392584
collect_time: 1.1168116098120808
reward_mean: 1269.6630081571998
reward_std: 529.4261601185582
reward_max: 2192.224231050462
reward_min: 331.9989298429175
total_envstep_count: 26523072
total_train_sample_count: 19883092
total_episode_count: 58162
total_duration: 5304.555806721595
[2023-06-29 14:57:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 306.25
avg_sample_per_episode: 306.25
avg_envstep_per_sec: 2606.907995539724
avg_train_sample_per_sec: 2606.907995539724
avg_episode_per_sec: 8.512352638497058
collect_time: 0.939810689211823
reward_mean: 1771.0759578707614
reward_std: 857.9403936445258
reward_max: 3504.247294843435
reward_min: 987.9808178347934
total_envstep_count: 26527192
total_train_sample_count: 19886342
total_episode_count: 58170
total_duration: 5305.495617410807
[2023-06-29 14:57:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2669
train_sample_count: 2669
avg_envstep_per_episode: 296.55555555555554
avg_sample_per_episode: 296.55555555555554
avg_envstep_per_sec: 2739.410765328834
avg_train_sample_per_sec: 2739.410765328834
avg_episode_per_sec: 9.237428582974712
collect_time: 0.9742971130069346
reward_mean: 1865.6695960584157
reward_std: 966.0765318229915
reward_max: 3589.892015044953
reward_min: 816.6928338563175
total_envstep_count: 26532080
total_train_sample_count: 19889811
total_episode_count: 58179
total_duration: 5306.469914523815
[2023-06-29 14:57:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3310
train_sample_count: 3310
avg_envstep_per_episode: 300.90909090909093
avg_sample_per_episode: 300.90909090909093
avg_envstep_per_sec: 2596.951095897035
avg_train_sample_per_sec: 2596.951095897035
avg_episode_per_sec: 8.630351073978062
collect_time: 1.2745715563260018
reward_mean: 1792.7935594805022
reward_std: 1014.1820890241264
reward_max: 3510.8925554496977
reward_min: 958.4541496366054
total_envstep_count: 26536376
total_train_sample_count: 19893121
total_episode_count: 58190
total_duration: 5307.744486080141
[2023-06-29 14:57:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2196
train_sample_count: 2196
avg_envstep_per_episode: 244.0
avg_sample_per_episode: 244.0
avg_envstep_per_sec: 2681.6962373251117
avg_train_sample_per_sec: 2681.6962373251117
avg_episode_per_sec: 10.99055834969308
collect_time: 0.8188846929920837
reward_mean: 1256.6893540847595
reward_std: 683.6777187723651
reward_max: 2590.6516046721445
reward_min: 485.6214607317886
total_envstep_count: 26540848
total_train_sample_count: 19896517
total_episode_count: 58199
total_duration: 5308.563370773133
[2023-06-29 14:57:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2196
train_sample_count: 2196
avg_envstep_per_episode: 274.5
avg_sample_per_episode: 274.5
avg_envstep_per_sec: 2441.442128818695
avg_train_sample_per_sec: 2441.442128818695
avg_episode_per_sec: 8.894142545787595
collect_time: 0.8994683814449236
reward_mean: 1742.7396830889409
reward_std: 861.2421756419341
reward_max: 3657.838561691811
reward_min: 552.3519669861222
total_envstep_count: 26545336
total_train_sample_count: 19899913
total_episode_count: 58207
total_duration: 5309.462839154578
[2023-06-29 14:57:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2606
train_sample_count: 2606
avg_envstep_per_episode: 186.14285714285714
avg_sample_per_episode: 186.14285714285714
avg_envstep_per_sec: 2725.1963568890055
avg_train_sample_per_sec: 2725.1963568890055
avg_episode_per_sec: 14.640348809073705
collect_time: 0.9562613693550229
reward_mean: 1395.7071945030395
reward_std: 968.0728274323633
reward_max: 3627.9581269457676
reward_min: 385.94763688716984
total_envstep_count: 26550232
total_train_sample_count: 19903319
total_episode_count: 58221
total_duration: 5310.419100523934
[2023-06-29 14:57:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3467
train_sample_count: 3467
avg_envstep_per_episode: 266.6923076923077
avg_sample_per_episode: 266.6923076923077
avg_envstep_per_sec: 2560.388761498381
avg_train_sample_per_sec: 2560.388761498381
avg_episode_per_sec: 9.600534727279767
collect_time: 1.3540912427576255
reward_mean: 1602.3910842067844
reward_std: 748.1494536263076
reward_max: 3550.1026426569338
reward_min: 760.9803491798153
total_envstep_count: 26554792
total_train_sample_count: 19906786
total_episode_count: 58234
total_duration: 5311.7731917666915
[2023-06-29 14:57:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2998
train_sample_count: 2998
avg_envstep_per_episode: 230.6153846153846
avg_sample_per_episode: 230.6153846153846
avg_envstep_per_sec: 2682.8269989138835
avg_train_sample_per_sec: 2682.8269989138835
avg_episode_per_sec: 11.633339221441123
collect_time: 1.11747794442717
reward_mean: 1123.7850085451114
reward_std: 145.84151912674258
reward_max: 1370.9546836422332
reward_min: 882.6688883076621
total_envstep_count: 26559536
total_train_sample_count: 19910184
total_episode_count: 58247
total_duration: 5312.890669711119
[2023-06-29 14:57:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3002
train_sample_count: 3002
avg_envstep_per_episode: 250.16666666666666
avg_sample_per_episode: 250.16666666666666
avg_envstep_per_sec: 2497.410513578647
avg_train_sample_per_sec: 2497.410513578647
avg_episode_per_sec: 9.982986729828037
collect_time: 1.202045071756467
reward_mean: 1421.9104839703605
reward_std: 349.08058937182324
reward_max: 1973.089066727707
reward_min: 935.2007791804111
total_envstep_count: 26564304
total_train_sample_count: 19913586
total_episode_count: 58259
total_duration: 5314.092714782875
[2023-06-29 14:57:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 16
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 209.125
avg_sample_per_episode: 209.125
avg_envstep_per_sec: 2757.208037099612
avg_train_sample_per_sec: 2757.208037099612
avg_episode_per_sec: 13.184497487625162
collect_time: 1.2135464408118277
reward_mean: 1152.396053900784
reward_std: 355.6017912275957
reward_max: 2058.9613921202954
reward_min: 471.80124274288016
total_envstep_count: 26568736
total_train_sample_count: 19916932
total_episode_count: 58275
total_duration: 5315.306261223687
[2023-06-29 14:57:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2655
train_sample_count: 2655
avg_envstep_per_episode: 265.5
avg_sample_per_episode: 265.5
avg_envstep_per_sec: 2719.589651810527
avg_train_sample_per_sec: 2719.589651810527
avg_episode_per_sec: 10.243275524710082
collect_time: 0.9762502215113492
reward_mean: 1344.553579467408
reward_std: 539.7714264787628
reward_max: 2689.504178528139
reward_min: 935.734393223413
total_envstep_count: 26573024
total_train_sample_count: 19920387
total_episode_count: 58285
total_duration: 5316.282511445199
[2023-06-29 14:57:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2834
train_sample_count: 2834
avg_envstep_per_episode: 283.4
avg_sample_per_episode: 283.4
avg_envstep_per_sec: 2522.130841347494
avg_train_sample_per_sec: 2522.130841347494
avg_episode_per_sec: 8.899544253166882
collect_time: 1.123653045091778
reward_mean: 1610.423519342102
reward_std: 866.3965975695382
reward_max: 3331.169318724045
reward_min: 647.693488140788
total_envstep_count: 26578152
total_train_sample_count: 19923621
total_episode_count: 58295
total_duration: 5317.40616449029
[2023-06-29 14:57:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2643
train_sample_count: 2643
avg_envstep_per_episode: 203.30769230769232
avg_sample_per_episode: 203.30769230769232
avg_envstep_per_sec: 2681.4641418289943
avg_train_sample_per_sec: 2681.4641418289943
avg_episode_per_sec: 13.189191768360546
collect_time: 0.9856555449580772
reward_mean: 1324.9398120871515
reward_std: 633.1356964246918
reward_max: 3093.731538493845
reward_min: 356.5857544830135
total_envstep_count: 26582256
total_train_sample_count: 19927064
total_episode_count: 58308
total_duration: 5318.391820035248
[2023-06-29 14:57:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 206.83333333333334
avg_sample_per_episode: 206.83333333333334
avg_envstep_per_sec: 2630.7430795507316
avg_train_sample_per_sec: 2630.7430795507316
avg_episode_per_sec: 12.719144623130047
collect_time: 0.9434596708789468
reward_mean: 1222.1981652532784
reward_std: 703.913130987619
reward_max: 2701.1508071283024
reward_min: 319.7932717881645
total_envstep_count: 26587136
total_train_sample_count: 19930346
total_episode_count: 58320
total_duration: 5319.335279706127
[2023-06-29 14:57:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1290
train_sample_count: 1290
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 2654.4607010382597
avg_train_sample_per_sec: 2654.4607010382597
avg_episode_per_sec: 18.519493263057626
collect_time: 0.4859744201507419
reward_mean: 1489.4840169083307
reward_std: 864.6880458014645
reward_max: 3531.2285060685895
reward_min: 336.484111229723
total_envstep_count: 26591408
total_train_sample_count: 19933636
total_episode_count: 58329
total_duration: 5319.821254126277
[2023-06-29 14:57:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3124
train_sample_count: 3124
avg_envstep_per_episode: 208.26666666666668
avg_sample_per_episode: 208.26666666666668
avg_envstep_per_sec: 2498.301380072014
avg_train_sample_per_sec: 2498.301380072014
avg_episode_per_sec: 11.995685243623626
collect_time: 1.2504496154543012
reward_mean: 1468.7981709642322
reward_std: 708.8112421034325
reward_max: 2926.4489838217532
reward_min: 538.3187906632817
total_envstep_count: 26595944
total_train_sample_count: 19937160
total_episode_count: 58344
total_duration: 5321.071703741732
[2023-06-29 14:58:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3354
train_sample_count: 3354
avg_envstep_per_episode: 279.5
avg_sample_per_episode: 279.5
avg_envstep_per_sec: 2464.1280758516023
avg_train_sample_per_sec: 2464.1280758516023
avg_episode_per_sec: 8.816200629164946
collect_time: 1.3611305487198988
reward_mean: 1424.8312394164623
reward_std: 511.8796788434595
reward_max: 2279.9469079581295
reward_min: 504.4980248579963
total_envstep_count: 26600552
total_train_sample_count: 19940514
total_episode_count: 58356
total_duration: 5322.432834290452
[2023-06-29 14:58:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1611
train_sample_count: 1611
avg_envstep_per_episode: 230.14285714285714
avg_sample_per_episode: 230.14285714285714
avg_envstep_per_sec: 2552.610059812918
avg_train_sample_per_sec: 2552.610059812918
avg_episode_per_sec: 11.09141552991336
collect_time: 0.6311187225040048
reward_mean: 1288.8845225986772
reward_std: 265.11550556916234
reward_max: 1657.419377951274
reward_min: 907.7862380113926
total_envstep_count: 26605032
total_train_sample_count: 19943725
total_episode_count: 58363
total_duration: 5323.063953012956
[2023-06-29 14:58:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1903
train_sample_count: 1903
avg_envstep_per_episode: 237.875
avg_sample_per_episode: 237.875
avg_envstep_per_sec: 2642.907666792749
avg_train_sample_per_sec: 2642.907666792749
avg_episode_per_sec: 11.11048940322753
collect_time: 0.7200402889251708
reward_mean: 2316.7252426113255
reward_std: 850.5561526153944
reward_max: 3574.201484123244
reward_min: 1061.4265507741802
total_envstep_count: 26609848
total_train_sample_count: 19947228
total_episode_count: 58371
total_duration: 5323.78399330188
[2023-06-29 14:58:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3421
train_sample_count: 3421
avg_envstep_per_episode: 244.35714285714286
avg_sample_per_episode: 244.35714285714286
avg_envstep_per_sec: 2519.534533049567
avg_train_sample_per_sec: 2519.534533049567
avg_episode_per_sec: 10.310869179390219
collect_time: 1.3577904788069433
reward_mean: 1628.6587797533446
reward_std: 889.5451595596529
reward_max: 3603.0868284361864
reward_min: 322.60711423312165
total_envstep_count: 26614368
total_train_sample_count: 19950649
total_episode_count: 58385
total_duration: 5325.141783780688
[2023-06-29 14:58:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2878
train_sample_count: 2878
avg_envstep_per_episode: 287.8
avg_sample_per_episode: 287.8
avg_envstep_per_sec: 2458.2042358208164
avg_train_sample_per_sec: 2458.2042358208164
avg_episode_per_sec: 8.541362876375317
collect_time: 1.170773346682079
reward_mean: 1432.4441772437194
reward_std: 714.9746315217461
reward_max: 3242.852640474794
reward_min: 370.2387647586301
total_envstep_count: 26619152
total_train_sample_count: 19953927
total_episode_count: 58395
total_duration: 5326.3125571273695
[2023-06-29 14:58:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 225.22222222222223
avg_sample_per_episode: 225.22222222222223
avg_envstep_per_sec: 2415.6260316289063
avg_train_sample_per_sec: 2415.6260316289063
avg_episode_per_sec: 10.725522587400176
collect_time: 0.8391199521198868
reward_mean: 1460.0453613927575
reward_std: 572.9214779966778
reward_max: 2947.8589607262916
reward_min: 915.8834781663705
total_envstep_count: 26623240
total_train_sample_count: 19957154
total_episode_count: 58404
total_duration: 5327.15167707949
[2023-06-29 14:58:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2468
train_sample_count: 2468
avg_envstep_per_episode: 308.5
avg_sample_per_episode: 308.5
avg_envstep_per_sec: 2634.5193860763984
avg_train_sample_per_sec: 2634.5193860763984
avg_episode_per_sec: 8.539771105596106
collect_time: 0.936793258399819
reward_mean: 2125.712992322716
reward_std: 986.3800635446776
reward_max: 3600.492723524921
reward_min: 943.634768224033
total_envstep_count: 26628024
total_train_sample_count: 19960422
total_episode_count: 58412
total_duration: 5328.08847033789
[2023-06-29 14:58:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2208
train_sample_count: 2208
avg_envstep_per_episode: 245.33333333333334
avg_sample_per_episode: 245.33333333333334
avg_envstep_per_sec: 2612.985035856198
avg_train_sample_per_sec: 2612.985035856198
avg_episode_per_sec: 10.650754222239938
collect_time: 0.8450105797396974
reward_mean: 1850.4796676676783
reward_std: 674.4144327792326
reward_max: 3083.842899826146
reward_min: 1237.2972445072141
total_envstep_count: 26632424
total_train_sample_count: 19963830
total_episode_count: 58421
total_duration: 5328.93348091763
[2023-06-29 14:58:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 223.45454545454547
avg_sample_per_episode: 223.45454545454547
avg_envstep_per_sec: 2656.0028827135247
avg_train_sample_per_sec: 2656.0028827135247
avg_episode_per_sec: 11.886099149653692
collect_time: 0.9254508027825505
reward_mean: 1568.5689614024488
reward_std: 738.5690709261746
reward_max: 2880.4608389338546
reward_min: 636.5822746275104
total_envstep_count: 26636584
total_train_sample_count: 19967088
total_episode_count: 58432
total_duration: 5329.858931720412
[2023-06-29 14:58:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1858
train_sample_count: 1858
avg_envstep_per_episode: 265.42857142857144
avg_sample_per_episode: 265.42857142857144
avg_envstep_per_sec: 2747.7562567981217
avg_train_sample_per_sec: 2747.7562567981217
avg_episode_per_sec: 10.352149514309392
collect_time: 0.67618806995824
reward_mean: 1825.1717920211318
reward_std: 491.42810994794706
reward_max: 2770.0675505772756
reward_min: 1329.38451151915
total_envstep_count: 26641504
total_train_sample_count: 19970546
total_episode_count: 58439
total_duration: 5330.53511979037
[2023-06-29 14:58:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3124
train_sample_count: 3124
avg_envstep_per_episode: 260.3333333333333
avg_sample_per_episode: 260.3333333333333
avg_envstep_per_sec: 2719.661964745912
avg_train_sample_per_sec: 2719.661964745912
avg_episode_per_sec: 10.446844935003503
collect_time: 1.1486721660615877
reward_mean: 1898.3339490868696
reward_std: 773.5431873948482
reward_max: 3450.222831177838
reward_min: 926.2688877172629
total_envstep_count: 26646408
total_train_sample_count: 19974070
total_episode_count: 58451
total_duration: 5331.683791956431
[2023-06-29 14:58:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1732
train_sample_count: 1732
avg_envstep_per_episode: 247.42857142857142
avg_sample_per_episode: 247.42857142857142
avg_envstep_per_sec: 2660.971872929085
avg_train_sample_per_sec: 2660.971872929085
avg_episode_per_sec: 10.754505260106
collect_time: 0.6508900066250937
reward_mean: 1749.7117984213487
reward_std: 713.6228819616191
reward_max: 3268.7554686415356
reward_min: 1001.2401733630784
total_envstep_count: 26650528
total_train_sample_count: 19977402
total_episode_count: 58458
total_duration: 5332.334681963056
[2023-06-29 14:58:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1748
train_sample_count: 1748
avg_envstep_per_episode: 291.3333333333333
avg_sample_per_episode: 291.3333333333333
avg_envstep_per_sec: 2392.592765265835
avg_train_sample_per_sec: 2392.592765265835
avg_episode_per_sec: 8.212560979173347
collect_time: 0.7305881825676188
reward_mean: 2524.7395948466296
reward_std: 647.4682302032534
reward_max: 3505.8828637659426
reward_min: 1454.909544705639
total_envstep_count: 26655040
total_train_sample_count: 19980750
total_episode_count: 58464
total_duration: 5333.065270145624
[2023-06-29 14:58:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2105
train_sample_count: 2105
avg_envstep_per_episode: 233.88888888888889
avg_sample_per_episode: 233.88888888888889
avg_envstep_per_sec: 2603.278038494428
avg_train_sample_per_sec: 2603.278038494428
avg_episode_per_sec: 11.130404915178078
collect_time: 0.8085959197878838
reward_mean: 2000.7237973283684
reward_std: 555.2599265352426
reward_max: 2697.1110670571443
reward_min: 1168.6526497384993
total_envstep_count: 26659096
total_train_sample_count: 19984055
total_episode_count: 58473
total_duration: 5333.873866065412
[2023-06-29 14:58:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3007
train_sample_count: 3007
avg_envstep_per_episode: 250.58333333333334
avg_sample_per_episode: 250.58333333333334
avg_envstep_per_sec: 2617.7353031925795
avg_train_sample_per_sec: 2617.7353031925795
avg_episode_per_sec: 10.446565892354823
collect_time: 1.1487028487306088
reward_mean: 1493.2210445054168
reward_std: 857.5744844260174
reward_max: 3573.4189728309448
reward_min: 604.7518351536448
total_envstep_count: 26663320
total_train_sample_count: 19987462
total_episode_count: 58485
total_duration: 5335.0225689141425
[2023-06-29 14:58:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2789
train_sample_count: 2789
avg_envstep_per_episode: 214.53846153846155
avg_sample_per_episode: 214.53846153846155
avg_envstep_per_sec: 2712.3599556334457
avg_train_sample_per_sec: 2712.3599556334457
avg_episode_per_sec: 12.642767810410469
collect_time: 1.0282558530652897
reward_mean: 1081.545117062774
reward_std: 540.5859066590609
reward_max: 2832.959431707238
reward_min: 551.7417782876418
total_envstep_count: 26668432
total_train_sample_count: 19991051
total_episode_count: 58498
total_duration: 5336.050824767208
[2023-06-29 14:58:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2413
train_sample_count: 2413
avg_envstep_per_episode: 241.3
avg_sample_per_episode: 241.3
avg_envstep_per_sec: 2551.661088764474
avg_train_sample_per_sec: 2551.661088764474
avg_episode_per_sec: 10.574641892931925
collect_time: 0.945658500897698
reward_mean: 1473.431602788884
reward_std: 619.9090917968457
reward_max: 3025.353940742796
reward_min: 939.995960750979
total_envstep_count: 26672272
total_train_sample_count: 19994264
total_episode_count: 58508
total_duration: 5336.996483268105
[2023-06-29 14:58:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 247.23076923076923
avg_sample_per_episode: 247.23076923076923
avg_envstep_per_sec: 2554.586121935526
avg_train_sample_per_sec: 2554.586121935526
avg_episode_per_sec: 10.33280011983878
collect_time: 1.2581294372510166
reward_mean: 1447.5286495455866
reward_std: 823.7692884083573
reward_max: 3285.295908430186
reward_min: 586.7027758398701
total_envstep_count: 26676840
total_train_sample_count: 19997478
total_episode_count: 58521
total_duration: 5338.2546127053565
[2023-06-29 14:58:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2792
train_sample_count: 2792
avg_envstep_per_episode: 232.66666666666666
avg_sample_per_episode: 232.66666666666666
avg_envstep_per_sec: 2521.9536556297585
avg_train_sample_per_sec: 2521.9536556297585
avg_episode_per_sec: 10.839342359440222
collect_time: 1.1070782342758032
reward_mean: 1192.6366106636888
reward_std: 589.5282045479554
reward_max: 2801.0345867947335
reward_min: 347.1422439806835
total_envstep_count: 26681672
total_train_sample_count: 20001070
total_episode_count: 58533
total_duration: 5339.361690939632
[2023-06-29 14:59:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3003
train_sample_count: 3003
avg_envstep_per_episode: 214.5
avg_sample_per_episode: 214.5
avg_envstep_per_sec: 2503.660528687698
avg_train_sample_per_sec: 2503.660528687698
avg_episode_per_sec: 11.672077056819104
collect_time: 1.1994437606818975
reward_mean: 1329.7577704041373
reward_std: 616.7710778788097
reward_max: 2854.5972568439447
reward_min: 461.5379922753458
total_envstep_count: 26686712
total_train_sample_count: 20004473
total_episode_count: 58547
total_duration: 5340.561134700314
[2023-06-29 14:59:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2753
train_sample_count: 2753
avg_envstep_per_episode: 305.8888888888889
avg_sample_per_episode: 305.8888888888889
avg_envstep_per_sec: 2749.4273230159743
avg_train_sample_per_sec: 2749.4273230159743
avg_episode_per_sec: 8.988320344040599
collect_time: 1.0012994258673864
reward_mean: 1931.6505727048586
reward_std: 887.4354531103918
reward_max: 3575.5619170613945
reward_min: 880.7101062370347
total_envstep_count: 26691472
total_train_sample_count: 20008026
total_episode_count: 58556
total_duration: 5341.562434126182
[2023-06-29 14:59:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3059
train_sample_count: 3059
avg_envstep_per_episode: 235.30769230769232
avg_sample_per_episode: 235.30769230769232
avg_envstep_per_sec: 2620.2994187983686
avg_train_sample_per_sec: 2620.2994187983686
avg_episode_per_sec: 11.135630089695585
collect_time: 1.167423836396076
reward_mean: 1345.0265047008625
reward_std: 592.0353568773037
reward_max: 3210.6018579746687
reward_min: 591.785376086435
total_envstep_count: 26696136
total_train_sample_count: 20011485
total_episode_count: 58569
total_duration: 5342.729857962578
[2023-06-29 14:59:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3040
train_sample_count: 3040
avg_envstep_per_episode: 202.66666666666666
avg_sample_per_episode: 202.66666666666666
avg_envstep_per_sec: 2586.4204005133824
avg_train_sample_per_sec: 2586.4204005133824
avg_episode_per_sec: 12.761942765691032
collect_time: 1.1753696341849862
reward_mean: 1145.7023521244234
reward_std: 563.1231240571001
reward_max: 2932.5481715317624
reward_min: 345.0474280805473
total_envstep_count: 26700912
total_train_sample_count: 20014925
total_episode_count: 58584
total_duration: 5343.905227596762
[2023-06-29 14:59:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3280
train_sample_count: 3280
avg_envstep_per_episode: 234.28571428571428
avg_sample_per_episode: 234.28571428571428
avg_envstep_per_sec: 2536.0010782286604
avg_train_sample_per_sec: 2536.0010782286604
avg_episode_per_sec: 10.82439484609794
collect_time: 1.2933748444188384
reward_mean: 1290.9483229973198
reward_std: 519.0824599019116
reward_max: 2480.0095290150157
reward_min: 496.5321764532854
total_envstep_count: 26704840
total_train_sample_count: 20018205
total_episode_count: 58598
total_duration: 5345.198602441181
[2023-06-29 14:59:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2531
train_sample_count: 2531
avg_envstep_per_episode: 253.1
avg_sample_per_episode: 253.1
avg_envstep_per_sec: 2710.5367844120024
avg_train_sample_per_sec: 2710.5367844120024
avg_episode_per_sec: 10.709351182979068
collect_time: 0.9337633839007468
reward_mean: 1128.1849424281413
reward_std: 233.93792159193745
reward_max: 1389.3364152212785
reward_min: 679.0046992862608
total_envstep_count: 26709336
total_train_sample_count: 20021536
total_episode_count: 58608
total_duration: 5346.132365825081
[2023-06-29 14:59:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3361
train_sample_count: 3361
avg_envstep_per_episode: 280.0833333333333
avg_sample_per_episode: 280.0833333333333
avg_envstep_per_sec: 2731.7378470001863
avg_train_sample_per_sec: 2731.7378470001863
avg_episode_per_sec: 9.753303827432976
collect_time: 1.2303523208461704
reward_mean: 1611.2771263489703
reward_std: 780.1065709866822
reward_max: 3502.549133635634
reward_min: 891.4930426715226
total_envstep_count: 26714136
total_train_sample_count: 20024897
total_episode_count: 58620
total_duration: 5347.362718145928
[2023-06-29 14:59:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2801
train_sample_count: 2801
avg_envstep_per_episode: 280.1
avg_sample_per_episode: 280.1
avg_envstep_per_sec: 2579.316900492587
avg_train_sample_per_sec: 2579.316900492587
avg_episode_per_sec: 9.208557302722554
collect_time: 1.0859464377816765
reward_mean: 1511.2127067980496
reward_std: 348.80795114206614
reward_max: 2137.4025330044105
reward_min: 933.3859406814234
total_envstep_count: 26718480
total_train_sample_count: 20028098
total_episode_count: 58630
total_duration: 5348.44866458371
[2023-06-29 14:59:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 3447
train_sample_count: 3447
avg_envstep_per_episode: 229.8
avg_sample_per_episode: 229.8
avg_envstep_per_sec: 2629.6963194416116
avg_train_sample_per_sec: 2629.6963194416116
avg_episode_per_sec: 11.4434130524004
collect_time: 1.3107977428861193
reward_mean: 1184.2198388922193
reward_std: 259.25216727387533
reward_max: 1650.6526837058461
reward_min: 609.633904071754
total_envstep_count: 26723448
total_train_sample_count: 20031545
total_episode_count: 58645
total_duration: 5349.759462326596
[2023-06-29 14:59:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3490
train_sample_count: 3490
avg_envstep_per_episode: 249.28571428571428
avg_sample_per_episode: 249.28571428571428
avg_envstep_per_sec: 2517.7588862739244
avg_train_sample_per_sec: 2517.7588862739244
avg_episode_per_sec: 10.099892380468464
collect_time: 1.386153383878991
reward_mean: 1283.568278916848
reward_std: 335.29235394056434
reward_max: 2099.533673974293
reward_min: 583.3297037278913
total_envstep_count: 26728096
total_train_sample_count: 20035035
total_episode_count: 58659
total_duration: 5351.145615710475
[2023-06-29 14:59:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3076
train_sample_count: 3076
avg_envstep_per_episode: 279.6363636363636
avg_sample_per_episode: 279.6363636363636
avg_envstep_per_sec: 2696.559891435834
avg_train_sample_per_sec: 2696.559891435834
avg_episode_per_sec: 9.64309454024518
collect_time: 1.1407126575490694
reward_mean: 1371.966908398272
reward_std: 519.7222444080192
reward_max: 2671.5150585852407
reward_min: 603.8833615369828
total_envstep_count: 26732176
total_train_sample_count: 20038511
total_episode_count: 58670
total_duration: 5352.2863283680235
[2023-06-29 14:59:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3060
train_sample_count: 3060
avg_envstep_per_episode: 278.1818181818182
avg_sample_per_episode: 278.1818181818182
avg_envstep_per_sec: 2771.6912730685153
avg_train_sample_per_sec: 2771.6912730685153
avg_episode_per_sec: 9.96359607965806
collect_time: 1.1040190621996298
reward_mean: 1283.8435522943066
reward_std: 291.24477209960213
reward_max: 1761.6985531736188
reward_min: 828.0297118772888
total_envstep_count: 26736704
total_train_sample_count: 20041971
total_episode_count: 58681
total_duration: 5353.390347430223
[2023-06-29 14:59:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2422
train_sample_count: 2422
avg_envstep_per_episode: 269.1111111111111
avg_sample_per_episode: 269.1111111111111
avg_envstep_per_sec: 2563.0449375033863
avg_train_sample_per_sec: 2563.0449375033863
avg_episode_per_sec: 9.524114136057175
collect_time: 0.9449697758164257
reward_mean: 1584.9088935477926
reward_std: 609.3953711118398
reward_max: 2654.1934712195707
reward_min: 918.7732876612146
total_envstep_count: 26741464
total_train_sample_count: 20045193
total_episode_count: 58690
total_duration: 5354.33531720604
[2023-06-29 14:59:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3229
train_sample_count: 3229
avg_envstep_per_episode: 248.3846153846154
avg_sample_per_episode: 248.3846153846154
avg_envstep_per_sec: 2539.9132780633463
avg_train_sample_per_sec: 2539.9132780633463
avg_episode_per_sec: 10.22572704082487
collect_time: 1.2713032479841493
reward_mean: 1590.544980062851
reward_std: 810.6435213100199
reward_max: 3623.596187676637
reward_min: 916.3330172217593
total_envstep_count: 26745968
total_train_sample_count: 20048422
total_episode_count: 58703
total_duration: 5355.606620454024
[2023-06-29 14:59:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3441
train_sample_count: 3441
avg_envstep_per_episode: 312.8181818181818
avg_sample_per_episode: 312.8181818181818
avg_envstep_per_sec: 2774.673161881503
avg_train_sample_per_sec: 2774.673161881503
avg_episode_per_sec: 8.869922923771151
collect_time: 1.2401460637859998
reward_mean: 1530.5437376495681
reward_std: 459.2191077556869
reward_max: 2531.959463193362
reward_min: 1018.8570620356421
total_envstep_count: 26750440
total_train_sample_count: 20051863
total_episode_count: 58714
total_duration: 5356.84676651781
[2023-06-29 14:59:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2494
train_sample_count: 2494
avg_envstep_per_episode: 277.1111111111111
avg_sample_per_episode: 277.1111111111111
avg_envstep_per_sec: 2725.6806878742614
avg_train_sample_per_sec: 2725.6806878742614
avg_episode_per_sec: 9.83605701317897
collect_time: 0.9150007963497194
reward_mean: 1386.7312648137263
reward_std: 501.8038054690902
reward_max: 2369.8532357062213
reward_min: 908.7789919866536
total_envstep_count: 26755144
total_train_sample_count: 20055157
total_episode_count: 58723
total_duration: 5357.761767314159
[2023-06-29 14:59:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 248.2
avg_sample_per_episode: 248.2
avg_envstep_per_sec: 2479.7647637973823
avg_train_sample_per_sec: 2479.7647637973823
avg_episode_per_sec: 9.990994213526923
collect_time: 1.000901390420273
reward_mean: 1713.4656608891778
reward_std: 831.5135409294332
reward_max: 3395.661530534241
reward_min: 117.48732012104182
total_envstep_count: 26759528
total_train_sample_count: 20058439
total_episode_count: 58733
total_duration: 5358.7626687045795
[2023-06-29 14:59:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2499
train_sample_count: 2499
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 2507.594273731492
avg_train_sample_per_sec: 2507.594273731492
avg_episode_per_sec: 12.04126902151977
collect_time: 0.9965727016441526
reward_mean: 1312.4778031948365
reward_std: 590.6878567875415
reward_max: 2516.860649049861
reward_min: 141.60123947819488
total_envstep_count: 26764392
total_train_sample_count: 20061738
total_episode_count: 58745
total_duration: 5359.759241406224
[2023-06-29 14:59:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2678
train_sample_count: 2678
avg_envstep_per_episode: 297.55555555555554
avg_sample_per_episode: 297.55555555555554
avg_envstep_per_sec: 2764.253852085828
avg_train_sample_per_sec: 2764.253852085828
avg_episode_per_sec: 9.28987478296208
collect_time: 0.9687966964319348
reward_mean: 2026.6423434089334
reward_std: 715.8944253560949
reward_max: 3586.7529175897266
reward_min: 1282.9577167535472
total_envstep_count: 26769528
total_train_sample_count: 20065216
total_episode_count: 58754
total_duration: 5360.728038102656
[2023-06-29 15:00:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2426
train_sample_count: 2426
avg_envstep_per_episode: 242.6
avg_sample_per_episode: 242.6
avg_envstep_per_sec: 2728.991980353018
avg_train_sample_per_sec: 2728.991980353018
avg_episode_per_sec: 11.248936440037172
collect_time: 0.8889729312015702
reward_mean: 1631.8976243479678
reward_std: 608.4804559407706
reward_max: 3271.689558686278
reward_min: 960.1118520880623
total_envstep_count: 26773984
total_train_sample_count: 20068442
total_episode_count: 58764
total_duration: 5361.617011033857
[2023-06-29 15:00:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2103
train_sample_count: 2103
avg_envstep_per_episode: 262.875
avg_sample_per_episode: 262.875
avg_envstep_per_sec: 2522.0854694974155
avg_train_sample_per_sec: 2522.0854694974155
avg_episode_per_sec: 9.594238590575047
collect_time: 0.8338337560063228
reward_mean: 1885.977569505113
reward_std: 683.0188283374898
reward_max: 3469.5664894781503
reward_min: 1178.489058597172
total_envstep_count: 26778496
total_train_sample_count: 20071745
total_episode_count: 58772
total_duration: 5362.450844789863
[2023-06-29 15:00:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2164
train_sample_count: 2164
avg_envstep_per_episode: 270.5
avg_sample_per_episode: 270.5
avg_envstep_per_sec: 2532.123857215971
avg_train_sample_per_sec: 2532.123857215971
avg_episode_per_sec: 9.360901505419486
collect_time: 0.8546185423880817
reward_mean: 1918.2739609346672
reward_std: 680.5151147566884
reward_max: 3529.4357237176428
reward_min: 1116.8683397550362
total_envstep_count: 26782696
total_train_sample_count: 20075109
total_episode_count: 58780
total_duration: 5363.305463332252
[2023-06-29 15:00:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3330
train_sample_count: 3330
avg_envstep_per_episode: 256.15384615384613
avg_sample_per_episode: 256.15384615384613
avg_envstep_per_sec: 2518.2438459660084
avg_train_sample_per_sec: 2518.2438459660084
avg_episode_per_sec: 9.830981981248682
collect_time: 1.3223500993894413
reward_mean: 1649.7448990636049
reward_std: 724.9670559201276
reward_max: 3533.7014849495986
reward_min: 1125.1631855230094
total_envstep_count: 26787376
total_train_sample_count: 20078439
total_episode_count: 58793
total_duration: 5364.627813431641
[2023-06-29 15:00:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2883
train_sample_count: 2883
avg_envstep_per_episode: 240.25
avg_sample_per_episode: 240.25
avg_envstep_per_sec: 2732.095927882014
avg_train_sample_per_sec: 2732.095927882014
avg_episode_per_sec: 11.371887316886635
collect_time: 1.0552338117333129
reward_mean: 1250.9079593598444
reward_std: 237.94205076973287
reward_max: 1750.6085168802692
reward_min: 947.9834832507762
total_envstep_count: 26792232
total_train_sample_count: 20081722
total_episode_count: 58805
total_duration: 5365.683047243374
[2023-06-29 15:00:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2128
train_sample_count: 2128
avg_envstep_per_episode: 236.44444444444446
avg_sample_per_episode: 236.44444444444446
avg_envstep_per_sec: 2530.3126507847473
avg_train_sample_per_sec: 2530.3126507847473
avg_episode_per_sec: 10.701510271176092
collect_time: 0.8410027904417366
reward_mean: 1508.7740817277038
reward_std: 863.0213220685415
reward_max: 3518.592857085545
reward_min: 121.13379105071292
total_envstep_count: 26796608
total_train_sample_count: 20085050
total_episode_count: 58814
total_duration: 5366.524050033816
[2023-06-29 15:00:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2061
train_sample_count: 2061
avg_envstep_per_episode: 257.625
avg_sample_per_episode: 257.625
avg_envstep_per_sec: 2467.554522618453
avg_train_sample_per_sec: 2467.554522618453
avg_episode_per_sec: 9.578086453637857
collect_time: 0.8352399029517547
reward_mean: 1632.9833350929666
reward_std: 1004.3690266506943
reward_max: 3150.7625950681804
reward_min: 122.32696037778935
total_envstep_count: 26801168
total_train_sample_count: 20088311
total_episode_count: 58822
total_duration: 5367.359289936768
[2023-06-29 15:00:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2594
train_sample_count: 2594
avg_envstep_per_episode: 235.8181818181818
avg_sample_per_episode: 235.8181818181818
avg_envstep_per_sec: 2465.354042861611
avg_train_sample_per_sec: 2465.354042861611
avg_episode_per_sec: 10.454469726861111
collect_time: 1.0521815345389767
reward_mean: 1965.517681902994
reward_std: 831.1250404916071
reward_max: 3613.4283946403975
reward_min: 1245.877688803605
total_envstep_count: 26805328
total_train_sample_count: 20091705
total_episode_count: 58833
total_duration: 5368.411471471307
[2023-06-29 15:00:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2471
train_sample_count: 2471
avg_envstep_per_episode: 308.875
avg_sample_per_episode: 308.875
avg_envstep_per_sec: 2785.4682541394395
avg_train_sample_per_sec: 2785.4682541394395
avg_episode_per_sec: 9.01810847151579
collect_time: 0.8871039891866966
reward_mean: 1737.031706650822
reward_std: 375.21203831729866
reward_max: 2218.946825138821
reward_min: 1185.3184181718184
total_envstep_count: 26809592
total_train_sample_count: 20094976
total_episode_count: 58841
total_duration: 5369.298575460493
[2023-06-29 15:00:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3436
train_sample_count: 3436
avg_envstep_per_episode: 286.3333333333333
avg_sample_per_episode: 286.3333333333333
avg_envstep_per_sec: 2769.0592051115013
avg_train_sample_per_sec: 2769.0592051115013
avg_episode_per_sec: 9.670753917735162
collect_time: 1.2408546533267941
reward_mean: 1641.6365897419407
reward_std: 607.8973045158334
reward_max: 2883.371181418151
reward_min: 586.6367280080806
total_envstep_count: 26813960
total_train_sample_count: 20098412
total_episode_count: 58853
total_duration: 5370.53943011382
[2023-06-29 15:00:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3397
train_sample_count: 3397
avg_envstep_per_episode: 283.0833333333333
avg_sample_per_episode: 283.0833333333333
avg_envstep_per_sec: 2565.7854786645275
avg_train_sample_per_sec: 2565.7854786645275
avg_episode_per_sec: 9.063710846033068
collect_time: 1.3239610358104112
reward_mean: 1279.7244894850794
reward_std: 367.89480515014856
reward_max: 2133.9275045805657
reward_min: 605.1164474545013
total_envstep_count: 26818696
total_train_sample_count: 20101809
total_episode_count: 58865
total_duration: 5371.863391149631
[2023-06-29 15:00:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2755
train_sample_count: 2755
avg_envstep_per_episode: 306.1111111111111
avg_sample_per_episode: 306.1111111111111
avg_envstep_per_sec: 2487.9303032891876
avg_train_sample_per_sec: 2487.9303032891876
avg_episode_per_sec: 8.127540010745077
collect_time: 1.1073461327906697
reward_mean: 1608.1221932897283
reward_std: 592.3466885248102
reward_max: 2941.5962104363066
reward_min: 942.5788124917304
total_envstep_count: 26823672
total_train_sample_count: 20105364
total_episode_count: 58874
total_duration: 5372.970737282421
[2023-06-29 15:00:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2980
train_sample_count: 2980
avg_envstep_per_episode: 270.90909090909093
avg_sample_per_episode: 270.90909090909093
avg_envstep_per_sec: 2551.328326633258
avg_train_sample_per_sec: 2551.328326633258
avg_episode_per_sec: 9.4176548969684
collect_time: 1.1680190153857692
reward_mean: 1646.4258382536752
reward_std: 432.5986321368924
reward_max: 2281.98768806093
reward_min: 925.1185395350876
total_envstep_count: 26828352
total_train_sample_count: 20108744
total_episode_count: 58885
total_duration: 5374.138756297807
[2023-06-29 15:00:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2013
train_sample_count: 2013
avg_envstep_per_episode: 223.66666666666666
avg_sample_per_episode: 223.66666666666666
avg_envstep_per_sec: 2730.5482170973437
avg_train_sample_per_sec: 2730.5482170973437
avg_episode_per_sec: 12.208114234414353
collect_time: 0.7372145957341418
reward_mean: 1523.4252746172042
reward_std: 508.9293615265319
reward_max: 2815.739106885624
reward_min: 1143.3049977711257
total_envstep_count: 26832904
total_train_sample_count: 20111957
total_episode_count: 58894
total_duration: 5374.875970893541
[2023-06-29 15:00:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3348
train_sample_count: 3348
avg_envstep_per_episode: 239.14285714285714
avg_sample_per_episode: 239.14285714285714
avg_envstep_per_sec: 2590.4103684146485
avg_train_sample_per_sec: 2590.4103684146485
avg_episode_per_sec: 10.832062472462688
collect_time: 1.2924593110121785
reward_mean: 1509.6257185101929
reward_std: 625.59704877734
reward_max: 2839.9441612597707
reward_min: 610.6410530113067
total_envstep_count: 26837520
total_train_sample_count: 20115305
total_episode_count: 58908
total_duration: 5376.168430204553
[2023-06-29 15:00:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 274.0833333333333
avg_sample_per_episode: 274.0833333333333
avg_envstep_per_sec: 2557.352875460543
avg_train_sample_per_sec: 2557.352875460543
avg_episode_per_sec: 9.330566891312412
collect_time: 1.286095490207896
reward_mean: 1354.3583647767175
reward_std: 228.58482097310412
reward_max: 1959.1924811903466
reward_min: 1140.1652590847846
total_envstep_count: 26841504
total_train_sample_count: 20118594
total_episode_count: 58920
total_duration: 5377.454525694761
[2023-06-29 15:00:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3484
train_sample_count: 3484
avg_envstep_per_episode: 348.4
avg_sample_per_episode: 348.4
avg_envstep_per_sec: 2549.206300386971
avg_train_sample_per_sec: 2549.206300386971
avg_episode_per_sec: 7.316895236472363
collect_time: 1.366699901640415
reward_mean: 1490.4702358872648
reward_std: 340.8344362242772
reward_max: 2388.2548865690596
reward_min: 1128.182657127653
total_envstep_count: 26846608
total_train_sample_count: 20122078
total_episode_count: 58930
total_duration: 5378.821225596402
[2023-06-29 15:00:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2848
train_sample_count: 2848
avg_envstep_per_episode: 237.33333333333334
avg_sample_per_episode: 237.33333333333334
avg_envstep_per_sec: 2772.8361012503015
avg_train_sample_per_sec: 2772.8361012503015
avg_episode_per_sec: 11.683298179425428
collect_time: 1.0271072274036703
reward_mean: 1322.3946710294179
reward_std: 263.2536565656144
reward_max: 1652.6924095900004
reward_min: 609.2923614249474
total_envstep_count: 26850880
total_train_sample_count: 20125326
total_episode_count: 58942
total_duration: 5379.848332823805
[2023-06-29 15:00:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2699
train_sample_count: 2699
avg_envstep_per_episode: 269.9
avg_sample_per_episode: 269.9
avg_envstep_per_sec: 2601.4111990331926
avg_train_sample_per_sec: 2601.4111990331926
avg_episode_per_sec: 9.638426080152621
collect_time: 1.0375137928994371
reward_mean: 1429.1657943595978
reward_std: 378.9238605421581
reward_max: 2308.7636910343203
reward_min: 939.2465223456792
total_envstep_count: 26855816
total_train_sample_count: 20128825
total_episode_count: 58952
total_duration: 5380.885846616705
[2023-06-29 15:00:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3120
train_sample_count: 3120
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 2609.0351452924674
avg_train_sample_per_sec: 2609.0351452924674
avg_episode_per_sec: 10.034750558817183
collect_time: 1.1958443739745999
reward_mean: 1635.902388633209
reward_std: 659.5217703232898
reward_max: 3538.6496188116735
reward_min: 1141.3759078812486
total_envstep_count: 26860944
total_train_sample_count: 20132345
total_episode_count: 58964
total_duration: 5382.08169099068
[2023-06-29 15:01:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3039
train_sample_count: 3039
avg_envstep_per_episode: 233.76923076923077
avg_sample_per_episode: 233.76923076923077
avg_envstep_per_sec: 2504.9611366232816
avg_train_sample_per_sec: 2504.9611366232816
avg_episode_per_sec: 10.715529705858065
collect_time: 1.2131924745533615
reward_mean: 1394.4768085689986
reward_std: 309.070525125696
reward_max: 2351.138881246645
reward_min: 1066.48287159954
total_envstep_count: 26865904
total_train_sample_count: 20135784
total_episode_count: 58977
total_duration: 5383.294883465233
[2023-06-29 15:01:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 2801.9913181039005
avg_train_sample_per_sec: 2801.9913181039005
avg_episode_per_sec: 12.343574088563438
collect_time: 0.7291243148399519
reward_mean: 1586.2577998771164
reward_std: 258.89301246676047
reward_max: 2013.2542207898125
reward_min: 1280.173501694458
total_envstep_count: 26870384
total_train_sample_count: 20139027
total_episode_count: 58986
total_duration: 5384.024007780074
[2023-06-29 15:01:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2275
train_sample_count: 2275
avg_envstep_per_episode: 227.5
avg_sample_per_episode: 227.5
avg_envstep_per_sec: 2748.4952773224013
avg_train_sample_per_sec: 2748.4952773224013
avg_episode_per_sec: 12.08129792229627
collect_time: 0.8277256354670971
reward_mean: 1549.389376652825
reward_std: 279.35153105786077
reward_max: 2117.6213922540637
reward_min: 1167.4307390468914
total_envstep_count: 26874672
total_train_sample_count: 20142502
total_episode_count: 58996
total_duration: 5384.85173341554
[2023-06-29 15:01:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3346
train_sample_count: 3346
avg_envstep_per_episode: 278.8333333333333
avg_sample_per_episode: 278.8333333333333
avg_envstep_per_sec: 2447.2304945938317
avg_train_sample_per_sec: 2447.2304945938317
avg_episode_per_sec: 8.776678402607885
collect_time: 1.3672598504275084
reward_mean: 1704.0463383364956
reward_std: 743.2835325650357
reward_max: 3463.9362037108
reward_min: 600.3166502725504
total_envstep_count: 26879192
total_train_sample_count: 20145848
total_episode_count: 59008
total_duration: 5386.218993265968
[2023-06-29 15:01:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2848
train_sample_count: 2848
avg_envstep_per_episode: 258.90909090909093
avg_sample_per_episode: 258.90909090909093
avg_envstep_per_sec: 2539.4918171173467
avg_train_sample_per_sec: 2539.4918171173467
avg_episode_per_sec: 9.808430473416719
collect_time: 1.1214842201117428
reward_mean: 1263.413704630006
reward_std: 415.12078707553167
reward_max: 1897.6457583697454
reward_min: 117.00272280552026
total_envstep_count: 26883784
total_train_sample_count: 20149096
total_episode_count: 59019
total_duration: 5387.340477486079
[2023-06-29 15:01:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2021
train_sample_count: 2021
avg_envstep_per_episode: 252.625
avg_sample_per_episode: 252.625
avg_envstep_per_sec: 2570.430245027365
avg_train_sample_per_sec: 2570.430245027365
avg_episode_per_sec: 10.174884690855476
collect_time: 0.7862496964894234
reward_mean: 1639.9769614174056
reward_std: 710.0528825050353
reward_max: 3360.115424752308
reward_min: 1149.1173562786037
total_envstep_count: 26887816
total_train_sample_count: 20152317
total_episode_count: 59027
total_duration: 5388.126727182568
[2023-06-29 15:01:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2952
train_sample_count: 2952
avg_envstep_per_episode: 295.2
avg_sample_per_episode: 295.2
avg_envstep_per_sec: 2625.692715880583
avg_train_sample_per_sec: 2625.692715880583
avg_episode_per_sec: 8.894623021275688
collect_time: 1.1242747417265782
reward_mean: 1852.249385112998
reward_std: 685.0850717672256
reward_max: 3689.0741817307403
reward_min: 1209.8739962277857
total_envstep_count: 26892224
total_train_sample_count: 20155669
total_episode_count: 59037
total_duration: 5389.2510019242945
[2023-06-29 15:01:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 320.3
avg_sample_per_episode: 320.3
avg_envstep_per_sec: 2590.0781504694296
avg_train_sample_per_sec: 2590.0781504694296
avg_episode_per_sec: 8.086413207834623
collect_time: 1.2366422223281115
reward_mean: 1686.9532624210156
reward_std: 554.4965208386607
reward_max: 2596.404720547847
reward_min: 995.358411940991
total_envstep_count: 26897048
total_train_sample_count: 20158872
total_episode_count: 59047
total_duration: 5390.487644146623
[2023-06-29 15:01:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2633
train_sample_count: 2633
avg_envstep_per_episode: 239.36363636363637
avg_sample_per_episode: 239.36363636363637
avg_envstep_per_sec: 2387.0035361639857
avg_train_sample_per_sec: 2387.0035361639857
avg_episode_per_sec: 9.972289744703321
collect_time: 1.1030565979937093
reward_mean: 1373.6206068618194
reward_std: 328.4644783506308
reward_max: 2159.3720448908307
reward_min: 971.3201924710971
total_envstep_count: 26902000
total_train_sample_count: 20162305
total_episode_count: 59058
total_duration: 5391.590700744617
[2023-06-29 15:01:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3547
train_sample_count: 3547
avg_envstep_per_episode: 253.35714285714286
avg_sample_per_episode: 253.35714285714286
avg_envstep_per_sec: 2515.8017670911636
avg_train_sample_per_sec: 2515.8017670911636
avg_episode_per_sec: 9.929863191225342
collect_time: 1.409888508068398
reward_mean: 1497.6279210521782
reward_std: 603.7822709941219
reward_max: 2799.4494984594817
reward_min: 133.3960901217335
total_envstep_count: 26906736
total_train_sample_count: 20165852
total_episode_count: 59072
total_duration: 5393.000589252685
[2023-06-29 15:01:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3035
train_sample_count: 3035
avg_envstep_per_episode: 275.90909090909093
avg_sample_per_episode: 275.90909090909093
avg_envstep_per_sec: 2437.6822877082936
avg_train_sample_per_sec: 2437.6822877082936
avg_episode_per_sec: 8.835092311298594
collect_time: 1.245035095551051
reward_mean: 1353.9257384523958
reward_std: 289.9412718947231
reward_max: 1829.4321588231085
reward_min: 601.5516056926825
total_envstep_count: 26911448
total_train_sample_count: 20169287
total_episode_count: 59083
total_duration: 5394.245624348237
[2023-06-29 15:01:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2751
train_sample_count: 2751
avg_envstep_per_episode: 250.0909090909091
avg_sample_per_episode: 250.0909090909091
avg_envstep_per_sec: 2408.2201324174807
avg_train_sample_per_sec: 2408.2201324174807
avg_episode_per_sec: 9.629378937329076
collect_time: 1.1423374312706294
reward_mean: 1421.2557402282343
reward_std: 330.7493925954764
reward_max: 2325.3947436054264
reward_min: 1131.0877872315914
total_envstep_count: 26916112
total_train_sample_count: 20172838
total_episode_count: 59094
total_duration: 5395.387961779507
[2023-06-29 15:01:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1348
train_sample_count: 1348
avg_envstep_per_episode: 269.6
avg_sample_per_episode: 269.6
avg_envstep_per_sec: 2537.358625328987
avg_train_sample_per_sec: 2537.358625328987
avg_episode_per_sec: 9.411567601368645
collect_time: 0.5312611258588731
reward_mean: 1872.877418399469
reward_std: 487.71647510967745
reward_max: 2595.4043440344385
reward_min: 1321.1685125710485
total_envstep_count: 26920048
total_train_sample_count: 20176186
total_episode_count: 59099
total_duration: 5395.919222905366
[2023-06-29 15:01:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2796
train_sample_count: 2796
avg_envstep_per_episode: 233.0
avg_sample_per_episode: 233.0
avg_envstep_per_sec: 2640.2164781614356
avg_train_sample_per_sec: 2640.2164781614356
avg_episode_per_sec: 11.331401193825904
collect_time: 1.0590040714945643
reward_mean: 1786.6804453914704
reward_std: 991.0651402292004
reward_max: 3359.8967649047813
reward_min: 117.41617946972971
total_envstep_count: 26924984
total_train_sample_count: 20179782
total_episode_count: 59111
total_duration: 5396.97822697686
[2023-06-29 15:01:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2041
train_sample_count: 2041
avg_envstep_per_episode: 204.1
avg_sample_per_episode: 204.1
avg_envstep_per_sec: 2588.109818810425
avg_train_sample_per_sec: 2588.109818810425
avg_episode_per_sec: 12.680596858453823
collect_time: 0.7886064127441494
reward_mean: 1402.4648866721293
reward_std: 204.12353218750053
reward_max: 1707.5798576255067
reward_min: 1059.3434437832184
total_envstep_count: 26929096
total_train_sample_count: 20183023
total_episode_count: 59121
total_duration: 5397.7668333896045
[2023-06-29 15:01:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3250
train_sample_count: 3250
avg_envstep_per_episode: 325.0
avg_sample_per_episode: 325.0
avg_envstep_per_sec: 2659.6510805469925
avg_train_sample_per_sec: 2659.6510805469925
avg_episode_per_sec: 8.183541786298438
collect_time: 1.2219647997329013
reward_mean: 2008.840724549464
reward_std: 754.1283880843757
reward_max: 3549.429854636612
reward_min: 1090.7965742883382
total_envstep_count: 26933904
total_train_sample_count: 20186273
total_episode_count: 59131
total_duration: 5398.988798189337
[2023-06-29 15:01:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 3395
train_sample_count: 3395
avg_envstep_per_episode: 242.5
avg_sample_per_episode: 242.5
avg_envstep_per_sec: 2556.6219409658233
avg_train_sample_per_sec: 2556.6219409658233
avg_episode_per_sec: 10.542770890580714
collect_time: 1.327924143026583
reward_mean: 1247.4380465450224
reward_std: 361.5021597336812
reward_max: 1657.1055505467107
reward_min: 118.68231444973507
total_envstep_count: 26938224
total_train_sample_count: 20189668
total_episode_count: 59145
total_duration: 5400.3167223323635
[2023-06-29 15:01:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 267.3333333333333
avg_sample_per_episode: 267.3333333333333
avg_envstep_per_sec: 2749.6360657048867
avg_train_sample_per_sec: 2749.6360657048867
avg_episode_per_sec: 10.285421692162917
collect_time: 1.1666998553052543
reward_mean: 1216.363362094369
reward_std: 73.85128344264363
reward_max: 1372.187713060071
reward_min: 1114.3529870529128
total_envstep_count: 26942968
total_train_sample_count: 20192876
total_episode_count: 59157
total_duration: 5401.483422187669
[2023-06-29 15:01:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3046
train_sample_count: 3046
avg_envstep_per_episode: 234.30769230769232
avg_sample_per_episode: 234.30769230769232
avg_envstep_per_sec: 2449.0489388043907
avg_train_sample_per_sec: 2449.0489388043907
avg_episode_per_sec: 10.452277151824385
collect_time: 1.24374811451789
reward_mean: 1237.2293579908865
reward_std: 111.58980219228437
reward_max: 1507.5983560124894
reward_min: 1095.6507375333279
total_envstep_count: 26947512
total_train_sample_count: 20196322
total_episode_count: 59170
total_duration: 5402.727170302187
[2023-06-29 15:01:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2234
train_sample_count: 2234
avg_envstep_per_episode: 223.4
avg_sample_per_episode: 223.4
avg_envstep_per_sec: 2749.9894341374975
avg_train_sample_per_sec: 2749.9894341374975
avg_episode_per_sec: 12.309710985396139
collect_time: 0.8123667575838045
reward_mean: 1316.6180873049382
reward_std: 204.72711840325317
reward_max: 1654.7781464414536
reward_min: 924.4093387454569
total_envstep_count: 26951568
total_train_sample_count: 20199756
total_episode_count: 59180
total_duration: 5403.539537059771
[2023-06-29 15:02:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3504
train_sample_count: 3504
avg_envstep_per_episode: 292.0
avg_sample_per_episode: 292.0
avg_envstep_per_sec: 2769.8491127314865
avg_train_sample_per_sec: 2769.8491127314865
avg_episode_per_sec: 9.485784632642076
collect_time: 1.2650508592305705
reward_mean: 1603.5891071772232
reward_std: 476.4104664359511
reward_max: 2580.3522626192016
reward_min: 1154.9569951447966
total_envstep_count: 26956472
total_train_sample_count: 20203260
total_episode_count: 59192
total_duration: 5404.804587919001
[2023-06-29 15:02:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3238
train_sample_count: 3238
avg_envstep_per_episode: 269.8333333333333
avg_sample_per_episode: 269.8333333333333
avg_envstep_per_sec: 2750.481786163241
avg_train_sample_per_sec: 2750.481786163241
avg_episode_per_sec: 10.193261715243636
collect_time: 1.1772482974762097
reward_mean: 1343.6134303000513
reward_std: 218.64630639263467
reward_max: 1993.4942680734632
reward_min: 1176.085429340553
total_envstep_count: 26960984
total_train_sample_count: 20206498
total_episode_count: 59204
total_duration: 5405.981836216478
[2023-06-29 15:02:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3325
train_sample_count: 3325
avg_envstep_per_episode: 277.0833333333333
avg_sample_per_episode: 277.0833333333333
avg_envstep_per_sec: 2543.407992215474
avg_train_sample_per_sec: 2543.407992215474
avg_episode_per_sec: 9.179216814010733
collect_time: 1.3073010740615423
reward_mean: 1343.848429175205
reward_std: 427.6103551693454
reward_max: 1952.7452914859766
reward_min: 541.9953576319145
total_envstep_count: 26965816
total_train_sample_count: 20209823
total_episode_count: 59216
total_duration: 5407.28913729054
[2023-06-29 15:02:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2463
train_sample_count: 2463
avg_envstep_per_episode: 273.6666666666667
avg_sample_per_episode: 273.6666666666667
avg_envstep_per_sec: 2618.2990817517048
avg_train_sample_per_sec: 2618.2990817517048
avg_episode_per_sec: 9.56747532917797
collect_time: 0.9406870350167156
reward_mean: 1591.9900499000926
reward_std: 522.3830937046076
reward_max: 2557.8628512747555
reward_min: 1193.4822750492835
total_envstep_count: 26970376
total_train_sample_count: 20213086
total_episode_count: 59225
total_duration: 5408.229824325556
[2023-06-29 15:02:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1623
train_sample_count: 1623
avg_envstep_per_episode: 202.875
avg_sample_per_episode: 202.875
avg_envstep_per_sec: 2747.773087121945
avg_train_sample_per_sec: 2747.773087121945
avg_episode_per_sec: 13.54416802031766
collect_time: 0.5906601267792284
reward_mean: 1595.3049391245952
reward_std: 330.60663671243566
reward_max: 2309.9418550761316
reward_min: 1308.838506197812
total_envstep_count: 26974920
total_train_sample_count: 20216309
total_episode_count: 59233
total_duration: 5408.820484452335
[2023-06-29 15:02:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2008
train_sample_count: 2008
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 2758.740339390768
avg_train_sample_per_sec: 2758.740339390768
avg_episode_per_sec: 10.99099736809071
collect_time: 0.7278684301413596
reward_mean: 2097.798961380611
reward_std: 841.5335455605317
reward_max: 3346.951709589016
reward_min: 1218.8381639497889
total_envstep_count: 26978648
total_train_sample_count: 20219517
total_episode_count: 59241
total_duration: 5409.548352882476
[2023-06-29 15:02:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3347
train_sample_count: 3347
avg_envstep_per_episode: 278.9166666666667
avg_sample_per_episode: 278.9166666666667
avg_envstep_per_sec: 2773.256007454274
avg_train_sample_per_sec: 2773.256007454274
avg_episode_per_sec: 9.942955509247472
collect_time: 1.2068846118077636
reward_mean: 1634.3852400088863
reward_std: 670.5677056791667
reward_max: 3568.929128093781
reward_min: 728.0865269437976
total_envstep_count: 26983008
total_train_sample_count: 20222864
total_episode_count: 59253
total_duration: 5410.755237494284
[2023-06-29 15:02:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1536
train_sample_count: 1536
avg_envstep_per_episode: 256.0
avg_sample_per_episode: 256.0
avg_envstep_per_sec: 2415.829742591117
avg_train_sample_per_sec: 2415.829742591117
avg_episode_per_sec: 9.43683493199655
collect_time: 0.6358063951777294
reward_mean: 1099.5699428096914
reward_std: 337.1968543184017
reward_max: 1301.0445376760078
reward_min: 350.5174870065212
total_envstep_count: 26988432
total_train_sample_count: 20226400
total_episode_count: 59259
total_duration: 5411.391043889462
[2023-06-29 15:02:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1721
train_sample_count: 1721
avg_envstep_per_episode: 245.85714285714286
avg_sample_per_episode: 245.85714285714286
avg_envstep_per_sec: 2621.638151007507
avg_train_sample_per_sec: 2621.638151007507
avg_episode_per_sec: 10.663258022691778
collect_time: 0.6564597785314545
reward_mean: 2889.4060186444162
reward_std: 823.5353007412062
reward_max: 3632.9476000711493
reward_min: 1581.3481041561204
total_envstep_count: 26993064
total_train_sample_count: 20229721
total_episode_count: 59266
total_duration: 5412.047503667994
[2023-06-29 15:02:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1771
train_sample_count: 1771
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 2422.1402183628484
avg_train_sample_per_sec: 2422.1402183628484
avg_episode_per_sec: 9.573676752422326
collect_time: 0.7311715426603331
reward_mean: 2347.7651066963967
reward_std: 983.23307705143
reward_max: 3499.809287491191
reward_min: 1368.035647717831
total_envstep_count: 26997344
total_train_sample_count: 20233092
total_episode_count: 59273
total_duration: 5412.778675210654
[2023-06-29 15:02:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2536
train_sample_count: 2536
avg_envstep_per_episode: 230.54545454545453
avg_sample_per_episode: 230.54545454545453
avg_envstep_per_sec: 2746.2598495075317
avg_train_sample_per_sec: 2746.2598495075317
avg_episode_per_sec: 11.912010388242448
collect_time: 0.9234377440484242
reward_mean: 1782.8045097785018
reward_std: 697.6745032582719
reward_max: 3408.8572606050648
reward_min: 1136.3040323164532
total_envstep_count: 27001720
total_train_sample_count: 20236428
total_episode_count: 59284
total_duration: 5413.702112954702
[2023-06-29 15:02:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2289
train_sample_count: 2289
avg_envstep_per_episode: 381.5
avg_sample_per_episode: 381.5
avg_envstep_per_sec: 2668.71022589456
avg_train_sample_per_sec: 2668.71022589456
avg_episode_per_sec: 6.995308586879581
collect_time: 0.8577177011538298
reward_mean: 2196.024342511519
reward_std: 825.8422716726509
reward_max: 3540.8079947879214
reward_min: 1345.1259924327735
total_envstep_count: 27006552
total_train_sample_count: 20239917
total_episode_count: 59290
total_duration: 5414.559830655856
[2023-06-29 15:02:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2107
train_sample_count: 2107
avg_envstep_per_episode: 234.11111111111111
avg_sample_per_episode: 234.11111111111111
avg_envstep_per_sec: 2732.804419841583
avg_train_sample_per_sec: 2732.804419841583
avg_episode_per_sec: 11.673108580244065
collect_time: 0.771002851394005
reward_mean: 1772.957283527651
reward_std: 921.3859730466355
reward_max: 3439.3911920715705
reward_min: 971.6753540008401
total_envstep_count: 27010824
total_train_sample_count: 20243224
total_episode_count: 59299
total_duration: 5415.33083350725
[2023-06-29 15:02:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2183
train_sample_count: 2183
avg_envstep_per_episode: 311.85714285714283
avg_sample_per_episode: 311.85714285714283
avg_envstep_per_sec: 2683.2905365195643
avg_train_sample_per_sec: 2683.2905365195643
avg_episode_per_sec: 8.604229846833235
collect_time: 0.8135533481333408
reward_mean: 2389.7803822154006
reward_std: 891.06341435761
reward_max: 3428.9735132008254
reward_min: 1352.9955560146748
total_envstep_count: 27015704
total_train_sample_count: 20246607
total_episode_count: 59306
total_duration: 5416.144386855383
[2023-06-29 15:02:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2458
train_sample_count: 2458
avg_envstep_per_episode: 307.25
avg_sample_per_episode: 307.25
avg_envstep_per_sec: 2784.8343414384094
avg_train_sample_per_sec: 2784.8343414384094
avg_episode_per_sec: 9.063740736984245
collect_time: 0.8826377797145397
reward_mean: 2171.285212619467
reward_std: 956.1667700786057
reward_max: 3414.990092681775
reward_min: 911.0581577271985
total_envstep_count: 27020120
total_train_sample_count: 20249865
total_episode_count: 59314
total_duration: 5417.027024635098
[2023-06-29 15:02:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2521
train_sample_count: 2521
avg_envstep_per_episode: 229.1818181818182
avg_sample_per_episode: 229.1818181818182
avg_envstep_per_sec: 2633.338133047943
avg_train_sample_per_sec: 2633.338133047943
avg_episode_per_sec: 11.490170354433706
collect_time: 0.9573400272307917
reward_mean: 1609.4516006441283
reward_std: 775.5828828910056
reward_max: 3244.221386364374
reward_min: 916.0315617751146
total_envstep_count: 27024376
total_train_sample_count: 20253186
total_episode_count: 59325
total_duration: 5417.984364662329
[2023-06-29 15:02:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2017
train_sample_count: 2017
avg_envstep_per_episode: 336.1666666666667
avg_sample_per_episode: 336.1666666666667
avg_envstep_per_sec: 2461.3786276188166
avg_train_sample_per_sec: 2461.3786276188166
avg_episode_per_sec: 7.321899735108031
collect_time: 0.8194594595758246
reward_mean: 1939.1135128548492
reward_std: 326.3688384905227
reward_max: 2558.8611213726545
reward_min: 1638.935201144335
total_envstep_count: 27028032
total_train_sample_count: 20256403
total_episode_count: 59331
total_duration: 5418.803824121906
[2023-06-29 15:02:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2742
train_sample_count: 2742
avg_envstep_per_episode: 304.6666666666667
avg_sample_per_episode: 304.6666666666667
avg_envstep_per_sec: 2518.2565893510045
avg_train_sample_per_sec: 2518.2565893510045
avg_episode_per_sec: 8.265612437694763
collect_time: 1.088848535766825
reward_mean: 1903.54945525482
reward_std: 831.984997445368
reward_max: 3407.5109382384626
reward_min: 995.1880173770795
total_envstep_count: 27032760
total_train_sample_count: 20259945
total_episode_count: 59340
total_duration: 5419.892672657672
[2023-06-29 15:02:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2189
train_sample_count: 2189
avg_envstep_per_episode: 273.625
avg_sample_per_episode: 273.625
avg_envstep_per_sec: 2717.1329078680137
avg_train_sample_per_sec: 2717.1329078680137
avg_episode_per_sec: 9.930133971194202
collect_time: 0.8056286071473733
reward_mean: 1776.6948368120225
reward_std: 379.69099299952467
reward_max: 2515.2357003830098
reward_min: 1202.0359355323233
total_envstep_count: 27037416
total_train_sample_count: 20263334
total_episode_count: 59348
total_duration: 5420.69830126482
[2023-06-29 15:02:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3414
train_sample_count: 3414
avg_envstep_per_episode: 310.3636363636364
avg_sample_per_episode: 310.3636363636364
avg_envstep_per_sec: 2597.634260828679
avg_train_sample_per_sec: 2597.634260828679
avg_episode_per_sec: 8.36964758907893
collect_time: 1.3142727794600653
reward_mean: 1959.003273264842
reward_std: 732.1321827987116
reward_max: 3077.92571794422
reward_min: 1028.270141870493
total_envstep_count: 27042392
total_train_sample_count: 20266748
total_episode_count: 59359
total_duration: 5422.01257404428
[2023-06-29 15:03:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2123
train_sample_count: 2123
avg_envstep_per_episode: 235.88888888888889
avg_sample_per_episode: 235.88888888888889
avg_envstep_per_sec: 2525.846441231612
avg_train_sample_per_sec: 2525.846441231612
avg_episode_per_sec: 10.707780485673345
collect_time: 0.8405103197662394
reward_mean: 1302.0925100986997
reward_std: 467.3379546939128
reward_max: 2444.6022926970513
reward_min: 639.7568330424427
total_envstep_count: 27046832
total_train_sample_count: 20270071
total_episode_count: 59368
total_duration: 5422.8530843640465
[2023-06-29 15:03:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2167
train_sample_count: 2167
avg_envstep_per_episode: 216.7
avg_sample_per_episode: 216.7
avg_envstep_per_sec: 2779.707889158551
avg_train_sample_per_sec: 2779.707889158551
avg_episode_per_sec: 12.827447573412787
collect_time: 0.779578317726031
reward_mean: 1735.6250892558987
reward_std: 774.3312698928402
reward_max: 3205.1561794837735
reward_min: 548.8548801993913
total_envstep_count: 27051104
total_train_sample_count: 20273438
total_episode_count: 59378
total_duration: 5423.632662681773
[2023-06-29 15:03:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2200
train_sample_count: 2200
avg_envstep_per_episode: 183.33333333333334
avg_sample_per_episode: 183.33333333333334
avg_envstep_per_sec: 2728.249173692231
avg_train_sample_per_sec: 2728.249173692231
avg_episode_per_sec: 14.881359129230352
collect_time: 0.8063779588807375
reward_mean: 1265.970848729765
reward_std: 393.03210344051905
reward_max: 1901.4397319130233
reward_min: 558.9964935799201
total_envstep_count: 27055480
total_train_sample_count: 20276838
total_episode_count: 59390
total_duration: 5424.439040640654
[2023-06-29 15:03:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2415
train_sample_count: 2415
avg_envstep_per_episode: 219.54545454545453
avg_sample_per_episode: 219.54545454545453
avg_envstep_per_sec: 2559.3357595274283
avg_train_sample_per_sec: 2559.3357595274283
avg_episode_per_sec: 11.65742996058042
collect_time: 0.9436042109793052
reward_mean: 1451.3857085902798
reward_std: 411.02742439871884
reward_max: 2172.986563823432
reward_min: 790.5423105287824
total_envstep_count: 27059456
total_train_sample_count: 20280053
total_episode_count: 59401
total_duration: 5425.382644851633
[2023-06-29 15:03:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2603
train_sample_count: 2603
avg_envstep_per_episode: 325.375
avg_sample_per_episode: 325.375
avg_envstep_per_sec: 2585.9529949101634
avg_train_sample_per_sec: 2585.9529949101634
avg_episode_per_sec: 7.947608128805727
collect_time: 1.0065921558216215
reward_mean: 1887.7083786489302
reward_std: 964.0287829617577
reward_max: 3485.9142762596157
reward_min: 470.77888849508713
total_envstep_count: 27064360
total_train_sample_count: 20283456
total_episode_count: 59409
total_duration: 5426.3892370074545
[2023-06-29 15:03:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2935
train_sample_count: 2935
avg_envstep_per_episode: 266.8181818181818
avg_sample_per_episode: 266.8181818181818
avg_envstep_per_sec: 2571.8938293367055
avg_train_sample_per_sec: 2571.8938293367055
avg_episode_per_sec: 9.639125084396511
collect_time: 1.141182410611771
reward_mean: 1707.4362308108632
reward_std: 556.2903424001618
reward_max: 2908.045160505375
reward_min: 581.6939997876333
total_envstep_count: 27069064
total_train_sample_count: 20286791
total_episode_count: 59420
total_duration: 5427.530419418066
[2023-06-29 15:03:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2361
train_sample_count: 2361
avg_envstep_per_episode: 262.3333333333333
avg_sample_per_episode: 262.3333333333333
avg_envstep_per_sec: 2764.8862985756878
avg_train_sample_per_sec: 2764.8862985756878
avg_episode_per_sec: 10.53959198948801
collect_time: 0.8539229990094902
reward_mean: 1624.6668130344904
reward_std: 973.2653720503117
reward_max: 3503.5089852564925
reward_min: 596.8726498835275
total_envstep_count: 27073880
total_train_sample_count: 20290352
total_episode_count: 59429
total_duration: 5428.3843424170755
[2023-06-29 15:03:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2596
train_sample_count: 2596
avg_envstep_per_episode: 216.33333333333334
avg_sample_per_episode: 216.33333333333334
avg_envstep_per_sec: 2714.9578956446335
avg_train_sample_per_sec: 2714.9578956446335
avg_episode_per_sec: 12.549882414381972
collect_time: 0.9561842576507478
reward_mean: 1492.4465399357312
reward_std: 941.8416173306457
reward_max: 3552.1860136469754
reward_min: 230.78083072875341
total_envstep_count: 27077776
total_train_sample_count: 20293748
total_episode_count: 59441
total_duration: 5429.340526674726
[2023-06-29 15:03:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1898
train_sample_count: 1898
avg_envstep_per_episode: 237.25
avg_sample_per_episode: 237.25
avg_envstep_per_sec: 2757.1671580387306
avg_train_sample_per_sec: 2757.1671580387306
avg_episode_per_sec: 11.621357884251761
collect_time: 0.6883877150742336
reward_mean: 1267.8991952841257
reward_std: 528.3935544155676
reward_max: 2066.7783421405848
reward_min: 309.1493955849902
total_envstep_count: 27082496
total_train_sample_count: 20297246
total_episode_count: 59449
total_duration: 5430.0289143898
[2023-06-29 15:03:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2431
train_sample_count: 2431
avg_envstep_per_episode: 243.1
avg_sample_per_episode: 243.1
avg_envstep_per_sec: 2556.7649967821662
avg_train_sample_per_sec: 2556.7649967821662
avg_episode_per_sec: 10.517338530572465
collect_time: 0.9508108891742305
reward_mean: 1952.15642474013
reward_std: 853.2955047131104
reward_max: 3317.749875027531
reward_min: 929.3027267676666
total_envstep_count: 27087296
total_train_sample_count: 20300477
total_episode_count: 59459
total_duration: 5430.979725278974
[2023-06-29 15:03:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3052
train_sample_count: 3052
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 2557.364277007209
avg_train_sample_per_sec: 2557.364277007209
avg_episode_per_sec: 10.0551675373809
collect_time: 1.1934162166258322
reward_mean: 1548.199262250363
reward_std: 710.3826051296221
reward_max: 3415.632915250639
reward_min: 819.6789736229505
total_envstep_count: 27091856
total_train_sample_count: 20303929
total_episode_count: 59471
total_duration: 5432.1731414956
[2023-06-29 15:03:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2891
train_sample_count: 2891
avg_envstep_per_episode: 222.3846153846154
avg_sample_per_episode: 222.3846153846154
avg_envstep_per_sec: 2543.2963077676095
avg_train_sample_per_sec: 2543.2963077676095
avg_episode_per_sec: 11.436475960214086
collect_time: 1.136713795860298
reward_mean: 1295.4929468653932
reward_std: 751.5135857693823
reward_max: 3553.22162941447
reward_min: 235.5786424686364
total_envstep_count: 27096720
total_train_sample_count: 20307220
total_episode_count: 59484
total_duration: 5433.309855291461
[2023-06-29 15:03:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3116
train_sample_count: 3116
avg_envstep_per_episode: 239.69230769230768
avg_sample_per_episode: 239.69230769230768
avg_envstep_per_sec: 2718.206418170894
avg_train_sample_per_sec: 2718.206418170894
avg_episode_per_sec: 11.34039904885161
collect_time: 1.146344140448607
reward_mean: 1366.1929038144626
reward_std: 754.0058143923268
reward_max: 2783.6986232779436
reward_min: 218.0675338050605
total_envstep_count: 27101048
total_train_sample_count: 20310736
total_episode_count: 59497
total_duration: 5434.456199431909
[2023-06-29 15:03:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2021
train_sample_count: 2021
avg_envstep_per_episode: 224.55555555555554
avg_sample_per_episode: 224.55555555555554
avg_envstep_per_sec: 2547.658453788006
avg_train_sample_per_sec: 2547.658453788006
avg_episode_per_sec: 11.345337003509181
collect_time: 0.7932774493359029
reward_mean: 1233.4147490950913
reward_std: 556.6772640825453
reward_max: 2159.7917793228744
reward_min: 221.04322971787624
total_envstep_count: 27105760
total_train_sample_count: 20313957
total_episode_count: 59506
total_duration: 5435.249476881245
[2023-06-29 15:03:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3260
train_sample_count: 3260
avg_envstep_per_episode: 250.76923076923077
avg_sample_per_episode: 250.76923076923077
avg_envstep_per_sec: 2610.4851485645227
avg_train_sample_per_sec: 2610.4851485645227
avg_episode_per_sec: 10.409910101637667
collect_time: 1.2488100159438327
reward_mean: 1647.8596071082543
reward_std: 727.7622574758302
reward_max: 3147.73141360953
reward_min: 832.7315029512196
total_envstep_count: 27109928
total_train_sample_count: 20317217
total_episode_count: 59519
total_duration: 5436.498286897188
[2023-06-29 15:03:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2696
train_sample_count: 2696
avg_envstep_per_episode: 269.6
avg_sample_per_episode: 269.6
avg_envstep_per_sec: 2532.9576796753186
avg_train_sample_per_sec: 2532.9576796753186
avg_episode_per_sec: 9.395243618973733
collect_time: 1.0643683554735035
reward_mean: 1185.0843030885212
reward_std: 541.3670058652596
reward_max: 2052.404563883683
reward_min: 251.9039149400052
total_envstep_count: 27114696
total_train_sample_count: 20320713
total_episode_count: 59529
total_duration: 5437.562655252662
[2023-06-29 15:03:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2085
train_sample_count: 2085
avg_envstep_per_episode: 260.625
avg_sample_per_episode: 260.625
avg_envstep_per_sec: 2781.419409837196
avg_train_sample_per_sec: 2781.419409837196
avg_episode_per_sec: 10.672112843500031
collect_time: 0.7496172611098737
reward_mean: 1826.9604479785369
reward_std: 777.4388900893092
reward_max: 3545.327542407372
reward_min: 1144.3943100868137
total_envstep_count: 27119408
total_train_sample_count: 20323998
total_episode_count: 59537
total_duration: 5438.312272513772
[2023-06-29 15:03:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2052
train_sample_count: 2052
avg_envstep_per_episode: 256.5
avg_sample_per_episode: 256.5
avg_envstep_per_sec: 2766.835243935114
avg_train_sample_per_sec: 2766.835243935114
avg_episode_per_sec: 10.786882042632023
collect_time: 0.7416415576236322
reward_mean: 1900.8384029960534
reward_std: 1026.3770864832209
reward_max: 3549.0416828973425
reward_min: 231.53137391255373
total_envstep_count: 27123344
total_train_sample_count: 20327250
total_episode_count: 59545
total_duration: 5439.053914071395
[2023-06-29 15:03:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2732
train_sample_count: 2732
avg_envstep_per_episode: 273.2
avg_sample_per_episode: 273.2
avg_envstep_per_sec: 2638.4427591482295
avg_train_sample_per_sec: 2638.4427591482295
avg_episode_per_sec: 9.657550362914456
collect_time: 1.0354592649498955
reward_mean: 1751.5765466704063
reward_std: 1061.9368836717333
reward_max: 3580.3051636524997
reward_min: 250.0707952021552
total_envstep_count: 27127664
total_train_sample_count: 20330782
total_episode_count: 59555
total_duration: 5440.0893733363455
[2023-06-29 15:04:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2232
train_sample_count: 2232
avg_envstep_per_episode: 372.0
avg_sample_per_episode: 372.0
avg_envstep_per_sec: 2700.9852956501436
avg_train_sample_per_sec: 2700.9852956501436
avg_episode_per_sec: 7.260713160349848
collect_time: 0.8263651059465483
reward_mean: 2309.822964449916
reward_std: 861.1964771250612
reward_max: 3502.648374604489
reward_min: 1334.6351225989708
total_envstep_count: 27132656
total_train_sample_count: 20334214
total_episode_count: 59561
total_duration: 5440.915738442292
[2023-06-29 15:04:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2979
train_sample_count: 2979
avg_envstep_per_episode: 372.375
avg_sample_per_episode: 372.375
avg_envstep_per_sec: 2799.57188998173
avg_train_sample_per_sec: 2799.57188998173
avg_episode_per_sec: 7.518152104684068
collect_time: 1.064091267189942
reward_mean: 2495.6964136294882
reward_std: 860.6654680330787
reward_max: 3594.3045005284785
reward_min: 922.5977706442418
total_envstep_count: 27137232
total_train_sample_count: 20337593
total_episode_count: 59569
total_duration: 5441.979829709482
[2023-06-29 15:04:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1723
train_sample_count: 1723
avg_envstep_per_episode: 287.1666666666667
avg_sample_per_episode: 287.1666666666667
avg_envstep_per_sec: 2748.648125775478
avg_train_sample_per_sec: 2748.648125775478
avg_episode_per_sec: 9.571612742108455
collect_time: 0.6268536099046468
reward_mean: 1633.6679710889628
reward_std: 904.802908144748
reward_max: 3379.934500596905
reward_min: 519.6351014367848
total_envstep_count: 27141640
total_train_sample_count: 20340916
total_episode_count: 59575
total_duration: 5442.606683319387
[2023-06-29 15:04:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2945
train_sample_count: 2945
avg_envstep_per_episode: 267.72727272727275
avg_sample_per_episode: 267.72727272727275
avg_envstep_per_sec: 2543.87043856169
avg_train_sample_per_sec: 2543.87043856169
avg_episode_per_sec: 9.501723200060642
collect_time: 1.157684745008126
reward_mean: 1927.8791525198378
reward_std: 1217.671248898105
reward_max: 3575.886453472859
reward_min: 255.45837363950778
total_envstep_count: 27146440
total_train_sample_count: 20344261
total_episode_count: 59586
total_duration: 5443.764368064395
[2023-06-29 15:04:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1713
train_sample_count: 1713
avg_envstep_per_episode: 214.125
avg_sample_per_episode: 214.125
avg_envstep_per_sec: 2746.480094530409
avg_train_sample_per_sec: 2746.480094530409
avg_episode_per_sec: 12.826527003060871
collect_time: 0.6237074149604886
reward_mean: 1263.8175401505823
reward_std: 503.87289455547767
reward_max: 2398.638636658462
reward_min: 579.9026543124298
total_envstep_count: 27150912
total_train_sample_count: 20347574
total_episode_count: 59594
total_duration: 5444.388075479355
[2023-06-29 15:04:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2315
train_sample_count: 2315
avg_envstep_per_episode: 257.22222222222223
avg_sample_per_episode: 257.22222222222223
avg_envstep_per_sec: 2504.342984041818
avg_train_sample_per_sec: 2504.342984041818
avg_episode_per_sec: 9.736106633423915
collect_time: 0.9243941483860837
reward_mean: 2119.3698470510158
reward_std: 1027.4503547069557
reward_max: 3528.999523393583
reward_min: 944.574012450464
total_envstep_count: 27155520
total_train_sample_count: 20351089
total_episode_count: 59603
total_duration: 5445.312469627742
[2023-06-29 15:04:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3159
train_sample_count: 3159
avg_envstep_per_episode: 263.25
avg_sample_per_episode: 263.25
avg_envstep_per_sec: 2786.8181949119203
avg_train_sample_per_sec: 2786.8181949119203
avg_episode_per_sec: 10.586203969276049
collect_time: 1.133550802046433
reward_mean: 1720.4362083260348
reward_std: 765.127660772152
reward_max: 3473.406849065389
reward_min: 1107.9114313313278
total_envstep_count: 27159856
total_train_sample_count: 20354648
total_episode_count: 59615
total_duration: 5446.446020429788
[2023-06-29 15:04:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2735
train_sample_count: 2735
avg_envstep_per_episode: 303.8888888888889
avg_sample_per_episode: 303.8888888888889
avg_envstep_per_sec: 2586.0003949806683
avg_train_sample_per_sec: 2586.0003949806683
avg_episode_per_sec: 8.509690513647538
collect_time: 1.0576177812302483
reward_mean: 1451.3538042880687
reward_std: 879.7411848139661
reward_max: 3510.373830054662
reward_min: 217.0151389413971
total_envstep_count: 27164952
total_train_sample_count: 20358183
total_episode_count: 59624
total_duration: 5447.503638211018
[2023-06-29 15:04:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2187
train_sample_count: 2187
avg_envstep_per_episode: 218.7
avg_sample_per_episode: 218.7
avg_envstep_per_sec: 2465.395706464094
avg_train_sample_per_sec: 2465.395706464094
avg_episode_per_sec: 11.272957048304042
collect_time: 0.8870786925870926
reward_mean: 1553.3205762762627
reward_std: 677.5829895963645
reward_max: 2785.14816183905
reward_min: 622.7410215623905
total_envstep_count: 27169248
total_train_sample_count: 20361570
total_episode_count: 59634
total_duration: 5448.390716903606
[2023-06-29 15:04:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2061
train_sample_count: 2061
avg_envstep_per_episode: 294.42857142857144
avg_sample_per_episode: 294.42857142857144
avg_envstep_per_sec: 2676.0580308406065
avg_train_sample_per_sec: 2676.0580308406065
avg_episode_per_sec: 9.088988945116082
collect_time: 0.77016267070733
reward_mean: 1812.0121323019873
reward_std: 946.261616352825
reward_max: 3492.8623111086486
reward_min: 608.7509580921419
total_envstep_count: 27173864
total_train_sample_count: 20364831
total_episode_count: 59641
total_duration: 5449.160879574313
[2023-06-29 15:04:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2133
train_sample_count: 2133
avg_envstep_per_episode: 213.3
avg_sample_per_episode: 213.3
avg_envstep_per_sec: 2755.5543678278837
avg_train_sample_per_sec: 2755.5543678278837
avg_episode_per_sec: 12.918679642887406
collect_time: 0.7740729142939671
reward_mean: 1760.088049886454
reward_std: 1135.0367400394891
reward_max: 3472.3008770007536
reward_min: 339.9074018588438
total_envstep_count: 27178064
total_train_sample_count: 20368164
total_episode_count: 59651
total_duration: 5449.934952488607
[2023-06-29 15:04:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2930
train_sample_count: 2930
avg_envstep_per_episode: 266.3636363636364
avg_sample_per_episode: 266.3636363636364
avg_envstep_per_sec: 2604.686708845873
avg_train_sample_per_sec: 2604.686708845873
avg_episode_per_sec: 9.778687302834335
collect_time: 1.1248953626742588
reward_mean: 1738.9361971393082
reward_std: 1075.8273676187844
reward_max: 3473.7089044334207
reward_min: 624.0671197818841
total_envstep_count: 27182792
total_train_sample_count: 20371494
total_episode_count: 59662
total_duration: 5451.059847851282
[2023-06-29 15:04:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1685
train_sample_count: 1685
avg_envstep_per_episode: 240.71428571428572
avg_sample_per_episode: 240.71428571428572
avg_envstep_per_sec: 2589.7474418220922
avg_train_sample_per_sec: 2589.7474418220922
avg_episode_per_sec: 10.758594713800976
collect_time: 0.6506425965670495
reward_mean: 1388.6744817219635
reward_std: 368.3009802983729
reward_max: 1924.4350356288119
reward_min: 987.9422728498644
total_envstep_count: 27187168
total_train_sample_count: 20374779
total_episode_count: 59669
total_duration: 5451.710490447849
[2023-06-29 15:04:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1978
train_sample_count: 1978
avg_envstep_per_episode: 219.77777777777777
avg_sample_per_episode: 219.77777777777777
avg_envstep_per_sec: 2740.7411691446246
avg_train_sample_per_sec: 2740.7411691446246
avg_episode_per_sec: 12.470510880840052
collect_time: 0.7217025898937135
reward_mean: 1909.7588345703089
reward_std: 1152.340499710413
reward_max: 3520.902180673026
reward_min: 306.8958664850846
total_envstep_count: 27191368
total_train_sample_count: 20378357
total_episode_count: 59678
total_duration: 5452.432193037743
[2023-06-29 15:04:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2914
train_sample_count: 2914
avg_envstep_per_episode: 264.90909090909093
avg_sample_per_episode: 264.90909090909093
avg_envstep_per_sec: 2568.716579421494
avg_train_sample_per_sec: 2568.716579421494
avg_episode_per_sec: 9.6965965592438
collect_time: 1.134418652234599
reward_mean: 1781.3893427239161
reward_std: 996.1537650049622
reward_max: 3454.2960169819576
reward_min: 587.2464028931737
total_envstep_count: 27195632
total_train_sample_count: 20381671
total_episode_count: 59689
total_duration: 5453.566611689977
[2023-06-29 15:04:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2620
train_sample_count: 2620
avg_envstep_per_episode: 291.1111111111111
avg_sample_per_episode: 291.1111111111111
avg_envstep_per_sec: 2798.185473047041
avg_train_sample_per_sec: 2798.185473047041
avg_episode_per_sec: 9.612087502833347
collect_time: 0.9363210642170161
reward_mean: 1477.5289213042515
reward_std: 513.5720140515538
reward_max: 2579.591656011968
reward_min: 962.6168648974975
total_envstep_count: 27200656
total_train_sample_count: 20385091
total_episode_count: 59698
total_duration: 5454.502932754194
[2023-06-29 15:04:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2354
train_sample_count: 2354
avg_envstep_per_episode: 336.2857142857143
avg_sample_per_episode: 336.2857142857143
avg_envstep_per_sec: 2565.402177003748
avg_train_sample_per_sec: 2565.402177003748
avg_episode_per_sec: 7.628638589221001
collect_time: 0.9175949179045858
reward_mean: 2262.6855901411973
reward_std: 720.923585529921
reward_max: 3222.4570737120735
reward_min: 1275.9079932017098
total_envstep_count: 27205280
total_train_sample_count: 20388645
total_episode_count: 59705
total_duration: 5455.420527672099
[2023-06-29 15:04:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2858
train_sample_count: 2858
avg_envstep_per_episode: 219.84615384615384
avg_sample_per_episode: 219.84615384615384
avg_envstep_per_sec: 2563.4698812826296
avg_train_sample_per_sec: 2563.4698812826296
avg_episode_per_sec: 11.660289872874102
collect_time: 1.1148950962396338
reward_mean: 1551.8147106516362
reward_std: 1084.637887259041
reward_max: 3501.6931937869736
reward_min: 323.79423232937495
total_envstep_count: 27210016
total_train_sample_count: 20391903
total_episode_count: 59718
total_duration: 5456.535422768338
[2023-06-29 15:04:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1797
train_sample_count: 1797
avg_envstep_per_episode: 224.625
avg_sample_per_episode: 224.625
avg_envstep_per_sec: 2697.0137523095555
avg_train_sample_per_sec: 2697.0137523095555
avg_episode_per_sec: 12.006739019742039
collect_time: 0.6662924868147819
reward_mean: 1413.4727306406282
reward_std: 432.4024577006107
reward_max: 2465.9727336786514
reward_min: 907.700539124213
total_envstep_count: 27214448
total_train_sample_count: 20395300
total_episode_count: 59726
total_duration: 5457.201715255153
[2023-06-29 15:04:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2726
train_sample_count: 2726
avg_envstep_per_episode: 272.6
avg_sample_per_episode: 272.6
avg_envstep_per_sec: 2690.8179900996006
avg_train_sample_per_sec: 2690.8179900996006
avg_episode_per_sec: 9.870939068597215
collect_time: 1.0130748382201418
reward_mean: 2046.712134707223
reward_std: 923.7432624245619
reward_max: 3568.8171922703227
reward_min: 1000.5374313422744
total_envstep_count: 27219392
total_train_sample_count: 20398826
total_episode_count: 59736
total_duration: 5458.214790093373
[2023-06-29 15:05:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2262
train_sample_count: 2262
avg_envstep_per_episode: 205.63636363636363
avg_sample_per_episode: 205.63636363636363
avg_envstep_per_sec: 2705.7780496736455
avg_train_sample_per_sec: 2705.7780496736455
avg_episode_per_sec: 13.158071859597746
collect_time: 0.835988746480085
reward_mean: 1529.1524900332713
reward_std: 725.9539324541171
reward_max: 3540.0584360910625
reward_min: 929.6222387817438
total_envstep_count: 27223896
total_train_sample_count: 20402288
total_episode_count: 59747
total_duration: 5459.050778839854
[2023-06-29 15:05:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 246.3846153846154
avg_sample_per_episode: 246.3846153846154
avg_envstep_per_sec: 2595.794908988399
avg_train_sample_per_sec: 2595.794908988399
avg_episode_per_sec: 10.535539749250448
collect_time: 1.2339187463959675
reward_mean: 1483.6672396543881
reward_std: 533.0184268035614
reward_max: 2577.8171196790045
reward_min: 885.5642716977775
total_envstep_count: 27228216
total_train_sample_count: 20405491
total_episode_count: 59760
total_duration: 5460.284697586249
[2023-06-29 15:05:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2865
train_sample_count: 2865
avg_envstep_per_episode: 286.5
avg_sample_per_episode: 286.5
avg_envstep_per_sec: 2597.435327022584
avg_train_sample_per_sec: 2597.435327022584
avg_episode_per_sec: 9.066091891876383
collect_time: 1.1030111010633412
reward_mean: 1366.3459301594817
reward_std: 583.5118122272271
reward_max: 2709.4550630148506
reward_min: 350.2616718002647
total_envstep_count: 27232144
total_train_sample_count: 20408756
total_episode_count: 59770
total_duration: 5461.387708687313
[2023-06-29 15:05:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3324
train_sample_count: 3324
avg_envstep_per_episode: 332.4
avg_sample_per_episode: 332.4
avg_envstep_per_sec: 2623.318959995032
avg_train_sample_per_sec: 2623.318959995032
avg_episode_per_sec: 7.892054632957376
collect_time: 1.267097158481367
reward_mean: 1617.0356723739242
reward_std: 689.5464517429982
reward_max: 3044.0593135195577
reward_min: 1150.7515954701566
total_envstep_count: 27236664
total_train_sample_count: 20412080
total_episode_count: 59780
total_duration: 5462.654805845794
[2023-06-29 15:05:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3433
train_sample_count: 3433
avg_envstep_per_episode: 264.0769230769231
avg_sample_per_episode: 264.0769230769231
avg_envstep_per_sec: 2698.5647098241207
avg_train_sample_per_sec: 2698.5647098241207
avg_episode_per_sec: 10.21885849918834
collect_time: 1.272157746487297
reward_mean: 1255.5084718969283
reward_std: 346.03542198619596
reward_max: 2299.948618985105
reward_min: 702.3079950147717
total_envstep_count: 27241288
total_train_sample_count: 20415513
total_episode_count: 59793
total_duration: 5463.926963592281
[2023-06-29 15:05:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2983
train_sample_count: 2983
avg_envstep_per_episode: 298.3
avg_sample_per_episode: 298.3
avg_envstep_per_sec: 2738.559580414368
avg_train_sample_per_sec: 2738.559580414368
avg_episode_per_sec: 9.18055508016885
collect_time: 1.0892587553448978
reward_mean: 1497.9182016723094
reward_std: 442.2633192297549
reward_max: 2329.520617558397
reward_min: 933.9094044090366
total_envstep_count: 27245680
total_train_sample_count: 20418896
total_episode_count: 59803
total_duration: 5465.016222347626
[2023-06-29 15:05:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3186
train_sample_count: 3186
avg_envstep_per_episode: 245.07692307692307
avg_sample_per_episode: 245.07692307692307
avg_envstep_per_sec: 2612.6435649327636
avg_train_sample_per_sec: 2612.6435649327636
avg_episode_per_sec: 10.660504188363442
collect_time: 1.2194545183135197
reward_mean: 1252.6793480722424
reward_std: 366.93995078851185
reward_max: 1904.6351128545316
reward_min: 287.635552613945
total_envstep_count: 27250688
total_train_sample_count: 20422482
total_episode_count: 59816
total_duration: 5466.23567686594
[2023-06-29 15:05:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2336
train_sample_count: 2336
avg_envstep_per_episode: 233.6
avg_sample_per_episode: 233.6
avg_envstep_per_sec: 2621.438594726781
avg_train_sample_per_sec: 2621.438594726781
avg_episode_per_sec: 11.221911792494781
collect_time: 0.8911137589486315
reward_mean: 1405.4013801510994
reward_std: 293.9900328682492
reward_max: 1953.9245280691896
reward_min: 900.8139483590176
total_envstep_count: 27255040
total_train_sample_count: 20426018
total_episode_count: 59826
total_duration: 5467.126790624889
[2023-06-29 15:05:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2439
train_sample_count: 2439
avg_envstep_per_episode: 221.72727272727272
avg_sample_per_episode: 221.72727272727272
avg_envstep_per_sec: 2494.476196997171
avg_train_sample_per_sec: 2494.476196997171
avg_episode_per_sec: 11.250200150458747
collect_time: 0.9777603822943057
reward_mean: 1506.8147193626937
reward_std: 823.3700009918869
reward_max: 3678.0864637853597
reward_min: 230.5831281246648
total_envstep_count: 27259744
total_train_sample_count: 20429257
total_episode_count: 59837
total_duration: 5468.104551007183
[2023-06-29 15:05:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 327.6
avg_sample_per_episode: 327.6
avg_envstep_per_sec: 2717.8005591681754
avg_train_sample_per_sec: 2717.8005591681754
avg_episode_per_sec: 8.29609450295536
collect_time: 1.20538646183908
reward_mean: 1988.028706565871
reward_std: 1007.7731942618426
reward_max: 3586.6403469059896
reward_min: 1174.4047785061089
total_envstep_count: 27264080
total_train_sample_count: 20432533
total_episode_count: 59847
total_duration: 5469.309937469022
[2023-06-29 15:05:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3253
train_sample_count: 3253
avg_envstep_per_episode: 250.23076923076923
avg_sample_per_episode: 250.23076923076923
avg_envstep_per_sec: 2526.6620272089817
avg_train_sample_per_sec: 2526.6620272089817
avg_episode_per_sec: 10.097327498837
collect_time: 1.28746938251704
reward_mean: 1140.09306811968
reward_std: 213.99129194761247
reward_max: 1501.6983278458881
reward_min: 657.6379972441779
total_envstep_count: 27268472
total_train_sample_count: 20435786
total_episode_count: 59860
total_duration: 5470.597406851539
[2023-06-29 15:05:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3045
train_sample_count: 3045
avg_envstep_per_episode: 234.23076923076923
avg_sample_per_episode: 234.23076923076923
avg_envstep_per_sec: 2633.1806527351396
avg_train_sample_per_sec: 2633.1806527351396
avg_episode_per_sec: 11.241822162744437
collect_time: 1.1563961617434395
reward_mean: 994.8110346614656
reward_std: 401.0096338333986
reward_max: 1435.5525511012847
reward_min: 243.41217554092873
total_envstep_count: 27272880
total_train_sample_count: 20439231
total_episode_count: 59873
total_duration: 5471.753803013282
[2023-06-29 15:05:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2042
train_sample_count: 2042
avg_envstep_per_episode: 185.63636363636363
avg_sample_per_episode: 185.63636363636363
avg_envstep_per_sec: 2704.826553184789
avg_train_sample_per_sec: 2704.826553184789
avg_episode_per_sec: 14.570564194433242
collect_time: 0.7549467442175373
reward_mean: 1159.9695837073489
reward_std: 856.1075839973911
reward_max: 3485.062283065879
reward_min: 119.75260535951446
total_envstep_count: 27278088
total_train_sample_count: 20442473
total_episode_count: 59884
total_duration: 5472.5087497575
[2023-06-29 15:05:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2614
train_sample_count: 2614
avg_envstep_per_episode: 201.07692307692307
avg_sample_per_episode: 201.07692307692307
avg_envstep_per_sec: 2742.002756187485
avg_train_sample_per_sec: 2742.002756187485
avg_episode_per_sec: 13.636586010113735
collect_time: 0.9533177871908993
reward_mean: 1480.1500663870434
reward_std: 544.1134329552555
reward_max: 2443.3982329671862
reward_min: 475.8322394158393
total_envstep_count: 27282416
total_train_sample_count: 20445887
total_episode_count: 59897
total_duration: 5473.46206754469
[2023-06-29 15:05:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3170
train_sample_count: 3170
avg_envstep_per_episode: 317.0
avg_sample_per_episode: 317.0
avg_envstep_per_sec: 2646.808252211799
avg_train_sample_per_sec: 2646.808252211799
avg_episode_per_sec: 8.349552846094001
collect_time: 1.1976689272262158
reward_mean: 1805.789673048912
reward_std: 995.7824845999612
reward_max: 3513.8030458464937
reward_min: 224.7863325193258
total_envstep_count: 27287064
total_train_sample_count: 20449457
total_episode_count: 59907
total_duration: 5474.659736471916
[2023-06-29 15:05:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2577
train_sample_count: 2577
avg_envstep_per_episode: 286.3333333333333
avg_sample_per_episode: 286.3333333333333
avg_envstep_per_sec: 2705.4223438775566
avg_train_sample_per_sec: 2705.4223438775566
avg_episode_per_sec: 9.44850643961894
collect_time: 0.9525314987627792
reward_mean: 1372.443018904396
reward_std: 858.9589387444233
reward_max: 3396.3496030756237
reward_min: 256.3309372360673
total_envstep_count: 27291536
total_train_sample_count: 20452834
total_episode_count: 59916
total_duration: 5475.61226797068
[2023-06-29 15:05:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2912
train_sample_count: 2912
avg_envstep_per_episode: 242.66666666666666
avg_sample_per_episode: 242.66666666666666
avg_envstep_per_sec: 2430.9335295338383
avg_train_sample_per_sec: 2430.9335295338383
avg_episode_per_sec: 10.017583226100982
collect_time: 1.19789371639397
reward_mean: 1517.172078166778
reward_std: 805.254275738672
reward_max: 3412.4842471801517
reward_min: 593.3164245776854
total_envstep_count: 27296288
total_train_sample_count: 20456146
total_episode_count: 59928
total_duration: 5476.810161687074
[2023-06-29 15:05:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2580
train_sample_count: 2580
avg_envstep_per_episode: 286.6666666666667
avg_sample_per_episode: 286.6666666666667
avg_envstep_per_sec: 2665.578939625413
avg_train_sample_per_sec: 2665.578939625413
avg_episode_per_sec: 9.298531184739813
collect_time: 0.9678948020059615
reward_mean: 1533.8472951326094
reward_std: 674.5186048775812
reward_max: 3433.8091816434153
reward_min: 1137.6686437184778
total_envstep_count: 27300512
total_train_sample_count: 20459526
total_episode_count: 59937
total_duration: 5477.77805648908
[2023-06-29 15:05:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2991
train_sample_count: 2991
avg_envstep_per_episode: 299.1
avg_sample_per_episode: 299.1
avg_envstep_per_sec: 2619.4491535202355
avg_train_sample_per_sec: 2619.4491535202355
avg_episode_per_sec: 8.757770489870396
collect_time: 1.1418431222382932
reward_mean: 1796.976200344227
reward_std: 868.8303437941659
reward_max: 3505.997425880021
reward_min: 1176.6443609834944
total_envstep_count: 27305136
total_train_sample_count: 20462917
total_episode_count: 59947
total_duration: 5478.919899611318
[2023-06-29 15:05:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3061
train_sample_count: 3061
avg_envstep_per_episode: 255.08333333333334
avg_sample_per_episode: 255.08333333333334
avg_envstep_per_sec: 2623.659734983213
avg_train_sample_per_sec: 2623.659734983213
avg_episode_per_sec: 10.285500431165813
collect_time: 1.1666909238211811
reward_mean: 1413.12858382744
reward_std: 407.1064014452354
reward_max: 2536.792367648581
reward_min: 743.9459898109662
total_envstep_count: 27310152
total_train_sample_count: 20466378
total_episode_count: 59959
total_duration: 5480.086590535139
[2023-06-29 15:06:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2707
train_sample_count: 2707
avg_envstep_per_episode: 246.0909090909091
avg_sample_per_episode: 246.0909090909091
avg_envstep_per_sec: 2555.156252906798
avg_train_sample_per_sec: 2555.156252906798
avg_episode_per_sec: 10.382977015875426
collect_time: 1.0594264037357644
reward_mean: 1503.550508026984
reward_std: 653.0127636944774
reward_max: 3524.315249029227
reward_min: 1042.0529174753594
total_envstep_count: 27314984
total_train_sample_count: 20469885
total_episode_count: 59970
total_duration: 5481.146016938875
[2023-06-29 15:06:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3088
train_sample_count: 3088
avg_envstep_per_episode: 257.3333333333333
avg_sample_per_episode: 257.3333333333333
avg_envstep_per_sec: 2541.0787741180716
avg_train_sample_per_sec: 2541.0787741180716
avg_episode_per_sec: 9.874658448645357
collect_time: 1.2152319052256644
reward_mean: 1440.9552001484362
reward_std: 335.6453299031222
reward_max: 2421.1243825131264
reward_min: 1167.2202305795554
total_envstep_count: 27319496
total_train_sample_count: 20473373
total_episode_count: 59982
total_duration: 5482.3612488441
[2023-06-29 15:06:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 247.30769230769232
avg_sample_per_episode: 247.30769230769232
avg_envstep_per_sec: 2796.6921715574563
avg_train_sample_per_sec: 2796.6921715574563
avg_episode_per_sec: 11.308553104275873
collect_time: 1.1495723529020325
reward_mean: 1360.829114735829
reward_std: 700.917665761746
reward_max: 3487.0539433359936
reward_min: 282.7772050570213
total_envstep_count: 27324824
total_train_sample_count: 20476588
total_episode_count: 59995
total_duration: 5483.510821197003
[2023-06-29 15:06:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2035
train_sample_count: 2035
avg_envstep_per_episode: 226.11111111111111
avg_sample_per_episode: 226.11111111111111
avg_envstep_per_sec: 2649.8088083996645
avg_train_sample_per_sec: 2649.8088083996645
avg_episode_per_sec: 11.71905615508451
collect_time: 0.7679799363445492
reward_mean: 1583.57207307148
reward_std: 504.2644824619591
reward_max: 2492.7050594897178
reward_min: 659.8499990358932
total_envstep_count: 27329112
total_train_sample_count: 20479823
total_episode_count: 60004
total_duration: 5484.278801133348
[2023-06-29 15:06:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2942
train_sample_count: 2942
avg_envstep_per_episode: 245.16666666666666
avg_sample_per_episode: 245.16666666666666
avg_envstep_per_sec: 2683.2768196171755
avg_train_sample_per_sec: 2683.2768196171755
avg_episode_per_sec: 10.944704906664212
collect_time: 1.0964206072557718
reward_mean: 1586.8421976424952
reward_std: 668.1648108690546
reward_max: 2698.023277135657
reward_min: 616.4780098722683
total_envstep_count: 27333784
total_train_sample_count: 20483165
total_episode_count: 60016
total_duration: 5485.375221740604
[2023-06-29 15:06:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2712
train_sample_count: 2712
avg_envstep_per_episode: 271.2
avg_sample_per_episode: 271.2
avg_envstep_per_sec: 2528.4983248357103
avg_train_sample_per_sec: 2528.4983248357103
avg_episode_per_sec: 9.323371404261469
collect_time: 1.0725733821382748
reward_mean: 1505.1361524563686
reward_std: 425.74263820273484
reward_max: 2286.831266710352
reward_min: 935.2492779212203
total_envstep_count: 27338336
total_train_sample_count: 20486677
total_episode_count: 60026
total_duration: 5486.447795122742
[2023-06-29 15:06:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2574
train_sample_count: 2574
avg_envstep_per_episode: 257.4
avg_sample_per_episode: 257.4
avg_envstep_per_sec: 2731.4287102505923
avg_train_sample_per_sec: 2731.4287102505923
avg_episode_per_sec: 10.611611150934703
collect_time: 0.9423639688417315
reward_mean: 1630.216994502432
reward_std: 663.1019207163758
reward_max: 3145.2497629236127
reward_min: 853.8905998748054
total_envstep_count: 27342816
total_train_sample_count: 20490051
total_episode_count: 60036
total_duration: 5487.390159091584
[2023-06-29 15:06:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2810
train_sample_count: 2810
avg_envstep_per_episode: 312.22222222222223
avg_sample_per_episode: 312.22222222222223
avg_envstep_per_sec: 2612.3002469124845
avg_train_sample_per_sec: 2612.3002469124845
avg_episode_per_sec: 8.366797943847814
collect_time: 1.0756803331933915
reward_mean: 1830.292287224871
reward_std: 962.7040529978731
reward_max: 3471.2363007092827
reward_min: 311.57284794762444
total_envstep_count: 27347560
total_train_sample_count: 20493261
total_episode_count: 60045
total_duration: 5488.465839424777
[2023-06-29 15:06:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 230.71428571428572
avg_sample_per_episode: 230.71428571428572
avg_envstep_per_sec: 2797.85675482499
avg_train_sample_per_sec: 2797.85675482499
avg_episode_per_sec: 12.126933302647014
collect_time: 0.5772275500576943
reward_mean: 1687.6226244845104
reward_std: 786.6131336615931
reward_max: 3504.1032489217455
reward_min: 927.2957632138713
total_envstep_count: 27352056
total_train_sample_count: 20496476
total_episode_count: 60052
total_duration: 5489.043066974835
[2023-06-29 15:06:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2546
train_sample_count: 2546
avg_envstep_per_episode: 231.45454545454547
avg_sample_per_episode: 231.45454545454547
avg_envstep_per_sec: 2484.667657638689
avg_train_sample_per_sec: 2484.667657638689
avg_episode_per_sec: 10.73501344620015
collect_time: 1.0246843243492767
reward_mean: 1896.3363936026456
reward_std: 899.6211554973333
reward_max: 3526.974064119752
reward_min: 694.5186878278336
total_envstep_count: 27356864
total_train_sample_count: 20499822
total_episode_count: 60063
total_duration: 5490.067751299184
[2023-06-29 15:06:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2831
train_sample_count: 2831
avg_envstep_per_episode: 235.91666666666666
avg_sample_per_episode: 235.91666666666666
avg_envstep_per_sec: 2704.008684733727
avg_train_sample_per_sec: 2704.008684733727
avg_episode_per_sec: 11.461711132746283
collect_time: 1.046964092971757
reward_mean: 1486.4793524335057
reward_std: 809.0070476778812
reward_max: 3177.019992479934
reward_min: 121.85882244853266
total_envstep_count: 27361424
total_train_sample_count: 20503053
total_episode_count: 60075
total_duration: 5491.114715392156
[2023-06-29 15:06:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 195.14285714285714
avg_sample_per_episode: 195.14285714285714
avg_envstep_per_sec: 2416.9176150104895
avg_train_sample_per_sec: 2416.9176150104895
avg_episode_per_sec: 12.38537577238172
collect_time: 0.5651826903475448
reward_mean: 1518.8549828255095
reward_std: 380.16804299320614
reward_max: 2017.1439829868148
reward_min: 915.5796181705591
total_envstep_count: 27365752
total_train_sample_count: 20506419
total_episode_count: 60082
total_duration: 5491.679898082503
[2023-06-29 15:06:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1685
train_sample_count: 1685
avg_envstep_per_episode: 240.71428571428572
avg_sample_per_episode: 240.71428571428572
avg_envstep_per_sec: 2440.9561798722925
avg_train_sample_per_sec: 2440.9561798722925
avg_episode_per_sec: 10.140470776917535
collect_time: 0.6903032565247267
reward_mean: 2201.8434576173217
reward_std: 1027.4310067193676
reward_max: 3487.6274597718857
reward_min: 734.828380298898
total_envstep_count: 27370264
total_train_sample_count: 20509704
total_episode_count: 60089
total_duration: 5492.370201339028
[2023-06-29 15:06:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2164
train_sample_count: 2164
avg_envstep_per_episode: 309.14285714285717
avg_sample_per_episode: 309.14285714285717
avg_envstep_per_sec: 2533.9027929606
avg_train_sample_per_sec: 2533.9027929606
avg_episode_per_sec: 8.196543230464048
collect_time: 0.8540185543075205
reward_mean: 2396.016590853007
reward_std: 983.7765370929807
reward_max: 3492.4482955170984
reward_min: 1020.67683213689
total_envstep_count: 27374824
total_train_sample_count: 20513068
total_episode_count: 60096
total_duration: 5493.224219893336
[2023-06-29 15:06:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1596
train_sample_count: 1596
avg_envstep_per_episode: 177.33333333333334
avg_sample_per_episode: 177.33333333333334
avg_envstep_per_sec: 2743.5985917243424
avg_train_sample_per_sec: 2743.5985917243424
avg_episode_per_sec: 15.471420630024488
collect_time: 0.5817177501162513
reward_mean: 1479.8393599757649
reward_std: 1150.869459817747
reward_max: 3469.373345662734
reward_min: 295.5894824275346
total_envstep_count: 27379520
total_train_sample_count: 20516664
total_episode_count: 60105
total_duration: 5493.805937643453
[2023-06-29 15:06:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1746
train_sample_count: 1746
avg_envstep_per_episode: 249.42857142857142
avg_sample_per_episode: 249.42857142857142
avg_envstep_per_sec: 2795.263153711657
avg_train_sample_per_sec: 2795.263153711657
avg_episode_per_sec: 11.206667855659566
collect_time: 0.6246281312303618
reward_mean: 2659.9477033593153
reward_std: 1005.4372929685155
reward_max: 3482.6950116119624
reward_min: 633.7727880920187
total_envstep_count: 27383768
total_train_sample_count: 20520010
total_episode_count: 60112
total_duration: 5494.430565774684
[2023-06-29 15:06:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1556
train_sample_count: 1556
avg_envstep_per_episode: 259.3333333333333
avg_sample_per_episode: 259.3333333333333
avg_envstep_per_sec: 2389.5478985026584
avg_train_sample_per_sec: 2389.5478985026584
avg_episode_per_sec: 9.214194981372719
collect_time: 0.6511692027496175
reward_mean: 2137.032641150004
reward_std: 1316.3655234302987
reward_max: 3444.8711331732566
reward_min: 452.1179195262484
total_envstep_count: 27388520
total_train_sample_count: 20523566
total_episode_count: 60118
total_duration: 5495.081734977433
[2023-06-29 15:06:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 201.75
avg_sample_per_episode: 201.75
avg_envstep_per_sec: 2723.419999594064
avg_train_sample_per_sec: 2723.419999594064
avg_episode_per_sec: 13.498983888942076
collect_time: 0.2963185994522646
reward_mean: 3033.2363572575086
reward_std: 494.18240200485934
reward_max: 3506.0409679551008
reward_min: 2223.9217226907886
total_envstep_count: 27392736
total_train_sample_count: 20526773
total_episode_count: 60122
total_duration: 5495.378053576886
[2023-06-29 15:06:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1601
train_sample_count: 1601
avg_envstep_per_episode: 266.8333333333333
avg_sample_per_episode: 266.8333333333333
avg_envstep_per_sec: 2718.055208344879
avg_train_sample_per_sec: 2718.055208344879
avg_episode_per_sec: 10.186340568438021
collect_time: 0.5890240915948526
reward_mean: 2668.6673188645677
reward_std: 995.5715944679471
reward_max: 3393.2450733203887
reward_min: 952.1076309709034
total_envstep_count: 27396792
total_train_sample_count: 20529974
total_episode_count: 60128
total_duration: 5495.967077668481
[2023-06-29 15:07:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1199
train_sample_count: 1199
avg_envstep_per_episode: 149.875
avg_sample_per_episode: 149.875
avg_envstep_per_sec: 2432.323660781169
avg_train_sample_per_sec: 2432.323660781169
avg_episode_per_sec: 16.2290152512505
collect_time: 0.49294426532648505
reward_mean: 1949.3915467578227
reward_std: 1159.246112492628
reward_max: 3360.583602798323
reward_min: 289.0769576963614
total_envstep_count: 27401456
total_train_sample_count: 20533573
total_episode_count: 60136
total_duration: 5496.460021933807
[2023-06-29 15:07:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2529
train_sample_count: 2529
avg_envstep_per_episode: 252.9
avg_sample_per_episode: 252.9
avg_envstep_per_sec: 2517.2832955999343
avg_train_sample_per_sec: 2517.2832955999343
avg_episode_per_sec: 9.953670603400294
collect_time: 1.0046545036947354
reward_mean: 2073.2818414440794
reward_std: 1057.0488201264234
reward_max: 3432.289233077944
reward_min: 395.4778574677254
total_envstep_count: 27405992
total_train_sample_count: 20536902
total_episode_count: 60146
total_duration: 5497.464676437502
[2023-06-29 15:07:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1666
train_sample_count: 1666
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 2649.396254034957
avg_train_sample_per_sec: 2649.396254034957
avg_episode_per_sec: 12.722190895726085
collect_time: 0.6288225090764464
reward_mean: 1550.5926561949914
reward_std: 943.2996382617166
reward_max: 3440.7884802865815
reward_min: 224.58332554597908
total_envstep_count: 27410408
total_train_sample_count: 20540168
total_episode_count: 60154
total_duration: 5498.093498946579
[2023-06-29 15:07:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2604
train_sample_count: 2604
avg_envstep_per_episode: 236.72727272727272
avg_sample_per_episode: 236.72727272727272
avg_envstep_per_sec: 2708.8853412130047
avg_train_sample_per_sec: 2708.8853412130047
avg_episode_per_sec: 11.443064037382126
collect_time: 0.961280996424146
reward_mean: 1870.7546739130069
reward_std: 973.6530588313667
reward_max: 3441.3904885828724
reward_min: 826.2737845851323
total_envstep_count: 27415672
total_train_sample_count: 20543572
total_episode_count: 60165
total_duration: 5499.054779943002
[2023-06-29 15:07:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2034
train_sample_count: 2034
avg_envstep_per_episode: 290.57142857142856
avg_sample_per_episode: 290.57142857142856
avg_envstep_per_sec: 2704.42502354091
avg_train_sample_per_sec: 2704.42502354091
avg_episode_per_sec: 9.307264092815325
collect_time: 0.7521007172670215
reward_mean: 1853.157830235936
reward_std: 595.561466110509
reward_max: 3122.364584963313
reward_min: 1230.9836913350737
total_envstep_count: 27420296
total_train_sample_count: 20546806
total_episode_count: 60172
total_duration: 5499.80688066027
[2023-06-29 15:07:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 201.875
avg_sample_per_episode: 201.875
avg_envstep_per_sec: 2777.641665433715
avg_train_sample_per_sec: 2777.641665433715
avg_episode_per_sec: 13.759215680167008
collect_time: 0.5814284902540968
reward_mean: 1930.3547416104211
reward_std: 1229.124077480758
reward_max: 3431.8064654185487
reward_min: 422.19827910880576
total_envstep_count: 27424872
total_train_sample_count: 20550021
total_episode_count: 60180
total_duration: 5500.388309150524
[2023-06-29 15:07:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1279
train_sample_count: 1279
avg_envstep_per_episode: 159.875
avg_sample_per_episode: 159.875
avg_envstep_per_sec: 2586.3672874026183
avg_train_sample_per_sec: 2586.3672874026183
avg_episode_per_sec: 16.177434166709105
collect_time: 0.4945159978745505
reward_mean: 1601.1991997800117
reward_std: 1334.399677590973
reward_max: 3393.695595698464
reward_min: 233.279226661936
total_envstep_count: 27429416
total_train_sample_count: 20553300
total_episode_count: 60188
total_duration: 5500.882825148398
[2023-06-29 15:07:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 2795.352722206517
avg_train_sample_per_sec: 2795.352722206517
avg_episode_per_sec: 13.804210973859343
collect_time: 0.4346499782828614
reward_mean: 2672.774146190094
reward_std: 940.9049793739277
reward_max: 3453.1949142377703
reward_min: 1303.5536359494758
total_envstep_count: 27433464
total_train_sample_count: 20556515
total_episode_count: 60194
total_duration: 5501.3174751266815
[2023-06-29 15:07:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 289.85714285714283
avg_sample_per_episode: 289.85714285714283
avg_envstep_per_sec: 2630.3304752256163
avg_train_sample_per_sec: 2630.3304752256163
avg_episode_per_sec: 9.074575321133226
collect_time: 0.7713859604755416
reward_mean: 2592.8391180832637
reward_std: 872.1986825895593
reward_max: 3469.1173569594084
reward_min: 843.5791937859816
total_envstep_count: 27437888
total_train_sample_count: 20559744
total_episode_count: 60201
total_duration: 5502.088861087157
[2023-06-29 15:07:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2328
train_sample_count: 2328
avg_envstep_per_episode: 258.6666666666667
avg_sample_per_episode: 258.6666666666667
avg_envstep_per_sec: 2669.186873698699
avg_train_sample_per_sec: 2669.186873698699
avg_episode_per_sec: 10.319021418938268
collect_time: 0.8721757262255995
reward_mean: 1867.3589266353167
reward_std: 1025.3403893480956
reward_max: 3388.8660157562117
reward_min: 261.1970113012396
total_envstep_count: 27442432
total_train_sample_count: 20563272
total_episode_count: 60210
total_duration: 5502.961036813383
[2023-06-29 15:07:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2323
train_sample_count: 2323
avg_envstep_per_episode: 290.375
avg_sample_per_episode: 290.375
avg_envstep_per_sec: 2504.7427445665244
avg_train_sample_per_sec: 2504.7427445665244
avg_episode_per_sec: 8.625889778963492
collect_time: 0.9274405545396731
reward_mean: 2055.1887914486733
reward_std: 775.4434328754044
reward_max: 3391.739381151073
reward_min: 1337.100899475183
total_envstep_count: 27447312
total_train_sample_count: 20566795
total_episode_count: 60218
total_duration: 5503.888477367922
[2023-06-29 15:07:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 182.0909090909091
avg_sample_per_episode: 182.0909090909091
avg_envstep_per_sec: 2644.9131486038973
avg_train_sample_per_sec: 2644.9131486038973
avg_episode_per_sec: 14.525234465622999
collect_time: 0.7573027496412397
reward_mean: 1425.048154887094
reward_std: 794.3621781610216
reward_max: 3299.9666485203556
reward_min: 278.6807967763253
total_envstep_count: 27451216
total_train_sample_count: 20569998
total_episode_count: 60229
total_duration: 5504.645780117563
[2023-06-29 15:07:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2333
train_sample_count: 2333
avg_envstep_per_episode: 333.2857142857143
avg_sample_per_episode: 333.2857142857143
avg_envstep_per_sec: 2510.102161250842
avg_train_sample_per_sec: 2510.102161250842
avg_episode_per_sec: 7.531382395523315
collect_time: 0.9294442417584359
reward_mean: 1983.5279610821692
reward_std: 732.3716309562116
reward_max: 3359.5476341625294
reward_min: 1091.6370367044071
total_envstep_count: 27456416
total_train_sample_count: 20573531
total_episode_count: 60236
total_duration: 5505.5752243593215
[2023-06-29 15:07:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1709
train_sample_count: 1709
avg_envstep_per_episode: 341.8
avg_sample_per_episode: 341.8
avg_envstep_per_sec: 2784.927456955925
avg_train_sample_per_sec: 2784.927456955925
avg_episode_per_sec: 8.147827551070582
collect_time: 0.6136605087257923
reward_mean: 2663.939583894262
reward_std: 878.731142195951
reward_max: 3442.884528507777
reward_min: 1242.4201383899294
total_envstep_count: 27461216
total_train_sample_count: 20576840
total_episode_count: 60241
total_duration: 5506.188884868047
[2023-06-29 15:07:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1614
train_sample_count: 1614
avg_envstep_per_episode: 230.57142857142858
avg_sample_per_episode: 230.57142857142858
avg_envstep_per_sec: 2730.917737409436
avg_train_sample_per_sec: 2730.917737409436
avg_episode_per_sec: 11.844128972655547
collect_time: 0.591010112787597
reward_mean: 2353.8445183742033
reward_std: 938.0146643208997
reward_max: 3411.2906525805115
reward_min: 1006.1239829477697
total_envstep_count: 27465768
total_train_sample_count: 20580054
total_episode_count: 60248
total_duration: 5506.779894980835
[2023-06-29 15:07:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1601
train_sample_count: 1601
avg_envstep_per_episode: 228.71428571428572
avg_sample_per_episode: 228.71428571428572
avg_envstep_per_sec: 2674.69096850249
avg_train_sample_per_sec: 2674.69096850249
avg_episode_per_sec: 11.694463947231373
collect_time: 0.5985738236131146
reward_mean: 2374.0397741994725
reward_std: 973.2822508789213
reward_max: 3396.0126945292836
reward_min: 1169.0097957819921
total_envstep_count: 27469968
total_train_sample_count: 20583255
total_episode_count: 60255
total_duration: 5507.378468804448
[2023-06-29 15:07:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 250.0
avg_sample_per_episode: 250.0
avg_envstep_per_sec: 2761.1857445280693
avg_train_sample_per_sec: 2761.1857445280693
avg_episode_per_sec: 11.044742978112277
collect_time: 0.4527040611002593
reward_mean: 1940.304306752246
reward_std: 691.4362982406902
reward_max: 3261.1776579008347
reward_min: 1307.3984937656116
total_envstep_count: 27473768
total_train_sample_count: 20586505
total_episode_count: 60260
total_duration: 5507.831172865548
[2023-06-29 15:07:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1953
train_sample_count: 1953
avg_envstep_per_episode: 279.0
avg_sample_per_episode: 279.0
avg_envstep_per_sec: 2744.961747955643
avg_train_sample_per_sec: 2744.961747955643
avg_episode_per_sec: 9.838572573317718
collect_time: 0.7114853245057167
reward_mean: 2779.0184762892104
reward_std: 967.2566162436981
reward_max: 3427.8244973191713
reward_min: 1162.545861197817
total_envstep_count: 27478712
total_train_sample_count: 20590058
total_episode_count: 60267
total_duration: 5508.542658190054
[2023-06-29 15:07:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 245.3
avg_sample_per_episode: 245.3
avg_envstep_per_sec: 2710.0385329991586
avg_train_sample_per_sec: 2710.0385329991586
avg_episode_per_sec: 11.047853783119278
collect_time: 0.9051531814513729
reward_mean: 1956.9511784766278
reward_std: 1094.6881096671673
reward_max: 3474.9823689077284
reward_min: 471.86046386093983
total_envstep_count: 27483256
total_train_sample_count: 20593311
total_episode_count: 60277
total_duration: 5509.447811371505
[2023-06-29 15:08:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 363.25
avg_sample_per_episode: 363.25
avg_envstep_per_sec: 2784.4134346185824
avg_train_sample_per_sec: 2784.4134346185824
avg_episode_per_sec: 7.665281306589353
collect_time: 0.521833425286226
reward_mean: 2410.30781891409
reward_std: 955.5243844581076
reward_max: 3370.7527326280283
reward_min: 1347.3591149297108
total_envstep_count: 27488024
total_train_sample_count: 20596764
total_episode_count: 60281
total_duration: 5509.969644796791
[2023-06-29 15:08:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1239
train_sample_count: 1239
avg_envstep_per_episode: 154.875
avg_sample_per_episode: 154.875
avg_envstep_per_sec: 2765.046355549067
avg_train_sample_per_sec: 2765.046355549067
avg_episode_per_sec: 17.853406654069843
collect_time: 0.4480937534784897
reward_mean: 2051.7599431071535
reward_std: 1061.8225061044188
reward_max: 3397.8993950321665
reward_min: 535.4940755790443
total_envstep_count: 27491664
total_train_sample_count: 20600003
total_episode_count: 60289
total_duration: 5510.417738550269
[2023-06-29 15:08:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2970
train_sample_count: 2970
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 2747.3139243077617
avg_train_sample_per_sec: 2747.3139243077617
avg_episode_per_sec: 8.32519371002352
collect_time: 1.081055926562287
reward_mean: 2187.654126125218
reward_std: 1121.309704205157
reward_max: 3407.491478496576
reward_min: 254.71371674838315
total_envstep_count: 27496432
total_train_sample_count: 20603373
total_episode_count: 60298
total_duration: 5511.498794476831
[2023-06-29 15:08:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2079
train_sample_count: 2079
avg_envstep_per_episode: 259.875
avg_sample_per_episode: 259.875
avg_envstep_per_sec: 2492.4262263167298
avg_train_sample_per_sec: 2492.4262263167298
avg_episode_per_sec: 9.590865709732485
collect_time: 0.834126995635219
reward_mean: 1614.626938693646
reward_std: 632.8365589549608
reward_max: 2976.6231145794563
reward_min: 811.4312231860526
total_envstep_count: 27501064
total_train_sample_count: 20606652
total_episode_count: 60306
total_duration: 5512.332921472466
[2023-06-29 15:08:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2065
train_sample_count: 2065
avg_envstep_per_episode: 187.72727272727272
avg_sample_per_episode: 187.72727272727272
avg_envstep_per_sec: 2680.9216140182593
avg_train_sample_per_sec: 2680.9216140182593
avg_episode_per_sec: 14.280938379758283
collect_time: 0.7702575074192137
reward_mean: 1400.5903966973974
reward_std: 1090.9868722202061
reward_max: 3455.4592848382604
reward_min: 235.50879646861574
total_envstep_count: 27505864
total_train_sample_count: 20609917
total_episode_count: 60317
total_duration: 5513.103178979885
[2023-06-29 15:08:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1283
train_sample_count: 1283
avg_envstep_per_episode: 142.55555555555554
avg_sample_per_episode: 142.55555555555554
avg_envstep_per_sec: 2723.169859856445
avg_train_sample_per_sec: 2723.169859856445
avg_episode_per_sec: 19.102516553942323
collect_time: 0.4711421123277396
reward_mean: 1216.4134167342502
reward_std: 1013.9568159110894
reward_max: 3269.7622618671735
reward_min: 209.40479710655347
total_envstep_count: 27510408
total_train_sample_count: 20613200
total_episode_count: 60326
total_duration: 5513.574321092213
[2023-06-29 15:08:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2747
train_sample_count: 2747
avg_envstep_per_episode: 196.21428571428572
avg_sample_per_episode: 196.21428571428572
avg_envstep_per_sec: 2807.376339346643
avg_train_sample_per_sec: 2807.376339346643
avg_episode_per_sec: 14.307706134274847
collect_time: 0.978493678065017
reward_mean: 1651.451391479512
reward_std: 1220.5268508228594
reward_max: 3482.373928227176
reward_min: 251.44825491171017
total_envstep_count: 27514880
total_train_sample_count: 20616747
total_episode_count: 60340
total_duration: 5514.552814770278
[2023-06-29 15:08:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2732
train_sample_count: 2732
avg_envstep_per_episode: 227.66666666666666
avg_sample_per_episode: 227.66666666666666
avg_envstep_per_sec: 2679.4872216407866
avg_train_sample_per_sec: 2679.4872216407866
avg_episode_per_sec: 11.769343579681347
collect_time: 1.0195980700841174
reward_mean: 1290.6636928468565
reward_std: 900.3844254944032
reward_max: 3349.818577177921
reward_min: 401.82429167428904
total_envstep_count: 27520032
total_train_sample_count: 20620279
total_episode_count: 60352
total_duration: 5515.572412840362
[2023-06-29 15:08:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2483
train_sample_count: 2483
avg_envstep_per_episode: 206.91666666666666
avg_sample_per_episode: 206.91666666666666
avg_envstep_per_sec: 2523.0766707961643
avg_train_sample_per_sec: 2523.0766707961643
avg_episode_per_sec: 12.193685078354397
collect_time: 0.9841159520596265
reward_mean: 1401.7513599661609
reward_std: 1016.6789889786368
reward_max: 3395.176278660427
reward_min: 271.09012613365144
total_envstep_count: 27524424
total_train_sample_count: 20623562
total_episode_count: 60364
total_duration: 5516.556528792421
[2023-06-29 15:08:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2709
train_sample_count: 2709
avg_envstep_per_episode: 246.27272727272728
avg_sample_per_episode: 246.27272727272728
avg_envstep_per_sec: 2575.719975492306
avg_train_sample_per_sec: 2575.719975492306
avg_episode_per_sec: 10.458811269994598
collect_time: 1.0517447648718956
reward_mean: 1480.015960250431
reward_std: 696.8895999803741
reward_max: 2943.893940355028
reward_min: 284.6867684464541
total_envstep_count: 27529200
total_train_sample_count: 20627071
total_episode_count: 60375
total_duration: 5517.608273557293
[2023-06-29 15:08:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2447
train_sample_count: 2447
avg_envstep_per_episode: 203.91666666666666
avg_sample_per_episode: 203.91666666666666
avg_envstep_per_sec: 2730.5745678256485
avg_train_sample_per_sec: 2730.5745678256485
avg_episode_per_sec: 13.390639482594109
collect_time: 0.8961483889995143
reward_mean: 1294.9325465206032
reward_std: 605.4921837061399
reward_max: 2325.9716324429896
reward_min: 375.9196383781245
total_envstep_count: 27533480
total_train_sample_count: 20630318
total_episode_count: 60387
total_duration: 5518.5044219462925
[2023-06-29 15:08:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2452
train_sample_count: 2452
avg_envstep_per_episode: 204.33333333333334
avg_sample_per_episode: 204.33333333333334
avg_envstep_per_sec: 2776.1009307625595
avg_train_sample_per_sec: 2776.1009307625595
avg_episode_per_sec: 13.586138323470928
collect_time: 0.8832531889704985
reward_mean: 1229.4439444878062
reward_std: 374.43371811810084
reward_max: 1805.2301419477883
reward_min: 244.64534791359026
total_envstep_count: 27537488
total_train_sample_count: 20633570
total_episode_count: 60399
total_duration: 5519.387675135263
[2023-06-29 15:08:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2592
train_sample_count: 2592
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 2559.2402424334678
avg_train_sample_per_sec: 2559.2402424334678
avg_episode_per_sec: 11.848334455710498
collect_time: 1.012800579259172
reward_mean: 1182.3092862617073
reward_std: 399.8108835182015
reward_max: 1887.5315778895492
reward_min: 453.710238874938
total_envstep_count: 27542552
total_train_sample_count: 20636962
total_episode_count: 60411
total_duration: 5520.400475714522
[2023-06-29 15:08:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2062
train_sample_count: 2062
avg_envstep_per_episode: 171.83333333333334
avg_sample_per_episode: 171.83333333333334
avg_envstep_per_sec: 2606.177871849227
avg_train_sample_per_sec: 2606.177871849227
avg_episode_per_sec: 15.166893531615287
collect_time: 0.7911969563830643
reward_mean: 1304.7731488256716
reward_std: 342.7645470675538
reward_max: 2192.131694595555
reward_min: 870.148532411137
total_envstep_count: 27546336
total_train_sample_count: 20640224
total_episode_count: 60423
total_duration: 5521.191672670905
[2023-06-29 15:08:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2650
train_sample_count: 2650
avg_envstep_per_episode: 220.83333333333334
avg_sample_per_episode: 220.83333333333334
avg_envstep_per_sec: 2553.4874784122444
avg_train_sample_per_sec: 2553.4874784122444
avg_episode_per_sec: 11.562962166395069
collect_time: 1.0377963559264316
reward_mean: 1257.6252949438901
reward_std: 266.46774810032446
reward_max: 1744.4519534134995
reward_min: 856.6536095085988
total_envstep_count: 27551272
total_train_sample_count: 20643674
total_episode_count: 60435
total_duration: 5522.229469026832
[2023-06-29 15:08:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2676
train_sample_count: 2676
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 2726.0306645965197
avg_train_sample_per_sec: 2726.0306645965197
avg_episode_per_sec: 12.224352756038204
collect_time: 0.981647064632736
reward_mean: 1436.4178826243185
reward_std: 372.7752558160637
reward_max: 2098.1739159057142
reward_min: 616.2280296782757
total_envstep_count: 27555624
total_train_sample_count: 20647150
total_episode_count: 60447
total_duration: 5523.211116091465
[2023-06-29 15:08:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3400
train_sample_count: 3400
avg_envstep_per_episode: 283.3333333333333
avg_sample_per_episode: 283.3333333333333
avg_envstep_per_sec: 2601.9143922311982
avg_train_sample_per_sec: 2601.9143922311982
avg_episode_per_sec: 9.183227266698347
collect_time: 1.3067301561310884
reward_mean: 1458.9999287561939
reward_std: 234.05443934537678
reward_max: 1883.1144408308137
reward_min: 1166.2525365696458
total_envstep_count: 27559920
total_train_sample_count: 20650550
total_episode_count: 60459
total_duration: 5524.517846247596
[2023-06-29 15:08:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3185
train_sample_count: 3185
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 2519.6298016297446
avg_train_sample_per_sec: 2519.6298016297446
avg_episode_per_sec: 10.284203271958143
collect_time: 1.2640745866475627
reward_mean: 1030.8119868739407
reward_std: 451.52244831436525
reward_max: 2270.782983883173
reward_min: 462.30393711553006
total_envstep_count: 27564632
total_train_sample_count: 20654135
total_episode_count: 60472
total_duration: 5525.7819208342435
[2023-06-29 15:08:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2872
train_sample_count: 2872
avg_envstep_per_episode: 319.1111111111111
avg_sample_per_episode: 319.1111111111111
avg_envstep_per_sec: 2647.7466754743245
avg_train_sample_per_sec: 2647.7466754743245
avg_episode_per_sec: 8.29725629501007
collect_time: 1.0846959139266985
reward_mean: 1611.3078837014878
reward_std: 327.2062723658953
reward_max: 2242.6651527251242
reward_min: 1206.5195899540736
total_envstep_count: 27569464
total_train_sample_count: 20657407
total_episode_count: 60481
total_duration: 5526.866616748171
[2023-06-29 15:08:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2515
train_sample_count: 2515
avg_envstep_per_episode: 251.5
avg_sample_per_episode: 251.5
avg_envstep_per_sec: 2742.0208124386418
avg_train_sample_per_sec: 2742.0208124386418
avg_episode_per_sec: 10.902667246276906
collect_time: 0.9172067507989705
reward_mean: 1679.313753257041
reward_std: 806.9414088859895
reward_max: 3348.7227882607826
reward_min: 903.594313984459
total_envstep_count: 27574328
total_train_sample_count: 20660722
total_episode_count: 60491
total_duration: 5527.7838234989695
[2023-06-29 15:09:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3086
train_sample_count: 3086
avg_envstep_per_episode: 237.3846153846154
avg_sample_per_episode: 237.3846153846154
avg_envstep_per_sec: 2757.751051642712
avg_train_sample_per_sec: 2757.751051642712
avg_episode_per_sec: 11.617227372441755
collect_time: 1.1190277665425092
reward_mean: 1477.4323923466536
reward_std: 509.7375449937282
reward_max: 2448.1482236288934
reward_min: 817.8915169764349
total_envstep_count: 27579304
total_train_sample_count: 20664208
total_episode_count: 60504
total_duration: 5528.902851265512
[2023-06-29 15:09:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2771
train_sample_count: 2771
avg_envstep_per_episode: 230.91666666666666
avg_sample_per_episode: 230.91666666666666
avg_envstep_per_sec: 2573.0822284477968
avg_train_sample_per_sec: 2573.0822284477968
avg_episode_per_sec: 11.142903912440836
collect_time: 1.076918556804769
reward_mean: 1373.0617697533028
reward_std: 416.6418278928308
reward_max: 2013.424885068532
reward_min: 495.22234849597476
total_envstep_count: 27583776
total_train_sample_count: 20667779
total_episode_count: 60516
total_duration: 5529.979769822317
[2023-06-29 15:09:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2272
train_sample_count: 2272
avg_envstep_per_episode: 252.44444444444446
avg_sample_per_episode: 252.44444444444446
avg_envstep_per_sec: 2441.046262168759
avg_train_sample_per_sec: 2441.046262168759
avg_episode_per_sec: 9.669637482182583
collect_time: 0.9307484398027881
reward_mean: 1446.0102685639893
reward_std: 476.92165113152095
reward_max: 2231.5375167510033
reward_min: 558.5866476296976
total_envstep_count: 27588576
total_train_sample_count: 20671251
total_episode_count: 60525
total_duration: 5530.910518262121
[2023-06-29 15:09:12][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1786
train_sample_count: 1786
avg_envstep_per_episode: 297.6666666666667
avg_sample_per_episode: 297.6666666666667
avg_envstep_per_sec: 2771.7307529695076
avg_train_sample_per_sec: 2771.7307529695076
avg_episode_per_sec: 9.311525485899802
collect_time: 0.644362731873058
reward_mean: 2586.8593941628246
reward_std: 811.7167737821244
reward_max: 3503.28625447219
reward_min: 1349.2199953830489
total_envstep_count: 27592920
total_train_sample_count: 20674637
total_episode_count: 60531
total_duration: 5531.554880993994
[2023-06-29 15:09:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2012
train_sample_count: 2012
avg_envstep_per_episode: 223.55555555555554
avg_sample_per_episode: 223.55555555555554
avg_envstep_per_sec: 2487.087670732613
avg_train_sample_per_sec: 2487.087670732613
avg_episode_per_sec: 11.125143656358606
collect_time: 0.8089783177636565
reward_mean: 1811.6239013425968
reward_std: 863.5368559626257
reward_max: 3475.4305026957445
reward_min: 233.2972482054107
total_envstep_count: 27597368
total_train_sample_count: 20677849
total_episode_count: 60540
total_duration: 5532.363859311758
[2023-06-29 15:09:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2440
train_sample_count: 2440
avg_envstep_per_episode: 221.8181818181818
avg_sample_per_episode: 221.8181818181818
avg_envstep_per_sec: 2818.5929228581417
avg_train_sample_per_sec: 2818.5929228581417
avg_episode_per_sec: 12.706771373540803
collect_time: 0.8656801697798074
reward_mean: 1496.7359894089036
reward_std: 544.4042908063684
reward_max: 3062.3963061855306
reward_min: 1021.0981384834715
total_envstep_count: 27601264
total_train_sample_count: 20681089
total_episode_count: 60551
total_duration: 5533.229539481537
[2023-06-29 15:09:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2071
train_sample_count: 2071
avg_envstep_per_episode: 258.875
avg_sample_per_episode: 258.875
avg_envstep_per_sec: 2510.472508467109
avg_train_sample_per_sec: 2510.472508467109
avg_episode_per_sec: 9.697624368776859
collect_time: 0.8249443055102601
reward_mean: 1669.4160280644883
reward_std: 867.2178237817016
reward_max: 3527.770590935451
reward_min: 453.49380866688693
total_envstep_count: 27605648
total_train_sample_count: 20684360
total_episode_count: 60559
total_duration: 5534.0544837870475
[2023-06-29 15:09:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3300
train_sample_count: 3300
avg_envstep_per_episode: 253.84615384615384
avg_sample_per_episode: 253.84615384615384
avg_envstep_per_sec: 2670.2442300648104
avg_train_sample_per_sec: 2670.2442300648104
avg_episode_per_sec: 10.51914393661895
collect_time: 1.2358420113204045
reward_mean: 1538.6986682482707
reward_std: 924.0326247729612
reward_max: 3492.740208484106
reward_min: 259.29227276893
total_envstep_count: 27609904
total_train_sample_count: 20687660
total_episode_count: 60572
total_duration: 5535.290325798368
[2023-06-29 15:09:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1850
train_sample_count: 1850
avg_envstep_per_episode: 264.2857142857143
avg_sample_per_episode: 264.2857142857143
avg_envstep_per_sec: 2583.083515692378
avg_train_sample_per_sec: 2583.083515692378
avg_episode_per_sec: 9.773829518836026
collect_time: 0.7161982912132517
reward_mean: 1272.1659215820707
reward_std: 426.02039908568094
reward_max: 1762.3762304243028
reward_min: 468.611356569134
total_envstep_count: 27614672
total_train_sample_count: 20691110
total_episode_count: 60579
total_duration: 5536.006524089581
[2023-06-29 15:09:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3060
train_sample_count: 3060
avg_envstep_per_episode: 255.0
avg_sample_per_episode: 255.0
avg_envstep_per_sec: 2802.7854059837778
avg_train_sample_per_sec: 2802.7854059837778
avg_episode_per_sec: 10.99131531758344
collect_time: 1.0917710622679442
reward_mean: 1822.1452951898657
reward_std: 893.5238076263639
reward_max: 3445.985065134927
reward_min: 367.6124621991461
total_envstep_count: 27619384
total_train_sample_count: 20694570
total_episode_count: 60591
total_duration: 5537.098295151849
[2023-06-29 15:09:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2278
train_sample_count: 2278
avg_envstep_per_episode: 284.75
avg_sample_per_episode: 284.75
avg_envstep_per_sec: 2616.1289593453384
avg_train_sample_per_sec: 2616.1289593453384
avg_episode_per_sec: 9.187459031941488
collect_time: 0.8707521820981057
reward_mean: 1565.3603681680202
reward_std: 349.29184920290027
reward_max: 2323.4664986370635
reward_min: 1174.453050453997
total_envstep_count: 27623688
total_train_sample_count: 20698048
total_episode_count: 60599
total_duration: 5537.969047333947
[2023-06-29 15:09:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2484
train_sample_count: 2484
avg_envstep_per_episode: 191.07692307692307
avg_sample_per_episode: 191.07692307692307
avg_envstep_per_sec: 2481.5519135969985
avg_train_sample_per_sec: 2481.5519135969985
avg_episode_per_sec: 12.987187953607481
collect_time: 1.0009865142814816
reward_mean: 1307.0957241058159
reward_std: 861.4227141095098
reward_max: 3518.012763931125
reward_min: 253.5027027419527
total_envstep_count: 27627904
total_train_sample_count: 20701332
total_episode_count: 60612
total_duration: 5538.970033848228
[2023-06-29 15:09:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2897
train_sample_count: 2897
avg_envstep_per_episode: 222.84615384615384
avg_sample_per_episode: 222.84615384615384
avg_envstep_per_sec: 2572.4430278482873
avg_train_sample_per_sec: 2572.4430278482873
avg_episode_per_sec: 11.543582796695802
collect_time: 1.1261668261019515
reward_mean: 1230.0294039982155
reward_std: 465.908168204964
reward_max: 1869.7298260231753
reward_min: 267.86802289892074
total_envstep_count: 27632416
total_train_sample_count: 20704629
total_episode_count: 60625
total_duration: 5540.09620067433
[2023-06-29 15:09:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 250.875
avg_sample_per_episode: 250.875
avg_envstep_per_sec: 2641.298493804468
avg_train_sample_per_sec: 2641.298493804468
avg_episode_per_sec: 10.528344768528024
collect_time: 0.7598535359436644
reward_mean: 1451.240791125234
reward_std: 346.5958904596751
reward_max: 2154.207124761611
reward_min: 1051.8811482871347
total_envstep_count: 27636784
total_train_sample_count: 20707836
total_episode_count: 60633
total_duration: 5540.856054210274
[2023-06-29 15:09:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2863
train_sample_count: 2863
avg_envstep_per_episode: 260.27272727272725
avg_sample_per_episode: 260.27272727272725
avg_envstep_per_sec: 2528.463161519307
avg_train_sample_per_sec: 2528.463161519307
avg_episode_per_sec: 9.714668102239742
collect_time: 1.1323083695946259
reward_mean: 1788.0367892171344
reward_std: 992.1139365510103
reward_max: 3452.7971141572116
reward_min: 227.6171392339244
total_envstep_count: 27641136
total_train_sample_count: 20711099
total_episode_count: 60644
total_duration: 5541.988362579868
[2023-06-29 15:09:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3004
train_sample_count: 3004
avg_envstep_per_episode: 231.07692307692307
avg_sample_per_episode: 231.07692307692307
avg_envstep_per_sec: 2526.236774915618
avg_train_sample_per_sec: 2526.236774915618
avg_episode_per_sec: 10.932449425400478
collect_time: 1.1891205249754708
reward_mean: 1172.960780286094
reward_std: 699.4840420644318
reward_max: 2401.5528877357297
reward_min: 224.33511052533296
total_envstep_count: 27645616
total_train_sample_count: 20714503
total_episode_count: 60657
total_duration: 5543.177483104844
[2023-06-29 15:09:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3417
train_sample_count: 3417
avg_envstep_per_episode: 262.84615384615387
avg_sample_per_episode: 262.84615384615387
avg_envstep_per_sec: 2724.605136712077
avg_train_sample_per_sec: 2724.605136712077
avg_episode_per_sec: 10.365778980760023
collect_time: 1.2541266820495949
reward_mean: 1290.312579302304
reward_std: 752.575759896266
reward_max: 3443.5964721063606
reward_min: 251.46121902496895
total_envstep_count: 27650256
total_train_sample_count: 20717920
total_episode_count: 60670
total_duration: 5544.431609786894
[2023-06-29 15:09:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2476
train_sample_count: 2476
avg_envstep_per_episode: 275.1111111111111
avg_sample_per_episode: 275.1111111111111
avg_envstep_per_sec: 2765.237908446472
avg_train_sample_per_sec: 2765.237908446472
avg_episode_per_sec: 10.051349424886206
collect_time: 0.8954021613970395
reward_mean: 1413.4446367257037
reward_std: 673.1952338188797
reward_max: 2560.7238019177835
reward_min: 316.061540617578
total_envstep_count: 27654912
total_train_sample_count: 20721196
total_episode_count: 60679
total_duration: 5545.327011948291
[2023-06-29 15:09:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2616
train_sample_count: 2616
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 2597.235627653453
avg_train_sample_per_sec: 2597.235627653453
avg_episode_per_sec: 11.913924897492903
collect_time: 1.0072247477844358
reward_mean: 1382.8586810048967
reward_std: 626.8826558691719
reward_max: 2665.971464425926
reward_min: 246.61522425594788
total_envstep_count: 27659512
total_train_sample_count: 20724612
total_episode_count: 60691
total_duration: 5546.334236696076
[2023-06-29 15:10:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2199
train_sample_count: 2199
avg_envstep_per_episode: 199.9090909090909
avg_sample_per_episode: 199.9090909090909
avg_envstep_per_sec: 2460.938017603543
avg_train_sample_per_sec: 2460.938017603543
avg_episode_per_sec: 12.310285672414267
collect_time: 0.8935617168210446
reward_mean: 1249.0452040711236
reward_std: 814.9153043475501
reward_max: 3045.2597622974317
reward_min: 238.9481332930351
total_envstep_count: 27663592
total_train_sample_count: 20728011
total_episode_count: 60702
total_duration: 5547.227798412897
[2023-06-29 15:10:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2455
train_sample_count: 2455
avg_envstep_per_episode: 223.1818181818182
avg_sample_per_episode: 223.1818181818182
avg_envstep_per_sec: 2516.0691852755504
avg_train_sample_per_sec: 2516.0691852755504
avg_episode_per_sec: 11.27362975072548
collect_time: 0.9757283362345769
reward_mean: 1439.5415904282909
reward_std: 467.0069358553285
reward_max: 2674.274714388285
reward_min: 840.5760625475083
total_envstep_count: 27668216
total_train_sample_count: 20731266
total_episode_count: 60713
total_duration: 5548.203526749131
[2023-06-29 15:10:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 1972
train_sample_count: 1972
avg_envstep_per_episode: 219.11111111111111
avg_sample_per_episode: 219.11111111111111
avg_envstep_per_sec: 2793.128620034197
avg_train_sample_per_sec: 2793.128620034197
avg_episode_per_sec: 12.747544411920778
collect_time: 0.7060183286424727
reward_mean: 1427.8261320594888
reward_std: 474.3221227266249
reward_max: 2610.3147380753503
reward_min: 903.3066939982407
total_envstep_count: 27672744
total_train_sample_count: 20734838
total_episode_count: 60722
total_duration: 5548.909545077773
[2023-06-29 15:10:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 225.44444444444446
avg_sample_per_episode: 225.44444444444446
avg_envstep_per_sec: 2680.424935246763
avg_train_sample_per_sec: 2680.424935246763
avg_episode_per_sec: 11.889514251957056
collect_time: 0.7569695287188514
reward_mean: 1987.9644144643955
reward_std: 890.7143310401908
reward_max: 3491.8276355063804
reward_min: 707.6274110552982
total_envstep_count: 27676816
total_train_sample_count: 20738067
total_episode_count: 60731
total_duration: 5549.666514606492
[2023-06-29 15:10:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2397
train_sample_count: 2397
avg_envstep_per_episode: 299.625
avg_sample_per_episode: 299.625
avg_envstep_per_sec: 2403.78079745518
avg_train_sample_per_sec: 2403.78079745518
avg_episode_per_sec: 8.022630946867519
collect_time: 0.9971791115636006
reward_mean: 1910.2960781576235
reward_std: 1025.7511557617709
reward_max: 3323.633177786868
reward_min: 410.6107812352781
total_envstep_count: 27681624
total_train_sample_count: 20741664
total_episode_count: 60739
total_duration: 5550.663693718056
[2023-06-29 15:10:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2432
train_sample_count: 2432
avg_envstep_per_episode: 243.2
avg_sample_per_episode: 243.2
avg_envstep_per_sec: 2281.893873058908
avg_train_sample_per_sec: 2281.893873058908
avg_episode_per_sec: 9.382787306985641
collect_time: 1.0657813795432445
reward_mean: 1691.7216660286333
reward_std: 1041.1704133237565
reward_max: 3639.3963994146047
reward_min: 530.5851553561367
total_envstep_count: 27686424
total_train_sample_count: 20744896
total_episode_count: 60749
total_duration: 5551.729475097599
[2023-06-29 15:10:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1739
train_sample_count: 1739
avg_envstep_per_episode: 217.375
avg_sample_per_episode: 217.375
avg_envstep_per_sec: 2352.109955118823
avg_train_sample_per_sec: 2352.109955118823
avg_episode_per_sec: 10.820517332346512
collect_time: 0.7393361846096815
reward_mean: 1495.2618832678804
reward_std: 821.436674055446
reward_max: 3512.885170717709
reward_min: 626.1455928306335
total_envstep_count: 27691112
total_train_sample_count: 20748235
total_episode_count: 60757
total_duration: 5552.468811282209
[2023-06-29 15:10:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2973
train_sample_count: 2973
avg_envstep_per_episode: 270.27272727272725
avg_sample_per_episode: 270.27272727272725
avg_envstep_per_sec: 2503.9077575907318
avg_train_sample_per_sec: 2503.9077575907318
avg_episode_per_sec: 9.264374481499512
collect_time: 1.1873440588964148
reward_mean: 2073.737220409402
reward_std: 1148.8479616350655
reward_max: 3537.793359180866
reward_min: 429.08282989208897
total_envstep_count: 27696240
total_train_sample_count: 20751608
total_episode_count: 60768
total_duration: 5553.656155341105
[2023-06-29 15:10:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1356
train_sample_count: 1356
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 2542.9507491375844
avg_train_sample_per_sec: 2542.9507491375844
avg_episode_per_sec: 11.251994465210549
collect_time: 0.5332387976683676
reward_mean: 1463.6548067952947
reward_std: 967.1680238026019
reward_max: 3498.5380369226177
reward_min: 438.74065271880227
total_envstep_count: 27700392
total_train_sample_count: 20754964
total_episode_count: 60774
total_duration: 5554.189394138773
[2023-06-29 15:10:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1554
train_sample_count: 1554
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 2221.5369932910357
avg_train_sample_per_sec: 2221.5369932910357
avg_episode_per_sec: 10.006923393202865
collect_time: 0.6995156977772712
reward_mean: 2213.3514328449514
reward_std: 1154.6271212792376
reward_max: 3527.1542458872673
reward_min: 729.7860644132801
total_envstep_count: 27704512
total_train_sample_count: 20758518
total_episode_count: 60781
total_duration: 5554.888909836551
[2023-06-29 15:10:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2322
train_sample_count: 2322
avg_envstep_per_episode: 290.25
avg_sample_per_episode: 290.25
avg_envstep_per_sec: 2586.591535211036
avg_train_sample_per_sec: 2586.591535211036
avg_episode_per_sec: 8.911598743190478
collect_time: 0.8977064868537705
reward_mean: 2253.0081267917108
reward_std: 840.6033915911399
reward_max: 3475.3537375704905
reward_min: 1105.8937284647157
total_envstep_count: 27709272
total_train_sample_count: 20762040
total_episode_count: 60789
total_duration: 5555.786616323405
[2023-06-29 15:10:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2162
train_sample_count: 2162
avg_envstep_per_episode: 308.85714285714283
avg_sample_per_episode: 308.85714285714283
avg_envstep_per_sec: 2724.423850655964
avg_train_sample_per_sec: 2724.423850655964
avg_episode_per_sec: 8.820983790282956
collect_time: 0.7935622790409251
reward_mean: 2417.574408515541
reward_std: 899.5094385145754
reward_max: 3483.489470635364
reward_min: 1387.532368513753
total_envstep_count: 27713720
total_train_sample_count: 20765402
total_episode_count: 60796
total_duration: 5556.580178602446
[2023-06-29 15:10:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 227.6
avg_sample_per_episode: 227.6
avg_envstep_per_sec: 2598.9270986533184
avg_train_sample_per_sec: 2598.9270986533184
avg_episode_per_sec: 11.418836110076091
collect_time: 0.4378729978958146
reward_mean: 2246.362516280938
reward_std: 1065.4692555121928
reward_max: 3540.1540830016165
reward_min: 882.3238482558764
total_envstep_count: 27718672
total_train_sample_count: 20768940
total_episode_count: 60801
total_duration: 5557.018051600342
[2023-06-29 15:10:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2145
train_sample_count: 2145
avg_envstep_per_episode: 306.42857142857144
avg_sample_per_episode: 306.42857142857144
avg_envstep_per_sec: 2672.1892901038354
avg_train_sample_per_sec: 2672.1892901038354
avg_episode_per_sec: 8.720431249756107
collect_time: 0.802712595228106
reward_mean: 2857.0327097850522
reward_std: 721.633613836397
reward_max: 3472.103814485407
reward_min: 1399.774975683965
total_envstep_count: 27723296
total_train_sample_count: 20772285
total_episode_count: 60808
total_duration: 5557.8207641955705
[2023-06-29 15:10:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1604
train_sample_count: 1604
avg_envstep_per_episode: 200.5
avg_sample_per_episode: 200.5
avg_envstep_per_sec: 2461.8148441689527
avg_train_sample_per_sec: 2461.8148441689527
avg_episode_per_sec: 12.278378275156872
collect_time: 0.6515518434699626
reward_mean: 2040.0083188363787
reward_std: 920.7964392819105
reward_max: 3414.2590212464174
reward_min: 847.770131470076
total_envstep_count: 27727752
total_train_sample_count: 20775489
total_episode_count: 60816
total_duration: 5558.47231603904
[2023-06-29 15:10:48][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1816
train_sample_count: 1816
avg_envstep_per_episode: 302.6666666666667
avg_sample_per_episode: 302.6666666666667
avg_envstep_per_sec: 2742.5657526412856
avg_train_sample_per_sec: 2742.5657526412856
avg_episode_per_sec: 9.061340592427156
collect_time: 0.6621536779021845
reward_mean: 2395.473880578968
reward_std: 798.8499624269771
reward_max: 3499.721102590978
reward_min: 1625.3531952903736
total_envstep_count: 27732480
total_train_sample_count: 20778905
total_episode_count: 60822
total_duration: 5559.1344697169425
[2023-06-29 15:10:51][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1806
train_sample_count: 1806
avg_envstep_per_episode: 258.0
avg_sample_per_episode: 258.0
avg_envstep_per_sec: 2713.9791428926205
avg_train_sample_per_sec: 2713.9791428926205
avg_episode_per_sec: 10.51929900345977
collect_time: 0.6654435811452568
reward_mean: 2284.572876149107
reward_std: 1058.013780957174
reward_max: 3542.2865314683586
reward_min: 602.978999184387
total_envstep_count: 27737256
total_train_sample_count: 20782311
total_episode_count: 60829
total_duration: 5559.799913298088
[2023-06-29 15:10:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 843
train_sample_count: 843
avg_envstep_per_episode: 210.75
avg_sample_per_episode: 210.75
avg_envstep_per_sec: 2686.0292602357945
avg_train_sample_per_sec: 2686.0292602357945
avg_episode_per_sec: 12.745097320217292
collect_time: 0.31384617155138395
reward_mean: 2979.568617655302
reward_std: 766.6893358123492
reward_max: 3458.982508167861
reward_min: 1652.203712608765
total_envstep_count: 27741544
total_train_sample_count: 20785554
total_episode_count: 60833
total_duration: 5560.113759469639
[2023-06-29 15:10:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1522
train_sample_count: 1522
avg_envstep_per_episode: 253.66666666666666
avg_sample_per_episode: 253.66666666666666
avg_envstep_per_sec: 2684.1967650356714
avg_train_sample_per_sec: 2684.1967650356714
avg_episode_per_sec: 10.58159040092906
collect_time: 0.5670225148266184
reward_mean: 3259.4088495354627
reward_std: 330.8767222767164
reward_max: 3507.489817372628
reward_min: 2547.060266073608
total_envstep_count: 27746032
total_train_sample_count: 20789076
total_episode_count: 60839
total_duration: 5560.680781984466
[2023-06-29 15:11:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1891
train_sample_count: 1891
avg_envstep_per_episode: 189.1
avg_sample_per_episode: 189.1
avg_envstep_per_sec: 2716.926915443884
avg_train_sample_per_sec: 2716.926915443884
avg_episode_per_sec: 14.36767274163873
collect_time: 0.6960069441879168
reward_mean: 1665.1623899730862
reward_std: 813.7419750482322
reward_max: 3413.71103649539
reward_min: 463.5081924195389
total_envstep_count: 27750264
total_train_sample_count: 20792567
total_episode_count: 60849
total_duration: 5561.376788928654
[2023-06-29 15:11:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1631
train_sample_count: 1631
avg_envstep_per_episode: 271.8333333333333
avg_sample_per_episode: 271.8333333333333
avg_envstep_per_sec: 2777.890589286386
avg_train_sample_per_sec: 2777.890589286386
avg_episode_per_sec: 10.219094749060893
collect_time: 0.5871361551424488
reward_mean: 2283.6684757344374
reward_std: 1076.3441365443198
reward_max: 3488.025868863371
reward_min: 427.0987381470571
total_envstep_count: 27754456
total_train_sample_count: 20795798
total_episode_count: 60855
total_duration: 5561.963925083796
[2023-06-29 15:11:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1735
train_sample_count: 1735
avg_envstep_per_episode: 289.1666666666667
avg_sample_per_episode: 289.1666666666667
avg_envstep_per_sec: 2775.753402252953
avg_train_sample_per_sec: 2775.753402252953
avg_episode_per_sec: 9.599147212402142
collect_time: 0.6250555249582975
reward_mean: 2385.6899580569343
reward_std: 1062.7357069539594
reward_max: 3401.5095257434277
reward_min: 428.53558792101876
total_envstep_count: 27758072
total_train_sample_count: 20799133
total_episode_count: 60861
total_duration: 5562.588980608754
[2023-06-29 15:11:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 2095
train_sample_count: 2095
avg_envstep_per_episode: 349.1666666666667
avg_sample_per_episode: 349.1666666666667
avg_envstep_per_sec: 2720.159435059119
avg_train_sample_per_sec: 2720.159435059119
avg_episode_per_sec: 7.7904327495726555
collect_time: 0.7701754437619823
reward_mean: 2285.7680416989842
reward_std: 667.3642606955422
reward_max: 3425.657601509911
reward_min: 1641.1007324850636
total_envstep_count: 27762176
total_train_sample_count: 20802428
total_episode_count: 60867
total_duration: 5563.3591560525165
[2023-06-29 15:11:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1704
train_sample_count: 1704
avg_envstep_per_episode: 284.0
avg_sample_per_episode: 284.0
avg_envstep_per_sec: 2673.6036620344335
avg_train_sample_per_sec: 2673.6036620344335
avg_episode_per_sec: 9.414097401529695
collect_time: 0.6373420354695991
reward_mean: 1973.5158119297075
reward_std: 1205.1702016777654
reward_max: 3453.404097232401
reward_min: 618.9838952833863
total_envstep_count: 27766312
total_train_sample_count: 20805732
total_episode_count: 60873
total_duration: 5563.996498087986
[2023-06-29 15:11:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1723
train_sample_count: 1723
avg_envstep_per_episode: 246.14285714285714
avg_sample_per_episode: 246.14285714285714
avg_envstep_per_sec: 2558.4537412441223
avg_train_sample_per_sec: 2558.4537412441223
avg_episode_per_sec: 10.394182349802007
collect_time: 0.6734536459362135
reward_mean: 1908.8121249581418
reward_std: 1397.3803922290163
reward_max: 3514.020127363215
reward_min: 403.7370361169313
total_envstep_count: 27770056
total_train_sample_count: 20809055
total_episode_count: 60880
total_duration: 5564.669951733922
[2023-06-29 15:11:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1632
train_sample_count: 1632
avg_envstep_per_episode: 233.14285714285714
avg_sample_per_episode: 233.14285714285714
avg_envstep_per_sec: 2384.661702015662
avg_train_sample_per_sec: 2384.661702015662
avg_episode_per_sec: 10.228328378743647
collect_time: 0.6843738038903102
reward_mean: 2148.433712383724
reward_std: 1172.5839310558677
reward_max: 3460.58960657546
reward_min: 410.6348231279539
total_envstep_count: 27774472
total_train_sample_count: 20812287
total_episode_count: 60887
total_duration: 5565.354325537813
[2023-06-29 15:11:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1695
train_sample_count: 1695
avg_envstep_per_episode: 282.5
avg_sample_per_episode: 282.5
avg_envstep_per_sec: 2719.0480189343616
avg_train_sample_per_sec: 2719.0480189343616
avg_episode_per_sec: 9.62494873959066
collect_time: 0.6233799433466046
reward_mean: 2034.6538825479158
reward_std: 1280.9036627899932
reward_max: 3359.563959152555
reward_min: 385.8842333941167
total_envstep_count: 27778688
total_train_sample_count: 20815582
total_episode_count: 60893
total_duration: 5565.977705481159
[2023-06-29 15:11:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1617
train_sample_count: 1617
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 2745.017806488847
avg_train_sample_per_sec: 2745.017806488847
avg_episode_per_sec: 11.883193967484186
collect_time: 0.5890672170423205
reward_mean: 2181.7599759047403
reward_std: 1416.3716326946198
reward_max: 3437.8837914034175
reward_min: 235.49935250433103
total_envstep_count: 27783264
total_train_sample_count: 20818799
total_episode_count: 60900
total_duration: 5566.566772698202
[2023-06-29 15:11:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 201.83333333333334
avg_sample_per_episode: 201.83333333333334
avg_envstep_per_sec: 2278.2222725663037
avg_train_sample_per_sec: 2278.2222725663037
avg_episode_per_sec: 11.28764131742182
collect_time: 0.5315548068257049
reward_mean: 2003.688150513635
reward_std: 1370.9170918042114
reward_max: 3443.2163480467675
reward_min: 423.05913805781694
total_envstep_count: 27787080
total_train_sample_count: 20822010
total_episode_count: 60906
total_duration: 5567.098327505028
[2023-06-29 15:11:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 272.55555555555554
avg_sample_per_episode: 272.55555555555554
avg_envstep_per_sec: 2759.8293265738357
avg_train_sample_per_sec: 2759.8293265738357
avg_episode_per_sec: 10.125749669451498
collect_time: 0.8888230791594833
reward_mean: 2269.1193950131633
reward_std: 1016.7777791315098
reward_max: 3444.666108665012
reward_min: 811.1208341880129
total_envstep_count: 27791728
total_train_sample_count: 20825263
total_episode_count: 60915
total_duration: 5567.9871505841875
[2023-06-29 15:11:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2504
train_sample_count: 2504
avg_envstep_per_episode: 250.4
avg_sample_per_episode: 250.4
avg_envstep_per_sec: 2598.5493198104605
avg_train_sample_per_sec: 2598.5493198104605
avg_episode_per_sec: 10.377593130233468
collect_time: 0.9636145756058396
reward_mean: 1397.0313492500222
reward_std: 1000.1585133012642
reward_max: 3342.3353509819312
reward_min: 269.670146735923
total_envstep_count: 27796144
total_train_sample_count: 20828567
total_episode_count: 60925
total_duration: 5568.950765159793
[2023-06-29 15:11:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2027
train_sample_count: 2027
avg_envstep_per_episode: 168.91666666666666
avg_sample_per_episode: 168.91666666666666
avg_envstep_per_sec: 2613.357891508904
avg_train_sample_per_sec: 2613.357891508904
avg_episode_per_sec: 15.471285001532731
collect_time: 0.7756304663000628
reward_mean: 1087.1726100776345
reward_std: 1084.0366921807777
reward_max: 3406.1777420868057
reward_min: 237.4329818243516
total_envstep_count: 27800352
total_train_sample_count: 20831794
total_episode_count: 60937
total_duration: 5569.726395626093
[2023-06-29 15:11:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2789
train_sample_count: 2789
avg_envstep_per_episode: 199.21428571428572
avg_sample_per_episode: 199.21428571428572
avg_envstep_per_sec: 2405.4108044983896
avg_train_sample_per_sec: 2405.4108044983896
avg_episode_per_sec: 12.07448951702311
collect_time: 1.1594693076061084
reward_mean: 1221.4900025745906
reward_std: 851.5173780592497
reward_max: 3432.076156603922
reward_min: 244.75017147394433
total_envstep_count: 27805168
total_train_sample_count: 20835383
total_episode_count: 60951
total_duration: 5570.885864933699
[2023-06-29 15:11:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2017
train_sample_count: 2017
avg_envstep_per_episode: 224.11111111111111
avg_sample_per_episode: 224.11111111111111
avg_envstep_per_sec: 2453.833520754296
avg_train_sample_per_sec: 2453.833520754296
avg_episode_per_sec: 10.949182789682034
collect_time: 0.8219791534105315
reward_mean: 1403.5968115890582
reward_std: 1041.7495886232437
reward_max: 3401.018616185001
reward_min: 405.3339407519817
total_envstep_count: 27809800
total_train_sample_count: 20838600
total_episode_count: 60960
total_duration: 5571.707844087109
[2023-06-29 15:11:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1850
train_sample_count: 1850
avg_envstep_per_episode: 308.3333333333333
avg_sample_per_episode: 308.3333333333333
avg_envstep_per_sec: 2777.094732194197
avg_train_sample_per_sec: 2777.094732194197
avg_episode_per_sec: 9.006793726035234
collect_time: 0.6661638072887436
reward_mean: 2456.5250999766445
reward_std: 947.087921600158
reward_max: 3468.475463709968
reward_min: 830.9596330615369
total_envstep_count: 27813824
total_train_sample_count: 20842050
total_episode_count: 60966
total_duration: 5572.374007894398
[2023-06-29 15:11:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2029
train_sample_count: 2029
avg_envstep_per_episode: 202.9
avg_sample_per_episode: 202.9
avg_envstep_per_sec: 2793.0124007506606
avg_train_sample_per_sec: 2793.0124007506606
avg_episode_per_sec: 13.76546279325116
collect_time: 0.7264557792348786
reward_mean: 1381.0810697182737
reward_std: 1250.1029095713418
reward_max: 3453.1024222395044
reward_min: 409.7968495530863
total_envstep_count: 27818488
total_train_sample_count: 20845279
total_episode_count: 60976
total_duration: 5573.100463673633
[2023-06-29 15:11:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2463
train_sample_count: 2463
avg_envstep_per_episode: 307.875
avg_sample_per_episode: 307.875
avg_envstep_per_sec: 2571.3331551251877
avg_train_sample_per_sec: 2571.3331551251877
avg_episode_per_sec: 8.351873829070849
collect_time: 0.9578688763417305
reward_mean: 2166.682114502076
reward_std: 1187.258332330083
reward_max: 3450.1722784154863
reward_min: 554.7469480897347
total_envstep_count: 27822200
total_train_sample_count: 20848542
total_episode_count: 60984
total_duration: 5574.058332549975
[2023-06-29 15:11:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2007
train_sample_count: 2007
avg_envstep_per_episode: 250.875
avg_sample_per_episode: 250.875
avg_envstep_per_sec: 2640.2653424328882
avg_train_sample_per_sec: 2640.2653424328882
avg_episode_per_sec: 10.524226576713057
collect_time: 0.760150871105492
reward_mean: 1440.6721994211025
reward_std: 1068.2118110764138
reward_max: 3405.802708089538
reward_min: 402.47009272476726
total_envstep_count: 27826312
total_train_sample_count: 20851749
total_episode_count: 60992
total_duration: 5574.818483421081
[2023-06-29 15:11:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1264
train_sample_count: 1264
avg_envstep_per_episode: 252.8
avg_sample_per_episode: 252.8
avg_envstep_per_sec: 2727.3799964339014
avg_train_sample_per_sec: 2727.3799964339014
avg_episode_per_sec: 10.788686694754357
collect_time: 0.4634484383007512
reward_mean: 2032.3978811318436
reward_std: 846.7226362823326
reward_max: 3446.7358803834845
reward_min: 891.5749418192503
total_envstep_count: 27830200
total_train_sample_count: 20855013
total_episode_count: 60997
total_duration: 5575.281931859381
[2023-06-29 15:12:01][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1298
train_sample_count: 1298
avg_envstep_per_episode: 162.25
avg_sample_per_episode: 162.25
avg_envstep_per_sec: 2616.629375512762
avg_train_sample_per_sec: 2616.629375512762
avg_episode_per_sec: 16.127145611788983
collect_time: 0.49605802493356177
reward_mean: 1869.8682371399082
reward_std: 770.1094482190175
reward_max: 3407.3113930078443
reward_min: 632.7791287275624
total_envstep_count: 27834536
total_train_sample_count: 20858311
total_episode_count: 61005
total_duration: 5575.777989884315
[2023-06-29 15:12:04][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2431
train_sample_count: 2431
avg_envstep_per_episode: 347.2857142857143
avg_sample_per_episode: 347.2857142857143
avg_envstep_per_sec: 2696.788194854042
avg_train_sample_per_sec: 2696.788194854042
avg_episode_per_sec: 7.76533005511242
collect_time: 0.9014426882462576
reward_mean: 2595.0788143155246
reward_std: 959.3210005673336
reward_max: 3522.8824012550413
reward_min: 642.889782284661
total_envstep_count: 27838488
total_train_sample_count: 20861542
total_episode_count: 61012
total_duration: 5576.6794325725605
[2023-06-29 15:12:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 3517
train_sample_count: 3517
avg_envstep_per_episode: 390.77777777777777
avg_sample_per_episode: 390.77777777777777
avg_envstep_per_sec: 2588.664543813758
avg_train_sample_per_sec: 2588.664543813758
avg_episode_per_sec: 6.624390359489287
collect_time: 1.3586155874868857
reward_mean: 2077.568260610283
reward_std: 857.5160885372329
reward_max: 3513.87808306544
reward_min: 1178.2144144348229
total_envstep_count: 27843392
total_train_sample_count: 20865059
total_episode_count: 61021
total_duration: 5578.038048160048
[2023-06-29 15:12:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2212
train_sample_count: 2212
avg_envstep_per_episode: 316.0
avg_sample_per_episode: 316.0
avg_envstep_per_sec: 2674.9760908325193
avg_train_sample_per_sec: 2674.9760908325193
avg_episode_per_sec: 8.465114211495314
collect_time: 0.8269232788961379
reward_mean: 1719.6945845806617
reward_std: 278.0934112446057
reward_max: 2103.1885381322927
reward_min: 1336.2526601299962
total_envstep_count: 27848112
total_train_sample_count: 20868471
total_episode_count: 61028
total_duration: 5578.864971438944
[2023-06-29 15:12:15][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1527
train_sample_count: 1527
avg_envstep_per_episode: 218.14285714285714
avg_sample_per_episode: 218.14285714285714
avg_envstep_per_sec: 2377.492643151551
avg_train_sample_per_sec: 2377.492643151551
avg_episode_per_sec: 10.898787493163626
collect_time: 0.6422732808021828
reward_mean: 2013.4337245804725
reward_std: 726.0778706442399
reward_max: 3439.2758681705477
reward_min: 1315.2385793247017
total_envstep_count: 27853032
total_train_sample_count: 20871998
total_episode_count: 61035
total_duration: 5579.507244719746
[2023-06-29 15:12:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2313
train_sample_count: 2313
avg_envstep_per_episode: 289.125
avg_sample_per_episode: 289.125
avg_envstep_per_sec: 2373.4527201993787
avg_train_sample_per_sec: 2373.4527201993787
avg_episode_per_sec: 8.20908852641376
collect_time: 0.9745296294782311
reward_mean: 2570.6899710199805
reward_std: 835.4875155700993
reward_max: 3643.500379227647
reward_min: 1324.0956195085946
total_envstep_count: 27857904
total_train_sample_count: 20875511
total_episode_count: 61043
total_duration: 5580.481774349225
[2023-06-29 15:12:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1941
train_sample_count: 1941
avg_envstep_per_episode: 323.5
avg_sample_per_episode: 323.5
avg_envstep_per_sec: 2282.012084424791
avg_train_sample_per_sec: 2282.012084424791
avg_episode_per_sec: 7.054133182147731
collect_time: 0.8505651715202257
reward_mean: 2272.148174823407
reward_std: 711.5239740103327
reward_max: 3504.978174598953
reward_min: 1658.2030998201958
total_envstep_count: 27861984
total_train_sample_count: 20879052
total_episode_count: 61049
total_duration: 5581.332339520745
[2023-06-29 15:12:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1596
train_sample_count: 1596
avg_envstep_per_episode: 266.0
avg_sample_per_episode: 266.0
avg_envstep_per_sec: 2475.788313811262
avg_train_sample_per_sec: 2475.788313811262
avg_episode_per_sec: 9.307474863952113
collect_time: 0.644643159149215
reward_mean: 2511.208986082765
reward_std: 894.273041875454
reward_max: 3528.2223894910835
reward_min: 1569.896751693494
total_envstep_count: 27866256
total_train_sample_count: 20882648
total_episode_count: 61055
total_duration: 5581.976982679895
[2023-06-29 15:12:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2847
train_sample_count: 2847
avg_envstep_per_episode: 355.875
avg_sample_per_episode: 355.875
avg_envstep_per_sec: 2787.3278147286496
avg_train_sample_per_sec: 2787.3278147286496
avg_episode_per_sec: 7.8323226265645225
collect_time: 1.0214083843873814
reward_mean: 2513.9893739158624
reward_std: 824.2063172635704
reward_max: 3535.0080567338205
reward_min: 1490.554448767829
total_envstep_count: 27871472
total_train_sample_count: 20885895
total_episode_count: 61063
total_duration: 5582.998391064282
[2023-06-29 15:12:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 2753.959104087048
avg_train_sample_per_sec: 2753.959104087048
avg_episode_per_sec: 12.809112112032784
collect_time: 0.31227769458293914
reward_mean: 1946.5833621750005
reward_std: 913.2761701346836
reward_max: 3498.9823346880667
reward_min: 1205.204228142445
total_envstep_count: 27875576
total_train_sample_count: 20889155
total_episode_count: 61067
total_duration: 5583.310668758865
[2023-06-29 15:12:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1434
train_sample_count: 1434
avg_envstep_per_episode: 204.85714285714286
avg_sample_per_episode: 204.85714285714286
avg_envstep_per_sec: 2446.9209907374902
avg_train_sample_per_sec: 2446.9209907374902
avg_episode_per_sec: 11.944523664687887
collect_time: 0.5860426247632129
reward_mean: 2835.2885025755027
reward_std: 872.321531725527
reward_max: 3564.3355141398906
reward_min: 1283.7319378378434
total_envstep_count: 27879896
total_train_sample_count: 20892589
total_episode_count: 61074
total_duration: 5583.896711383629
[2023-06-29 15:12:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2054
train_sample_count: 2054
avg_envstep_per_episode: 256.75
avg_sample_per_episode: 256.75
avg_envstep_per_sec: 2568.5033357050092
avg_train_sample_per_sec: 2568.5033357050092
avg_episode_per_sec: 10.003907831372967
collect_time: 0.799687495611608
reward_mean: 1922.7893038381917
reward_std: 700.3067082315413
reward_max: 3425.937000386485
reward_min: 1270.1333938841583
total_envstep_count: 27884352
total_train_sample_count: 20895843
total_episode_count: 61082
total_duration: 5584.69639887924
[2023-06-29 15:12:39][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2153
train_sample_count: 2153
avg_envstep_per_episode: 307.57142857142856
avg_sample_per_episode: 307.57142857142856
avg_envstep_per_sec: 2596.059468566241
avg_train_sample_per_sec: 2596.059468566241
avg_episode_per_sec: 8.440509187163812
collect_time: 0.8293338523516431
reward_mean: 2533.162902490357
reward_std: 873.648153725152
reward_max: 3520.328450938399
reward_min: 1503.9978661396942
total_envstep_count: 27889280
total_train_sample_count: 20899196
total_episode_count: 61089
total_duration: 5585.525732731592
[2023-06-29 15:12:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2567
train_sample_count: 2567
avg_envstep_per_episode: 320.875
avg_sample_per_episode: 320.875
avg_envstep_per_sec: 2692.05006988746
avg_train_sample_per_sec: 2692.05006988746
avg_episode_per_sec: 8.389715839150634
collect_time: 0.9535483863074332
reward_mean: 2391.5379870513443
reward_std: 872.0748923981861
reward_max: 3509.1330193740223
reward_min: 741.1858646304527
total_envstep_count: 27893432
total_train_sample_count: 20902563
total_episode_count: 61097
total_duration: 5586.4792811178995
[2023-06-29 15:12:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1491
train_sample_count: 1491
avg_envstep_per_episode: 298.2
avg_sample_per_episode: 298.2
avg_envstep_per_sec: 2788.726974296305
avg_train_sample_per_sec: 2788.726974296305
avg_episode_per_sec: 9.351867787713966
collect_time: 0.534652554281056
reward_mean: 2044.1346174724308
reward_std: 721.8186165052771
reward_max: 2922.2922913941657
reward_min: 1099.864309376962
total_envstep_count: 27898624
total_train_sample_count: 20906054
total_episode_count: 61102
total_duration: 5587.01393367218
[2023-06-29 15:12:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1302
train_sample_count: 1302
avg_envstep_per_episode: 217.0
avg_sample_per_episode: 217.0
avg_envstep_per_sec: 2554.243553010784
avg_train_sample_per_sec: 2554.243553010784
avg_episode_per_sec: 11.770707617561216
collect_time: 0.5097399574387819
reward_mean: 2911.01550688188
reward_std: 802.803496149345
reward_max: 3644.1984148362544
reward_min: 1690.2370757824542
total_envstep_count: 27903184
total_train_sample_count: 20909356
total_episode_count: 61108
total_duration: 5587.523673629619
[2023-06-29 15:12:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1375
train_sample_count: 1375
avg_envstep_per_episode: 196.42857142857142
avg_sample_per_episode: 196.42857142857142
avg_envstep_per_sec: 2383.696760642246
avg_train_sample_per_sec: 2383.696760642246
avg_episode_per_sec: 12.135183508724161
collect_time: 0.5768351170765236
reward_mean: 2486.01010342606
reward_std: 775.4454804839243
reward_max: 3525.606102750629
reward_min: 1639.3166873340942
total_envstep_count: 27907400
total_train_sample_count: 20912731
total_episode_count: 61115
total_duration: 5588.100508746696
[2023-06-29 15:12:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1780
train_sample_count: 1780
avg_envstep_per_episode: 254.28571428571428
avg_sample_per_episode: 254.28571428571428
avg_envstep_per_sec: 2759.4998185892905
avg_train_sample_per_sec: 2759.4998185892905
avg_episode_per_sec: 10.851965578721929
collect_time: 0.645044434505515
reward_mean: 2284.839018974987
reward_std: 838.3286238454498
reward_max: 3558.238953322818
reward_min: 1380.82200967752
total_envstep_count: 27911992
total_train_sample_count: 20916111
total_episode_count: 61122
total_duration: 5588.745553181201
[2023-06-29 15:12:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2009
train_sample_count: 2009
avg_envstep_per_episode: 223.22222222222223
avg_sample_per_episode: 223.22222222222223
avg_envstep_per_sec: 2689.0323817414082
avg_train_sample_per_sec: 2689.0323817414082
avg_episode_per_sec: 12.04643675245031
collect_time: 0.7471088907821104
reward_mean: 1894.9183932543888
reward_std: 735.285267324356
reward_max: 3484.248944936207
reward_min: 879.5410087932036
total_envstep_count: 27916368
total_train_sample_count: 20919320
total_episode_count: 61131
total_duration: 5589.492662071983
[2023-06-29 15:13:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 4
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 2793.705725195912
avg_train_sample_per_sec: 2793.705725195912
avg_episode_per_sec: 13.177857194320339
collect_time: 0.3035394860496744
reward_mean: 2341.6083609479842
reward_std: 901.0546295611146
reward_max: 3443.837496812042
reward_min: 1266.1384613896075
total_envstep_count: 27920432
total_train_sample_count: 20922568
total_episode_count: 61135
total_duration: 5589.796201558033
[2023-06-29 15:13:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2407
train_sample_count: 2407
avg_envstep_per_episode: 240.7
avg_sample_per_episode: 240.7
avg_envstep_per_sec: 2680.180740691286
avg_train_sample_per_sec: 2680.180740691286
avg_episode_per_sec: 11.134942836274556
collect_time: 0.8980737617639826
reward_mean: 2296.542422730744
reward_std: 1036.1756531809426
reward_max: 3644.0656916188236
reward_min: 557.2977677018879
total_envstep_count: 27925168
total_train_sample_count: 20925775
total_episode_count: 61145
total_duration: 5590.694275319797
[2023-06-29 15:13:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 6
envstep_count: 1548
train_sample_count: 1548
avg_envstep_per_episode: 258.0
avg_sample_per_episode: 258.0
avg_envstep_per_sec: 2457.8283582881245
avg_train_sample_per_sec: 2457.8283582881245
avg_episode_per_sec: 9.526466504992731
collect_time: 0.6298242897149176
reward_mean: 2139.1606760411037
reward_std: 745.8805915083514
reward_max: 3505.4514613433016
reward_min: 1333.3381018111497
total_envstep_count: 27929824
total_train_sample_count: 20929323
total_episode_count: 61151
total_duration: 5591.324099609512
[2023-06-29 15:13:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1705
train_sample_count: 1705
avg_envstep_per_episode: 170.5
avg_sample_per_episode: 170.5
avg_envstep_per_sec: 2723.864117876201
avg_train_sample_per_sec: 2723.864117876201
avg_episode_per_sec: 15.975742626839889
collect_time: 0.6259489923929795
reward_mean: 1595.8559499407852
reward_std: 756.0281273958999
reward_max: 2974.486937125479
reward_min: 515.7567778046817
total_envstep_count: 27933880
total_train_sample_count: 20932628
total_episode_count: 61161
total_duration: 5591.950048601905
[2023-06-29 15:13:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3368
train_sample_count: 3368
avg_envstep_per_episode: 280.6666666666667
avg_sample_per_episode: 280.6666666666667
avg_envstep_per_sec: 2780.4976516989195
avg_train_sample_per_sec: 2780.4976516989195
avg_episode_per_sec: 9.906761229331067
collect_time: 1.2112939559370277
reward_mean: 1788.0513826283316
reward_std: 667.6191279041857
reward_max: 3032.7949284924243
reward_min: 1153.295289141487
total_envstep_count: 27938656
total_train_sample_count: 20935996
total_episode_count: 61173
total_duration: 5593.1613425578425
[2023-06-29 15:13:17][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 1537
train_sample_count: 1537
avg_envstep_per_episode: 307.4
avg_sample_per_episode: 307.4
avg_envstep_per_sec: 2573.1749144785003
avg_train_sample_per_sec: 2573.1749144785003
avg_episode_per_sec: 8.370770704224139
collect_time: 0.5973165645878762
reward_mean: 1482.8006204903065
reward_std: 330.78627626110784
reward_max: 2063.773895661648
reward_min: 1209.7829795547702
total_envstep_count: 27943448
total_train_sample_count: 20939533
total_episode_count: 61178
total_duration: 5593.758659122431
[2023-06-29 15:13:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 1757
train_sample_count: 1757
avg_envstep_per_episode: 175.7
avg_sample_per_episode: 175.7
avg_envstep_per_sec: 2286.975688383863
avg_train_sample_per_sec: 2286.975688383863
avg_episode_per_sec: 13.016367036903036
collect_time: 0.7682635232741013
reward_mean: 1945.9956164394837
reward_std: 1091.810381585684
reward_max: 3584.102320868753
reward_min: 558.221160378225
total_envstep_count: 27947552
total_train_sample_count: 20942890
total_episode_count: 61188
total_duration: 5594.526922645705
[2023-06-29 15:13:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2489
train_sample_count: 2489
avg_envstep_per_episode: 276.55555555555554
avg_sample_per_episode: 276.55555555555554
avg_envstep_per_sec: 2471.1830416269127
avg_train_sample_per_sec: 2471.1830416269127
avg_episode_per_sec: 8.935575481977587
collect_time: 1.0072098901914435
reward_mean: 1893.705367189982
reward_std: 550.8640708699006
reward_max: 2649.0673299745667
reward_min: 1191.491462002164
total_envstep_count: 27951888
total_train_sample_count: 20946179
total_episode_count: 61197
total_duration: 5595.534132535896
[2023-06-29 15:13:25][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3392
train_sample_count: 3392
avg_envstep_per_episode: 282.6666666666667
avg_sample_per_episode: 282.6666666666667
avg_envstep_per_sec: 2637.65038642323
avg_train_sample_per_sec: 2637.65038642323
avg_episode_per_sec: 9.331310329327465
collect_time: 1.285993025254458
reward_mean: 1614.4421960657721
reward_std: 672.1074063439303
reward_max: 3433.009541508729
reward_min: 926.5176062300982
total_envstep_count: 27956416
total_train_sample_count: 20949571
total_episode_count: 61209
total_duration: 5596.82012556115
[2023-06-29 15:13:28][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3050
train_sample_count: 3050
avg_envstep_per_episode: 254.16666666666666
avg_sample_per_episode: 254.16666666666666
avg_envstep_per_sec: 2760.8275656254405
avg_train_sample_per_sec: 2760.8275656254405
avg_episode_per_sec: 10.862272389345996
collect_time: 1.1047412152700127
reward_mean: 1200.5324669153144
reward_std: 361.3163800699657
reward_max: 1816.8084264380836
reward_min: 533.0515793284726
total_envstep_count: 27961248
total_train_sample_count: 20953021
total_episode_count: 61221
total_duration: 5597.9248667764205
[2023-06-29 15:13:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2800
train_sample_count: 2800
avg_envstep_per_episode: 254.54545454545453
avg_sample_per_episode: 254.54545454545453
avg_envstep_per_sec: 2586.625424350514
avg_train_sample_per_sec: 2586.625424350514
avg_episode_per_sec: 10.161742738519877
collect_time: 1.0824914862588049
reward_mean: 1487.1663681659845
reward_std: 417.2558303879298
reward_max: 2596.9165020031955
reward_min: 1162.886478553302
total_envstep_count: 27964864
total_train_sample_count: 20956221
total_episode_count: 61232
total_duration: 5599.007358262679
[2023-06-29 15:13:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3317
train_sample_count: 3317
avg_envstep_per_episode: 301.54545454545456
avg_sample_per_episode: 301.54545454545456
avg_envstep_per_sec: 2571.9646647321
avg_train_sample_per_sec: 2571.9646647321
avg_episode_per_sec: 8.529276850181821
collect_time: 1.2896755719408393
reward_mean: 1313.7435048129926
reward_std: 363.5745486326915
reward_max: 2002.4650705497788
reward_min: 541.6279148403644
total_envstep_count: 27969816
total_train_sample_count: 20959538
total_episode_count: 61243
total_duration: 5600.29703383462
[2023-06-29 15:13:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1630
train_sample_count: 1630
avg_envstep_per_episode: 203.75
avg_sample_per_episode: 203.75
avg_envstep_per_sec: 2739.916584170037
avg_train_sample_per_sec: 2739.916584170037
avg_episode_per_sec: 13.447443357889751
collect_time: 0.5949086221884935
reward_mean: 1344.1681647667651
reward_std: 138.33096636825115
reward_max: 1563.9596685871213
reward_min: 1182.861975815072
total_envstep_count: 27974120
total_train_sample_count: 20962768
total_episode_count: 61251
total_duration: 5600.8919424568085
[2023-06-29 15:13:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2021
train_sample_count: 2021
avg_envstep_per_episode: 202.1
avg_sample_per_episode: 202.1
avg_envstep_per_sec: 2783.291069100633
avg_train_sample_per_sec: 2783.291069100633
avg_episode_per_sec: 13.771850910938314
collect_time: 0.7261188103668392
reward_mean: 1725.1990779806679
reward_std: 600.8060988986598
reward_max: 3046.5398685883138
reward_min: 1173.0914462261392
total_envstep_count: 27978560
total_train_sample_count: 20965989
total_episode_count: 61261
total_duration: 5601.618061267175
[2023-06-29 15:13:43][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2092
train_sample_count: 2092
avg_envstep_per_episode: 209.2
avg_sample_per_episode: 209.2
avg_envstep_per_sec: 2515.2312761061758
avg_train_sample_per_sec: 2515.2312761061758
avg_episode_per_sec: 12.023094054044817
collect_time: 0.8317326600831001
reward_mean: 1595.6086717368007
reward_std: 436.22382768809865
reward_max: 2576.016295439684
reward_min: 1027.8069601785205
total_envstep_count: 27983304
total_train_sample_count: 20969281
total_episode_count: 61271
total_duration: 5602.449793927258
[2023-06-29 15:13:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3076
train_sample_count: 3076
avg_envstep_per_episode: 236.6153846153846
avg_sample_per_episode: 236.6153846153846
avg_envstep_per_sec: 2473.955572052935
avg_train_sample_per_sec: 2473.955572052935
avg_episode_per_sec: 10.455598971615135
collect_time: 1.2433529667016119
reward_mean: 1552.2361148326552
reward_std: 270.1098241110762
reward_max: 2155.17411241606
reward_min: 1281.1027815335942
total_envstep_count: 27988224
total_train_sample_count: 20972757
total_episode_count: 61284
total_duration: 5603.693146893959
[2023-06-29 15:13:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3405
train_sample_count: 3405
avg_envstep_per_episode: 283.75
avg_sample_per_episode: 283.75
avg_envstep_per_sec: 2455.79130880272
avg_train_sample_per_sec: 2455.79130880272
avg_episode_per_sec: 8.654771132344388
collect_time: 1.386518466693349
reward_mean: 1525.0008316674637
reward_std: 473.7196423307327
reward_max: 2568.7363872287087
reward_min: 834.6193539077213
total_envstep_count: 27993088
total_train_sample_count: 20976162
total_episode_count: 61296
total_duration: 5605.079665360652
[2023-06-29 15:13:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3194
train_sample_count: 3194
avg_envstep_per_episode: 290.3636363636364
avg_sample_per_episode: 290.3636363636364
avg_envstep_per_sec: 2663.1291082459456
avg_train_sample_per_sec: 2663.1291082459456
avg_episode_per_sec: 9.17170325319518
collect_time: 1.1993410271061584
reward_mean: 1477.5199706002284
reward_std: 242.1672463489828
reward_max: 1873.8560023664013
reward_min: 1179.0158012803877
total_envstep_count: 27998192
total_train_sample_count: 20979756
total_episode_count: 61307
total_duration: 5606.279006387758
[2023-06-29 15:13:56][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2139
train_sample_count: 2139
avg_envstep_per_episode: 213.9
avg_sample_per_episode: 213.9
avg_envstep_per_sec: 2598.4455106778637
avg_train_sample_per_sec: 2598.4455106778637
avg_episode_per_sec: 12.147945351462665
collect_time: 0.8231844736440107
reward_mean: 1297.657099620116
reward_std: 403.40416712044504
reward_max: 2063.7919387057964
reward_min: 407.5567667522038
total_envstep_count: 28002416
total_train_sample_count: 20983095
total_episode_count: 61317
total_duration: 5607.102190861402
[2023-06-29 15:13:59][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2023
train_sample_count: 2023
avg_envstep_per_episode: 252.875
avg_sample_per_episode: 252.875
avg_envstep_per_sec: 2380.9345882423177
avg_train_sample_per_sec: 2380.9345882423177
avg_episode_per_sec: 9.41546055656873
collect_time: 0.849666349504143
reward_mean: 1898.5968263976322
reward_std: 678.9094059386452
reward_max: 3465.978222545371
reward_min: 1231.9457239199487
total_envstep_count: 28007200
total_train_sample_count: 20986318
total_episode_count: 61325
total_duration: 5607.951857210906
[2023-06-29 15:14:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2448
train_sample_count: 2448
avg_envstep_per_episode: 222.54545454545453
avg_sample_per_episode: 222.54545454545453
avg_envstep_per_sec: 2417.518372325829
avg_train_sample_per_sec: 2417.518372325829
avg_episode_per_sec: 10.863031901790897
collect_time: 1.0126086436500772
reward_mean: 1498.1390674415184
reward_std: 809.663554831706
reward_max: 3287.547677300074
reward_min: 467.5507365292043
total_envstep_count: 28011848
total_train_sample_count: 20989566
total_episode_count: 61336
total_duration: 5608.964465854557
[2023-06-29 15:14:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2443
train_sample_count: 2443
avg_envstep_per_episode: 222.0909090909091
avg_sample_per_episode: 222.0909090909091
avg_envstep_per_sec: 2675.954114979271
avg_train_sample_per_sec: 2675.954114979271
avg_episode_per_sec: 12.04891332982889
collect_time: 0.912945400044322
reward_mean: 1523.86834579469
reward_std: 812.7233825380418
reward_max: 3470.0419625707136
reward_min: 530.2590428511909
total_envstep_count: 28015824
total_train_sample_count: 20992809
total_episode_count: 61347
total_duration: 5609.877411254601
[2023-06-29 15:14:09][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3315
train_sample_count: 3315
avg_envstep_per_episode: 276.25
avg_sample_per_episode: 276.25
avg_envstep_per_sec: 2762.721615803861
avg_train_sample_per_sec: 2762.721615803861
avg_episode_per_sec: 10.000802229154248
collect_time: 1.1999037402237303
reward_mean: 1442.4487720453099
reward_std: 682.6712783071523
reward_max: 3407.6558081919156
reward_min: 510.9133192364405
total_envstep_count: 28020488
total_train_sample_count: 20996124
total_episode_count: 61359
total_duration: 5611.0773149948245
[2023-06-29 15:14:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2571
train_sample_count: 2571
avg_envstep_per_episode: 257.1
avg_sample_per_episode: 257.1
avg_envstep_per_sec: 2495.5498445113235
avg_train_sample_per_sec: 2495.5498445113235
avg_episode_per_sec: 9.70653381762475
collect_time: 1.0302338803829627
reward_mean: 1360.4130029963362
reward_std: 245.1702768229251
reward_max: 1885.2640602419622
reward_min: 1047.9627790455156
total_envstep_count: 28024880
total_train_sample_count: 20999495
total_episode_count: 61369
total_duration: 5612.107548875208
[2023-06-29 15:14:14][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3295
train_sample_count: 3295
avg_envstep_per_episode: 299.54545454545456
avg_sample_per_episode: 299.54545454545456
avg_envstep_per_sec: 2497.369645559055
avg_train_sample_per_sec: 2497.369645559055
avg_episode_per_sec: 8.337197602776815
collect_time: 1.3193881834270431
reward_mean: 1620.3503190606345
reward_std: 667.4382392995155
reward_max: 3435.3489931578865
reward_min: 1085.095222714398
total_envstep_count: 28029128
total_train_sample_count: 21002790
total_episode_count: 61380
total_duration: 5613.426937058634
[2023-06-29 15:14:18][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3416
train_sample_count: 3416
avg_envstep_per_episode: 310.54545454545456
avg_sample_per_episode: 310.54545454545456
avg_envstep_per_sec: 2721.2798748498353
avg_train_sample_per_sec: 2721.2798748498353
avg_episode_per_sec: 8.762903578263522
collect_time: 1.2552916851995977
reward_mean: 1401.8791632707164
reward_std: 357.2547321325482
reward_max: 2232.5055600974215
reward_min: 1070.4030835765168
total_envstep_count: 28033976
total_train_sample_count: 21006206
total_episode_count: 61391
total_duration: 5614.682228743834
[2023-06-29 15:14:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2092
train_sample_count: 2092
avg_envstep_per_episode: 209.2
avg_sample_per_episode: 209.2
avg_envstep_per_sec: 2537.1971240461808
avg_train_sample_per_sec: 2537.1971240461808
avg_episode_per_sec: 12.128093327180597
collect_time: 0.8245319136511533
reward_mean: 1208.571594472501
reward_std: 254.1221162255093
reward_max: 1502.6158170154322
reward_min: 534.396257203137
total_envstep_count: 28038328
total_train_sample_count: 21009498
total_episode_count: 61401
total_duration: 5615.506760657485
[2023-06-29 15:14:24][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2522
train_sample_count: 2522
avg_envstep_per_episode: 252.2
avg_sample_per_episode: 252.2
avg_envstep_per_sec: 2454.4518265623233
avg_train_sample_per_sec: 2454.4518265623233
avg_episode_per_sec: 9.732164260754653
collect_time: 1.027520675984211
reward_mean: 1675.4199681811194
reward_std: 655.7269616227876
reward_max: 3479.674576265659
reward_min: 1109.1385012255405
total_envstep_count: 28042424
total_train_sample_count: 21012820
total_episode_count: 61411
total_duration: 5616.534281333469
[2023-06-29 15:14:27][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 3535
train_sample_count: 3535
avg_envstep_per_episode: 271.9230769230769
avg_sample_per_episode: 271.9230769230769
avg_envstep_per_sec: 2561.701091503245
avg_train_sample_per_sec: 2561.701091503245
avg_episode_per_sec: 9.420682939050124
collect_time: 1.3799424186237155
reward_mean: 1360.6510251503253
reward_std: 226.670161384309
reward_max: 1729.4321188081844
reward_min: 911.8433013457494
total_envstep_count: 28047304
total_train_sample_count: 21016355
total_episode_count: 61424
total_duration: 5617.914223752093
[2023-06-29 15:14:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2427
train_sample_count: 2427
avg_envstep_per_episode: 220.63636363636363
avg_sample_per_episode: 220.63636363636363
avg_envstep_per_sec: 2572.6651803532636
avg_train_sample_per_sec: 2572.6651803532636
avg_episode_per_sec: 11.660204772923734
collect_time: 0.9433796587812248
reward_mean: 1154.580161344863
reward_std: 243.37000770622453
reward_max: 1492.965627057222
reward_min: 458.4826686466462
total_envstep_count: 28051776
total_train_sample_count: 21019582
total_episode_count: 61435
total_duration: 5618.857603410874
[2023-06-29 15:14:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2895
train_sample_count: 2895
avg_envstep_per_episode: 263.1818181818182
avg_sample_per_episode: 263.1818181818182
avg_envstep_per_sec: 2715.6766348410806
avg_train_sample_per_sec: 2715.6766348410806
avg_episode_per_sec: 10.318633154836576
collect_time: 1.0660326648829503
reward_mean: 1431.8697991530325
reward_std: 223.5262491217677
reward_max: 1822.8602524939645
reward_min: 1040.1958364437562
total_envstep_count: 28056264
total_train_sample_count: 21022877
total_episode_count: 61446
total_duration: 5619.923636075757
[2023-06-29 15:14:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3042
train_sample_count: 3042
avg_envstep_per_episode: 276.54545454545456
avg_sample_per_episode: 276.54545454545456
avg_envstep_per_sec: 2469.430846159624
avg_train_sample_per_sec: 2469.430846159624
avg_episode_per_sec: 8.929565847388513
collect_time: 1.2318628013944253
reward_mean: 1597.3278016154952
reward_std: 679.5370751527208
reward_max: 3465.3600746225447
reward_min: 925.6500449781856
total_envstep_count: 28060976
total_train_sample_count: 21026319
total_episode_count: 61457
total_duration: 5621.155498877151
[2023-06-29 15:14:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2289
train_sample_count: 2289
avg_envstep_per_episode: 254.33333333333334
avg_sample_per_episode: 254.33333333333334
avg_envstep_per_sec: 2484.5087778830307
avg_train_sample_per_sec: 2484.5087778830307
avg_episode_per_sec: 9.768710791152152
collect_time: 0.9213088802006095
reward_mean: 1389.5736769804153
reward_std: 167.31430493219653
reward_max: 1667.3650328829183
reward_min: 1161.208713640505
total_envstep_count: 28065616
total_train_sample_count: 21029808
total_episode_count: 61466
total_duration: 5622.076807757352
[2023-06-29 15:14:42][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1774
train_sample_count: 1774
avg_envstep_per_episode: 221.75
avg_sample_per_episode: 221.75
avg_envstep_per_sec: 2401.44220835107
avg_train_sample_per_sec: 2401.44220835107
avg_episode_per_sec: 10.829502630669989
collect_time: 0.7387227532817049
reward_mean: 1974.1716258928195
reward_std: 684.1235068627309
reward_max: 3503.495293652632
reward_min: 1311.2140949935942
total_envstep_count: 28069632
total_train_sample_count: 21033182
total_episode_count: 61474
total_duration: 5622.815530510634
[2023-06-29 15:14:45][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 1979
train_sample_count: 1979
avg_envstep_per_episode: 247.375
avg_sample_per_episode: 247.375
avg_envstep_per_sec: 2760.6643902025585
avg_train_sample_per_sec: 2760.6643902025585
avg_episode_per_sec: 11.15983583709978
collect_time: 0.7168564230492337
reward_mean: 1890.3539693527557
reward_std: 578.8315967724565
reward_max: 2834.8692302048157
reward_min: 1153.0646749979003
total_envstep_count: 28074248
total_train_sample_count: 21036761
total_episode_count: 61482
total_duration: 5623.5323869336835
[2023-06-29 15:14:49][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2280
train_sample_count: 2280
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 2750.2841147571576
avg_train_sample_per_sec: 2750.2841147571576
avg_episode_per_sec: 12.062649626127884
collect_time: 0.8290052608624101
reward_mean: 1711.5755941332347
reward_std: 533.7708501585698
reward_max: 2659.9469658406424
reward_min: 963.0097615896454
total_envstep_count: 28078904
total_train_sample_count: 21040241
total_episode_count: 61492
total_duration: 5624.361392194546
[2023-06-29 15:14:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2650
train_sample_count: 2650
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 2596.1408633157857
avg_train_sample_per_sec: 2596.1408633157857
avg_episode_per_sec: 9.796757974776549
collect_time: 1.0207458452833817
reward_mean: 1693.1865664557195
reward_std: 768.4002461658721
reward_max: 3326.313765713361
reward_min: 427.2420582527051
total_envstep_count: 28082888
total_train_sample_count: 21043691
total_episode_count: 61502
total_duration: 5625.382138039829
[2023-06-29 15:14:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3038
train_sample_count: 3038
avg_envstep_per_episode: 379.75
avg_sample_per_episode: 379.75
avg_envstep_per_sec: 2564.9732701905955
avg_train_sample_per_sec: 2564.9732701905955
avg_episode_per_sec: 6.754373325057526
collect_time: 1.1844178008818997
reward_mean: 1982.7683569125936
reward_std: 963.315571188082
reward_max: 3581.4502799439283
reward_min: 882.0296119283046
total_envstep_count: 28088208
total_train_sample_count: 21047129
total_episode_count: 61510
total_duration: 5626.566555840712
[2023-06-29 15:14:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1700
train_sample_count: 1700
avg_envstep_per_episode: 242.85714285714286
avg_sample_per_episode: 242.85714285714286
avg_envstep_per_sec: 2727.267268722358
avg_train_sample_per_sec: 2727.267268722358
avg_episode_per_sec: 11.229924047680298
collect_time: 0.6233345809178426
reward_mean: 1895.5679009377363
reward_std: 742.3595772408928
reward_max: 3237.5158721134158
reward_min: 998.1776949729358
total_envstep_count: 28092472
total_train_sample_count: 21050429
total_episode_count: 61517
total_duration: 5627.18989042163
[2023-06-29 15:15:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 3
envstep_count: 820
train_sample_count: 820
avg_envstep_per_episode: 273.3333333333333
avg_sample_per_episode: 273.3333333333333
avg_envstep_per_sec: 2778.557647839645
avg_train_sample_per_sec: 2778.557647839645
avg_episode_per_sec: 10.165454809169432
collect_time: 0.2951171449106186
reward_mean: 2966.732628488418
reward_std: 451.31978444890325
reward_max: 3556.0867135714143
reward_min: 2459.851336344102
total_envstep_count: 28095992
total_train_sample_count: 21053649
total_episode_count: 61520
total_duration: 5627.48500756654
[2023-06-29 15:15:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2408
train_sample_count: 2408
avg_envstep_per_episode: 240.8
avg_sample_per_episode: 240.8
avg_envstep_per_sec: 2516.217633408278
avg_train_sample_per_sec: 2516.217633408278
avg_episode_per_sec: 10.449408776612449
collect_time: 0.9569919422026725
reward_mean: 2129.7332120030615
reward_std: 1053.5365383093942
reward_max: 3473.9515100427775
reward_min: 553.0463051553332
total_envstep_count: 28100160
total_train_sample_count: 21056857
total_episode_count: 61530
total_duration: 5628.441999508743
[2023-06-29 15:15:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 2044
train_sample_count: 2044
avg_envstep_per_episode: 292.0
avg_sample_per_episode: 292.0
avg_envstep_per_sec: 2403.88137505899
avg_train_sample_per_sec: 2403.88137505899
avg_episode_per_sec: 8.232470462530788
collect_time: 0.8502915415074678
reward_mean: 1892.6152080335362
reward_std: 787.429495383373
reward_max: 3450.918908351501
reward_min: 1054.178566456615
total_envstep_count: 28104856
total_train_sample_count: 21060101
total_episode_count: 61537
total_duration: 5629.29229105025
[2023-06-29 15:15:10][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 3340
train_sample_count: 3340
avg_envstep_per_episode: 303.6363636363636
avg_sample_per_episode: 303.6363636363636
avg_envstep_per_sec: 2785.9712632682604
avg_train_sample_per_sec: 2785.9712632682604
avg_episode_per_sec: 9.17535445986553
collect_time: 1.1988637657668446
reward_mean: 1939.0252929607611
reward_std: 895.8128577531755
reward_max: 3578.939465582427
reward_min: 543.1680751914474
total_envstep_count: 28109656
total_train_sample_count: 21063441
total_episode_count: 61548
total_duration: 5630.491154816017
[2023-06-29 15:15:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2670
train_sample_count: 2670
avg_envstep_per_episode: 242.72727272727272
avg_sample_per_episode: 242.72727272727272
avg_envstep_per_sec: 2738.3670456426926
avg_train_sample_per_sec: 2738.3670456426926
avg_episode_per_sec: 11.281661985793866
collect_time: 0.9750336443204431
reward_mean: 1248.962072047443
reward_std: 385.5207144267141
reward_max: 1964.7261571087251
reward_min: 222.81844866929302
total_envstep_count: 28114224
total_train_sample_count: 21066911
total_episode_count: 61559
total_duration: 5631.466188460337
[2023-06-29 15:15:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2812
train_sample_count: 2812
avg_envstep_per_episode: 255.63636363636363
avg_sample_per_episode: 255.63636363636363
avg_envstep_per_sec: 2618.297540370843
avg_train_sample_per_sec: 2618.297540370843
avg_episode_per_sec: 10.2422734509528
collect_time: 1.0739803084418442
reward_mean: 1490.0006990759218
reward_std: 716.8419175193577
reward_max: 3137.1785047312
reward_min: 238.16769402987762
total_envstep_count: 28119351
total_train_sample_count: 21070123
total_episode_count: 61570
total_duration: 5632.540168768779
[2023-06-29 15:15:20][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 204.7
avg_sample_per_episode: 204.7
avg_envstep_per_sec: 2703.6888280810335
avg_train_sample_per_sec: 2703.6888280810335
avg_episode_per_sec: 13.20805485139733
collect_time: 0.7571137546375394
reward_mean: 1413.8862284663915
reward_std: 444.45160005201666
reward_max: 2009.295666508756
reward_min: 423.360132566015
total_envstep_count: 28123751
total_train_sample_count: 21073370
total_episode_count: 61580
total_duration: 5633.2972825234165
[2023-06-29 15:15:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2307
train_sample_count: 2307
avg_envstep_per_episode: 230.7
avg_sample_per_episode: 230.7
avg_envstep_per_sec: 2499.062154630862
avg_train_sample_per_sec: 2499.062154630862
avg_episode_per_sec: 10.832519092461474
collect_time: 0.9231463073957711
reward_mean: 1590.5402211820772
reward_std: 556.409346739066
reward_max: 2949.7983149016036
reward_min: 1174.0896159785825
total_envstep_count: 28128543
total_train_sample_count: 21076877
total_episode_count: 61590
total_duration: 5634.220428830812
[2023-06-29 15:15:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2100
train_sample_count: 2100
avg_envstep_per_episode: 210.0
avg_sample_per_episode: 210.0
avg_envstep_per_sec: 2748.743296396295
avg_train_sample_per_sec: 2748.743296396295
avg_episode_per_sec: 13.08925379236331
collect_time: 0.7639854921167714
reward_mean: 1600.9601459511891
reward_std: 772.4341206734712
reward_max: 3399.5653018821245
reward_min: 420.2492297510755
total_envstep_count: 28133231
total_train_sample_count: 21080177
total_episode_count: 61600
total_duration: 5634.984414322929
[2023-06-29 15:15:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2811
train_sample_count: 2811
avg_envstep_per_episode: 255.54545454545453
avg_sample_per_episode: 255.54545454545453
avg_envstep_per_sec: 2570.71361801616
avg_train_sample_per_sec: 2570.71361801616
avg_episode_per_sec: 10.059711774520725
collect_time: 1.0934706924567004
reward_mean: 1811.9885398171411
reward_std: 882.7414543600164
reward_max: 3428.411833120978
reward_min: 477.5106540900548
total_envstep_count: 28137359
total_train_sample_count: 21083388
total_episode_count: 61611
total_duration: 5636.077885015386
[2023-06-29 15:15:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2453
train_sample_count: 2453
avg_envstep_per_episode: 272.55555555555554
avg_sample_per_episode: 272.55555555555554
avg_envstep_per_sec: 2620.5678617546714
avg_train_sample_per_sec: 2620.5678617546714
avg_episode_per_sec: 9.614802591028146
collect_time: 0.9360566600086166
reward_mean: 1392.2141776804601
reward_std: 515.5145658774697
reward_max: 2443.1485039885742
reward_min: 666.6542441744758
total_envstep_count: 28141911
total_train_sample_count: 21086641
total_episode_count: 61620
total_duration: 5637.013941675395
[2023-06-29 15:15:36][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2130
train_sample_count: 2130
avg_envstep_per_episode: 266.25
avg_sample_per_episode: 266.25
avg_envstep_per_sec: 2610.4738760032055
avg_train_sample_per_sec: 2610.4738760032055
avg_episode_per_sec: 9.804596717382932
collect_time: 0.8159438098883256
reward_mean: 1813.4905852154889
reward_std: 754.691092258861
reward_max: 3213.318098516601
reward_min: 1249.3036536991078
total_envstep_count: 28147039
total_train_sample_count: 21089971
total_episode_count: 61628
total_duration: 5637.829885485283
[2023-06-29 15:15:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2872
train_sample_count: 2872
avg_envstep_per_episode: 220.92307692307693
avg_sample_per_episode: 220.92307692307693
avg_envstep_per_sec: 2706.4177600255503
avg_train_sample_per_sec: 2706.4177600255503
avg_episode_per_sec: 12.250498217385847
collect_time: 1.0611813306948172
reward_mean: 1661.5825735153533
reward_std: 822.3233636324477
reward_max: 3536.141939147212
reward_min: 907.3849155025391
total_envstep_count: 28151255
total_train_sample_count: 21093243
total_episode_count: 61641
total_duration: 5638.891066815978
[2023-06-29 15:15:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 1852
train_sample_count: 1852
avg_envstep_per_episode: 264.57142857142856
avg_sample_per_episode: 264.57142857142856
avg_envstep_per_sec: 2622.5578811005316
avg_train_sample_per_sec: 2622.5578811005316
avg_episode_per_sec: 9.912475792496611
collect_time: 0.7061807914122473
reward_mean: 1533.3515238709676
reward_std: 418.21920346613257
reward_max: 2259.3251164630005
reward_min: 1087.2588741300451
total_envstep_count: 28155703
total_train_sample_count: 21096695
total_episode_count: 61648
total_duration: 5639.59724760739
[2023-06-29 15:15:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2649
train_sample_count: 2649
avg_envstep_per_episode: 331.125
avg_sample_per_episode: 331.125
avg_envstep_per_sec: 2403.1500213611107
avg_train_sample_per_sec: 2403.1500213611107
avg_episode_per_sec: 7.257531208338575
collect_time: 1.1023032172163947
reward_mean: 2207.2611059494684
reward_std: 987.5540226950465
reward_max: 3527.9676570655674
reward_min: 955.8131911974988
total_envstep_count: 28160951
total_train_sample_count: 21100144
total_episode_count: 61656
total_duration: 5640.699550824606
[2023-06-29 15:15:47][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2152
train_sample_count: 2152
avg_envstep_per_episode: 239.11111111111111
avg_sample_per_episode: 239.11111111111111
avg_envstep_per_sec: 2738.511047882952
avg_train_sample_per_sec: 2738.511047882952
avg_episode_per_sec: 11.452880776462159
collect_time: 0.785828489413485
reward_mean: 1871.3609725149206
reward_std: 937.0389128617466
reward_max: 3430.987565109168
reward_min: 733.8468711620797
total_envstep_count: 28165559
total_train_sample_count: 21103496
total_episode_count: 61665
total_duration: 5641.48537931402
[2023-06-29 15:15:52][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3440
train_sample_count: 3440
avg_envstep_per_episode: 286.6666666666667
avg_sample_per_episode: 286.6666666666667
avg_envstep_per_sec: 2791.900825176079
avg_train_sample_per_sec: 2791.900825176079
avg_episode_per_sec: 9.739188925032833
collect_time: 1.2321354573126884
reward_mean: 1815.5678582985067
reward_std: 667.0809413613606
reward_max: 3422.121643336432
reward_min: 1142.8386624201516
total_envstep_count: 28170191
total_train_sample_count: 21106936
total_episode_count: 61677
total_duration: 5642.717514771332
[2023-06-29 15:15:55][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2749
train_sample_count: 2749
avg_envstep_per_episode: 274.9
avg_sample_per_episode: 274.9
avg_envstep_per_sec: 2523.7097103311417
avg_train_sample_per_sec: 2523.7097103311417
avg_episode_per_sec: 9.180464570138748
collect_time: 1.089269494326785
reward_mean: 1374.2834838634303
reward_std: 390.4236829906987
reward_max: 2148.6542415409
reward_min: 943.619206652559
total_envstep_count: 28175047
total_train_sample_count: 21110485
total_episode_count: 61687
total_duration: 5643.806784265659
[2023-06-29 15:15:58][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3190
train_sample_count: 3190
avg_envstep_per_episode: 319.0
avg_sample_per_episode: 319.0
avg_envstep_per_sec: 2704.687027336185
avg_train_sample_per_sec: 2704.687027336185
avg_episode_per_sec: 8.47864271892221
collect_time: 1.1794340593786905
reward_mean: 1771.1852227715033
reward_std: 665.7454875422535
reward_max: 3307.8672530953327
reward_min: 1136.8881685833915
total_envstep_count: 28180471
total_train_sample_count: 21114075
total_episode_count: 61697
total_duration: 5644.986218325038
[2023-06-29 15:16:00][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 2764
train_sample_count: 2764
avg_envstep_per_episode: 230.33333333333334
avg_sample_per_episode: 230.33333333333334
avg_envstep_per_sec: 2713.417149231218
avg_train_sample_per_sec: 2713.417149231218
avg_episode_per_sec: 11.780392833131193
collect_time: 1.018641752442345
reward_mean: 1530.926781240548
reward_std: 645.7552943433361
reward_max: 3572.560039465126
reward_min: 973.7830788263568
total_envstep_count: 28184623
total_train_sample_count: 21117639
total_episode_count: 61709
total_duration: 5646.00486007748
[2023-06-29 15:16:03][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 3191
train_sample_count: 3191
avg_envstep_per_episode: 398.875
avg_sample_per_episode: 398.875
avg_envstep_per_sec: 2793.326527004909
avg_train_sample_per_sec: 2793.326527004909
avg_episode_per_sec: 7.003012289576707
collect_time: 1.142365552022122
reward_mean: 1966.1294566649021
reward_std: 883.0110428605485
reward_max: 3425.5274612178127
reward_min: 976.5611134870902
total_envstep_count: 28189479
total_train_sample_count: 21121230
total_episode_count: 61717
total_duration: 5647.147225629502
[2023-06-29 15:16:08][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2220
train_sample_count: 2220
avg_envstep_per_episode: 277.5
avg_sample_per_episode: 277.5
avg_envstep_per_sec: 2543.9525080733492
avg_train_sample_per_sec: 2543.9525080733492
avg_episode_per_sec: 9.167396425489548
collect_time: 0.872657800393179
reward_mean: 1638.973775972503
reward_std: 829.0572234544019
reward_max: 3134.076154959817
reward_min: 891.8278721778444
total_envstep_count: 28193551
total_train_sample_count: 21124650
total_episode_count: 61725
total_duration: 5648.019883429895
[2023-06-29 15:16:11][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2708
train_sample_count: 2708
avg_envstep_per_episode: 338.5
avg_sample_per_episode: 338.5
avg_envstep_per_sec: 2570.6377662884224
avg_train_sample_per_sec: 2570.6377662884224
avg_episode_per_sec: 7.594203150039653
collect_time: 1.0534350796183571
reward_mean: 2005.9192060748903
reward_std: 738.5643579503294
reward_max: 3508.9418481154307
reward_min: 1242.0582108175988
total_envstep_count: 28198887
total_train_sample_count: 21128158
total_episode_count: 61733
total_duration: 5649.073318509514
[2023-06-29 15:16:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2351
train_sample_count: 2351
avg_envstep_per_episode: 213.72727272727272
avg_sample_per_episode: 213.72727272727272
avg_envstep_per_sec: 2735.0805351198305
avg_train_sample_per_sec: 2735.0805351198305
avg_episode_per_sec: 12.797059075422432
collect_time: 0.8595724951466546
reward_mean: 1614.8504242333927
reward_std: 692.7025966121006
reward_max: 3048.2273880452835
reward_min: 947.0904232436573
total_envstep_count: 28203031
total_train_sample_count: 21131709
total_episode_count: 61744
total_duration: 5649.932891004661
[2023-06-29 15:16:16][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 2233
train_sample_count: 2233
avg_envstep_per_episode: 279.125
avg_sample_per_episode: 279.125
avg_envstep_per_sec: 2504.9973540485666
avg_train_sample_per_sec: 2504.9973540485666
avg_episode_per_sec: 8.97446432261018
collect_time: 0.8914181072451173
reward_mean: 1688.4084142925435
reward_std: 753.7708377974819
reward_max: 3386.0660019814986
reward_min: 661.7547519677933
total_envstep_count: 28207615
total_train_sample_count: 21135142
total_episode_count: 61752
total_duration: 5650.824309111906
[2023-06-29 15:16:19][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2433
train_sample_count: 2433
avg_envstep_per_episode: 270.3333333333333
avg_sample_per_episode: 270.3333333333333
avg_envstep_per_sec: 2805.4210455092625
avg_train_sample_per_sec: 2805.4210455092625
avg_episode_per_sec: 10.377636419886297
collect_time: 0.8672495003538203
reward_mean: 1858.3869647487372
reward_std: 724.8409799037324
reward_max: 3356.592036046328
reward_min: 683.6472925385224
total_envstep_count: 28212151
total_train_sample_count: 21138375
total_episode_count: 61761
total_duration: 5651.6915586122595
[2023-06-29 15:16:23][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2974
train_sample_count: 2974
avg_envstep_per_episode: 270.3636363636364
avg_sample_per_episode: 270.3636363636364
avg_envstep_per_sec: 2631.4524894304986
avg_train_sample_per_sec: 2631.4524894304986
avg_episode_per_sec: 9.733011897691824
collect_time: 1.1301743094148113
reward_mean: 1619.2108796810423
reward_std: 759.3473210351907
reward_max: 3480.7401238187526
reward_min: 650.0452301498739
total_envstep_count: 28216263
total_train_sample_count: 21141749
total_episode_count: 61772
total_duration: 5652.821732921674
[2023-06-29 15:16:26][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2946
train_sample_count: 2946
avg_envstep_per_episode: 327.3333333333333
avg_sample_per_episode: 327.3333333333333
avg_envstep_per_sec: 2535.099668299058
avg_train_sample_per_sec: 2535.099668299058
avg_episode_per_sec: 7.744703670974719
collect_time: 1.1620844879746437
reward_mean: 1556.372003530502
reward_std: 739.2481031632593
reward_max: 3344.585725101751
reward_min: 957.2543600967742
total_envstep_count: 28221063
total_train_sample_count: 21145095
total_episode_count: 61781
total_duration: 5653.9838174096485
[2023-06-29 15:16:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2721
train_sample_count: 2721
avg_envstep_per_episode: 247.36363636363637
avg_sample_per_episode: 247.36363636363637
avg_envstep_per_sec: 2684.9982957273664
avg_train_sample_per_sec: 2684.9982957273664
avg_episode_per_sec: 10.85445838037524
collect_time: 1.0134084644783288
reward_mean: 1439.8895607681957
reward_std: 512.0980991207022
reward_max: 2459.5458442485296
reward_min: 641.6322089920543
total_envstep_count: 28225903
total_train_sample_count: 21148616
total_episode_count: 61792
total_duration: 5654.997225874127
[2023-06-29 15:16:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 9
envstep_count: 2081
train_sample_count: 2081
avg_envstep_per_episode: 231.22222222222223
avg_sample_per_episode: 231.22222222222223
avg_envstep_per_sec: 2471.2181234597087
avg_train_sample_per_sec: 2471.2181234597087
avg_episode_per_sec: 10.687632441680625
collect_time: 0.8420948277469724
reward_mean: 1387.479575319526
reward_std: 380.3377319821025
reward_max: 2107.153883969091
reward_min: 935.1152161263673
total_envstep_count: 28229911
total_train_sample_count: 21151897
total_episode_count: 61801
total_duration: 5655.839320701874
[2023-06-29 15:16:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 2965
train_sample_count: 2965
avg_envstep_per_episode: 296.5
avg_sample_per_episode: 296.5
avg_envstep_per_sec: 2725.1427116332693
avg_train_sample_per_sec: 2725.1427116332693
avg_episode_per_sec: 9.191037813265664
collect_time: 1.088016413724981
reward_mean: 1834.2666816159406
reward_std: 837.8401581789117
reward_max: 3401.0567969784756
reward_min: 950.1191813462165
total_envstep_count: 28234471
total_train_sample_count: 21155262
total_episode_count: 61811
total_duration: 5656.9273371156
[2023-06-29 15:16:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 2867
train_sample_count: 2867
avg_envstep_per_episode: 260.6363636363636
avg_sample_per_episode: 260.6363636363636
avg_envstep_per_sec: 2521.470000961669
avg_train_sample_per_sec: 2521.470000961669
avg_episode_per_sec: 9.674283226570758
collect_time: 1.1370351417651403
reward_mean: 1437.5680694287362
reward_std: 653.3341852722808
reward_max: 3383.8393188403898
reward_min: 881.7617209494199
total_envstep_count: 28238799
total_train_sample_count: 21158529
total_episode_count: 61822
total_duration: 5658.064372257365
[2023-06-29 15:16:41][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 3362
train_sample_count: 3362
avg_envstep_per_episode: 280.1666666666667
avg_sample_per_episode: 280.1666666666667
avg_envstep_per_sec: 2542.397908124552
avg_train_sample_per_sec: 2542.397908124552
avg_episode_per_sec: 9.074590986762232
collect_time: 1.3223736494025213
reward_mean: 1364.1298211481128
reward_std: 316.54961093087906
reward_max: 2213.461746008172
reward_min: 943.493055640225
total_envstep_count: 28243303
total_train_sample_count: 21161891
total_episode_count: 61834
total_duration: 5659.386745906768
[2023-06-29 15:16:44][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 3093
train_sample_count: 3093
avg_envstep_per_episode: 309.3
avg_sample_per_episode: 309.3
avg_envstep_per_sec: 2710.7706140215496
avg_train_sample_per_sec: 2710.7706140215496
avg_episode_per_sec: 8.764211490532007
collect_time: 1.1410039580632003
reward_mean: 1463.7851445000306
reward_std: 361.3012452047899
reward_max: 2442.351455944338
reward_min: 1114.3953398588621
total_envstep_count: 28247895
total_train_sample_count: 21165384
total_episode_count: 61844
total_duration: 5660.527749864831
