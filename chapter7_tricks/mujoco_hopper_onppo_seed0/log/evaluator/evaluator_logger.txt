[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 107.6503, current episode: 1
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 119.0743, current episode: 2
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 125.4453, current episode: 3
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 130.0970, current episode: 4
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 132.9295, current episode: 5
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 146.6948, current episode: 6
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 149.5880, current episode: 7
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 176.2515, current episode: 8
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 189.0290, current episode: 9
[2023-06-29 09:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 202.1698, current episode: 10
[2023-06-29 09:50:24][interaction_serial_evaluator.py:279][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 10.000000     | 1950.000000   |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 195.000000              | 0.365896      | 5329.385492         | 27.330182            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 147.892944  | 29.901752  | 202.169785 | 107.650276 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 62.1528, current episode: 1
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 62.1981, current episode: 2
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 62.3932, current episode: 3
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 61.9734, current episode: 4
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 61.7261, current episode: 5
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 64.1748, current episode: 6
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7292, current episode: 7
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 64.1639, current episode: 8
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 64.2361, current episode: 9
[2023-06-29 09:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 65.9440, current episode: 10
[2023-06-29 09:50:38][interaction_serial_evaluator.py:279][INFO] 
+-------+------------+-----------------------+---------------+---------------+
| Name  | train_iter | ckpt_name             | episode_count | envstep_count |
+-------+------------+-----------------------+---------------+---------------+
| Value | 500.000000 | iteration_500.pth.tar | 10.000000     | 400.000000    |
+-------+------------+-----------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 40.000000               | 0.097520      | 4101.725432         | 102.543136           |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 63.269149   | 1.309314   | 65.944038  | 61.726112  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 78.0872, current episode: 1
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 79.9261, current episode: 2
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 79.9504, current episode: 3
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 79.8716, current episode: 4
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 79.7896, current episode: 5
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 81.8648, current episode: 6
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 81.8309, current episode: 7
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 81.9897, current episode: 8
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 83.7543, current episode: 9
[2023-06-29 09:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 83.4966, current episode: 10
[2023-06-29 09:50:52][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 1000.000000 | iteration_1000.pth.tar | 10.000000     | 540.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 54.000000               | 0.111934      | 4824.288626         | 89.338678            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 81.056125   | 1.722891   | 83.754288  | 78.087173  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 68.1832, current episode: 1
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 70.0258, current episode: 2
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 70.3154, current episode: 3
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 70.3976, current episode: 4
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 70.1607, current episode: 5
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 70.0183, current episode: 6
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 69.8327, current episode: 7
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 70.1147, current episode: 8
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 72.0302, current episode: 9
[2023-06-29 09:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 71.8173, current episode: 10
[2023-06-29 09:51:05][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 1500.000000 | iteration_1500.pth.tar | 10.000000     | 440.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 44.000000               | 0.112733      | 3903.037750         | 88.705403            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 70.289599   | 1.010536   | 72.030220  | 68.183220  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 66.7601, current episode: 1
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 66.8385, current episode: 2
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 66.9836, current episode: 3
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 66.6887, current episode: 4
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 66.3143, current episode: 5
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 68.9794, current episode: 6
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 68.6905, current episode: 7
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 68.9437, current episode: 8
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 68.4846, current episode: 9
[2023-06-29 09:51:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 69.0664, current episode: 10
[2023-06-29 09:51:18][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 10.000000     | 420.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 42.000000               | 0.091316      | 4599.412932         | 109.509832           |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 67.774982   | 1.080412   | 69.066437  | 66.314255  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 58.9973, current episode: 1
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 59.1047, current episode: 2
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 61.2050, current episode: 3
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 60.9224, current episode: 4
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 61.2630, current episode: 5
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 61.1644, current episode: 6
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 61.1739, current episode: 7
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 60.7582, current episode: 8
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 60.7558, current episode: 9
[2023-06-29 09:51:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 61.2659, current episode: 10
[2023-06-29 09:51:31][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2500.000000 | iteration_2500.pth.tar | 10.000000     | 370.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 37.000000               | 0.089192      | 4148.364695         | 112.117965           |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 60.661057   | 0.825665   | 61.265854  | 58.997337  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 76.7441, current episode: 1
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 79.2101, current episode: 2
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 78.7241, current episode: 3
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 78.8240, current episode: 4
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 78.9591, current episode: 5
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 79.1238, current episode: 6
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 78.5369, current episode: 7
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 79.3595, current episode: 8
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 81.4388, current episode: 9
[2023-06-29 09:51:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 81.2142, current episode: 10
[2023-06-29 09:51:45][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 3000.000000 | iteration_3000.pth.tar | 10.000000     | 510.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 51.000000               | 0.111648      | 4567.929226         | 89.567240            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 79.213450   | 1.264740   | 81.438805  | 76.744110  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 74.9491, current episode: 1
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 75.0331, current episode: 2
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 75.0653, current episode: 3
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 74.8403, current episode: 4
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 77.6197, current episode: 5
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 77.7900, current episode: 6
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 77.3932, current episode: 7
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 77.5091, current episode: 8
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 77.5875, current episode: 9
[2023-06-29 09:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 77.7421, current episode: 10
[2023-06-29 09:51:58][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 3500.000000 | iteration_3500.pth.tar | 10.000000     | 480.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 48.000000               | 0.105531      | 4548.434497         | 94.759052            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 76.552950   | 1.296196   | 77.790001  | 74.840332  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 148.7720, current episode: 1
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 148.8312, current episode: 2
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 148.7316, current episode: 3
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 152.5553, current episode: 4
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 151.3121, current episode: 5
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 151.9504, current episode: 6
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 152.3227, current episode: 7
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 152.7215, current episode: 8
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.6887, current episode: 9
[2023-06-29 09:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 155.4288, current episode: 10
[2023-06-29 09:52:12][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 10.000000     | 830.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 83.000000               | 0.156371      | 5307.886906         | 63.950445            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 151.831424  | 2.400663   | 155.688721 | 148.731567 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 164.9732, current episode: 1
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 167.3347, current episode: 2
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 167.3850, current episode: 3
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 168.2256, current episode: 4
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 167.3595, current episode: 5
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 171.2168, current episode: 6
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 170.8782, current episode: 7
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 171.2649, current episode: 8
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 174.4342, current episode: 9
[2023-06-29 09:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 174.1689, current episode: 10
[2023-06-29 09:52:25][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4500.000000 | iteration_4500.pth.tar | 10.000000     | 920.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 92.000000               | 0.175414      | 5244.722494         | 57.007853            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 169.724094  | 2.991046   | 174.434204 | 164.973175 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 162.9129, current episode: 1
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 164.5654, current episode: 2
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 164.5528, current episode: 3
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 165.1503, current episode: 4
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 164.4962, current episode: 5
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 167.3465, current episode: 6
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 167.0833, current episode: 7
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 167.4822, current episode: 8
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 169.6279, current episode: 9
[2023-06-29 09:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 169.3097, current episode: 10
[2023-06-29 09:52:39][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 5000.000000 | iteration_5000.pth.tar | 10.000000     | 1080.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 108.000000              | 0.209728      | 5149.517718         | 47.680720            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 166.252742  | 2.129012   | 169.627945 | 162.912903 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 80.3073, current episode: 1
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 80.8236, current episode: 2
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 79.2143, current episode: 3
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 79.2301, current episode: 4
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 79.2261, current episode: 5
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 79.7836, current episode: 6
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 80.0756, current episode: 7
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 79.2209, current episode: 8
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 80.3545, current episode: 9
[2023-06-29 09:52:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 82.6305, current episode: 10
[2023-06-29 09:52:53][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 5500.000000 | iteration_5500.pth.tar | 10.000000     | 520.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 52.000000               | 0.125025      | 4159.163040         | 79.983905            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 80.086647   | 1.010502   | 82.630455  | 79.214317  |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 165.0844, current episode: 1
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 164.7669, current episode: 2
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 167.2526, current episode: 3
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 168.6825, current episode: 4
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 167.5216, current episode: 5
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 171.9311, current episode: 6
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 171.6294, current episode: 7
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 172.1320, current episode: 8
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 177.8879, current episode: 9
[2023-06-29 09:53:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 177.7036, current episode: 10
[2023-06-29 09:53:06][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 10.000000     | 990.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 99.000000               | 0.182972      | 5410.670691         | 54.653239            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 170.459209  | 4.442538   | 177.887939 | 164.766922 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 222.9158, current episode: 1
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 222.7857, current episode: 2
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 222.3373, current episode: 3
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 220.0047, current episode: 4
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 220.2802, current episode: 5
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 220.1684, current episode: 6
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 221.3808, current episode: 7
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 221.9480, current episode: 8
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 220.4546, current episode: 9
[2023-06-29 09:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 222.6682, current episode: 10
[2023-06-29 09:53:20][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6500.000000 | iteration_6500.pth.tar | 10.000000     | 1000.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 100.000000              | 0.177334      | 5639.078012         | 56.390780            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 221.494351  | 1.119281   | 222.915756 | 220.004684 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 215.3886, current episode: 1
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 216.0323, current episode: 2
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 218.6679, current episode: 3
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 219.4035, current episode: 4
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 217.8572, current episode: 5
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 218.0941, current episode: 6
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 218.5486, current episode: 7
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 218.1703, current episode: 8
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 219.1708, current episode: 9
[2023-06-29 09:53:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 218.8523, current episode: 10
[2023-06-29 09:53:34][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 7000.000000 | iteration_7000.pth.tar | 10.000000     | 980.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 98.000000               | 0.178267      | 5497.372443         | 56.095637            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 218.018553  | 1.247397   | 219.403488 | 215.388611 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 231.8797, current episode: 1
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 233.6087, current episode: 2
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 230.4110, current episode: 3
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 231.7291, current episode: 4
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 231.8685, current episode: 5
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 230.7364, current episode: 6
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 233.4760, current episode: 7
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 232.2715, current episode: 8
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 232.8693, current episode: 9
[2023-06-29 09:53:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 233.1422, current episode: 10
[2023-06-29 09:53:47][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 7500.000000 | iteration_7500.pth.tar | 10.000000     | 1130.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 113.000000              | 0.199607      | 5661.117337         | 50.098384            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 232.199237  | 1.035868   | 233.608734 | 230.411026 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 253.4814, current episode: 1
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 253.3399, current episode: 2
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 253.2200, current episode: 3
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 253.0268, current episode: 4
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 253.2869, current episode: 5
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 251.7135, current episode: 6
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 253.8189, current episode: 7
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 253.1736, current episode: 8
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 253.5082, current episode: 9
[2023-06-29 09:54:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 253.3545, current episode: 10
[2023-06-29 09:54:01][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 10.000000     | 1330.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 133.000000              | 0.227050      | 5857.736177         | 44.043129            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 253.192386  | 0.533696   | 253.818893 | 251.713531 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 217.6494, current episode: 1
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 219.1112, current episode: 2
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 219.2392, current episode: 3
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 223.6572, current episode: 4
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 222.9880, current episode: 5
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 222.8982, current episode: 6
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 222.4816, current episode: 7
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 225.1139, current episode: 8
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 231.1324, current episode: 9
[2023-06-29 09:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 231.6143, current episode: 10
[2023-06-29 09:54:15][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8500.000000 | iteration_8500.pth.tar | 10.000000     | 1090.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 109.000000              | 0.195510      | 5575.160812         | 51.148264            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 223.588539  | 4.471622   | 231.614334 | 217.649368 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 298.1274, current episode: 1
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 298.7076, current episode: 2
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 304.0898, current episode: 3
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 304.5547, current episode: 4
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 305.3875, current episode: 5
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 306.6649, current episode: 6
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 309.7006, current episode: 7
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 313.5798, current episode: 8
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 314.7043, current episode: 9
[2023-06-29 09:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 315.3384, current episode: 10
[2023-06-29 09:54:29][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 9000.000000 | iteration_9000.pth.tar | 10.000000     | 1950.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 195.000000              | 0.330330      | 5903.182508         | 30.272731            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 307.085495  | 5.865556   | 315.338409 | 298.127380 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 294.8850, current episode: 1
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 295.2087, current episode: 2
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 298.7460, current episode: 3
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 298.3729, current episode: 4
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 299.7056, current episode: 5
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 301.8799, current episode: 6
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 301.1533, current episode: 7
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 304.9261, current episode: 8
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 306.4217, current episode: 9
[2023-06-29 09:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 307.2601, current episode: 10
[2023-06-29 09:54:43][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 9500.000000 | iteration_9500.pth.tar | 10.000000     | 1820.000000   |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 182.000000              | 0.329741      | 5519.481986         | 30.326824            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 300.855933  | 4.113113   | 307.260101 | 294.885010 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 342.8324, current episode: 1
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 343.8512, current episode: 2
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 343.8998, current episode: 3
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 345.9209, current episode: 4
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 346.4788, current episode: 5
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 350.9914, current episode: 6
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 350.1627, current episode: 7
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 351.9295, current episode: 8
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 359.8488, current episode: 9
[2023-06-29 09:54:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 358.8361, current episode: 10
[2023-06-29 09:54:57][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 10000.000000 | iteration_10000.pth.tar | 10.000000     | 1580.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 158.000000              | 0.286187      | 5520.859026         | 34.942146            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 349.475150  | 5.766160   | 359.848785 | 342.832397 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 339.5316, current episode: 1
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 342.4365, current episode: 2
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 342.9028, current episode: 3
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 342.9835, current episode: 4
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 343.4435, current episode: 5
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 342.9409, current episode: 6
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 342.3266, current episode: 7
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 342.0365, current episode: 8
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 342.0643, current episode: 9
[2023-06-29 09:55:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 342.6066, current episode: 10
[2023-06-29 09:55:11][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 10500.000000 | iteration_10500.pth.tar | 10.000000     | 1400.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 140.000000              | 0.233240      | 6002.391787         | 42.874227            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 342.327283  | 1.021939   | 343.443512 | 339.531647 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 359.6797, current episode: 1
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 359.4836, current episode: 2
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 359.9139, current episode: 3
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 359.0006, current episode: 4
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 362.0816, current episode: 5
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 361.1216, current episode: 6
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 361.8514, current episode: 7
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 361.6430, current episode: 8
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 360.9080, current episode: 9
[2023-06-29 09:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 362.1949, current episode: 10
[2023-06-29 09:55:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 11000.000000 | iteration_11000.pth.tar | 10.000000     | 1390.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 139.000000              | 0.231855      | 5995.122824         | 43.130380            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 360.787845  | 1.119327   | 362.194946 | 359.000610 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 426.7097, current episode: 1
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 429.1875, current episode: 2
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 428.0002, current episode: 3
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 429.7660, current episode: 4
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 429.7871, current episode: 5
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 429.6270, current episode: 6
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 429.1685, current episode: 7
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 428.6215, current episode: 8
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 427.9220, current episode: 9
[2023-06-29 09:55:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 429.3111, current episode: 10
[2023-06-29 09:55:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 11500.000000 | iteration_11500.pth.tar | 10.000000     | 1520.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 152.000000              | 0.253943      | 5985.590319         | 39.378884            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 428.810056  | 0.946020   | 429.787109 | 426.709686 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 449.4816, current episode: 1
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 449.2600, current episode: 2
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 449.9849, current episode: 3
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 448.6995, current episode: 4
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 448.0808, current episode: 5
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 447.9470, current episode: 6
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 448.4910, current episode: 7
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 452.0041, current episode: 8
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 450.8083, current episode: 9
[2023-06-29 09:55:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 450.2388, current episode: 10
[2023-06-29 09:55:53][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 12000.000000 | iteration_12000.pth.tar | 10.000000     | 1550.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 155.000000              | 0.273978      | 5657.396807         | 36.499334            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 449.499588  | 1.220886   | 452.004089 | 447.946991 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 443.5878, current episode: 1
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 443.9819, current episode: 2
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 446.3657, current episode: 3
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.3716, current episode: 4
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 446.7187, current episode: 5
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 446.1109, current episode: 6
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 446.1519, current episode: 7
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 446.5016, current episode: 8
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 448.1841, current episode: 9
[2023-06-29 09:56:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 448.3806, current episode: 10
[2023-06-29 09:56:07][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 12500.000000 | iteration_12500.pth.tar | 10.000000     | 1540.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 154.000000              | 0.256967      | 5992.989317         | 38.915515            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 446.335461  | 1.483969   | 448.380554 | 443.587799 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 566.0275, current episode: 1
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 570.6556, current episode: 2
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 570.3330, current episode: 3
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 571.4429, current episode: 4
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 569.1184, current episode: 5
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 568.1216, current episode: 6
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 568.6011, current episode: 7
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 565.9346, current episode: 8
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 568.7306, current episode: 9
[2023-06-29 09:56:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 573.7524, current episode: 10
[2023-06-29 09:56:21][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 13000.000000 | iteration_13000.pth.tar | 10.000000     | 1830.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 183.000000              | 0.308171      | 5938.268211         | 32.449553            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 569.271771  | 2.271167   | 573.752380 | 565.934570 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 718.4255, current episode: 1
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 718.5624, current episode: 2
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 718.1450, current episode: 3
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 719.1448, current episode: 4
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 717.9969, current episode: 5
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 717.5114, current episode: 6
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 716.1737, current episode: 7
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 717.9752, current episode: 8
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 720.0473, current episode: 9
[2023-06-29 09:56:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 719.9636, current episode: 10
[2023-06-29 09:56:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 13500.000000 | iteration_13500.pth.tar | 10.000000     | 2230.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 223.000000              | 0.366794      | 6079.704231         | 27.263248            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 718.394580  | 1.090585   | 720.047302 | 716.173706 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 727.3172, current episode: 1
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 728.3281, current episode: 2
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 731.3896, current episode: 3
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 731.5562, current episode: 4
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 728.6972, current episode: 5
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 730.6207, current episode: 6
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 732.5884, current episode: 7
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 733.8818, current episode: 8
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 732.8779, current episode: 9
[2023-06-29 09:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 736.0364, current episode: 10
[2023-06-29 09:56:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 14000.000000 | iteration_14000.pth.tar | 10.000000     | 2320.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 232.000000              | 0.393448      | 5896.588853         | 25.416331            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 731.329333  | 2.554302   | 736.036377 | 727.317200 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 763.9979, current episode: 1
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 762.5464, current episode: 2
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 814.9611, current episode: 3
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 820.7142, current episode: 4
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 827.2434, current episode: 5
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 830.6977, current episode: 6
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 834.1757, current episode: 7
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 836.1981, current episode: 8
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 845.4081, current episode: 9
[2023-06-29 09:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 853.3340, current episode: 10
[2023-06-29 09:57:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 14500.000000 | iteration_14500.pth.tar | 10.000000     | 2640.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 264.000000              | 0.439540      | 6006.274588         | 22.751040            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 818.927661  | 29.729650  | 853.333984 | 762.546387 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 967.2102, current episode: 1
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1010.4054, current episode: 2
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1012.8045, current episode: 3
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1009.8813, current episode: 4
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1014.1559, current episode: 5
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1024.5425, current episode: 6
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1040.0316, current episode: 7
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1047.7581, current episode: 8
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1122.0793, current episode: 9
[2023-06-29 09:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1127.8243, current episode: 10
[2023-06-29 09:57:19][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 15000.000000 | iteration_15000.pth.tar | 10.000000     | 3580.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 358.000000              | 0.580986      | 6161.937607         | 17.212116            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1037.669324 | 48.149533  | 1127.824341 | 967.210205 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 957.0637, current episode: 1
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 974.0573, current episode: 2
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 979.1708, current episode: 3
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 996.7178, current episode: 4
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1071.8918, current episode: 5
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1066.0166, current episode: 6
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1088.7252, current episode: 7
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1160.3744, current episode: 8
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1197.5518, current episode: 9
[2023-06-29 09:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1200.7860, current episode: 10
[2023-06-29 09:57:34][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 15500.000000 | iteration_15500.pth.tar | 10.000000     | 3760.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 376.000000              | 0.645941      | 5820.964712         | 15.481289            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1069.235553 | 88.026140  | 1200.786011 | 957.063721 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1034.6978, current episode: 1
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1057.0280, current episode: 2
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1081.7820, current episode: 3
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1083.4906, current episode: 4
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1084.8885, current episode: 5
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1100.7485, current episode: 6
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1118.7805, current episode: 7
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1116.3052, current episode: 8
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1161.2831, current episode: 9
[2023-06-29 09:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1208.0214, current episode: 10
[2023-06-29 09:57:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 16000.000000 | iteration_16000.pth.tar | 10.000000     | 3840.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 384.000000              | 0.641821      | 5982.978988         | 15.580674            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1104.702551 | 47.713740  | 1208.021362 | 1034.697754 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 943.6700, current episode: 1
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 968.8719, current episode: 2
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 970.0595, current episode: 3
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 973.2810, current episode: 4
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1002.2535, current episode: 5
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1005.3151, current episode: 6
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1009.7932, current episode: 7
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1021.4920, current episode: 8
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1033.0065, current episode: 9
[2023-06-29 09:58:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1032.3442, current episode: 10
[2023-06-29 09:58:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 16500.000000 | iteration_16500.pth.tar | 10.000000     | 3340.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 334.000000              | 0.700797      | 4765.999667         | 14.269460            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 996.008704  | 28.844013  | 1033.006470 | 943.670044 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 938.1846, current episode: 1
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 943.0178, current episode: 2
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 941.6636, current episode: 3
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 946.3652, current episode: 4
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 946.8985, current episode: 5
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 951.5469, current episode: 6
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 972.0544, current episode: 7
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 972.2902, current episode: 8
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 973.7170, current episode: 9
[2023-06-29 09:58:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 976.1005, current episode: 10
[2023-06-29 09:58:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 17000.000000 | iteration_17000.pth.tar | 10.000000     | 3090.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 309.000000              | 0.492973      | 6268.090700         | 20.285083            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 956.183881  | 14.586482  | 976.100525 | 938.184631 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1074.1462, current episode: 1
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1091.3999, current episode: 2
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1095.7528, current episode: 3
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1099.7327, current episode: 4
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1110.7534, current episode: 5
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1145.3264, current episode: 6
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1145.7695, current episode: 7
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1212.3489, current episode: 8
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1214.9465, current episode: 9
[2023-06-29 09:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1214.7134, current episode: 10
[2023-06-29 09:58:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 17500.000000 | iteration_17500.pth.tar | 10.000000     | 3840.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 384.000000              | 0.640143      | 5998.659624         | 15.621509            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1140.488977 | 52.560461  | 1214.946533 | 1074.146240 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1019.7722, current episode: 1
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1018.9584, current episode: 2
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1021.2288, current episode: 3
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1023.3558, current episode: 4
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1023.1227, current episode: 5
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1021.8023, current episode: 6
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1020.9739, current episode: 7
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1026.0383, current episode: 8
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1024.7957, current episode: 9
[2023-06-29 09:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1023.5021, current episode: 10
[2023-06-29 09:58:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 18000.000000 | iteration_18000.pth.tar | 10.000000     | 3230.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 323.000000              | 0.529190      | 6103.664322         | 18.896794            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1022.355035 | 2.100455   | 1026.038330 | 1018.958435 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 998.7310, current episode: 1
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 997.9988, current episode: 2
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.1133, current episode: 3
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1001.6693, current episode: 4
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1000.9377, current episode: 5
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.1003, current episode: 6
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1007.9336, current episode: 7
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1010.3906, current episode: 8
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1009.6029, current episode: 9
[2023-06-29 09:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1013.0987, current episode: 10
[2023-06-29 09:59:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 18500.000000 | iteration_18500.pth.tar | 10.000000     | 3240.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 324.000000              | 0.574844      | 5636.307034         | 17.396009            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1004.357629 | 5.096736   | 1013.098694 | 997.998840 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 09:59:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 900.4330, current episode: 1
[2023-06-29 09:59:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 902.1920, current episode: 2
[2023-06-29 09:59:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.1052, current episode: 3
[2023-06-29 09:59:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 906.9883, current episode: 4
[2023-06-29 09:59:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 908.2921, current episode: 5
[2023-06-29 09:59:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 906.4419, current episode: 6
[2023-06-29 09:59:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 911.9334, current episode: 7
[2023-06-29 09:59:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 911.4937, current episode: 8
[2023-06-29 09:59:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 911.3138, current episode: 9
[2023-06-29 09:59:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 908.1462, current episode: 10
[2023-06-29 09:59:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 19000.000000 | iteration_19000.pth.tar | 10.000000     | 2910.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 291.000000              | 0.472673      | 6156.478372         | 21.156283            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 907.333954  | 3.638168   | 911.933411 | 900.433044 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 933.6705, current episode: 1
[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 936.9479, current episode: 2
[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 934.6793, current episode: 3
[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 934.5601, current episode: 4
[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 939.4315, current episode: 5
[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 939.4640, current episode: 6
[2023-06-29 09:59:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 957.2836, current episode: 7
[2023-06-29 09:59:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 958.8295, current episode: 8
[2023-06-29 09:59:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 961.7963, current episode: 9
[2023-06-29 09:59:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 980.3915, current episode: 10
[2023-06-29 09:59:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 19500.000000 | iteration_19500.pth.tar | 10.000000     | 3140.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 314.000000              | 0.676330      | 4642.707240         | 14.785692            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 947.705414  | 15.079727  | 980.391479 | 933.670471 |
+-------+-------------+------------+------------+------------+


[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 905.9459, current episode: 1
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 907.8660, current episode: 2
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 912.4578, current episode: 3
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 909.9329, current episode: 4
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 911.3733, current episode: 5
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 912.0643, current episode: 6
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 916.2448, current episode: 7
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 915.6729, current episode: 8
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 929.1977, current episode: 9
[2023-06-29 09:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 926.3120, current episode: 10
[2023-06-29 09:59:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 20000.000000 | iteration_20000.pth.tar | 10.000000     | 2970.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 297.000000              | 0.470735      | 6309.281671         | 21.243373            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 914.706750  | 7.193445   | 929.197693 | 905.945923 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1201.6091, current episode: 1
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1230.3186, current episode: 2
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1214.3589, current episode: 3
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1237.6046, current episode: 4
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1248.0839, current episode: 5
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1254.8306, current episode: 6
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1251.3721, current episode: 7
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1255.0221, current episode: 8
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1254.6996, current episode: 9
[2023-06-29 10:00:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1268.0660, current episode: 10
[2023-06-29 10:00:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 20500.000000 | iteration_20500.pth.tar | 10.000000     | 4130.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 413.000000              | 0.793498      | 5204.804924         | 12.602433            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1241.596545 | 19.619800  | 1268.066040 | 1201.609131 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 940.7064, current episode: 1
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 952.2560, current episode: 2
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 952.5956, current episode: 3
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 954.9601, current episode: 4
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 948.5470, current episode: 5
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 952.2910, current episode: 6
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 952.5659, current episode: 7
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 955.8069, current episode: 8
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 954.8481, current episode: 9
[2023-06-29 10:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 958.6806, current episode: 10
[2023-06-29 10:00:21][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 21000.000000 | iteration_21000.pth.tar | 10.000000     | 2950.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 295.000000              | 0.479118      | 6157.149689         | 20.871694            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 952.325763  | 4.639293   | 958.680603 | 940.706360 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1021.6427, current episode: 1
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1044.0404, current episode: 2
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1236.1620, current episode: 3
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1295.4934, current episode: 4
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1288.4122, current episode: 5
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1329.3468, current episode: 6
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1331.4125, current episode: 7
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1336.6315, current episode: 8
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1329.5117, current episode: 9
[2023-06-29 10:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1352.5641, current episode: 10
[2023-06-29 10:00:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 21500.000000 | iteration_21500.pth.tar | 10.000000     | 4200.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 420.000000              | 0.673455      | 6236.493321         | 14.848794            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1256.521729 | 116.253234 | 1352.564087 | 1021.642700 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:00:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 994.9250, current episode: 1
[2023-06-29 10:00:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 988.4105, current episode: 2
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 987.7935, current episode: 3
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 996.8239, current episode: 4
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 997.0708, current episode: 5
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 997.1608, current episode: 6
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 997.7246, current episode: 7
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1004.6380, current episode: 8
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1007.7676, current episode: 9
[2023-06-29 10:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1006.9099, current episode: 10
[2023-06-29 10:00:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 22000.000000 | iteration_22000.pth.tar | 10.000000     | 3340.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 334.000000              | 0.531468      | 6284.476874         | 18.815799            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 997.922455  | 6.537671   | 1007.767639 | 987.793457 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1252.0848, current episode: 1
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1266.7871, current episode: 2
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1271.0839, current episode: 3
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1266.1818, current episode: 4
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1284.3558, current episode: 5
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1280.1558, current episode: 6
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1275.7015, current episode: 7
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1283.3823, current episode: 8
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1278.3695, current episode: 9
[2023-06-29 10:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1291.8599, current episode: 10
[2023-06-29 10:01:06][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 22500.000000 | iteration_22500.pth.tar | 10.000000     | 4200.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 420.000000              | 0.664395      | 6321.543948         | 15.051295            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1274.996240 | 10.798755  | 1291.859863 | 1252.084839 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1005.1704, current episode: 1
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1014.1590, current episode: 2
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1034.9960, current episode: 3
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1058.8949, current episode: 4
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1056.0712, current episode: 5
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1056.7747, current episode: 6
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1074.2926, current episode: 7
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1265.8250, current episode: 8
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1306.6824, current episode: 9
[2023-06-29 10:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1309.0170, current episode: 10
[2023-06-29 10:01:21][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 23000.000000 | iteration_23000.pth.tar | 10.000000     | 4150.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 415.000000              | 0.666031      | 6230.944574         | 15.014324            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1118.188300 | 117.188307 | 1309.016968 | 1005.170410 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1007.0278, current episode: 1
[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1012.0538, current episode: 2
[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1026.5282, current episode: 3
[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1029.8425, current episode: 4
[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1030.7760, current episode: 5
[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1027.3152, current episode: 6
[2023-06-29 10:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1081.5640, current episode: 7
[2023-06-29 10:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1074.8273, current episode: 8
[2023-06-29 10:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1152.7827, current episode: 9
[2023-06-29 10:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1282.1091, current episode: 10
[2023-06-29 10:01:37][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 23500.000000 | iteration_23500.pth.tar | 10.000000     | 3920.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 392.000000              | 0.636025      | 6163.284240         | 15.722664            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1072.482660 | 81.317186  | 1282.109131 | 1007.027832 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1054.3571, current episode: 1
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1067.9227, current episode: 2
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.1910, current episode: 3
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1068.2596, current episode: 4
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1069.0609, current episode: 5
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1072.6656, current episode: 6
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1068.2793, current episode: 7
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1073.7495, current episode: 8
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1072.0983, current episode: 9
[2023-06-29 10:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1072.5564, current episode: 10
[2023-06-29 10:01:52][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 24000.000000 | iteration_24000.pth.tar | 10.000000     | 3350.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 335.000000              | 0.551389      | 6075.567797         | 18.136023            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1068.814050 | 5.240042   | 1073.749512 | 1054.357056 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1049.4015, current episode: 1
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1047.0814, current episode: 2
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1054.8348, current episode: 3
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1057.9125, current episode: 4
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1061.1294, current episode: 5
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1063.5366, current episode: 6
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1066.8419, current episode: 7
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1061.7030, current episode: 8
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1066.2094, current episode: 9
[2023-06-29 10:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1070.0389, current episode: 10
[2023-06-29 10:02:07][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 24500.000000 | iteration_24500.pth.tar | 10.000000     | 3250.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 325.000000              | 0.564905      | 5753.175089         | 17.702077            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1059.868945 | 7.161806   | 1070.038940 | 1047.081421 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1024.6661, current episode: 1
[2023-06-29 10:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1028.2668, current episode: 2
[2023-06-29 10:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1034.6339, current episode: 3
[2023-06-29 10:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1030.9430, current episode: 4
[2023-06-29 10:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1045.5481, current episode: 5
[2023-06-29 10:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1083.0652, current episode: 6
[2023-06-29 10:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1092.2617, current episode: 7
[2023-06-29 10:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1094.5685, current episode: 8
[2023-06-29 10:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1094.2910, current episode: 9
[2023-06-29 10:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1105.8695, current episode: 10
[2023-06-29 10:02:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 25000.000000 | iteration_25000.pth.tar | 10.000000     | 3340.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 334.000000              | 0.531415      | 6285.106281         | 18.817683            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1063.411389 | 31.437862  | 1105.869507 | 1024.666138 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1046.8113, current episode: 1
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1093.1216, current episode: 2
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1103.8057, current episode: 3
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.1362, current episode: 4
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1158.4198, current episode: 5
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1167.9738, current episode: 6
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1161.7096, current episode: 7
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1164.1566, current episode: 8
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1171.2881, current episode: 9
[2023-06-29 10:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1196.4482, current episode: 10
[2023-06-29 10:02:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 25500.000000 | iteration_25500.pth.tar | 10.000000     | 3590.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 359.000000              | 0.597178      | 6011.610603         | 16.745433            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1141.587085 | 43.192442  | 1196.448242 | 1046.811279 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1013.2797, current episode: 1
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1013.9778, current episode: 2
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1015.8615, current episode: 3
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1014.5123, current episode: 4
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1017.3182, current episode: 5
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1019.7378, current episode: 6
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1024.2321, current episode: 7
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1021.9236, current episode: 8
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1043.1373, current episode: 9
[2023-06-29 10:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1100.4739, current episode: 10
[2023-06-29 10:02:53][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 26000.000000 | iteration_26000.pth.tar | 10.000000     | 3250.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 325.000000              | 0.532077      | 6108.136780         | 18.794267            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1028.445422 | 25.408014  | 1100.473877 | 1013.279663 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1282.7604, current episode: 1
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1284.4713, current episode: 2
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1296.5936, current episode: 3
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1291.6431, current episode: 4
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1296.5557, current episode: 5
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1285.5903, current episode: 6
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1288.2053, current episode: 7
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1306.1350, current episode: 8
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1345.4728, current episode: 9
[2023-06-29 10:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1354.8213, current episode: 10
[2023-06-29 10:03:08][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 26500.000000 | iteration_26500.pth.tar | 10.000000     | 4160.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 416.000000              | 0.666480      | 6241.748444         | 15.004203            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1303.224878 | 24.464648  | 1354.821289 | 1282.760376 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 998.9183, current episode: 1
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 999.6885, current episode: 2
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1056.8636, current episode: 3
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1033.8547, current episode: 4
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1034.7949, current episode: 5
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1038.2966, current episode: 6
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1039.1014, current episode: 7
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1043.4668, current episode: 8
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1058.5208, current episode: 9
[2023-06-29 10:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1092.8024, current episode: 10
[2023-06-29 10:03:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 27000.000000 | iteration_27000.pth.tar | 10.000000     | 3280.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 328.000000              | 0.529232      | 6197.655065         | 18.895290            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1039.630804 | 26.091071  | 1092.802368 | 998.918274 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 957.6909, current episode: 1
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1001.1289, current episode: 2
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1009.4499, current episode: 3
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1010.4745, current episode: 4
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1014.3110, current episode: 5
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1013.5025, current episode: 6
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1011.8364, current episode: 7
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1011.7149, current episode: 8
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1013.9256, current episode: 9
[2023-06-29 10:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1018.1355, current episode: 10
[2023-06-29 10:03:40][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 27500.000000 | iteration_27500.pth.tar | 10.000000     | 3090.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 309.000000              | 0.576501      | 5359.917564         | 17.346012            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1006.217017 | 16.706635  | 1018.135498 | 957.690918 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1013.4097, current episode: 1
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1016.3008, current episode: 2
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1019.8045, current episode: 3
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1023.4617, current episode: 4
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1024.1873, current episode: 5
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1025.9159, current episode: 6
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1026.6465, current episode: 7
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1027.9238, current episode: 8
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1029.9374, current episode: 9
[2023-06-29 10:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1029.9099, current episode: 10
[2023-06-29 10:03:55][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 28000.000000 | iteration_28000.pth.tar | 10.000000     | 3119.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 311.900000              | 0.500412      | 6232.860477         | 19.983522            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1023.749750 | 5.338380   | 1029.937378 | 1013.409729 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1010.1851, current episode: 1
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1004.9930, current episode: 2
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1010.5234, current episode: 3
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1013.3782, current episode: 4
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1015.8594, current episode: 5
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1010.4263, current episode: 6
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1015.1613, current episode: 7
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1019.5905, current episode: 8
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1022.4227, current episode: 9
[2023-06-29 10:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1036.1171, current episode: 10
[2023-06-29 10:04:09][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 28500.000000 | iteration_28500.pth.tar | 10.000000     | 3100.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 310.000000              | 0.494630      | 6267.314338         | 20.217143            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1015.865692 | 8.260036   | 1036.117065 | 1004.992981 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1116.5129, current episode: 1
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1116.9320, current episode: 2
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1128.5625, current episode: 3
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1126.2268, current episode: 4
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1278.2076, current episode: 5
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1284.5530, current episode: 6
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1296.4360, current episode: 7
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1301.4684, current episode: 8
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1315.7163, current episode: 9
[2023-06-29 10:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1323.3815, current episode: 10
[2023-06-29 10:04:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 29000.000000 | iteration_29000.pth.tar | 10.000000     | 4070.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 407.000000              | 0.654289      | 6220.491024         | 15.283762            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1228.799707 | 88.088923  | 1323.381470 | 1116.512939 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1066.3776, current episode: 1
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1065.1182, current episode: 2
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1067.4535, current episode: 3
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1077.6266, current episode: 4
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1085.0775, current episode: 5
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1079.8179, current episode: 6
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1085.1404, current episode: 7
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1094.3473, current episode: 8
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1100.7598, current episode: 9
[2023-06-29 10:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1131.0624, current episode: 10
[2023-06-29 10:04:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 29500.000000 | iteration_29500.pth.tar | 10.000000     | 3350.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 335.000000              | 0.540772      | 6194.844883         | 18.492074            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1085.278101 | 18.941809  | 1131.062378 | 1065.118164 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1092.4185, current episode: 1
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1092.3635, current episode: 2
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1100.0734, current episode: 3
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1163.4718, current episode: 4
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1170.7207, current episode: 5
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1271.0034, current episode: 6
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1268.5002, current episode: 7
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1276.0806, current episode: 8
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1278.1027, current episode: 9
[2023-06-29 10:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1279.7622, current episode: 10
[2023-06-29 10:04:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 30000.000000 | iteration_30000.pth.tar | 10.000000     | 3800.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 380.000000              | 0.626929      | 6061.294042         | 15.950774            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1199.249695 | 79.570563  | 1279.762207 | 1092.363525 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1244.6069, current episode: 1
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1249.2617, current episode: 2
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1265.8955, current episode: 3
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1275.8795, current episode: 4
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1267.3016, current episode: 5
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1296.8124, current episode: 6
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1295.1985, current episode: 7
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1298.8113, current episode: 8
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1301.9174, current episode: 9
[2023-06-29 10:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1330.9417, current episode: 10
[2023-06-29 10:05:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 30500.000000 | iteration_30500.pth.tar | 10.000000     | 3970.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 397.000000              | 0.620726      | 6395.741500         | 16.110180            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1282.662646 | 25.390381  | 1330.941650 | 1244.606934 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1314.9153, current episode: 1
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1362.5577, current episode: 2
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1587.2812, current episode: 3
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1588.2606, current episode: 4
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1595.6447, current episode: 5
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1595.9590, current episode: 6
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1595.7963, current episode: 7
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1594.3218, current episode: 8
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1609.9849, current episode: 9
[2023-06-29 10:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2119.2139, current episode: 10
[2023-06-29 10:05:26][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 31000.000000 | iteration_31000.pth.tar | 10.000000     | 6350.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 635.000000              | 1.023019      | 6207.118082         | 9.774989             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1596.393530 | 201.888481 | 2119.213867 | 1314.915283 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1618.3784, current episode: 1
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1611.8605, current episode: 2
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1608.6990, current episode: 3
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1619.8124, current episode: 4
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1621.1047, current episode: 5
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1665.0046, current episode: 6
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1654.4840, current episode: 7
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1666.2653, current episode: 8
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1678.7335, current episode: 9
[2023-06-29 10:05:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1693.1211, current episode: 10
[2023-06-29 10:05:42][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 31500.000000 | iteration_31500.pth.tar | 10.000000     | 5130.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 513.000000              | 0.832522      | 6162.000428         | 12.011697            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1643.746350 | 29.513248  | 1693.121094 | 1608.698975 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 983.7278, current episode: 1
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1364.6124, current episode: 2
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1581.4493, current episode: 3
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1600.3363, current episode: 4
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1721.8473, current episode: 5
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1776.8353, current episode: 6
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1880.7876, current episode: 7
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1877.6670, current episode: 8
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1907.9460, current episode: 9
[2023-06-29 10:05:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1950.8385, current episode: 10
[2023-06-29 10:05:57][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 32000.000000 | iteration_32000.pth.tar | 10.000000     | 5850.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 585.000000              | 0.911453      | 6418.325399         | 10.971496            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1664.604767 | 285.268594 | 1950.838501 | 983.727844 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 1
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 2
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 3
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 4
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 5
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 6
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 133.9540, current episode: 7
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 249.5569, current episode: 8
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 275.6054, current episode: 9
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 9
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 9
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 9
[2023-06-29 10:06:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 133.9540, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 249.5569, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 275.6054, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 133.9540, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 249.5569, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 275.6054, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 133.9540, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 249.5569, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 275.6054, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 133.9540, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 249.5569, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 9
[2023-06-29 10:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 275.6054, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 151.7522, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.1028, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 133.9540, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 120.8894, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 249.5569, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 275.6054, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 132.0377, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 122.8989, current episode: 9
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1013.9229, current episode: 10
[2023-06-29 10:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 143.2978, current episode: 10
[2023-06-29 10:06:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 32500.000000 | iteration_32500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.824069      | 5482.247743         | 5.482248             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 249.801798  | 259.744863 | 1013.922913 | 120.889366 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 915.6967, current episode: 1
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 936.8755, current episode: 2
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 981.4958, current episode: 3
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 971.5663, current episode: 4
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 978.8013, current episode: 5
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 994.5488, current episode: 6
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1013.5255, current episode: 7
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1464.2770, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 915.6967, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 936.8755, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 981.4958, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 971.5663, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 978.8013, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 994.5488, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1013.5255, current episode: 8
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2329.5896, current episode: 9
[2023-06-29 10:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 915.6967, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 936.8755, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 981.4958, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1464.2770, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 971.5663, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 978.8013, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 994.5488, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1013.5255, current episode: 9
[2023-06-29 10:06:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3127.6555, current episode: 10
[2023-06-29 10:06:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 33000.000000 | iteration_33000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.623617      | 6159.086837         | 6.159087             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1371.403198 | 717.201571 | 3127.655518 | 915.696655 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 883.6317, current episode: 1
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 945.7463, current episode: 2
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 941.9292, current episode: 3
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1030.6605, current episode: 4
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1541.6063, current episode: 5
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1491.0638, current episode: 6
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 883.6317, current episode: 6
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 945.7463, current episode: 6
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 941.9292, current episode: 6
[2023-06-29 10:06:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1030.6605, current episode: 6
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2802.8401, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 883.6317, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 945.7463, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 941.9292, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1541.6063, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1491.0638, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1030.6605, current episode: 7
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3190.3809, current episode: 8
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3188.9927, current episode: 9
[2023-06-29 10:06:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3151.8250, current episode: 10
[2023-06-29 10:06:46][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 33500.000000 | iteration_33500.pth.tar | 10.000000     | 9999.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.601331      | 6244.180885         | 6.244805             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1916.867645 | 980.757661 | 3190.380859 | 883.631653 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:07:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2440.6763, current episode: 1
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3120.6890, current episode: 2
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3167.1089, current episode: 3
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3152.5842, current episode: 4
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3139.5339, current episode: 5
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3115.1470, current episode: 6
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3081.2588, current episode: 7
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3172.6165, current episode: 8
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3199.3765, current episode: 9
[2023-06-29 10:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3109.7749, current episode: 10
[2023-06-29 10:07:02][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 34000.000000 | iteration_34000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.647167      | 6071.031213         | 6.071031             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3069.876587 | 212.301270 | 3199.376465 | 2440.676270 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1198.7535, current episode: 1
[2023-06-29 10:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1342.6931, current episode: 2
[2023-06-29 10:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1346.1710, current episode: 3
[2023-06-29 10:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1351.6414, current episode: 4
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1198.7535, current episode: 4
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2539.7949, current episode: 5
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2615.3037, current episode: 6
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1342.6931, current episode: 6
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1346.1710, current episode: 6
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1351.6414, current episode: 6
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3220.1680, current episode: 7
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3260.2292, current episode: 8
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3202.5078, current episode: 9
[2023-06-29 10:07:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3265.4424, current episode: 10
[2023-06-29 10:07:18][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 34500.000000 | iteration_34500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.646516      | 6073.430233         | 6.073430             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2334.270508 | 871.715325 | 3265.442383 | 1198.753540 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1021.8408, current episode: 1
[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1563.3114, current episode: 2
[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1771.0944, current episode: 3
[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1890.0970, current episode: 4
[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1890.5763, current episode: 5
[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1904.7356, current episode: 6
[2023-06-29 10:07:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1021.8408, current episode: 6
[2023-06-29 10:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1021.8408, current episode: 6
[2023-06-29 10:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1563.3114, current episode: 6
[2023-06-29 10:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3163.0105, current episode: 7
[2023-06-29 10:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3172.2983, current episode: 8
[2023-06-29 10:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3127.2419, current episode: 9
[2023-06-29 10:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3239.8215, current episode: 10
[2023-06-29 10:07:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 35000.000000 | iteration_35000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.756445      | 5693.317024         | 5.693317             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2274.402777 | 775.548680 | 3239.821533 | 1021.840759 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2077.8850, current episode: 1
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2330.0525, current episode: 2
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2391.3005, current episode: 3
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2927.0083, current episode: 4
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2957.4468, current episode: 5
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2992.3267, current episode: 6
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2908.9592, current episode: 7
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2874.6509, current episode: 8
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3021.0901, current episode: 9
[2023-06-29 10:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2908.9670, current episode: 10
[2023-06-29 10:07:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 35500.000000 | iteration_35500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.567544      | 6379.406478         | 6.379406             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2738.968701 | 320.655177 | 3021.090088 | 2077.885010 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1714.9517, current episode: 1
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2252.4751, current episode: 2
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2252.3894, current episode: 3
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2298.8362, current episode: 4
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2409.4905, current episode: 5
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2679.0225, current episode: 6
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3032.1509, current episode: 7
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2842.0793, current episode: 8
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2998.4060, current episode: 9
[2023-06-29 10:08:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2842.8323, current episode: 10
[2023-06-29 10:08:08][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 36000.000000 | iteration_36000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.518618      | 6584.933749         | 6.584934             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2532.263379 | 396.903574 | 3032.150879 | 1714.951660 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:08:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1302.1586, current episode: 1
[2023-06-29 10:08:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1325.3879, current episode: 2
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1342.1240, current episode: 3
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1354.3984, current episode: 4
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1355.2103, current episode: 5
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1347.1276, current episode: 6
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1577.6177, current episode: 7
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1603.6934, current episode: 8
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1302.1586, current episode: 8
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1325.3879, current episode: 8
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1342.1240, current episode: 8
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1354.3984, current episode: 8
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1355.2103, current episode: 8
[2023-06-29 10:08:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1347.1276, current episode: 8
[2023-06-29 10:08:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1577.6177, current episode: 8
[2023-06-29 10:08:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1603.6934, current episode: 8
[2023-06-29 10:08:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2882.7117, current episode: 9
[2023-06-29 10:08:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3213.9128, current episode: 10
[2023-06-29 10:08:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 36500.000000 | iteration_36500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.785568      | 5600.460343         | 5.600460             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1730.434241 | 670.466665 | 3213.912842 | 1302.158569 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1010.4387, current episode: 1
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1009.4565, current episode: 2
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1023.9717, current episode: 3
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1029.1787, current episode: 4
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1043.6760, current episode: 5
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1049.4761, current episode: 6
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1050.4515, current episode: 7
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1047.7028, current episode: 8
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1269.6158, current episode: 9
[2023-06-29 10:08:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1494.5219, current episode: 10
[2023-06-29 10:08:40][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 37000.000000 | iteration_37000.pth.tar | 10.000000     | 4430.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 443.000000              | 0.750213      | 5904.987148         | 13.329542            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1102.848969 | 149.085975 | 1494.521851 | 1009.456482 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1019.6880, current episode: 1
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1118.6921, current episode: 2
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1130.8514, current episode: 3
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1140.1051, current episode: 4
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1201.6022, current episode: 5
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1223.6171, current episode: 6
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1241.1379, current episode: 7
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1309.4412, current episode: 8
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1327.7438, current episode: 9
[2023-06-29 10:08:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1383.4819, current episode: 10
[2023-06-29 10:08:56][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 37500.000000 | iteration_37500.pth.tar | 10.000000     | 4100.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 410.000000              | 0.655401      | 6255.713308         | 15.257837            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1209.636072 | 105.251079 | 1383.481934 | 1019.687988 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1342.2935, current episode: 1
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1377.9974, current episode: 2
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1415.6521, current episode: 3
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1520.6830, current episode: 4
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1512.9590, current episode: 5
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1532.1901, current episode: 6
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1565.3181, current episode: 7
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1635.6445, current episode: 8
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1806.5944, current episode: 9
[2023-06-29 10:09:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1820.9465, current episode: 10
[2023-06-29 10:09:12][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 38000.000000 | iteration_38000.pth.tar | 10.000000     | 5290.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 529.000000              | 0.844528      | 6263.854685         | 11.840935            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1553.027856 | 154.937280 | 1820.946533 | 1342.293457 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 893.4778, current episode: 1
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 966.6853, current episode: 2
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1021.2435, current episode: 3
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1025.1033, current episode: 4
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1027.5822, current episode: 5
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1035.8743, current episode: 6
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1060.4863, current episode: 7
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1097.6417, current episode: 8
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1121.1210, current episode: 9
[2023-06-29 10:09:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1211.1129, current episode: 10
[2023-06-29 10:09:27][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 38500.000000 | iteration_38500.pth.tar | 10.000000     | 3500.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 350.000000              | 0.564516      | 6200.004195         | 17.714298            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1046.032819 | 81.747966  | 1211.112915 | 893.477783 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1136.4824, current episode: 1
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1263.0361, current episode: 2
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1353.1212, current episode: 3
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1424.4207, current episode: 4
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1455.4574, current episode: 5
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1740.7000, current episode: 6
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1919.8973, current episode: 7
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1945.2954, current episode: 8
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2001.0101, current episode: 9
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1136.4824, current episode: 9
[2023-06-29 10:09:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2267.7649, current episode: 10
[2023-06-29 10:09:42][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 39000.000000 | iteration_39000.pth.tar | 10.000000     | 6640.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 664.000000              | 1.053207      | 6304.555621         | 9.494813             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1650.718555 | 355.445926 | 2267.764893 | 1136.482422 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:09:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1060.7417, current episode: 1
[2023-06-29 10:09:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1050.2507, current episode: 2
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1316.1241, current episode: 3
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1629.8853, current episode: 4
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1611.0305, current episode: 5
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1623.5227, current episode: 6
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1601.3157, current episode: 7
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1861.0748, current episode: 8
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1060.7417, current episode: 8
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1050.2507, current episode: 8
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2211.0049, current episode: 9
[2023-06-29 10:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2515.4917, current episode: 10
[2023-06-29 10:09:58][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 39500.000000 | iteration_39500.pth.tar | 10.000000     | 7560.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 756.000000              | 1.207172      | 6262.573251         | 8.283827             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1648.044214 | 439.512087 | 2515.491699 | 1050.250732 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1022.0102, current episode: 1
[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1032.5979, current episode: 2
[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1302.5729, current episode: 3
[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1413.0106, current episode: 4
[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1468.3467, current episode: 5
[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1519.9131, current episode: 6
[2023-06-29 10:10:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1573.3729, current episode: 7
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1880.3168, current episode: 8
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2094.9326, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1022.0102, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1032.5979, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1302.5729, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1413.0106, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1468.3467, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1519.9131, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1573.3729, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1022.0102, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1032.5979, current episode: 9
[2023-06-29 10:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3184.3376, current episode: 10
[2023-06-29 10:10:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 40000.000000 | iteration_40000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.643603      | 6084.196004         | 6.084196             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1649.141132 | 601.116782 | 3184.337646 | 1022.010193 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1011.2708, current episode: 1
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.4193, current episode: 2
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.3473, current episode: 3
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1292.8059, current episode: 4
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1296.4714, current episode: 5
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1307.8246, current episode: 6
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1494.7168, current episode: 7
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1011.2708, current episode: 7
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.4193, current episode: 7
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2149.3357, current episode: 8
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.3473, current episode: 8
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1292.8059, current episode: 8
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1296.4714, current episode: 8
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1307.8246, current episode: 8
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2720.7490, current episode: 9
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1494.7168, current episode: 9
[2023-06-29 10:10:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1011.2708, current episode: 9
[2023-06-29 10:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.4193, current episode: 9
[2023-06-29 10:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.3473, current episode: 9
[2023-06-29 10:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3269.5576, current episode: 10
[2023-06-29 10:10:31][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 40500.000000 | iteration_40500.pth.tar | 10.000000     | 9690.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 969.000000              | 1.543261      | 6278.911055         | 6.479784             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1661.949835 | 746.212117 | 3269.557617 | 1011.270752 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1951.4841, current episode: 1
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1972.4830, current episode: 2
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1940.4613, current episode: 3
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2302.9805, current episode: 4
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2346.5386, current episode: 5
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2811.1948, current episode: 6
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2823.5945, current episode: 7
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3233.4487, current episode: 8
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3248.1758, current episode: 9
[2023-06-29 10:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3233.6682, current episode: 10
[2023-06-29 10:10:46][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 41000.000000 | iteration_41000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.564762      | 6390.748892         | 6.390749             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2586.402954 | 521.294394 | 3248.175781 | 1940.461304 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:11:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1352.2766, current episode: 1
[2023-06-29 10:11:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1513.5734, current episode: 2
[2023-06-29 10:11:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1620.2560, current episode: 3
[2023-06-29 10:11:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1621.6177, current episode: 4
[2023-06-29 10:11:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1646.7009, current episode: 5
[2023-06-29 10:11:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1687.7404, current episode: 6
[2023-06-29 10:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1779.7484, current episode: 7
[2023-06-29 10:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2164.5903, current episode: 8
[2023-06-29 10:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2396.6733, current episode: 9
[2023-06-29 10:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1352.2766, current episode: 9
[2023-06-29 10:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1513.5734, current episode: 9
[2023-06-29 10:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3143.1575, current episode: 10
[2023-06-29 10:11:02][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 41500.000000 | iteration_41500.pth.tar | 10.000000     | 9250.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 925.000000              | 1.480152      | 6249.356723         | 6.756061             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1892.633447 | 508.954339 | 3143.157471 | 1352.276611 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 945.9241, current episode: 1
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 964.1116, current episode: 2
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 962.3770, current episode: 3
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 965.6621, current episode: 4
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 985.0358, current episode: 5
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 993.8436, current episode: 6
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 986.8259, current episode: 7
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 994.2274, current episode: 8
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 996.0551, current episode: 9
[2023-06-29 10:11:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1013.2666, current episode: 10
[2023-06-29 10:11:18][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 42000.000000 | iteration_42000.pth.tar | 10.000000     | 2900.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 290.000000              | 0.475788      | 6095.154040         | 21.017773            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 980.732910  | 19.377399  | 1013.266602 | 945.924072 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1018.0897, current episode: 1
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.2073, current episode: 2
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.6569, current episode: 3
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1053.0264, current episode: 4
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1056.3500, current episode: 5
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1635.9962, current episode: 6
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1878.8136, current episode: 7
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1018.0897, current episode: 7
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.2073, current episode: 7
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2104.9495, current episode: 8
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.6569, current episode: 8
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1053.0264, current episode: 8
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2145.7029, current episode: 9
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1056.3500, current episode: 9
[2023-06-29 10:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2709.1948, current episode: 10
[2023-06-29 10:11:33][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 42500.000000 | iteration_42500.pth.tar | 10.000000     | 7880.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 788.000000              | 1.239365      | 6358.096598         | 8.068651             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1568.098712 | 584.358659 | 2709.194824 | 1017.207275 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1065.5814, current episode: 1
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1376.3632, current episode: 2
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1610.3802, current episode: 3
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1951.6090, current episode: 4
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2111.8633, current episode: 5
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2138.2197, current episode: 6
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1065.5814, current episode: 6
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2214.2910, current episode: 7
[2023-06-29 10:11:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1376.3632, current episode: 7
[2023-06-29 10:11:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3023.0393, current episode: 8
[2023-06-29 10:11:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1610.3802, current episode: 8
[2023-06-29 10:11:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1065.5814, current episode: 8
[2023-06-29 10:11:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3255.6277, current episode: 9
[2023-06-29 10:11:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3265.5396, current episode: 10
[2023-06-29 10:11:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 43000.000000 | iteration_43000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.602687      | 6239.520032         | 6.239520             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2201.251440 | 728.939243 | 3265.539551 | 1065.581421 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 975.3441, current episode: 1
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 985.4102, current episode: 2
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1035.6610, current episode: 3
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1039.0314, current episode: 4
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1033.1624, current episode: 5
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1274.0382, current episode: 6
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1512.7642, current episode: 7
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1552.3640, current episode: 8
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1588.0596, current episode: 9
[2023-06-29 10:12:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1699.8829, current episode: 10
[2023-06-29 10:12:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 43500.000000 | iteration_43500.pth.tar | 10.000000     | 4920.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 492.000000              | 0.800243      | 6148.128900         | 12.496197            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1269.571790 | 275.101142 | 1699.882935 | 975.344055 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 725.0115, current episode: 1
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 748.9826, current episode: 2
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 756.3474, current episode: 3
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 757.9084, current episode: 4
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 764.5191, current episode: 5
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 766.0720, current episode: 6
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 770.8849, current episode: 7
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 777.9682, current episode: 8
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 797.1848, current episode: 9
[2023-06-29 10:12:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 805.9140, current episode: 10
[2023-06-29 10:12:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 44000.000000 | iteration_44000.pth.tar | 10.000000     | 2370.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 237.000000              | 0.383580      | 6178.639486         | 26.070209            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 767.079303  | 22.026261  | 805.914001 | 725.011536 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 849.5314, current episode: 1
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 850.1440, current episode: 2
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 854.2031, current episode: 3
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 861.9580, current episode: 4
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 879.8011, current episode: 5
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 888.7238, current episode: 6
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 900.9725, current episode: 7
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 909.2065, current episode: 8
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 982.6210, current episode: 9
[2023-06-29 10:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1026.7920, current episode: 10
[2023-06-29 10:12:34][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 44500.000000 | iteration_44500.pth.tar | 10.000000     | 2930.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 293.000000              | 0.490021      | 5979.331531         | 20.407275            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 900.395337  | 56.655959  | 1026.791992 | 849.531372 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:12:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 962.4204, current episode: 1
[2023-06-29 10:12:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 984.6985, current episode: 2
[2023-06-29 10:12:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1032.4386, current episode: 3
[2023-06-29 10:12:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1098.8872, current episode: 4
[2023-06-29 10:12:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1266.2649, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 962.4204, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 984.6985, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1032.4386, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1098.8872, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1266.2649, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 962.4204, current episode: 5
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2847.7300, current episode: 6
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 984.6985, current episode: 6
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1032.4386, current episode: 6
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1098.8872, current episode: 6
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3284.4214, current episode: 7
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3315.4395, current episode: 8
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3171.7302, current episode: 9
[2023-06-29 10:12:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3317.8826, current episode: 10
[2023-06-29 10:12:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 45000.000000 | iteration_45000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.585470      | 6307.278570         | 6.307279             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2128.191321 | 1069.493175 | 3317.882568 | 962.420410 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:13:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1026.9146, current episode: 1
[2023-06-29 10:13:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1033.8561, current episode: 2
[2023-06-29 10:13:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1055.2759, current episode: 3
[2023-06-29 10:13:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1338.0317, current episode: 4
[2023-06-29 10:13:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1026.9146, current episode: 4
[2023-06-29 10:13:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1033.8561, current episode: 4
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1055.2759, current episode: 4
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1338.0317, current episode: 4
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1026.9146, current episode: 4
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1033.8561, current episode: 4
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1055.2759, current episode: 4
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3356.1748, current episode: 5
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3346.9946, current episode: 6
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3363.2322, current episode: 7
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3354.0122, current episode: 8
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3358.8569, current episode: 9
[2023-06-29 10:13:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3354.4399, current episode: 10
[2023-06-29 10:13:06][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 45500.000000 | iteration_45500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.599867      | 6250.518365         | 6.250518             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2458.778894 | 1101.481260 | 3363.232178 | 1026.914551 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3354.4985, current episode: 1
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3360.8589, current episode: 2
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3340.0625, current episode: 3
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3321.8298, current episode: 4
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3346.2798, current episode: 5
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3351.6694, current episode: 6
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3337.3689, current episode: 7
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3349.0264, current episode: 8
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3359.7266, current episode: 9
[2023-06-29 10:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3331.4883, current episode: 10
[2023-06-29 10:13:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 46000.000000 | iteration_46000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535304      | 6513.366674         | 6.513367             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3345.280908 | 11.925500  | 3360.858887 | 3321.829834 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 280.8337, current episode: 1
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 282.6807, current episode: 2
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 281.4876, current episode: 3
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 282.3618, current episode: 4
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 281.0290, current episode: 5
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 289.8192, current episode: 6
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 288.8496, current episode: 7
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 289.5700, current episode: 8
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 303.2814, current episode: 9
[2023-06-29 10:13:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 306.4238, current episode: 10
[2023-06-29 10:13:37][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 46500.000000 | iteration_46500.pth.tar | 10.000000     | 1390.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 139.000000              | 0.248949      | 5583.465276         | 40.168815            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 288.633685  | 8.819766   | 306.423767 | 280.833740 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1369.5811, current episode: 1
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1422.6068, current episode: 2
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1425.9900, current episode: 3
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1421.2014, current episode: 4
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1676.2708, current episode: 5
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1742.7029, current episode: 6
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1892.6991, current episode: 7
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2592.1521, current episode: 8
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1369.5811, current episode: 8
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1422.6068, current episode: 8
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1425.9900, current episode: 8
[2023-06-29 10:13:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1421.2014, current episode: 8
[2023-06-29 10:13:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3249.0493, current episode: 9
[2023-06-29 10:13:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3219.9563, current episode: 10
[2023-06-29 10:13:53][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 47000.000000 | iteration_47000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.622712      | 6162.523776         | 6.162524             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2001.220972 | 705.469271 | 3249.049316 | 1369.581055 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 947.6269, current episode: 1
[2023-06-29 10:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1086.4584, current episode: 2
[2023-06-29 10:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1085.3887, current episode: 3
[2023-06-29 10:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1624.8555, current episode: 4
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 947.6269, current episode: 4
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1086.4584, current episode: 4
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1085.3887, current episode: 4
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 947.6269, current episode: 4
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2858.8516, current episode: 5
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1624.8555, current episode: 5
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1086.4584, current episode: 5
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1085.3887, current episode: 5
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3406.4824, current episode: 6
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3474.5554, current episode: 7
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3376.4954, current episode: 8
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3403.9565, current episode: 9
[2023-06-29 10:14:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3395.2593, current episode: 10
[2023-06-29 10:14:08][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 47500.000000 | iteration_47500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.605703      | 6227.801768         | 6.227802             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2465.992999 | 1070.070764 | 3474.555420 | 947.626892 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2257.9373, current episode: 1
[2023-06-29 10:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2677.7566, current episode: 2
[2023-06-29 10:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2874.4832, current episode: 3
[2023-06-29 10:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2874.3542, current episode: 4
[2023-06-29 10:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2889.0540, current episode: 5
[2023-06-29 10:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3145.6387, current episode: 6
[2023-06-29 10:14:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3287.5046, current episode: 7
[2023-06-29 10:14:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3412.7214, current episode: 8
[2023-06-29 10:14:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3405.8394, current episode: 9
[2023-06-29 10:14:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3475.3782, current episode: 10
[2023-06-29 10:14:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 48000.000000 | iteration_48000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.564243      | 6392.869453         | 6.392869             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3030.066748 | 367.995477 | 3475.378174 | 2257.937256 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3023.1951, current episode: 1
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3144.6265, current episode: 2
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3327.0198, current episode: 3
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3318.3076, current episode: 4
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3455.0234, current episode: 5
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3382.4702, current episode: 6
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3417.5647, current episode: 7
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3400.0171, current episode: 8
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3422.2317, current episode: 9
[2023-06-29 10:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3407.0134, current episode: 10
[2023-06-29 10:14:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 48500.000000 | iteration_48500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.716685      | 5825.180309         | 5.825180             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3329.746948 | 131.920155 | 3455.023438 | 3023.195068 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 742.6696, current episode: 1
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 758.5522, current episode: 2
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 758.8002, current episode: 3
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 823.7585, current episode: 4
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 847.0096, current episode: 5
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 861.8829, current episode: 6
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 898.3109, current episode: 7
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 899.4752, current episode: 8
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 905.0047, current episode: 9
[2023-06-29 10:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 919.7029, current episode: 10
[2023-06-29 10:14:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 49000.000000 | iteration_49000.pth.tar | 10.000000     | 2600.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 260.000000              | 0.420135      | 6188.481945         | 23.801854            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 841.516687  | 64.019349  | 919.702942 | 742.669556 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:15:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 850.3517, current episode: 1
[2023-06-29 10:15:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 867.9953, current episode: 2
[2023-06-29 10:15:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 980.1254, current episode: 3
[2023-06-29 10:15:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.2927, current episode: 4
[2023-06-29 10:15:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1022.8701, current episode: 5
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1380.4684, current episode: 6
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 850.3517, current episode: 6
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 867.9953, current episode: 6
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 980.1254, current episode: 6
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.2927, current episode: 6
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1022.8701, current episode: 6
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2489.9585, current episode: 7
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 850.3517, current episode: 7
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 867.9953, current episode: 7
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1380.4684, current episode: 7
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 980.1254, current episode: 7
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.2927, current episode: 7
[2023-06-29 10:15:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1022.8701, current episode: 7
[2023-06-29 10:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 850.3517, current episode: 7
[2023-06-29 10:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 867.9953, current episode: 7
[2023-06-29 10:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3357.4390, current episode: 8
[2023-06-29 10:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3413.2031, current episode: 9
[2023-06-29 10:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3421.4976, current episode: 10
[2023-06-29 10:15:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 49500.000000 | iteration_49500.pth.tar | 10.000000     | 9999.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.590895      | 6285.140341         | 6.285769             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1877.520166 | 1093.153604 | 3421.497559 | 850.351685 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1082.5420, current episode: 1
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1095.4691, current episode: 2
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1168.0159, current episode: 3
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1180.2960, current episode: 4
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1192.2471, current episode: 5
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1082.5420, current episode: 5
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1095.4691, current episode: 5
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2241.1648, current episode: 6
[2023-06-29 10:15:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1168.0159, current episode: 6
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1180.2960, current episode: 6
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1192.2471, current episode: 6
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2860.7000, current episode: 7
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1082.5420, current episode: 7
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1095.4691, current episode: 7
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3465.5742, current episode: 8
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1168.0159, current episode: 8
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3276.3816, current episode: 9
[2023-06-29 10:15:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3445.7280, current episode: 10
[2023-06-29 10:15:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 50000.000000 | iteration_50000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.567087      | 6381.267987         | 6.381268             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2100.811865 | 1011.978466 | 3465.574219 | 1082.541992 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 10:15:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1022.0143, current episode: 1
[2023-06-29 10:15:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1027.0222, current episode: 2
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1025.8850, current episode: 3
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1037.8463, current episode: 4
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1037.1298, current episode: 5
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1028.8539, current episode: 6
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1035.2605, current episode: 7
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1065.6917, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1022.0143, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1027.0222, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1025.8850, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1037.8463, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1037.1298, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1028.8539, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1035.2605, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1065.6917, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1022.0143, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1027.0222, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1025.8850, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1037.8463, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1037.1298, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1028.8539, current episode: 8
[2023-06-29 10:15:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1035.2605, current episode: 8
[2023-06-29 10:15:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1065.6917, current episode: 8
[2023-06-29 10:15:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3388.6021, current episode: 9
[2023-06-29 10:15:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3328.5374, current episode: 10
[2023-06-29 10:15:41][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 50500.000000 | iteration_50500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.613563      | 6197.463035         | 6.197463             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1499.684302 | 929.610080 | 3388.602051 | 1022.014282 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1330.1593, current episode: 1
[2023-06-29 10:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1330.8046, current episode: 2
[2023-06-29 10:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1344.1704, current episode: 3
[2023-06-29 10:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1368.2283, current episode: 4
[2023-06-29 10:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1362.5626, current episode: 5
[2023-06-29 10:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1412.5490, current episode: 6
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1902.8125, current episode: 7
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1951.2959, current episode: 8
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2553.6743, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1330.1593, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1330.8046, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1344.1704, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1368.2283, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1362.5626, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1412.5490, current episode: 9
[2023-06-29 10:15:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3406.9548, current episode: 10
[2023-06-29 10:15:56][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 51000.000000 | iteration_51000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.581467      | 6323.242749         | 6.323243             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1796.321167 | 660.320088 | 3406.954834 | 1330.159302 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1002.1064, current episode: 1
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1055.2822, current episode: 2
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1379.7906, current episode: 3
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1375.4961, current episode: 4
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1567.9424, current episode: 5
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1616.3049, current episode: 6
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1858.8164, current episode: 7
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1905.5874, current episode: 8
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1002.1064, current episode: 8
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1997.8586, current episode: 9
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1055.2822, current episode: 9
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1379.7906, current episode: 9
[2023-06-29 10:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1375.4961, current episode: 9
[2023-06-29 10:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2858.1580, current episode: 10
[2023-06-29 10:16:12][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 51500.000000 | iteration_51500.pth.tar | 10.000000     | 8140.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 814.000000              | 1.300235      | 6260.407431         | 7.690918             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1661.734308 | 511.653518 | 2858.157959 | 1002.106384 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 978.7365, current episode: 1
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1034.2222, current episode: 2
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1400.2642, current episode: 3
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1398.9896, current episode: 4
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1418.9755, current episode: 5
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1432.1661, current episode: 6
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1652.2186, current episode: 7
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 978.7365, current episode: 7
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1950.3879, current episode: 8
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1974.8145, current episode: 9
[2023-06-29 10:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1034.2222, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1400.2642, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1398.9896, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1418.9755, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1432.1661, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 978.7365, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1034.2222, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1652.2186, current episode: 9
[2023-06-29 10:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3349.0107, current episode: 10
[2023-06-29 10:16:27][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 52000.000000 | iteration_52000.pth.tar | 10.000000     | 9260.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 926.000000              | 1.511027      | 6128.283864         | 6.618017             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1658.978577 | 643.237813 | 3349.010742 | 978.736450 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 860.1706, current episode: 1
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 868.8665, current episode: 2
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 940.7838, current episode: 3
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 944.0692, current episode: 4
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 945.5408, current episode: 5
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 949.8381, current episode: 6
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 959.9685, current episode: 7
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.5438, current episode: 8
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 970.4802, current episode: 9
[2023-06-29 10:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.8916, current episode: 10
[2023-06-29 10:16:42][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 52500.000000 | iteration_52500.pth.tar | 10.000000     | 2800.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 280.000000              | 0.461511      | 6067.023422         | 21.667941            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 939.015295  | 39.915003  | 991.891602 | 860.170593 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 925.4808, current episode: 1
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 991.6852, current episode: 2
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1018.7365, current episode: 3
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1024.0186, current episode: 4
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1020.3587, current episode: 5
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1026.1674, current episode: 6
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1027.9082, current episode: 7
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1041.5286, current episode: 8
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1040.3502, current episode: 9
[2023-06-29 10:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1050.0470, current episode: 10
[2023-06-29 10:16:57][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 53000.000000 | iteration_53000.pth.tar | 10.000000     | 2910.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 291.000000              | 0.470284      | 6187.750827         | 21.263749            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1016.628101 | 33.942302  | 1050.046997 | 925.480774 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1668.9233, current episode: 1
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1687.2152, current episode: 2
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1725.1509, current episode: 3
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1790.4761, current episode: 4
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1938.2512, current episode: 5
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2518.0918, current episode: 6
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2730.1584, current episode: 7
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2744.8599, current episode: 8
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3178.8533, current episode: 9
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1668.9233, current episode: 9
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1687.2152, current episode: 9
[2023-06-29 10:17:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1725.1509, current episode: 9
[2023-06-29 10:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1790.4761, current episode: 9
[2023-06-29 10:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3479.1606, current episode: 10
[2023-06-29 10:17:13][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 53500.000000 | iteration_53500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.587145      | 6300.620994         | 6.300621             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2346.114075 | 637.709159 | 3479.160645 | 1668.923340 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:17:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1052.5015, current episode: 1
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1863.3457, current episode: 2
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1052.5015, current episode: 2
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1052.5015, current episode: 2
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3514.6826, current episode: 3
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3505.6946, current episode: 4
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3498.6270, current episode: 5
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3490.8237, current episode: 6
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3465.6213, current episode: 7
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3493.0205, current episode: 8
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3514.0408, current episode: 9
[2023-06-29 10:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.6511, current episode: 10
[2023-06-29 10:17:28][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 54000.000000 | iteration_54000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522880      | 6566.503968         | 6.566504             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3091.300879 | 836.690693 | 3514.682617 | 1052.501465 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3490.6658, current episode: 1
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3510.8882, current episode: 2
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3469.5381, current episode: 3
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3475.4688, current episode: 4
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3497.3311, current episode: 5
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3513.4473, current episode: 6
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3492.1536, current episode: 7
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3461.3828, current episode: 8
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3482.4490, current episode: 9
[2023-06-29 10:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3482.1555, current episode: 10
[2023-06-29 10:17:44][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 54500.000000 | iteration_54500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517104      | 6591.505374         | 6.591505             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3487.547998 | 15.975410  | 3513.447266 | 3461.382812 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1985.8630, current episode: 1
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2645.7742, current episode: 2
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.6213, current episode: 3
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3483.4502, current episode: 4
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3500.2822, current episode: 5
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3478.2510, current episode: 6
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3508.7429, current episode: 7
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3492.0708, current episode: 8
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.7244, current episode: 9
[2023-06-29 10:18:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3502.6323, current episode: 10
[2023-06-29 10:18:00][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 55000.000000 | iteration_55000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547527      | 6461.921361         | 6.461921             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3259.441235 | 494.428692 | 3508.742920 | 1985.863037 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3504.5125, current episode: 1
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3475.5779, current episode: 2
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3510.2986, current episode: 3
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3488.4443, current episode: 4
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3501.0193, current episode: 5
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3506.8555, current episode: 6
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.4487, current episode: 7
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3502.6724, current episode: 8
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.0510, current episode: 9
[2023-06-29 10:18:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.9043, current episode: 10
[2023-06-29 10:18:16][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 55500.000000 | iteration_55500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.526220      | 6552.137039         | 6.552137             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3495.078442 | 16.214858  | 3510.298584 | 3457.051025 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3480.5649, current episode: 1
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3524.8469, current episode: 2
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3465.5789, current episode: 3
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3498.7256, current episode: 4
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3406.6570, current episode: 5
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3503.9058, current episode: 6
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3483.2019, current episode: 7
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3505.5598, current episode: 8
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3538.4121, current episode: 9
[2023-06-29 10:18:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.3459, current episode: 10
[2023-06-29 10:18:32][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 56000.000000 | iteration_56000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509336      | 6625.430265         | 6.625430             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3489.779883 | 34.273860  | 3538.412109 | 3406.656982 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3519.1477, current episode: 1
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3393.7295, current episode: 2
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3523.5620, current episode: 3
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3290.2671, current episode: 4
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3438.3237, current episode: 5
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3391.0564, current episode: 6
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3402.1899, current episode: 7
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3482.3286, current episode: 8
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3444.6519, current episode: 9
[2023-06-29 10:18:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3374.3582, current episode: 10
[2023-06-29 10:18:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 56500.000000 | iteration_56500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522818      | 6566.770841         | 6.566771             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3425.961499 | 67.666216  | 3523.562012 | 3290.267090 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3431.8894, current episode: 1
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3478.0647, current episode: 2
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3459.0701, current episode: 3
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3461.7773, current episode: 4
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3499.3962, current episode: 5
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3467.6912, current episode: 6
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3534.8433, current episode: 7
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3530.6184, current episode: 8
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3546.0776, current episode: 9
[2023-06-29 10:19:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3436.9504, current episode: 10
[2023-06-29 10:19:04][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 57000.000000 | iteration_57000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.531406      | 6529.948526         | 6.529949             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3484.637866 | 38.975186  | 3546.077637 | 3431.889404 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2038.5571, current episode: 1
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2468.5063, current episode: 2
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2536.0239, current episode: 3
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3039.6091, current episode: 4
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3539.0298, current episode: 5
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3500.7942, current episode: 6
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3533.5803, current episode: 7
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3639.0515, current episode: 8
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3541.6301, current episode: 9
[2023-06-29 10:19:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3482.1689, current episode: 10
[2023-06-29 10:19:19][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 57500.000000 | iteration_57500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.543052      | 6480.663502         | 6.480664             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3131.895142 | 548.637413 | 3639.051514 | 2038.557129 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:19:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1021.4630, current episode: 1
[2023-06-29 10:19:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1055.6842, current episode: 2
[2023-06-29 10:19:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1061.9088, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1021.4630, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1055.6842, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1061.9088, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1021.4630, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1055.6842, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1061.9088, current episode: 3
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3526.9028, current episode: 4
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3496.3887, current episode: 5
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3517.1199, current episode: 6
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3510.0613, current episode: 7
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3538.6541, current episode: 8
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3484.9333, current episode: 9
[2023-06-29 10:19:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3525.0435, current episode: 10
[2023-06-29 10:19:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 58000.000000 | iteration_58000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.579682      | 6330.389944         | 6.330390             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2773.815948 | 1131.024355 | 3538.654053 | 1021.462952 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3507.0325, current episode: 1
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3503.8167, current episode: 2
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3507.3704, current episode: 3
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3519.3467, current episode: 4
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3513.6831, current episode: 5
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3521.8037, current episode: 6
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.8640, current episode: 7
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3514.5247, current episode: 8
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3486.0972, current episode: 9
[2023-06-29 10:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.0959, current episode: 10
[2023-06-29 10:19:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 58500.000000 | iteration_58500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.586769      | 6302.113408         | 6.302113             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3509.763477 | 9.498748   | 3521.803711 | 3486.097168 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2066.7139, current episode: 1
[2023-06-29 10:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2815.1738, current episode: 2
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3029.8250, current episode: 3
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3339.2861, current episode: 4
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3181.3091, current episode: 5
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3261.5322, current episode: 6
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3181.8870, current episode: 7
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3286.0229, current episode: 8
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3325.6440, current episode: 9
[2023-06-29 10:20:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3328.9810, current episode: 10
[2023-06-29 10:20:07][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 59000.000000 | iteration_59000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.581365      | 6323.651785         | 6.323652             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3081.637500 | 372.152940 | 3339.286133 | 2066.713867 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3479.4497, current episode: 1
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3468.3755, current episode: 2
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3464.8765, current episode: 3
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3464.4863, current episode: 4
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3460.3975, current episode: 5
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3474.4683, current episode: 6
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3475.1072, current episode: 7
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3484.1025, current episode: 8
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3486.1526, current episode: 9
[2023-06-29 10:20:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3474.4075, current episode: 10
[2023-06-29 10:20:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 59500.000000 | iteration_59500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519724      | 6580.141659         | 6.580142             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3473.182349 | 8.153433   | 3486.152588 | 3460.397461 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3507.5669, current episode: 1
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3481.8420, current episode: 2
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3497.0125, current episode: 3
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3496.9939, current episode: 4
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3499.7756, current episode: 5
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.7458, current episode: 6
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3495.3066, current episode: 7
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3497.0925, current episode: 8
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3488.7156, current episode: 9
[2023-06-29 10:20:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3501.1150, current episode: 10
[2023-06-29 10:20:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 60000.000000 | iteration_60000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.620034      | 6172.709736         | 6.172710             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3496.316650 | 6.583728   | 3507.566895 | 3481.842041 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:20:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1263.1273, current episode: 1
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1540.5956, current episode: 2
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1734.7645, current episode: 3
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1263.1273, current episode: 3
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1540.5956, current episode: 3
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1734.7645, current episode: 3
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3448.7144, current episode: 4
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3425.1667, current episode: 5
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3422.3586, current episode: 6
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3434.2461, current episode: 7
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3431.5217, current episode: 8
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3439.9563, current episode: 9
[2023-06-29 10:20:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3447.3933, current episode: 10
[2023-06-29 10:20:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 60500.000000 | iteration_60500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548413      | 6458.226971         | 6.458227             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2858.784460 | 887.524176 | 3448.714355 | 1263.127319 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3348.7368, current episode: 1
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3416.3152, current episode: 2
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3407.6458, current episode: 3
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3411.6841, current episode: 4
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3392.0813, current episode: 5
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3433.5801, current episode: 6
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3431.4216, current episode: 7
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3457.6108, current episode: 8
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3436.9124, current episode: 9
[2023-06-29 10:21:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3420.6353, current episode: 10
[2023-06-29 10:21:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 61000.000000 | iteration_61000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.565579      | 6387.414299         | 6.387414             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3415.662329 | 28.144235  | 3457.610840 | 3348.736816 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:21:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1853.2579, current episode: 1
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2763.7441, current episode: 2
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3305.6333, current episode: 3
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3206.6917, current episode: 4
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3269.0435, current episode: 5
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3327.2949, current episode: 6
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3346.0913, current episode: 7
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3257.7754, current episode: 8
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3216.1313, current episode: 9
[2023-06-29 10:21:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3313.3577, current episode: 10
[2023-06-29 10:21:26][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 61500.000000 | iteration_61500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523239      | 6564.956850         | 6.564957             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3085.902112 | 440.887185 | 3346.091309 | 1853.257935 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 741.7916, current episode: 1
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 790.9210, current episode: 2
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 845.2896, current episode: 3
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 901.6735, current episode: 4
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 924.2117, current episode: 5
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 930.4528, current episode: 6
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 944.8867, current episode: 7
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 946.6466, current episode: 8
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1058.8832, current episode: 9
[2023-06-29 10:21:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1169.5978, current episode: 10
[2023-06-29 10:21:41][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 62000.000000 | iteration_62000.pth.tar | 10.000000     | 3140.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 314.000000              | 0.518339      | 6057.813852         | 19.292401            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 925.435437  | 117.083600 | 1169.597778 | 741.791565 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1107.3600, current episode: 1
[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1147.4651, current episode: 2
[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1357.2023, current episode: 3
[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1796.1852, current episode: 4
[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1923.1228, current episode: 5
[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1545.8013, current episode: 6
[2023-06-29 10:21:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1802.7074, current episode: 7
[2023-06-29 10:21:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1881.4541, current episode: 8
[2023-06-29 10:21:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1107.3600, current episode: 8
[2023-06-29 10:21:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1147.4651, current episode: 8
[2023-06-29 10:21:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2580.8481, current episode: 9
[2023-06-29 10:21:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2906.7100, current episode: 10
[2023-06-29 10:21:57][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 62500.000000 | iteration_62500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.588682      | 6294.527326         | 6.294527             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1804.885620 | 549.758745 | 2906.709961 | 1107.359985 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1302.7518, current episode: 1
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1541.0829, current episode: 2
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1477.0814, current episode: 3
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1454.2767, current episode: 4
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1509.7036, current episode: 5
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1873.8739, current episode: 6
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2143.4778, current episode: 7
[2023-06-29 10:22:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2252.1101, current episode: 8
[2023-06-29 10:22:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1302.7518, current episode: 8
[2023-06-29 10:22:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2784.8794, current episode: 9
[2023-06-29 10:22:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1541.0829, current episode: 9
[2023-06-29 10:22:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3088.5930, current episode: 10
[2023-06-29 10:22:13][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 63000.000000 | iteration_63000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.576496      | 6343.179974         | 6.343180             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1942.783069 | 581.101886 | 3088.593018 | 1302.751831 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:22:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1661.8304, current episode: 1
[2023-06-29 10:22:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1770.3992, current episode: 2
[2023-06-29 10:22:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1858.5189, current episode: 3
[2023-06-29 10:22:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1894.0049, current episode: 4
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2264.0205, current episode: 5
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2565.9558, current episode: 6
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2516.9082, current episode: 7
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2826.3057, current episode: 8
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1661.8304, current episode: 8
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3506.2056, current episode: 9
[2023-06-29 10:22:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3422.4834, current episode: 10
[2023-06-29 10:22:29][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 63500.000000 | iteration_63500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.551660      | 6444.710177         | 6.444710             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2428.663257 | 631.894560 | 3506.205566 | 1661.830444 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1251.3708, current episode: 1
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1291.1080, current episode: 2
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1298.0435, current episode: 3
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1314.3605, current episode: 4
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1335.1316, current episode: 5
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1349.0559, current episode: 6
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1402.9462, current episode: 7
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1374.5089, current episode: 8
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1968.8634, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1251.3708, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1291.1080, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1298.0435, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1314.3605, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1335.1316, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1349.0559, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1402.9462, current episode: 9
[2023-06-29 10:22:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1374.5089, current episode: 9
[2023-06-29 10:22:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3482.8489, current episode: 10
[2023-06-29 10:22:45][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 64000.000000 | iteration_64000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.532021      | 6527.327247         | 6.527327             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1606.823767 | 655.228460 | 3482.848877 | 1251.370850 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1701.4694, current episode: 1
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1700.2783, current episode: 2
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1698.5768, current episode: 3
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1768.1287, current episode: 4
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1765.6425, current episode: 5
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1778.0695, current episode: 6
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1791.7885, current episode: 7
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1801.8260, current episode: 8
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1842.5950, current episode: 9
[2023-06-29 10:23:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1888.1146, current episode: 10
[2023-06-29 10:23:00][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 64500.000000 | iteration_64500.pth.tar | 10.000000     | 5210.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 521.000000              | 0.802292      | 6493.899006         | 12.464298            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1773.648914 | 59.432336  | 1888.114624 | 1698.576782 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1507.6632, current episode: 1
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1510.3654, current episode: 2
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1524.0446, current episode: 3
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1538.6200, current episode: 4
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1557.3712, current episode: 5
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1570.1670, current episode: 6
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1578.0718, current episode: 7
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1608.6604, current episode: 8
[2023-06-29 10:23:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1691.6418, current episode: 9
[2023-06-29 10:23:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1881.2948, current episode: 10
[2023-06-29 10:23:15][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 65000.000000 | iteration_65000.pth.tar | 10.000000     | 5230.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 523.000000              | 0.781716      | 6690.405096         | 12.792362            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1596.790015 | 108.065818 | 1881.294800 | 1507.663208 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:23:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1613.8552, current episode: 1
[2023-06-29 10:23:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2218.3257, current episode: 2
[2023-06-29 10:23:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2446.3113, current episode: 3
[2023-06-29 10:23:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2470.8359, current episode: 4
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3058.4177, current episode: 5
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3108.9529, current episode: 6
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1613.8552, current episode: 6
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3477.5278, current episode: 7
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3488.8420, current episode: 8
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3472.9731, current episode: 9
[2023-06-29 10:23:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3466.8381, current episode: 10
[2023-06-29 10:23:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 65500.000000 | iteration_65500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525355      | 6555.851017         | 6.555851             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2882.287988 | 624.848852 | 3488.842041 | 1613.855225 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3465.2546, current episode: 1
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3467.8291, current episode: 2
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3466.5737, current episode: 3
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3462.2217, current episode: 4
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3469.1326, current episode: 5
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3464.1558, current episode: 6
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3471.5742, current episode: 7
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3469.5657, current episode: 8
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3471.2563, current episode: 9
[2023-06-29 10:23:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3466.3721, current episode: 10
[2023-06-29 10:23:45][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 66000.000000 | iteration_66000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493358      | 6696.318365         | 6.696318             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3467.393579 | 2.895742   | 3471.574219 | 3462.221680 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3491.9087, current episode: 1
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3493.1951, current episode: 2
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3487.0066, current episode: 3
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3489.2563, current episode: 4
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3491.6150, current episode: 5
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3492.2666, current episode: 6
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3487.6460, current episode: 7
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3490.9016, current episode: 8
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3489.0762, current episode: 9
[2023-06-29 10:24:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3488.1484, current episode: 10
[2023-06-29 10:24:01][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 66500.000000 | iteration_66500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514381      | 6603.359749         | 6.603360             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3490.102051 | 2.040652   | 3493.195068 | 3487.006592 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3470.0173, current episode: 1
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3471.7314, current episode: 2
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3468.7288, current episode: 3
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3472.6069, current episode: 4
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3467.8206, current episode: 5
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3472.3958, current episode: 6
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3472.3889, current episode: 7
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3470.9885, current episode: 8
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3464.9829, current episode: 9
[2023-06-29 10:24:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3469.9312, current episode: 10
[2023-06-29 10:24:16][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 67000.000000 | iteration_67000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523183      | 6565.200973         | 6.565201             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3470.159229 | 2.313146   | 3472.606934 | 3464.982910 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3486.4553, current episode: 1
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3483.5710, current episode: 2
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3484.5581, current episode: 3
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3487.9155, current episode: 4
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3483.5481, current episode: 5
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3488.0874, current episode: 6
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.3481, current episode: 7
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3485.9556, current episode: 8
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3482.5464, current episode: 9
[2023-06-29 10:24:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3481.0781, current episode: 10
[2023-06-29 10:24:32][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 67500.000000 | iteration_67500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504420      | 6647.079744         | 6.647080             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3484.806372 | 2.164716   | 3488.087402 | 3481.078125 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1530.9739, current episode: 1
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1538.6840, current episode: 2
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1561.6520, current episode: 3
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1593.6101, current episode: 4
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1621.0424, current episode: 5
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1631.1158, current episode: 6
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1637.9786, current episode: 7
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1772.6554, current episode: 8
[2023-06-29 10:24:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1786.3486, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1530.9739, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1538.6840, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1561.6520, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1593.6101, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1621.0424, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1631.1158, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1637.9786, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1772.6554, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1786.3486, current episode: 9
[2023-06-29 10:24:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3526.6860, current episode: 10
[2023-06-29 10:24:47][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 68000.000000 | iteration_68000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.567590      | 6379.219692         | 6.379220             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1820.074683 | 574.910005 | 3526.686035 | 1530.973877 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:25:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1347.4788, current episode: 1
[2023-06-29 10:25:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1338.9347, current episode: 2
[2023-06-29 10:25:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1354.3026, current episode: 3
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1968.5614, current episode: 4
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1990.8522, current episode: 5
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2326.2729, current episode: 6
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1347.4788, current episode: 6
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1338.9347, current episode: 6
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1354.3026, current episode: 6
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3496.0618, current episode: 7
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3495.9924, current episode: 8
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3486.5596, current episode: 9
[2023-06-29 10:25:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3476.0693, current episode: 10
[2023-06-29 10:25:02][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 68500.000000 | iteration_68500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510457      | 6620.511658         | 6.620512             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2428.108569 | 917.567832 | 3496.061768 | 1338.934692 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1351.1736, current episode: 1
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1357.8987, current episode: 2
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1378.0995, current episode: 3
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1657.4437, current episode: 4
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1351.1736, current episode: 4
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1357.8987, current episode: 4
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1378.0995, current episode: 4
[2023-06-29 10:25:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1657.4437, current episode: 4
[2023-06-29 10:25:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3453.1814, current episode: 5
[2023-06-29 10:25:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3478.3616, current episode: 6
[2023-06-29 10:25:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3458.1533, current episode: 7
[2023-06-29 10:25:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3459.1501, current episode: 8
[2023-06-29 10:25:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.0242, current episode: 9
[2023-06-29 10:25:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3460.2961, current episode: 10
[2023-06-29 10:25:18][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 69000.000000 | iteration_69000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496498      | 6682.266234         | 6.682266             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2651.078223 | 995.306484 | 3478.361572 | 1351.173584 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:25:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2002.9835, current episode: 1
[2023-06-29 10:25:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1945.2452, current episode: 2
[2023-06-29 10:25:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2183.2375, current episode: 3
[2023-06-29 10:25:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2295.1191, current episode: 4
[2023-06-29 10:25:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3453.3022, current episode: 5
[2023-06-29 10:25:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3480.2534, current episode: 6
[2023-06-29 10:25:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3460.7734, current episode: 7
[2023-06-29 10:25:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3450.1946, current episode: 8
[2023-06-29 10:25:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3452.9214, current episode: 9
[2023-06-29 10:25:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3459.2173, current episode: 10
[2023-06-29 10:25:33][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 69500.000000 | iteration_69500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488533      | 6718.021700         | 6.718022             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2918.324780 | 668.650198 | 3480.253418 | 1945.245239 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:25:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1518.3071, current episode: 1
[2023-06-29 10:25:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1521.6660, current episode: 2
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1643.4525, current episode: 3
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2559.9163, current episode: 4
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2850.0530, current episode: 5
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1518.3071, current episode: 5
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1521.6660, current episode: 5
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1643.4525, current episode: 5
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3474.5820, current episode: 6
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3494.4866, current episode: 7
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3480.1838, current episode: 8
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3482.0500, current episode: 9
[2023-06-29 10:25:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3492.2883, current episode: 10
[2023-06-29 10:25:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 70000.000000 | iteration_70000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.518781      | 6584.228779         | 6.584229             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2751.698572 | 836.407178 | 3494.486572 | 1518.307129 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 734.1533, current episode: 1
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 743.6851, current episode: 2
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 953.4011, current episode: 3
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.6190, current episode: 4
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 986.1866, current episode: 5
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1007.2042, current episode: 6
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 734.1533, current episode: 6
[2023-06-29 10:26:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 743.6851, current episode: 6
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1629.7657, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 953.4011, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.6190, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 986.1866, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1007.2042, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 734.1533, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 743.6851, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 953.4011, current episode: 7
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3036.5894, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.6190, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 986.1866, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1007.2042, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 734.1533, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 743.6851, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1629.7657, current episode: 8
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3506.8396, current episode: 9
[2023-06-29 10:26:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3508.9563, current episode: 10
[2023-06-29 10:26:04][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 70500.000000 | iteration_70500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.559369      | 6412.849748         | 6.412850             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1709.040033 | 1106.123149 | 3508.956299 | 734.153259 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:26:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1003.5288, current episode: 1
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1004.5600, current episode: 2
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1231.5872, current episode: 3
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1283.0840, current episode: 4
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1302.4524, current episode: 5
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1317.2865, current episode: 6
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1003.5288, current episode: 6
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1811.1178, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1004.5600, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1231.5872, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1283.0840, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1302.4524, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1317.2865, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1003.5288, current episode: 7
[2023-06-29 10:26:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1004.5600, current episode: 7
[2023-06-29 10:26:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3292.3330, current episode: 8
[2023-06-29 10:26:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3451.5796, current episode: 9
[2023-06-29 10:26:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3476.8101, current episode: 10
[2023-06-29 10:26:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 71000.000000 | iteration_71000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.574623      | 6350.726302         | 6.350726             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1917.433929 | 998.330290 | 3476.810059 | 1003.528809 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:26:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 1
[2023-06-29 10:26:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 639.6857, current episode: 2
[2023-06-29 10:26:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 2
[2023-06-29 10:26:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 948.6072, current episode: 3
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1313.3323, current episode: 4
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 4
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1067.0756, current episode: 5
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 639.6857, current episode: 5
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1233.8251, current episode: 6
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1544.9335, current episode: 7
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 7
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1625.2616, current episode: 8
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1764.5513, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 639.6857, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 948.6072, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1313.3323, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1067.0756, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 639.6857, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1233.8251, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1544.9335, current episode: 9
[2023-06-29 10:26:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 948.6072, current episode: 9
[2023-06-29 10:26:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3276.0586, current episode: 10
[2023-06-29 10:26:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 234.7878, current episode: 10
[2023-06-29 10:26:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 71500.000000 | iteration_71500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.570083      | 6369.089020         | 6.369089             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1364.811853 | 774.427323 | 3276.058594 | 234.787781 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 989.6630, current episode: 1
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 999.4724, current episode: 2
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1004.2631, current episode: 3
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1002.2156, current episode: 4
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1011.0222, current episode: 5
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1015.8684, current episode: 6
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1211.9825, current episode: 7
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1246.3828, current episode: 8
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1334.4550, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 989.6630, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 999.4724, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1004.2631, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1002.2156, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1011.0222, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1015.8684, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1211.9825, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1246.3828, current episode: 9
[2023-06-29 10:26:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1334.4550, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 989.6630, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 999.4724, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1004.2631, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1002.2156, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1011.0222, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1015.8684, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1211.9825, current episode: 9
[2023-06-29 10:26:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3344.0310, current episode: 10
[2023-06-29 10:26:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 72000.000000 | iteration_72000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.559084      | 6414.023661         | 6.414024             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1315.935602 | 686.610008 | 3344.031006 | 989.662964 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 700.1469, current episode: 1
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 701.1163, current episode: 2
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 709.0566, current episode: 3
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 704.0765, current episode: 4
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 706.7598, current episode: 5
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 707.4601, current episode: 6
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 707.9165, current episode: 7
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 712.1749, current episode: 8
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 710.4108, current episode: 9
[2023-06-29 10:27:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 709.0577, current episode: 10
[2023-06-29 10:27:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 72500.000000 | iteration_72500.pth.tar | 10.000000     | 2170.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 217.000000              | 0.341235      | 6359.249610         | 29.305298            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 706.817609  | 3.711935   | 712.174866 | 700.146851 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 702.8939, current episode: 1
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 701.6142, current episode: 2
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 705.2805, current episode: 3
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 708.6990, current episode: 4
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 710.6022, current episode: 5
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 712.0524, current episode: 6
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 707.6246, current episode: 7
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 708.7650, current episode: 8
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 715.1531, current episode: 9
[2023-06-29 10:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 715.4937, current episode: 10
[2023-06-29 10:27:19][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 73000.000000 | iteration_73000.pth.tar | 10.000000     | 2190.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 219.000000              | 0.357519      | 6125.547313         | 27.970536            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 708.817865  | 4.464173   | 715.493652 | 701.614197 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 939.9148, current episode: 1
[2023-06-29 10:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 969.6801, current episode: 2
[2023-06-29 10:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 977.3225, current episode: 3
[2023-06-29 10:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.0085, current episode: 4
[2023-06-29 10:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1280.8672, current episode: 5
[2023-06-29 10:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1594.7239, current episode: 6
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 939.9148, current episode: 6
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1893.1508, current episode: 7
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 969.6801, current episode: 7
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 977.3225, current episode: 7
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2087.5964, current episode: 8
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.0085, current episode: 8
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1280.8672, current episode: 8
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 939.9148, current episode: 8
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3106.1489, current episode: 9
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 969.6801, current episode: 9
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 977.3225, current episode: 9
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.0085, current episode: 9
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1594.7239, current episode: 9
[2023-06-29 10:27:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.2007, current episode: 10
[2023-06-29 10:27:34][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 73500.000000 | iteration_73500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.568374      | 6376.029119         | 6.376029             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1731.061377 | 874.433864 | 3477.200684 | 939.914795 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.6537, current episode: 1
[2023-06-29 10:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 816.7938, current episode: 2
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1003.2883, current episode: 3
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1311.6731, current episode: 4
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.6537, current episode: 4
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 816.7938, current episode: 4
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1931.9308, current episode: 5
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1003.2883, current episode: 5
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.6537, current episode: 5
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 816.7938, current episode: 5
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1311.6731, current episode: 5
[2023-06-29 10:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1003.2883, current episode: 5
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.6537, current episode: 5
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 816.7938, current episode: 5
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3441.7800, current episode: 6
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3371.8386, current episode: 7
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3453.4988, current episode: 8
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.7188, current episode: 9
[2023-06-29 10:27:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3436.9644, current episode: 10
[2023-06-29 10:27:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 74000.000000 | iteration_74000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.544671      | 6473.871425         | 6.473871             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2303.514026 | 1167.505680 | 3457.718750 | 809.653687 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.6528, current episode: 1
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1221.4216, current episode: 2
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1234.8145, current episode: 3
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1248.3281, current episode: 4
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1261.5311, current episode: 5
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2567.5820, current episode: 6
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.6528, current episode: 6
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1221.4216, current episode: 6
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1234.8145, current episode: 6
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1248.3281, current episode: 6
[2023-06-29 10:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1261.5311, current episode: 6
[2023-06-29 10:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3360.2974, current episode: 7
[2023-06-29 10:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3354.1797, current episode: 8
[2023-06-29 10:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3299.7747, current episode: 9
[2023-06-29 10:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3387.6602, current episode: 10
[2023-06-29 10:28:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 74500.000000 | iteration_74500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535761      | 6511.427826         | 6.511428             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2217.824207 | 1001.125204 | 3387.660156 | 1221.421631 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 10:28:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1032.1565, current episode: 1
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1032.1565, current episode: 1
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2360.9934, current episode: 2
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2492.9702, current episode: 3
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1032.1565, current episode: 3
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3365.0193, current episode: 4
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3470.5457, current episode: 5
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3419.3738, current episode: 6
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3457.3887, current episode: 7
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3456.1379, current episode: 8
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3405.6719, current episode: 9
[2023-06-29 10:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3409.4573, current episode: 10
[2023-06-29 10:28:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 75000.000000 | iteration_75000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508149      | 6630.645448         | 6.630645             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2986.971460 | 762.636025 | 3470.545654 | 1032.156494 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:28:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1468.8055, current episode: 1
[2023-06-29 10:28:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1493.7012, current episode: 2
[2023-06-29 10:28:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1382.2216, current episode: 3
[2023-06-29 10:28:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1956.1353, current episode: 4
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2439.7102, current episode: 5
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3008.3208, current episode: 6
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1468.8055, current episode: 6
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1493.7012, current episode: 6
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1382.2216, current episode: 6
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3220.5374, current episode: 7
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3058.1113, current episode: 8
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3256.6963, current episode: 9
[2023-06-29 10:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3259.6528, current episode: 10
[2023-06-29 10:28:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 75500.000000 | iteration_75500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.543376      | 6479.301590         | 6.479302             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2454.389233 | 764.379641 | 3259.652832 | 1382.221558 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 903.6960, current episode: 1
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 926.7814, current episode: 2
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 937.5820, current episode: 3
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1004.2488, current episode: 4
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 998.1736, current episode: 5
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 996.0180, current episode: 6
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1277.5027, current episode: 7
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 903.6960, current episode: 7
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 926.7814, current episode: 7
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 937.5820, current episode: 7
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1004.2488, current episode: 7
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 998.1736, current episode: 7
[2023-06-29 10:28:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 996.0180, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1277.5027, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 903.6960, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 926.7814, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 937.5820, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1004.2488, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 998.1736, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 996.0180, current episode: 7
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3296.3718, current episode: 8
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3302.1260, current episode: 9
[2023-06-29 10:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3323.2737, current episode: 10
[2023-06-29 10:28:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 76000.000000 | iteration_76000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.588861      | 6293.818367         | 6.293818             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1696.577399 | 1058.965715 | 3323.273682 | 903.696045 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 579.8121, current episode: 1
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 669.5234, current episode: 2
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 662.9357, current episode: 3
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 674.7571, current episode: 4
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 673.1746, current episode: 5
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 672.8575, current episode: 6
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 680.5219, current episode: 7
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 707.0847, current episode: 8
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 749.5797, current episode: 9
[2023-06-29 10:29:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 893.9179, current episode: 10
[2023-06-29 10:29:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 76500.000000 | iteration_76500.pth.tar | 10.000000     | 2780.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 278.000000              | 0.434754      | 6394.426620         | 23.001535            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 696.416455  | 76.944600  | 893.917908 | 579.812073 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 615.6162, current episode: 1
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 636.6479, current episode: 2
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 643.3458, current episode: 3
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 649.4942, current episode: 4
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 652.6748, current episode: 5
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 652.8403, current episode: 6
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 655.2768, current episode: 7
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 666.8648, current episode: 8
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 667.0663, current episode: 9
[2023-06-29 10:29:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 676.6792, current episode: 10
[2023-06-29 10:29:19][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 77000.000000 | iteration_77000.pth.tar | 10.000000     | 2050.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 205.000000              | 0.346095      | 5923.233851         | 28.893824            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 651.650635  | 16.457034  | 676.679199 | 615.616211 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:29:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1151.9879, current episode: 1
[2023-06-29 10:29:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1161.0684, current episode: 2
[2023-06-29 10:29:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1195.7974, current episode: 3
[2023-06-29 10:29:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1419.3906, current episode: 4
[2023-06-29 10:29:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1425.2472, current episode: 5
[2023-06-29 10:29:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1484.6345, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1151.9879, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1161.0684, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1195.7974, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1419.3906, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1425.2472, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1484.6345, current episode: 6
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2727.7788, current episode: 7
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3117.1038, current episode: 8
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2695.5530, current episode: 9
[2023-06-29 10:29:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3229.0513, current episode: 10
[2023-06-29 10:29:34][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 77500.000000 | iteration_77500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515163      | 6599.948535         | 6.599949             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1960.761279 | 822.147754 | 3229.051270 | 1151.987915 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1159.8840, current episode: 1
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1172.3253, current episode: 2
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1176.8553, current episode: 3
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1184.0553, current episode: 4
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1547.1959, current episode: 5
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1500.9193, current episode: 6
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1159.8840, current episode: 6
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1172.3253, current episode: 6
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1176.8553, current episode: 6
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1184.0553, current episode: 6
[2023-06-29 10:29:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2627.5266, current episode: 7
[2023-06-29 10:29:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1547.1959, current episode: 7
[2023-06-29 10:29:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1500.9193, current episode: 7
[2023-06-29 10:29:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2539.1997, current episode: 8
[2023-06-29 10:29:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2546.0242, current episode: 9
[2023-06-29 10:29:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2869.0027, current episode: 10
[2023-06-29 10:29:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 78000.000000 | iteration_78000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.533283      | 6521.953395         | 6.521953             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1832.298840 | 681.533815 | 2869.002686 | 1159.884033 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:30:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1255.5720, current episode: 1
[2023-06-29 10:30:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1382.7220, current episode: 2
[2023-06-29 10:30:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1389.3629, current episode: 3
[2023-06-29 10:30:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1768.2458, current episode: 4
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1255.5720, current episode: 4
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2633.7810, current episode: 5
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1382.7220, current episode: 5
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1389.3629, current episode: 5
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3253.6238, current episode: 6
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3182.4399, current episode: 7
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3241.2629, current episode: 8
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3267.0002, current episode: 9
[2023-06-29 10:30:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3217.7578, current episode: 10
[2023-06-29 10:30:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 78500.000000 | iteration_78500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505995      | 6640.129385         | 6.640129             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2459.176855 | 851.688407 | 3267.000244 | 1255.572021 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:30:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1218.0497, current episode: 1
[2023-06-29 10:30:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1232.4402, current episode: 2
[2023-06-29 10:30:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1240.7277, current episode: 3
[2023-06-29 10:30:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1266.3605, current episode: 4
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1395.3176, current episode: 5
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1552.3763, current episode: 6
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1549.9583, current episode: 7
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1618.4237, current episode: 8
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2286.2549, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1218.0497, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1232.4402, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1240.7277, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1266.3605, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1395.3176, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1552.3763, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1549.9583, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1618.4237, current episode: 9
[2023-06-29 10:30:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3222.3923, current episode: 10
[2023-06-29 10:30:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 79000.000000 | iteration_79000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.564064      | 6393.600905         | 6.393601             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1658.230115 | 603.123527 | 3222.392334 | 1218.049683 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 988.0717, current episode: 1
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 978.4045, current episode: 2
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 981.9729, current episode: 3
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 998.7771, current episode: 4
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1013.4590, current episode: 5
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1043.0382, current episode: 6
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1064.7509, current episode: 7
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1161.8121, current episode: 8
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1199.1753, current episode: 9
[2023-06-29 10:30:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1485.6429, current episode: 10
[2023-06-29 10:30:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 79500.000000 | iteration_79500.pth.tar | 10.000000     | 4280.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 428.000000              | 0.711046      | 6019.298385         | 14.063781            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1091.510461 | 150.040866 | 1485.642944 | 978.404480 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1734.9629, current episode: 1
[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1766.4215, current episode: 2
[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1780.1207, current episode: 3
[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1791.9053, current episode: 4
[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1806.4174, current episode: 5
[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1814.7504, current episode: 6
[2023-06-29 10:30:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1837.8274, current episode: 7
[2023-06-29 10:30:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2014.8160, current episode: 8
[2023-06-29 10:30:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2077.8787, current episode: 9
[2023-06-29 10:30:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2283.6819, current episode: 10
[2023-06-29 10:30:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 80000.000000 | iteration_80000.pth.tar | 10.000000     | 6640.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 664.000000              | 1.052867      | 6306.589139         | 9.497875             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1890.878210 | 167.996986 | 2283.681885 | 1734.962891 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1827.3649, current episode: 1
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2115.9658, current episode: 2
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2393.5320, current episode: 3
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2650.7881, current episode: 4
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2651.3127, current episode: 5
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2886.6599, current episode: 6
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2971.7617, current episode: 7
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3103.3989, current episode: 8
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3218.7012, current episode: 9
[2023-06-29 10:31:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3172.6006, current episode: 10
[2023-06-29 10:31:06][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 80500.000000 | iteration_80500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515589      | 6598.094913         | 6.598095             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2699.208582 | 443.297407 | 3218.701172 | 1827.364868 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1658.9406, current episode: 1
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1745.1079, current episode: 2
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1770.0773, current episode: 3
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1796.8035, current episode: 4
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2075.2344, current episode: 5
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2068.5713, current episode: 6
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2054.9622, current episode: 7
[2023-06-29 10:31:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2112.4739, current episode: 8
[2023-06-29 10:31:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2188.7310, current episode: 9
[2023-06-29 10:31:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1658.9406, current episode: 9
[2023-06-29 10:31:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3430.7820, current episode: 10
[2023-06-29 10:31:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 81000.000000 | iteration_81000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488778      | 6716.918928         | 6.716919             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2090.168384 | 479.888669 | 3430.781982 | 1658.940552 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 768.5303, current episode: 1
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 778.8244, current episode: 2
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 789.9944, current episode: 3
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 784.6040, current episode: 4
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 783.4292, current episode: 5
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 790.7155, current episode: 6
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 811.7820, current episode: 7
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 820.5760, current episode: 8
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 816.2785, current episode: 9
[2023-06-29 10:31:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 874.8176, current episode: 10
[2023-06-29 10:31:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 81500.000000 | iteration_81500.pth.tar | 10.000000     | 2560.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 256.000000              | 0.404997      | 6321.033379         | 24.691537            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 801.955182  | 29.194711  | 874.817566 | 768.530273 |
+-------+-------------+------------+------------+------------+


[2023-06-29 10:31:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.3815, current episode: 1
[2023-06-29 10:31:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1158.2241, current episode: 2
[2023-06-29 10:31:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1168.1743, current episode: 3
[2023-06-29 10:31:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2111.2002, current episode: 4
[2023-06-29 10:31:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.3815, current episode: 4
[2023-06-29 10:31:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1158.2241, current episode: 4
[2023-06-29 10:31:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1168.1743, current episode: 4
[2023-06-29 10:31:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2887.8088, current episode: 5
[2023-06-29 10:31:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3264.4207, current episode: 6
[2023-06-29 10:31:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.3815, current episode: 6
[2023-06-29 10:31:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1158.2241, current episode: 6
[2023-06-29 10:31:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3350.1487, current episode: 7
[2023-06-29 10:31:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3407.0027, current episode: 8
[2023-06-29 10:31:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3371.1658, current episode: 9
[2023-06-29 10:31:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3368.5425, current episode: 10
[2023-06-29 10:31:52][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 82000.000000 | iteration_82000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553112      | 6438.684927         | 6.438685             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2523.906921 | 965.871879 | 3407.002686 | 1152.381470 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 856.8940, current episode: 1
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 891.0328, current episode: 2
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 893.7182, current episode: 3
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 905.1291, current episode: 4
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 955.0397, current episode: 5
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 983.8505, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 856.8940, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 891.0328, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 893.7182, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 905.1291, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 955.0397, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 983.8505, current episode: 6
[2023-06-29 10:32:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 856.8940, current episode: 6
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 891.0328, current episode: 6
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 893.7182, current episode: 6
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2791.5239, current episode: 7
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 905.1291, current episode: 7
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 955.0397, current episode: 7
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 983.8505, current episode: 7
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 856.8940, current episode: 7
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3457.8074, current episode: 8
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3429.3325, current episode: 9
[2023-06-29 10:32:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3452.5762, current episode: 10
[2023-06-29 10:32:07][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 82500.000000 | iteration_82500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525152      | 6556.723623         | 6.556724             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1861.690417 | 1174.605866 | 3457.807373 | 856.893982 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:32:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 948.5387, current episode: 1
[2023-06-29 10:32:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 958.5647, current episode: 2
[2023-06-29 10:32:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 959.0811, current episode: 3
[2023-06-29 10:32:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 989.1352, current episode: 4
[2023-06-29 10:32:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 960.9615, current episode: 5
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1160.5721, current episode: 6
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1382.8514, current episode: 7
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1780.7052, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 948.5387, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 958.5647, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 959.0811, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 989.1352, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 960.9615, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1160.5721, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1382.8514, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 948.5387, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 958.5647, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 959.0811, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 989.1352, current episode: 8
[2023-06-29 10:32:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 960.9615, current episode: 8
[2023-06-29 10:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1160.5721, current episode: 8
[2023-06-29 10:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3335.1167, current episode: 9
[2023-06-29 10:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3331.9763, current episode: 10
[2023-06-29 10:32:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 83000.000000 | iteration_83000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536110      | 6509.951556         | 6.509952             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1580.750293 | 911.466693 | 3335.116699 | 948.538696 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:32:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1534.1433, current episode: 1
[2023-06-29 10:32:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1805.6943, current episode: 2
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1534.1433, current episode: 2
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3408.9792, current episode: 3
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3410.2717, current episode: 4
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3410.3755, current episode: 5
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3412.6421, current episode: 6
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3399.7559, current episode: 7
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3409.1001, current episode: 8
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3384.4070, current episode: 9
[2023-06-29 10:32:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3414.9990, current episode: 10
[2023-06-29 10:32:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 83500.000000 | iteration_83500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.660529      | 6022.177964         | 6.022178             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3059.036816 | 697.257299 | 3414.999023 | 1534.143311 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:32:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 899.2502, current episode: 1
[2023-06-29 10:32:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 898.0478, current episode: 2
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 946.2491, current episode: 3
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 951.6610, current episode: 4
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 963.6370, current episode: 5
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1267.7499, current episode: 6
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1275.2516, current episode: 7
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1511.8917, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 899.2502, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 898.0478, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 946.2491, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 951.6610, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 963.6370, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1267.7499, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1275.2516, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 899.2502, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 898.0478, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 946.2491, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 951.6610, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 963.6370, current episode: 8
[2023-06-29 10:32:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1511.8917, current episode: 8
[2023-06-29 10:32:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3396.0977, current episode: 9
[2023-06-29 10:32:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3381.6709, current episode: 10
[2023-06-29 10:32:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 84000.000000 | iteration_84000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.533189      | 6522.353751         | 6.522354             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1549.150684 | 939.923132 | 3396.097656 | 898.047791 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 10:33:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1176.1312, current episode: 1
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1176.1312, current episode: 1
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1176.1312, current episode: 1
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3391.7261, current episode: 2
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3363.7747, current episode: 3
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3400.0430, current episode: 4
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3395.2595, current episode: 5
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3375.6838, current episode: 6
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3392.3542, current episode: 7
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3389.1401, current episode: 8
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3387.7278, current episode: 9
[2023-06-29 10:33:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3359.8521, current episode: 10
[2023-06-29 10:33:09][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 84500.000000 | iteration_84500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492535      | 6700.012423         | 6.700012             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3163.169250 | 662.467933 | 3400.042969 | 1176.131226 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:33:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 944.6176, current episode: 1
[2023-06-29 10:33:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.5511, current episode: 2
[2023-06-29 10:33:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1004.2942, current episode: 3
[2023-06-29 10:33:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1014.7969, current episode: 4
[2023-06-29 10:33:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1053.2036, current episode: 5
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1460.4594, current episode: 6
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1820.3119, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 944.6176, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.5511, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1004.2942, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1014.7969, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1053.2036, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 944.6176, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1460.4594, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.5511, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1004.2942, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1014.7969, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1053.2036, current episode: 7
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3396.2937, current episode: 8
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3424.2104, current episode: 9
[2023-06-29 10:33:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3424.0425, current episode: 10
[2023-06-29 10:33:24][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 85000.000000 | iteration_85000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.550295      | 6450.386590         | 6.450387             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1850.078131 | 1056.478164 | 3424.210449 | 944.617554 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3310.6938, current episode: 1
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3288.0732, current episode: 2
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3377.0444, current episode: 3
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3348.3274, current episode: 4
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3389.9871, current episode: 5
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3306.3433, current episode: 6
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3366.2205, current episode: 7
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3297.9006, current episode: 8
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3294.8787, current episode: 9
[2023-06-29 10:33:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3377.2402, current episode: 10
[2023-06-29 10:33:40][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 85500.000000 | iteration_85500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514501      | 6602.832835         | 6.602833             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3335.670923 | 37.846515  | 3389.987061 | 3288.073242 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3409.3091, current episode: 1
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3403.8149, current episode: 2
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3424.9365, current episode: 3
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3429.4514, current episode: 4
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3444.6904, current episode: 5
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3413.4714, current episode: 6
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3427.7292, current episode: 7
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3409.1008, current episode: 8
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3408.7527, current episode: 9
[2023-06-29 10:33:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3430.7927, current episode: 10
[2023-06-29 10:33:55][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 86000.000000 | iteration_86000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.468305      | 6810.576113         | 6.810576             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3420.204932 | 12.503152  | 3444.690430 | 3403.814941 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:34:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1230.0372, current episode: 1
[2023-06-29 10:34:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1404.6340, current episode: 2
[2023-06-29 10:34:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1839.8403, current episode: 3
[2023-06-29 10:34:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1230.0372, current episode: 3
[2023-06-29 10:34:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1404.6340, current episode: 3
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3499.2273, current episode: 4
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3517.6248, current episode: 5
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3509.6958, current episode: 6
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3504.7371, current episode: 7
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3507.0439, current episode: 8
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3498.3020, current episode: 9
[2023-06-29 10:34:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3507.0752, current episode: 10
[2023-06-29 10:34:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 86500.000000 | iteration_86500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502731      | 6654.552760         | 6.654553             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2901.821765 | 933.904591 | 3517.624756 | 1230.037231 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3377.0586, current episode: 1
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3376.6350, current episode: 2
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3384.9414, current episode: 3
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3401.8040, current episode: 4
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3400.4617, current episode: 5
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3362.9580, current episode: 6
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3379.0300, current episode: 7
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3386.2327, current episode: 8
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3342.5154, current episode: 9
[2023-06-29 10:34:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3399.6274, current episode: 10
[2023-06-29 10:34:25][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 87000.000000 | iteration_87000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509779      | 6623.484116         | 6.623484             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3381.126416 | 17.453786  | 3401.803955 | 3342.515381 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3413.1360, current episode: 1
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3382.2292, current episode: 2
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3420.8713, current episode: 3
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3426.0269, current episode: 4
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3434.8862, current episode: 5
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3405.9602, current episode: 6
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3419.9502, current episode: 7
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3407.5022, current episode: 8
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3403.4697, current episode: 9
[2023-06-29 10:34:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3418.5215, current episode: 10
[2023-06-29 10:34:41][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 87500.000000 | iteration_87500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509333      | 6625.443125         | 6.625443             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3413.255347 | 13.806782  | 3434.886230 | 3382.229248 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3383.3064, current episode: 1
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3340.5886, current episode: 2
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3387.2268, current episode: 3
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3412.1360, current episode: 4
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3386.2224, current episode: 5
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3374.4436, current episode: 6
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3383.5708, current episode: 7
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3333.1387, current episode: 8
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3336.7178, current episode: 9
[2023-06-29 10:34:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3394.4617, current episode: 10
[2023-06-29 10:34:57][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 88000.000000 | iteration_88000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507924      | 6631.635248         | 6.631635             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3373.181274 | 25.583207  | 3412.135986 | 3333.138672 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3440.3223, current episode: 1
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3427.7795, current episode: 2
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3437.9751, current episode: 3
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3430.1287, current episode: 4
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3442.7766, current episode: 5
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3461.2043, current episode: 6
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3428.7690, current episode: 7
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3454.6958, current episode: 8
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3434.8440, current episode: 9
[2023-06-29 10:35:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3451.9622, current episode: 10
[2023-06-29 10:35:12][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 88500.000000 | iteration_88500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496558      | 6681.998068         | 6.681998             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3441.045752 | 10.996197  | 3461.204346 | 3427.779541 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3369.7915, current episode: 1
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3358.0950, current episode: 2
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3394.8413, current episode: 3
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3395.1882, current episode: 4
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3373.6230, current episode: 5
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3353.9380, current episode: 6
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3386.6375, current episode: 7
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3341.1431, current episode: 8
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3354.8970, current episode: 9
[2023-06-29 10:35:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3394.8245, current episode: 10
[2023-06-29 10:35:28][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 89000.000000 | iteration_89000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485075      | 6733.664657         | 6.733665             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3372.297900 | 18.882545  | 3395.188232 | 3341.143066 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3443.5571, current episode: 1
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3417.8823, current episode: 2
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3419.0994, current episode: 3
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3420.2896, current episode: 4
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3405.8633, current episode: 5
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3413.2556, current episode: 6
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3447.6135, current episode: 7
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3408.2974, current episode: 8
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3428.5242, current episode: 9
[2023-06-29 10:35:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3450.8181, current episode: 10
[2023-06-29 10:35:43][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 89500.000000 | iteration_89500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491276      | 6705.667369         | 6.705667             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3425.520044 | 15.565406  | 3450.818115 | 3405.863281 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3424.0159, current episode: 1
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3412.3384, current episode: 2
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3435.6772, current episode: 3
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3424.0833, current episode: 4
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3431.1746, current episode: 5
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3412.9470, current episode: 6
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3424.6125, current episode: 7
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3406.0295, current episode: 8
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3406.9983, current episode: 9
[2023-06-29 10:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3424.7908, current episode: 10
[2023-06-29 10:35:59][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 90000.000000 | iteration_90000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510186      | 6621.701284         | 6.621701             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3420.266748 | 9.589711   | 3435.677246 | 3406.029541 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3443.5981, current episode: 1
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3421.6565, current episode: 2
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3456.6528, current episode: 3
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3436.1003, current episode: 4
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3444.2695, current episode: 5
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3434.8691, current episode: 6
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3449.6445, current episode: 7
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3411.1133, current episode: 8
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3422.8733, current episode: 9
[2023-06-29 10:36:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3449.4282, current episode: 10
[2023-06-29 10:36:14][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 90500.000000 | iteration_90500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.518047      | 6587.411338         | 6.587411             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3437.020581 | 13.810921  | 3456.652832 | 3411.113281 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3411.2400, current episode: 1
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3391.4534, current episode: 2
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3416.9954, current episode: 3
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3411.7219, current episode: 4
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3415.1987, current episode: 5
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3402.7026, current episode: 6
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3412.6387, current episode: 7
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3387.6831, current episode: 8
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3391.7476, current episode: 9
[2023-06-29 10:36:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3411.2183, current episode: 10
[2023-06-29 10:36:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 91000.000000 | iteration_91000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.474863      | 6780.289487         | 6.780289             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3405.259961 | 10.453018  | 3416.995361 | 3387.683105 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3438.4749, current episode: 1
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3411.8730, current episode: 2
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3433.0217, current episode: 3
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3446.3201, current episode: 4
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3455.7305, current episode: 5
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3460.4368, current episode: 6
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3465.2817, current episode: 7
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3423.7161, current episode: 8
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3435.5789, current episode: 9
[2023-06-29 10:36:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3423.0466, current episode: 10
[2023-06-29 10:36:45][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 91500.000000 | iteration_91500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.546345      | 6466.860772         | 6.466861             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3439.348022 | 16.595920  | 3465.281738 | 3411.873047 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.0627, current episode: 1
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3502.5735, current episode: 2
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3525.0803, current episode: 3
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3523.4707, current episode: 4
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3524.0720, current episode: 5
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3495.8091, current episode: 6
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3516.3738, current episode: 7
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.8660, current episode: 8
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.5037, current episode: 9
[2023-06-29 10:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3527.5264, current episode: 10
[2023-06-29 10:37:01][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 92000.000000 | iteration_92000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519032      | 6583.140923         | 6.583141             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3515.433813 | 10.303108  | 3527.526367 | 3495.809082 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3481.7324, current episode: 1
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3475.6428, current episode: 2
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3492.8020, current episode: 3
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3502.8347, current episode: 4
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3494.5591, current episode: 5
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3495.3562, current episode: 6
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.5325, current episode: 7
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3478.5737, current episode: 8
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3491.9119, current episode: 9
[2023-06-29 10:37:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3491.9304, current episode: 10
[2023-06-29 10:37:17][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 92500.000000 | iteration_92500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484195      | 6737.657162         | 6.737657             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3488.987573 | 8.087780   | 3502.834717 | 3475.642822 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3523.7686, current episode: 1
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3517.1555, current episode: 2
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3519.4346, current episode: 3
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3523.7468, current episode: 4
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.5061, current episode: 5
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.6531, current episode: 6
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3525.9163, current episode: 7
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3509.1250, current episode: 8
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.7561, current episode: 9
[2023-06-29 10:37:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.9844, current episode: 10
[2023-06-29 10:37:32][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 93000.000000 | iteration_93000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.466382      | 6819.504482         | 6.819504             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3520.504639 | 9.410787   | 3535.984375 | 3504.756104 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3491.1487, current episode: 1
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3479.3872, current episode: 2
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3495.8047, current episode: 3
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3491.1565, current episode: 4
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3505.2781, current episode: 5
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.7124, current episode: 6
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3497.3970, current episode: 7
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3480.0444, current episode: 8
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3471.1426, current episode: 9
[2023-06-29 10:37:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3495.2607, current episode: 10
[2023-06-29 10:37:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 93500.000000 | iteration_93500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510572      | 6620.009820         | 6.620010             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3490.433228 | 9.884902   | 3505.278076 | 3471.142578 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2202.3003, current episode: 1
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2198.1721, current episode: 2
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2307.9858, current episode: 3
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2330.9998, current episode: 4
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2359.9485, current episode: 5
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2481.7725, current episode: 6
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2729.2593, current episode: 7
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2780.9238, current episode: 8
[2023-06-29 10:38:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3028.5181, current episode: 9
[2023-06-29 10:38:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3532.5862, current episode: 10
[2023-06-29 10:38:04][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 94000.000000 | iteration_94000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525188      | 6556.568290         | 6.556568             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2595.246631 | 406.377503 | 3532.586182 | 2198.172119 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2959.5837, current episode: 1
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3550.3440, current episode: 2
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3502.5120, current episode: 3
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3496.8149, current episode: 4
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3508.0259, current episode: 5
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3512.1250, current episode: 6
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3504.4043, current episode: 7
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3515.3972, current episode: 8
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.1489, current episode: 9
[2023-06-29 10:38:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3496.0413, current episode: 10
[2023-06-29 10:38:19][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 94500.000000 | iteration_94500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503637      | 6650.539865         | 6.650540             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3454.939722 | 165.770084 | 3550.343994 | 2959.583740 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3447.9695, current episode: 1
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3423.1509, current episode: 2
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3451.2959, current episode: 3
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3453.8076, current episode: 4
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3450.4355, current episode: 5
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3441.8958, current episode: 6
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3443.6555, current episode: 7
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3432.8162, current episode: 8
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3427.4575, current episode: 9
[2023-06-29 10:38:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3450.0466, current episode: 10
[2023-06-29 10:38:34][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 95000.000000 | iteration_95000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536313      | 6509.088251         | 6.509088             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3442.253101 | 10.249888  | 3453.807617 | 3423.150879 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3484.5127, current episode: 1
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3443.2170, current episode: 2
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3488.8091, current episode: 3
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3495.1001, current episode: 4
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3483.5730, current episode: 5
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3478.9102, current episode: 6
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3482.3032, current episode: 7
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3459.2395, current episode: 8
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.1699, current episode: 9
[2023-06-29 10:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3480.3433, current episode: 10
[2023-06-29 10:38:50][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 95500.000000 | iteration_95500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.521629      | 6571.905649         | 6.571906             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3475.317798 | 15.592693  | 3495.100098 | 3443.217041 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3437.3511, current episode: 1
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3434.1833, current episode: 2
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3450.4414, current episode: 3
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3454.6040, current episode: 4
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3452.3157, current episode: 5
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3445.8013, current episode: 6
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3444.5662, current episode: 7
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3438.6345, current episode: 8
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3429.7100, current episode: 9
[2023-06-29 10:39:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3439.5803, current episode: 10
[2023-06-29 10:39:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 96000.000000 | iteration_96000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.472208      | 6792.520665         | 6.792521             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3442.718774 | 7.767488   | 3454.604004 | 3429.709961 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3455.0688, current episode: 1
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3426.1533, current episode: 2
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3439.6997, current episode: 3
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3457.4121, current episode: 4
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3466.3745, current episode: 5
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3425.9924, current episode: 6
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3445.3889, current episode: 7
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3413.4812, current episode: 8
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3409.3472, current episode: 9
[2023-06-29 10:39:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3428.3872, current episode: 10
[2023-06-29 10:39:21][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 96500.000000 | iteration_96500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505745      | 6641.230236         | 6.641230             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3436.730542 | 18.203697  | 3466.374512 | 3409.347168 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1877.4645, current episode: 1
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2231.7502, current episode: 2
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2280.3728, current episode: 3
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3490.5244, current episode: 4
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3515.7144, current episode: 5
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3494.6733, current episode: 6
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3521.5129, current episode: 7
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3491.9963, current episode: 8
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3510.3950, current episode: 9
[2023-06-29 10:39:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3478.2908, current episode: 10
[2023-06-29 10:39:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 97000.000000 | iteration_97000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496302      | 6683.143378         | 6.683143             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3089.269470 | 635.849440 | 3521.512939 | 1877.464478 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1383.9646, current episode: 1
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1386.9575, current episode: 2
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1440.1714, current episode: 3
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1451.5660, current episode: 4
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1610.4719, current episode: 5
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1642.1521, current episode: 6
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1634.0029, current episode: 7
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1641.1052, current episode: 8
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1711.0520, current episode: 9
[2023-06-29 10:39:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2115.2952, current episode: 10
[2023-06-29 10:39:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 97500.000000 | iteration_97500.pth.tar | 10.000000     | 5810.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 581.000000              | 0.877124      | 6623.919806         | 11.400895            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1601.673889 | 205.475584 | 2115.295166 | 1383.964600 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:40:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1749.3080, current episode: 1
[2023-06-29 10:40:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1781.6481, current episode: 2
[2023-06-29 10:40:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1985.8245, current episode: 3
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1749.3080, current episode: 3
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1781.6481, current episode: 3
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3533.2119, current episode: 4
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3530.2102, current episode: 5
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3505.0879, current episode: 6
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3524.6313, current episode: 7
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.9082, current episode: 8
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3541.1794, current episode: 9
[2023-06-29 10:40:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.7996, current episode: 10
[2023-06-29 10:40:07][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 98000.000000 | iteration_98000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524109      | 6561.210479         | 6.561210             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3019.380908 | 774.973225 | 3541.179443 | 1749.307983 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2209.5405, current episode: 1
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2401.7200, current episode: 2
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2420.2800, current episode: 3
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2447.3784, current episode: 4
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2491.7764, current episode: 5
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2554.9285, current episode: 6
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2780.7874, current episode: 7
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2953.2351, current episode: 8
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3664.4553, current episode: 9
[2023-06-29 10:40:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3589.2048, current episode: 10
[2023-06-29 10:40:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 98500.000000 | iteration_98500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.531659      | 6528.870207         | 6.528870             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2751.330640 | 479.703117 | 3664.455322 | 2209.540527 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3472.6482, current episode: 1
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3381.6016, current episode: 2
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3525.8359, current episode: 3
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3521.3687, current episode: 4
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3525.1028, current episode: 5
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3436.4460, current episode: 6
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3439.7966, current episode: 7
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3415.1594, current episode: 8
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3392.1101, current episode: 9
[2023-06-29 10:40:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3521.7317, current episode: 10
[2023-06-29 10:40:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 99000.000000 | iteration_99000.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.562600      | 6399.590526         | 6.399591             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3463.180103 | 54.715169  | 3525.835938 | 3381.601562 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3538.7803, current episode: 1
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3487.9736, current episode: 2
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3514.1685, current episode: 3
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3529.4819, current episode: 4
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3522.4111, current episode: 5
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.0149, current episode: 6
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3536.9412, current episode: 7
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3521.3298, current episode: 8
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3476.1831, current episode: 9
[2023-06-29 10:40:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.7876, current episode: 10
[2023-06-29 10:40:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 99500.000000 | iteration_99500.pth.tar | 10.000000     | 10000.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516779      | 6592.920176         | 6.592920             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3516.307202 | 19.127327  | 3538.780273 | 3476.183105 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:41:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2025.5432, current episode: 1
[2023-06-29 10:41:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2213.9668, current episode: 2
[2023-06-29 10:41:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2483.8333, current episode: 3
[2023-06-29 10:41:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2530.4375, current episode: 4
[2023-06-29 10:41:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3222.3953, current episode: 5
[2023-06-29 10:41:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3222.1064, current episode: 6
[2023-06-29 10:41:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3543.0081, current episode: 7
[2023-06-29 10:41:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3611.5110, current episode: 8
[2023-06-29 10:41:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3640.6765, current episode: 9
[2023-06-29 10:41:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3523.2112, current episode: 10
[2023-06-29 10:41:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 100000.000000 | iteration_100000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506231      | 6639.088085         | 6.639088             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3001.668921 | 592.124491 | 3640.676514 | 2025.543213 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1818.1787, current episode: 1
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2143.1785, current episode: 2
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3144.0576, current episode: 3
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3159.8167, current episode: 4
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3446.9131, current episode: 5
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3453.9512, current episode: 6
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3494.1743, current episode: 7
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3501.0127, current episode: 8
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3489.4451, current episode: 9
[2023-06-29 10:41:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3483.7095, current episode: 10
[2023-06-29 10:41:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 100500.000000 | iteration_100500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502759      | 6654.425729         | 6.654426             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3113.443726 | 585.064112 | 3501.012695 | 1818.178711 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.2268, current episode: 1
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3508.6021, current episode: 2
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3543.9824, current episode: 3
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3539.0337, current episode: 4
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3540.8809, current episode: 5
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3527.0981, current episode: 6
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3532.9011, current episode: 7
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3515.5730, current episode: 8
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3509.2971, current episode: 9
[2023-06-29 10:41:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3510.2698, current episode: 10
[2023-06-29 10:41:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 101000.000000 | iteration_101000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488581      | 6717.808499         | 6.717808             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3521.986499 | 16.373454  | 3543.982422 | 3492.226807 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3504.4678, current episode: 1
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3456.7932, current episode: 2
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3515.6655, current episode: 3
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3515.0698, current episode: 4
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3470.7646, current episode: 5
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3492.0647, current episode: 6
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3507.4102, current episode: 7
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3481.8271, current episode: 8
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3461.9165, current episode: 9
[2023-06-29 10:41:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3504.2229, current episode: 10
[2023-06-29 10:41:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 101500.000000 | iteration_101500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.774707      | 5634.734008         | 5.634734             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3491.020239 | 20.794129  | 3515.665527 | 3456.793213 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1942.1991, current episode: 1
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2028.3245, current episode: 2
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3283.9517, current episode: 3
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3550.8999, current episode: 4
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3476.5425, current episode: 5
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3521.9207, current episode: 6
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3541.4119, current episode: 7
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3529.9312, current episode: 8
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3482.4963, current episode: 9
[2023-06-29 10:42:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3503.7578, current episode: 10
[2023-06-29 10:42:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 102000.000000 | iteration_102000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.557875      | 6419.002253         | 6.419002             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3186.143542 | 605.040788 | 3550.899902 | 1942.199097 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3495.5857, current episode: 1
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3473.2361, current episode: 2
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3506.7026, current episode: 3
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3508.6941, current episode: 4
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3496.5991, current episode: 5
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3435.1079, current episode: 6
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3507.3679, current episode: 7
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3490.8757, current episode: 8
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3488.6631, current episode: 9
[2023-06-29 10:42:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3511.5413, current episode: 10
[2023-06-29 10:42:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 102500.000000 | iteration_102500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.628700      | 6139.867255         | 6.139867             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3491.437354 | 21.782862  | 3511.541260 | 3435.107910 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3455.8779, current episode: 1
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3527.2478, current episode: 2
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3521.6008, current episode: 3
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3530.5151, current episode: 4
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3541.9387, current episode: 5
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3522.0024, current episode: 6
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3512.4729, current episode: 7
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.1184, current episode: 8
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3455.6128, current episode: 9
[2023-06-29 10:42:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3509.7510, current episode: 10
[2023-06-29 10:42:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 103000.000000 | iteration_103000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.583110      | 6316.681978         | 6.316682             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3509.513794 | 28.238212  | 3541.938721 | 3455.612793 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2284.0315, current episode: 1
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3518.4114, current episode: 2
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3476.8689, current episode: 3
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3548.2156, current episode: 4
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3540.3091, current episode: 5
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3513.4158, current episode: 6
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3532.7568, current episode: 7
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.5596, current episode: 8
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3485.2620, current episode: 9
[2023-06-29 10:43:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3517.2446, current episode: 10
[2023-06-29 10:43:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 103500.000000 | iteration_103500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.596192      | 6264.910901         | 6.264911             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3394.407520 | 370.733380 | 3548.215576 | 2284.031494 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1763.9569, current episode: 1
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1814.1102, current episode: 2
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1909.6873, current episode: 3
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1941.4999, current episode: 4
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2017.0228, current episode: 5
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2109.0383, current episode: 6
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2154.9927, current episode: 7
[2023-06-29 10:43:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2297.6252, current episode: 8
[2023-06-29 10:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2576.3591, current episode: 9
[2023-06-29 10:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2591.7256, current episode: 10
[2023-06-29 10:43:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 104000.000000 | iteration_104000.pth.tar | 10.000000     | 6980.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 698.000000              | 1.215730      | 5741.405337         | 8.225509             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2117.601807 | 277.607604 | 2591.725586 | 1763.956909 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3506.6660, current episode: 1
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3526.2966, current episode: 2
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3517.5381, current episode: 3
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3564.0986, current episode: 4
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3536.6104, current episode: 5
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3528.6057, current episode: 6
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3530.2961, current episode: 7
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3557.5366, current episode: 8
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3544.5569, current episode: 9
[2023-06-29 10:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3532.8796, current episode: 10
[2023-06-29 10:43:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 104500.000000 | iteration_104500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.572255      | 6360.292890         | 6.360293             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3534.508472 | 16.422947  | 3564.098633 | 3506.666016 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3554.0112, current episode: 1
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3528.2039, current episode: 2
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3544.2302, current episode: 3
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3539.5356, current episode: 4
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3533.0574, current episode: 5
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3523.4204, current episode: 6
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3516.7080, current episode: 7
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.6748, current episode: 8
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3518.9221, current episode: 9
[2023-06-29 10:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3524.4463, current episode: 10
[2023-06-29 10:43:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 105000.000000 | iteration_105000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.545887      | 6468.779807         | 6.468780             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3530.120996 | 11.765141  | 3554.011230 | 3516.708008 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1310.5494, current episode: 1
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1312.2933, current episode: 2
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1450.3925, current episode: 3
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1488.7585, current episode: 4
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1561.8367, current episode: 5
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1568.3527, current episode: 6
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1575.4614, current episode: 7
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1650.3397, current episode: 8
[2023-06-29 10:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2557.4324, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1310.5494, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1312.2933, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1450.3925, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1488.7585, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1561.8367, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1568.3527, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1575.4614, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1650.3397, current episode: 9
[2023-06-29 10:44:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3607.0884, current episode: 10
[2023-06-29 10:44:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 105500.000000 | iteration_105500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.693074      | 5906.415613         | 5.906416             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1808.250500 | 686.899254 | 3607.088379 | 1310.549438 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3578.0093, current episode: 1
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3469.0312, current episode: 2
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3526.5557, current episode: 3
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.9875, current episode: 4
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3535.7065, current episode: 5
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3506.8845, current episode: 6
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3554.8611, current episode: 7
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3525.6506, current episode: 8
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3737.8513, current episode: 9
[2023-06-29 10:44:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3553.5925, current episode: 10
[2023-06-29 10:44:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 106000.000000 | iteration_106000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.845303      | 5419.164287         | 5.419164             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3555.713037 | 67.753249  | 3737.851318 | 3469.031250 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1568.7582, current episode: 1
[2023-06-29 10:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1623.7882, current episode: 2
[2023-06-29 10:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2046.2302, current episode: 3
[2023-06-29 10:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2519.7905, current episode: 4
[2023-06-29 10:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2858.8557, current episode: 5
[2023-06-29 10:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1568.7582, current episode: 5
[2023-06-29 10:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1623.7882, current episode: 5
[2023-06-29 10:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.3118, current episode: 6
[2023-06-29 10:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3686.0967, current episode: 7
[2023-06-29 10:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3587.2402, current episode: 8
[2023-06-29 10:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3610.8569, current episode: 9
[2023-06-29 10:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3612.9058, current episode: 10
[2023-06-29 10:44:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 106500.000000 | iteration_106500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.581902      | 6321.504691         | 6.321505             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2869.983423 | 827.075441 | 3686.096680 | 1568.758179 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1718.6582, current episode: 1
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2189.2502, current episode: 2
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1718.6582, current episode: 2
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3580.3704, current episode: 3
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3672.2104, current episode: 4
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3613.1289, current episode: 5
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3575.9255, current episode: 6
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.8330, current episode: 7
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3597.6299, current episode: 8
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3552.1060, current episode: 9
[2023-06-29 10:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3603.9863, current episode: 10
[2023-06-29 10:44:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 107000.000000 | iteration_107000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.570363      | 6367.954760         | 6.367955             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3268.209888 | 666.177908 | 3672.210449 | 1718.658203 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2580.7922, current episode: 1
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3574.9819, current episode: 2
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3529.8838, current episode: 3
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3570.6213, current episode: 4
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3533.8333, current episode: 5
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3564.5967, current episode: 6
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3573.5383, current episode: 7
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3479.8040, current episode: 8
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3531.0723, current episode: 9
[2023-06-29 10:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.0381, current episode: 10
[2023-06-29 10:45:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 107500.000000 | iteration_107500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.557621      | 6420.046595         | 6.420047             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3450.316187 | 291.197588 | 3574.981934 | 2580.792236 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3607.1619, current episode: 1
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3486.4348, current episode: 2
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3599.7561, current episode: 3
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3585.8467, current episode: 4
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3601.5930, current episode: 5
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3577.3030, current episode: 6
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3603.5239, current episode: 7
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.1299, current episode: 8
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3559.5898, current episode: 9
[2023-06-29 10:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3598.3330, current episode: 10
[2023-06-29 10:45:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 108000.000000 | iteration_108000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548392      | 6458.311489         | 6.458311             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3578.767212 | 34.383108  | 3607.161865 | 3486.434814 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3597.2144, current episode: 1
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3463.2666, current episode: 2
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3524.8979, current episode: 3
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3536.7388, current episode: 4
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3602.0608, current episode: 5
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3577.9873, current episode: 6
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3584.6968, current episode: 7
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3544.7405, current episode: 8
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3480.9458, current episode: 9
[2023-06-29 10:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3586.8801, current episode: 10
[2023-06-29 10:45:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 108500.000000 | iteration_108500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519768      | 6579.951918         | 6.579952             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3549.942896 | 46.272658  | 3602.060791 | 3463.266602 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3554.3276, current episode: 1
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3612.4980, current episode: 2
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3584.5535, current episode: 3
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3566.7283, current episode: 4
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3497.6985, current episode: 5
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3603.4888, current episode: 6
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3593.1084, current episode: 7
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3584.3430, current episode: 8
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3551.6904, current episode: 9
[2023-06-29 10:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3589.0317, current episode: 10
[2023-06-29 10:46:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 109000.000000 | iteration_109000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528428      | 6542.670077         | 6.542670             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3573.746826 | 31.496034  | 3612.498047 | 3497.698486 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3218.4075, current episode: 1
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3614.2224, current episode: 2
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3558.6626, current episode: 3
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3618.7764, current episode: 4
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3624.6018, current episode: 5
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3615.5276, current episode: 6
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3618.9094, current episode: 7
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3608.2234, current episode: 8
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3588.6887, current episode: 9
[2023-06-29 10:46:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3620.3254, current episode: 10
[2023-06-29 10:46:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 109500.000000 | iteration_109500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540188      | 6492.715984         | 6.492716             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3568.634521 | 118.258678 | 3624.601807 | 3218.407471 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:46:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1658.6378, current episode: 1
[2023-06-29 10:46:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1646.7852, current episode: 2
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1658.6378, current episode: 2
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1646.7852, current episode: 2
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3586.6204, current episode: 3
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3519.3879, current episode: 4
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3493.0159, current episode: 5
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3524.5095, current episode: 6
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3598.6782, current episode: 7
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3545.0908, current episode: 8
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3551.2036, current episode: 9
[2023-06-29 10:46:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3527.9668, current episode: 10
[2023-06-29 10:46:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 110000.000000 | iteration_110000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.538831      | 6498.438138         | 6.498438             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3165.189612 | 756.818537 | 3598.678223 | 1646.785156 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1350.6023, current episode: 1
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1542.3567, current episode: 2
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1553.1652, current episode: 3
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1553.3427, current episode: 4
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1592.1440, current episode: 5
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1645.8947, current episode: 6
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1663.9703, current episode: 7
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2588.8625, current episode: 8
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1350.6023, current episode: 8
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1542.3567, current episode: 8
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1553.1652, current episode: 8
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1553.3427, current episode: 8
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1592.1440, current episode: 8
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3194.4397, current episode: 9
[2023-06-29 10:46:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1645.8947, current episode: 9
[2023-06-29 10:46:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1663.9703, current episode: 9
[2023-06-29 10:46:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3587.9463, current episode: 10
[2023-06-29 10:46:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 110500.000000 | iteration_110500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.599382      | 6252.413251         | 6.252413             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2027.272437 | 756.475565 | 3587.946289 | 1350.602295 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3630.0273, current episode: 1
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3616.1143, current episode: 2
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3578.7041, current episode: 3
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3616.4314, current episode: 4
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3603.7375, current episode: 5
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3584.5522, current episode: 6
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3593.6770, current episode: 7
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3630.8875, current episode: 8
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3621.5645, current episode: 9
[2023-06-29 10:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3557.6489, current episode: 10
[2023-06-29 10:47:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 111000.000000 | iteration_111000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500255      | 6665.535131         | 6.665535             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3603.334473 | 22.975827  | 3630.887451 | 3557.648926 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3577.8396, current episode: 1
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3578.1206, current episode: 2
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3567.6472, current episode: 3
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3603.7061, current episode: 4
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3565.6108, current episode: 5
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3556.6370, current episode: 6
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3580.0317, current episode: 7
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3547.3184, current episode: 8
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3555.6985, current episode: 9
[2023-06-29 10:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3553.1853, current episode: 10
[2023-06-29 10:47:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 111500.000000 | iteration_111500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519638      | 6580.515889         | 6.580516             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3568.579517 | 15.965760  | 3603.706055 | 3547.318359 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3601.7073, current episode: 1
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3593.3638, current episode: 2
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3623.8096, current episode: 3
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3625.2498, current episode: 4
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3617.2927, current episode: 5
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3606.1699, current episode: 6
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3584.3792, current episode: 7
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3613.3723, current episode: 8
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3601.4573, current episode: 9
[2023-06-29 10:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3582.4114, current episode: 10
[2023-06-29 10:47:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 112000.000000 | iteration_112000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.569223      | 6372.580975         | 6.372581             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3604.921313 | 14.424376  | 3625.249756 | 3582.411377 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3609.8328, current episode: 1
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3607.6055, current episode: 2
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3619.6719, current episode: 3
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3614.6467, current episode: 4
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3609.2183, current episode: 5
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3606.7378, current episode: 6
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3587.7563, current episode: 7
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3595.2126, current episode: 8
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3613.0459, current episode: 9
[2023-06-29 10:47:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3599.2341, current episode: 10
[2023-06-29 10:47:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 112500.000000 | iteration_112500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.642393      | 6088.676912         | 6.088677             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3606.296191 | 9.130156   | 3619.671875 | 3587.756348 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3575.2253, current episode: 1
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3541.4539, current episode: 2
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3575.1711, current episode: 3
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3556.2332, current episode: 4
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3590.5032, current episode: 5
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3567.5024, current episode: 6
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3560.5212, current episode: 7
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3563.5525, current episode: 8
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3558.5349, current episode: 9
[2023-06-29 10:48:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3572.3469, current episode: 10
[2023-06-29 10:48:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 113000.000000 | iteration_113000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.622048      | 6165.047163         | 6.165047             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3566.104468 | 12.655801  | 3590.503174 | 3541.453857 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3572.7517, current episode: 1
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3537.8801, current episode: 2
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3580.4963, current episode: 3
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3553.0037, current episode: 4
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3573.9304, current episode: 5
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3538.8848, current episode: 6
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3568.4446, current episode: 7
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.1353, current episode: 8
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3542.0647, current episode: 9
[2023-06-29 10:48:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3553.8438, current episode: 10
[2023-06-29 10:48:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 113500.000000 | iteration_113500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.556304      | 6425.480544         | 6.425481             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3553.943530 | 18.914511  | 3580.496338 | 3518.135254 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:48:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2206.3105, current episode: 1
[2023-06-29 10:48:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2216.1404, current episode: 2
[2023-06-29 10:48:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2193.3696, current episode: 3
[2023-06-29 10:48:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2321.4111, current episode: 4
[2023-06-29 10:48:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2416.3872, current episode: 5
[2023-06-29 10:48:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2764.2703, current episode: 6
[2023-06-29 10:48:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3519.9385, current episode: 7
[2023-06-29 10:48:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3543.4126, current episode: 8
[2023-06-29 10:48:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3522.8914, current episode: 9
[2023-06-29 10:48:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3523.8452, current episode: 10
[2023-06-29 10:48:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 114000.000000 | iteration_114000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.533483      | 6521.103515         | 6.521104             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2822.797681 | 595.914632 | 3543.412598 | 2193.369629 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3013.0962, current episode: 1
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3542.5364, current episode: 2
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3457.9319, current episode: 3
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3401.4717, current episode: 4
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3521.5193, current episode: 5
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3495.6208, current episode: 6
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3517.1372, current episode: 7
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3531.1494, current episode: 8
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3521.1975, current episode: 9
[2023-06-29 10:48:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3488.2295, current episode: 10
[2023-06-29 10:48:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 114500.000000 | iteration_114500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535919      | 6510.758687         | 6.510759             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3448.988989 | 150.557329 | 3542.536377 | 3013.096191 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1803.4871, current episode: 1
[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1818.8173, current episode: 2
[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1794.5708, current episode: 3
[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1849.4371, current episode: 4
[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1884.2457, current episode: 5
[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1942.7261, current episode: 6
[2023-06-29 10:49:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2024.5977, current episode: 7
[2023-06-29 10:49:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3557.1497, current episode: 8
[2023-06-29 10:49:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1803.4871, current episode: 8
[2023-06-29 10:49:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1818.8173, current episode: 8
[2023-06-29 10:49:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1794.5708, current episode: 8
[2023-06-29 10:49:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3664.3945, current episode: 9
[2023-06-29 10:49:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3550.3862, current episode: 10
[2023-06-29 10:49:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 115000.000000 | iteration_115000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.741169      | 5743.267260         | 5.743267             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2388.981213 | 789.883351 | 3664.394531 | 1794.570801 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:49:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1888.9010, current episode: 1
[2023-06-29 10:49:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1996.2169, current episode: 2
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2581.6050, current episode: 3
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2701.7842, current episode: 4
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3024.9832, current episode: 5
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3534.8735, current episode: 6
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3615.8352, current episode: 7
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3569.6443, current episode: 8
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3550.7002, current episode: 9
[2023-06-29 10:49:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3534.8855, current episode: 10
[2023-06-29 10:49:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 115500.000000 | iteration_115500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.571243      | 6364.386287         | 6.364386             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2999.942896 | 639.213827 | 3615.835205 | 1888.901001 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3588.8342, current episode: 1
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3563.8132, current episode: 2
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3591.7534, current episode: 3
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3607.1956, current episode: 4
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3569.2136, current episode: 5
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3581.6638, current episode: 6
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3595.2393, current episode: 7
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3508.1184, current episode: 8
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3589.9172, current episode: 9
[2023-06-29 10:49:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3611.4421, current episode: 10
[2023-06-29 10:49:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 116000.000000 | iteration_116000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525683      | 6554.442639         | 6.554443             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3580.719092 | 27.960503  | 3611.442139 | 3508.118408 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3502.0967, current episode: 1
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3588.0723, current episode: 2
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3483.0120, current episode: 3
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3512.7075, current episode: 4
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3427.7590, current episode: 5
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3493.8757, current episode: 6
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3486.3008, current episode: 7
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3503.1880, current episode: 8
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3470.6062, current episode: 9
[2023-06-29 10:50:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.4958, current episode: 10
[2023-06-29 10:50:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 116500.000000 | iteration_116500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535165      | 6513.958653         | 6.513959             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3498.211401 | 38.350260  | 3588.072266 | 3427.759033 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1693.2052, current episode: 1
[2023-06-29 10:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1705.1788, current episode: 2
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1693.2052, current episode: 2
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1705.1788, current episode: 2
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3547.5085, current episode: 3
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3533.2231, current episode: 4
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3590.9182, current episode: 5
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3594.9824, current episode: 6
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3598.2678, current episode: 7
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3552.3611, current episode: 8
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3548.6641, current episode: 9
[2023-06-29 10:50:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3562.6489, current episode: 10
[2023-06-29 10:50:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 117000.000000 | iteration_117000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.645552      | 6076.987689         | 6.076988             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3192.695825 | 747.052331 | 3598.267822 | 1693.205200 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1525.1361, current episode: 1
[2023-06-29 10:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1582.2610, current episode: 2
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1767.4849, current episode: 3
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1905.9922, current episode: 4
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2110.6450, current episode: 5
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2119.4951, current episode: 6
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2219.9050, current episode: 7
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2328.0269, current episode: 8
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2466.4478, current episode: 9
[2023-06-29 10:50:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2819.6626, current episode: 10
[2023-06-29 10:50:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 117500.000000 | iteration_117500.pth.tar | 10.000000     | 7640.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 764.000000              | 1.248844      | 6117.655247         | 8.007402             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2084.505652 | 382.543047 | 2819.662598 | 1525.136108 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1319.8405, current episode: 1
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1326.5425, current episode: 2
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1315.5167, current episode: 3
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1327.9255, current episode: 4
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1329.4196, current episode: 5
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1340.8412, current episode: 6
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1366.9264, current episode: 7
[2023-06-29 10:50:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1413.9420, current episode: 8
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2604.6931, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1319.8405, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1326.5425, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1315.5167, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1327.9255, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1329.4196, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1340.8412, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1366.9264, current episode: 9
[2023-06-29 10:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2870.3228, current episode: 10
[2023-06-29 10:50:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 118000.000000 | iteration_118000.pth.tar | 10.000000     | 7790.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 779.000000              | 1.307042      | 5960.023300         | 7.650864             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1621.597021 | 561.783359 | 2870.322754 | 1315.516724 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1624.3594, current episode: 1
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1633.3315, current episode: 2
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1663.3419, current episode: 3
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1727.0472, current episode: 4
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1723.7489, current episode: 5
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1989.1786, current episode: 6
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1981.6676, current episode: 7
[2023-06-29 10:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2126.5906, current episode: 8
[2023-06-29 10:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2355.3542, current episode: 9
[2023-06-29 10:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2969.6487, current episode: 10
[2023-06-29 10:51:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 118500.000000 | iteration_118500.pth.tar | 10.000000     | 7880.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 788.000000              | 1.274152      | 6184.505568         | 7.848357             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1979.426868 | 402.299540 | 2969.648682 | 1624.359375 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2053.9006, current episode: 1
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2062.5210, current episode: 2
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2075.7417, current episode: 3
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2307.5264, current episode: 4
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2674.3816, current episode: 5
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2895.1025, current episode: 6
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3646.2996, current episode: 7
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3687.2949, current episode: 8
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3709.1353, current episode: 9
[2023-06-29 10:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3605.2109, current episode: 10
[2023-06-29 10:51:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 119000.000000 | iteration_119000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.564593      | 6391.439466         | 6.391439             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2871.711450 | 694.220848 | 3709.135254 | 2053.900635 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3640.2917, current episode: 1
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3629.9631, current episode: 2
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3625.1702, current episode: 3
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3641.0525, current episode: 4
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3644.6980, current episode: 5
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3620.8164, current episode: 6
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3627.4844, current episode: 7
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3617.8291, current episode: 8
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3607.9775, current episode: 9
[2023-06-29 10:51:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3629.9089, current episode: 10
[2023-06-29 10:51:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 119500.000000 | iteration_119500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.537464      | 6504.219446         | 6.504219             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3628.519189 | 10.813436  | 3644.697998 | 3607.977539 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3628.6306, current episode: 1
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3601.1770, current episode: 2
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3598.8994, current episode: 3
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3597.6108, current episode: 4
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3611.4224, current episode: 5
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3614.1997, current episode: 6
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3613.4685, current episode: 7
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3589.4819, current episode: 8
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3609.3591, current episode: 9
[2023-06-29 10:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3640.6099, current episode: 10
[2023-06-29 10:51:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 120000.000000 | iteration_120000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.584517      | 6311.072550         | 6.311073             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3610.485938 | 14.454600  | 3640.609863 | 3589.481934 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1847.6367, current episode: 1
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1866.6774, current episode: 2
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1903.5662, current episode: 3
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1894.7700, current episode: 4
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1903.5284, current episode: 5
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1913.0120, current episode: 6
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1970.7858, current episode: 7
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1979.4105, current episode: 8
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2050.2520, current episode: 9
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1847.6367, current episode: 9
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1866.6774, current episode: 9
[2023-06-29 10:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3644.7864, current episode: 10
[2023-06-29 10:52:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 120500.000000 | iteration_120500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.618538      | 6178.416871         | 6.178417             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2097.442529 | 518.884421 | 3644.786377 | 1847.636719 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2232.3711, current episode: 1
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3602.1494, current episode: 2
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3603.6414, current episode: 3
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3606.9531, current episode: 4
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3624.4224, current episode: 5
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3564.4746, current episode: 6
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3599.5571, current episode: 7
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3582.8059, current episode: 8
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3547.8760, current episode: 9
[2023-06-29 10:52:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3598.7957, current episode: 10
[2023-06-29 10:52:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 121000.000000 | iteration_121000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524854      | 6558.003831         | 6.558004             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3456.304663 | 408.517350 | 3624.422363 | 2232.371094 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3598.8125, current episode: 1
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3607.3303, current episode: 2
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3630.8069, current episode: 3
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3627.0647, current episode: 4
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3622.6477, current episode: 5
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3570.3345, current episode: 6
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3612.6768, current episode: 7
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3622.3948, current episode: 8
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3597.8865, current episode: 9
[2023-06-29 10:52:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3609.4023, current episode: 10
[2023-06-29 10:52:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 121500.000000 | iteration_121500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.561361      | 6404.669905         | 6.404670             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3609.935693 | 17.022294  | 3630.806885 | 3570.334473 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:53:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1300.9838, current episode: 1
[2023-06-29 10:53:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1656.5170, current episode: 2
[2023-06-29 10:53:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1822.2838, current episode: 3
[2023-06-29 10:53:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1914.4822, current episode: 4
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2064.7742, current episode: 5
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2215.3484, current episode: 6
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2208.4365, current episode: 7
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2277.8601, current episode: 8
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2292.4626, current episode: 9
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1300.9838, current episode: 9
[2023-06-29 10:53:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2797.8743, current episode: 10
[2023-06-29 10:53:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 122000.000000 | iteration_122000.pth.tar | 10.000000     | 7540.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 754.000000              | 1.258567      | 5990.938668         | 7.945542             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2055.102283 | 388.393925 | 2797.874268 | 1300.983765 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1442.7684, current episode: 1
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1819.8502, current episode: 2
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1886.0081, current episode: 3
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2064.2141, current episode: 4
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2067.1938, current episode: 5
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2127.0457, current episode: 6
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2137.7014, current episode: 7
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2156.8638, current episode: 8
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2648.4907, current episode: 9
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1442.7684, current episode: 9
[2023-06-29 10:53:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3064.3438, current episode: 10
[2023-06-29 10:53:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 122500.000000 | iteration_122500.pth.tar | 10.000000     | 8350.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 835.000000              | 1.297280      | 6436.542797         | 7.708434             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2141.447998 | 421.615297 | 3064.343750 | 1442.768433 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:53:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1441.1921, current episode: 1
[2023-06-29 10:53:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1449.2495, current episode: 2
[2023-06-29 10:53:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1485.1399, current episode: 3
[2023-06-29 10:53:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1553.2496, current episode: 4
[2023-06-29 10:53:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1688.2953, current episode: 5
[2023-06-29 10:53:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2093.4438, current episode: 6
[2023-06-29 10:53:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2272.5696, current episode: 7
[2023-06-29 10:53:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2754.4875, current episode: 8
[2023-06-29 10:53:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2893.4734, current episode: 9
[2023-06-29 10:53:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2894.4590, current episode: 10
[2023-06-29 10:53:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 123000.000000 | iteration_123000.pth.tar | 10.000000     | 7780.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 778.000000              | 1.184613      | 6567.546836         | 8.441577             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2052.555981 | 583.131771 | 2894.458984 | 1441.192139 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1655.1497, current episode: 1
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1697.9436, current episode: 2
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1844.1534, current episode: 3
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1946.7072, current episode: 4
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2694.1223, current episode: 5
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3170.0994, current episode: 6
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3301.7173, current episode: 7
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1655.1497, current episode: 7
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1697.9436, current episode: 7
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3532.5422, current episode: 8
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1844.1534, current episode: 8
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3665.7676, current episode: 9
[2023-06-29 10:53:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3762.3145, current episode: 10
[2023-06-29 10:53:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 123500.000000 | iteration_123500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.563372      | 6396.428994         | 6.396429             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2727.051709 | 820.114138 | 3762.314453 | 1655.149658 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:54:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1401.1632, current episode: 1
[2023-06-29 10:54:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1402.0781, current episode: 2
[2023-06-29 10:54:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1969.0742, current episode: 3
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1401.1632, current episode: 3
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1402.0781, current episode: 3
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3555.5791, current episode: 4
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3607.0042, current episode: 5
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3619.7261, current episode: 6
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3586.1196, current episode: 7
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.3269, current episode: 8
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3561.8672, current episode: 9
[2023-06-29 10:54:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3633.6140, current episode: 10
[2023-06-29 10:54:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 124000.000000 | iteration_124000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540908      | 6489.678227         | 6.489678             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2991.955261 | 929.190224 | 3633.614014 | 1401.163208 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:54:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1617.9714, current episode: 1
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1617.9714, current episode: 1
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3548.4395, current episode: 2
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3616.0508, current episode: 3
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3595.9758, current episode: 4
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3582.9419, current episode: 5
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3594.5205, current episode: 6
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3634.6885, current episode: 7
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3505.6709, current episode: 8
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3537.7305, current episode: 9
[2023-06-29 10:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3586.0935, current episode: 10
[2023-06-29 10:54:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 124500.000000 | iteration_124500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.489975      | 6711.523765         | 6.711524             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3382.008325 | 589.122992 | 3634.688477 | 1617.971436 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3572.9294, current episode: 1
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3560.1223, current episode: 2
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3587.5657, current episode: 3
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3618.0271, current episode: 4
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3567.5374, current episode: 5
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3589.8162, current episode: 6
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3657.1304, current episode: 7
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3496.8347, current episode: 8
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3575.4314, current episode: 9
[2023-06-29 10:54:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3613.3660, current episode: 10
[2023-06-29 10:54:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 125000.000000 | iteration_125000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536063      | 6510.149181         | 6.510149             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3583.876050 | 40.061915  | 3657.130371 | 3496.834717 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:54:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1588.6049, current episode: 1
[2023-06-29 10:54:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1581.1229, current episode: 2
[2023-06-29 10:54:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1562.6248, current episode: 3
[2023-06-29 10:54:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1951.4539, current episode: 4
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1588.6049, current episode: 4
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1581.1229, current episode: 4
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1562.6248, current episode: 4
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3531.1921, current episode: 5
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.4688, current episode: 6
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3634.8252, current episode: 7
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3575.6646, current episode: 8
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3588.9114, current episode: 9
[2023-06-29 10:54:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3602.0518, current episode: 10
[2023-06-29 10:54:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 125500.000000 | iteration_125500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536653      | 6507.649745         | 6.507650             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2819.892017 | 944.005652 | 3634.825195 | 1562.624756 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1451.7594, current episode: 1
[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1461.6135, current episode: 2
[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1484.7749, current episode: 3
[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1609.3857, current episode: 4
[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1629.1954, current episode: 5
[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1747.5913, current episode: 6
[2023-06-29 10:55:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1775.6227, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1451.7594, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1461.6135, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1484.7749, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1609.3857, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1629.1954, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1747.5913, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1775.6227, current episode: 7
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3597.1311, current episode: 8
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3587.9517, current episode: 9
[2023-06-29 10:55:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3598.1846, current episode: 10
[2023-06-29 10:55:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 126000.000000 | iteration_126000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.585970      | 6305.290109         | 6.305290             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2194.321033 | 922.443550 | 3598.184570 | 1451.759399 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3559.3267, current episode: 1
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3528.9023, current episode: 2
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3572.2703, current episode: 3
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3558.1187, current episode: 4
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3577.0332, current episode: 5
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3529.4839, current episode: 6
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3599.5127, current episode: 7
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3525.4009, current episode: 8
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3530.7476, current episode: 9
[2023-06-29 10:55:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3600.2781, current episode: 10
[2023-06-29 10:55:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 126500.000000 | iteration_126500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.653163      | 6049.009530         | 6.049010             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3558.107422 | 27.465510  | 3600.278076 | 3525.400879 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3565.4880, current episode: 1
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3584.5054, current episode: 2
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3494.3145, current episode: 3
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.7656, current episode: 4
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3584.2778, current episode: 5
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.6951, current episode: 6
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3528.0825, current episode: 7
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3575.7256, current episode: 8
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3502.1226, current episode: 9
[2023-06-29 10:55:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3523.0386, current episode: 10
[2023-06-29 10:55:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 127000.000000 | iteration_127000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.701245      | 5878.047730         | 5.878048             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3548.801562 | 32.680057  | 3584.505371 | 3494.314453 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:55:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1724.1649, current episode: 1
[2023-06-29 10:55:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1784.3427, current episode: 2
[2023-06-29 10:55:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1835.6824, current episode: 3
[2023-06-29 10:55:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1877.2041, current episode: 4
[2023-06-29 10:55:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2198.4961, current episode: 5
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1724.1649, current episode: 5
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1784.3427, current episode: 5
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1835.6824, current episode: 5
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3690.0859, current episode: 6
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1877.2041, current episode: 6
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3606.2476, current episode: 7
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3675.9712, current episode: 8
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3596.1833, current episode: 9
[2023-06-29 10:55:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3537.2437, current episode: 10
[2023-06-29 10:55:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 127500.000000 | iteration_127500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.675321      | 5969.006488         | 5.969006             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2752.562183 | 877.313796 | 3690.085938 | 1724.164917 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1363.6079, current episode: 1
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1362.3615, current episode: 2
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1394.7286, current episode: 3
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1373.5768, current episode: 4
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1451.4749, current episode: 5
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1423.4880, current episode: 6
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1490.9969, current episode: 7
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1547.8958, current episode: 8
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1515.9508, current episode: 9
[2023-06-29 10:56:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2159.6804, current episode: 10
[2023-06-29 10:56:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 128000.000000 | iteration_128000.pth.tar | 10.000000     | 5810.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 581.000000              | 0.899881      | 6456.407180         | 11.112577            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1508.376160 | 225.815627 | 2159.680420 | 1362.361450 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:56:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1816.3116, current episode: 1
[2023-06-29 10:56:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1890.4116, current episode: 2
[2023-06-29 10:56:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2643.5969, current episode: 3
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1816.3116, current episode: 3
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3590.8381, current episode: 4
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3626.7827, current episode: 5
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3602.8345, current episode: 6
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3611.9060, current episode: 7
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3630.4768, current episode: 8
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3625.9954, current episode: 9
[2023-06-29 10:56:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3633.8411, current episode: 10
[2023-06-29 10:56:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 128500.000000 | iteration_128500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523365      | 6564.415531         | 6.564416             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3167.299475 | 717.659169 | 3633.841064 | 1816.311646 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2449.0427, current episode: 1
[2023-06-29 10:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2817.7346, current episode: 2
[2023-06-29 10:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3084.0725, current episode: 3
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3661.7524, current episode: 4
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3532.0479, current episode: 5
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.2080, current episode: 6
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.2742, current episode: 7
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3506.3335, current episode: 8
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3489.9070, current episode: 9
[2023-06-29 10:56:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3588.4297, current episode: 10
[2023-06-29 10:56:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 129000.000000 | iteration_129000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503476      | 6651.253707         | 6.651254             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3321.580249 | 382.580475 | 3661.752441 | 2449.042725 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:57:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1671.6528, current episode: 1
[2023-06-29 10:57:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2269.3223, current episode: 2
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1671.6528, current episode: 2
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3573.4094, current episode: 3
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3517.1682, current episode: 4
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3575.4128, current episode: 5
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3568.0369, current episode: 6
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3554.1392, current episode: 7
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3567.0300, current episode: 8
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3493.4858, current episode: 9
[2023-06-29 10:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3554.0737, current episode: 10
[2023-06-29 10:57:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 129500.000000 | iteration_129500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.562905      | 6398.343429         | 6.398343             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3234.373120 | 646.392678 | 3575.412842 | 1671.652832 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1336.0079, current episode: 1
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1340.9288, current episode: 2
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1293.8647, current episode: 3
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1326.8721, current episode: 4
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1335.2784, current episode: 5
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1390.8344, current episode: 6
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1346.7252, current episode: 7
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1424.7117, current episode: 8
[2023-06-29 10:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2123.8772, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1336.0079, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1340.9288, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1293.8647, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1326.8721, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1335.2784, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1390.8344, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1346.7252, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1424.7117, current episode: 9
[2023-06-29 10:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3559.0273, current episode: 10
[2023-06-29 10:57:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 130000.000000 | iteration_130000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.612026      | 6203.372008         | 6.203372             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1647.812781 | 678.469163 | 3559.027344 | 1293.864746 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1340.5360, current episode: 1
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1352.8341, current episode: 2
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1354.2583, current episode: 3
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1369.4266, current episode: 4
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1360.8959, current episode: 5
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1360.2294, current episode: 6
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1359.8340, current episode: 7
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1380.5231, current episode: 8
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1414.3588, current episode: 9
[2023-06-29 10:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1488.9738, current episode: 10
[2023-06-29 10:57:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 130500.000000 | iteration_130500.pth.tar | 10.000000     | 4060.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 406.000000              | 0.654446      | 6203.724023         | 15.280108            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1378.186987 | 41.539793  | 1488.973755 | 1340.536011 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1390.0009, current episode: 1
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1391.6104, current episode: 2
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1430.7935, current episode: 3
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1470.5205, current episode: 4
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1493.3173, current episode: 5
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1567.9055, current episode: 6
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1607.1796, current episode: 7
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1587.5840, current episode: 8
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1726.8049, current episode: 9
[2023-06-29 10:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2037.9120, current episode: 10
[2023-06-29 10:57:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 131000.000000 | iteration_131000.pth.tar | 10.000000     | 5590.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 559.000000              | 0.899868      | 6212.025289         | 11.112746            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1570.362842 | 185.634435 | 2037.911987 | 1390.000854 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:58:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1339.4824, current episode: 1
[2023-06-29 10:58:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1385.9491, current episode: 2
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1553.8951, current episode: 3
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1454.9235, current episode: 4
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1473.6810, current episode: 5
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1775.8691, current episode: 6
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1791.1300, current episode: 7
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2077.1677, current episode: 8
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1339.4824, current episode: 8
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1385.9491, current episode: 8
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2719.8496, current episode: 9
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1553.8951, current episode: 9
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1454.9235, current episode: 9
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1473.6810, current episode: 9
[2023-06-29 10:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3369.5364, current episode: 10
[2023-06-29 10:58:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 131500.000000 | iteration_131500.pth.tar | 10.000000     | 9590.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 959.000000              | 1.626373      | 5896.557483         | 6.148652             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1894.148401 | 629.925038 | 3369.536377 | 1339.482422 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1348.9617, current episode: 1
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1387.8594, current episode: 2
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1382.0061, current episode: 3
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1402.7883, current episode: 4
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1381.5336, current episode: 5
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1367.0029, current episode: 6
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1387.3898, current episode: 7
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1479.3162, current episode: 8
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1489.1462, current episode: 9
[2023-06-29 10:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1493.2928, current episode: 10
[2023-06-29 10:58:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 132000.000000 | iteration_132000.pth.tar | 10.000000     | 4240.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 424.000000              | 0.712530      | 5950.625886         | 14.034495            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1411.929700 | 51.177317  | 1493.292847 | 1348.961670 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1250.7910, current episode: 1
[2023-06-29 10:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1391.0164, current episode: 2
[2023-06-29 10:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1554.8014, current episode: 3
[2023-06-29 10:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1586.7610, current episode: 4
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1634.8574, current episode: 5
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2228.5825, current episode: 6
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2282.3489, current episode: 7
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2318.2236, current episode: 8
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2376.5002, current episode: 9
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1250.7910, current episode: 9
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1391.0164, current episode: 9
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1554.8014, current episode: 9
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1586.7610, current episode: 9
[2023-06-29 10:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3176.9041, current episode: 10
[2023-06-29 10:58:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 132500.000000 | iteration_132500.pth.tar | 10.000000     | 8750.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 875.000000              | 1.351393      | 6474.799544         | 7.399771             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1980.078650 | 564.853670 | 3176.904053 | 1250.791016 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1313.6886, current episode: 1
[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1348.2024, current episode: 2
[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1358.7574, current episode: 3
[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1415.8759, current episode: 4
[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1448.9663, current episode: 5
[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1585.9817, current episode: 6
[2023-06-29 10:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1751.6118, current episode: 7
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2371.8494, current episode: 8
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2667.7029, current episode: 9
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1313.6886, current episode: 9
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1348.2024, current episode: 9
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1358.7574, current episode: 9
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1415.8759, current episode: 9
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1448.9663, current episode: 9
[2023-06-29 10:58:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3082.3733, current episode: 10
[2023-06-29 10:58:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 133000.000000 | iteration_133000.pth.tar | 10.000000     | 8390.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 839.000000              | 1.301292      | 6447.436011         | 7.684667             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1834.500964 | 605.535646 | 3082.373291 | 1313.688599 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1419.4087, current episode: 1
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1424.6339, current episode: 2
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1453.5087, current episode: 3
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1457.7589, current episode: 4
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1466.1681, current episode: 5
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1528.1665, current episode: 6
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1558.0588, current episode: 7
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1561.2992, current episode: 8
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2146.1243, current episode: 9
[2023-06-29 10:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2194.3745, current episode: 10
[2023-06-29 10:59:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 133500.000000 | iteration_133500.pth.tar | 10.000000     | 5950.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 595.000000              | 0.924535      | 6435.670396         | 10.816253            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1620.950159 | 279.021550 | 2194.374512 | 1419.408691 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1402.0258, current episode: 1
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1401.3060, current episode: 2
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1384.8752, current episode: 3
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1402.5493, current episode: 4
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1405.7280, current episode: 5
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1408.7130, current episode: 6
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1432.3989, current episode: 7
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1490.5333, current episode: 8
[2023-06-29 10:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1506.7001, current episode: 9
[2023-06-29 10:59:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2301.0593, current episode: 10
[2023-06-29 10:59:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 134000.000000 | iteration_134000.pth.tar | 10.000000     | 6390.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 639.000000              | 0.993777      | 6430.012938         | 10.062618            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1513.588904 | 265.304390 | 2301.059326 | 1384.875244 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1333.7042, current episode: 1
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1323.9510, current episode: 2
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1330.3074, current episode: 3
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1339.4502, current episode: 4
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1339.7451, current episode: 5
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1342.6731, current episode: 6
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1354.9037, current episode: 7
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1343.9254, current episode: 8
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1344.1616, current episode: 9
[2023-06-29 10:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1383.9974, current episode: 10
[2023-06-29 10:59:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 134500.000000 | iteration_134500.pth.tar | 10.000000     | 4040.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 404.000000              | 0.644567      | 6267.776959         | 15.514299            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1343.681921 | 15.664361  | 1383.997437 | 1323.951050 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2756.0217, current episode: 1
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2788.6189, current episode: 2
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3091.0076, current episode: 3
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3158.3386, current episode: 4
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3144.8315, current episode: 5
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3475.1318, current episode: 6
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3526.6533, current episode: 7
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3484.9946, current episode: 8
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3472.4092, current episode: 9
[2023-06-29 10:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3429.8245, current episode: 10
[2023-06-29 10:59:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 135000.000000 | iteration_135000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.527200      | 6547.930016         | 6.547930             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3232.783179 | 276.208297 | 3526.653320 | 2756.021729 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1591.5916, current episode: 1
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2474.6208, current episode: 2
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2911.1282, current episode: 3
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3077.8054, current episode: 4
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3169.6230, current episode: 5
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1591.5916, current episode: 5
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3370.0984, current episode: 6
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3471.8018, current episode: 7
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3497.3696, current episode: 8
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3439.7847, current episode: 9
[2023-06-29 11:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.8145, current episode: 10
[2023-06-29 11:00:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 135500.000000 | iteration_135500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.539244      | 6496.697248         | 6.496697             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3049.463794 | 576.120686 | 3497.369629 | 1591.591553 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1690.3047, current episode: 1
[2023-06-29 11:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1858.3352, current episode: 2
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1690.3047, current episode: 2
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3486.6445, current episode: 3
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3444.9373, current episode: 4
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3484.2605, current episode: 5
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3504.7129, current episode: 6
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3496.0535, current episode: 7
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3435.7251, current episode: 8
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3449.1577, current episode: 9
[2023-06-29 11:00:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3493.0925, current episode: 10
[2023-06-29 11:00:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 136000.000000 | iteration_136000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.518335      | 6586.161985         | 6.586162             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3134.322388 | 681.404356 | 3504.712891 | 1690.304688 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1260.7026, current episode: 1
[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1265.9261, current episode: 2
[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1292.0140, current episode: 3
[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1273.4025, current episode: 4
[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1303.1208, current episode: 5
[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1289.2711, current episode: 6
[2023-06-29 11:00:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1308.9326, current episode: 7
[2023-06-29 11:00:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1335.1326, current episode: 8
[2023-06-29 11:00:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1337.4131, current episode: 9
[2023-06-29 11:00:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1346.0630, current episode: 10
[2023-06-29 11:00:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 136500.000000 | iteration_136500.pth.tar | 10.000000     | 3920.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 392.000000              | 0.642961      | 6096.788191         | 15.553031            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1301.197852 | 29.021788  | 1346.062988 | 1260.702637 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1385.1252, current episode: 1
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1355.6208, current episode: 2
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1405.2308, current episode: 3
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1406.1680, current episode: 4
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1402.2777, current episode: 5
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1427.4706, current episode: 6
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1468.3501, current episode: 7
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1412.6674, current episode: 8
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1478.4862, current episode: 9
[2023-06-29 11:00:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1532.9414, current episode: 10
[2023-06-29 11:00:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 137000.000000 | iteration_137000.pth.tar | 10.000000     | 4380.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 438.000000              | 0.811468      | 5397.624928         | 12.323345            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1427.433826 | 49.148291  | 1532.941406 | 1355.620850 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1346.9994, current episode: 1
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1397.8942, current episode: 2
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1344.2684, current episode: 3
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1344.8220, current episode: 4
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1349.8640, current episode: 5
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1378.8645, current episode: 6
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1371.5164, current episode: 7
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1414.0239, current episode: 8
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1543.3085, current episode: 9
[2023-06-29 11:01:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1572.3743, current episode: 10
[2023-06-29 11:01:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 137500.000000 | iteration_137500.pth.tar | 10.000000     | 4490.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 449.000000              | 0.736485      | 6096.526188         | 13.578009            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1406.393555 | 79.229958  | 1572.374268 | 1344.268433 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:01:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1440.0554, current episode: 1
[2023-06-29 11:01:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1454.1553, current episode: 2
[2023-06-29 11:01:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1469.3972, current episode: 3
[2023-06-29 11:01:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1459.3059, current episode: 4
[2023-06-29 11:01:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1476.4026, current episode: 5
[2023-06-29 11:01:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1544.4515, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1440.0554, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1454.1553, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1469.3972, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1459.3059, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1476.4026, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1544.4515, current episode: 6
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3422.7334, current episode: 7
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3506.4646, current episode: 8
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3456.0232, current episode: 9
[2023-06-29 11:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3421.4390, current episode: 10
[2023-06-29 11:01:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 138000.000000 | iteration_138000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.567433      | 6379.857096         | 6.379857             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2265.042810 | 969.467572 | 3506.464600 | 1440.055420 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1442.6776, current episode: 1
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1429.3375, current episode: 2
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1595.6855, current episode: 3
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1577.1152, current episode: 4
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1708.7804, current episode: 5
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1716.3865, current episode: 6
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1671.7971, current episode: 7
[2023-06-29 11:01:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1682.4694, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1442.6776, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1429.3375, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1595.6855, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1577.1152, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1708.7804, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1716.3865, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1671.7971, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1682.4694, current episode: 8
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3451.4827, current episode: 9
[2023-06-29 11:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3459.3738, current episode: 10
[2023-06-29 11:01:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 138500.000000 | iteration_138500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.605914      | 6226.984217         | 6.226984             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1973.510571 | 747.121864 | 3459.373779 | 1429.337524 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:01:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1610.6160, current episode: 1
[2023-06-29 11:01:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2020.8065, current episode: 2
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2377.0330, current episode: 3
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2798.0022, current episode: 4
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3155.1750, current episode: 5
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3082.9688, current episode: 6
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3166.7214, current episode: 7
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1610.6160, current episode: 7
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3455.7422, current episode: 8
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3556.3640, current episode: 9
[2023-06-29 11:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3459.0754, current episode: 10
[2023-06-29 11:01:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 139000.000000 | iteration_139000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.617248      | 6183.342444         | 6.183342             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2868.250452 | 626.998464 | 3556.364014 | 1610.615967 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1420.1376, current episode: 1
[2023-06-29 11:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1668.9568, current episode: 2
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1884.0936, current episode: 3
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2130.2568, current episode: 4
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2277.8530, current episode: 5
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2383.2617, current episode: 6
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1420.1376, current episode: 6
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1668.9568, current episode: 6
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3366.4341, current episode: 7
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3530.7285, current episode: 8
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3510.0571, current episode: 9
[2023-06-29 11:02:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3509.1736, current episode: 10
[2023-06-29 11:02:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 139500.000000 | iteration_139500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.557042      | 6422.435373         | 6.422435             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2568.095288 | 790.009480 | 3530.728516 | 1420.137573 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:02:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1650.6023, current episode: 1
[2023-06-29 11:02:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1773.1881, current episode: 2
[2023-06-29 11:02:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2003.6895, current episode: 3
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1650.6023, current episode: 3
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1773.1881, current episode: 3
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3497.2034, current episode: 4
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3460.3274, current episode: 5
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3478.5767, current episode: 6
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3554.8833, current episode: 7
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3498.3208, current episode: 8
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3439.9385, current episode: 9
[2023-06-29 11:02:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.0830, current episode: 10
[2023-06-29 11:02:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 140000.000000 | iteration_140000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.583869      | 6313.655337         | 6.313655             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2988.581287 | 776.859982 | 3554.883301 | 1650.602295 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2749.1204, current episode: 1
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3378.7827, current episode: 2
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3456.0291, current episode: 3
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3385.7075, current episode: 4
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3348.5190, current episode: 5
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3443.0833, current episode: 6
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3408.8906, current episode: 7
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3455.5557, current episode: 8
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3318.1943, current episode: 9
[2023-06-29 11:02:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3404.3691, current episode: 10
[2023-06-29 11:02:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 140500.000000 | iteration_140500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553186      | 6438.380292         | 6.438380             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3334.825171 | 199.835835 | 3456.029053 | 2749.120361 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2497.8682, current episode: 1
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3464.8853, current episode: 2
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3465.0315, current episode: 3
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3468.7153, current episode: 4
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3545.8894, current episode: 5
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3397.3928, current episode: 6
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3438.0876, current episode: 7
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3504.1331, current episode: 8
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3429.4509, current episode: 9
[2023-06-29 11:03:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3483.4814, current episode: 10
[2023-06-29 11:03:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 141000.000000 | iteration_141000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.653420      | 6048.070347         | 6.048070             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3369.493555 | 293.107112 | 3545.889404 | 2497.868164 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:03:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1507.5179, current episode: 1
[2023-06-29 11:03:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1546.0781, current episode: 2
[2023-06-29 11:03:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1667.2899, current episode: 3
[2023-06-29 11:03:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1674.2728, current episode: 4
[2023-06-29 11:03:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1756.9620, current episode: 5
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1507.5179, current episode: 5
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1546.0781, current episode: 5
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1667.2899, current episode: 5
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1674.2728, current episode: 5
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1756.9620, current episode: 5
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3566.7876, current episode: 6
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.3530, current episode: 7
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3449.5161, current episode: 8
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3498.5583, current episode: 9
[2023-06-29 11:03:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3446.2532, current episode: 10
[2023-06-29 11:03:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 141500.000000 | iteration_141500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536060      | 6510.161080         | 6.510161             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2562.958911 | 935.296217 | 3566.787598 | 1507.517944 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1337.3610, current episode: 1
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1349.2324, current episode: 2
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1324.6472, current episode: 3
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1347.7251, current episode: 4
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1366.6270, current episode: 5
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1333.0322, current episode: 6
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1437.7656, current episode: 7
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1506.7471, current episode: 8
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1861.8770, current episode: 9
[2023-06-29 11:03:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1901.6399, current episode: 10
[2023-06-29 11:03:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 142000.000000 | iteration_142000.pth.tar | 10.000000     | 5150.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 515.000000              | 0.804268      | 6403.338634         | 12.433667            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1476.665442 | 209.649309 | 1901.639893 | 1324.647217 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3496.5647, current episode: 1
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3463.7759, current episode: 2
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3423.6318, current episode: 3
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3489.1304, current episode: 4
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3502.7271, current episode: 5
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3381.5132, current episode: 6
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3390.0674, current episode: 7
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3463.6536, current episode: 8
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3374.0977, current episode: 9
[2023-06-29 11:03:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3498.6663, current episode: 10
[2023-06-29 11:03:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 142500.000000 | iteration_142500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515092      | 6600.260143         | 6.600260             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3448.382788 | 48.925303  | 3502.727051 | 3374.097656 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:04:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1593.2278, current episode: 1
[2023-06-29 11:04:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3018.5276, current episode: 2
[2023-06-29 11:04:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1593.2278, current episode: 2
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3460.9153, current episode: 3
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3621.9270, current episode: 4
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3457.0830, current episode: 5
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3438.6587, current episode: 6
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3383.4966, current episode: 7
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3474.4441, current episode: 8
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3441.5530, current episode: 9
[2023-06-29 11:04:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3419.1213, current episode: 10
[2023-06-29 11:04:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 143000.000000 | iteration_143000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.583506      | 6315.099896         | 6.315100             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3230.895435 | 564.765907 | 3621.927002 | 1593.227783 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1943.4619, current episode: 1
[2023-06-29 11:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2176.3145, current episode: 2
[2023-06-29 11:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2874.9612, current episode: 3
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3352.9587, current episode: 4
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3490.2263, current episode: 5
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3401.8765, current episode: 6
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3488.6570, current episode: 7
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3338.7688, current episode: 8
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3355.5979, current episode: 9
[2023-06-29 11:04:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3516.6902, current episode: 10
[2023-06-29 11:04:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 143500.000000 | iteration_143500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536373      | 6508.837423         | 6.508837             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3093.951294 | 547.309038 | 3516.690186 | 1943.461914 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1365.6898, current episode: 1
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1454.6056, current episode: 2
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1554.7646, current episode: 3
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1554.4777, current episode: 4
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1595.7738, current episode: 5
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1603.7266, current episode: 6
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1614.5594, current episode: 7
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1904.4912, current episode: 8
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2212.4766, current episode: 9
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1365.6898, current episode: 9
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1454.6056, current episode: 9
[2023-06-29 11:04:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3036.4873, current episode: 10
[2023-06-29 11:04:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 144000.000000 | iteration_144000.pth.tar | 10.000000     | 8320.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 832.000000              | 1.320359      | 6301.317659         | 7.573699             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1789.705261 | 474.537711 | 3036.487305 | 1365.689819 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1432.3066, current episode: 1
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1529.7288, current episode: 2
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1612.9122, current episode: 3
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1612.6173, current episode: 4
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1675.9738, current episode: 5
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1691.9858, current episode: 6
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1905.9856, current episode: 7
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1925.1409, current episode: 8
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2158.5330, current episode: 9
[2023-06-29 11:04:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2338.5698, current episode: 10
[2023-06-29 11:04:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 144500.000000 | iteration_144500.pth.tar | 10.000000     | 6460.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 646.000000              | 1.027137      | 6289.329015         | 9.735803             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1788.375378 | 273.779807 | 2338.569824 | 1432.306641 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1356.7297, current episode: 1
[2023-06-29 11:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1624.6825, current episode: 2
[2023-06-29 11:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1764.6605, current episode: 3
[2023-06-29 11:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1920.8356, current episode: 4
[2023-06-29 11:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2010.2749, current episode: 5
[2023-06-29 11:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1356.7297, current episode: 5
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1624.6825, current episode: 5
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1764.6605, current episode: 5
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3471.3367, current episode: 6
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3421.8230, current episode: 7
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3450.6233, current episode: 8
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3571.3892, current episode: 9
[2023-06-29 11:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3461.5181, current episode: 10
[2023-06-29 11:05:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 145000.000000 | iteration_145000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.551256      | 6446.390340         | 6.446390             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2605.387341 | 885.861044 | 3571.389160 | 1356.729736 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3499.4573, current episode: 1
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3388.6536, current episode: 2
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3385.6965, current episode: 3
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3409.2400, current episode: 4
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3455.2058, current episode: 5
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3451.9709, current episode: 6
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3419.9355, current episode: 7
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3446.3105, current episode: 8
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3380.8696, current episode: 9
[2023-06-29 11:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3403.2749, current episode: 10
[2023-06-29 11:05:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 145500.000000 | iteration_145500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525915      | 6553.444814         | 6.553445             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3424.061475 | 36.315784  | 3499.457275 | 3380.869629 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1248.6895, current episode: 1
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1325.0857, current episode: 2
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1352.5780, current episode: 3
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1366.5626, current episode: 4
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1473.9253, current episode: 5
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1468.3177, current episode: 6
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1595.1951, current episode: 7
[2023-06-29 11:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1649.1699, current episode: 8
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2206.8271, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1248.6895, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1325.0857, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1352.5780, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1366.5626, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1473.9253, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1468.3177, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1595.1951, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1649.1699, current episode: 9
[2023-06-29 11:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3479.1216, current episode: 10
[2023-06-29 11:05:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 146000.000000 | iteration_146000.pth.tar | 10.000000     | 9440.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 944.000000              | 1.485942      | 6352.874471         | 6.729740             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1716.547253 | 641.395972 | 3479.121582 | 1248.689453 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1219.7949, current episode: 1
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1209.4027, current episode: 2
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1208.0626, current episode: 3
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1219.3892, current episode: 4
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1253.0416, current episode: 5
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1253.3898, current episode: 6
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1262.0148, current episode: 7
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1260.7430, current episode: 8
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1278.3583, current episode: 9
[2023-06-29 11:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1322.8921, current episode: 10
[2023-06-29 11:05:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 146500.000000 | iteration_146500.pth.tar | 10.000000     | 3630.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 363.000000              | 0.583334      | 6222.848244         | 17.142833            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1248.708899 | 34.113843  | 1322.892090 | 1208.062622 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1204.5024, current episode: 1
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1221.2679, current episode: 2
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1247.2211, current episode: 3
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1279.1407, current episode: 4
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1278.5399, current episode: 5
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1285.5771, current episode: 6
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1288.2201, current episode: 7
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1277.5582, current episode: 8
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1303.7588, current episode: 9
[2023-06-29 11:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1323.8427, current episode: 10
[2023-06-29 11:06:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 147000.000000 | iteration_147000.pth.tar | 10.000000     | 3670.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 367.000000              | 0.580486      | 6322.285656         | 17.226936            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1270.962903 | 34.642846  | 1323.842651 | 1204.502441 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1179.7729, current episode: 1
[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1218.8943, current episode: 2
[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1210.3396, current episode: 3
[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1455.7485, current episode: 4
[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1477.5411, current episode: 5
[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1559.9846, current episode: 6
[2023-06-29 11:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1783.2081, current episode: 7
[2023-06-29 11:06:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2017.7343, current episode: 8
[2023-06-29 11:06:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2044.0223, current episode: 9
[2023-06-29 11:06:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1179.7729, current episode: 9
[2023-06-29 11:06:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1218.8943, current episode: 9
[2023-06-29 11:06:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1210.3396, current episode: 9
[2023-06-29 11:06:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2611.2739, current episode: 10
[2023-06-29 11:06:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 147500.000000 | iteration_147500.pth.tar | 10.000000     | 7190.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 719.000000              | 1.281524      | 5610.509418         | 7.803212             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1655.851978 | 436.781059 | 2611.273926 | 1179.772949 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1172.1355, current episode: 1
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1164.8352, current episode: 2
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1206.2987, current episode: 3
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1209.0671, current episode: 4
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1305.9785, current episode: 5
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1340.3436, current episode: 6
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1392.7227, current episode: 7
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1468.0078, current episode: 8
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1576.9872, current episode: 9
[2023-06-29 11:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1968.8502, current episode: 10
[2023-06-29 11:06:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 148000.000000 | iteration_148000.pth.tar | 10.000000     | 5410.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 541.000000              | 0.925319      | 5846.632928         | 10.807085            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1380.522656 | 234.392528 | 1968.850220 | 1164.835205 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1236.7024, current episode: 1
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1262.8022, current episode: 2
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1258.0499, current episode: 3
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1320.5594, current episode: 4
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1303.1282, current episode: 5
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1342.9382, current episode: 6
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1340.4811, current episode: 7
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1616.5587, current episode: 8
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1613.8307, current episode: 9
[2023-06-29 11:06:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2136.8906, current episode: 10
[2023-06-29 11:06:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 148500.000000 | iteration_148500.pth.tar | 10.000000     | 5750.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 575.000000              | 0.906472      | 6343.273382         | 11.031780            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1443.194153 | 265.538009 | 2136.890625 | 1236.702393 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1574.8208, current episode: 1
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1926.0121, current episode: 2
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2283.6545, current episode: 3
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2349.9456, current episode: 4
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2353.2588, current episode: 5
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2604.4258, current episode: 6
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1574.8208, current episode: 6
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3580.5161, current episode: 7
[2023-06-29 11:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3594.4573, current episode: 8
[2023-06-29 11:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3496.5906, current episode: 9
[2023-06-29 11:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3484.0164, current episode: 10
[2023-06-29 11:07:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 149000.000000 | iteration_149000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.537855      | 6502.561654         | 6.502562             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2724.769788 | 714.758441 | 3594.457275 | 1574.820801 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1826.9750, current episode: 1
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1979.3037, current episode: 2
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2010.0728, current episode: 3
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2061.3914, current episode: 4
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2228.8538, current episode: 5
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2518.5537, current episode: 6
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3166.5610, current episode: 7
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3352.9204, current episode: 8
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3456.6865, current episode: 9
[2023-06-29 11:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3604.5842, current episode: 10
[2023-06-29 11:07:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 149500.000000 | iteration_149500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.574390      | 6351.667286         | 6.351667             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2620.590247 | 662.726962 | 3604.584229 | 1826.974976 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1461.9835, current episode: 1
[2023-06-29 11:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1461.5566, current episode: 2
[2023-06-29 11:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1515.2209, current episode: 3
[2023-06-29 11:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1613.5748, current episode: 4
[2023-06-29 11:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1677.6243, current episode: 5
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2332.0320, current episode: 6
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2446.6077, current episode: 7
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2494.5210, current episode: 8
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1461.9835, current episode: 8
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1461.5566, current episode: 8
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1515.2209, current episode: 8
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1613.5748, current episode: 8
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1677.6243, current episode: 8
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3448.6360, current episode: 9
[2023-06-29 11:07:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3464.1223, current episode: 10
[2023-06-29 11:07:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 150000.000000 | iteration_150000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.565062      | 6389.524674         | 6.389525             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2191.587915 | 741.420257 | 3464.122314 | 1461.556641 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1619.5638, current episode: 1
[2023-06-29 11:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1726.4041, current episode: 2
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1804.2098, current episode: 3
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1819.6926, current episode: 4
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1840.0038, current episode: 5
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1920.7646, current episode: 6
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1619.5638, current episode: 6
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1726.4041, current episode: 6
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1804.2098, current episode: 6
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1819.6926, current episode: 6
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3444.9224, current episode: 7
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3480.2637, current episode: 8
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3419.1064, current episode: 9
[2023-06-29 11:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3441.3347, current episode: 10
[2023-06-29 11:08:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 150500.000000 | iteration_150500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.583884      | 6313.594027         | 6.313594             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2451.626599 | 815.655085 | 3480.263672 | 1619.563843 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:08:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1919.8839, current episode: 1
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1974.4161, current episode: 2
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2041.1891, current episode: 3
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2308.0688, current episode: 4
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3497.9382, current episode: 5
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3460.8188, current episode: 6
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3505.4182, current episode: 7
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3518.7922, current episode: 8
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3514.3506, current episode: 9
[2023-06-29 11:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3488.0581, current episode: 10
[2023-06-29 11:08:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 151000.000000 | iteration_151000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516042      | 6596.124954         | 6.596125             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2922.893420 | 710.264215 | 3518.792236 | 1919.883911 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:08:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1853.7275, current episode: 1
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3448.2695, current episode: 2
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3454.6951, current episode: 3
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3489.5049, current episode: 4
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1853.7275, current episode: 4
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3501.1863, current episode: 5
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3470.1052, current episode: 6
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3480.3247, current episode: 7
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3485.1746, current episode: 8
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.9314, current episode: 9
[2023-06-29 11:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3483.3506, current episode: 10
[2023-06-29 11:08:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 151500.000000 | iteration_151500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.575994      | 6345.203222         | 6.345203             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3314.426978 | 487.128783 | 3501.186279 | 1853.727539 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:08:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3175.1270, current episode: 1
[2023-06-29 11:08:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3471.2778, current episode: 2
[2023-06-29 11:08:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3465.7769, current episode: 3
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3467.8525, current episode: 4
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3446.9426, current episode: 5
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3463.6816, current episode: 6
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3508.1050, current episode: 7
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3455.5156, current episode: 8
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3452.6348, current episode: 9
[2023-06-29 11:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3459.5645, current episode: 10
[2023-06-29 11:08:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 152000.000000 | iteration_152000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525296      | 6556.106531         | 6.556107             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3436.647827 | 88.597021  | 3508.104980 | 3175.126953 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1484.3942, current episode: 1
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1498.5731, current episode: 2
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1479.5067, current episode: 3
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1570.0713, current episode: 4
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1563.8473, current episode: 5
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1580.7817, current episode: 6
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1640.6350, current episode: 7
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2134.8188, current episode: 8
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1484.3942, current episode: 8
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1498.5731, current episode: 8
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1479.5067, current episode: 8
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1570.0713, current episode: 8
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1563.8473, current episode: 8
[2023-06-29 11:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1580.7817, current episode: 8
[2023-06-29 11:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1640.6350, current episode: 8
[2023-06-29 11:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3556.6743, current episode: 9
[2023-06-29 11:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3496.0332, current episode: 10
[2023-06-29 11:09:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 152500.000000 | iteration_152500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.651975      | 6053.358672         | 6.053359             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2000.533569 | 784.070796 | 3556.674316 | 1479.506714 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3625.6260, current episode: 1
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3509.8958, current episode: 2
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3486.7993, current episode: 3
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3490.4961, current episode: 4
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3539.1123, current episode: 5
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3482.5413, current episode: 6
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3493.3066, current episode: 7
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3482.1145, current episode: 8
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.9695, current episode: 9
[2023-06-29 11:09:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.8784, current episode: 10
[2023-06-29 11:09:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 153000.000000 | iteration_153000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.599189      | 6253.170667         | 6.253171             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3505.873975 | 44.551541  | 3625.625977 | 3457.969482 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3489.2522, current episode: 1
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3468.6313, current episode: 2
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3495.2893, current episode: 3
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3455.1921, current episode: 4
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3482.3455, current episode: 5
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3496.5703, current episode: 6
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3477.1865, current episode: 7
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3477.1582, current episode: 8
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3472.3335, current episode: 9
[2023-06-29 11:09:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3463.2646, current episode: 10
[2023-06-29 11:09:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 153500.000000 | iteration_153500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.622362      | 6163.850836         | 6.163851             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3477.722363 | 12.833866  | 3496.570312 | 3455.192139 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:09:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1633.9027, current episode: 1
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1633.9027, current episode: 1
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3604.0146, current episode: 2
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3472.4531, current episode: 3
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3482.4675, current episode: 4
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3501.6506, current episode: 5
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3508.4480, current episode: 6
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3493.5156, current episode: 7
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3613.0762, current episode: 8
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3513.6672, current episode: 9
[2023-06-29 11:09:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3485.1853, current episode: 10
[2023-06-29 11:09:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 154000.000000 | iteration_154000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.781173      | 5614.276326         | 5.614276             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3330.838098 | 567.569864 | 3613.076172 | 1633.902710 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1485.6160, current episode: 1
[2023-06-29 11:10:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1574.7045, current episode: 2
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1794.1254, current episode: 3
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1768.6954, current episode: 4
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1805.5276, current episode: 5
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1826.8108, current episode: 6
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2764.1091, current episode: 7
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1485.6160, current episode: 7
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1574.7045, current episode: 7
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1794.1254, current episode: 7
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3589.7534, current episode: 8
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1768.6954, current episode: 8
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3520.5828, current episode: 9
[2023-06-29 11:10:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3474.9487, current episode: 10
[2023-06-29 11:10:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 154500.000000 | iteration_154500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.712740      | 5838.597003         | 5.838597             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2360.487366 | 831.172689 | 3589.753418 | 1485.615967 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1697.9282, current episode: 1
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1847.3925, current episode: 2
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2207.9849, current episode: 3
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2800.2722, current episode: 4
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1697.9282, current episode: 4
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3482.8438, current episode: 5
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3456.2063, current episode: 6
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3457.0110, current episode: 7
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3470.4783, current episode: 8
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3494.8992, current episode: 9
[2023-06-29 11:10:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3459.8567, current episode: 10
[2023-06-29 11:10:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 155000.000000 | iteration_155000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.756021      | 5694.693522         | 5.694694             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2937.487292 | 705.681254 | 3494.899170 | 1697.928223 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:10:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1344.5009, current episode: 1
[2023-06-29 11:10:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1471.3772, current episode: 2
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1790.1870, current episode: 3
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1870.9921, current episode: 4
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1889.0627, current episode: 5
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2554.4692, current episode: 6
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1344.5009, current episode: 6
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1471.3772, current episode: 6
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3182.8381, current episode: 7
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1790.1870, current episode: 7
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3597.9258, current episode: 8
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3514.4585, current episode: 9
[2023-06-29 11:10:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3486.7759, current episode: 10
[2023-06-29 11:10:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 155500.000000 | iteration_155500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.681706      | 5946.342821         | 5.946343             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2470.258740 | 856.426064 | 3597.925781 | 1344.500854 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:11:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 859.1425, current episode: 1
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1256.4926, current episode: 2
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1401.6531, current episode: 3
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1626.1737, current episode: 4
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 859.1425, current episode: 4
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1785.0208, current episode: 5
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1884.1484, current episode: 6
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1949.4888, current episode: 7
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2009.1549, current episode: 8
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1256.4926, current episode: 8
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2581.8721, current episode: 9
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 859.1425, current episode: 9
[2023-06-29 11:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2773.0098, current episode: 10
[2023-06-29 11:11:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 156000.000000 | iteration_156000.pth.tar | 10.000000     | 7680.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 768.000000              | 1.268079      | 6056.406850         | 7.885946             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1812.615649 | 547.666642 | 2773.009766 | 859.142456 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 932.5639, current episode: 1
[2023-06-29 11:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 943.6274, current episode: 2
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1708.4469, current episode: 3
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1757.0083, current episode: 4
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 932.5639, current episode: 4
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 943.6274, current episode: 4
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2064.3198, current episode: 5
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 932.5639, current episode: 5
[2023-06-29 11:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 943.6274, current episode: 5
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1708.4469, current episode: 5
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1757.0083, current episode: 5
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3419.2695, current episode: 6
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3419.7190, current episode: 7
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3452.5737, current episode: 8
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3421.5889, current episode: 9
[2023-06-29 11:11:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3442.6289, current episode: 10
[2023-06-29 11:11:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 156500.000000 | iteration_156500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.719869      | 5814.396679         | 5.814397             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2456.174640 | 1027.840772 | 3452.573730 | 932.563904 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 681.7829, current episode: 1
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 795.0521, current episode: 2
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 804.4686, current episode: 3
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 870.4858, current episode: 4
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 925.4354, current episode: 5
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 931.9901, current episode: 6
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 681.7829, current episode: 6
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 795.0521, current episode: 6
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 804.4686, current episode: 6
[2023-06-29 11:11:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1694.3779, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 870.4858, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 925.4354, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 931.9901, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 681.7829, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 795.0521, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 804.4686, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 870.4858, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 681.7829, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 925.4354, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 931.9901, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 795.0521, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 804.4686, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1694.3779, current episode: 7
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3443.0166, current episode: 8
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3453.0913, current episode: 9
[2023-06-29 11:11:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3454.1648, current episode: 10
[2023-06-29 11:11:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 157000.000000 | iteration_157000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.737170      | 5756.488857         | 5.756489             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1705.386548 | 1171.487442 | 3454.164795 | 681.782898 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:11:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 762.4408, current episode: 1
[2023-06-29 11:11:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.9964, current episode: 2
[2023-06-29 11:11:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 897.7772, current episode: 3
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 955.0114, current episode: 4
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1502.9694, current episode: 5
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 762.4408, current episode: 5
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.9964, current episode: 5
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 897.7772, current episode: 5
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 955.0114, current episode: 5
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2132.9753, current episode: 6
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 762.4408, current episode: 6
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2524.2739, current episode: 7
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.9964, current episode: 7
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2800.9780, current episode: 8
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 897.7772, current episode: 8
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 955.0114, current episode: 8
[2023-06-29 11:11:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1502.9694, current episode: 8
[2023-06-29 11:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3227.5750, current episode: 9
[2023-06-29 11:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 762.4408, current episode: 9
[2023-06-29 11:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.9964, current episode: 9
[2023-06-29 11:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3440.7192, current episode: 10
[2023-06-29 11:11:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 157500.000000 | iteration_157500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.725517      | 5795.364628         | 5.795365             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1904.671655 | 997.323918 | 3440.719238 | 762.440796 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 845.5414, current episode: 1
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 925.1000, current episode: 2
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.7010, current episode: 3
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1147.7799, current episode: 4
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1530.3219, current episode: 5
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1537.9321, current episode: 6
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1572.4215, current episode: 7
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 845.5414, current episode: 7
[2023-06-29 11:12:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 925.1000, current episode: 7
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.7010, current episode: 7
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1147.7799, current episode: 7
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 845.5414, current episode: 7
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2671.6260, current episode: 8
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2670.6692, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 925.1000, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1530.3219, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1537.9321, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.7010, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1572.4215, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 845.5414, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1147.7799, current episode: 9
[2023-06-29 11:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3460.0483, current episode: 10
[2023-06-29 11:12:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 158000.000000 | iteration_158000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.801811      | 5549.970807         | 5.549971             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1736.414148 | 846.394774 | 3460.048340 | 845.541443 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:12:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.0411, current episode: 1
[2023-06-29 11:12:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1388.5033, current episode: 2
[2023-06-29 11:12:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1389.0601, current episode: 3
[2023-06-29 11:12:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1405.7728, current episode: 4
[2023-06-29 11:12:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1819.9651, current episode: 5
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.0411, current episode: 5
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2347.7959, current episode: 6
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2649.0596, current episode: 7
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1388.5033, current episode: 7
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1389.0601, current episode: 7
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1405.7728, current episode: 7
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.0411, current episode: 7
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3021.4348, current episode: 8
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3039.4329, current episode: 9
[2023-06-29 11:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3589.0942, current episode: 10
[2023-06-29 11:12:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 158500.000000 | iteration_158500.pth.tar | 10.000000     | 9880.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 988.000000              | 1.589507      | 6215.765352         | 6.291260             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2160.615979 | 845.918440 | 3589.094238 | 956.041138 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1128.6384, current episode: 1
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1244.0289, current episode: 2
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1256.9620, current episode: 3
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1308.4386, current episode: 4
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1379.6008, current episode: 5
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1717.0544, current episode: 6
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1762.2891, current episode: 7
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1790.5781, current episode: 8
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1937.8772, current episode: 9
[2023-06-29 11:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1954.9758, current episode: 10
[2023-06-29 11:12:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 159000.000000 | iteration_159000.pth.tar | 10.000000     | 5490.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 549.000000              | 0.952450      | 5764.079814         | 10.499235            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1548.044348 | 298.276796 | 1954.975830 | 1128.638428 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1039.9474, current episode: 1
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1040.4664, current episode: 2
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1080.7863, current episode: 3
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1098.5392, current episode: 4
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1110.3071, current episode: 5
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1120.9098, current episode: 6
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1516.0577, current episode: 7
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1686.6819, current episode: 8
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1748.8561, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1039.9474, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1040.4664, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1080.7863, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1098.5392, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1110.3071, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1120.9098, current episode: 9
[2023-06-29 11:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2403.8555, current episode: 10
[2023-06-29 11:13:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 159500.000000 | iteration_159500.pth.tar | 10.000000     | 6660.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 666.000000              | 1.262504      | 5275.230693         | 7.920767             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1384.640735 | 428.510771 | 2403.855469 | 1039.947388 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1207.9712, current episode: 1
[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1233.8962, current episode: 2
[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1235.7415, current episode: 3
[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1260.7992, current episode: 4
[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1668.8472, current episode: 5
[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2003.4819, current episode: 6
[2023-06-29 11:13:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2069.8171, current episode: 7
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1207.9712, current episode: 7
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1233.8962, current episode: 7
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1235.7415, current episode: 7
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1260.7992, current episode: 7
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3141.6777, current episode: 8
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1668.8472, current episode: 8
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3320.0339, current episode: 9
[2023-06-29 11:13:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3341.1653, current episode: 10
[2023-06-29 11:13:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 160000.000000 | iteration_160000.pth.tar | 10.000000     | 9220.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 922.000000              | 1.605578      | 5742.479394         | 6.228286             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2048.343127 | 853.261606 | 3341.165283 | 1207.971191 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1505.4163, current episode: 1
[2023-06-29 11:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1787.7438, current episode: 2
[2023-06-29 11:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1955.9771, current episode: 3
[2023-06-29 11:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2244.6147, current episode: 4
[2023-06-29 11:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2230.5784, current episode: 5
[2023-06-29 11:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2270.4246, current episode: 6
[2023-06-29 11:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1505.4163, current episode: 6
[2023-06-29 11:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1787.7438, current episode: 6
[2023-06-29 11:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3491.0325, current episode: 7
[2023-06-29 11:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3623.7441, current episode: 8
[2023-06-29 11:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3466.8899, current episode: 9
[2023-06-29 11:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3449.9270, current episode: 10
[2023-06-29 11:13:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 160500.000000 | iteration_160500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.688798      | 5921.371815         | 5.921372             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2602.634827 | 771.999080 | 3623.744141 | 1505.416260 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:13:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1761.4595, current episode: 1
[2023-06-29 11:13:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2888.1091, current episode: 2
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1761.4595, current episode: 2
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3478.6782, current episode: 3
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3453.2705, current episode: 4
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3460.3643, current episode: 5
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3460.0088, current episode: 6
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3474.2898, current episode: 7
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3447.9670, current episode: 8
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3460.9246, current episode: 9
[2023-06-29 11:13:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3438.5356, current episode: 10
[2023-06-29 11:13:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 161000.000000 | iteration_161000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.640438      | 6095.932959         | 6.095933             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3232.360742 | 519.144260 | 3478.678223 | 1761.459473 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:14:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1303.0977, current episode: 1
[2023-06-29 11:14:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1421.3387, current episode: 2
[2023-06-29 11:14:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1530.1904, current episode: 3
[2023-06-29 11:14:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1303.0977, current episode: 3
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1421.3387, current episode: 3
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1530.1904, current episode: 3
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3452.6260, current episode: 4
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3468.3926, current episode: 5
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3461.0779, current episode: 6
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3445.6240, current episode: 7
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3473.8948, current episode: 8
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3473.3857, current episode: 9
[2023-06-29 11:14:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3450.6016, current episode: 10
[2023-06-29 11:14:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 161500.000000 | iteration_161500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.651282      | 6055.899083         | 6.055899             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2848.022937 | 937.452205 | 3473.894775 | 1303.097656 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:14:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1603.9238, current episode: 1
[2023-06-29 11:14:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1623.9966, current episode: 2
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2296.9509, current episode: 3
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2816.5171, current episode: 4
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1603.9238, current episode: 4
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1623.9966, current episode: 4
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3234.2563, current episode: 5
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3478.4714, current episode: 6
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3471.1792, current episode: 7
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3457.6562, current episode: 8
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3420.0059, current episode: 9
[2023-06-29 11:14:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3482.3147, current episode: 10
[2023-06-29 11:14:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 162000.000000 | iteration_162000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553332      | 6437.772119         | 6.437772             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2888.527222 | 732.830040 | 3482.314697 | 1603.923828 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:14:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1147.6622, current episode: 1
[2023-06-29 11:14:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1508.4293, current episode: 2
[2023-06-29 11:14:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2156.8655, current episode: 3
[2023-06-29 11:14:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2200.9209, current episode: 4
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1147.6622, current episode: 4
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1508.4293, current episode: 4
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1147.6622, current episode: 4
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3514.9456, current episode: 5
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3381.3967, current episode: 6
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3422.7583, current episode: 7
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3410.2151, current episode: 8
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3411.0581, current episode: 9
[2023-06-29 11:14:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3404.4822, current episode: 10
[2023-06-29 11:14:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 162500.000000 | iteration_162500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.684929      | 5934.969628         | 5.934970             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2755.873389 | 866.000664 | 3514.945557 | 1147.662231 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 937.5193, current episode: 1
[2023-06-29 11:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1608.0745, current episode: 2
[2023-06-29 11:14:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 937.5193, current episode: 2
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 937.5193, current episode: 2
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1608.0745, current episode: 2
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3428.9187, current episode: 3
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3452.3892, current episode: 4
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3427.8059, current episode: 5
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3426.2778, current episode: 6
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3397.8933, current episode: 7
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3404.0872, current episode: 8
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3385.7275, current episode: 9
[2023-06-29 11:14:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3442.5393, current episode: 10
[2023-06-29 11:14:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 163000.000000 | iteration_163000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.555896      | 6427.163301         | 6.427163             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2991.123273 | 872.358032 | 3452.389160 | 937.519348 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1269.6262, current episode: 1
[2023-06-29 11:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1351.6036, current episode: 2
[2023-06-29 11:15:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1499.3777, current episode: 3
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1580.9659, current episode: 4
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1609.5133, current episode: 5
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1269.6262, current episode: 5
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1351.6036, current episode: 5
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1499.3777, current episode: 5
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1580.9659, current episode: 5
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1609.5133, current episode: 5
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3464.2820, current episode: 6
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3455.0771, current episode: 7
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3469.9187, current episode: 8
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3480.7661, current episode: 9
[2023-06-29 11:15:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.2908, current episode: 10
[2023-06-29 11:15:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 163500.000000 | iteration_163500.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.605334      | 6228.611378         | 6.229234             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2463.842151 | 1005.955133 | 3480.766113 | 1269.626221 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 11:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1346.9502, current episode: 1
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1346.9502, current episode: 1
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3474.0134, current episode: 2
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3432.0642, current episode: 3
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3444.9058, current episode: 4
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3470.4778, current episode: 5
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3461.1057, current episode: 6
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3451.5215, current episode: 7
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3451.4307, current episode: 8
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3451.1243, current episode: 9
[2023-06-29 11:15:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3456.4756, current episode: 10
[2023-06-29 11:15:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 164000.000000 | iteration_164000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.573146      | 6356.687616         | 6.356688             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3244.006909 | 632.455648 | 3474.013428 | 1346.950195 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3477.7034, current episode: 1
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3461.3965, current episode: 2
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3480.7974, current episode: 3
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3490.5317, current episode: 4
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3479.2073, current episode: 5
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3483.7266, current episode: 6
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3477.6536, current episode: 7
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3464.9600, current episode: 8
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3445.3208, current episode: 9
[2023-06-29 11:15:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3485.0315, current episode: 10
[2023-06-29 11:15:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 164500.000000 | iteration_164500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.543380      | 6479.286216         | 6.479286             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3474.632861 | 12.841510  | 3490.531738 | 3445.320801 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:15:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1030.7443, current episode: 1
[2023-06-29 11:15:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1192.5962, current episode: 2
[2023-06-29 11:15:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1337.6974, current episode: 3
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1030.7443, current episode: 3
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1192.5962, current episode: 3
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1337.6974, current episode: 3
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2886.6692, current episode: 4
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1030.7443, current episode: 4
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1192.5962, current episode: 4
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3485.8523, current episode: 5
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3473.6995, current episode: 6
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3481.6304, current episode: 7
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3509.8293, current episode: 8
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3473.9805, current episode: 9
[2023-06-29 11:16:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3471.1633, current episode: 10
[2023-06-29 11:16:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 165000.000000 | iteration_165000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 2.001119      | 4997.204018         | 4.997204             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2734.386230 | 1030.254996 | 3509.829346 | 1030.744263 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 11:16:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1929.4865, current episode: 1
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3449.0564, current episode: 2
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3465.2068, current episode: 3
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3426.2119, current episode: 4
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3489.6667, current episode: 5
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3455.4412, current episode: 6
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3418.0447, current episode: 7
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3460.2852, current episode: 8
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3472.6975, current episode: 9
[2023-06-29 11:16:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3470.2017, current episode: 10
[2023-06-29 11:16:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 165500.000000 | iteration_165500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.543077      | 6480.556353         | 6.480556             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3303.629846 | 458.494331 | 3489.666748 | 1929.486450 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:16:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1287.0778, current episode: 1
[2023-06-29 11:16:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1335.5000, current episode: 2
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1287.0778, current episode: 2
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1335.5000, current episode: 2
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3289.3760, current episode: 3
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3346.6021, current episode: 4
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3451.5210, current episode: 5
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3490.3899, current episode: 6
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3471.5437, current episode: 7
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3478.9753, current episode: 8
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3462.8547, current episode: 9
[2023-06-29 11:16:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3479.8955, current episode: 10
[2023-06-29 11:16:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 166000.000000 | iteration_166000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.656270      | 6037.661980         | 6.037662             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3009.373596 | 851.370316 | 3490.389893 | 1287.077759 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3345.0850, current episode: 1
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3396.3569, current episode: 2
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3331.9409, current episode: 3
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3342.5117, current episode: 4
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3379.3459, current episode: 5
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3410.0093, current episode: 6
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3375.2976, current episode: 7
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3359.9426, current episode: 8
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3416.5645, current episode: 9
[2023-06-29 11:16:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3359.6245, current episode: 10
[2023-06-29 11:16:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 166500.000000 | iteration_166500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.576169      | 6344.498034         | 6.344498             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3371.667896 | 27.540754  | 3416.564453 | 3331.940918 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2243.1584, current episode: 1
[2023-06-29 11:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2918.9155, current episode: 2
[2023-06-29 11:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3143.2954, current episode: 3
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3306.1038, current episode: 4
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3323.0928, current episode: 5
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3343.8245, current episode: 6
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3283.7251, current episode: 7
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3376.0647, current episode: 8
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3425.0789, current episode: 9
[2023-06-29 11:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3311.3826, current episode: 10
[2023-06-29 11:17:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 167000.000000 | iteration_167000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.803061      | 5546.125457         | 5.546125             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3167.464160 | 336.950203 | 3425.078857 | 2243.158447 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:17:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1357.1029, current episode: 1
[2023-06-29 11:17:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1357.7761, current episode: 2
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1357.1029, current episode: 2
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1357.7761, current episode: 2
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3376.7769, current episode: 3
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3384.9077, current episode: 4
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3416.4561, current episode: 5
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3356.7358, current episode: 6
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3368.7920, current episode: 7
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3368.2161, current episode: 8
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3403.3020, current episode: 9
[2023-06-29 11:17:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3368.6206, current episode: 10
[2023-06-29 11:17:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 167500.000000 | iteration_167500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.640313      | 6096.398860         | 6.096399             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2975.868616 | 809.390017 | 3416.456055 | 1357.102905 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3444.6526, current episode: 1
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3445.9990, current episode: 2
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3429.1233, current episode: 3
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3453.6460, current episode: 4
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3457.5129, current episode: 5
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3443.8369, current episode: 6
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3454.7319, current episode: 7
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3454.1885, current episode: 8
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3450.9971, current episode: 9
[2023-06-29 11:17:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3475.1692, current episode: 10
[2023-06-29 11:17:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 168000.000000 | iteration_168000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.675653      | 5967.824161         | 5.967824             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3450.985742 | 11.193126  | 3475.169189 | 3429.123291 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:17:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1345.8878, current episode: 1
[2023-06-29 11:17:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1345.9991, current episode: 2
[2023-06-29 11:17:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1458.7761, current episode: 3
[2023-06-29 11:17:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1506.4728, current episode: 4
[2023-06-29 11:17:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1545.0630, current episode: 5
[2023-06-29 11:17:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1692.6819, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1345.8878, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1345.9991, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1458.7761, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1506.4728, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1545.0630, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1692.6819, current episode: 6
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3506.3245, current episode: 7
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3518.8088, current episode: 8
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3485.3794, current episode: 9
[2023-06-29 11:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3475.6597, current episode: 10
[2023-06-29 11:17:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 168500.000000 | iteration_168500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.658745      | 6028.652880         | 6.028653             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2288.105310 | 991.118295 | 3518.808838 | 1345.887817 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:18:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2584.4031, current episode: 1
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3485.7224, current episode: 2
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3460.6353, current episode: 3
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3467.3071, current episode: 4
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3461.5381, current episode: 5
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3482.8440, current episode: 6
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3468.3682, current episode: 7
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3466.3601, current episode: 8
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3476.2893, current episode: 9
[2023-06-29 11:18:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3486.7078, current episode: 10
[2023-06-29 11:18:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 169000.000000 | iteration_169000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.639394      | 6099.816589         | 6.099817             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3384.017529 | 266.695593 | 3486.707764 | 2584.403076 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:18:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1659.2338, current episode: 1
[2023-06-29 11:18:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1676.2686, current episode: 2
[2023-06-29 11:18:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1669.9465, current episode: 3
[2023-06-29 11:18:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2283.9705, current episode: 4
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1659.2338, current episode: 4
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1676.2686, current episode: 4
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1669.9465, current episode: 4
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3454.4565, current episode: 5
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3420.1135, current episode: 6
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3422.5017, current episode: 7
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3470.1963, current episode: 8
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3409.2876, current episode: 9
[2023-06-29 11:18:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3426.3354, current episode: 10
[2023-06-29 11:18:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 169500.000000 | iteration_169500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.600910      | 6246.446247         | 6.246446             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2789.231042 | 807.423102 | 3470.196289 | 1659.233765 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:18:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1836.0615, current episode: 1
[2023-06-29 11:18:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2056.6511, current episode: 2
[2023-06-29 11:18:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2476.2458, current episode: 3
[2023-06-29 11:18:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2502.9980, current episode: 4
[2023-06-29 11:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3330.9890, current episode: 5
[2023-06-29 11:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3432.1594, current episode: 6
[2023-06-29 11:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3467.3982, current episode: 7
[2023-06-29 11:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3449.3965, current episode: 8
[2023-06-29 11:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3413.7986, current episode: 9
[2023-06-29 11:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3404.7556, current episode: 10
[2023-06-29 11:18:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 170000.000000 | iteration_170000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.871170      | 5344.248683         | 5.344249             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2937.045386 | 614.666295 | 3467.398193 | 1836.061523 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3456.1663, current episode: 1
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3417.5103, current episode: 2
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3449.7686, current episode: 3
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3434.0237, current episode: 4
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3434.2791, current episode: 5
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3447.6743, current episode: 6
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3441.7170, current episode: 7
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3434.6917, current episode: 8
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3410.6523, current episode: 9
[2023-06-29 11:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3442.8064, current episode: 10
[2023-06-29 11:19:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 170500.000000 | iteration_170500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.701509      | 5877.136426         | 5.877136             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3436.928955 | 13.401032  | 3456.166260 | 3410.652344 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3424.6326, current episode: 1
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3429.9331, current episode: 2
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3458.1348, current episode: 3
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3440.9343, current episode: 4
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3372.0732, current episode: 5
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3420.7085, current episode: 6
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3405.9578, current episode: 7
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3401.4470, current episode: 8
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3421.8501, current episode: 9
[2023-06-29 11:19:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3437.8381, current episode: 10
[2023-06-29 11:19:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 171000.000000 | iteration_171000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.571958      | 6361.492099         | 6.361492             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3421.350952 | 22.704357  | 3458.134766 | 3372.073242 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3419.0288, current episode: 1
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3408.3770, current episode: 2
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3441.8958, current episode: 3
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3423.5847, current episode: 4
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3444.1838, current episode: 5
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3360.6580, current episode: 6
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3392.6577, current episode: 7
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3373.1038, current episode: 8
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3417.6860, current episode: 9
[2023-06-29 11:19:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3459.3582, current episode: 10
[2023-06-29 11:19:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 171500.000000 | iteration_171500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.614245      | 6194.845589         | 6.194846             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3414.053369 | 29.803189  | 3459.358154 | 3360.657959 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3430.2590, current episode: 1
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3407.8262, current episode: 2
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3419.1570, current episode: 3
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3456.0801, current episode: 4
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3439.7178, current episode: 5
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3417.9668, current episode: 6
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3415.1643, current episode: 7
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3364.6853, current episode: 8
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3433.4194, current episode: 9
[2023-06-29 11:19:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3382.6672, current episode: 10
[2023-06-29 11:19:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 172000.000000 | iteration_172000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547413      | 6462.396967         | 6.462397             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3416.694312 | 25.488228  | 3456.080078 | 3364.685303 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3461.5337, current episode: 1
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3404.5798, current episode: 2
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3454.9966, current episode: 3
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3448.3218, current episode: 4
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3453.8625, current episode: 5
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3450.9634, current episode: 6
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3459.4119, current episode: 7
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3427.7278, current episode: 8
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3378.7976, current episode: 9
[2023-06-29 11:20:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3455.3828, current episode: 10
[2023-06-29 11:20:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 172500.000000 | iteration_172500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.630534      | 6132.961742         | 6.132962             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3439.557788 | 26.139318  | 3461.533691 | 3378.797607 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3475.5222, current episode: 1
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3477.8938, current episode: 2
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3440.3318, current episode: 3
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3499.9744, current episode: 4
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3480.1108, current episode: 5
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3448.8279, current episode: 6
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3453.5315, current episode: 7
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3427.7935, current episode: 8
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3467.9346, current episode: 9
[2023-06-29 11:20:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3483.1970, current episode: 10
[2023-06-29 11:20:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 173000.000000 | iteration_173000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541444      | 6487.423608         | 6.487424             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3465.511743 | 21.098689  | 3499.974365 | 3427.793457 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:20:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3493.8430, current episode: 1
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3457.9634, current episode: 2
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3490.6890, current episode: 3
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3512.8210, current episode: 4
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3499.4033, current episode: 5
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3471.3943, current episode: 6
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3498.6399, current episode: 7
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3485.6492, current episode: 8
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3460.8191, current episode: 9
[2023-06-29 11:20:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3507.4631, current episode: 10
[2023-06-29 11:20:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 173500.000000 | iteration_173500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.695471      | 5898.065842         | 5.898066             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3487.868530 | 17.893060  | 3512.821045 | 3457.963379 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 871.7525, current episode: 1
[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 922.9668, current episode: 2
[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 945.3192, current episode: 3
[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 871.7525, current episode: 3
[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 922.9668, current episode: 3
[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 945.3192, current episode: 3
[2023-06-29 11:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 871.7525, current episode: 3
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 922.9668, current episode: 3
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 945.3192, current episode: 3
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 871.7525, current episode: 3
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3393.2356, current episode: 4
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3420.6272, current episode: 5
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3390.0769, current episode: 6
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3426.6123, current episode: 7
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3423.3923, current episode: 8
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3403.9470, current episode: 9
[2023-06-29 11:20:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3391.5962, current episode: 10
[2023-06-29 11:20:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 174000.000000 | iteration_174000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.773895      | 5637.312956         | 5.637313             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2658.952606 | 1142.960436 | 3426.612305 | 871.752502 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3474.1604, current episode: 1
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3449.7881, current episode: 2
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3476.0352, current episode: 3
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3487.1521, current episode: 4
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3470.2119, current episode: 5
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3473.6694, current episode: 6
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3466.3611, current episode: 7
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3446.9172, current episode: 8
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3473.0500, current episode: 9
[2023-06-29 11:21:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3479.4597, current episode: 10
[2023-06-29 11:21:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 174500.000000 | iteration_174500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.750683      | 5712.057231         | 5.712057             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3469.680518 | 11.890255  | 3487.152100 | 3446.917236 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3508.4612, current episode: 1
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3487.9089, current episode: 2
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3502.6394, current episode: 3
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3508.4324, current episode: 4
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3514.8184, current episode: 5
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.7729, current episode: 6
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3505.5410, current episode: 7
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.2603, current episode: 8
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3492.7856, current episode: 9
[2023-06-29 11:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.0049, current episode: 10
[2023-06-29 11:21:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 175000.000000 | iteration_175000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.743571      | 5735.357231         | 5.735357             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3503.362500 | 8.293437   | 3514.818359 | 3487.908936 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3480.6782, current episode: 1
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3518.0015, current episode: 2
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3506.1826, current episode: 3
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3511.1641, current episode: 4
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3509.2896, current episode: 5
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3521.7236, current episode: 6
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3515.0247, current episode: 7
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3492.6514, current episode: 8
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3480.2573, current episode: 9
[2023-06-29 11:21:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3520.6626, current episode: 10
[2023-06-29 11:21:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 175500.000000 | iteration_175500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.631565      | 6129.084872         | 6.129085             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3505.563550 | 14.850538  | 3521.723633 | 3480.257324 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.8513, current episode: 1
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3449.2883, current episode: 2
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3505.0894, current episode: 3
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3505.1172, current episode: 4
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3524.0959, current episode: 5
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3552.7131, current episode: 6
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3466.3982, current episode: 7
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3499.5774, current episode: 8
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3495.4036, current episode: 9
[2023-06-29 11:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.5105, current episode: 10
[2023-06-29 11:22:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 176000.000000 | iteration_176000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.626395      | 6148.567771         | 6.148568             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3500.904492 | 27.275186  | 3552.713135 | 3449.288330 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3475.5476, current episode: 1
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3467.6099, current episode: 2
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3489.5361, current episode: 3
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3479.1375, current episode: 4
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3468.1533, current episode: 5
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.2151, current episode: 6
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3468.7131, current episode: 7
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3452.5969, current episode: 8
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3454.6389, current episode: 9
[2023-06-29 11:22:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3478.5359, current episode: 10
[2023-06-29 11:22:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 176500.000000 | iteration_176500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.567809      | 6378.327639         | 6.378328             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3473.168433 | 13.261490  | 3497.215088 | 3452.596924 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:22:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1526.9294, current episode: 1
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2265.4270, current episode: 2
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2962.6785, current episode: 3
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1526.9294, current episode: 3
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3532.9578, current episode: 4
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3558.9690, current episode: 5
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.7493, current episode: 6
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3536.0305, current episode: 7
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3635.3335, current episode: 8
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3535.5354, current episode: 9
[2023-06-29 11:22:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.6858, current episode: 10
[2023-06-29 11:22:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 177000.000000 | iteration_177000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.559821      | 6410.990842         | 6.410991             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3162.929614 | 678.115519 | 3635.333496 | 1526.929443 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:22:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1272.1704, current episode: 1
[2023-06-29 11:22:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1321.3826, current episode: 2
[2023-06-29 11:22:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1327.1979, current episode: 3
[2023-06-29 11:22:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1343.1698, current episode: 4
[2023-06-29 11:22:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1342.2583, current episode: 5
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1346.4528, current episode: 6
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1351.4233, current episode: 7
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1405.9501, current episode: 8
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1687.7634, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1272.1704, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1321.3826, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1327.1979, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1343.1698, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1342.2583, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1346.4528, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1351.4233, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1405.9501, current episode: 9
[2023-06-29 11:22:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1687.7634, current episode: 9
[2023-06-29 11:22:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3579.7324, current episode: 10
[2023-06-29 11:22:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 177500.000000 | iteration_177500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.749150      | 5717.064089         | 5.717064             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1597.750098 | 669.525029 | 3579.732422 | 1272.170410 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1346.8824, current episode: 1
[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1360.1044, current episode: 2
[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1271.8705, current episode: 3
[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1278.1436, current episode: 4
[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1704.4438, current episode: 5
[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1703.6912, current episode: 6
[2023-06-29 11:23:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2064.5408, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1346.8824, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1360.1044, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1271.8705, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1278.1436, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1704.4438, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1703.6912, current episode: 7
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3614.0195, current episode: 8
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3550.1582, current episode: 9
[2023-06-29 11:23:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3500.8022, current episode: 10
[2023-06-29 11:23:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 178000.000000 | iteration_178000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 2.111327      | 4736.357417         | 4.736357             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2139.465662 | 955.643570 | 3614.019531 | 1271.870483 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:23:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1357.9269, current episode: 1
[2023-06-29 11:23:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1637.8137, current episode: 2
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1357.9269, current episode: 2
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1637.8137, current episode: 2
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3445.0051, current episode: 3
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3535.4265, current episode: 4
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3511.9983, current episode: 5
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.9507, current episode: 6
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3514.6987, current episode: 7
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3491.7273, current episode: 8
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3512.3770, current episode: 9
[2023-06-29 11:23:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3541.1931, current episode: 10
[2023-06-29 11:23:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 178500.000000 | iteration_178500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.784386      | 5604.169798         | 5.604170             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3108.911731 | 808.390351 | 3541.193115 | 1357.926880 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:23:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2548.3369, current episode: 1
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3051.9299, current episode: 2
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3654.2642, current episode: 3
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3528.9792, current episode: 4
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3510.2354, current episode: 5
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3531.1790, current episode: 6
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3521.3618, current episode: 7
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3541.9390, current episode: 8
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3549.9712, current episode: 9
[2023-06-29 11:23:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3515.4353, current episode: 10
[2023-06-29 11:23:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 179000.000000 | iteration_179000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.622318      | 6163.402791         | 6.164019             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3395.363184 | 320.562860 | 3654.264160 | 2548.336914 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3525.6594, current episode: 1
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3490.0942, current episode: 2
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3570.8894, current episode: 3
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3531.8655, current episode: 4
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3544.4387, current episode: 5
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.9639, current episode: 6
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3514.8271, current episode: 7
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3507.2837, current episode: 8
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3511.1260, current episode: 9
[2023-06-29 11:24:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3549.6887, current episode: 10
[2023-06-29 11:24:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 179500.000000 | iteration_179500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.722298      | 5806.197464         | 5.806197             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3524.383667 | 23.866740  | 3570.889404 | 3490.094238 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2006.4969, current episode: 1
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1882.7646, current episode: 2
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2652.4282, current episode: 3
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3015.7209, current episode: 4
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3219.1926, current episode: 5
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3203.8093, current episode: 6
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3534.3677, current episode: 7
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3558.1460, current episode: 8
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.2014, current episode: 9
[2023-06-29 11:24:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3571.4141, current episode: 10
[2023-06-29 11:24:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 180000.000000 | iteration_180000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535303      | 6513.373924         | 6.513374             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3018.954187 | 605.238949 | 3571.414062 | 1882.764648 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3583.7942, current episode: 1
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3554.1406, current episode: 2
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3552.2559, current episode: 3
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3544.8723, current episode: 4
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.7078, current episode: 5
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3519.1189, current episode: 6
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3519.8188, current episode: 7
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3539.7859, current episode: 8
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3532.0781, current episode: 9
[2023-06-29 11:24:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3524.3660, current episode: 10
[2023-06-29 11:24:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 180500.000000 | iteration_180500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.647144      | 6071.113550         | 6.071114             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3543.093848 | 19.430519  | 3583.794189 | 3519.118896 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3545.5750, current episode: 1
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3526.1897, current episode: 2
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3535.8027, current episode: 3
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3527.9978, current episode: 4
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3541.0410, current episode: 5
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3529.3696, current episode: 6
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3538.6318, current episode: 7
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3524.5386, current episode: 8
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3508.8081, current episode: 9
[2023-06-29 11:24:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3547.6721, current episode: 10
[2023-06-29 11:24:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 181000.000000 | iteration_181000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.735197      | 5763.035544         | 5.763036             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3532.562646 | 11.032424  | 3547.672119 | 3508.808105 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3556.8948, current episode: 1
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3504.1807, current episode: 2
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3536.1799, current episode: 3
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3515.6960, current episode: 4
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3513.3057, current episode: 5
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3531.8264, current episode: 6
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3532.4426, current episode: 7
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3541.8794, current episode: 8
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.9097, current episode: 9
[2023-06-29 11:25:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3517.5376, current episode: 10
[2023-06-29 11:25:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 181500.000000 | iteration_181500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.573479      | 6355.345752         | 6.355346             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3526.685278 | 15.095295  | 3556.894775 | 3504.180664 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3546.9629, current episode: 1
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3592.6829, current episode: 2
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3549.7034, current episode: 3
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3512.6267, current episode: 4
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3533.5857, current episode: 5
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3539.2534, current episode: 6
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3557.0151, current episode: 7
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3517.7266, current episode: 8
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3507.6538, current episode: 9
[2023-06-29 11:25:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.0481, current episode: 10
[2023-06-29 11:25:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 182000.000000 | iteration_182000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.549862      | 6452.187612         | 6.452188             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3539.225854 | 23.578686  | 3592.682861 | 3507.653809 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3505.7717, current episode: 1
[2023-06-29 11:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3490.7400, current episode: 2
[2023-06-29 11:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3539.8145, current episode: 3
[2023-06-29 11:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3573.6853, current episode: 4
[2023-06-29 11:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3538.5508, current episode: 5
[2023-06-29 11:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3550.0391, current episode: 6
[2023-06-29 11:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3527.8833, current episode: 7
[2023-06-29 11:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3536.2598, current episode: 8
[2023-06-29 11:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3513.5525, current episode: 9
[2023-06-29 11:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3553.0706, current episode: 10
[2023-06-29 11:25:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 182500.000000 | iteration_182500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 2.012505      | 4968.932044         | 4.968932             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3532.936743 | 23.168855  | 3573.685303 | 3490.739990 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3522.7952, current episode: 1
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3511.0007, current episode: 2
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3523.1106, current episode: 3
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3539.7603, current episode: 4
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3533.3809, current episode: 5
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3511.7593, current episode: 6
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3527.9004, current episode: 7
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3517.2781, current episode: 8
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3508.2776, current episode: 9
[2023-06-29 11:27:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3527.2368, current episode: 10
[2023-06-29 11:27:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 183000.000000 | iteration_183000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.840566      | 5433.111218         | 5.433111             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3522.249976 | 9.720533   | 3539.760254 | 3508.277588 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3533.1133, current episode: 1
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3506.6167, current episode: 2
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3525.3362, current episode: 3
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.8599, current episode: 4
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3544.2920, current episode: 5
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3514.2241, current episode: 6
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3515.7163, current episode: 7
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.0073, current episode: 8
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3513.9851, current episode: 9
[2023-06-29 11:27:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3555.7302, current episode: 10
[2023-06-29 11:27:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 183500.000000 | iteration_183500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.580886      | 6325.568322         | 6.325568             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3526.888110 | 15.302121  | 3555.730225 | 3506.616699 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:27:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 718.9818, current episode: 1
[2023-06-29 11:27:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 986.3275, current episode: 2
[2023-06-29 11:27:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 718.9818, current episode: 2
[2023-06-29 11:27:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 986.3275, current episode: 2
[2023-06-29 11:27:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 718.9818, current episode: 2
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 986.3275, current episode: 2
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 718.9818, current episode: 2
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3486.5803, current episode: 3
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3527.7119, current episode: 4
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3478.2539, current episode: 5
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3488.4646, current episode: 6
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.9338, current episode: 7
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3515.7461, current episode: 8
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3517.4517, current episode: 9
[2023-06-29 11:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3476.8896, current episode: 10
[2023-06-29 11:27:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 184000.000000 | iteration_184000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.550950      | 6447.662329         | 6.447662             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2968.134131 | 1059.559629 | 3527.711914 | 718.981812 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3520.5710, current episode: 1
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3512.1531, current episode: 2
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3514.4023, current episode: 3
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3514.7490, current episode: 4
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.7937, current episode: 5
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3522.0457, current episode: 6
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3521.1841, current episode: 7
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3520.8345, current episode: 8
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3486.4048, current episode: 9
[2023-06-29 11:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3542.5339, current episode: 10
[2023-06-29 11:28:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 184500.000000 | iteration_184500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.624549      | 6155.553821         | 6.155554             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3518.967212 | 14.041701  | 3542.533936 | 3486.404785 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:28:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1553.2322, current episode: 1
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1553.2322, current episode: 1
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3525.6111, current episode: 2
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3513.1184, current episode: 3
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3502.2319, current episode: 4
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3506.6509, current episode: 5
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3493.7976, current episode: 6
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3528.5723, current episode: 7
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3505.2068, current episode: 8
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3508.5930, current episode: 9
[2023-06-29 11:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3516.2876, current episode: 10
[2023-06-29 11:28:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 185000.000000 | iteration_185000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528137      | 6543.914483         | 6.543914             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3315.330176 | 587.449898 | 3528.572266 | 1553.232178 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:28:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 1
[2023-06-29 11:28:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 155.0954, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 154.6100, current episode: 2
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3493.8833, current episode: 3
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3512.9995, current episode: 4
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3496.3191, current episode: 5
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3498.2415, current episode: 6
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3515.8794, current episode: 7
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3504.0588, current episode: 8
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3490.1887, current episode: 9
[2023-06-29 11:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3485.3826, current episode: 10
[2023-06-29 11:28:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 185500.000000 | iteration_185500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.917903      | 5214.027159         | 5.214027             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2830.665833 | 1337.936473 | 3515.879395 | 154.610001 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3490.2437, current episode: 1
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3476.8108, current episode: 2
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3500.1357, current episode: 3
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3471.5342, current episode: 4
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3486.6309, current episode: 5
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3481.6772, current episode: 6
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3486.0208, current episode: 7
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3436.1121, current episode: 8
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3456.6499, current episode: 9
[2023-06-29 11:28:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3480.6516, current episode: 10
[2023-06-29 11:28:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 186000.000000 | iteration_186000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524587      | 6559.151666         | 6.559152             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.646680 | 17.420126  | 3500.135742 | 3436.112061 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3467.5718, current episode: 1
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3474.3398, current episode: 2
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3460.9399, current episode: 3
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3447.7795, current episode: 4
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3459.9160, current episode: 5
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3474.7043, current episode: 6
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3467.4453, current episode: 7
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3467.2703, current episode: 8
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3461.2407, current episode: 9
[2023-06-29 11:29:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3466.8157, current episode: 10
[2023-06-29 11:29:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 186500.000000 | iteration_186500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497592      | 6677.384826         | 6.677385             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3464.802344 | 7.450289   | 3474.704346 | 3447.779541 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3505.9280, current episode: 1
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3455.7070, current episode: 2
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3493.1895, current episode: 3
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3495.8037, current episode: 4
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3497.0203, current episode: 5
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3476.4019, current episode: 6
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3502.2810, current episode: 7
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3479.2876, current episode: 8
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3447.9817, current episode: 9
[2023-06-29 11:29:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3474.9075, current episode: 10
[2023-06-29 11:29:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 187000.000000 | iteration_187000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500675      | 6663.668341         | 6.663668             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3482.850806 | 18.589108  | 3505.927979 | 3447.981689 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3521.2388, current episode: 1
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3488.0674, current episode: 2
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3506.0942, current episode: 3
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.0784, current episode: 4
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3513.2954, current episode: 5
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3513.4961, current episode: 6
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3515.5837, current episode: 7
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3497.9089, current episode: 8
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3459.2832, current episode: 9
[2023-06-29 11:29:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3522.2097, current episode: 10
[2023-06-29 11:29:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 187500.000000 | iteration_187500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.701737      | 5876.349329         | 5.876349             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3505.425586 | 18.398860  | 3522.209717 | 3459.283203 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3537.0178, current episode: 1
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3453.3906, current episode: 2
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3560.6646, current episode: 3
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.4160, current episode: 4
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3555.4070, current episode: 5
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3548.6060, current episode: 6
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3530.8198, current episode: 7
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3524.7993, current episode: 8
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3482.3945, current episode: 9
[2023-06-29 11:30:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.0007, current episode: 10
[2023-06-29 11:30:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 188000.000000 | iteration_188000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505410      | 6642.707403         | 6.642707             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3526.351636 | 31.726160  | 3560.664551 | 3453.390625 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:30:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1463.5518, current episode: 1
[2023-06-29 11:30:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1486.9185, current episode: 2
[2023-06-29 11:30:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1557.5286, current episode: 3
[2023-06-29 11:30:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1583.9056, current episode: 4
[2023-06-29 11:30:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1657.1132, current episode: 5
[2023-06-29 11:30:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2134.6941, current episode: 6
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1463.5518, current episode: 6
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1486.9185, current episode: 6
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1557.5286, current episode: 6
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1583.9056, current episode: 6
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1657.1132, current episode: 6
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3648.6162, current episode: 7
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3512.3335, current episode: 8
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3480.8049, current episode: 9
[2023-06-29 11:30:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3528.6621, current episode: 10
[2023-06-29 11:30:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 188500.000000 | iteration_188500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535207      | 6513.778407         | 6.513778             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2405.412842 | 945.872197 | 3648.616211 | 1463.551758 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:30:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1525.4750, current episode: 1
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1543.1853, current episode: 2
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1524.2029, current episode: 3
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1578.0355, current episode: 4
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1588.0553, current episode: 5
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1606.3203, current episode: 6
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1636.7081, current episode: 7
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1692.1958, current episode: 8
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1954.6620, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1525.4750, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1543.1853, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1524.2029, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1578.0355, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1588.0553, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1606.3203, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1636.7081, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1692.1958, current episode: 9
[2023-06-29 11:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3496.0117, current episode: 10
[2023-06-29 11:30:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 189000.000000 | iteration_189000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.576778      | 6342.045104         | 6.342045             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1814.485193 | 573.205573 | 3496.011719 | 1524.202881 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:30:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2083.9341, current episode: 1
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3528.0430, current episode: 2
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3495.2683, current episode: 3
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3509.0156, current episode: 4
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3500.3691, current episode: 5
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.4973, current episode: 6
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3514.7266, current episode: 7
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3603.7361, current episode: 8
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3478.4751, current episode: 9
[2023-06-29 11:30:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3501.2783, current episode: 10
[2023-06-29 11:30:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 189500.000000 | iteration_189500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486123      | 6728.916261         | 6.728916             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3374.734351 | 431.476204 | 3603.736084 | 2083.934082 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:31:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1555.1904, current episode: 1
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2540.8054, current episode: 2
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2651.8552, current episode: 3
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2867.2068, current episode: 4
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1555.1904, current episode: 4
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3528.3374, current episode: 5
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.7275, current episode: 6
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3500.2551, current episode: 7
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3515.4692, current episode: 8
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3508.7739, current episode: 9
[2023-06-29 11:31:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3541.7686, current episode: 10
[2023-06-29 11:31:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 190000.000000 | iteration_190000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510164      | 6621.798699         | 6.621799             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3075.038965 | 634.091413 | 3541.768555 | 1555.190430 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1474.2103, current episode: 1
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1445.7335, current episode: 2
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1532.3584, current episode: 3
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1636.5629, current episode: 4
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1663.4130, current episode: 5
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1698.9465, current episode: 6
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1711.9512, current episode: 7
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1787.4521, current episode: 8
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1907.5732, current episode: 9
[2023-06-29 11:31:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2459.5925, current episode: 10
[2023-06-29 11:31:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 190500.000000 | iteration_190500.pth.tar | 10.000000     | 6760.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 676.000000              | 1.054306      | 6411.798337         | 9.484909             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1731.779370 | 276.922192 | 2459.592529 | 1445.733521 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1617.5463, current episode: 1
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1679.2527, current episode: 2
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2135.7063, current episode: 3
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2863.4954, current episode: 4
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1617.5463, current episode: 4
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1679.2527, current episode: 4
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3539.9448, current episode: 5
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3564.9402, current episode: 6
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.2410, current episode: 7
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3526.8008, current episode: 8
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3500.7227, current episode: 9
[2023-06-29 11:31:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3533.9270, current episode: 10
[2023-06-29 11:31:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 191000.000000 | iteration_191000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540190      | 6492.707236         | 6.492707             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2951.357703 | 782.650171 | 3564.940186 | 1617.546265 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3517.3450, current episode: 1
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3500.3149, current episode: 2
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3527.3352, current episode: 3
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3543.1663, current episode: 4
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3510.7327, current episode: 5
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3502.2891, current episode: 6
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3514.2119, current episode: 7
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3486.5332, current episode: 8
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3484.1421, current episode: 9
[2023-06-29 11:31:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3515.7993, current episode: 10
[2023-06-29 11:31:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 191500.000000 | iteration_191500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.466113      | 6820.758753         | 6.820759             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3510.186963 | 16.966435  | 3543.166260 | 3484.142090 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3545.2605, current episode: 1
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3514.8308, current episode: 2
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.1104, current episode: 3
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3647.9722, current episode: 4
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3549.2031, current episode: 5
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3553.5442, current episode: 6
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3541.0525, current episode: 7
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.8469, current episode: 8
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3512.8403, current episode: 9
[2023-06-29 11:32:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3537.4492, current episode: 10
[2023-06-29 11:32:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 192000.000000 | iteration_192000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498306      | 6674.202302         | 6.674202             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3548.111011 | 35.980282  | 3647.972168 | 3512.840332 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1376.6381, current episode: 1
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1387.9937, current episode: 2
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1523.7650, current episode: 3
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1564.3846, current episode: 4
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1566.7848, current episode: 5
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1624.0862, current episode: 6
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1617.2870, current episode: 7
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1644.6326, current episode: 8
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1971.0907, current episode: 9
[2023-06-29 11:32:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2143.5959, current episode: 10
[2023-06-29 11:32:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 192500.000000 | iteration_192500.pth.tar | 10.000000     | 5780.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 578.000000              | 0.866050      | 6673.982949         | 11.546683            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1642.025854 | 228.349493 | 2143.595947 | 1376.638062 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:32:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1446.8090, current episode: 1
[2023-06-29 11:32:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1459.0249, current episode: 2
[2023-06-29 11:32:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1539.2810, current episode: 3
[2023-06-29 11:32:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1531.1266, current episode: 4
[2023-06-29 11:32:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1612.7180, current episode: 5
[2023-06-29 11:32:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2041.9938, current episode: 6
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2540.6868, current episode: 7
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2662.8486, current episode: 8
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1446.8090, current episode: 8
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1459.0249, current episode: 8
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1539.2810, current episode: 8
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1531.1266, current episode: 8
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3109.5007, current episode: 9
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1612.7180, current episode: 9
[2023-06-29 11:32:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3336.5718, current episode: 10
[2023-06-29 11:32:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 193000.000000 | iteration_193000.pth.tar | 10.000000     | 9070.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 907.000000              | 1.365113      | 6644.139625         | 7.325402             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2128.056116 | 690.483328 | 3336.571777 | 1446.808960 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:32:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1757.2506, current episode: 1
[2023-06-29 11:32:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3080.6631, current episode: 2
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1757.2506, current episode: 2
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3532.5659, current episode: 3
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3524.1250, current episode: 4
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3525.5781, current episode: 5
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3507.8269, current episode: 6
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3604.0432, current episode: 7
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3557.3010, current episode: 8
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3533.0308, current episode: 9
[2023-06-29 11:32:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3536.0554, current episode: 10
[2023-06-29 11:32:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 193500.000000 | iteration_193500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524039      | 6561.510557         | 6.561511             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3315.844006 | 537.842176 | 3604.043213 | 1757.250610 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:33:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2373.0557, current episode: 1
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2570.1853, current episode: 2
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3235.3489, current episode: 3
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3512.8093, current episode: 4
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3531.5691, current episode: 5
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3560.8696, current episode: 6
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3544.4644, current episode: 7
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3606.5627, current episode: 8
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.8311, current episode: 9
[2023-06-29 11:33:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3536.4636, current episode: 10
[2023-06-29 11:33:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 194000.000000 | iteration_194000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506444      | 6638.148773         | 6.638149             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3299.015967 | 426.677397 | 3606.562744 | 2373.055664 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3508.2610, current episode: 1
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3496.8401, current episode: 2
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3484.4028, current episode: 3
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3503.0229, current episode: 4
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3494.3193, current episode: 5
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3509.0642, current episode: 6
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3517.6558, current episode: 7
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3492.6836, current episode: 8
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3490.1145, current episode: 9
[2023-06-29 11:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3502.1270, current episode: 10
[2023-06-29 11:33:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 194500.000000 | iteration_194500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503526      | 6651.033922         | 6.651034             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3499.849121 | 9.551669   | 3517.655762 | 3484.402832 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2712.4160, current episode: 1
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3245.5178, current episode: 2
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3542.1272, current episode: 3
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3512.6531, current episode: 4
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3515.6953, current episode: 5
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3508.7056, current episode: 6
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3519.3765, current episode: 7
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3512.7915, current episode: 8
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3520.1414, current episode: 9
[2023-06-29 11:33:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3540.5991, current episode: 10
[2023-06-29 11:33:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 195000.000000 | iteration_195000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.477379      | 6768.743706         | 6.768744             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3413.002344 | 247.833362 | 3542.127197 | 2712.416016 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1662.6450, current episode: 1
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1662.6450, current episode: 1
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3507.2883, current episode: 2
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3506.5681, current episode: 3
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3499.5051, current episode: 4
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3520.0115, current episode: 5
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3535.7212, current episode: 6
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3570.9353, current episode: 7
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3536.7764, current episode: 8
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3511.0408, current episode: 9
[2023-06-29 11:33:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3522.5005, current episode: 10
[2023-06-29 11:33:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 195500.000000 | iteration_195500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499198      | 6670.234656         | 6.670235             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3337.299219 | 558.564530 | 3570.935303 | 1662.645020 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1343.4960, current episode: 1
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1393.7703, current episode: 2
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1376.0032, current episode: 3
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1379.2048, current episode: 4
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1546.0542, current episode: 5
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1567.6930, current episode: 6
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1633.6293, current episode: 7
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1662.2749, current episode: 8
[2023-06-29 11:34:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1999.3396, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1343.4960, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1393.7703, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1376.0032, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1379.2048, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1546.0542, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1567.6930, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1633.6293, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1662.2749, current episode: 9
[2023-06-29 11:34:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3544.7632, current episode: 10
[2023-06-29 11:34:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 196000.000000 | iteration_196000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540505      | 6491.375749         | 6.491376             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1744.622839 | 628.381364 | 3544.763184 | 1343.495972 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:34:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1937.6805, current episode: 1
[2023-06-29 11:34:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1960.9014, current episode: 2
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3472.5947, current episode: 3
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3538.7988, current episode: 4
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3491.5215, current episode: 5
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3509.0466, current episode: 6
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3513.4922, current episode: 7
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3533.2842, current episode: 8
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.7212, current episode: 9
[2023-06-29 11:34:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3524.6216, current episode: 10
[2023-06-29 11:34:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 196500.000000 | iteration_196500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499715      | 6667.935354         | 6.667935             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3198.666272 | 624.978003 | 3538.798828 | 1937.680542 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 471.2136, current episode: 1
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 862.7734, current episode: 2
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 868.9600, current episode: 3
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 878.3051, current episode: 4
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 944.4494, current episode: 5
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1026.4429, current episode: 6
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 471.2136, current episode: 6
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1632.7194, current episode: 7
[2023-06-29 11:34:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 471.2136, current episode: 7
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 862.7734, current episode: 7
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 868.9600, current episode: 7
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 878.3051, current episode: 7
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 944.4494, current episode: 7
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1026.4429, current episode: 7
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2281.6047, current episode: 8
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2365.4626, current episode: 9
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 471.2136, current episode: 9
[2023-06-29 11:34:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2480.7810, current episode: 10
[2023-06-29 11:34:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 197000.000000 | iteration_197000.pth.tar | 10.000000     | 6730.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 673.000000              | 1.049848      | 6410.452407         | 9.525189             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1381.271204 | 705.732264 | 2480.781006 | 471.213562 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:34:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1536.7816, current episode: 1
[2023-06-29 11:34:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1552.3099, current episode: 2
[2023-06-29 11:34:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1562.0624, current episode: 3
[2023-06-29 11:34:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1626.5992, current episode: 4
[2023-06-29 11:34:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1835.7355, current episode: 5
[2023-06-29 11:34:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1872.4380, current episode: 6
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1536.7816, current episode: 6
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1552.3099, current episode: 6
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1562.0624, current episode: 6
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1626.5992, current episode: 6
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3565.3879, current episode: 7
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1835.7355, current episode: 7
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3535.0918, current episode: 8
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3521.1621, current episode: 9
[2023-06-29 11:34:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3567.0984, current episode: 10
[2023-06-29 11:34:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 197500.000000 | iteration_197500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.552057      | 6443.063321         | 6.443063             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2417.466687 | 928.620668 | 3567.098389 | 1536.781616 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1584.0809, current episode: 1
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1766.3409, current episode: 2
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2172.8259, current episode: 3
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2277.5137, current episode: 4
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2764.3716, current episode: 5
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1584.0809, current episode: 5
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1766.3409, current episode: 5
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3586.4661, current episode: 6
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3535.8586, current episode: 7
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3520.7827, current episode: 8
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3557.1516, current episode: 9
[2023-06-29 11:35:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.0198, current episode: 10
[2023-06-29 11:35:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 198000.000000 | iteration_198000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.526865      | 6549.366490         | 6.549366             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2830.041187 | 774.504443 | 3586.466064 | 1584.080933 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:35:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1454.3743, current episode: 1
[2023-06-29 11:35:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1542.5320, current episode: 2
[2023-06-29 11:35:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1557.4758, current episode: 3
[2023-06-29 11:35:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1549.7812, current episode: 4
[2023-06-29 11:35:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1667.8306, current episode: 5
[2023-06-29 11:35:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1871.7345, current episode: 6
[2023-06-29 11:35:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1930.9755, current episode: 7
[2023-06-29 11:35:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2009.9983, current episode: 8
[2023-06-29 11:35:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2548.0730, current episode: 9
[2023-06-29 11:35:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2962.0874, current episode: 10
[2023-06-29 11:35:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 198500.000000 | iteration_198500.pth.tar | 10.000000     | 8040.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 804.000000              | 1.211923      | 6634.086988         | 8.251352             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1909.486255 | 467.036478 | 2962.087402 | 1454.374268 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:35:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2020.7930, current episode: 1
[2023-06-29 11:35:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2325.5381, current episode: 2
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3036.2683, current episode: 3
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3230.4451, current episode: 4
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3674.4929, current episode: 5
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3542.2227, current episode: 6
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3566.4973, current episode: 7
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3540.4041, current episode: 8
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3605.3333, current episode: 9
[2023-06-29 11:35:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3570.3093, current episode: 10
[2023-06-29 11:35:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 199000.000000 | iteration_199000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491248      | 6705.794168         | 6.705794             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3211.230396 | 554.577833 | 3674.492920 | 2020.792969 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:35:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 480.6677, current episode: 1
[2023-06-29 11:35:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 542.4999, current episode: 2
[2023-06-29 11:35:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 799.9689, current episode: 3
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 828.9620, current episode: 4
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 956.9654, current episode: 5
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 971.5884, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 480.6677, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 542.4999, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 799.9689, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 828.9620, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 480.6677, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 956.9654, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 542.4999, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 971.5884, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 480.6677, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 799.9689, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 542.4999, current episode: 6
[2023-06-29 11:35:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 828.9620, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 956.9654, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 971.5884, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 480.6677, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 542.4999, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 799.9689, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 828.9620, current episode: 6
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3484.2207, current episode: 7
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3461.4309, current episode: 8
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3495.1528, current episode: 9
[2023-06-29 11:35:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3484.6865, current episode: 10
[2023-06-29 11:35:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 199500.000000 | iteration_199500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.763706      | 5669.878652         | 5.669879             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1850.614331 | 1339.587248 | 3495.152832 | 480.667725 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 374.7583, current episode: 1
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 446.1462, current episode: 2
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 490.9179, current episode: 3
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 504.8163, current episode: 4
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 519.5084, current episode: 5
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 522.6719, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 374.7583, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 446.1462, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 490.9179, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 504.8163, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 519.5084, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 522.6719, current episode: 6
[2023-06-29 11:36:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 374.7583, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 446.1462, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 490.9179, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 504.8163, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 519.5084, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 522.6719, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 374.7583, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 446.1462, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 490.9179, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 504.8163, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 519.5084, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 522.6719, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 374.7583, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 446.1462, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 490.9179, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 374.7583, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 504.8163, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 519.5084, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 522.6719, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 446.1462, current episode: 6
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3441.9780, current episode: 7
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3436.1343, current episode: 8
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3427.0684, current episode: 9
[2023-06-29 11:36:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3431.0339, current episode: 10
[2023-06-29 11:36:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 200000.000000 | iteration_200000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.591877      | 6281.890641         | 6.281891             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1659.503366 | 1449.479691 | 3441.978027 | 374.758331 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2189.0969, current episode: 1
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2509.5161, current episode: 2
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2594.9233, current episode: 3
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2792.8274, current episode: 4
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2841.4128, current episode: 5
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2926.5422, current episode: 6
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3132.5559, current episode: 7
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3300.7156, current episode: 8
[2023-06-29 11:36:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3317.7827, current episode: 9
[2023-06-29 11:36:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3586.0833, current episode: 10
[2023-06-29 11:36:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 200500.000000 | iteration_200500.pth.tar | 10.000000     | 9880.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 988.000000              | 1.463944      | 6748.892736         | 6.830863             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2919.145630 | 402.839649 | 3586.083252 | 2189.096924 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2231.4688, current episode: 1
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2638.3872, current episode: 2
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2627.6816, current episode: 3
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2896.7866, current episode: 4
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2888.5588, current episode: 5
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3517.5505, current episode: 6
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3532.4326, current episode: 7
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.2830, current episode: 8
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.2878, current episode: 9
[2023-06-29 11:36:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.1379, current episode: 10
[2023-06-29 11:36:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 201000.000000 | iteration_201000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499840      | 6667.378548         | 6.667379             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3089.757495 | 465.859307 | 3532.432617 | 2231.468750 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2372.5039, current episode: 1
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2361.6233, current episode: 2
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2359.8728, current episode: 3
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2558.0027, current episode: 4
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3113.9106, current episode: 5
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3406.4019, current episode: 6
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.2141, current episode: 7
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3619.4233, current episode: 8
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3555.0452, current episode: 9
[2023-06-29 11:36:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3559.8772, current episode: 10
[2023-06-29 11:36:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 201500.000000 | iteration_201500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508516      | 6629.032021         | 6.629032             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3047.087500 | 537.208233 | 3619.423340 | 2359.872803 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3498.6763, current episode: 1
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3482.1953, current episode: 2
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3518.9448, current episode: 3
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3475.5535, current episode: 4
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3486.0945, current episode: 5
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3474.8679, current episode: 6
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3496.3945, current episode: 7
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3451.2373, current episode: 8
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3442.5947, current episode: 9
[2023-06-29 11:37:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3488.9321, current episode: 10
[2023-06-29 11:37:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 202000.000000 | iteration_202000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520317      | 6577.577110         | 6.577577             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3481.549097 | 21.224015  | 3518.944824 | 3442.594727 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2399.2896, current episode: 1
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3470.8218, current episode: 2
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3462.9021, current episode: 3
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3445.0312, current episode: 4
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3478.2883, current episode: 5
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3485.9958, current episode: 6
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3490.2537, current episode: 7
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3457.1055, current episode: 8
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3470.4124, current episode: 9
[2023-06-29 11:37:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3466.8853, current episode: 10
[2023-06-29 11:37:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 202500.000000 | iteration_202500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503157      | 6652.666183         | 6.652666             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3362.698560 | 321.382993 | 3490.253662 | 2399.289551 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1347.7007, current episode: 1
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1359.8295, current episode: 2
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1366.2898, current episode: 3
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1369.7594, current episode: 4
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1398.8497, current episode: 5
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1411.7026, current episode: 6
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1570.5310, current episode: 7
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1630.9778, current episode: 8
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1658.6417, current episode: 9
[2023-06-29 11:37:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2359.3257, current episode: 10
[2023-06-29 11:37:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 203000.000000 | iteration_203000.pth.tar | 10.000000     | 6750.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 675.000000              | 1.086270      | 6213.926000         | 9.205816             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1547.360791 | 293.090238 | 2359.325684 | 1347.700684 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:37:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1324.0698, current episode: 1
[2023-06-29 11:37:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1306.4709, current episode: 2
[2023-06-29 11:37:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1351.8737, current episode: 3
[2023-06-29 11:37:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1328.5798, current episode: 4
[2023-06-29 11:37:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1347.8459, current episode: 5
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1779.1459, current episode: 6
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2288.5251, current episode: 7
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2303.7490, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1324.0698, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1306.4709, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1351.8737, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1328.5798, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1347.8459, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1779.1459, current episode: 8
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3475.6704, current episode: 9
[2023-06-29 11:37:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3510.6204, current episode: 10
[2023-06-29 11:37:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 203500.000000 | iteration_203500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517424      | 6590.116627         | 6.590117             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2001.655103 | 831.737835 | 3510.620361 | 1306.470947 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1383.5752, current episode: 1
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1309.6041, current episode: 2
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1325.1732, current episode: 3
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1365.4347, current episode: 4
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1366.7692, current episode: 5
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1437.4115, current episode: 6
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1533.5543, current episode: 7
[2023-06-29 11:38:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2118.4326, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1383.5752, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1309.6041, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1325.1732, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1365.4347, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1366.7692, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1437.4115, current episode: 8
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3020.3474, current episode: 9
[2023-06-29 11:38:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2963.3015, current episode: 10
[2023-06-29 11:38:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 204000.000000 | iteration_204000.pth.tar | 10.000000     | 8460.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 846.000000              | 1.342403      | 6302.129250         | 7.449325             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1782.360376 | 644.915799 | 3020.347412 | 1309.604126 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:38:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1558.5421, current episode: 1
[2023-06-29 11:38:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1603.9684, current episode: 2
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1828.3878, current episode: 3
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1966.2554, current episode: 4
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2310.2068, current episode: 5
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2711.0847, current episode: 6
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1558.5421, current episode: 6
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3215.0354, current episode: 7
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1603.9684, current episode: 7
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3522.5129, current episode: 8
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3480.9734, current episode: 9
[2023-06-29 11:38:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3531.4353, current episode: 10
[2023-06-29 11:38:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 204500.000000 | iteration_204500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507728      | 6632.495927         | 6.632496             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2572.840222 | 776.895039 | 3531.435303 | 1558.542114 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1392.1857, current episode: 1
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1441.2599, current episode: 2
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1440.8544, current episode: 3
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1466.9014, current episode: 4
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1486.0638, current episode: 5
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1408.2029, current episode: 6
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1459.0747, current episode: 7
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1495.0216, current episode: 8
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1495.7228, current episode: 9
[2023-06-29 11:38:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1620.4872, current episode: 10
[2023-06-29 11:38:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 205000.000000 | iteration_205000.pth.tar | 10.000000     | 4460.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 446.000000              | 0.688444      | 6478.381057         | 14.525518            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1470.577429 | 59.889253  | 1620.487183 | 1392.185669 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1336.3552, current episode: 1
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1346.4360, current episode: 2
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1342.0760, current episode: 3
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1334.6504, current episode: 4
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1344.7063, current episode: 5
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1377.2737, current episode: 6
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1390.9648, current episode: 7
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2368.8782, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1336.3552, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1346.4360, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1342.0760, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1334.6504, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1344.7063, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1377.2737, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1390.9648, current episode: 8
[2023-06-29 11:38:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2934.8286, current episode: 9
[2023-06-29 11:39:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3299.2903, current episode: 10
[2023-06-29 11:39:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 205500.000000 | iteration_205500.pth.tar | 10.000000     | 9200.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 920.000000              | 1.425936      | 6451.903415         | 7.012938             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1807.545959 | 725.189031 | 3299.290283 | 1334.650391 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:39:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1420.4994, current episode: 1
[2023-06-29 11:39:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1633.1196, current episode: 2
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2356.5037, current episode: 3
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2562.9998, current episode: 4
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2730.7124, current episode: 5
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1420.4994, current episode: 5
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3050.1399, current episode: 6
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3052.1990, current episode: 7
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1633.1196, current episode: 7
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3417.9795, current episode: 8
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3521.9080, current episode: 9
[2023-06-29 11:39:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3542.5176, current episode: 10
[2023-06-29 11:39:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 206000.000000 | iteration_206000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.559214      | 6413.487866         | 6.413488             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2728.857874 | 710.790757 | 3542.517578 | 1420.499390 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1751.1636, current episode: 1
[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2080.2388, current episode: 2
[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2120.4231, current episode: 3
[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2407.6819, current episode: 4
[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2689.0903, current episode: 5
[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2783.3376, current episode: 6
[2023-06-29 11:39:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3101.2620, current episode: 7
[2023-06-29 11:39:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1751.1636, current episode: 7
[2023-06-29 11:39:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3563.1228, current episode: 8
[2023-06-29 11:39:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3462.9812, current episode: 9
[2023-06-29 11:39:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3555.4675, current episode: 10
[2023-06-29 11:39:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 206500.000000 | iteration_206500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479012      | 6761.270531         | 6.761271             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2751.476880 | 625.002116 | 3563.122803 | 1751.163574 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:39:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1692.3940, current episode: 1
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1956.7330, current episode: 2
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1989.2073, current episode: 3
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2074.4224, current episode: 4
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2080.3760, current episode: 5
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2768.9897, current episode: 6
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3258.7288, current episode: 7
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1692.3940, current episode: 7
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3564.4424, current episode: 8
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3529.8269, current episode: 9
[2023-06-29 11:39:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3545.8245, current episode: 10
[2023-06-29 11:39:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 207000.000000 | iteration_207000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478140      | 6765.258975         | 6.765259             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2646.094495 | 727.144750 | 3564.442383 | 1692.394043 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:40:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1821.7031, current episode: 1
[2023-06-29 11:40:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1766.9675, current episode: 2
[2023-06-29 11:40:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1782.8683, current episode: 3
[2023-06-29 11:40:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1978.6447, current episode: 4
[2023-06-29 11:40:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1996.6560, current episode: 5
[2023-06-29 11:40:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2665.0427, current episode: 6
[2023-06-29 11:40:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2967.9324, current episode: 7
[2023-06-29 11:40:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3330.6636, current episode: 8
[2023-06-29 11:40:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1821.7031, current episode: 8
[2023-06-29 11:40:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1766.9675, current episode: 8
[2023-06-29 11:40:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3683.8135, current episode: 9
[2023-06-29 11:40:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3562.5688, current episode: 10
[2023-06-29 11:40:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 207500.000000 | iteration_207500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504775      | 6645.513836         | 6.645514             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2555.686060 | 739.765303 | 3683.813477 | 1766.967529 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:40:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1281.7788, current episode: 1
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1381.1549, current episode: 2
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1547.1293, current episode: 3
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1617.1385, current episode: 4
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1641.7191, current episode: 5
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1717.0054, current episode: 6
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1976.6451, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1281.7788, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1381.1549, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1547.1293, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1617.1385, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1641.7191, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1717.0054, current episode: 7
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3562.2000, current episode: 8
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.8623, current episode: 9
[2023-06-29 11:40:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.8901, current episode: 10
[2023-06-29 11:40:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 208000.000000 | iteration_208000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494747      | 6690.097251         | 6.690097             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2191.252356 | 928.180350 | 3601.890137 | 1281.778809 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1154.6694, current episode: 1
[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1227.6681, current episode: 2
[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1479.9467, current episode: 3
[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1524.2611, current episode: 4
[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1571.3239, current episode: 5
[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1824.4734, current episode: 6
[2023-06-29 11:40:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2290.0679, current episode: 7
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1154.6694, current episode: 7
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2397.6677, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1227.6681, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1479.9467, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1524.2611, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1571.3239, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1154.6694, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1824.4734, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1227.6681, current episode: 8
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3642.2036, current episode: 9
[2023-06-29 11:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.9932, current episode: 10
[2023-06-29 11:40:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 208500.000000 | iteration_208500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517790      | 6588.524980         | 6.588525             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2067.527490 | 857.840070 | 3642.203613 | 1154.669434 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1434.8386, current episode: 1
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1658.5646, current episode: 2
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1769.6921, current episode: 3
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1839.7230, current episode: 4
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1845.1952, current episode: 5
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1969.7686, current episode: 6
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2300.6250, current episode: 7
[2023-06-29 11:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1434.8386, current episode: 7
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1658.5646, current episode: 7
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1769.6921, current episode: 7
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1839.7230, current episode: 7
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1845.1952, current episode: 7
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3554.3677, current episode: 8
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3565.3794, current episode: 9
[2023-06-29 11:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3603.6680, current episode: 10
[2023-06-29 11:40:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 209000.000000 | iteration_209000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.526961      | 6548.956004         | 6.548956             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2354.182214 | 825.453928 | 3603.667969 | 1434.838623 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:41:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1456.6743, current episode: 1
[2023-06-29 11:41:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1440.7764, current episode: 2
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1478.6150, current episode: 3
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1523.2522, current episode: 4
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1529.0381, current episode: 5
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1543.3612, current episode: 6
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1649.8369, current episode: 7
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1673.6792, current episode: 8
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2084.8650, current episode: 9
[2023-06-29 11:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2322.9375, current episode: 10
[2023-06-29 11:41:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 209500.000000 | iteration_209500.pth.tar | 10.000000     | 6340.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 634.000000              | 0.978753      | 6477.627847         | 10.217079            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1670.303577 | 281.243953 | 2322.937500 | 1440.776367 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1507.9559, current episode: 1
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1526.4838, current episode: 2
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1539.1954, current episode: 3
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1618.0392, current episode: 4
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1615.0463, current episode: 5
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1780.3636, current episode: 6
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1796.7584, current episode: 7
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1912.2050, current episode: 8
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2595.0898, current episode: 9
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1507.9559, current episode: 9
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1526.4838, current episode: 9
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1539.1954, current episode: 9
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1618.0392, current episode: 9
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1615.0463, current episode: 9
[2023-06-29 11:41:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3345.7246, current episode: 10
[2023-06-29 11:41:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 210000.000000 | iteration_210000.pth.tar | 10.000000     | 9019.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 901.900000              | 1.366004      | 6602.471908         | 7.320625             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1923.686206 | 563.637580 | 3345.724609 | 1507.955933 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1640.9375, current episode: 1
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1672.1451, current episode: 2
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2681.3132, current episode: 3
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3115.6143, current episode: 4
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1640.9375, current episode: 4
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3400.0837, current episode: 5
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1672.1451, current episode: 5
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3562.9741, current episode: 6
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3555.9248, current episode: 7
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3591.8735, current episode: 8
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3591.3906, current episode: 9
[2023-06-29 11:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3576.1799, current episode: 10
[2023-06-29 11:41:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 210500.000000 | iteration_210500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.538577      | 6499.512100         | 6.499512             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3038.843689 | 743.517902 | 3591.873535 | 1640.937500 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:41:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1572.2058, current episode: 1
[2023-06-29 11:41:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1663.3605, current episode: 2
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3066.5466, current episode: 3
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1572.2058, current episode: 3
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1663.3605, current episode: 3
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3597.1550, current episode: 4
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3578.5632, current episode: 5
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3612.1990, current episode: 6
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3575.3774, current episode: 7
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3568.6091, current episode: 8
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.8860, current episode: 9
[2023-06-29 11:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3558.3406, current episode: 10
[2023-06-29 11:41:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 211000.000000 | iteration_211000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511707      | 6615.037291         | 6.615037             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3136.124329 | 774.609562 | 3612.198975 | 1572.205811 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3527.0513, current episode: 1
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3526.2729, current episode: 2
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3547.8000, current episode: 3
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3550.9653, current episode: 4
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3545.7317, current episode: 5
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3539.2783, current episode: 6
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3551.5908, current episode: 7
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3534.5657, current episode: 8
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.4998, current episode: 9
[2023-06-29 11:42:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3547.0925, current episode: 10
[2023-06-29 11:42:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 211500.000000 | iteration_211500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496354      | 6682.911668         | 6.682912             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3538.084839 | 12.721332  | 3551.590820 | 3510.499756 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3508.9116, current episode: 1
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3500.1963, current episode: 2
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3503.5771, current episode: 3
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3518.0190, current episode: 4
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3512.4028, current episode: 5
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3515.0693, current episode: 6
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3514.8889, current episode: 7
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.6587, current episode: 8
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.9983, current episode: 9
[2023-06-29 11:42:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3509.8865, current episode: 10
[2023-06-29 11:42:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 212000.000000 | iteration_212000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494436      | 6691.488561         | 6.691489             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3509.560864 | 5.717405   | 3518.019043 | 3500.196289 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3525.5295, current episode: 1
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3511.3235, current episode: 2
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3512.3591, current episode: 3
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3525.5400, current episode: 4
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3530.0061, current episode: 5
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3528.7549, current episode: 6
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3512.5029, current episode: 7
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3519.8662, current episode: 8
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.0020, current episode: 9
[2023-06-29 11:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3518.4084, current episode: 10
[2023-06-29 11:42:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 212500.000000 | iteration_212500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540776      | 6490.234542         | 6.490235             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3520.029272 | 6.681583   | 3530.006104 | 3511.323486 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1667.6625, current episode: 1
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1703.8905, current episode: 2
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2117.4194, current episode: 3
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2343.6960, current episode: 4
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1667.6625, current episode: 4
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1703.8905, current episode: 4
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3561.0967, current episode: 5
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.4314, current episode: 6
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3540.3123, current episode: 7
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3544.6841, current episode: 8
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3546.5129, current episode: 9
[2023-06-29 11:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3570.1228, current episode: 10
[2023-06-29 11:42:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 213000.000000 | iteration_213000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507160      | 6634.997620         | 6.634998             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2914.082861 | 800.971178 | 3570.122803 | 1667.662476 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3354.4185, current episode: 1
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3563.8879, current episode: 2
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3519.9836, current episode: 3
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3542.6738, current episode: 4
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3544.2107, current episode: 5
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3509.4697, current episode: 6
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3535.1033, current episode: 7
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3511.2205, current episode: 8
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3551.9106, current episode: 9
[2023-06-29 11:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3506.9409, current episode: 10
[2023-06-29 11:43:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 213500.000000 | iteration_213500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487193      | 6724.077969         | 6.724078             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3513.981958 | 56.290670  | 3563.887939 | 3354.418457 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:43:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1667.8390, current episode: 1
[2023-06-29 11:43:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1756.3136, current episode: 2
[2023-06-29 11:43:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1691.8124, current episode: 3
[2023-06-29 11:43:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1909.6107, current episode: 4
[2023-06-29 11:43:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1928.4095, current episode: 5
[2023-06-29 11:43:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1979.0944, current episode: 6
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2457.4771, current episode: 7
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2881.6101, current episode: 8
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2921.4626, current episode: 9
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1667.8390, current episode: 9
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1756.3136, current episode: 9
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1691.8124, current episode: 9
[2023-06-29 11:43:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3690.5640, current episode: 10
[2023-06-29 11:43:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 214000.000000 | iteration_214000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494673      | 6690.424534         | 6.690425             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2288.419336 | 643.443121 | 3690.563965 | 1667.838989 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2180.9753, current episode: 1
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2970.1069, current episode: 2
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3157.3220, current episode: 3
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3257.0784, current episode: 4
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3581.9680, current episode: 5
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3498.0364, current episode: 6
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3508.9272, current episode: 7
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3493.7485, current episode: 8
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3655.2175, current episode: 9
[2023-06-29 11:43:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3523.9983, current episode: 10
[2023-06-29 11:43:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 214500.000000 | iteration_214500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.477692      | 6767.308908         | 6.767309             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3282.737866 | 419.110160 | 3655.217529 | 2180.975342 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:43:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2105.8130, current episode: 1
[2023-06-29 11:43:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3020.4805, current episode: 2
[2023-06-29 11:43:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3023.1155, current episode: 3
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3462.4016, current episode: 4
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3526.0435, current episode: 5
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3519.8408, current episode: 6
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3505.4307, current episode: 7
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3510.5325, current episode: 8
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3522.7905, current episode: 9
[2023-06-29 11:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3511.1323, current episode: 10
[2023-06-29 11:43:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 215000.000000 | iteration_215000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540019      | 6493.425169         | 6.493425             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3270.758081 | 433.458879 | 3526.043457 | 2105.812988 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3545.4529, current episode: 1
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3516.6880, current episode: 2
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3522.0195, current episode: 3
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3526.2290, current episode: 4
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3521.0479, current episode: 5
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3514.4705, current episode: 6
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3515.4084, current episode: 7
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3497.3613, current episode: 8
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3509.0854, current episode: 9
[2023-06-29 11:44:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3522.7854, current episode: 10
[2023-06-29 11:44:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 215500.000000 | iteration_215500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512077      | 6613.420772         | 6.613421             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3519.054834 | 11.768244  | 3545.452881 | 3497.361328 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1893.8303, current episode: 1
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2218.0474, current episode: 2
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2451.4473, current episode: 3
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2477.9268, current episode: 4
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2688.2051, current episode: 5
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3502.3108, current episode: 6
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3535.0068, current episode: 7
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3590.5754, current episode: 8
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3542.4546, current episode: 9
[2023-06-29 11:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3604.0410, current episode: 10
[2023-06-29 11:44:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 216000.000000 | iteration_216000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508712      | 6628.170095         | 6.628170             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2950.384546 | 634.632281 | 3604.041016 | 1893.830322 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3272.3499, current episode: 1
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3524.5955, current episode: 2
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3514.8765, current episode: 3
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3523.1709, current episode: 4
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3511.7788, current episode: 5
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3502.3723, current episode: 6
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3520.3872, current episode: 7
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3513.6594, current episode: 8
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.8311, current episode: 9
[2023-06-29 11:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3516.9421, current episode: 10
[2023-06-29 11:44:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 216500.000000 | iteration_216500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483845      | 6739.247950         | 6.739248             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3491.096362 | 73.175072  | 3524.595459 | 3272.349854 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1529.6448, current episode: 1
[2023-06-29 11:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1793.5676, current episode: 2
[2023-06-29 11:44:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1529.6448, current episode: 2
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1793.5676, current episode: 2
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3518.3955, current episode: 3
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3523.1838, current episode: 4
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3542.4944, current episode: 5
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3531.8711, current episode: 6
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3505.7446, current episode: 7
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3526.1938, current episode: 8
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3538.3633, current episode: 9
[2023-06-29 11:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3508.5188, current episode: 10
[2023-06-29 11:44:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 217000.000000 | iteration_217000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496399      | 6682.709956         | 6.682710             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3151.797778 | 747.510812 | 3542.494385 | 1529.644775 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.0872, current episode: 1
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3492.0510, current episode: 2
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3511.7690, current episode: 3
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3494.9043, current episode: 4
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3501.8115, current episode: 5
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3498.5994, current episode: 6
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3483.7214, current episode: 7
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3478.0439, current episode: 8
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3478.4250, current episode: 9
[2023-06-29 11:45:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3504.2708, current episode: 10
[2023-06-29 11:45:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 217500.000000 | iteration_217500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515194      | 6599.816136         | 6.599816             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3495.968359 | 12.489753  | 3516.087158 | 3478.043945 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:45:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2181.2239, current episode: 1
[2023-06-29 11:45:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2425.0625, current episode: 2
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3535.2827, current episode: 3
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3542.7456, current episode: 4
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3525.6755, current episode: 5
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3518.8032, current episode: 6
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.8359, current episode: 7
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3479.0044, current episode: 8
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3528.8208, current episode: 9
[2023-06-29 11:45:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3555.3013, current episode: 10
[2023-06-29 11:45:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 218000.000000 | iteration_218000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499378      | 6669.430942         | 6.669431             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3280.175586 | 491.929329 | 3555.301270 | 2181.223877 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3499.7454, current episode: 1
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3440.2192, current episode: 2
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3504.8428, current episode: 3
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3482.9011, current episode: 4
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3484.3245, current episode: 5
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3473.6890, current episode: 6
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.5732, current episode: 7
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3480.9724, current episode: 8
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3443.2329, current episode: 9
[2023-06-29 11:45:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3471.8467, current episode: 10
[2023-06-29 11:45:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 218500.000000 | iteration_218500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500158      | 6665.965243         | 6.665965             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.634717 | 19.958464  | 3504.842773 | 3440.219238 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2563.5847, current episode: 1
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2587.0071, current episode: 2
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2893.2385, current episode: 3
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3008.2598, current episode: 4
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3476.9146, current episode: 5
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3467.8213, current episode: 6
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3474.4590, current episode: 7
[2023-06-29 11:45:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3484.0469, current episode: 8
[2023-06-29 11:45:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3589.2515, current episode: 9
[2023-06-29 11:45:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3476.8342, current episode: 10
[2023-06-29 11:45:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 219000.000000 | iteration_219000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511547      | 6615.739257         | 6.615739             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3202.141748 | 380.023677 | 3589.251465 | 2563.584717 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:46:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1817.9861, current episode: 1
[2023-06-29 11:46:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1850.2281, current episode: 2
[2023-06-29 11:46:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1956.7606, current episode: 3
[2023-06-29 11:46:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2009.9733, current episode: 4
[2023-06-29 11:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3477.3281, current episode: 5
[2023-06-29 11:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3401.7153, current episode: 6
[2023-06-29 11:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3495.5342, current episode: 7
[2023-06-29 11:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3461.3105, current episode: 8
[2023-06-29 11:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3386.3901, current episode: 9
[2023-06-29 11:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3437.2710, current episode: 10
[2023-06-29 11:46:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 219500.000000 | iteration_219500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516882      | 6592.469729         | 6.592470             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2829.449744 | 753.978899 | 3495.534180 | 1817.986084 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1346.3877, current episode: 1
[2023-06-29 11:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1407.0371, current episode: 2
[2023-06-29 11:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1524.7085, current episode: 3
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2238.6909, current episode: 4
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2315.6138, current episode: 5
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2443.7588, current episode: 6
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2531.1665, current episode: 7
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1346.3877, current episode: 7
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1407.0371, current episode: 7
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1524.7085, current episode: 7
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3018.6519, current episode: 8
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3357.5237, current episode: 9
[2023-06-29 11:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3377.6611, current episode: 10
[2023-06-29 11:46:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 220000.000000 | iteration_220000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524722      | 6558.574023         | 6.558574             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2356.119995 | 717.678132 | 3377.661133 | 1346.387695 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2286.6506, current episode: 1
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2320.1328, current episode: 2
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2304.0071, current episode: 3
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2303.9124, current episode: 4
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2844.6926, current episode: 5
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2907.8044, current episode: 6
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2914.8765, current episode: 7
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3367.8960, current episode: 8
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3344.6780, current episode: 9
[2023-06-29 11:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3479.2205, current episode: 10
[2023-06-29 11:46:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 220500.000000 | iteration_220500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491532      | 6704.514327         | 6.704514             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2807.387085 | 457.460660 | 3479.220459 | 2286.650635 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:46:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 1
[2023-06-29 11:46:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 2
[2023-06-29 11:46:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 420.6260, current episode: 3
[2023-06-29 11:46:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 470.9832, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 420.6260, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 470.9832, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 420.6260, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 470.9832, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 420.6260, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 470.9832, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 420.6260, current episode: 4
[2023-06-29 11:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 470.9832, current episode: 4
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 4
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 420.6260, current episode: 4
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 281.5400, current episode: 4
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3407.7605, current episode: 5
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3407.0288, current episode: 6
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3360.2061, current episode: 7
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 280.6995, current episode: 7
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3366.3833, current episode: 8
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3394.6497, current episode: 9
[2023-06-29 11:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3388.3870, current episode: 10
[2023-06-29 11:47:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 221000.000000 | iteration_221000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.584028      | 6313.020389         | 6.313020             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2177.826392 | 1482.448687 | 3407.760498 | 280.699493 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:47:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1608.8474, current episode: 1
[2023-06-29 11:47:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1592.5165, current episode: 2
[2023-06-29 11:47:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1650.4783, current episode: 3
[2023-06-29 11:47:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1714.7506, current episode: 4
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2597.0938, current episode: 5
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2623.0410, current episode: 6
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2741.5054, current episode: 7
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1608.8474, current episode: 7
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1592.5165, current episode: 7
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1650.4783, current episode: 7
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1714.7506, current episode: 7
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3487.6768, current episode: 8
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.5054, current episode: 9
[2023-06-29 11:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3515.5737, current episode: 10
[2023-06-29 11:47:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 221500.000000 | iteration_221500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502124      | 6657.239911         | 6.657240             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2504.198877 | 778.891158 | 3515.573730 | 1592.516479 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3525.9558, current episode: 1
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3451.5442, current episode: 2
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3481.7693, current episode: 3
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3469.1738, current episode: 4
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3486.6016, current episode: 5
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3500.5083, current episode: 6
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3519.9563, current episode: 7
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3482.3198, current episode: 8
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3495.8669, current episode: 9
[2023-06-29 11:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3493.9324, current episode: 10
[2023-06-29 11:47:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 222000.000000 | iteration_222000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505770      | 6641.120942         | 6.641121             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3490.762842 | 20.965562  | 3525.955811 | 3451.544189 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3462.4233, current episode: 1
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3477.0681, current episode: 2
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3470.4380, current episode: 3
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3494.1582, current episode: 4
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3457.7893, current episode: 5
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3486.9209, current episode: 6
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3482.4548, current episode: 7
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3472.9741, current episode: 8
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3507.4856, current episode: 9
[2023-06-29 11:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3456.5203, current episode: 10
[2023-06-29 11:47:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 222500.000000 | iteration_222500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499767      | 6667.703612         | 6.667704             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.823267 | 15.530178  | 3507.485596 | 3456.520264 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:48:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1497.0686, current episode: 1
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1497.0686, current episode: 1
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3420.2415, current episode: 2
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3477.9722, current episode: 3
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3504.3977, current episode: 4
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3513.0662, current episode: 5
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3378.6304, current episode: 6
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3495.8469, current episode: 7
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3334.6873, current episode: 8
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3469.1614, current episode: 9
[2023-06-29 11:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3479.9795, current episode: 10
[2023-06-29 11:48:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 223000.000000 | iteration_223000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.513461      | 6607.373981         | 6.607374             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3257.105151 | 589.255445 | 3513.066162 | 1497.068604 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:48:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1981.8660, current episode: 1
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3395.7407, current episode: 2
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3476.0867, current episode: 3
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3492.2083, current episode: 4
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3505.5964, current episode: 5
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3386.8691, current episode: 6
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3483.3315, current episode: 7
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3363.9167, current episode: 8
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3361.6626, current episode: 9
[2023-06-29 11:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3378.4241, current episode: 10
[2023-06-29 11:48:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 223500.000000 | iteration_223500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486059      | 6729.208659         | 6.729209             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3282.570215 | 436.923417 | 3505.596436 | 1981.865967 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3499.6414, current episode: 1
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3454.6389, current episode: 2
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3516.0215, current episode: 3
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.6355, current episode: 4
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3508.5312, current episode: 5
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3487.2954, current episode: 6
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3493.1526, current episode: 7
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3500.2039, current episode: 8
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3438.5151, current episode: 9
[2023-06-29 11:48:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3471.2915, current episode: 10
[2023-06-29 11:48:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 224000.000000 | iteration_224000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514022      | 6604.921828         | 6.604922             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3484.992700 | 23.071458  | 3516.021484 | 3438.515137 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:48:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1130.1720, current episode: 1
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1130.1720, current episode: 1
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1130.1720, current episode: 1
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3394.9167, current episode: 2
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3456.7793, current episode: 3
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3447.9070, current episode: 4
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3450.9851, current episode: 5
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3427.1865, current episode: 6
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3383.7500, current episode: 7
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3446.6926, current episode: 8
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3453.2925, current episode: 9
[2023-06-29 11:48:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3111.7073, current episode: 10
[2023-06-29 11:48:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 224500.000000 | iteration_224500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484397      | 6736.742384         | 6.736742             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3170.338904 | 687.165003 | 3456.779297 | 1130.171997 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1122.0171, current episode: 1
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1122.0171, current episode: 1
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1122.0171, current episode: 1
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3526.2373, current episode: 2
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3489.1853, current episode: 3
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3531.9746, current episode: 4
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3496.9475, current episode: 5
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3490.6824, current episode: 6
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3486.5562, current episode: 7
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3474.3228, current episode: 8
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3466.8484, current episode: 9
[2023-06-29 11:49:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3495.9641, current episode: 10
[2023-06-29 11:49:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 225000.000000 | iteration_225000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491216      | 6705.936342         | 6.705936             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3258.073560 | 712.277891 | 3531.974609 | 1122.017090 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:49:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1668.8951, current episode: 1
[2023-06-29 11:49:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1685.9440, current episode: 2
[2023-06-29 11:49:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1729.3970, current episode: 3
[2023-06-29 11:49:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1962.9138, current episode: 4
[2023-06-29 11:49:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3118.4502, current episode: 5
[2023-06-29 11:49:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1668.8951, current episode: 5
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3429.2698, current episode: 6
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1685.9440, current episode: 6
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1729.3970, current episode: 6
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3512.1299, current episode: 7
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3591.8711, current episode: 8
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3491.0894, current episode: 9
[2023-06-29 11:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3528.1548, current episode: 10
[2023-06-29 11:49:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 225500.000000 | iteration_225500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.490962      | 6707.077793         | 6.707078             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2771.811499 | 836.592548 | 3591.871094 | 1668.895142 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3481.8247, current episode: 1
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3455.7312, current episode: 2
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3513.4619, current episode: 3
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3474.8105, current episode: 4
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3461.9890, current episode: 5
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3452.7188, current episode: 6
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3465.1870, current episode: 7
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3446.1987, current episode: 8
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3471.9587, current episode: 9
[2023-06-29 11:49:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3469.2056, current episode: 10
[2023-06-29 11:49:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 226000.000000 | iteration_226000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511427      | 6616.265028         | 6.616265             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3469.308618 | 17.909975  | 3513.461914 | 3446.198730 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:49:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1130.0599, current episode: 1
[2023-06-29 11:49:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1145.2908, current episode: 2
[2023-06-29 11:49:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1192.2476, current episode: 3
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1245.2894, current episode: 4
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1465.8214, current episode: 5
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1585.5510, current episode: 6
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1983.4032, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1130.0599, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1145.2908, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1192.2476, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1245.2894, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1465.8214, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1585.5510, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1130.0599, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1145.2908, current episode: 7
[2023-06-29 11:49:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3592.1528, current episode: 8
[2023-06-29 11:49:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1192.2476, current episode: 8
[2023-06-29 11:49:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3495.0740, current episode: 9
[2023-06-29 11:49:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3521.2554, current episode: 10
[2023-06-29 11:49:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 226500.000000 | iteration_226500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.554569      | 6432.651738         | 6.432652             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2035.614551 | 1011.854563 | 3592.152832 | 1130.059937 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 11:50:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 970.3669, current episode: 1
[2023-06-29 11:50:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1024.1689, current episode: 2
[2023-06-29 11:50:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1029.6591, current episode: 3
[2023-06-29 11:50:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1044.6786, current episode: 4
[2023-06-29 11:50:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1089.7715, current episode: 5
[2023-06-29 11:50:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1219.9528, current episode: 6
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 970.3669, current episode: 6
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2138.7327, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1024.1689, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1029.6591, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1044.6786, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1089.7715, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1219.9528, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 970.3669, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1024.1689, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1029.6591, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1044.6786, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1089.7715, current episode: 7
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3457.4187, current episode: 8
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3453.4875, current episode: 9
[2023-06-29 11:50:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3440.9504, current episode: 10
[2023-06-29 11:50:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 227000.000000 | iteration_227000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528233      | 6543.503113         | 6.543503             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1886.918707 | 1072.752873 | 3457.418701 | 970.366882 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1167.1337, current episode: 1
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1247.8052, current episode: 2
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1248.4390, current episode: 3
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1261.1472, current episode: 4
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1265.3468, current episode: 5
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1286.9882, current episode: 6
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1516.8964, current episode: 7
[2023-06-29 11:50:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2055.3281, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1167.1337, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1247.8052, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1248.4390, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1261.1472, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1265.3468, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1286.9882, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1516.8964, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1167.1337, current episode: 8
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3413.5264, current episode: 9
[2023-06-29 11:50:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3475.3494, current episode: 10
[2023-06-29 11:50:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 227500.000000 | iteration_227500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511684      | 6615.138250         | 6.615138             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1793.796021 | 860.480916 | 3475.349365 | 1167.133667 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1151.3708, current episode: 1
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1335.7598, current episode: 2
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1557.0175, current episode: 3
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1556.6460, current episode: 4
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1564.6039, current episode: 5
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1889.5657, current episode: 6
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1151.3708, current episode: 6
[2023-06-29 11:50:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1335.7598, current episode: 6
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1557.0175, current episode: 6
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1556.6460, current episode: 6
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1564.6039, current episode: 6
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1151.3708, current episode: 6
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3466.9209, current episode: 7
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3422.3169, current episode: 8
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3453.2144, current episode: 9
[2023-06-29 11:50:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3430.9204, current episode: 10
[2023-06-29 11:50:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 228000.000000 | iteration_228000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548232      | 6458.980585         | 6.458981             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2282.833618 | 963.857212 | 3466.920898 | 1151.370850 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1079.4006, current episode: 1
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1076.9664, current episode: 2
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1089.4548, current episode: 3
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1090.5931, current episode: 4
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1102.0188, current episode: 5
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1135.1337, current episode: 6
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1202.4810, current episode: 7
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1365.7131, current episode: 8
[2023-06-29 11:50:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1391.3811, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1079.4006, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1076.9664, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1089.4548, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1090.5931, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1102.0188, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1135.1337, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1202.4810, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1365.7131, current episode: 9
[2023-06-29 11:50:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2718.4668, current episode: 10
[2023-06-29 11:50:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 228500.000000 | iteration_228500.pth.tar | 10.000000     | 7600.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 760.000000              | 1.214678      | 6256.803582         | 8.232636             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1325.160950 | 477.583712 | 2718.466797 | 1076.966431 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1414.8448, current episode: 1
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1428.6287, current episode: 2
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1448.3269, current episode: 3
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1478.2688, current episode: 4
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1406.5579, current episode: 5
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1517.1039, current episode: 6
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1616.7760, current episode: 7
[2023-06-29 11:51:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1680.0385, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1414.8448, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1428.6287, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1448.3269, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1478.2688, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1406.5579, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1517.1039, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1616.7760, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1680.0385, current episode: 8
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.0146, current episode: 9
[2023-06-29 11:51:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3412.6621, current episode: 10
[2023-06-29 11:51:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 229000.000000 | iteration_229000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.595633      | 6267.106976         | 6.267107             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1893.022217 | 793.281928 | 3527.014648 | 1406.557861 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3410.0579, current episode: 1
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3394.6121, current episode: 2
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3418.5815, current episode: 3
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3387.9033, current episode: 4
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3412.0122, current episode: 5
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3408.9236, current episode: 6
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3378.8496, current episode: 7
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3401.7981, current episode: 8
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3376.2703, current episode: 9
[2023-06-29 11:51:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3377.9165, current episode: 10
[2023-06-29 11:51:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 229500.000000 | iteration_229500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484671      | 6735.497221         | 6.735497             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3396.692505 | 14.958862  | 3418.581543 | 3376.270264 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1708.4921, current episode: 1
[2023-06-29 11:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1934.8818, current episode: 2
[2023-06-29 11:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1895.8068, current episode: 3
[2023-06-29 11:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2065.6733, current episode: 4
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1708.4921, current episode: 4
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3430.0930, current episode: 5
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3406.7139, current episode: 6
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3384.0796, current episode: 7
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3435.9199, current episode: 8
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3418.1099, current episode: 9
[2023-06-29 11:51:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3402.3071, current episode: 10
[2023-06-29 11:51:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 230000.000000 | iteration_230000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.534351      | 6517.413236         | 6.517413             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2808.207739 | 745.080003 | 3435.919922 | 1708.492065 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1073.2804, current episode: 1
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1157.0035, current episode: 2
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1252.5310, current episode: 3
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1253.2545, current episode: 4
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1491.8246, current episode: 5
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1526.5227, current episode: 6
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1073.2804, current episode: 6
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1157.0035, current episode: 6
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1252.5310, current episode: 6
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1253.2545, current episode: 6
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2608.8567, current episode: 7
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1491.8246, current episode: 7
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1526.5227, current episode: 7
[2023-06-29 11:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1073.2804, current episode: 7
[2023-06-29 11:51:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1157.0035, current episode: 7
[2023-06-29 11:51:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3473.9609, current episode: 8
[2023-06-29 11:51:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3406.2097, current episode: 9
[2023-06-29 11:51:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3423.9368, current episode: 10
[2023-06-29 11:51:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 230500.000000 | iteration_230500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504354      | 6647.373164         | 6.647373             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2066.738086 | 983.461400 | 3473.960938 | 1073.280396 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1131.8528, current episode: 1
[2023-06-29 11:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1137.5144, current episode: 2
[2023-06-29 11:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1280.9716, current episode: 3
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1344.7687, current episode: 4
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1363.7799, current episode: 5
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1394.8558, current episode: 6
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1399.1401, current episode: 7
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1452.6604, current episode: 8
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2257.5972, current episode: 9
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1131.8528, current episode: 9
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1137.5144, current episode: 9
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1280.9716, current episode: 9
[2023-06-29 11:52:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2560.4211, current episode: 10
[2023-06-29 11:52:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 231000.000000 | iteration_231000.pth.tar | 10.000000     | 7180.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 718.000000              | 1.082344      | 6633.749740         | 9.239206             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1532.356201 | 454.862682 | 2560.421143 | 1131.852783 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1119.5345, current episode: 1
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1168.9054, current episode: 2
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1282.1907, current episode: 3
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1307.2859, current episode: 4
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1375.4100, current episode: 5
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1363.8423, current episode: 6
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1612.1403, current episode: 7
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1989.0750, current episode: 8
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1119.5345, current episode: 8
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1168.9054, current episode: 8
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2415.7385, current episode: 9
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1282.1907, current episode: 9
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1307.2859, current episode: 9
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1375.4100, current episode: 9
[2023-06-29 11:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1363.8423, current episode: 9
[2023-06-29 11:52:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1612.1403, current episode: 9
[2023-06-29 11:52:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1119.5345, current episode: 9
[2023-06-29 11:52:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3457.7939, current episode: 10
[2023-06-29 11:52:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 231500.000000 | iteration_231500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522569      | 6567.848553         | 6.567849             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1709.191650 | 697.044566 | 3457.793945 | 1119.534546 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2201.8760, current episode: 1
[2023-06-29 11:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2390.0347, current episode: 2
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3372.3911, current episode: 3
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3323.4785, current episode: 4
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3342.3296, current episode: 5
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3397.5620, current episode: 6
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3365.0454, current episode: 7
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3373.9409, current episode: 8
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3347.7681, current episode: 9
[2023-06-29 11:52:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3358.6621, current episode: 10
[2023-06-29 11:52:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 232000.000000 | iteration_232000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483992      | 6738.581612         | 6.738582             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3147.308838 | 428.169408 | 3397.562012 | 2201.875977 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1329.3044, current episode: 1
[2023-06-29 11:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1541.5713, current episode: 2
[2023-06-29 11:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2096.3298, current episode: 3
[2023-06-29 11:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2152.3796, current episode: 4
[2023-06-29 11:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2203.7852, current episode: 5
[2023-06-29 11:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1329.3044, current episode: 5
[2023-06-29 11:52:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3004.8447, current episode: 6
[2023-06-29 11:52:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1541.5713, current episode: 6
[2023-06-29 11:52:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3423.9075, current episode: 7
[2023-06-29 11:52:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3401.6194, current episode: 8
[2023-06-29 11:52:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3436.8718, current episode: 9
[2023-06-29 11:52:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3386.9241, current episode: 10
[2023-06-29 11:52:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 232500.000000 | iteration_232500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485930      | 6729.791873         | 6.729792             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2597.753784 | 784.273056 | 3436.871826 | 1329.304443 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 890.8310, current episode: 1
[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 894.9418, current episode: 2
[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1018.1675, current episode: 3
[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1053.6609, current episode: 4
[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1099.4078, current episode: 5
[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1147.4471, current episode: 6
[2023-06-29 11:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1176.6166, current episode: 7
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1296.1907, current episode: 8
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 890.8310, current episode: 8
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 894.9418, current episode: 8
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1926.1449, current episode: 9
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1018.1675, current episode: 9
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1053.6609, current episode: 9
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1099.4078, current episode: 9
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1147.4471, current episode: 9
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1176.6166, current episode: 9
[2023-06-29 11:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2602.6201, current episode: 10
[2023-06-29 11:53:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 233000.000000 | iteration_233000.pth.tar | 10.000000     | 7200.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 720.000000              | 1.109453      | 6489.683825         | 9.013450             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1310.602850 | 513.624752 | 2602.620117 | 890.830994 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:53:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1209.2175, current episode: 1
[2023-06-29 11:53:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1374.7704, current episode: 2
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1890.6630, current episode: 3
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2029.0609, current episode: 4
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1209.2175, current episode: 4
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2530.0879, current episode: 5
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1374.7704, current episode: 5
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2816.5940, current episode: 6
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3432.8855, current episode: 7
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1209.2175, current episode: 7
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3483.9011, current episode: 8
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3445.7122, current episode: 9
[2023-06-29 11:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3467.3689, current episode: 10
[2023-06-29 11:53:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 233500.000000 | iteration_233500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500195      | 6665.801436         | 6.665801             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2568.026135 | 851.393484 | 3483.901123 | 1209.217529 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1249.5586, current episode: 1
[2023-06-29 11:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1621.5763, current episode: 2
[2023-06-29 11:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1249.5586, current episode: 2
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2804.1406, current episode: 3
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2999.0750, current episode: 4
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1621.5763, current episode: 4
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3411.9607, current episode: 5
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3473.3342, current episode: 6
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3446.7920, current episode: 7
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3449.3860, current episode: 8
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3482.5139, current episode: 9
[2023-06-29 11:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3467.1169, current episode: 10
[2023-06-29 11:53:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 234000.000000 | iteration_234000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528665      | 6541.655460         | 6.541655             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2940.545422 | 788.254780 | 3482.513916 | 1249.558594 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1326.4257, current episode: 1
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1358.3445, current episode: 2
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1449.8591, current episode: 3
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1510.4442, current episode: 4
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2080.4346, current episode: 5
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2196.6216, current episode: 6
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2198.4019, current episode: 7
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2202.7615, current episode: 8
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1326.4257, current episode: 8
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1358.3445, current episode: 8
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1449.8591, current episode: 8
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1510.4442, current episode: 8
[2023-06-29 11:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3306.8887, current episode: 9
[2023-06-29 11:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3502.6084, current episode: 10
[2023-06-29 11:53:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 234500.000000 | iteration_234500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.555959      | 6426.905134         | 6.426905             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2113.279004 | 732.858649 | 3502.608398 | 1326.425659 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1177.8059, current episode: 1
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1239.1608, current episode: 2
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1290.6160, current episode: 3
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1398.6146, current episode: 4
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1478.5374, current episode: 5
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1585.7274, current episode: 6
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1572.8472, current episode: 7
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1750.3641, current episode: 8
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1962.1427, current episode: 9
[2023-06-29 11:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1958.5719, current episode: 10
[2023-06-29 11:54:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 235000.000000 | iteration_235000.pth.tar | 10.000000     | 5500.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 550.000000              | 0.834531      | 6590.524191         | 11.982771            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1541.438794 | 266.168720 | 1962.142700 | 1177.805908 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1001.2206, current episode: 1
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1036.2188, current episode: 2
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1086.5902, current episode: 3
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1145.7263, current episode: 4
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1163.2003, current episode: 5
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1191.4873, current episode: 6
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1645.1935, current episode: 7
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1693.2531, current episode: 8
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1889.6198, current episode: 9
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1001.2206, current episode: 9
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1036.2188, current episode: 9
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1086.5902, current episode: 9
[2023-06-29 11:54:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1145.7263, current episode: 9
[2023-06-29 11:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1163.2003, current episode: 9
[2023-06-29 11:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1191.4873, current episode: 9
[2023-06-29 11:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3108.4060, current episode: 10
[2023-06-29 11:54:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 235500.000000 | iteration_235500.pth.tar | 10.000000     | 8540.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 854.000000              | 1.298764      | 6575.483579         | 7.699629             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1496.091583 | 613.673697 | 3108.406006 | 1001.220642 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.8627, current episode: 1
[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1181.2468, current episode: 2
[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1203.5245, current episode: 3
[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1261.1646, current episode: 4
[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1397.5642, current episode: 5
[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1427.6729, current episode: 6
[2023-06-29 11:54:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.3398, current episode: 7
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2140.4011, current episode: 8
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.8627, current episode: 8
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1181.2468, current episode: 8
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1203.5245, current episode: 8
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2412.1685, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1261.1646, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1397.5642, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1427.6729, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.3398, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.8627, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1181.2468, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1203.5245, current episode: 9
[2023-06-29 11:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3419.2922, current episode: 10
[2023-06-29 11:54:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 236000.000000 | iteration_236000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505931      | 6640.409812         | 6.640410             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1714.523730 | 694.708682 | 3419.292236 | 1181.246826 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1087.2751, current episode: 1
[2023-06-29 11:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1095.1949, current episode: 2
[2023-06-29 11:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1111.4658, current episode: 3
[2023-06-29 11:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1317.4684, current episode: 4
[2023-06-29 11:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1324.5231, current episode: 5
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1405.0043, current episode: 6
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1533.7074, current episode: 7
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1558.1781, current episode: 8
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1087.2751, current episode: 8
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2215.8647, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1095.1949, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1111.4658, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1317.4684, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1324.5231, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1405.0043, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1533.7074, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1558.1781, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1087.2751, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1095.1949, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1111.4658, current episode: 9
[2023-06-29 11:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3411.1636, current episode: 10
[2023-06-29 11:54:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 236500.000000 | iteration_236500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.521328      | 6573.205506         | 6.573206             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1605.984546 | 679.375011 | 3411.163574 | 1087.275146 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 944.9710, current episode: 1
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 951.2972, current episode: 2
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 954.0424, current episode: 3
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 963.1958, current episode: 4
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 972.8419, current episode: 5
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1108.9369, current episode: 6
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1382.7079, current episode: 7
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1458.7037, current episode: 8
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1625.3917, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 944.9710, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 951.2972, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 954.0424, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 963.1958, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 972.8419, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1108.9369, current episode: 9
[2023-06-29 11:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1382.7079, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1458.7037, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 944.9710, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 951.2972, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 954.0424, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 963.1958, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 972.8419, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1625.3917, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1108.9369, current episode: 9
[2023-06-29 11:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3375.4287, current episode: 10
[2023-06-29 11:55:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 237000.000000 | iteration_237000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547965      | 6460.094525         | 6.460095             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1373.751727 | 708.182101 | 3375.428711 | 944.971008 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 934.4274, current episode: 1
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 952.8688, current episode: 2
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1062.3591, current episode: 3
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1116.7603, current episode: 4
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1209.1293, current episode: 5
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1275.8260, current episode: 6
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1558.2085, current episode: 7
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 934.4274, current episode: 7
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 952.8688, current episode: 7
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1062.3591, current episode: 7
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1116.7603, current episode: 7
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1209.1293, current episode: 7
[2023-06-29 11:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1275.8260, current episode: 7
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 934.4274, current episode: 7
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2978.6917, current episode: 8
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 952.8688, current episode: 8
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1558.2085, current episode: 8
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1062.3591, current episode: 8
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1116.7603, current episode: 8
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3500.8591, current episode: 9
[2023-06-29 11:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3391.6138, current episode: 10
[2023-06-29 11:55:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 237500.000000 | iteration_237500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.578366      | 6335.665769         | 6.335666             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1798.074402 | 998.777276 | 3500.859131 | 934.427429 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1990.5000, current episode: 1
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2075.3042, current episode: 2
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2468.5276, current episode: 3
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3024.9092, current episode: 4
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3438.0698, current episode: 5
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3485.8896, current episode: 6
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3437.1890, current episode: 7
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3442.5469, current episode: 8
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3465.5205, current episode: 9
[2023-06-29 11:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3421.9387, current episode: 10
[2023-06-29 11:55:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 238000.000000 | iteration_238000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525058      | 6557.126685         | 6.557127             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3025.039551 | 579.714037 | 3485.889648 | 1990.500000 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1316.9510, current episode: 1
[2023-06-29 11:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1352.0095, current episode: 2
[2023-06-29 11:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1407.5638, current episode: 3
[2023-06-29 11:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1565.0187, current episode: 4
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1590.2142, current episode: 5
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1316.9510, current episode: 5
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1352.0095, current episode: 5
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1407.5638, current episode: 5
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1565.0187, current episode: 5
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1590.2142, current episode: 5
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3209.6724, current episode: 6
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.6753, current episode: 7
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3458.6470, current episode: 8
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3454.0283, current episode: 9
[2023-06-29 11:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3457.4534, current episode: 10
[2023-06-29 11:56:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 238500.000000 | iteration_238500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.572090      | 6360.960598         | 6.360961             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2432.823364 | 992.513549 | 3516.675293 | 1316.951050 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1277.0387, current episode: 1
[2023-06-29 11:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1318.7377, current episode: 2
[2023-06-29 11:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1467.0756, current episode: 3
[2023-06-29 11:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1493.2266, current episode: 4
[2023-06-29 11:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1607.7526, current episode: 5
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1277.0387, current episode: 5
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1318.7377, current episode: 5
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1467.0756, current episode: 5
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1493.2266, current episode: 5
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1607.7526, current episode: 5
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3410.8779, current episode: 6
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3512.2825, current episode: 7
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3485.5222, current episode: 8
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3465.1775, current episode: 9
[2023-06-29 11:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3474.6150, current episode: 10
[2023-06-29 11:56:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 239000.000000 | iteration_239000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519042      | 6583.098072         | 6.583098             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2451.230615 | 1022.299959 | 3512.282471 | 1277.038696 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 11:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1318.9045, current episode: 1
[2023-06-29 11:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1446.3787, current episode: 2
[2023-06-29 11:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1483.8788, current episode: 3
[2023-06-29 11:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1318.9045, current episode: 3
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1446.3787, current episode: 3
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1483.8788, current episode: 3
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3425.2700, current episode: 4
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3439.7820, current episode: 5
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3436.8853, current episode: 6
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3462.7588, current episode: 7
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3431.3669, current episode: 8
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3424.9514, current episode: 9
[2023-06-29 11:56:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3434.7571, current episode: 10
[2023-06-29 11:56:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 239500.000000 | iteration_239500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.620119      | 6172.387892         | 6.172388             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2830.493347 | 926.610585 | 3462.758789 | 1318.904541 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1241.5848, current episode: 1
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1341.5730, current episode: 2
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1799.0963, current episode: 3
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1916.3873, current episode: 4
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1965.5927, current episode: 5
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2211.8384, current episode: 6
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2449.7559, current episode: 7
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1241.5848, current episode: 7
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1341.5730, current episode: 7
[2023-06-29 11:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1799.0963, current episode: 7
[2023-06-29 11:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3439.4390, current episode: 8
[2023-06-29 11:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3462.1211, current episode: 9
[2023-06-29 11:56:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3442.7954, current episode: 10
[2023-06-29 11:56:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 240000.000000 | iteration_240000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502352      | 6656.228392         | 6.656228             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2327.018384 | 807.864081 | 3462.121094 | 1241.584839 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1116.2288, current episode: 1
[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1230.4692, current episode: 2
[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1224.2283, current episode: 3
[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1238.1099, current episode: 4
[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1259.8798, current episode: 5
[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1267.3971, current episode: 6
[2023-06-29 11:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1381.7673, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1116.2288, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1230.4692, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1224.2283, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1238.1099, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1259.8798, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1267.3971, current episode: 7
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2680.0986, current episode: 8
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1381.7673, current episode: 8
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1116.2288, current episode: 8
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3430.2415, current episode: 9
[2023-06-29 11:57:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3467.8477, current episode: 10
[2023-06-29 11:57:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 240500.000000 | iteration_240500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536363      | 6508.879830         | 6.508880             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1829.626807 | 916.223522 | 3467.847656 | 1116.228760 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:57:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1832.6799, current episode: 1
[2023-06-29 11:57:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2133.5466, current episode: 2
[2023-06-29 11:57:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2278.1228, current episode: 3
[2023-06-29 11:57:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2915.3291, current episode: 4
[2023-06-29 11:57:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3347.4583, current episode: 5
[2023-06-29 11:57:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3399.0496, current episode: 6
[2023-06-29 11:57:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3478.3662, current episode: 7
[2023-06-29 11:57:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3476.5701, current episode: 8
[2023-06-29 11:57:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3450.0935, current episode: 9
[2023-06-29 11:57:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3425.2827, current episode: 10
[2023-06-29 11:57:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 241000.000000 | iteration_241000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.538997      | 6497.736619         | 6.497737             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2973.649878 | 612.705536 | 3478.366211 | 1832.679932 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:57:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2295.2671, current episode: 1
[2023-06-29 11:57:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2876.6812, current episode: 2
[2023-06-29 11:57:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3414.3762, current episode: 3
[2023-06-29 11:57:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3412.9451, current episode: 4
[2023-06-29 11:57:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3414.9951, current episode: 5
[2023-06-29 11:57:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3413.3359, current episode: 6
[2023-06-29 11:57:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3410.3162, current episode: 7
[2023-06-29 11:57:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3432.5522, current episode: 8
[2023-06-29 11:57:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3439.5161, current episode: 9
[2023-06-29 11:57:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3420.3403, current episode: 10
[2023-06-29 11:57:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 241500.000000 | iteration_241500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524091      | 6561.288781         | 6.561289             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3253.032544 | 358.081187 | 3439.516113 | 2295.267090 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1690.5236, current episode: 1
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1767.1541, current episode: 2
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1778.4158, current episode: 3
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1794.8944, current episode: 4
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2305.0732, current episode: 5
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2416.3306, current episode: 6
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2497.1262, current episode: 7
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2779.7783, current episode: 8
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3124.5791, current episode: 9
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1690.5236, current episode: 9
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1767.1541, current episode: 9
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1778.4158, current episode: 9
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1794.8944, current episode: 9
[2023-06-29 11:57:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3420.9766, current episode: 10
[2023-06-29 11:57:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 242000.000000 | iteration_242000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505236      | 6643.476673         | 6.643477             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2357.485181 | 580.400406 | 3420.976562 | 1690.523560 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1958.2975, current episode: 1
[2023-06-29 11:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2075.3896, current episode: 2
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3037.8677, current episode: 3
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3119.3757, current episode: 4
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3522.9302, current episode: 5
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3618.7219, current episode: 6
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3494.0762, current episode: 7
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3486.7800, current episode: 8
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3483.6978, current episode: 9
[2023-06-29 11:58:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3456.3848, current episode: 10
[2023-06-29 11:58:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 242500.000000 | iteration_242500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476071      | 6774.743340         | 6.774743             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3125.352136 | 581.222057 | 3618.721924 | 1958.297485 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1794.9261, current episode: 1
[2023-06-29 11:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1802.1393, current episode: 2
[2023-06-29 11:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2103.9326, current episode: 3
[2023-06-29 11:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2209.5471, current episode: 4
[2023-06-29 11:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2298.5554, current episode: 5
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3221.6372, current episode: 6
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1794.9261, current episode: 6
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1802.1393, current episode: 6
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3498.4651, current episode: 7
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3483.2097, current episode: 8
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3489.2087, current episode: 9
[2023-06-29 11:58:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3507.2190, current episode: 10
[2023-06-29 11:58:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 243000.000000 | iteration_243000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505089      | 6644.123795         | 6.644124             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2740.884033 | 718.548390 | 3507.218994 | 1794.926147 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1810.1941, current episode: 1
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2587.3484, current episode: 2
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1810.1941, current episode: 2
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3490.6008, current episode: 3
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3462.2546, current episode: 4
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3531.6077, current episode: 5
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3505.1328, current episode: 6
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3485.1541, current episode: 7
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3512.3428, current episode: 8
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3495.8245, current episode: 9
[2023-06-29 11:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3475.7478, current episode: 10
[2023-06-29 11:58:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 243500.000000 | iteration_243500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508868      | 6627.484791         | 6.627485             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3235.620752 | 547.076768 | 3531.607666 | 1810.194092 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1208.3770, current episode: 1
[2023-06-29 11:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1213.7590, current episode: 2
[2023-06-29 11:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1251.1431, current episode: 3
[2023-06-29 11:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1280.1464, current episode: 4
[2023-06-29 11:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1285.5991, current episode: 5
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1208.3770, current episode: 5
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1213.7590, current episode: 5
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1251.1431, current episode: 5
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1280.1464, current episode: 5
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1285.5991, current episode: 5
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2630.6450, current episode: 6
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3473.4836, current episode: 7
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3470.0942, current episode: 8
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3447.0471, current episode: 9
[2023-06-29 11:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3445.0227, current episode: 10
[2023-06-29 11:58:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 244000.000000 | iteration_244000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.545892      | 6468.756821         | 6.468757             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2270.531726 | 1049.494763 | 3473.483643 | 1208.376953 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 11:59:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1346.1105, current episode: 1
[2023-06-29 11:59:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1980.0637, current episode: 2
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1346.1105, current episode: 2
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2944.3645, current episode: 3
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.4761, current episode: 4
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3452.8240, current episode: 5
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3497.2993, current episode: 6
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3509.2668, current episode: 7
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3523.2249, current episode: 8
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3468.4155, current episode: 9
[2023-06-29 11:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3468.7976, current episode: 10
[2023-06-29 11:59:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 244500.000000 | iteration_244500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511429      | 6616.257013         | 6.616257             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3079.184290 | 741.784691 | 3601.476074 | 1346.110474 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1133.6555, current episode: 1
[2023-06-29 11:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1249.1556, current episode: 2
[2023-06-29 11:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1258.8806, current episode: 3
[2023-06-29 11:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1306.0116, current episode: 4
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1611.5933, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1133.6555, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1249.1556, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1258.8806, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1306.0116, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1611.5933, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1133.6555, current episode: 5
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3449.0190, current episode: 6
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3452.3655, current episode: 7
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3495.4980, current episode: 8
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.0115, current episode: 9
[2023-06-29 11:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3475.1155, current episode: 10
[2023-06-29 11:59:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 245000.000000 | iteration_245000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.544023      | 6476.587161         | 6.476587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2396.330615 | 1090.588786 | 3532.011475 | 1133.655518 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1333.0834, current episode: 1
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1343.0217, current episode: 2
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1347.7766, current episode: 3
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1348.4543, current episode: 4
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1381.1200, current episode: 5
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1371.4785, current episode: 6
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1419.4675, current episode: 7
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1422.5681, current episode: 8
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1458.4496, current episode: 9
[2023-06-29 11:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1620.2733, current episode: 10
[2023-06-29 11:59:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 245500.000000 | iteration_245500.pth.tar | 10.000000     | 4360.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 436.000000              | 0.661375      | 6592.326592         | 15.120015            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1404.569312 | 81.789199  | 1620.273315 | 1333.083374 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2055.1926, current episode: 1
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2069.3186, current episode: 2
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2094.6660, current episode: 3
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2558.1763, current episode: 4
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2866.5554, current episode: 5
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.0310, current episode: 6
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3468.9751, current episode: 7
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3370.6758, current episode: 8
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3447.6599, current episode: 9
[2023-06-29 11:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3471.5596, current episode: 10
[2023-06-29 11:59:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 246000.000000 | iteration_246000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503102      | 6652.908227         | 6.652908             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2890.381030 | 608.477527 | 3501.031006 | 2055.192627 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1315.5967, current episode: 1
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1367.9230, current episode: 2
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1387.7571, current episode: 3
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1401.6189, current episode: 4
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1407.7031, current episode: 5
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1512.5264, current episode: 6
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1552.6747, current episode: 7
[2023-06-29 12:00:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1583.7919, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1315.5967, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1367.9230, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1387.7571, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1401.6189, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1407.7031, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1512.5264, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1552.6747, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1583.7919, current episode: 8
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3412.6472, current episode: 9
[2023-06-29 12:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3473.6077, current episode: 10
[2023-06-29 12:00:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 246500.000000 | iteration_246500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.544989      | 6472.538446         | 6.472538             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1841.584656 | 804.906416 | 3473.607666 | 1315.596680 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1343.8580, current episode: 1
[2023-06-29 12:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1359.7893, current episode: 2
[2023-06-29 12:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1480.8057, current episode: 3
[2023-06-29 12:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1804.8000, current episode: 4
[2023-06-29 12:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1995.7792, current episode: 5
[2023-06-29 12:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2605.1782, current episode: 6
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1343.8580, current episode: 6
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1359.7893, current episode: 6
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2744.2964, current episode: 7
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1480.8057, current episode: 7
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3406.6909, current episode: 8
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3482.6277, current episode: 9
[2023-06-29 12:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.5530, current episode: 10
[2023-06-29 12:00:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 247000.000000 | iteration_247000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519743      | 6580.059208         | 6.580059             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2370.837842 | 841.067660 | 3484.552979 | 1343.858032 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2010.7159, current episode: 1
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2651.6909, current episode: 2
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3333.0598, current episode: 3
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3505.9009, current episode: 4
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3435.2734, current episode: 5
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3398.5168, current episode: 6
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3523.3982, current episode: 7
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3502.8230, current episode: 8
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3488.4673, current episode: 9
[2023-06-29 12:00:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3435.0847, current episode: 10
[2023-06-29 12:00:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 247500.000000 | iteration_247500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.552351      | 6441.840256         | 6.441840             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3228.493103 | 474.102309 | 3523.398193 | 2010.715942 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1146.0140, current episode: 1
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1204.4049, current episode: 2
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1325.3544, current episode: 3
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1732.0023, current episode: 4
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2166.7312, current episode: 5
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2332.1763, current episode: 6
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1146.0140, current episode: 6
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1204.4049, current episode: 6
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1325.3544, current episode: 6
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2911.4194, current episode: 7
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2924.7395, current episode: 8
[2023-06-29 12:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3187.7285, current episode: 9
[2023-06-29 12:00:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1732.0023, current episode: 9
[2023-06-29 12:00:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1146.0140, current episode: 9
[2023-06-29 12:00:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1204.4049, current episode: 9
[2023-06-29 12:00:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3542.8867, current episode: 10
[2023-06-29 12:00:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 248000.000000 | iteration_248000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.534464      | 6516.934683         | 6.516935             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2247.345728 | 830.216919 | 3542.886719 | 1146.014038 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1348.8352, current episode: 1
[2023-06-29 12:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1818.5398, current episode: 2
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1348.8352, current episode: 2
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1818.5398, current episode: 2
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.4136, current episode: 3
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3500.6829, current episode: 4
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.1743, current episode: 5
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3507.9365, current episode: 6
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3500.3291, current episode: 7
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3492.7051, current episode: 8
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3484.0840, current episode: 9
[2023-06-29 12:01:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3464.7415, current episode: 10
[2023-06-29 12:01:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 248500.000000 | iteration_248500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.585819      | 6305.888069         | 6.305888             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3109.044189 | 769.962195 | 3507.936523 | 1348.835205 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3459.8806, current episode: 1
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3509.0842, current episode: 2
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3406.8628, current episode: 3
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3435.3564, current episode: 4
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3435.5557, current episode: 5
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3478.5469, current episode: 6
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3505.7043, current episode: 7
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3438.0154, current episode: 8
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3489.2839, current episode: 9
[2023-06-29 12:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3444.2783, current episode: 10
[2023-06-29 12:01:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 249000.000000 | iteration_249000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485225      | 6732.987249         | 6.732987             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3460.256860 | 32.338717  | 3509.084229 | 3406.862793 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1164.0873, current episode: 1
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1277.4023, current episode: 2
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1293.2831, current episode: 3
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1298.5140, current episode: 4
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1327.6985, current episode: 5
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1384.6277, current episode: 6
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1164.0873, current episode: 6
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1277.4023, current episode: 6
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1293.2831, current episode: 6
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1298.5140, current episode: 6
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1327.6985, current episode: 6
[2023-06-29 12:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1384.6277, current episode: 6
[2023-06-29 12:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1164.0873, current episode: 6
[2023-06-29 12:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3522.5320, current episode: 7
[2023-06-29 12:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3475.0420, current episode: 8
[2023-06-29 12:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3519.2415, current episode: 9
[2023-06-29 12:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3502.8000, current episode: 10
[2023-06-29 12:01:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 249500.000000 | iteration_249500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519861      | 6579.548687         | 6.579549             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2176.522839 | 1085.902997 | 3522.531982 | 1164.087280 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3519.7783, current episode: 1
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3537.9849, current episode: 2
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3539.2793, current episode: 3
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3537.6819, current episode: 4
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3568.5496, current episode: 5
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3484.9727, current episode: 6
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3503.1111, current episode: 7
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.8320, current episode: 8
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3551.3916, current episode: 9
[2023-06-29 12:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3497.7449, current episode: 10
[2023-06-29 12:01:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 250000.000000 | iteration_250000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.472548      | 6790.950230         | 6.790950             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3530.332617 | 26.692192  | 3568.549561 | 3484.972656 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3538.9722, current episode: 1
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3511.4004, current episode: 2
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3503.4126, current episode: 3
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3486.9429, current episode: 4
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3506.2522, current episode: 5
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3516.6165, current episode: 6
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3545.0625, current episode: 7
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3525.3010, current episode: 8
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3489.7080, current episode: 9
[2023-06-29 12:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.2812, current episode: 10
[2023-06-29 12:02:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 250500.000000 | iteration_250500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479191      | 6760.451425         | 6.760451             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3511.794946 | 18.879413  | 3545.062500 | 3486.942871 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3504.3728, current episode: 1
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3496.2666, current episode: 2
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3507.0352, current episode: 3
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3486.3655, current episode: 4
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3514.9426, current episode: 5
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3477.6853, current episode: 6
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3508.3477, current episode: 7
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3507.7183, current episode: 8
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3493.8455, current episode: 9
[2023-06-29 12:02:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3517.4011, current episode: 10
[2023-06-29 12:02:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 251000.000000 | iteration_251000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508218      | 6630.342770         | 6.630343             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3501.398047 | 12.000284  | 3517.401123 | 3477.685303 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 903.2108, current episode: 1
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 908.8386, current episode: 2
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 929.7150, current episode: 3
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 990.9024, current episode: 4
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1336.0884, current episode: 5
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1679.4940, current episode: 6
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 903.2108, current episode: 6
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 908.8386, current episode: 6
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 929.7150, current episode: 6
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1999.0137, current episode: 7
[2023-06-29 12:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 990.9024, current episode: 7
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1336.0884, current episode: 7
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 903.2108, current episode: 7
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 908.8386, current episode: 7
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 929.7150, current episode: 7
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3010.8081, current episode: 8
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 990.9024, current episode: 8
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3174.0251, current episode: 9
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1679.4940, current episode: 9
[2023-06-29 12:02:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3591.4658, current episode: 10
[2023-06-29 12:02:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 251500.000000 | iteration_251500.pth.tar | 10.000000     | 9700.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 970.000000              | 1.734422      | 5592.640459         | 5.765609             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1852.356195 | 990.742952 | 3591.465820 | 903.210754 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 859.3289, current episode: 1
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 890.9236, current episode: 2
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 905.2047, current episode: 3
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 953.0109, current episode: 4
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 951.3481, current episode: 5
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1012.3698, current episode: 6
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 859.3289, current episode: 6
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1822.9248, current episode: 7
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 890.9236, current episode: 7
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 905.2047, current episode: 7
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1927.5751, current episode: 8
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1945.6097, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 953.0109, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 951.3481, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1012.3698, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 859.3289, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 890.9236, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 905.2047, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 953.0109, current episode: 9
[2023-06-29 12:02:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 951.3481, current episode: 9
[2023-06-29 12:03:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2992.9675, current episode: 10
[2023-06-29 12:03:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 252000.000000 | iteration_252000.pth.tar | 10.000000     | 8040.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 804.000000              | 1.255709      | 6402.756784         | 7.963628             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1426.126312 | 680.680683 | 2992.967529 | 859.328857 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 12:03:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2168.2971, current episode: 1
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2591.0793, current episode: 2
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3028.5159, current episode: 3
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3651.6167, current episode: 4
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3566.4917, current episode: 5
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3557.1125, current episode: 6
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3546.1802, current episode: 7
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3582.3010, current episode: 8
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.7031, current episode: 9
[2023-06-29 12:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3555.3430, current episode: 10
[2023-06-29 12:03:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 252500.000000 | iteration_252500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479730      | 6757.990280         | 6.757990             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3280.964063 | 488.740258 | 3651.616699 | 2168.297119 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1409.4409, current episode: 1
[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1439.3999, current episode: 2
[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1503.7474, current episode: 3
[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1649.1093, current episode: 4
[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1764.6354, current episode: 5
[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1806.8287, current episode: 6
[2023-06-29 12:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2156.3254, current episode: 7
[2023-06-29 12:03:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2535.2773, current episode: 8
[2023-06-29 12:03:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2569.0767, current episode: 9
[2023-06-29 12:03:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1409.4409, current episode: 9
[2023-06-29 12:03:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1439.3999, current episode: 9
[2023-06-29 12:03:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2952.7063, current episode: 10
[2023-06-29 12:03:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 253000.000000 | iteration_253000.pth.tar | 10.000000     | 8020.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 802.000000              | 1.212927      | 6612.103762         | 8.244518             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1978.654736 | 516.046110 | 2952.706299 | 1409.440918 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3530.1028, current episode: 1
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3490.8811, current episode: 2
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3546.4951, current episode: 3
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3509.5728, current episode: 4
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3553.9717, current episode: 5
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3541.2605, current episode: 6
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3445.9688, current episode: 7
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3540.4514, current episode: 8
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3563.8362, current episode: 9
[2023-06-29 12:03:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3482.3101, current episode: 10
[2023-06-29 12:03:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 253500.000000 | iteration_253500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476050      | 6774.839147         | 6.774839             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3520.485034 | 35.504162  | 3563.836182 | 3445.968750 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.3149, current episode: 1
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3528.4917, current episode: 2
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3550.0474, current episode: 3
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3559.7480, current episode: 4
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3580.7954, current episode: 5
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3577.3037, current episode: 6
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.6267, current episode: 7
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3557.5430, current episode: 8
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3522.0693, current episode: 9
[2023-06-29 12:04:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3567.5830, current episode: 10
[2023-06-29 12:04:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 254000.000000 | iteration_254000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505580      | 6641.959313         | 6.641959             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3557.252319 | 18.268671  | 3580.795410 | 3522.069336 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3510.8391, current episode: 1
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3484.3643, current episode: 2
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3474.5974, current episode: 3
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3500.6848, current episode: 4
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3522.6052, current episode: 5
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3520.0325, current episode: 6
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3521.4602, current episode: 7
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.3906, current episode: 8
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.2126, current episode: 9
[2023-06-29 12:04:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3531.2202, current episode: 10
[2023-06-29 12:04:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 254500.000000 | iteration_254500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483952      | 6738.763429         | 6.738763             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3509.440698 | 17.048481  | 3531.220215 | 3474.597412 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3542.9241, current episode: 1
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3545.5696, current episode: 2
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3517.1436, current episode: 3
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.6165, current episode: 4
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3556.8430, current episode: 5
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3549.2188, current episode: 6
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3541.6609, current episode: 7
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.9028, current episode: 8
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.2747, current episode: 9
[2023-06-29 12:04:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.1621, current episode: 10
[2023-06-29 12:04:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 255000.000000 | iteration_255000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486426      | 6727.548572         | 6.727549             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3536.231592 | 12.839961  | 3556.843018 | 3517.143555 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3481.9275, current episode: 1
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3363.7383, current episode: 2
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3473.2134, current episode: 3
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3436.8538, current episode: 4
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3464.5552, current episode: 5
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3450.9856, current episode: 6
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3473.2014, current episode: 7
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3426.8145, current episode: 8
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3294.4238, current episode: 9
[2023-06-29 12:04:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3452.8308, current episode: 10
[2023-06-29 12:04:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 255500.000000 | iteration_255500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508140      | 6630.683016         | 6.630683             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3431.854419 | 56.018007  | 3481.927490 | 3294.423828 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:05:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2217.0503, current episode: 1
[2023-06-29 12:05:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2885.1013, current episode: 2
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3484.0627, current episode: 3
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3491.1011, current episode: 4
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3441.5383, current episode: 5
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3365.3445, current episode: 6
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3300.6389, current episode: 7
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3436.1636, current episode: 8
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3511.2793, current episode: 9
[2023-06-29 12:05:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3339.1714, current episode: 10
[2023-06-29 12:05:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 256000.000000 | iteration_256000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514495      | 6602.859444         | 6.602859             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3247.145142 | 384.239587 | 3511.279297 | 2217.050293 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3565.6521, current episode: 1
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3514.4419, current episode: 2
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3507.9797, current episode: 3
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3500.3418, current episode: 4
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3512.7168, current episode: 5
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3435.1340, current episode: 6
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3506.4609, current episode: 7
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3390.1951, current episode: 8
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3498.9021, current episode: 9
[2023-06-29 12:05:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3511.5840, current episode: 10
[2023-06-29 12:05:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 256500.000000 | iteration_256500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484523      | 6736.168488         | 6.736168             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3494.340845 | 45.679175  | 3565.652100 | 3390.195068 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:05:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1853.5718, current episode: 1
[2023-06-29 12:05:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1917.5369, current episode: 2
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3236.0430, current episode: 3
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3254.4246, current episode: 4
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3431.5537, current episode: 5
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3431.2156, current episode: 6
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3383.3279, current episode: 7
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3417.5759, current episode: 8
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3324.5586, current episode: 9
[2023-06-29 12:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3436.7944, current episode: 10
[2023-06-29 12:05:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 257000.000000 | iteration_257000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.463687      | 6832.063997         | 6.832064             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3068.660229 | 595.730898 | 3436.794434 | 1853.571777 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3426.7400, current episode: 1
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3447.6628, current episode: 2
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3300.8206, current episode: 3
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3419.0239, current episode: 4
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3356.5039, current episode: 5
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3373.3770, current episode: 6
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3445.2112, current episode: 7
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3493.7400, current episode: 8
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3377.2717, current episode: 9
[2023-06-29 12:05:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3364.7209, current episode: 10
[2023-06-29 12:05:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 257500.000000 | iteration_257500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.463693      | 6832.032659         | 6.832033             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3400.507202 | 53.268933  | 3493.739990 | 3300.820557 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3180.7275, current episode: 1
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3409.6079, current episode: 2
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3313.7241, current episode: 3
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3366.8906, current episode: 4
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3357.6270, current episode: 5
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3310.9055, current episode: 6
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3318.2810, current episode: 7
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3357.8215, current episode: 8
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3432.2095, current episode: 9
[2023-06-29 12:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3374.1167, current episode: 10
[2023-06-29 12:06:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 258000.000000 | iteration_258000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.471257      | 6796.910923         | 6.796911             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3342.191138 | 65.720279  | 3432.209473 | 3180.727539 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3498.4346, current episode: 1
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3448.1519, current episode: 2
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3432.5408, current episode: 3
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3375.6333, current episode: 4
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3509.0276, current episode: 5
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3453.1008, current episode: 6
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3492.8796, current episode: 7
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3485.8967, current episode: 8
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3420.4397, current episode: 9
[2023-06-29 12:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3404.8433, current episode: 10
[2023-06-29 12:06:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 258500.000000 | iteration_258500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.451883      | 6887.605329         | 6.887605             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3452.094824 | 42.041317  | 3509.027588 | 3375.633301 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3382.5903, current episode: 1
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3515.5610, current episode: 2
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.8679, current episode: 3
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3508.3992, current episode: 4
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3366.1204, current episode: 5
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3457.8508, current episode: 6
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3476.2693, current episode: 7
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3445.1494, current episode: 8
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3407.1064, current episode: 9
[2023-06-29 12:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3493.8752, current episode: 10
[2023-06-29 12:06:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 259000.000000 | iteration_259000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484719      | 6735.282356         | 6.735282             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3459.379004 | 55.862353  | 3540.867920 | 3366.120361 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3494.1602, current episode: 1
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3559.0483, current episode: 2
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3552.7314, current episode: 3
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3492.5117, current episode: 4
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3550.0293, current episode: 5
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3554.9038, current episode: 6
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3497.5632, current episode: 7
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3504.6809, current episode: 8
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3562.1067, current episode: 9
[2023-06-29 12:06:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3542.9905, current episode: 10
[2023-06-29 12:06:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 259500.000000 | iteration_259500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500458      | 6664.633867         | 6.664634             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3531.072607 | 28.201153  | 3562.106689 | 3492.511719 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3513.5066, current episode: 1
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3545.6992, current episode: 2
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3564.7090, current episode: 3
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3551.1538, current episode: 4
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3505.6702, current episode: 5
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3555.8967, current episode: 6
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3488.4690, current episode: 7
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3558.7561, current episode: 8
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3492.1997, current episode: 9
[2023-06-29 12:07:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3531.3223, current episode: 10
[2023-06-29 12:07:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 260000.000000 | iteration_260000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479230      | 6760.272342         | 6.760272             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3530.738257 | 27.221636  | 3564.708984 | 3488.468994 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1846.2207, current episode: 1
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1859.7327, current episode: 2
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1846.2207, current episode: 2
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1859.7327, current episode: 2
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3457.5291, current episode: 3
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3482.4307, current episode: 4
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3481.6687, current episode: 5
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3517.0916, current episode: 6
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3527.7842, current episode: 7
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3497.2290, current episode: 8
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.0950, current episode: 9
[2023-06-29 12:07:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3502.4653, current episode: 10
[2023-06-29 12:07:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 260500.000000 | iteration_260500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506174      | 6639.339904         | 6.639340             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3164.924683 | 656.259033 | 3527.784180 | 1846.220703 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:07:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1112.7456, current episode: 1
[2023-06-29 12:07:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1238.4922, current episode: 2
[2023-06-29 12:07:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1480.6023, current episode: 3
[2023-06-29 12:07:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1112.7456, current episode: 3
[2023-06-29 12:07:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1238.4922, current episode: 3
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1480.6023, current episode: 3
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1112.7456, current episode: 3
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3480.6421, current episode: 4
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1238.4922, current episode: 4
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3496.8723, current episode: 5
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3496.1782, current episode: 6
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3455.9419, current episode: 7
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3471.5073, current episode: 8
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3495.1936, current episode: 9
[2023-06-29 12:07:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3507.5720, current episode: 10
[2023-06-29 12:07:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 261000.000000 | iteration_261000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.502227      | 6656.118740         | 6.656784             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2823.574756 | 1015.829199 | 3507.572021 | 1112.745605 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:07:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1333.5198, current episode: 1
[2023-06-29 12:07:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1333.5198, current episode: 1
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3481.5679, current episode: 2
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3462.1880, current episode: 3
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3409.0183, current episode: 4
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3454.5837, current episode: 5
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3482.1426, current episode: 6
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3492.1033, current episode: 7
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3471.7083, current episode: 8
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3462.6804, current episode: 9
[2023-06-29 12:07:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3453.7148, current episode: 10
[2023-06-29 12:07:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 261500.000000 | iteration_261500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511625      | 6615.397872         | 6.615398             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3250.322705 | 639.302399 | 3492.103271 | 1333.519775 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:08:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1267.3627, current episode: 1
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1267.3627, current episode: 1
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3484.8123, current episode: 2
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3427.9624, current episode: 3
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3522.2024, current episode: 4
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3516.1365, current episode: 5
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.6799, current episode: 6
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3477.3005, current episode: 7
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3513.6682, current episode: 8
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.2952, current episode: 9
[2023-06-29 12:08:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3503.4619, current episode: 10
[2023-06-29 12:08:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 262000.000000 | iteration_262000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.530742      | 6532.780291         | 6.532780             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3270.288196 | 668.173487 | 3522.202393 | 1267.362671 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:08:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1002.8760, current episode: 1
[2023-06-29 12:08:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1024.6847, current episode: 2
[2023-06-29 12:08:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.2441, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1002.8760, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1024.6847, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.2441, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1002.8760, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1024.6847, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.2441, current episode: 3
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3496.8911, current episode: 4
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3463.8367, current episode: 5
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3487.7966, current episode: 6
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3475.5051, current episode: 7
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3473.4634, current episode: 8
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3460.9995, current episode: 9
[2023-06-29 12:08:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.6514, current episode: 10
[2023-06-29 12:08:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 262500.000000 | iteration_262500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502464      | 6655.731940         | 6.655732             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2760.794867 | 1098.558650 | 3496.891113 | 1002.876038 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.9534, current episode: 1
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3516.1140, current episode: 2
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3534.2415, current episode: 3
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3557.2712, current episode: 4
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.4224, current episode: 5
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3513.2917, current episode: 6
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3542.5369, current episode: 7
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3531.6621, current episode: 8
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3492.1165, current episode: 9
[2023-06-29 12:08:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3544.7551, current episode: 10
[2023-06-29 12:08:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 263000.000000 | iteration_263000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487552      | 6722.451857         | 6.722452             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3528.336475 | 17.912587  | 3557.271240 | 3492.116455 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1737.4301, current episode: 1
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1982.7052, current episode: 2
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2504.3347, current episode: 3
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2922.6687, current episode: 4
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2920.0649, current episode: 5
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3022.3577, current episode: 6
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3049.9827, current episode: 7
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3127.0342, current episode: 8
[2023-06-29 12:08:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1737.4301, current episode: 8
[2023-06-29 12:08:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3602.1372, current episode: 9
[2023-06-29 12:08:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3582.1130, current episode: 10
[2023-06-29 12:08:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 263500.000000 | iteration_263500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507877      | 6631.842478         | 6.631842             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2845.082837 | 580.309636 | 3602.137207 | 1737.430054 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1903.1862, current episode: 1
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2387.7910, current episode: 2
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2441.5166, current episode: 3
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2457.1709, current episode: 4
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2858.5693, current episode: 5
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3186.3440, current episode: 6
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3236.3237, current episode: 7
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3407.8789, current episode: 8
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3697.7004, current episode: 9
[2023-06-29 12:09:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3613.2021, current episode: 10
[2023-06-29 12:09:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 264000.000000 | iteration_264000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497948      | 6675.801345         | 6.675801             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2918.968323 | 570.828333 | 3697.700439 | 1903.186157 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 957.7319, current episode: 1
[2023-06-29 12:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1006.0265, current episode: 2
[2023-06-29 12:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1010.7005, current episode: 3
[2023-06-29 12:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1090.3500, current episode: 4
[2023-06-29 12:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1177.1156, current episode: 5
[2023-06-29 12:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1176.1046, current episode: 6
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 957.7319, current episode: 6
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1006.0265, current episode: 6
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1010.7005, current episode: 6
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2096.2715, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1090.3500, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1177.1156, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1176.1046, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 957.7319, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1006.0265, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1010.7005, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1090.3500, current episode: 7
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3523.7161, current episode: 8
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1177.1156, current episode: 8
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1176.1046, current episode: 8
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3603.1172, current episode: 9
[2023-06-29 12:09:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3553.6152, current episode: 10
[2023-06-29 12:09:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 264500.000000 | iteration_264500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.537672      | 6503.337009         | 6.503337             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1919.474902 | 1117.419623 | 3603.117188 | 957.731873 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1026.8955, current episode: 1
[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2072.0679, current episode: 2
[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2099.9160, current episode: 3
[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1026.8955, current episode: 3
[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2506.5247, current episode: 4
[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3001.5886, current episode: 5
[2023-06-29 12:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1026.8955, current episode: 5
[2023-06-29 12:09:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3447.0610, current episode: 6
[2023-06-29 12:09:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3656.1814, current episode: 7
[2023-06-29 12:09:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3697.1321, current episode: 8
[2023-06-29 12:09:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3695.9094, current episode: 9
[2023-06-29 12:09:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3695.0366, current episode: 10
[2023-06-29 12:09:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 265000.000000 | iteration_265000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494658      | 6690.494475         | 6.690494             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2889.831323 | 881.492835 | 3697.132080 | 1026.895508 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1027.7555, current episode: 1
[2023-06-29 12:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1150.9592, current episode: 2
[2023-06-29 12:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1982.1292, current episode: 3
[2023-06-29 12:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1027.7555, current episode: 3
[2023-06-29 12:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1150.9592, current episode: 3
[2023-06-29 12:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2889.7017, current episode: 4
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1027.7555, current episode: 4
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3257.8323, current episode: 5
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1150.9592, current episode: 5
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3582.5276, current episode: 6
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3552.4407, current episode: 7
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3732.6172, current episode: 8
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3569.7146, current episode: 9
[2023-06-29 12:09:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3600.4072, current episode: 10
[2023-06-29 12:09:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 265500.000000 | iteration_265500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.526346      | 6551.593640         | 6.551594             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2834.608508 | 1000.808752 | 3732.617188 | 1027.755493 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 973.3226, current episode: 1
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 980.0658, current episode: 2
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1138.1523, current episode: 3
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1140.2145, current episode: 4
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1158.6614, current episode: 5
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1262.1063, current episode: 6
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1260.7600, current episode: 7
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1290.0310, current episode: 8
[2023-06-29 12:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1638.4371, current episode: 9
[2023-06-29 12:10:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 973.3226, current episode: 9
[2023-06-29 12:10:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 980.0658, current episode: 9
[2023-06-29 12:10:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2228.3196, current episode: 10
[2023-06-29 12:10:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 266000.000000 | iteration_266000.pth.tar | 10.000000     | 5979.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 597.900000              | 0.907908      | 6585.468867         | 11.014332            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1307.007062 | 354.919675 | 2228.319580 | 973.322571 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 12:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1924.2870, current episode: 1
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1939.9681, current episode: 2
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1973.3801, current episode: 3
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2252.4570, current episode: 4
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2801.2046, current episode: 5
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2843.5220, current episode: 6
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2823.1843, current episode: 7
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3484.1162, current episode: 8
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3568.5115, current episode: 9
[2023-06-29 12:10:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3610.7573, current episode: 10
[2023-06-29 12:10:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 266500.000000 | iteration_266500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487380      | 6723.229777         | 6.723230             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2722.138818 | 644.002609 | 3610.757324 | 1924.286987 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1984.3827, current episode: 1
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2139.6169, current episode: 2
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2545.2708, current episode: 3
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2649.2764, current episode: 4
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2656.6560, current episode: 5
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2650.4380, current episode: 6
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2677.3757, current episode: 7
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2724.9583, current episode: 8
[2023-06-29 12:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3562.0188, current episode: 9
[2023-06-29 12:10:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3634.4326, current episode: 10
[2023-06-29 12:10:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 267000.000000 | iteration_267000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.481162      | 6751.457679         | 6.751458             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2722.442615 | 496.923054 | 3634.432617 | 1984.382690 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1210.3430, current episode: 1
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1269.3087, current episode: 2
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1305.4080, current episode: 3
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1366.0265, current episode: 4
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1377.6510, current episode: 5
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1381.2394, current episode: 6
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1380.2108, current episode: 7
[2023-06-29 12:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1210.3430, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1269.3087, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1305.4080, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1366.0265, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1377.6510, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1381.2394, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1380.2108, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1210.3430, current episode: 7
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3489.3223, current episode: 8
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3580.7930, current episode: 9
[2023-06-29 12:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3501.1035, current episode: 10
[2023-06-29 12:10:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 267500.000000 | iteration_267500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523434      | 6564.117291         | 6.564117             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 1986.140613 | 1008.193840 | 3580.792969 | 1210.343018 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1663.3751, current episode: 1
[2023-06-29 12:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1663.3751, current episode: 1
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3594.0361, current episode: 2
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3705.7798, current episode: 3
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3600.5203, current episode: 4
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3583.4648, current episode: 5
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3539.1917, current episode: 6
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3562.0447, current episode: 7
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3549.5779, current episode: 8
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3589.7048, current episode: 9
[2023-06-29 12:11:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3619.7625, current episode: 10
[2023-06-29 12:11:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 268000.000000 | iteration_268000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.467338      | 6815.064020         | 6.815064             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3400.745764 | 580.789912 | 3705.779785 | 1663.375122 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1218.2107, current episode: 1
[2023-06-29 12:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1283.9467, current episode: 2
[2023-06-29 12:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1311.6105, current episode: 3
[2023-06-29 12:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1218.2107, current episode: 3
[2023-06-29 12:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1283.9467, current episode: 3
[2023-06-29 12:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1311.6105, current episode: 3
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1218.2107, current episode: 3
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3601.8276, current episode: 4
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3586.7537, current episode: 5
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3608.4497, current episode: 6
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3561.1306, current episode: 7
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3561.6829, current episode: 8
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3580.7126, current episode: 9
[2023-06-29 12:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3562.8875, current episode: 10
[2023-06-29 12:11:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 268500.000000 | iteration_268500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507741      | 6632.440618         | 6.632441             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2887.721240 | 1058.551760 | 3608.449707 | 1218.210693 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1038.1512, current episode: 1
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1043.8148, current episode: 2
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1055.0822, current episode: 3
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1053.9641, current episode: 4
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1180.6630, current episode: 5
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1188.2439, current episode: 6
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1296.5094, current episode: 7
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1337.8538, current episode: 8
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1038.1512, current episode: 8
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1043.8148, current episode: 8
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1055.0822, current episode: 8
[2023-06-29 12:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1053.9641, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1180.6630, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1188.2439, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1296.5094, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1337.8538, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1038.1512, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1043.8148, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1055.0822, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1053.9641, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1180.6630, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1188.2439, current episode: 8
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3633.9956, current episode: 9
[2023-06-29 12:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3661.6455, current episode: 10
[2023-06-29 12:11:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 269000.000000 | iteration_269000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.527576      | 6546.320492         | 6.546320             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 1648.992346 | 1004.481871 | 3661.645508 | 1038.151245 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1362.3997, current episode: 1
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1388.2129, current episode: 2
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1385.9937, current episode: 3
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1580.3245, current episode: 4
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1617.2040, current episode: 5
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1362.3997, current episode: 5
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1388.2129, current episode: 5
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1385.9937, current episode: 5
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2832.2598, current episode: 6
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1580.3245, current episode: 6
[2023-06-29 12:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1617.2040, current episode: 6
[2023-06-29 12:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3661.2078, current episode: 7
[2023-06-29 12:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3613.8975, current episode: 8
[2023-06-29 12:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3659.6392, current episode: 9
[2023-06-29 12:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3806.8457, current episode: 10
[2023-06-29 12:11:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 269500.000000 | iteration_269500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491663      | 6703.925610         | 6.703926             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2490.798450 | 1055.825588 | 3806.845703 | 1362.399658 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:12:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1256.0347, current episode: 1
[2023-06-29 12:12:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1256.0347, current episode: 1
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1256.0347, current episode: 1
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3597.2219, current episode: 2
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3584.8816, current episode: 3
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3583.4832, current episode: 4
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.8955, current episode: 5
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3583.4836, current episode: 6
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3581.8564, current episode: 7
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3598.1187, current episode: 8
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3543.9863, current episode: 9
[2023-06-29 12:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3582.1538, current episode: 10
[2023-06-29 12:12:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 270000.000000 | iteration_270000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496926      | 6680.357376         | 6.680357             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3346.311572 | 696.956237 | 3598.118652 | 1256.034668 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:12:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1380.3694, current episode: 1
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1455.7285, current episode: 2
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1465.0623, current episode: 3
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1502.0400, current episode: 4
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1570.3346, current episode: 5
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1680.0602, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1380.3694, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1455.7285, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1465.0623, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1502.0400, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1570.3346, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1680.0602, current episode: 6
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3556.5964, current episode: 7
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3551.8005, current episode: 8
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.6445, current episode: 9
[2023-06-29 12:12:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3574.6077, current episode: 10
[2023-06-29 12:12:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 270500.000000 | iteration_270500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541603      | 6486.753230         | 6.486753             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2332.024414 | 1010.804851 | 3583.644531 | 1380.369385 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1724.2568, current episode: 1
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1719.8411, current episode: 2
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1724.2568, current episode: 2
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1719.8411, current episode: 2
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3614.9309, current episode: 3
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3562.0820, current episode: 4
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3561.0432, current episode: 5
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3542.8953, current episode: 6
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3585.3181, current episode: 7
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3531.5911, current episode: 8
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3561.1948, current episode: 9
[2023-06-29 12:12:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3610.9353, current episode: 10
[2023-06-29 12:12:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 271000.000000 | iteration_271000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522369      | 6568.708028         | 6.568708             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3201.408862 | 740.109528 | 3614.930908 | 1719.841064 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3559.9023, current episode: 1
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3574.5535, current episode: 2
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3571.8469, current episode: 3
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3588.2703, current episode: 4
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3567.5654, current episode: 5
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3566.0686, current episode: 6
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3545.6294, current episode: 7
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3574.4084, current episode: 8
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3568.4417, current episode: 9
[2023-06-29 12:12:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3556.9534, current episode: 10
[2023-06-29 12:12:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 271500.000000 | iteration_271500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494028      | 6693.313003         | 6.693313             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3567.363989 | 10.944458  | 3588.270264 | 3545.629395 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:13:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1665.1392, current episode: 1
[2023-06-29 12:13:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1975.6250, current episode: 2
[2023-06-29 12:13:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2432.0833, current episode: 3
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3009.8696, current episode: 4
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1665.1392, current episode: 4
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3566.6025, current episode: 5
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3520.3726, current episode: 6
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3534.1548, current episode: 7
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3567.4985, current episode: 8
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3558.7031, current episode: 9
[2023-06-29 12:13:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3546.7732, current episode: 10
[2023-06-29 12:13:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 272000.000000 | iteration_272000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498671      | 6672.578480         | 6.672578             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3037.682178 | 703.557890 | 3567.498535 | 1665.139160 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3550.8574, current episode: 1
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3577.4990, current episode: 2
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3493.4690, current episode: 3
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3473.7598, current episode: 4
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3542.0669, current episode: 5
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3606.1370, current episode: 6
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3505.2859, current episode: 7
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3595.1353, current episode: 8
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3565.0178, current episode: 9
[2023-06-29 12:13:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3515.2061, current episode: 10
[2023-06-29 12:13:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 272500.000000 | iteration_272500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478411      | 6764.020563         | 6.764021             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3542.443408 | 42.286201  | 3606.136963 | 3473.759766 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:13:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1551.0709, current episode: 1
[2023-06-29 12:13:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1551.0709, current episode: 1
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3463.7922, current episode: 2
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3599.1885, current episode: 3
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3597.0242, current episode: 4
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3571.1528, current episode: 5
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3588.0557, current episode: 6
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3454.9934, current episode: 7
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3549.9292, current episode: 8
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3589.8931, current episode: 9
[2023-06-29 12:13:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3475.0537, current episode: 10
[2023-06-29 12:13:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 273000.000000 | iteration_273000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512982      | 6609.464783         | 6.609465             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3344.015369 | 600.134457 | 3599.188477 | 1551.070923 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:13:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2091.7327, current episode: 1
[2023-06-29 12:13:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2191.9880, current episode: 2
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3580.7864, current episode: 3
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3545.3213, current episode: 4
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.9939, current episode: 5
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3514.9202, current episode: 6
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3564.3079, current episode: 7
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.5356, current episode: 8
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3581.0513, current episode: 9
[2023-06-29 12:13:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3594.5935, current episode: 10
[2023-06-29 12:13:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 273500.000000 | iteration_273500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.489757      | 6712.503759         | 6.712504             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3278.623071 | 569.212536 | 3594.593506 | 2091.732666 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3568.6643, current episode: 1
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3569.9504, current episode: 2
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3510.5352, current episode: 3
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.8806, current episode: 4
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3538.9241, current episode: 5
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3563.3530, current episode: 6
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3597.2083, current episode: 7
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3579.7336, current episode: 8
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3561.6985, current episode: 9
[2023-06-29 12:14:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3601.3840, current episode: 10
[2023-06-29 12:14:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 274000.000000 | iteration_274000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505286      | 6643.254708         | 6.643255             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3563.733203 | 25.740382  | 3601.384033 | 3510.535156 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3584.4377, current episode: 1
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3588.0339, current episode: 2
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.3623, current episode: 3
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3597.7834, current episode: 4
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3606.1697, current episode: 5
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3587.0833, current episode: 6
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3612.7070, current episode: 7
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3571.7842, current episode: 8
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3586.0291, current episode: 9
[2023-06-29 12:14:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3587.7380, current episode: 10
[2023-06-29 12:14:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 274500.000000 | iteration_274500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478243      | 6764.788582         | 6.764789             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3590.412866 | 11.359103  | 3612.707031 | 3571.784180 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.9507, current episode: 1
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3587.9087, current episode: 2
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3576.0688, current episode: 3
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3564.5588, current episode: 4
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3586.9458, current episode: 5
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3579.1458, current episode: 6
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3536.3149, current episode: 7
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.3342, current episode: 8
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3592.7529, current episode: 9
[2023-06-29 12:14:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3594.8054, current episode: 10
[2023-06-29 12:14:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 275000.000000 | iteration_275000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491042      | 6706.717582         | 6.706718             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3575.578613 | 17.747744  | 3594.805420 | 3536.314941 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3570.6050, current episode: 1
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3565.8223, current episode: 2
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.5149, current episode: 3
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3569.3857, current episode: 4
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3576.1853, current episode: 5
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3570.9524, current episode: 6
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3566.0471, current episode: 7
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3545.1047, current episode: 8
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3570.6724, current episode: 9
[2023-06-29 12:14:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3565.6831, current episode: 10
[2023-06-29 12:14:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 275500.000000 | iteration_275500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512127      | 6613.200277         | 6.613200             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3566.897290 | 7.859938   | 3576.185303 | 3545.104736 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3622.0891, current episode: 1
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3578.7156, current episode: 2
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3572.3113, current episode: 3
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3587.9126, current episode: 4
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3588.3694, current episode: 5
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3575.1174, current episode: 6
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3566.1550, current episode: 7
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3590.0627, current episode: 8
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3575.7361, current episode: 9
[2023-06-29 12:15:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3592.1804, current episode: 10
[2023-06-29 12:15:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 276000.000000 | iteration_276000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522352      | 6568.784929         | 6.568785             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3584.864966 | 14.871320  | 3622.089111 | 3566.155029 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.8748, current episode: 1
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3574.3784, current episode: 2
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3532.7915, current episode: 3
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3610.4526, current episode: 4
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3582.7532, current episode: 5
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3564.9441, current episode: 6
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3630.2954, current episode: 7
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.2710, current episode: 8
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3581.1038, current episode: 9
[2023-06-29 12:15:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3566.3733, current episode: 10
[2023-06-29 12:15:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 276500.000000 | iteration_276500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493822      | 6694.238452         | 6.694238             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3577.523804 | 25.483179  | 3630.295410 | 3532.791504 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:15:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2535.8176, current episode: 1
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3557.4075, current episode: 2
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3647.2029, current episode: 3
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3555.4219, current episode: 4
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.2446, current episode: 5
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3525.6455, current episode: 6
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3541.0996, current episode: 7
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.6821, current episode: 8
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3531.2727, current episode: 9
[2023-06-29 12:15:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3522.7717, current episode: 10
[2023-06-29 12:15:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 277000.000000 | iteration_277000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.490144      | 6710.762295         | 6.710762             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3451.756616 | 307.167019 | 3647.202881 | 2535.817627 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3556.0354, current episode: 1
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3558.0940, current episode: 2
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3553.5591, current episode: 3
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3563.9521, current episode: 4
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3546.7202, current episode: 5
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3552.3528, current episode: 6
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3564.1890, current episode: 7
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3555.1558, current episode: 8
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3566.0950, current episode: 9
[2023-06-29 12:15:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3558.5745, current episode: 10
[2023-06-29 12:15:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 277500.000000 | iteration_277500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.460073      | 6848.970911         | 6.848971             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3557.472778 | 5.723765   | 3566.094971 | 3546.720215 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3532.0139, current episode: 1
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3560.5759, current episode: 2
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3571.1672, current episode: 3
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3563.3264, current episode: 4
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3559.6714, current episode: 5
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3567.1348, current episode: 6
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3495.3511, current episode: 7
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.2588, current episode: 8
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3552.9062, current episode: 9
[2023-06-29 12:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3570.9404, current episode: 10
[2023-06-29 12:16:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 278000.000000 | iteration_278000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486103      | 6729.008013         | 6.729008             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3550.534619 | 22.789199  | 3571.167236 | 3495.351074 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:16:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1902.5071, current episode: 1
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1902.5071, current episode: 1
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3566.6697, current episode: 2
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3595.6550, current episode: 3
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3564.9363, current episode: 4
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3569.4900, current episode: 5
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3562.2615, current episode: 6
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3577.9607, current episode: 7
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3575.3894, current episode: 8
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.4302, current episode: 9
[2023-06-29 12:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3581.3235, current episode: 10
[2023-06-29 12:16:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 278500.000000 | iteration_278500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483570      | 6740.496164         | 6.740496             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3406.462329 | 501.404537 | 3595.655029 | 1902.507080 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1521.0510, current episode: 1
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1531.2566, current episode: 2
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1677.1250, current episode: 3
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1816.6378, current episode: 4
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2013.7889, current episode: 5
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2080.5710, current episode: 6
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2268.6392, current episode: 7
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1521.0510, current episode: 7
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1531.2566, current episode: 7
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1677.1250, current episode: 7
[2023-06-29 12:16:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1816.6378, current episode: 7
[2023-06-29 12:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3639.8162, current episode: 8
[2023-06-29 12:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3610.5276, current episode: 9
[2023-06-29 12:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3606.7078, current episode: 10
[2023-06-29 12:16:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 279000.000000 | iteration_279000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492892      | 6698.408883         | 6.698409             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2376.612109 | 843.313137 | 3639.816162 | 1521.051025 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1609.9597, current episode: 1
[2023-06-29 12:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1771.0535, current episode: 2
[2023-06-29 12:16:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1774.4629, current episode: 3
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2107.4336, current episode: 4
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2206.2295, current episode: 5
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2553.8047, current episode: 6
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2598.7065, current episode: 7
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2663.9116, current episode: 8
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2883.4485, current episode: 9
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1609.9597, current episode: 9
[2023-06-29 12:16:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3362.8110, current episode: 10
[2023-06-29 12:16:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 279500.000000 | iteration_279500.pth.tar | 10.000000     | 8930.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 893.000000              | 1.358387      | 6573.975348         | 7.361675             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2353.182153 | 529.695584 | 3362.811035 | 1609.959717 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1134.2640, current episode: 1
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1143.8521, current episode: 2
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1186.1245, current episode: 3
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1212.9545, current episode: 4
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1224.9012, current episode: 5
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1228.5671, current episode: 6
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1268.4359, current episode: 7
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1271.3262, current episode: 8
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1318.3551, current episode: 9
[2023-06-29 12:17:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1463.2809, current episode: 10
[2023-06-29 12:17:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 280000.000000 | iteration_280000.pth.tar | 10.000000     | 3860.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 386.000000              | 0.593029      | 6508.962011         | 16.862596            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1245.206152 | 90.515191  | 1463.280884 | 1134.264038 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1689.4211, current episode: 1
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1696.9061, current episode: 2
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1722.5179, current episode: 3
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2334.7646, current episode: 4
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2840.2068, current episode: 5
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3347.7156, current episode: 6
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1689.4211, current episode: 6
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1696.9061, current episode: 6
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1722.5179, current episode: 6
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3578.5945, current episode: 7
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3604.5664, current episode: 8
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3578.5581, current episode: 9
[2023-06-29 12:17:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3551.3589, current episode: 10
[2023-06-29 12:17:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 280500.000000 | iteration_280500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498592      | 6672.928511         | 6.672929             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2794.461011 | 809.514948 | 3604.566406 | 1689.421143 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:17:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2086.4121, current episode: 1
[2023-06-29 12:17:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2346.0371, current episode: 2
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3652.5991, current episode: 3
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3611.6274, current episode: 4
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3555.8862, current episode: 5
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3563.8127, current episode: 6
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3622.4832, current episode: 7
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3594.7100, current episode: 8
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3589.8738, current episode: 9
[2023-06-29 12:17:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3567.2891, current episode: 10
[2023-06-29 12:17:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 281000.000000 | iteration_281000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495454      | 6686.932076         | 6.686932             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3319.073071 | 555.160812 | 3652.599121 | 2086.412109 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3531.6509, current episode: 1
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3532.9412, current episode: 2
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3544.7141, current episode: 3
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.5059, current episode: 4
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3547.8035, current episode: 5
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3536.8159, current episode: 6
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3547.8030, current episode: 7
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3554.1064, current episode: 8
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3545.1902, current episode: 9
[2023-06-29 12:17:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3530.9163, current episode: 10
[2023-06-29 12:17:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 281500.000000 | iteration_281500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479398      | 6759.504233         | 6.759504             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3541.344727 | 7.525328   | 3554.106445 | 3530.916260 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.9438, current episode: 1
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3578.0112, current episode: 2
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3569.8289, current episode: 3
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3550.4089, current episode: 4
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3563.2527, current episode: 5
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3551.8613, current episode: 6
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3536.8230, current episode: 7
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3555.2678, current episode: 8
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3545.7939, current episode: 9
[2023-06-29 12:18:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.4656, current episode: 10
[2023-06-29 12:18:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 282000.000000 | iteration_282000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508529      | 6628.973551         | 6.628974             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3556.965723 | 11.470598  | 3578.011230 | 3536.822998 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3589.7109, current episode: 1
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3594.1877, current episode: 2
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3591.8381, current episode: 3
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3575.7261, current episode: 4
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3600.6030, current episode: 5
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3591.5823, current episode: 6
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3602.3279, current episode: 7
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3582.8374, current episode: 8
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3591.4861, current episode: 9
[2023-06-29 12:18:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3589.0764, current episode: 10
[2023-06-29 12:18:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 282500.000000 | iteration_282500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.477277      | 6769.212972         | 6.769213             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3590.937598 | 7.329545   | 3602.327881 | 3575.726074 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3578.4995, current episode: 1
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3561.6064, current episode: 2
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3578.4333, current episode: 3
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3588.7188, current episode: 4
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3586.4480, current episode: 5
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3579.6506, current episode: 6
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3582.7012, current episode: 7
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3574.9695, current episode: 8
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3578.8989, current episode: 9
[2023-06-29 12:18:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3596.1230, current episode: 10
[2023-06-29 12:18:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 283000.000000 | iteration_283000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.465654      | 6822.891902         | 6.822892             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3580.604932 | 8.665172   | 3596.123047 | 3561.606445 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:19:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3586.8916, current episode: 1
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3580.9858, current episode: 2
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3572.2690, current episode: 3
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3576.1667, current episode: 4
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3590.9771, current episode: 5
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3597.9836, current episode: 6
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3577.4382, current episode: 7
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3579.2495, current episode: 8
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3579.2063, current episode: 9
[2023-06-29 12:19:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3588.0850, current episode: 10
[2023-06-29 12:19:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 283500.000000 | iteration_283500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494114      | 6692.928021         | 6.692928             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3582.925293 | 7.445694   | 3597.983643 | 3572.269043 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3579.1008, current episode: 1
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3567.7810, current episode: 2
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3570.3093, current episode: 3
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3565.2837, current episode: 4
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3573.9565, current episode: 5
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3578.9163, current episode: 6
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3556.7739, current episode: 7
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3569.9607, current episode: 8
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3567.6914, current episode: 9
[2023-06-29 12:19:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3571.9817, current episode: 10
[2023-06-29 12:19:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 284000.000000 | iteration_284000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523446      | 6564.064694         | 6.564065             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3570.175537 | 6.237959   | 3579.100830 | 3556.773926 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3547.4932, current episode: 1
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3548.5723, current episode: 2
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3561.4138, current episode: 3
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.4263, current episode: 4
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3568.6470, current episode: 5
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3616.6548, current episode: 6
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.4541, current episode: 7
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3566.1013, current episode: 8
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3555.9988, current episode: 9
[2023-06-29 12:19:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3550.9536, current episode: 10
[2023-06-29 12:19:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 284500.000000 | iteration_284500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.468518      | 6809.586521         | 6.809587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3564.571509 | 18.945172  | 3616.654785 | 3547.493164 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3559.0347, current episode: 1
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3561.4341, current episode: 2
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3570.6050, current episode: 3
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3557.4749, current episode: 4
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3558.6316, current episode: 5
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3579.3088, current episode: 6
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3576.4275, current episode: 7
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3573.9434, current episode: 8
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3567.9280, current episode: 9
[2023-06-29 12:19:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3573.9783, current episode: 10
[2023-06-29 12:19:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 285000.000000 | iteration_285000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516598      | 6593.707147         | 6.593707             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3567.876611 | 7.737240   | 3579.308838 | 3557.474854 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:20:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3545.2703, current episode: 1
[2023-06-29 12:20:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3559.0374, current episode: 2
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3562.7822, current episode: 3
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3561.0459, current episode: 4
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3553.2336, current episode: 5
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3546.6033, current episode: 6
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3548.4246, current episode: 7
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3557.9160, current episode: 8
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3554.4495, current episode: 9
[2023-06-29 12:20:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3557.4341, current episode: 10
[2023-06-29 12:20:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 285500.000000 | iteration_285500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499462      | 6669.059561         | 6.669060             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3554.619678 | 5.815754   | 3562.782227 | 3545.270264 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1300.9207, current episode: 1
[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1333.5410, current episode: 2
[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1333.7183, current episode: 3
[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1340.4767, current episode: 4
[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1349.6984, current episode: 5
[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1361.2585, current episode: 6
[2023-06-29 12:20:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1376.2255, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1300.9207, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1333.5410, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1333.7183, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1340.4767, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1349.6984, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1361.2585, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1376.2255, current episode: 7
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3502.1340, current episode: 8
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3510.6973, current episode: 9
[2023-06-29 12:20:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3512.9272, current episode: 10
[2023-06-29 12:20:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 286000.000000 | iteration_286000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516913      | 6592.334978         | 6.592335             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1992.159753 | 992.910189 | 3512.927246 | 1300.920654 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1349.0436, current episode: 1
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1342.5266, current episode: 2
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1358.4670, current episode: 3
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1374.4078, current episode: 4
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1367.7852, current episode: 5
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1382.9916, current episode: 6
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1415.5712, current episode: 7
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1426.6295, current episode: 8
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1429.6091, current episode: 9
[2023-06-29 12:20:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1538.5863, current episode: 10
[2023-06-29 12:20:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 286500.000000 | iteration_286500.pth.tar | 10.000000     | 4310.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 431.000000              | 0.662541      | 6505.262429         | 15.093416            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1398.561792 | 55.335836  | 1538.586304 | 1342.526611 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3552.3074, current episode: 1
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3581.6165, current episode: 2
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.1079, current episode: 3
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3571.5374, current episode: 4
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3593.3435, current episode: 5
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3551.9888, current episode: 6
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3581.7112, current episode: 7
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3581.6658, current episode: 8
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3554.3896, current episode: 9
[2023-06-29 12:20:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3567.7031, current episode: 10
[2023-06-29 12:20:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 287000.000000 | iteration_287000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487339      | 6723.414628         | 6.723415             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3570.437109 | 13.577659  | 3593.343506 | 3551.988770 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3546.3621, current episode: 1
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3542.5510, current episode: 2
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3554.2144, current episode: 3
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3544.1030, current episode: 4
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3571.2024, current episode: 5
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3540.9368, current episode: 6
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3555.6514, current episode: 7
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3546.4314, current episode: 8
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3531.9075, current episode: 9
[2023-06-29 12:21:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3545.5769, current episode: 10
[2023-06-29 12:21:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 287500.000000 | iteration_287500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476953      | 6770.695583         | 6.770696             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3547.893677 | 10.000754  | 3571.202393 | 3531.907471 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3570.7202, current episode: 1
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3544.2104, current episode: 2
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3586.2236, current episode: 3
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3564.5984, current episode: 4
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3593.1692, current episode: 5
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3576.8044, current episode: 6
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3556.9666, current episode: 7
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3585.6133, current episode: 8
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3604.7249, current episode: 9
[2023-06-29 12:21:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3592.0615, current episode: 10
[2023-06-29 12:21:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 288000.000000 | iteration_288000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520071      | 6578.638297         | 6.578638             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3577.509253 | 17.559607  | 3604.724854 | 3544.210449 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.3987, current episode: 1
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3524.5486, current episode: 2
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3542.3076, current episode: 3
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3555.1184, current episode: 4
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3560.6694, current episode: 5
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3544.5933, current episode: 6
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3540.4463, current episode: 7
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.0676, current episode: 8
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.3940, current episode: 9
[2023-06-29 12:21:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3538.6370, current episode: 10
[2023-06-29 12:21:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 288500.000000 | iteration_288500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488020      | 6720.340243         | 6.720340             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3542.218091 | 11.143629  | 3560.669434 | 3524.548584 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.8591, current episode: 1
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3493.6135, current episode: 2
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3512.8074, current episode: 3
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.0269, current episode: 4
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3505.6934, current episode: 5
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3522.2371, current episode: 6
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3511.4219, current episode: 7
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3521.7468, current episode: 8
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3501.5071, current episode: 9
[2023-06-29 12:21:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3518.1748, current episode: 10
[2023-06-29 12:21:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 289000.000000 | iteration_289000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.474927      | 6779.997683         | 6.779998             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3512.108789 | 8.806883   | 3522.237061 | 3493.613525 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1436.1025, current episode: 1
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1443.9363, current episode: 2
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1595.3140, current episode: 3
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1656.5143, current episode: 4
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1651.7787, current episode: 5
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1649.1281, current episode: 6
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1737.1102, current episode: 7
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1721.8566, current episode: 8
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1785.1986, current episode: 9
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1436.1025, current episode: 9
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1443.9363, current episode: 9
[2023-06-29 12:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1595.3140, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1656.5143, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1651.7787, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1649.1281, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1737.1102, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1721.8566, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1785.1986, current episode: 9
[2023-06-29 12:22:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3598.3855, current episode: 10
[2023-06-29 12:22:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 289500.000000 | iteration_289500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.615573      | 6189.753419         | 6.189753             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1827.532471 | 600.275753 | 3598.385498 | 1436.102539 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1382.5760, current episode: 1
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1475.3577, current episode: 2
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1481.3573, current episode: 3
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1535.7500, current episode: 4
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1569.8599, current episode: 5
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1602.5911, current episode: 6
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1621.2677, current episode: 7
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1879.7400, current episode: 8
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1914.8340, current episode: 9
[2023-06-29 12:22:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2162.9204, current episode: 10
[2023-06-29 12:22:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 290000.000000 | iteration_290000.pth.tar | 10.000000     | 5740.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 574.000000              | 0.864380      | 6640.600192         | 11.568990            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1662.625403 | 231.822210 | 2162.920410 | 1382.576050 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1936.0061, current episode: 1
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1980.3004, current episode: 2
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1960.8890, current episode: 3
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1995.2178, current episode: 4
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2022.5775, current episode: 5
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2019.1056, current episode: 6
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2109.9055, current episode: 7
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2164.5874, current episode: 8
[2023-06-29 12:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2813.2507, current episode: 9
[2023-06-29 12:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3042.7673, current episode: 10
[2023-06-29 12:22:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 290500.000000 | iteration_290500.pth.tar | 10.000000     | 8240.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 824.000000              | 1.227208      | 6714.426152         | 8.148575             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2204.460742 | 371.049505 | 3042.767334 | 1936.006104 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1911.7754, current episode: 1
[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1975.9824, current episode: 2
[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2051.2063, current episode: 3
[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2135.1248, current episode: 4
[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2130.8284, current episode: 5
[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2972.6187, current episode: 6
[2023-06-29 12:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3369.7830, current episode: 7
[2023-06-29 12:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3562.1030, current episode: 8
[2023-06-29 12:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3587.6196, current episode: 9
[2023-06-29 12:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3541.4707, current episode: 10
[2023-06-29 12:22:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 291000.000000 | iteration_291000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484691      | 6735.410277         | 6.735410             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2723.851221 | 704.689836 | 3587.619629 | 1911.775391 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3023.3743, current episode: 1
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3537.7466, current episode: 2
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3552.2458, current episode: 3
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.4158, current episode: 4
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3565.0798, current episode: 5
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3565.4670, current episode: 6
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3554.7959, current episode: 7
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3551.7612, current episode: 8
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3564.0740, current episode: 9
[2023-06-29 12:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3566.2229, current episode: 10
[2023-06-29 12:23:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 291500.000000 | iteration_291500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498553      | 6673.103540         | 6.673104             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3506.318335 | 161.373402 | 3582.415771 | 3023.374268 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3584.0510, current episode: 1
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3541.5405, current episode: 2
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.9553, current episode: 3
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3561.9265, current episode: 4
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.0732, current episode: 5
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3553.1072, current episode: 6
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.9961, current episode: 7
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.2441, current episode: 8
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3534.9348, current episode: 9
[2023-06-29 12:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3573.0676, current episode: 10
[2023-06-29 12:23:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 292000.000000 | iteration_292000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486658      | 6726.497350         | 6.726497             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3551.589648 | 16.933390  | 3584.051025 | 3532.244141 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3541.7407, current episode: 1
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3569.4829, current episode: 2
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.7585, current episode: 3
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.8723, current episode: 4
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3556.5217, current episode: 5
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3539.5515, current episode: 6
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3578.3772, current episode: 7
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3530.0691, current episode: 8
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3533.8733, current episode: 9
[2023-06-29 12:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3536.7673, current episode: 10
[2023-06-29 12:23:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 292500.000000 | iteration_292500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503173      | 6652.594869         | 6.652595             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3546.901465 | 15.141461  | 3578.377197 | 3530.069092 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.3257, current episode: 1
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3562.2246, current episode: 2
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.9521, current episode: 3
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3530.6387, current episode: 4
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3568.0483, current episode: 5
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3573.2122, current episode: 6
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3561.0576, current episode: 7
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.0476, current episode: 8
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3567.6367, current episode: 9
[2023-06-29 12:23:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3570.6631, current episode: 10
[2023-06-29 12:23:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 293000.000000 | iteration_293000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486102      | 6729.012434         | 6.729012             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3562.380664 | 11.883975  | 3573.212158 | 3530.638672 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3622.1426, current episode: 1
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3601.7400, current episode: 2
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3605.3232, current episode: 3
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3573.4023, current episode: 4
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3589.0188, current episode: 5
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3575.9604, current episode: 6
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3608.3020, current episode: 7
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.9856, current episode: 8
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3623.1697, current episode: 9
[2023-06-29 12:24:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3603.4238, current episode: 10
[2023-06-29 12:24:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 293500.000000 | iteration_293500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506675      | 6637.133368         | 6.637133             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3597.146851 | 18.508238  | 3623.169678 | 3568.985596 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3606.5098, current episode: 1
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3625.9253, current episode: 2
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3593.8860, current episode: 3
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3592.7219, current episode: 4
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3631.9675, current episode: 5
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3622.5068, current episode: 6
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3604.5312, current episode: 7
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3606.8655, current episode: 8
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3595.6948, current episode: 9
[2023-06-29 12:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3596.3965, current episode: 10
[2023-06-29 12:24:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 294000.000000 | iteration_294000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499275      | 6669.891968         | 6.669892             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3607.700537 | 13.562943  | 3631.967529 | 3592.721924 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:24:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1728.9282, current episode: 1
[2023-06-29 12:24:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1740.3848, current episode: 2
[2023-06-29 12:24:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2174.7668, current episode: 3
[2023-06-29 12:24:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2226.4158, current episode: 4
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3070.2778, current episode: 5
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3253.6118, current episode: 6
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3416.3997, current episode: 7
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1728.9282, current episode: 7
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1740.3848, current episode: 7
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3666.8228, current episode: 8
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3797.8418, current episode: 9
[2023-06-29 12:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3763.1475, current episode: 10
[2023-06-29 12:24:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 294500.000000 | iteration_294500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495233      | 6687.921827         | 6.687922             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2883.859692 | 790.762630 | 3797.841797 | 1728.928223 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3595.7869, current episode: 1
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3594.1492, current episode: 2
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3595.6335, current episode: 3
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3608.5046, current episode: 4
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3549.6040, current episode: 5
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3603.8972, current episode: 6
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3582.0515, current episode: 7
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.8728, current episode: 8
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3553.2336, current episode: 9
[2023-06-29 12:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3573.9365, current episode: 10
[2023-06-29 12:24:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 295000.000000 | iteration_295000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.482407      | 6745.786930         | 6.745787             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3582.566992 | 19.536305  | 3608.504639 | 3549.604004 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:25:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2692.9575, current episode: 1
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3596.0444, current episode: 2
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3591.8777, current episode: 3
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3573.9983, current episode: 4
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3574.4727, current episode: 5
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3598.0005, current episode: 6
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3582.2202, current episode: 7
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3625.6985, current episode: 8
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3599.0159, current episode: 9
[2023-06-29 12:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3569.0986, current episode: 10
[2023-06-29 12:25:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 295500.000000 | iteration_295500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491804      | 6703.295310         | 6.703295             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3500.338428 | 269.582551 | 3625.698486 | 2692.957520 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3575.2297, current episode: 1
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3576.1201, current episode: 2
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3588.7908, current episode: 3
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3623.6726, current episode: 4
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3594.3125, current episode: 5
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3580.6550, current episode: 6
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3624.7542, current episode: 7
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3624.7341, current episode: 8
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3505.1721, current episode: 9
[2023-06-29 12:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3571.8213, current episode: 10
[2023-06-29 12:25:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 296000.000000 | iteration_296000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483691      | 6739.949355         | 6.739949             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3586.526245 | 33.870224  | 3624.754150 | 3505.172119 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3520.9431, current episode: 1
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3524.7424, current episode: 2
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3495.7966, current episode: 3
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3511.5896, current episode: 4
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3506.6851, current episode: 5
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3522.9041, current episode: 6
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3562.7161, current episode: 7
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3541.6152, current episode: 8
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3539.4004, current episode: 9
[2023-06-29 12:25:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.9910, current episode: 10
[2023-06-29 12:25:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 296500.000000 | iteration_296500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484322      | 6737.084219         | 6.737084             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3525.638354 | 18.209349  | 3562.716064 | 3495.796631 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3595.1538, current episode: 1
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3596.7131, current episode: 2
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3580.2847, current episode: 3
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3556.8381, current episode: 4
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3589.9348, current episode: 5
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.8203, current episode: 6
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3580.7056, current episode: 7
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3567.0547, current episode: 8
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3581.3103, current episode: 9
[2023-06-29 12:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3572.6135, current episode: 10
[2023-06-29 12:25:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 297000.000000 | iteration_297000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493633      | 6695.083723         | 6.695084             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3580.642896 | 11.825054  | 3596.713135 | 3556.838135 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.4001, current episode: 1
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3567.4211, current episode: 2
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3559.6995, current episode: 3
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3566.5420, current episode: 4
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3577.4426, current episode: 5
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3566.2676, current episode: 6
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3565.5325, current episode: 7
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3551.8701, current episode: 8
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3563.5862, current episode: 9
[2023-06-29 12:26:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3567.4131, current episode: 10
[2023-06-29 12:26:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 297500.000000 | iteration_297500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492242      | 6701.324534         | 6.701325             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3563.917480 | 7.043425   | 3577.442627 | 3551.870117 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3536.4512, current episode: 1
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3543.7500, current episode: 2
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3527.0613, current episode: 3
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3561.4343, current episode: 4
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3552.8689, current episode: 5
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3521.5776, current episode: 6
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3525.9341, current episode: 7
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3610.2725, current episode: 8
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3557.4663, current episode: 9
[2023-06-29 12:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3614.0212, current episode: 10
[2023-06-29 12:26:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 298000.000000 | iteration_298000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.480594      | 6754.047709         | 6.754048             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3555.083740 | 31.310672  | 3614.021240 | 3521.577637 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1495.8116, current episode: 1
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1540.7410, current episode: 2
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1616.1409, current episode: 3
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1617.1840, current episode: 4
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1636.9688, current episode: 5
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1684.3125, current episode: 6
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1681.6783, current episode: 7
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1667.3967, current episode: 8
[2023-06-29 12:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1922.6830, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1495.8116, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1540.7410, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1616.1409, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1617.1840, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1636.9688, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1684.3125, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1681.6783, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1667.3967, current episode: 9
[2023-06-29 12:26:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3682.4133, current episode: 10
[2023-06-29 12:26:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 298500.000000 | iteration_298500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528190      | 6543.690758         | 6.543691             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1854.533008 | 618.652623 | 3682.413330 | 1495.811646 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2412.6978, current episode: 1
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2696.3137, current episode: 2
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2954.2561, current episode: 3
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3712.0122, current episode: 4
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.1589, current episode: 5
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.8994, current episode: 6
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.5337, current episode: 7
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3560.8796, current episode: 8
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3599.2483, current episode: 9
[2023-06-29 12:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3594.6143, current episode: 10
[2023-06-29 12:26:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 299000.000000 | iteration_299000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.481894      | 6747.444311         | 6.748119             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3324.761401 | 436.169059 | 3712.012207 | 2412.697754 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1300.5072, current episode: 1
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1353.6583, current episode: 2
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1386.3745, current episode: 3
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1396.6555, current episode: 4
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1885.4974, current episode: 5
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1941.0793, current episode: 6
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1300.5072, current episode: 6
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1353.6583, current episode: 6
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1386.3745, current episode: 6
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1396.6555, current episode: 6
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2893.3074, current episode: 7
[2023-06-29 12:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3046.8521, current episode: 8
[2023-06-29 12:27:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1885.4974, current episode: 8
[2023-06-29 12:27:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3611.0129, current episode: 9
[2023-06-29 12:27:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3580.5776, current episode: 10
[2023-06-29 12:27:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 299500.000000 | iteration_299500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.532385      | 6525.777218         | 6.525777             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2239.552234 | 898.767152 | 3611.012939 | 1300.507202 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1386.2152, current episode: 1
[2023-06-29 12:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2180.7625, current episode: 2
[2023-06-29 12:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2285.2480, current episode: 3
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1386.2152, current episode: 3
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3005.1465, current episode: 4
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3067.1672, current episode: 5
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3459.3140, current episode: 6
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3556.9736, current episode: 7
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3531.3179, current episode: 8
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3619.2686, current episode: 9
[2023-06-29 12:27:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3578.2375, current episode: 10
[2023-06-29 12:27:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 300000.000000 | iteration_300000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478739      | 6762.518543         | 6.762519             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2966.965100 | 728.099346 | 3619.268555 | 1386.215210 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1360.3456, current episode: 1
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1374.0020, current episode: 2
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1457.3785, current episode: 3
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1484.7784, current episode: 4
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1571.6619, current episode: 5
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1814.1221, current episode: 6
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1815.4720, current episode: 7
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1886.4199, current episode: 8
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2187.8425, current episode: 9
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1360.3456, current episode: 9
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2701.5261, current episode: 10
[2023-06-29 12:27:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1374.0020, current episode: 10
[2023-06-29 12:27:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 300500.000000 | iteration_300500.pth.tar | 10.000000     | 7200.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 720.000000              | 1.088855      | 6612.447847         | 9.183955             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1765.354907 | 400.342143 | 2701.526123 | 1360.345581 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1858.0198, current episode: 1
[2023-06-29 12:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2677.1101, current episode: 2
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1858.0198, current episode: 2
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3675.8931, current episode: 3
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3615.5767, current episode: 4
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3627.9546, current episode: 5
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3675.2656, current episode: 6
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3644.6802, current episode: 7
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3659.7598, current episode: 8
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3639.7524, current episode: 9
[2023-06-29 12:27:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3630.0750, current episode: 10
[2023-06-29 12:27:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 301000.000000 | iteration_301000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528031      | 6544.368775         | 6.544369             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3370.408716 | 581.343302 | 3675.893066 | 1858.019775 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2484.2031, current episode: 1
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2729.8601, current episode: 2
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3114.6008, current episode: 3
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3368.1667, current episode: 4
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3641.8364, current episode: 5
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3567.4639, current episode: 6
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3585.9221, current episode: 7
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3622.0645, current episode: 8
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3620.5828, current episode: 9
[2023-06-29 12:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3608.5222, current episode: 10
[2023-06-29 12:28:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 301500.000000 | iteration_301500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491215      | 6705.940733         | 6.705941             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3334.322266 | 398.703990 | 3641.836426 | 2484.203125 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:28:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1179.9249, current episode: 1
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1260.8173, current episode: 2
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1281.1008, current episode: 3
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1328.0498, current episode: 4
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1376.9542, current episode: 5
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1580.9146, current episode: 6
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1581.3267, current episode: 7
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1593.0654, current episode: 8
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2017.7819, current episode: 9
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1179.9249, current episode: 9
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1260.8173, current episode: 9
[2023-06-29 12:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2579.7107, current episode: 10
[2023-06-29 12:28:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 302000.000000 | iteration_302000.pth.tar | 10.000000     | 6819.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 681.900000              | 1.035793      | 6583.361156         | 9.654438             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1577.964624 | 405.856032 | 2579.710693 | 1179.924927 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1317.5345, current episode: 1
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1399.6428, current episode: 2
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1486.1711, current episode: 3
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1500.3674, current episode: 4
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2341.1890, current episode: 5
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1317.5345, current episode: 5
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1399.6428, current episode: 5
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2932.2112, current episode: 6
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1486.1711, current episode: 6
[2023-06-29 12:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1500.3674, current episode: 6
[2023-06-29 12:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3637.3403, current episode: 7
[2023-06-29 12:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3612.3093, current episode: 8
[2023-06-29 12:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3615.2024, current episode: 9
[2023-06-29 12:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3616.7224, current episode: 10
[2023-06-29 12:28:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 302500.000000 | iteration_302500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511193      | 6617.289025         | 6.617289             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2545.869055 | 992.402783 | 3637.340332 | 1317.534546 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3554.6929, current episode: 1
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3536.2307, current episode: 2
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3624.9812, current episode: 3
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3582.6096, current episode: 4
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3557.3528, current episode: 5
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3595.8149, current episode: 6
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3571.3271, current episode: 7
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3590.8657, current episode: 8
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3581.3911, current episode: 9
[2023-06-29 12:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3537.7305, current episode: 10
[2023-06-29 12:28:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 303000.000000 | iteration_303000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511226      | 6617.144705         | 6.617145             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3573.299658 | 26.234164  | 3624.981201 | 3536.230713 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3572.3237, current episode: 1
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3560.0298, current episode: 2
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3569.5156, current episode: 3
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3553.9009, current episode: 4
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3568.8518, current episode: 5
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3540.6096, current episode: 6
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3567.7969, current episode: 7
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3571.7688, current episode: 8
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.8230, current episode: 9
[2023-06-29 12:29:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3601.6477, current episode: 10
[2023-06-29 12:29:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 303500.000000 | iteration_303500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505211      | 6643.584967         | 6.643585             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3564.226782 | 17.531859  | 3601.647705 | 3535.822998 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3558.1624, current episode: 1
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3593.9333, current episode: 2
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3574.2117, current episode: 3
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3585.2383, current episode: 4
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3593.1453, current episode: 5
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3595.7075, current episode: 6
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3583.6836, current episode: 7
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3621.5535, current episode: 8
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3562.2903, current episode: 9
[2023-06-29 12:29:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3599.8691, current episode: 10
[2023-06-29 12:29:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 304000.000000 | iteration_304000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508268      | 6630.120609         | 6.630121             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3586.779492 | 17.721599  | 3621.553467 | 3558.162354 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2309.5237, current episode: 1
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3451.5654, current episode: 2
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3529.3738, current episode: 3
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3620.7485, current episode: 4
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3602.7163, current episode: 5
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3597.8450, current episode: 6
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3621.8521, current episode: 7
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3606.0007, current episode: 8
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3657.5012, current episode: 9
[2023-06-29 12:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3615.7268, current episode: 10
[2023-06-29 12:29:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 304500.000000 | iteration_304500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497310      | 6678.642351         | 6.678642             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3461.285352 | 387.871402 | 3657.501221 | 2309.523682 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:29:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2059.0063, current episode: 1
[2023-06-29 12:29:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2792.1689, current episode: 2
[2023-06-29 12:29:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2795.9497, current episode: 3
[2023-06-29 12:29:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3191.0923, current episode: 4
[2023-06-29 12:29:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3473.4084, current episode: 5
[2023-06-29 12:29:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3593.7593, current episode: 6
[2023-06-29 12:29:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3662.0134, current episode: 7
[2023-06-29 12:29:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3631.8677, current episode: 8
[2023-06-29 12:29:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3626.4448, current episode: 9
[2023-06-29 12:29:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3639.1150, current episode: 10
[2023-06-29 12:29:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 305000.000000 | iteration_305000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492516      | 6700.097909         | 6.700098             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3246.482593 | 511.308533 | 3662.013428 | 2059.006348 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:30:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2182.4861, current episode: 1
[2023-06-29 12:30:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2223.8159, current episode: 2
[2023-06-29 12:30:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2343.0732, current episode: 3
[2023-06-29 12:30:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2902.5527, current episode: 4
[2023-06-29 12:30:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2948.4268, current episode: 5
[2023-06-29 12:30:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3010.1130, current episode: 6
[2023-06-29 12:30:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3740.2583, current episode: 7
[2023-06-29 12:30:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3591.2542, current episode: 8
[2023-06-29 12:30:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3590.3108, current episode: 9
[2023-06-29 12:30:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3603.4106, current episode: 10
[2023-06-29 12:30:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 305500.000000 | iteration_305500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485414      | 6732.130721         | 6.732131             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3013.570166 | 576.445583 | 3740.258301 | 2182.486084 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3606.3315, current episode: 1
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3655.4160, current episode: 2
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3628.8242, current episode: 3
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3604.4656, current episode: 4
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3588.4189, current episode: 5
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3591.8728, current episode: 6
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3573.6521, current episode: 7
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3579.2817, current episode: 8
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3553.2522, current episode: 9
[2023-06-29 12:30:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3595.1211, current episode: 10
[2023-06-29 12:30:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 306000.000000 | iteration_306000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.462285      | 6838.612583         | 6.838613             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3597.663623 | 27.276372  | 3655.416016 | 3553.252197 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:30:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1920.6760, current episode: 1
[2023-06-29 12:30:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2641.7913, current episode: 2
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2724.2175, current episode: 3
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3745.6099, current episode: 4
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3672.7175, current episode: 5
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3622.2542, current episode: 6
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3674.8772, current episode: 7
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3637.7576, current episode: 8
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3700.2810, current episode: 9
[2023-06-29 12:30:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3767.2058, current episode: 10
[2023-06-29 12:30:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 306500.000000 | iteration_306500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479501      | 6759.035197         | 6.759035             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3310.738794 | 611.604373 | 3767.205811 | 1920.676025 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1784.6831, current episode: 1
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1806.8076, current episode: 2
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1816.8041, current episode: 3
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1852.2283, current episode: 4
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1927.9568, current episode: 5
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2264.2759, current episode: 6
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2302.0747, current episode: 7
[2023-06-29 12:30:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2585.2830, current episode: 8
[2023-06-29 12:31:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3520.7393, current episode: 9
[2023-06-29 12:31:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1784.6831, current episode: 9
[2023-06-29 12:31:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1806.8076, current episode: 9
[2023-06-29 12:31:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1816.8041, current episode: 9
[2023-06-29 12:31:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1852.2283, current episode: 9
[2023-06-29 12:31:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3626.4797, current episode: 10
[2023-06-29 12:31:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 307000.000000 | iteration_307000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505165      | 6643.789711         | 6.643790             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2348.733240 | 662.559780 | 3626.479736 | 1784.683105 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:31:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1690.3445, current episode: 1
[2023-06-29 12:31:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1671.9431, current episode: 2
[2023-06-29 12:31:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1690.4568, current episode: 3
[2023-06-29 12:31:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1694.3118, current episode: 4
[2023-06-29 12:31:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1696.6305, current episode: 5
[2023-06-29 12:31:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2027.6157, current episode: 6
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2391.9585, current episode: 7
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2402.4631, current episode: 8
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2640.4846, current episode: 9
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1690.3445, current episode: 9
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1671.9431, current episode: 9
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1690.4568, current episode: 9
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1694.3118, current episode: 9
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1696.6305, current episode: 9
[2023-06-29 12:31:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3710.4092, current episode: 10
[2023-06-29 12:31:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 307500.000000 | iteration_307500.pth.tar | 10.000000     | 9860.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 986.000000              | 1.478200      | 6670.273226         | 6.764983             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2161.661780 | 622.539049 | 3710.409180 | 1671.943115 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:31:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1551.2584, current episode: 1
[2023-06-29 12:31:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1638.6766, current episode: 2
[2023-06-29 12:31:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1651.4266, current episode: 3
[2023-06-29 12:31:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1668.6943, current episode: 4
[2023-06-29 12:31:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1687.5597, current episode: 5
[2023-06-29 12:31:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1700.9309, current episode: 6
[2023-06-29 12:31:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2012.8220, current episode: 7
[2023-06-29 12:31:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2511.2156, current episode: 8
[2023-06-29 12:31:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2651.7893, current episode: 9
[2023-06-29 12:31:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3019.4412, current episode: 10
[2023-06-29 12:31:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 308000.000000 | iteration_308000.pth.tar | 10.000000     | 7910.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 791.000000              | 1.180090      | 6702.880175         | 8.473932             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2009.381470 | 497.490393 | 3019.441162 | 1551.258423 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1354.2175, current episode: 1
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1392.1897, current episode: 2
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1388.3961, current episode: 3
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1394.6385, current episode: 4
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1552.8986, current episode: 5
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1574.0304, current episode: 6
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1661.0236, current episode: 7
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1763.7932, current episode: 8
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2070.7896, current episode: 9
[2023-06-29 12:31:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2419.3987, current episode: 10
[2023-06-29 12:31:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 308500.000000 | iteration_308500.pth.tar | 10.000000     | 6410.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 641.000000              | 0.975428      | 6571.471121         | 10.251905            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1657.137585 | 329.302094 | 2419.398682 | 1354.217529 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3589.8525, current episode: 1
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3546.8799, current episode: 2
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3581.6506, current episode: 3
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3589.2476, current episode: 4
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3593.7734, current episode: 5
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3578.0825, current episode: 6
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3618.2578, current episode: 7
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3616.9226, current episode: 8
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3573.1951, current episode: 9
[2023-06-29 12:32:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3586.5447, current episode: 10
[2023-06-29 12:32:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 309000.000000 | iteration_309000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498313      | 6674.172939         | 6.674173             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3587.440674 | 19.591028  | 3618.257812 | 3546.879883 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3548.7507, current episode: 1
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3568.3596, current episode: 2
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3542.7324, current episode: 3
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.5654, current episode: 4
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3513.1118, current episode: 5
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3551.7847, current episode: 6
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3549.4709, current episode: 7
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3539.1785, current episode: 8
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3520.5300, current episode: 9
[2023-06-29 12:32:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3558.9324, current episode: 10
[2023-06-29 12:32:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 309500.000000 | iteration_309500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486869      | 6725.540321         | 6.725540             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3545.341650 | 16.479245  | 3568.359619 | 3513.111816 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3574.3894, current episode: 1
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3541.3108, current episode: 2
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3594.2292, current episode: 3
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.1926, current episode: 4
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3530.3716, current episode: 5
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.9404, current episode: 6
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3562.9224, current episode: 7
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3538.9604, current episode: 8
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3579.8276, current episode: 9
[2023-06-29 12:32:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3528.5286, current episode: 10
[2023-06-29 12:32:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 310000.000000 | iteration_310000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.469644      | 6804.368750         | 6.804369             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3557.167310 | 23.766964  | 3594.229248 | 3528.528564 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3592.0859, current episode: 1
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3598.9814, current episode: 2
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3555.0999, current episode: 3
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3580.1038, current episode: 4
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3613.0566, current episode: 5
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3555.5146, current episode: 6
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3584.9214, current episode: 7
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3581.6094, current episode: 8
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3554.0833, current episode: 9
[2023-06-29 12:32:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3554.4023, current episode: 10
[2023-06-29 12:32:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 310500.000000 | iteration_310500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512152      | 6613.093505         | 6.613094             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3576.985864 | 20.202834  | 3613.056641 | 3554.083252 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2104.4944, current episode: 1
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2955.1416, current episode: 2
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2971.2605, current episode: 3
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3348.6172, current episode: 4
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3750.7617, current episode: 5
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3619.9509, current episode: 6
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3707.8982, current episode: 7
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3741.9780, current episode: 8
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3733.8276, current episode: 9
[2023-06-29 12:33:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3608.6455, current episode: 10
[2023-06-29 12:33:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 311000.000000 | iteration_311000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503111      | 6652.869866         | 6.652870             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3354.257568 | 507.927569 | 3750.761719 | 2104.494385 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2314.7126, current episode: 1
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2977.5083, current episode: 2
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3081.1958, current episode: 3
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3374.0779, current episode: 4
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3755.4871, current episode: 5
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3592.4680, current episode: 6
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3575.6023, current episode: 7
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3675.2332, current episode: 8
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3569.6594, current episode: 9
[2023-06-29 12:33:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3581.7327, current episode: 10
[2023-06-29 12:33:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 311500.000000 | iteration_311500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.795226      | 5570.330592         | 5.570331             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3349.767725 | 420.147434 | 3755.487061 | 2314.712646 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:33:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2481.1079, current episode: 1
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2606.5586, current episode: 2
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2627.7319, current episode: 3
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2638.3123, current episode: 4
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2823.7678, current episode: 5
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2994.2834, current episode: 6
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3465.7581, current episode: 7
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3774.6602, current episode: 8
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3622.9829, current episode: 9
[2023-06-29 12:33:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3633.2178, current episode: 10
[2023-06-29 12:33:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 312000.000000 | iteration_312000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.542187      | 6484.299439         | 6.484299             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3066.838086 | 478.117686 | 3774.660156 | 2481.107910 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1712.0175, current episode: 1
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1991.5958, current episode: 2
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2112.8416, current episode: 3
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2215.9014, current episode: 4
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2219.2124, current episode: 5
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2245.0081, current episode: 6
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2293.7268, current episode: 7
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2945.2275, current episode: 8
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1712.0175, current episode: 8
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3739.5198, current episode: 9
[2023-06-29 12:33:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3592.8411, current episode: 10
[2023-06-29 12:33:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 312500.000000 | iteration_312500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494200      | 6692.544724         | 6.692545             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2506.789185 | 649.991053 | 3739.519775 | 1712.017456 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:34:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1694.3713, current episode: 1
[2023-06-29 12:34:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2276.2810, current episode: 2
[2023-06-29 12:34:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2489.3015, current episode: 3
[2023-06-29 12:34:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2613.1477, current episode: 4
[2023-06-29 12:34:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2955.2939, current episode: 5
[2023-06-29 12:34:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3296.7703, current episode: 6
[2023-06-29 12:34:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1694.3713, current episode: 6
[2023-06-29 12:34:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3492.9614, current episode: 7
[2023-06-29 12:34:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3459.4758, current episode: 8
[2023-06-29 12:34:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3592.6702, current episode: 9
[2023-06-29 12:34:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3544.1467, current episode: 10
[2023-06-29 12:34:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 313000.000000 | iteration_313000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499828      | 6667.431186         | 6.667431             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2941.441992 | 616.130379 | 3592.670166 | 1694.371338 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1985.1566, current episode: 1
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2034.0701, current episode: 2
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2261.5728, current episode: 3
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2265.5134, current episode: 4
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2416.7603, current episode: 5
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3330.6458, current episode: 6
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3582.3452, current episode: 7
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3585.1294, current episode: 8
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3744.9370, current episode: 9
[2023-06-29 12:34:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3578.2922, current episode: 10
[2023-06-29 12:34:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 313500.000000 | iteration_313500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497850      | 6676.236047         | 6.676236             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2878.442273 | 701.445712 | 3744.937012 | 1985.156616 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:34:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1461.0447, current episode: 1
[2023-06-29 12:34:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1734.2245, current episode: 2
[2023-06-29 12:34:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1893.3358, current episode: 3
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1966.0201, current episode: 4
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1994.9390, current episode: 5
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1987.5188, current episode: 6
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2400.5332, current episode: 7
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1461.0447, current episode: 7
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1734.2245, current episode: 7
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3670.6902, current episode: 8
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1893.3358, current episode: 8
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3629.2256, current episode: 9
[2023-06-29 12:34:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3615.2881, current episode: 10
[2023-06-29 12:34:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 314000.000000 | iteration_314000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524182      | 6560.895191         | 6.560895             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2435.281995 | 818.185965 | 3670.690186 | 1461.044678 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1253.6564, current episode: 1
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1261.5620, current episode: 2
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1303.3378, current episode: 3
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1371.7976, current episode: 4
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1370.6315, current episode: 5
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1376.8965, current episode: 6
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1403.6406, current episode: 7
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1409.2866, current episode: 8
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1409.5806, current episode: 9
[2023-06-29 12:34:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1474.4724, current episode: 10
[2023-06-29 12:34:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 314500.000000 | iteration_314500.pth.tar | 10.000000     | 3890.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 389.000000              | 0.585343      | 6645.676618         | 17.084002            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1363.486194 | 66.724524  | 1474.472412 | 1253.656372 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 870.6912, current episode: 1
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 876.4630, current episode: 2
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 874.3557, current episode: 3
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1211.4110, current episode: 4
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1336.6256, current episode: 5
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1358.8657, current episode: 6
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1416.4597, current episode: 7
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 870.6912, current episode: 7
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 876.4630, current episode: 7
[2023-06-29 12:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 874.3557, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1211.4110, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1336.6256, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1358.8657, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1416.4597, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 870.6912, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 876.4630, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 874.3557, current episode: 7
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3589.2073, current episode: 8
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3600.3337, current episode: 9
[2023-06-29 12:35:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3648.0249, current episode: 10
[2023-06-29 12:35:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 315000.000000 | iteration_315000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.542208      | 6484.211160         | 6.484211             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1878.243774 | 1152.069785 | 3648.024902 | 870.691162 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 12:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1129.9675, current episode: 1
[2023-06-29 12:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1252.5399, current episode: 2
[2023-06-29 12:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1402.6498, current episode: 3
[2023-06-29 12:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1417.6827, current episode: 4
[2023-06-29 12:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1441.7772, current episode: 5
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1467.6929, current episode: 6
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1495.2533, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1129.9675, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1252.5399, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1402.6498, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1417.6827, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1441.7772, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1467.6929, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1495.2533, current episode: 7
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3249.9995, current episode: 8
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1129.9675, current episode: 8
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3645.0928, current episode: 9
[2023-06-29 12:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3615.0542, current episode: 10
[2023-06-29 12:35:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 315500.000000 | iteration_315500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522505      | 6568.122908         | 6.568123             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2011.770984 | 986.769986 | 3645.092773 | 1129.967529 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1957.5862, current episode: 1
[2023-06-29 12:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2185.2661, current episode: 2
[2023-06-29 12:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2372.9919, current episode: 3
[2023-06-29 12:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2723.7852, current episode: 4
[2023-06-29 12:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2746.8770, current episode: 5
[2023-06-29 12:35:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3605.8462, current episode: 6
[2023-06-29 12:35:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3610.1165, current episode: 7
[2023-06-29 12:35:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3592.3853, current episode: 8
[2023-06-29 12:35:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3774.7993, current episode: 9
[2023-06-29 12:35:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3690.4849, current episode: 10
[2023-06-29 12:35:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 316000.000000 | iteration_316000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498863      | 6671.725298         | 6.671725             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3026.013843 | 666.667159 | 3774.799316 | 1957.586182 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2364.8943, current episode: 1
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2920.2378, current episode: 2
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3040.1401, current episode: 3
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3170.5283, current episode: 4
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3248.0552, current episode: 5
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3689.3965, current episode: 6
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3699.4810, current episode: 7
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3747.1636, current episode: 8
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3659.2891, current episode: 9
[2023-06-29 12:35:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3698.5540, current episode: 10
[2023-06-29 12:35:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 316500.000000 | iteration_316500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522957      | 6566.173960         | 6.566174             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3323.773975 | 435.784596 | 3747.163574 | 2364.894287 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 853.8928, current episode: 1
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1145.0895, current episode: 2
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1150.1064, current episode: 3
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 853.8928, current episode: 3
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2130.4785, current episode: 4
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1145.0895, current episode: 4
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1150.1064, current episode: 4
[2023-06-29 12:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2841.3596, current episode: 5
[2023-06-29 12:36:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 853.8928, current episode: 5
[2023-06-29 12:36:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3255.7253, current episode: 6
[2023-06-29 12:36:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3625.8667, current episode: 7
[2023-06-29 12:36:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3632.3906, current episode: 8
[2023-06-29 12:36:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.8101, current episode: 9
[2023-06-29 12:36:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3752.4541, current episode: 10
[2023-06-29 12:36:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 317000.000000 | iteration_317000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.546074      | 6467.994285         | 6.467994             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2598.917371 | 1114.743103 | 3752.454102 | 853.892822 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2523.3677, current episode: 1
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2955.6328, current episode: 2
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3230.7234, current episode: 3
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3287.0557, current episode: 4
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3656.2146, current episode: 5
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3607.0608, current episode: 6
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3605.1621, current episode: 7
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3636.8113, current episode: 8
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3619.3538, current episode: 9
[2023-06-29 12:36:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3626.6174, current episode: 10
[2023-06-29 12:36:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 317500.000000 | iteration_317500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494200      | 6692.542537         | 6.692543             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3374.799951 | 361.548018 | 3656.214600 | 2523.367676 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2288.3523, current episode: 1
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2371.3499, current episode: 2
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2489.0273, current episode: 3
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2522.8796, current episode: 4
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2548.8193, current episode: 5
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3037.7578, current episode: 6
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3586.9453, current episode: 7
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3593.0701, current episode: 8
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3607.3423, current episode: 9
[2023-06-29 12:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3585.7402, current episode: 10
[2023-06-29 12:36:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 318000.000000 | iteration_318000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.513646      | 6606.562965         | 6.606563             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2963.128418 | 546.806003 | 3607.342285 | 2288.352295 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2283.2761, current episode: 1
[2023-06-29 12:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2920.5525, current episode: 2
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3595.7952, current episode: 3
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3618.1235, current episode: 4
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3608.7017, current episode: 5
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3571.5789, current episode: 6
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3607.8567, current episode: 7
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3564.9851, current episode: 8
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3594.4788, current episode: 9
[2023-06-29 12:36:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3660.6113, current episode: 10
[2023-06-29 12:36:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 318500.000000 | iteration_318500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.460777      | 6845.670819         | 6.845671             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3402.595972 | 425.669918 | 3660.611328 | 2283.276123 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1395.5745, current episode: 1
[2023-06-29 12:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1677.2662, current episode: 2
[2023-06-29 12:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1719.8879, current episode: 3
[2023-06-29 12:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1724.9513, current episode: 4
[2023-06-29 12:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2240.9319, current episode: 5
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2679.2456, current episode: 6
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1395.5745, current episode: 6
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1677.2662, current episode: 6
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1719.8879, current episode: 6
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1724.9513, current episode: 6
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3674.2156, current episode: 7
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3589.5881, current episode: 8
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3610.8484, current episode: 9
[2023-06-29 12:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.9009, current episode: 10
[2023-06-29 12:37:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 319000.000000 | iteration_319000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.539858      | 6493.454725         | 6.494104             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2591.441040 | 901.981529 | 3674.215576 | 1395.574463 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2031.6147, current episode: 1
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2036.8177, current episode: 2
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2250.5388, current episode: 3
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2675.6855, current episode: 4
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2693.3179, current episode: 5
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3593.4048, current episode: 6
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3641.7451, current episode: 7
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3624.8601, current episode: 8
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3606.0837, current episode: 9
[2023-06-29 12:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3583.0513, current episode: 10
[2023-06-29 12:37:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 319500.000000 | iteration_319500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485630      | 6731.149413         | 6.731149             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2973.711975 | 669.418238 | 3641.745117 | 2031.614746 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2137.8811, current episode: 1
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3105.5081, current episode: 2
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3103.0237, current episode: 3
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3607.5808, current episode: 4
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3574.4512, current episode: 5
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3555.9241, current episode: 6
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3591.6772, current episode: 7
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3575.5200, current episode: 8
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.4331, current episode: 9
[2023-06-29 12:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.9976, current episode: 10
[2023-06-29 12:37:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 320000.000000 | iteration_320000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511353      | 6616.586730         | 6.616587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3340.499683 | 442.764849 | 3607.580811 | 2137.881104 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1149.6505, current episode: 1
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1194.3735, current episode: 2
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1305.7950, current episode: 3
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1332.9597, current episode: 4
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1334.1062, current episode: 5
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1615.1073, current episode: 6
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1149.6505, current episode: 6
[2023-06-29 12:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1194.3735, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1305.7950, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1332.9597, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1334.1062, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1615.1073, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1149.6505, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1194.3735, current episode: 6
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3518.9958, current episode: 7
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3595.2383, current episode: 8
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3576.1479, current episode: 9
[2023-06-29 12:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3601.0938, current episode: 10
[2023-06-29 12:37:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 320500.000000 | iteration_320500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.555558      | 6428.561395         | 6.428561             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2222.346814 | 1108.875309 | 3601.093750 | 1149.650513 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1747.1797, current episode: 1
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1860.9053, current episode: 2
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2003.6801, current episode: 3
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2022.2067, current episode: 4
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2522.8867, current episode: 5
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2542.4326, current episode: 6
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2499.1453, current episode: 7
[2023-06-29 12:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1747.1797, current episode: 7
[2023-06-29 12:38:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3624.5859, current episode: 8
[2023-06-29 12:38:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3567.6904, current episode: 9
[2023-06-29 12:38:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3600.8562, current episode: 10
[2023-06-29 12:38:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 321000.000000 | iteration_321000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483967      | 6738.693029         | 6.738693             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2599.156885 | 705.006766 | 3624.585938 | 1747.179688 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:38:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1412.6304, current episode: 1
[2023-06-29 12:38:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1397.8348, current episode: 2
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1803.7147, current episode: 3
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1820.1456, current episode: 4
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1991.2502, current episode: 5
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1412.6304, current episode: 5
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1397.8348, current episode: 5
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2936.9956, current episode: 6
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3286.5369, current episode: 7
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3295.7407, current episode: 8
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3573.1868, current episode: 9
[2023-06-29 12:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3571.4026, current episode: 10
[2023-06-29 12:38:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 321500.000000 | iteration_321500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.475934      | 6775.370338         | 6.775370             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2508.943835 | 857.007838 | 3573.186768 | 1397.834839 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:38:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1807.1711, current episode: 1
[2023-06-29 12:38:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1890.0492, current episode: 2
[2023-06-29 12:38:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1911.3547, current episode: 3
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2651.0103, current episode: 4
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2882.2576, current episode: 5
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3527.2800, current episode: 6
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3596.1877, current episode: 7
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3571.6521, current episode: 8
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3493.1233, current episode: 9
[2023-06-29 12:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.4644, current episode: 10
[2023-06-29 12:38:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 322000.000000 | iteration_322000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493606      | 6695.207933         | 6.695208             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2889.255042 | 732.992466 | 3596.187744 | 1807.171143 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2341.0144, current episode: 1
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3543.5076, current episode: 2
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3506.7175, current episode: 3
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3600.2424, current episode: 4
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3609.4402, current episode: 5
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3617.6526, current episode: 6
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3615.8530, current episode: 7
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3566.2385, current episode: 8
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3610.3062, current episode: 9
[2023-06-29 12:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3478.2668, current episode: 10
[2023-06-29 12:38:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 322500.000000 | iteration_322500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488018      | 6720.346859         | 6.720347             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3448.923926 | 372.211642 | 3617.652588 | 2341.014404 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:39:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1674.1681, current episode: 1
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1674.1681, current episode: 1
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3720.6919, current episode: 2
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3547.7322, current episode: 3
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3570.6609, current episode: 4
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3561.4021, current episode: 5
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3515.0134, current episode: 6
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3611.4417, current episode: 7
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3646.4851, current episode: 8
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3546.6243, current episode: 9
[2023-06-29 12:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3718.3887, current episode: 10
[2023-06-29 12:39:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 323000.000000 | iteration_323000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.475797      | 6775.998012         | 6.775998             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3411.260828 | 582.977887 | 3720.691895 | 1674.168091 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:39:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1149.2430, current episode: 1
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1484.8585, current episode: 2
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1603.5687, current episode: 3
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1806.6895, current episode: 4
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1803.7820, current episode: 5
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1149.2430, current episode: 5
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2570.1250, current episode: 6
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1484.8585, current episode: 6
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2896.6367, current episode: 7
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1603.5687, current episode: 7
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3430.1196, current episode: 8
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1806.6895, current episode: 8
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1803.7820, current episode: 8
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1149.2430, current episode: 8
[2023-06-29 12:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3511.1191, current episode: 9
[2023-06-29 12:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3485.0022, current episode: 10
[2023-06-29 12:39:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 323500.000000 | iteration_323500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.533276      | 6521.981953         | 6.521982             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2374.114441 | 865.189279 | 3511.119141 | 1149.243042 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1204.2271, current episode: 1
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1131.7791, current episode: 2
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1353.7571, current episode: 3
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1450.2068, current episode: 4
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1609.5333, current episode: 5
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1870.2069, current episode: 6
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1204.2271, current episode: 6
[2023-06-29 12:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1131.7791, current episode: 6
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1353.7571, current episode: 6
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2613.0891, current episode: 7
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2789.8777, current episode: 8
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1450.2068, current episode: 8
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3056.4890, current episode: 9
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1609.5333, current episode: 9
[2023-06-29 12:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3252.2327, current episode: 10
[2023-06-29 12:39:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 324000.000000 | iteration_324000.pth.tar | 10.000000     | 9010.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 901.000000              | 1.372495      | 6564.687546         | 7.286002             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2033.139868 | 771.319217 | 3252.232666 | 1131.779053 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1766.8201, current episode: 1
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2344.1731, current episode: 2
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3301.0261, current episode: 3
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3525.4556, current episode: 4
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1766.8201, current episode: 4
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3468.8577, current episode: 5
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3546.5989, current episode: 6
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.5520, current episode: 7
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3561.6797, current episode: 8
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3487.5986, current episode: 9
[2023-06-29 12:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3531.9023, current episode: 10
[2023-06-29 12:39:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 324500.000000 | iteration_324500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512378      | 6612.103895         | 6.612104             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3206.966406 | 594.203787 | 3561.679688 | 1766.820068 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:40:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2591.1953, current episode: 1
[2023-06-29 12:40:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2618.8440, current episode: 2
[2023-06-29 12:40:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2608.0293, current episode: 3
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3434.3831, current episode: 4
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3511.9580, current episode: 5
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3534.2739, current episode: 6
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3548.2087, current episode: 7
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3563.1467, current episode: 8
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3562.4778, current episode: 9
[2023-06-29 12:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.4900, current episode: 10
[2023-06-29 12:40:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 325000.000000 | iteration_325000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.490820      | 6707.717593         | 6.707718             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3253.700684 | 425.598094 | 3564.489990 | 2591.195312 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1452.5056, current episode: 1
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1460.3872, current episode: 2
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2102.4824, current episode: 3
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2297.0359, current episode: 4
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2403.6504, current episode: 5
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2513.2505, current episode: 6
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2568.6626, current episode: 7
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1452.5056, current episode: 7
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3035.9844, current episode: 8
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1460.3872, current episode: 8
[2023-06-29 12:40:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3490.5662, current episode: 9
[2023-06-29 12:40:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3755.9854, current episode: 10
[2023-06-29 12:40:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 325500.000000 | iteration_325500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.460474      | 6847.092113         | 6.847092             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2508.051050 | 723.655917 | 3755.985352 | 1452.505615 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:40:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1782.8593, current episode: 1
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1922.4869, current episode: 2
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2187.2258, current episode: 3
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2411.6436, current episode: 4
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2618.8220, current episode: 5
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3351.8059, current episode: 6
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1782.8593, current episode: 6
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3570.8167, current episode: 7
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3564.0645, current episode: 8
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3614.9241, current episode: 9
[2023-06-29 12:40:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3536.9441, current episode: 10
[2023-06-29 12:40:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 326000.000000 | iteration_326000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479514      | 6758.977200         | 6.758977             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2856.159277 | 708.649038 | 3614.924072 | 1782.859253 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:40:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1807.5237, current episode: 1
[2023-06-29 12:40:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1904.9143, current episode: 2
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1957.6001, current episode: 3
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1966.1184, current episode: 4
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1956.6664, current episode: 5
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2683.2285, current episode: 6
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3490.8708, current episode: 7
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3595.4155, current episode: 8
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1807.5237, current episode: 8
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3561.1572, current episode: 9
[2023-06-29 12:40:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3570.4534, current episode: 10
[2023-06-29 12:40:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 326500.000000 | iteration_326500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478322      | 6764.427172         | 6.764427             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2649.394836 | 772.797443 | 3595.415527 | 1807.523682 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:41:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1664.5707, current episode: 1
[2023-06-29 12:41:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1983.4235, current episode: 2
[2023-06-29 12:41:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2149.1497, current episode: 3
[2023-06-29 12:41:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2225.3052, current episode: 4
[2023-06-29 12:41:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2542.0588, current episode: 5
[2023-06-29 12:41:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2584.4561, current episode: 6
[2023-06-29 12:41:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3021.6558, current episode: 7
[2023-06-29 12:41:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3217.8059, current episode: 8
[2023-06-29 12:41:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1664.5707, current episode: 8
[2023-06-29 12:41:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3549.0349, current episode: 9
[2023-06-29 12:41:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3674.7729, current episode: 10
[2023-06-29 12:41:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 327000.000000 | iteration_327000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523539      | 6563.666564         | 6.563667             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2661.223340 | 646.548883 | 3674.772949 | 1664.570679 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1569.6176, current episode: 1
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1627.8540, current episode: 2
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1684.3224, current episode: 3
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1812.7758, current episode: 4
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2312.5247, current episode: 5
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1569.6176, current episode: 5
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3129.8113, current episode: 6
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3227.8425, current episode: 7
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1627.8540, current episode: 7
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1684.3224, current episode: 7
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3508.0591, current episode: 8
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1812.7758, current episode: 8
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3556.4497, current episode: 9
[2023-06-29 12:41:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3574.9741, current episode: 10
[2023-06-29 12:41:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 327500.000000 | iteration_327500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.621876      | 6165.698171         | 6.165698             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2600.423108 | 831.409148 | 3574.974121 | 1569.617554 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:41:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1695.7434, current episode: 1
[2023-06-29 12:41:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1983.8485, current episode: 2
[2023-06-29 12:41:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2371.6826, current episode: 3
[2023-06-29 12:41:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2516.2178, current episode: 4
[2023-06-29 12:41:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2559.5889, current episode: 5
[2023-06-29 12:41:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3228.7034, current episode: 6
[2023-06-29 12:41:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1695.7434, current episode: 6
[2023-06-29 12:41:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.6118, current episode: 7
[2023-06-29 12:41:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3567.1333, current episode: 8
[2023-06-29 12:41:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3558.7681, current episode: 9
[2023-06-29 12:41:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3580.4604, current episode: 10
[2023-06-29 12:41:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 328000.000000 | iteration_328000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500683      | 6663.630398         | 6.663630             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2861.575818 | 685.157941 | 3580.460449 | 1695.743408 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:41:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1621.9443, current episode: 1
[2023-06-29 12:41:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1703.3013, current episode: 2
[2023-06-29 12:41:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1749.7264, current episode: 3
[2023-06-29 12:41:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1841.0284, current episode: 4
[2023-06-29 12:41:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1926.1235, current episode: 5
[2023-06-29 12:41:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1943.7473, current episode: 6
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1621.9443, current episode: 6
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1703.3013, current episode: 6
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1749.7264, current episode: 6
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3584.1663, current episode: 7
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3534.2717, current episode: 8
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3604.4138, current episode: 9
[2023-06-29 12:41:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3594.8682, current episode: 10
[2023-06-29 12:41:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 328500.000000 | iteration_328500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509463      | 6624.874106         | 6.624874             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2510.359131 | 877.732496 | 3604.413818 | 1621.944336 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1559.7983, current episode: 1
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1655.2418, current episode: 2
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1559.7983, current episode: 2
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1655.2418, current episode: 2
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3547.8708, current episode: 3
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3607.0647, current episode: 4
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3569.0066, current episode: 5
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3576.4946, current episode: 6
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3588.9905, current episode: 7
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.4917, current episode: 8
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3601.1829, current episode: 9
[2023-06-29 12:42:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3604.5403, current episode: 10
[2023-06-29 12:42:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 329000.000000 | iteration_329000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.453043      | 6882.108358         | 6.882108             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3191.168225 | 792.306688 | 3607.064697 | 1559.798340 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2186.6938, current episode: 1
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2456.0652, current episode: 2
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2632.8828, current episode: 3
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2617.9321, current episode: 4
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3476.0342, current episode: 5
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3487.9163, current episode: 6
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3758.5483, current episode: 7
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3723.6831, current episode: 8
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3751.1821, current episode: 9
[2023-06-29 12:42:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3648.1438, current episode: 10
[2023-06-29 12:42:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 329500.000000 | iteration_329500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492359      | 6700.802698         | 6.700803             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3173.908179 | 590.236472 | 3758.548340 | 2186.693848 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:42:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1676.7002, current episode: 1
[2023-06-29 12:42:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1993.8459, current episode: 2
[2023-06-29 12:42:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1982.8488, current episode: 3
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3021.9673, current episode: 4
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1676.7002, current episode: 4
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3545.0259, current episode: 5
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3647.1758, current episode: 6
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.0903, current episode: 7
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.9155, current episode: 8
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3563.5715, current episode: 9
[2023-06-29 12:42:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.7097, current episode: 10
[2023-06-29 12:42:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 330000.000000 | iteration_330000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502771      | 6654.371675         | 6.654372             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3011.085095 | 759.710865 | 3647.175781 | 1676.700195 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1022.8118, current episode: 1
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1099.3475, current episode: 2
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1116.3273, current episode: 3
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1111.9260, current episode: 4
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1172.5842, current episode: 5
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1250.8126, current episode: 6
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1627.4755, current episode: 7
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1688.6490, current episode: 8
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1022.8118, current episode: 8
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1099.3475, current episode: 8
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1116.3273, current episode: 8
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1111.9260, current episode: 8
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1172.5842, current episode: 8
[2023-06-29 12:42:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1250.8126, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1627.4755, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1022.8118, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1688.6490, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1099.3475, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1116.3273, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1111.9260, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1172.5842, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1250.8126, current episode: 8
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3646.9050, current episode: 9
[2023-06-29 12:43:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3591.4324, current episode: 10
[2023-06-29 12:43:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 330500.000000 | iteration_330500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524204      | 6560.801661         | 6.560802             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1732.827142 | 966.870043 | 3646.905029 | 1022.811829 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1078.9990, current episode: 1
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1078.7941, current episode: 2
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1130.2483, current episode: 3
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1187.4923, current episode: 4
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1220.3156, current episode: 5
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1227.7740, current episode: 6
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1245.3464, current episode: 7
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1283.4424, current episode: 8
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1363.1177, current episode: 9
[2023-06-29 12:43:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1565.5110, current episode: 10
[2023-06-29 12:43:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 331000.000000 | iteration_331000.pth.tar | 10.000000     | 4130.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 413.000000              | 0.619635      | 6665.209498         | 16.138522            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1238.104077 | 137.928734 | 1565.510986 | 1078.794067 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1260.8992, current episode: 1
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1548.0907, current episode: 2
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1782.2776, current episode: 3
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1813.0350, current episode: 4
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2546.2363, current episode: 5
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1260.8992, current episode: 5
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2636.6624, current episode: 6
[2023-06-29 12:43:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2733.4116, current episode: 7
[2023-06-29 12:43:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1548.0907, current episode: 7
[2023-06-29 12:43:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3034.9910, current episode: 8
[2023-06-29 12:43:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3151.8667, current episode: 9
[2023-06-29 12:43:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3604.0635, current episode: 10
[2023-06-29 12:43:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 331500.000000 | iteration_331500.pth.tar | 10.000000     | 9510.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 951.000000              | 1.423913      | 6678.778999         | 7.022901             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2411.153394 | 731.779228 | 3604.063477 | 1260.899170 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1330.1909, current episode: 1
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1413.9608, current episode: 2
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1440.2147, current episode: 3
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1436.9591, current episode: 4
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1684.7341, current episode: 5
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1689.0768, current episode: 6
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1706.1832, current episode: 7
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2034.3102, current episode: 8
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2041.1078, current episode: 9
[2023-06-29 12:43:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2402.3267, current episode: 10
[2023-06-29 12:43:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 332000.000000 | iteration_332000.pth.tar | 10.000000     | 6440.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 644.000000              | 0.983062      | 6550.958458         | 10.172296            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1717.906433 | 327.692054 | 2402.326660 | 1330.190918 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1686.9690, current episode: 1
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1796.2402, current episode: 2
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1810.0096, current episode: 3
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2052.4312, current episode: 4
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2061.7043, current episode: 5
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2076.9106, current episode: 6
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2312.7712, current episode: 7
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2362.8125, current episode: 8
[2023-06-29 12:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1686.9690, current episode: 8
[2023-06-29 12:44:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1796.2402, current episode: 8
[2023-06-29 12:44:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1810.0096, current episode: 8
[2023-06-29 12:44:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3598.8833, current episode: 9
[2023-06-29 12:44:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3573.0630, current episode: 10
[2023-06-29 12:44:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 332500.000000 | iteration_332500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.569312      | 6372.219612         | 6.372220             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2333.179504 | 658.665499 | 3598.883301 | 1686.968994 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1291.4735, current episode: 1
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1297.7169, current episode: 2
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1346.7878, current episode: 3
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1914.3171, current episode: 4
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1954.8947, current episode: 5
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1997.0083, current episode: 6
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2572.8782, current episode: 7
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1291.4735, current episode: 7
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1297.7169, current episode: 7
[2023-06-29 12:44:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1346.7878, current episode: 7
[2023-06-29 12:44:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3566.3708, current episode: 8
[2023-06-29 12:44:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3533.9995, current episode: 9
[2023-06-29 12:44:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3543.0554, current episode: 10
[2023-06-29 12:44:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 333000.000000 | iteration_333000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514410      | 6603.230408         | 6.603230             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2301.850232 | 896.438976 | 3566.370850 | 1291.473511 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1696.4958, current episode: 1
[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1874.2744, current episode: 2
[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1857.9066, current episode: 3
[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1906.3057, current episode: 4
[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1974.2571, current episode: 5
[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1985.8260, current episode: 6
[2023-06-29 12:44:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2025.5806, current episode: 7
[2023-06-29 12:44:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2237.0227, current episode: 8
[2023-06-29 12:44:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2262.9600, current episode: 9
[2023-06-29 12:44:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1696.4958, current episode: 9
[2023-06-29 12:44:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3583.3694, current episode: 10
[2023-06-29 12:44:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 333500.000000 | iteration_333500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508877      | 6627.443506         | 6.627444             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2140.399829 | 507.313907 | 3583.369385 | 1696.495850 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:44:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1729.2400, current episode: 1
[2023-06-29 12:44:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1728.6543, current episode: 2
[2023-06-29 12:44:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1775.6151, current episode: 3
[2023-06-29 12:44:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1786.9712, current episode: 4
[2023-06-29 12:44:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2802.7891, current episode: 5
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3471.8796, current episode: 6
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1729.2400, current episode: 6
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3566.7144, current episode: 7
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1728.6543, current episode: 7
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1775.6151, current episode: 7
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1786.9712, current episode: 7
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3526.4460, current episode: 8
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3537.9507, current episode: 9
[2023-06-29 12:44:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3663.7593, current episode: 10
[2023-06-29 12:44:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 334000.000000 | iteration_334000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493069      | 6697.612054         | 6.697612             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2759.001965 | 849.161238 | 3663.759277 | 1728.654297 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1462.6737, current episode: 1
[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1743.6108, current episode: 2
[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1757.5475, current episode: 3
[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1822.0948, current episode: 4
[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1871.4622, current episode: 5
[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1854.5624, current episode: 6
[2023-06-29 12:45:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1938.6749, current episode: 7
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1462.6737, current episode: 7
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3351.1978, current episode: 8
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1743.6108, current episode: 8
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1757.5475, current episode: 8
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1822.0948, current episode: 8
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3552.9321, current episode: 9
[2023-06-29 12:45:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3598.1021, current episode: 10
[2023-06-29 12:45:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 334500.000000 | iteration_334500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486535      | 6727.054683         | 6.727055             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2295.285828 | 800.353034 | 3598.102051 | 1462.673706 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1418.8730, current episode: 1
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1421.8433, current episode: 2
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1435.2979, current episode: 3
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1496.6005, current episode: 4
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1655.5623, current episode: 5
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1663.3728, current episode: 6
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2054.8264, current episode: 7
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2197.2869, current episode: 8
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2407.9902, current episode: 9
[2023-06-29 12:45:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2531.4832, current episode: 10
[2023-06-29 12:45:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 335000.000000 | iteration_335000.pth.tar | 10.000000     | 6820.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 682.000000              | 1.036694      | 6578.602548         | 9.646045             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1828.313635 | 408.940696 | 2531.483154 | 1418.873047 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1357.2585, current episode: 1
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1454.0627, current episode: 2
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1532.6809, current episode: 3
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1546.9760, current episode: 4
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1620.5045, current episode: 5
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1796.3256, current episode: 6
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1918.5105, current episode: 7
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1930.9736, current episode: 8
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2685.8899, current episode: 9
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1357.2585, current episode: 9
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1454.0627, current episode: 9
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1532.6809, current episode: 9
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1546.9760, current episode: 9
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1620.5045, current episode: 9
[2023-06-29 12:45:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1796.3256, current episode: 9
[2023-06-29 12:45:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3595.5049, current episode: 10
[2023-06-29 12:45:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 335500.000000 | iteration_335500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.559752      | 6411.275831         | 6.411276             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1943.868713 | 656.982559 | 3595.504883 | 1357.258545 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:45:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1500.1027, current episode: 1
[2023-06-29 12:45:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1539.7058, current episode: 2
[2023-06-29 12:45:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1797.1060, current episode: 3
[2023-06-29 12:45:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1860.7772, current episode: 4
[2023-06-29 12:45:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1875.7870, current episode: 5
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2447.2798, current episode: 6
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2496.9045, current episode: 7
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2571.8918, current episode: 8
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2966.5854, current episode: 9
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1500.1027, current episode: 9
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1539.7058, current episode: 9
[2023-06-29 12:45:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3384.4768, current episode: 10
[2023-06-29 12:45:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 336000.000000 | iteration_336000.pth.tar | 10.000000     | 9160.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 916.000000              | 1.445669      | 6336.167094         | 6.917213             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2244.061707 | 597.258892 | 3384.476807 | 1500.102661 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1396.8368, current episode: 1
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2073.0491, current episode: 2
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2195.5803, current episode: 3
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2179.6868, current episode: 4
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2192.4087, current episode: 5
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2231.3638, current episode: 6
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2399.1868, current episode: 7
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2460.0232, current episode: 8
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1396.8368, current episode: 8
[2023-06-29 12:46:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3419.8035, current episode: 9
[2023-06-29 12:46:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3567.4929, current episode: 10
[2023-06-29 12:46:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 336500.000000 | iteration_336500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516680      | 6593.348927         | 6.593349             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2411.543176 | 606.663070 | 3567.492920 | 1396.836792 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1503.6243, current episode: 1
[2023-06-29 12:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1706.8380, current episode: 2
[2023-06-29 12:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1859.1825, current episode: 3
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2267.8164, current episode: 4
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2912.3772, current episode: 5
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2977.4670, current episode: 6
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1503.6243, current episode: 6
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3103.3240, current episode: 7
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3175.3987, current episode: 8
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1706.8380, current episode: 8
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3678.3044, current episode: 9
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1859.1825, current episode: 9
[2023-06-29 12:46:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3639.0193, current episode: 10
[2023-06-29 12:46:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 337000.000000 | iteration_337000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514700      | 6601.966003         | 6.601966             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2682.335181 | 752.191789 | 3678.304443 | 1503.624268 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:46:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1205.8192, current episode: 1
[2023-06-29 12:46:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1258.9982, current episode: 2
[2023-06-29 12:46:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1286.3547, current episode: 3
[2023-06-29 12:46:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1289.0332, current episode: 4
[2023-06-29 12:46:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1408.5037, current episode: 5
[2023-06-29 12:46:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1966.8451, current episode: 6
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1205.8192, current episode: 6
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1258.9982, current episode: 6
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1286.3547, current episode: 6
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1289.0332, current episode: 6
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2592.7522, current episode: 7
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1408.5037, current episode: 7
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3271.4700, current episode: 8
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3455.5442, current episode: 9
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1205.8192, current episode: 9
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1258.9982, current episode: 9
[2023-06-29 12:46:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3594.0852, current episode: 10
[2023-06-29 12:46:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 337500.000000 | iteration_337500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528912      | 6540.597293         | 6.540597             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2132.940564 | 948.499499 | 3594.085205 | 1205.819214 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1385.2150, current episode: 1
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1589.1129, current episode: 2
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1774.3856, current episode: 3
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1866.3741, current episode: 4
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2190.7422, current episode: 5
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2498.6499, current episode: 6
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2525.3804, current episode: 7
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1385.2150, current episode: 7
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2863.6306, current episode: 8
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3106.2512, current episode: 9
[2023-06-29 12:46:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1589.1129, current episode: 9
[2023-06-29 12:46:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1774.3856, current episode: 9
[2023-06-29 12:46:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1866.3741, current episode: 9
[2023-06-29 12:46:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3721.3787, current episode: 10
[2023-06-29 12:46:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 338000.000000 | iteration_338000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514954      | 6600.858982         | 6.600859             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2352.112061 | 697.823077 | 3721.378662 | 1385.214966 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:47:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1564.7313, current episode: 1
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2638.8237, current episode: 2
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2827.1372, current episode: 3
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3070.4207, current episode: 4
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1564.7313, current episode: 4
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3121.1736, current episode: 5
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3555.1392, current episode: 6
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3571.8169, current episode: 7
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.6936, current episode: 8
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3574.2439, current episode: 9
[2023-06-29 12:47:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3546.3716, current episode: 10
[2023-06-29 12:47:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 338500.000000 | iteration_338500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508411      | 6629.494452         | 6.629494             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3102.155164 | 608.556422 | 3574.243896 | 1564.731323 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1288.2714, current episode: 1
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1294.1562, current episode: 2
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1297.8698, current episode: 3
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1343.3099, current episode: 4
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1512.2064, current episode: 5
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.3407, current episode: 6
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1904.9462, current episode: 7
[2023-06-29 12:47:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1923.9982, current episode: 8
[2023-06-29 12:47:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2235.4209, current episode: 9
[2023-06-29 12:47:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2308.8711, current episode: 10
[2023-06-29 12:47:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 339000.000000 | iteration_339000.pth.tar | 10.000000     | 6130.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 613.000000              | 0.949123      | 6458.596054         | 10.536046            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1662.439075 | 377.889014 | 2308.871094 | 1288.271362 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:47:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1941.6400, current episode: 1
[2023-06-29 12:47:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2602.8262, current episode: 2
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3563.1716, current episode: 3
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3560.5110, current episode: 4
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3556.5618, current episode: 5
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3553.5688, current episode: 6
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3561.8679, current episode: 7
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3562.5847, current episode: 8
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3564.7893, current episode: 9
[2023-06-29 12:47:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3570.3464, current episode: 10
[2023-06-29 12:47:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 339500.000000 | iteration_339500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498610      | 6672.848066         | 6.672848             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3303.786780 | 536.565215 | 3570.346436 | 1941.640015 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:47:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1151.3657, current episode: 1
[2023-06-29 12:47:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1665.2167, current episode: 2
[2023-06-29 12:47:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1887.5663, current episode: 3
[2023-06-29 12:47:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1151.3657, current episode: 3
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3123.7751, current episode: 4
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1665.2167, current episode: 4
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1151.3657, current episode: 4
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3554.8821, current episode: 5
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3565.9763, current episode: 6
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3542.9961, current episode: 7
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.0659, current episode: 8
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3552.1140, current episode: 9
[2023-06-29 12:47:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.2710, current episode: 10
[2023-06-29 12:47:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 340000.000000 | iteration_340000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522172      | 6569.561406         | 6.569561             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2914.122925 | 906.008704 | 3565.976318 | 1151.365723 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:48:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1830.4219, current episode: 1
[2023-06-29 12:48:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1962.1736, current episode: 2
[2023-06-29 12:48:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1830.4219, current episode: 2
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3523.3940, current episode: 3
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3525.5566, current episode: 4
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3519.2029, current episode: 5
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.5715, current episode: 6
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3538.4077, current episode: 7
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3523.8679, current episode: 8
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3539.5410, current episode: 9
[2023-06-29 12:48:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3530.9236, current episode: 10
[2023-06-29 12:48:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 340500.000000 | iteration_340500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511447      | 6616.178462         | 6.616178             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3202.606079 | 653.847416 | 3539.541016 | 1830.421875 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:48:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1972.6766, current episode: 1
[2023-06-29 12:48:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2000.8396, current episode: 2
[2023-06-29 12:48:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2147.2019, current episode: 3
[2023-06-29 12:48:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2165.5991, current episode: 4
[2023-06-29 12:48:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3738.4060, current episode: 5
[2023-06-29 12:48:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.5627, current episode: 6
[2023-06-29 12:48:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3570.3062, current episode: 7
[2023-06-29 12:48:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3569.7676, current episode: 8
[2023-06-29 12:48:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3580.9033, current episode: 9
[2023-06-29 12:48:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3576.1265, current episode: 10
[2023-06-29 12:48:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 341000.000000 | iteration_341000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496641      | 6681.628011         | 6.681628             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2989.138953 | 752.656915 | 3738.406006 | 1972.676636 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3564.4182, current episode: 1
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3755.9678, current episode: 2
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3557.2744, current episode: 3
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3547.9287, current episode: 4
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3556.8984, current episode: 5
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3722.1348, current episode: 6
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3552.6934, current episode: 7
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3564.6951, current episode: 8
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3568.0000, current episode: 9
[2023-06-29 12:48:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3562.7585, current episode: 10
[2023-06-29 12:48:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 341500.000000 | iteration_341500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487860      | 6721.061980         | 6.721062             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3595.276929 | 72.509143  | 3755.967773 | 3547.928711 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3557.4670, current episode: 1
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3565.9009, current episode: 2
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3554.4814, current episode: 3
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3561.8818, current episode: 4
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3553.0632, current episode: 5
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3548.6482, current episode: 6
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.1047, current episode: 7
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3568.8818, current episode: 8
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3563.1680, current episode: 9
[2023-06-29 12:48:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3562.6685, current episode: 10
[2023-06-29 12:48:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 342000.000000 | iteration_342000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.461967      | 6840.100053         | 6.840100             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3560.526563 | 6.545086   | 3569.104736 | 3548.648193 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3547.8430, current episode: 1
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3558.5000, current episode: 2
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3556.5281, current episode: 3
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3553.0623, current episode: 4
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.1348, current episode: 5
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3561.6172, current episode: 6
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3551.9541, current episode: 7
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3570.1851, current episode: 8
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3580.0366, current episode: 9
[2023-06-29 12:49:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3540.9680, current episode: 10
[2023-06-29 12:49:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 342500.000000 | iteration_342500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.458223      | 6857.662157         | 6.857662             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3557.182910 | 10.696873  | 3580.036621 | 3540.968018 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3548.6509, current episode: 1
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3560.8984, current episode: 2
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.6833, current episode: 3
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3540.5735, current episode: 4
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.2349, current episode: 5
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3553.1541, current episode: 6
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3549.3086, current episode: 7
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3545.1128, current episode: 8
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3560.1443, current episode: 9
[2023-06-29 12:49:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3557.2634, current episode: 10
[2023-06-29 12:49:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 343000.000000 | iteration_343000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.464086      | 6830.200157         | 6.830200             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3550.702417 | 6.948532   | 3560.898438 | 3540.573486 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3548.3848, current episode: 1
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3573.5784, current episode: 2
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3556.1384, current episode: 3
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3544.3367, current episode: 4
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3540.2188, current episode: 5
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3558.9390, current episode: 6
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3540.8530, current episode: 7
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3549.2856, current episode: 8
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3534.5789, current episode: 9
[2023-06-29 12:49:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3544.8157, current episode: 10
[2023-06-29 12:49:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 343500.000000 | iteration_343500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509029      | 6626.779258         | 6.626779             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3549.112915 | 10.699893  | 3573.578369 | 3534.578857 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3528.2034, current episode: 1
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3555.0278, current episode: 2
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3544.9644, current episode: 3
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.8215, current episode: 4
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3536.5496, current episode: 5
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3544.4480, current episode: 6
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3555.3003, current episode: 7
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3544.1926, current episode: 8
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3567.3120, current episode: 9
[2023-06-29 12:49:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3558.0417, current episode: 10
[2023-06-29 12:49:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 344000.000000 | iteration_344000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493515      | 6695.615067         | 6.695615             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3547.586133 | 10.827201  | 3567.312012 | 3528.203369 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:50:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2314.7371, current episode: 1
[2023-06-29 12:50:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2796.6824, current episode: 2
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2941.2083, current episode: 3
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.5742, current episode: 4
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3568.9299, current episode: 5
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3592.7180, current episode: 6
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3561.7654, current episode: 7
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3578.6458, current episode: 8
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3559.4990, current episode: 9
[2023-06-29 12:50:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.3767, current episode: 10
[2023-06-29 12:50:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 344500.000000 | iteration_344500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497650      | 6677.127391         | 6.677127             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3305.013672 | 432.170210 | 3592.718018 | 2314.737061 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3574.5583, current episode: 1
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3574.9099, current episode: 2
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3564.1648, current episode: 3
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3553.8550, current episode: 4
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3558.5967, current episode: 5
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3587.7412, current episode: 6
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3568.9463, current episode: 7
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3564.5498, current episode: 8
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3584.4619, current episode: 9
[2023-06-29 12:50:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3575.0945, current episode: 10
[2023-06-29 12:50:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 345000.000000 | iteration_345000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.549996      | 6451.628146         | 6.451628             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3570.687842 | 10.225301  | 3587.741211 | 3553.854980 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1796.0886, current episode: 1
[2023-06-29 12:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2003.3965, current episode: 2
[2023-06-29 12:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2919.5085, current episode: 3
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1796.0886, current episode: 3
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3601.5081, current episode: 4
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3617.0120, current episode: 5
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3584.7351, current episode: 6
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3615.2844, current episode: 7
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3614.9890, current episode: 8
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3586.5083, current episode: 9
[2023-06-29 12:50:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3640.6458, current episode: 10
[2023-06-29 12:50:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 345500.000000 | iteration_345500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488702      | 6717.262060         | 6.717262             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3197.967627 | 682.116153 | 3640.645752 | 1796.088623 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:50:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1578.7070, current episode: 1
[2023-06-29 12:50:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1607.1639, current episode: 2
[2023-06-29 12:50:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1713.3873, current episode: 3
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1578.7070, current episode: 3
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1607.1639, current episode: 3
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1713.3873, current episode: 3
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3555.5051, current episode: 4
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3573.4424, current episode: 5
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3563.6221, current episode: 6
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.3586, current episode: 7
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3574.2708, current episode: 8
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3553.8909, current episode: 9
[2023-06-29 12:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3554.7109, current episode: 10
[2023-06-29 12:50:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 346000.000000 | iteration_346000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.488949      | 6715.476360         | 6.716148             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2984.405908 | 885.243121 | 3574.270752 | 1578.707031 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:51:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1157.8074, current episode: 1
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1157.8074, current episode: 1
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1157.8074, current episode: 1
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3554.1445, current episode: 2
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3535.4314, current episode: 3
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3568.8245, current episode: 4
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3559.7893, current episode: 5
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3544.5754, current episode: 6
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.7903, current episode: 7
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3542.2617, current episode: 8
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3545.7183, current episode: 9
[2023-06-29 12:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3554.5398, current episode: 10
[2023-06-29 12:51:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 346500.000000 | iteration_346500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.459950      | 6849.549298         | 6.849549             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3312.288257 | 718.221452 | 3568.824463 | 1157.807373 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:51:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2264.2908, current episode: 1
[2023-06-29 12:51:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3115.2134, current episode: 2
[2023-06-29 12:51:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3429.1104, current episode: 3
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3563.3833, current episode: 4
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.9512, current episode: 5
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3601.3955, current episode: 6
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3587.2844, current episode: 7
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3541.4253, current episode: 8
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.1719, current episode: 9
[2023-06-29 12:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3543.4163, current episode: 10
[2023-06-29 12:51:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 347000.000000 | iteration_347000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.482492      | 6745.399777         | 6.745400             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3372.964233 | 393.437996 | 3601.395508 | 2264.290771 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 855.4691, current episode: 1
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.2975, current episode: 2
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1103.8154, current episode: 3
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1237.6873, current episode: 4
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 855.4691, current episode: 4
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.2975, current episode: 4
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1103.8154, current episode: 4
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1237.6873, current episode: 4
[2023-06-29 12:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 855.4691, current episode: 4
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3019.4141, current episode: 5
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.2975, current episode: 5
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1103.8154, current episode: 5
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3405.5156, current episode: 6
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 855.4691, current episode: 6
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1237.6873, current episode: 6
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3576.8533, current episode: 7
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.1514, current episode: 8
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3528.5251, current episode: 9
[2023-06-29 12:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3550.9612, current episode: 10
[2023-06-29 12:51:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 347500.000000 | iteration_347500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504114      | 6648.433252         | 6.648433             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2484.468994 | 1188.485848 | 3582.151367 | 855.469055 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 12:51:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1961.9681, current episode: 1
[2023-06-29 12:51:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2225.8713, current episode: 2
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3088.9275, current episode: 3
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3323.6643, current episode: 4
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3507.0354, current episode: 5
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3530.6094, current episode: 6
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3535.5918, current episode: 7
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3543.2207, current episode: 8
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3553.9121, current episode: 9
[2023-06-29 12:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3520.2781, current episode: 10
[2023-06-29 12:51:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 348000.000000 | iteration_348000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505962      | 6640.275247         | 6.640275             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3179.107874 | 562.738138 | 3553.912109 | 1961.968140 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1684.7419, current episode: 1
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1887.1912, current episode: 2
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2040.0206, current episode: 3
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2106.6655, current episode: 4
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2116.8457, current episode: 5
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2163.1965, current episode: 6
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2430.8374, current episode: 7
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2440.3801, current episode: 8
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1684.7419, current episode: 8
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3490.2461, current episode: 9
[2023-06-29 12:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3629.7288, current episode: 10
[2023-06-29 12:52:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 348500.000000 | iteration_348500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505675      | 6641.538217         | 6.641538             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2398.985388 | 618.861056 | 3629.728760 | 1684.741943 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3517.7717, current episode: 1
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3510.2375, current episode: 2
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3484.4233, current episode: 3
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3507.2661, current episode: 4
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3491.2268, current episode: 5
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3498.5149, current episode: 6
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3518.5317, current episode: 7
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.9375, current episode: 8
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3520.5352, current episode: 9
[2023-06-29 12:52:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3504.2549, current episode: 10
[2023-06-29 12:52:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 349000.000000 | iteration_349000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517359      | 6590.399207         | 6.590399             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3505.469971 | 11.327025  | 3520.535156 | 3484.423340 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3512.6836, current episode: 1
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3533.3228, current episode: 2
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3532.1479, current episode: 3
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3509.8491, current episode: 4
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3511.5076, current episode: 5
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3518.2102, current episode: 6
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3510.3545, current episode: 7
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3526.6938, current episode: 8
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3509.3853, current episode: 9
[2023-06-29 12:52:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3512.0498, current episode: 10
[2023-06-29 12:52:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 349500.000000 | iteration_349500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479699      | 6758.132446         | 6.758132             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3517.620459 | 9.022544   | 3533.322754 | 3509.385254 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3514.4016, current episode: 1
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3524.1401, current episode: 2
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.0051, current episode: 3
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3530.6729, current episode: 4
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3525.3037, current episode: 5
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3535.8770, current episode: 6
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3510.9500, current episode: 7
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3533.4192, current episode: 8
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3543.4282, current episode: 9
[2023-06-29 12:52:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3536.2725, current episode: 10
[2023-06-29 12:52:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 350000.000000 | iteration_350000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496462      | 6682.429761         | 6.682430             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3529.447021 | 10.129141  | 3543.428223 | 3510.949951 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3517.6196, current episode: 1
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3527.7715, current episode: 2
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3530.4617, current episode: 3
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3510.6357, current episode: 4
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3522.8799, current episode: 5
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3533.3364, current episode: 6
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3527.0938, current episode: 7
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3535.3313, current episode: 8
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3529.8677, current episode: 9
[2023-06-29 12:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.5864, current episode: 10
[2023-06-29 12:53:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 350500.000000 | iteration_350500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501708      | 6659.084696         | 6.659085             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3526.458398 | 7.119575   | 3535.331299 | 3510.635742 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3488.3169, current episode: 1
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3492.8296, current episode: 2
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3451.7249, current episode: 3
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.7090, current episode: 4
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3476.3420, current episode: 5
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3483.5103, current episode: 6
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.7285, current episode: 7
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3480.4626, current episode: 8
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3499.4209, current episode: 9
[2023-06-29 12:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.5547, current episode: 10
[2023-06-29 12:53:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 351000.000000 | iteration_351000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499748      | 6667.788275         | 6.667788             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3482.859937 | 12.201686  | 3499.420898 | 3451.724854 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3483.0486, current episode: 1
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3496.2039, current episode: 2
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3502.2427, current episode: 3
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3476.1008, current episode: 4
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3464.9504, current episode: 5
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3490.9565, current episode: 6
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3476.5344, current episode: 7
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3500.8245, current episode: 8
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3491.3660, current episode: 9
[2023-06-29 12:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3493.7764, current episode: 10
[2023-06-29 12:53:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 351500.000000 | iteration_351500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508951      | 6627.118603         | 6.627119             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3487.600415 | 11.468710  | 3502.242676 | 3464.950439 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3474.2351, current episode: 1
[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3495.6309, current episode: 2
[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3478.4392, current episode: 3
[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3472.4473, current episode: 4
[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3473.1448, current episode: 5
[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3481.1360, current episode: 6
[2023-06-29 12:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3492.7747, current episode: 7
[2023-06-29 12:54:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3486.8206, current episode: 8
[2023-06-29 12:54:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3499.5762, current episode: 9
[2023-06-29 12:54:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3483.4287, current episode: 10
[2023-06-29 12:54:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 352000.000000 | iteration_352000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.484062      | 6738.262349         | 6.738262             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3483.763330 | 9.210809   | 3499.576172 | 3472.447266 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1644.8540, current episode: 1
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1644.8540, current episode: 1
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.0776, current episode: 2
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3502.3403, current episode: 3
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3494.2842, current episode: 4
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3498.1833, current episode: 5
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3510.8218, current episode: 6
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3494.0776, current episode: 7
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3486.1633, current episode: 8
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3520.9778, current episode: 9
[2023-06-29 12:54:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3508.9514, current episode: 10
[2023-06-29 12:54:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 352500.000000 | iteration_352500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487347      | 6723.382071         | 6.723382             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3315.273145 | 556.892683 | 3520.977783 | 1644.854004 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1346.3801, current episode: 1
[2023-06-29 12:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1476.2419, current episode: 2
[2023-06-29 12:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1489.6945, current episode: 3
[2023-06-29 12:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1503.7523, current episode: 4
[2023-06-29 12:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1648.9775, current episode: 5
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1346.3801, current episode: 5
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1476.2419, current episode: 5
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1489.6945, current episode: 5
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1503.7523, current episode: 5
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1648.9775, current episode: 5
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3502.4624, current episode: 6
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3451.5955, current episode: 7
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3502.3567, current episode: 8
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.8872, current episode: 9
[2023-06-29 12:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.5608, current episode: 10
[2023-06-29 12:54:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 353000.000000 | iteration_353000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498768      | 6672.146971         | 6.672147             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2494.490894 | 1003.919273 | 3518.887207 | 1346.380127 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1301.5168, current episode: 1
[2023-06-29 12:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1312.8154, current episode: 2
[2023-06-29 12:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1306.0120, current episode: 3
[2023-06-29 12:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1639.2395, current episode: 4
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1301.5168, current episode: 4
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1312.8154, current episode: 4
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1306.0120, current episode: 4
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1639.2395, current episode: 4
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3504.0962, current episode: 5
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3501.5435, current episode: 6
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3500.9136, current episode: 7
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3475.1604, current episode: 8
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3510.0234, current episode: 9
[2023-06-29 12:54:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3512.6770, current episode: 10
[2023-06-29 12:54:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 353500.000000 | iteration_353500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553058      | 6438.910133         | 6.438910             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2656.399780 | 1038.142694 | 3512.677002 | 1301.516846 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:55:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1660.4240, current episode: 1
[2023-06-29 12:55:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1660.4240, current episode: 1
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3483.6890, current episode: 2
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3505.0132, current episode: 3
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3502.8770, current episode: 4
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3470.7517, current episode: 5
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3495.3542, current episode: 6
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.3013, current episode: 7
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3488.6814, current episode: 8
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3508.7568, current episode: 9
[2023-06-29 12:55:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3463.2976, current episode: 10
[2023-06-29 12:55:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 354000.000000 | iteration_354000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507207      | 6634.788044         | 6.634788             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3307.614612 | 549.240777 | 3508.756836 | 1660.423950 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3532.5513, current episode: 1
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3548.6814, current episode: 2
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3545.9917, current episode: 3
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3529.6274, current episode: 4
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3537.1555, current episode: 5
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3545.0737, current episode: 6
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3551.1155, current episode: 7
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3536.4233, current episode: 8
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3552.1492, current episode: 9
[2023-06-29 12:55:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3528.6938, current episode: 10
[2023-06-29 12:55:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 354500.000000 | iteration_354500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.459800      | 6850.253803         | 6.850254             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3540.746289 | 8.452117   | 3552.149170 | 3528.693848 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 739.1370, current episode: 1
[2023-06-29 12:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 739.1370, current episode: 1
[2023-06-29 12:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 739.1370, current episode: 1
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 739.1370, current episode: 1
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3491.2817, current episode: 2
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3531.0923, current episode: 3
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3517.1367, current episode: 4
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3488.2034, current episode: 5
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3526.6240, current episode: 6
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3516.8467, current episode: 7
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3487.7217, current episode: 8
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3543.5303, current episode: 9
[2023-06-29 12:55:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3526.1768, current episode: 10
[2023-06-29 12:55:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 355000.000000 | iteration_355000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511608      | 6615.473732         | 6.615474             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 3236.775055 | 832.747845 | 3543.530273 | 739.137024 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 12:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1286.3562, current episode: 1
[2023-06-29 12:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1286.3562, current episode: 1
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3506.7861, current episode: 2
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3537.1597, current episode: 3
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3500.0276, current episode: 4
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3519.7097, current episode: 5
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3509.0146, current episode: 6
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.5918, current episode: 7
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3503.7297, current episode: 8
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3527.1628, current episode: 9
[2023-06-29 12:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3519.4998, current episode: 10
[2023-06-29 12:55:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 355500.000000 | iteration_355500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501854      | 6658.435739         | 6.658436             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3292.203809 | 668.701238 | 3537.159668 | 1286.356201 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 871.0161, current episode: 1
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 948.2956, current episode: 2
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1009.7252, current episode: 3
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1034.2003, current episode: 4
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1049.3176, current episode: 5
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1196.9847, current episode: 6
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1195.6681, current episode: 7
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1213.4032, current episode: 8
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1251.9366, current episode: 9
[2023-06-29 12:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.0912, current episode: 10
[2023-06-29 12:56:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 356000.000000 | iteration_356000.pth.tar | 10.000000     | 3470.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 347.000000              | 0.562608      | 6167.707013         | 17.774372            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1105.463867 | 133.637635 | 1284.091187 | 871.016113 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 985.1299, current episode: 1
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1020.8409, current episode: 2
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1028.3717, current episode: 3
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1161.5433, current episode: 4
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1192.8479, current episode: 5
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1188.2158, current episode: 6
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1357.7888, current episode: 7
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1483.3774, current episode: 8
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 985.1299, current episode: 8
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1020.8409, current episode: 8
[2023-06-29 12:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1028.3717, current episode: 8
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1161.5433, current episode: 8
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1192.8479, current episode: 8
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1188.2158, current episode: 8
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2415.5159, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1357.7888, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1483.3774, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 985.1299, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1020.8409, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1028.3717, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1161.5433, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1192.8479, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1188.2158, current episode: 9
[2023-06-29 12:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.9609, current episode: 10
[2023-06-29 12:56:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 356500.000000 | iteration_356500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548903      | 6456.182405         | 6.456182             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1536.859271 | 775.201401 | 3534.960938 | 985.129944 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1161.2618, current episode: 1
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1196.8721, current episode: 2
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1262.0903, current episode: 3
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1301.6682, current episode: 4
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1440.2305, current episode: 5
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1161.2618, current episode: 5
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1196.8721, current episode: 5
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1262.0903, current episode: 5
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1301.6682, current episode: 5
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1440.2305, current episode: 5
[2023-06-29 12:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1161.2618, current episode: 5
[2023-06-29 12:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1196.8721, current episode: 5
[2023-06-29 12:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3539.5151, current episode: 6
[2023-06-29 12:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3562.0879, current episode: 7
[2023-06-29 12:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3553.3950, current episode: 8
[2023-06-29 12:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3548.0339, current episode: 9
[2023-06-29 12:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3546.4314, current episode: 10
[2023-06-29 12:56:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 357000.000000 | iteration_357000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510700      | 6619.448687         | 6.619449             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2411.158630 | 1140.816485 | 3562.087891 | 1161.261841 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1058.7935, current episode: 1
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1187.7909, current episode: 2
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1224.3073, current episode: 3
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1297.8153, current episode: 4
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1469.0428, current episode: 5
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1058.7935, current episode: 5
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1187.7909, current episode: 5
[2023-06-29 12:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1224.3073, current episode: 5
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1297.8153, current episode: 5
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1469.0428, current episode: 5
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1058.7935, current episode: 5
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1187.7909, current episode: 5
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1224.3073, current episode: 5
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3521.4141, current episode: 6
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3520.1729, current episode: 7
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3528.4395, current episode: 8
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3532.3438, current episode: 9
[2023-06-29 12:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.5454, current episode: 10
[2023-06-29 12:56:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 357500.000000 | iteration_357500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.549607      | 6453.249391         | 6.453249             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2386.366528 | 1142.823780 | 3532.343750 | 1058.793457 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.5712, current episode: 1
[2023-06-29 12:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1269.0386, current episode: 2
[2023-06-29 12:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1276.1802, current episode: 3
[2023-06-29 12:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1294.0435, current episode: 4
[2023-06-29 12:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1351.6848, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.5712, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1269.0386, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1276.1802, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1294.0435, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1351.6848, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.5712, current episode: 5
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3538.4988, current episode: 6
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3544.3164, current episode: 7
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.2402, current episode: 8
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3558.4971, current episode: 9
[2023-06-29 12:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.3296, current episode: 10
[2023-06-29 12:57:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 358000.000000 | iteration_358000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.537921      | 6502.284491         | 6.502284             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2408.740027 | 1125.468229 | 3558.497070 | 1227.571167 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1289.6814, current episode: 1
[2023-06-29 12:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1580.6689, current episode: 2
[2023-06-29 12:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1289.6814, current episode: 2
[2023-06-29 12:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1580.6689, current episode: 2
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3551.8323, current episode: 3
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3541.8748, current episode: 4
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3550.3865, current episode: 5
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3537.8506, current episode: 6
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3561.1816, current episode: 7
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3560.6479, current episode: 8
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3564.7983, current episode: 9
[2023-06-29 12:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3560.4883, current episode: 10
[2023-06-29 12:57:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 358500.000000 | iteration_358500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487374      | 6723.259573         | 6.723260             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3129.941064 | 849.917316 | 3564.798340 | 1289.681396 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3484.2295, current episode: 1
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3492.1494, current episode: 2
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3495.4565, current episode: 3
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3519.4878, current episode: 4
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3470.0518, current episode: 5
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3490.2668, current episode: 6
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3490.0098, current episode: 7
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3505.7573, current episode: 8
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.8523, current episode: 9
[2023-06-29 12:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3502.4143, current episode: 10
[2023-06-29 12:57:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 359000.000000 | iteration_359000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.480742      | 6753.370647         | 6.753371             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3492.767554 | 13.448449  | 3519.487793 | 3470.051758 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1290.8940, current episode: 1
[2023-06-29 12:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1310.3199, current episode: 2
[2023-06-29 12:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1290.8940, current episode: 2
[2023-06-29 12:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1310.3199, current episode: 2
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3523.3989, current episode: 3
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3558.5520, current episode: 4
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3550.4434, current episode: 5
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3501.8401, current episode: 6
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.0684, current episode: 7
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3526.2375, current episode: 8
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3544.9451, current episode: 9
[2023-06-29 12:57:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3495.0166, current episode: 10
[2023-06-29 12:57:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 359500.000000 | iteration_359500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476287      | 6773.748450         | 6.773748             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3083.571594 | 891.691618 | 3558.552002 | 1290.894043 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1438.7993, current episode: 1
[2023-06-29 12:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1453.7612, current episode: 2
[2023-06-29 12:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1438.7993, current episode: 2
[2023-06-29 12:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1453.7612, current episode: 2
[2023-06-29 12:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3530.9619, current episode: 3
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3525.1436, current episode: 4
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3547.8799, current episode: 5
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3552.9514, current episode: 6
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.0959, current episode: 7
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3539.0859, current episode: 8
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3585.2302, current episode: 9
[2023-06-29 12:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3567.0483, current episode: 10
[2023-06-29 12:58:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 360000.000000 | iteration_360000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508966      | 6627.055878         | 6.627056             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3127.495776 | 840.784424 | 3585.230225 | 1438.799316 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:58:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1054.3715, current episode: 1
[2023-06-29 12:58:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1173.4119, current episode: 2
[2023-06-29 12:58:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1431.0961, current episode: 3
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1054.3715, current episode: 3
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1173.4119, current episode: 3
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1431.0961, current episode: 3
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1054.3715, current episode: 3
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1173.4119, current episode: 3
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3520.9519, current episode: 4
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3561.0332, current episode: 5
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3554.6719, current episode: 6
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3528.1704, current episode: 7
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3533.7417, current episode: 8
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.2161, current episode: 9
[2023-06-29 12:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3537.5308, current episode: 10
[2023-06-29 12:58:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 360500.000000 | iteration_360500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508435      | 6629.387154         | 6.629387             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2843.019531 | 1066.300861 | 3561.033203 | 1054.371460 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1216.2679, current episode: 1
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1277.3334, current episode: 2
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1330.5924, current episode: 3
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1342.3995, current episode: 4
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1365.0439, current episode: 5
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1980.0535, current episode: 6
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1216.2679, current episode: 6
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1277.3334, current episode: 6
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1330.5924, current episode: 6
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1342.3995, current episode: 6
[2023-06-29 12:58:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1365.0439, current episode: 6
[2023-06-29 12:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1216.2679, current episode: 6
[2023-06-29 12:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3540.4553, current episode: 7
[2023-06-29 12:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.1265, current episode: 8
[2023-06-29 12:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3531.0774, current episode: 9
[2023-06-29 12:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3542.3572, current episode: 10
[2023-06-29 12:58:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 361000.000000 | iteration_361000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.532080      | 6527.072931         | 6.527073             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2266.070703 | 1056.661642 | 3542.357178 | 1216.267944 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:58:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1199.1777, current episode: 1
[2023-06-29 12:58:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1219.5287, current episode: 2
[2023-06-29 12:58:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.3075, current episode: 3
[2023-06-29 12:58:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1280.5892, current episode: 4
[2023-06-29 12:58:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1612.5654, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1199.1777, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1219.5287, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.3075, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1280.5892, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1612.5654, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1199.1777, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1219.5287, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.3075, current episode: 5
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.9294, current episode: 6
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3544.8218, current episode: 7
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3555.1482, current episode: 8
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.8909, current episode: 9
[2023-06-29 12:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3563.0974, current episode: 10
[2023-06-29 12:58:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 361500.000000 | iteration_361500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517781      | 6588.567372         | 6.588567             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2433.905627 | 1128.305909 | 3569.890869 | 1199.177734 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 12:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1302.6273, current episode: 1
[2023-06-29 12:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1312.7384, current episode: 2
[2023-06-29 12:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1383.4020, current episode: 3
[2023-06-29 12:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1302.6273, current episode: 3
[2023-06-29 12:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1312.7384, current episode: 3
[2023-06-29 12:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1383.4020, current episode: 3
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3510.3020, current episode: 4
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3485.3633, current episode: 5
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3498.4001, current episode: 6
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3500.9116, current episode: 7
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3502.8850, current episode: 8
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.1758, current episode: 9
[2023-06-29 12:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3486.3267, current episode: 10
[2023-06-29 12:59:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 362000.000000 | iteration_362000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.490703      | 6708.242155         | 6.708242             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2849.913220 | 993.337791 | 3516.175781 | 1302.627319 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3515.2246, current episode: 1
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3486.4854, current episode: 2
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3504.2949, current episode: 3
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.2900, current episode: 4
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3476.3672, current episode: 5
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3506.7908, current episode: 6
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3481.9915, current episode: 7
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3489.7119, current episode: 8
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3504.6755, current episode: 9
[2023-06-29 12:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3511.0168, current episode: 10
[2023-06-29 12:59:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 362500.000000 | iteration_362500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500271      | 6665.462457         | 6.665462             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3495.684863 | 13.465391  | 3515.224609 | 3476.367188 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1654.6714, current episode: 1
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1654.6714, current episode: 1
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3447.9438, current episode: 2
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3533.1003, current episode: 3
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.0122, current episode: 4
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3540.7659, current episode: 5
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3555.6184, current episode: 6
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3496.2319, current episode: 7
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3499.7866, current episode: 8
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3565.1707, current episode: 9
[2023-06-29 12:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.3030, current episode: 10
[2023-06-29 12:59:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 363000.000000 | iteration_363000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483676      | 6740.018117         | 6.740018             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3335.260425 | 561.150540 | 3565.170654 | 1654.671387 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1289.3933, current episode: 1
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1399.8309, current episode: 2
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1623.7917, current episode: 3
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2219.1875, current episode: 4
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1289.3933, current episode: 4
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1399.8309, current episode: 4
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1623.7917, current episode: 4
[2023-06-29 12:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3596.0586, current episode: 5
[2023-06-29 12:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3547.2981, current episode: 6
[2023-06-29 12:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3538.9211, current episode: 7
[2023-06-29 12:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.7632, current episode: 8
[2023-06-29 12:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3566.8789, current episode: 9
[2023-06-29 12:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3549.3455, current episode: 10
[2023-06-29 12:59:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 363500.000000 | iteration_363500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.489669      | 6712.902548         | 6.712903             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2790.946887 | 972.453473 | 3596.058594 | 1289.393311 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1360.4615, current episode: 1
[2023-06-29 13:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1892.7795, current episode: 2
[2023-06-29 13:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2123.1204, current episode: 3
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1360.4615, current episode: 3
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3554.3047, current episode: 4
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1892.7795, current episode: 4
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3565.5034, current episode: 5
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3546.3438, current episode: 6
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3561.9971, current episode: 7
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3534.9199, current episode: 8
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3512.1228, current episode: 9
[2023-06-29 13:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3522.8657, current episode: 10
[2023-06-29 13:00:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 364000.000000 | iteration_364000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520615      | 6576.284499         | 6.576284             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3017.441882 | 821.162398 | 3565.503418 | 1360.461548 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1345.5248, current episode: 1
[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1636.2714, current episode: 2
[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2212.6831, current episode: 3
[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2189.0342, current episode: 4
[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2425.1421, current episode: 5
[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2421.1191, current episode: 6
[2023-06-29 13:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1345.5248, current episode: 6
[2023-06-29 13:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2768.2817, current episode: 7
[2023-06-29 13:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3054.9868, current episode: 8
[2023-06-29 13:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3124.0928, current episode: 9
[2023-06-29 13:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1636.2714, current episode: 9
[2023-06-29 13:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3374.9983, current episode: 10
[2023-06-29 13:00:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 364500.000000 | iteration_364500.pth.tar | 10.000000     | 9090.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 909.000000              | 1.375685      | 6607.619360         | 7.269108             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2455.213428 | 615.220100 | 3374.998291 | 1345.524780 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1484.8715, current episode: 1
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1485.3313, current episode: 2
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1532.4714, current episode: 3
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1492.2576, current episode: 4
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1532.4409, current episode: 5
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1559.5850, current episode: 6
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1729.9329, current episode: 7
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1769.4608, current episode: 8
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1791.3774, current episode: 9
[2023-06-29 13:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1832.1608, current episode: 10
[2023-06-29 13:00:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 365000.000000 | iteration_365000.pth.tar | 10.000000     | 4920.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 492.000000              | 0.747090      | 6585.551167         | 13.385267            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1620.988953 | 134.345725 | 1832.160767 | 1484.871460 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1181.6952, current episode: 1
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1336.0087, current episode: 2
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1354.3877, current episode: 3
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1481.0945, current episode: 4
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1590.5227, current episode: 5
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1603.5688, current episode: 6
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1814.1836, current episode: 7
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1888.0797, current episode: 8
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1920.7427, current episode: 9
[2023-06-29 13:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2092.9365, current episode: 10
[2023-06-29 13:00:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 365500.000000 | iteration_365500.pth.tar | 10.000000     | 5500.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 550.000000              | 0.847978      | 6486.018050         | 11.792760            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1626.322009 | 280.541468 | 2092.936523 | 1181.695190 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:01:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1900.5917, current episode: 1
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1951.3109, current episode: 2
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1980.5571, current episode: 3
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1953.7876, current episode: 4
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2471.6033, current episode: 5
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2863.0190, current episode: 6
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2886.1733, current episode: 7
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3015.7664, current episode: 8
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3620.6008, current episode: 9
[2023-06-29 13:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.1003, current episode: 10
[2023-06-29 13:01:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 366000.000000 | iteration_366000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502319      | 6656.373880         | 6.656374             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2620.351050 | 633.322045 | 3620.600830 | 1900.591675 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3574.0168, current episode: 1
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3578.0781, current episode: 2
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3555.6252, current episode: 3
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3579.7898, current episode: 4
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3572.2122, current episode: 5
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3570.1489, current episode: 6
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3552.4485, current episode: 7
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3560.8555, current episode: 8
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3561.7209, current episode: 9
[2023-06-29 13:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3563.3469, current episode: 10
[2023-06-29 13:01:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 366500.000000 | iteration_366500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497584      | 6677.423470         | 6.677423             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3566.824292 | 8.901762   | 3579.789795 | 3552.448486 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1986.8098, current episode: 1
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2881.0752, current episode: 2
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3284.1860, current episode: 3
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3680.0522, current episode: 4
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3593.1035, current episode: 5
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3617.8369, current episode: 6
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3581.4170, current episode: 7
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3571.3201, current episode: 8
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3572.1602, current episode: 9
[2023-06-29 13:01:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3597.4553, current episode: 10
[2023-06-29 13:01:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 367000.000000 | iteration_367000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510983      | 6618.208005         | 6.618208             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3336.541626 | 503.348213 | 3680.052246 | 1986.809814 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1533.7833, current episode: 1
[2023-06-29 13:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1789.4872, current episode: 2
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1805.8964, current episode: 3
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1933.0336, current episode: 4
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1930.5775, current episode: 5
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1991.2456, current episode: 6
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2273.8323, current episode: 7
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2318.3350, current episode: 8
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2457.0581, current episode: 9
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1533.7833, current episode: 9
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1789.4872, current episode: 9
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1805.8964, current episode: 9
[2023-06-29 13:01:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3624.0613, current episode: 10
[2023-06-29 13:01:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 367500.000000 | iteration_367500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.513940      | 6605.281839         | 6.605282             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2165.731018 | 552.888885 | 3624.061279 | 1533.783325 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.4346, current episode: 1
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.0939, current episode: 2
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1004.9116, current episode: 3
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1200.6349, current episode: 4
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1828.9999, current episode: 5
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.4346, current episode: 5
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.0939, current episode: 5
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1004.9116, current episode: 5
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2378.5269, current episode: 6
[2023-06-29 13:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1200.6349, current episode: 6
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2915.2019, current episode: 7
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2938.5593, current episode: 8
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1002.4346, current episode: 8
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.0939, current episode: 8
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1004.9116, current episode: 8
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1828.9999, current episode: 8
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1200.6349, current episode: 8
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3614.8645, current episode: 9
[2023-06-29 13:02:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3634.1858, current episode: 10
[2023-06-29 13:02:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 368000.000000 | iteration_368000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516091      | 6595.908797         | 6.595909             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2151.941333 | 1027.649555 | 3634.185791 | 1001.093933 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1315.4033, current episode: 1
[2023-06-29 13:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1566.4353, current episode: 2
[2023-06-29 13:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1788.5006, current episode: 3
[2023-06-29 13:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1946.6206, current episode: 4
[2023-06-29 13:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1911.8729, current episode: 5
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2066.8064, current episode: 6
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2185.5930, current episode: 7
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2223.9133, current episode: 8
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1315.4033, current episode: 8
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1566.4353, current episode: 8
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3325.8630, current episode: 9
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1788.5006, current episode: 9
[2023-06-29 13:02:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3660.4446, current episode: 10
[2023-06-29 13:02:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 368500.000000 | iteration_368500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.521421      | 6572.801519         | 6.572802             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2199.145312 | 701.387495 | 3660.444580 | 1315.403320 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 882.4562, current episode: 1
[2023-06-29 13:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 914.6078, current episode: 2
[2023-06-29 13:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1042.1359, current episode: 3
[2023-06-29 13:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.6333, current episode: 4
[2023-06-29 13:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1160.1384, current episode: 5
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 882.4562, current episode: 5
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 914.6078, current episode: 5
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1042.1359, current episode: 5
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2309.0662, current episode: 6
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.6333, current episode: 6
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1160.1384, current episode: 6
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2712.7585, current episode: 7
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 882.4562, current episode: 7
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 914.6078, current episode: 7
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1042.1359, current episode: 7
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3315.9995, current episode: 8
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.6333, current episode: 8
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1160.1384, current episode: 8
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 882.4562, current episode: 8
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3596.8635, current episode: 9
[2023-06-29 13:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3652.7937, current episode: 10
[2023-06-29 13:02:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 369000.000000 | iteration_369000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548687      | 6457.082119         | 6.457082             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2073.845300 | 1110.502043 | 3652.793701 | 882.456177 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 13:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1264.0565, current episode: 1
[2023-06-29 13:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1344.8802, current episode: 2
[2023-06-29 13:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1430.4076, current episode: 3
[2023-06-29 13:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1706.7224, current episode: 4
[2023-06-29 13:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1810.6844, current episode: 5
[2023-06-29 13:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1264.0565, current episode: 5
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1344.8802, current episode: 5
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2752.1206, current episode: 6
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1430.4076, current episode: 6
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1706.7224, current episode: 6
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3389.7017, current episode: 7
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1810.6844, current episode: 7
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1264.0565, current episode: 7
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3597.0737, current episode: 8
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3579.7239, current episode: 9
[2023-06-29 13:02:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3792.6477, current episode: 10
[2023-06-29 13:02:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 369500.000000 | iteration_369500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514412      | 6603.222956         | 6.603223             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2466.801880 | 999.737781 | 3792.647705 | 1264.056519 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1358.6401, current episode: 1
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1423.0867, current episode: 2
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1417.6038, current episode: 3
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1694.3062, current episode: 4
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1715.3530, current episode: 5
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2048.0796, current episode: 6
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2578.8684, current episode: 7
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1358.6401, current episode: 7
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1423.0867, current episode: 7
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1417.6038, current episode: 7
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3044.5364, current episode: 8
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1694.3062, current episode: 8
[2023-06-29 13:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1715.3530, current episode: 8
[2023-06-29 13:03:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3657.6038, current episode: 9
[2023-06-29 13:03:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3697.2849, current episode: 10
[2023-06-29 13:03:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 370000.000000 | iteration_370000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495200      | 6688.067066         | 6.688067             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2263.536279 | 872.937489 | 3697.284912 | 1358.640137 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1116.5388, current episode: 1
[2023-06-29 13:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1266.9203, current episode: 2
[2023-06-29 13:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1314.6534, current episode: 3
[2023-06-29 13:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1354.8511, current episode: 4
[2023-06-29 13:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1397.0299, current episode: 5
[2023-06-29 13:03:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1407.8547, current episode: 6
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1836.9540, current episode: 7
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2009.6841, current episode: 8
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1116.5388, current episode: 8
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2525.4216, current episode: 9
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1266.9203, current episode: 9
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1314.6534, current episode: 9
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1354.8511, current episode: 9
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1397.0299, current episode: 9
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1407.8547, current episode: 9
[2023-06-29 13:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3075.1860, current episode: 10
[2023-06-29 13:03:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 370500.000000 | iteration_370500.pth.tar | 10.000000     | 8050.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 805.000000              | 1.367677      | 5885.891590         | 7.311667             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1730.509399 | 604.198176 | 3075.186035 | 1116.538818 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 861.1464, current episode: 1
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1020.1725, current episode: 2
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1043.4777, current episode: 3
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1042.4618, current episode: 4
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1064.1780, current episode: 5
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1104.7970, current episode: 6
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1153.2456, current episode: 7
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1318.1731, current episode: 8
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1829.7909, current episode: 9
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 861.1464, current episode: 9
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1020.1725, current episode: 9
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1043.4777, current episode: 9
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1042.4618, current episode: 9
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1064.1780, current episode: 9
[2023-06-29 13:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2269.4067, current episode: 10
[2023-06-29 13:03:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 371000.000000 | iteration_371000.pth.tar | 10.000000     | 5910.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 591.000000              | 0.909736      | 6496.389126         | 10.992198            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1270.684967 | 415.985937 | 2269.406738 | 861.146423 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1035.6877, current episode: 1
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1052.2594, current episode: 2
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1064.4393, current episode: 3
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1087.6665, current episode: 4
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1119.7380, current episode: 5
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1138.7987, current episode: 6
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1623.5746, current episode: 7
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1688.3158, current episode: 8
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1717.0348, current episode: 9
[2023-06-29 13:03:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1904.0531, current episode: 10
[2023-06-29 13:03:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 371500.000000 | iteration_371500.pth.tar | 10.000000     | 5190.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 519.000000              | 0.781409      | 6641.851912         | 12.797403            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1343.156799 | 326.489462 | 1904.053101 | 1035.687744 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1200.3195, current episode: 1
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1199.0020, current episode: 2
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1248.7471, current episode: 3
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1262.0223, current episode: 4
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1298.1631, current episode: 5
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1358.5831, current episode: 6
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1389.3671, current episode: 7
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1399.3057, current episode: 8
[2023-06-29 13:04:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1586.2209, current episode: 9
[2023-06-29 13:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2243.8391, current episode: 10
[2023-06-29 13:04:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 372000.000000 | iteration_372000.pth.tar | 10.000000     | 5990.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 599.000000              | 0.908159      | 6595.761340         | 11.011288            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1418.556982 | 296.257750 | 2243.839111 | 1199.001953 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1030.0657, current episode: 1
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1105.6958, current episode: 2
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1290.6077, current episode: 3
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1274.9154, current episode: 4
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1362.9738, current episode: 5
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1368.9465, current episode: 6
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1592.3232, current episode: 7
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1030.0657, current episode: 7
[2023-06-29 13:04:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1105.6958, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1290.6077, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1274.9154, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1362.9738, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1368.9465, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1592.3232, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1030.0657, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1105.6958, current episode: 7
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3627.3196, current episode: 8
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3665.7366, current episode: 9
[2023-06-29 13:04:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3751.8843, current episode: 10
[2023-06-29 13:04:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 372500.000000 | iteration_372500.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.535671      | 6511.161216         | 6.511812             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2007.046851 | 1105.948384 | 3751.884277 | 1030.065674 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:04:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1315.9458, current episode: 1
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2096.7925, current episode: 2
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1315.9458, current episode: 2
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3652.2488, current episode: 3
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3574.1438, current episode: 4
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3577.8496, current episode: 5
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3589.2048, current episode: 6
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3562.1404, current episode: 7
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3606.3667, current episode: 8
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3597.6333, current episode: 9
[2023-06-29 13:04:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3552.4507, current episode: 10
[2023-06-29 13:04:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 373000.000000 | iteration_373000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.462513      | 6837.546342         | 6.837546             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3212.477637 | 773.469242 | 3652.248779 | 1315.945801 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1004.8858, current episode: 1
[2023-06-29 13:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1286.4182, current episode: 2
[2023-06-29 13:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1649.4297, current episode: 3
[2023-06-29 13:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1004.8858, current episode: 3
[2023-06-29 13:04:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1286.4182, current episode: 3
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1004.8858, current episode: 3
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1649.4297, current episode: 3
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3543.5391, current episode: 4
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3611.1616, current episode: 5
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3572.0156, current episode: 6
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3535.3618, current episode: 7
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3559.5393, current episode: 8
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3600.8096, current episode: 9
[2023-06-29 13:04:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3555.9961, current episode: 10
[2023-06-29 13:04:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 373500.000000 | iteration_373500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.527295      | 6547.521805         | 6.547522             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2891.915680 | 1043.552423 | 3611.161621 | 1004.885803 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:05:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1137.6193, current episode: 1
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2155.6946, current episode: 2
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1137.6193, current episode: 2
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2719.2410, current episode: 3
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2978.4250, current episode: 4
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2942.1587, current episode: 5
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3239.9736, current episode: 6
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3259.5698, current episode: 7
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3294.4963, current episode: 8
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1137.6193, current episode: 8
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3536.2495, current episode: 9
[2023-06-29 13:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3593.7649, current episode: 10
[2023-06-29 13:05:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 374000.000000 | iteration_374000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.499264      | 6669.272220         | 6.669939             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2885.719275 | 706.056780 | 3593.764893 | 1137.619263 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1446.7435, current episode: 1
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1515.6320, current episode: 2
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2049.7520, current episode: 3
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2062.6599, current episode: 4
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2580.3511, current episode: 5
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2709.1748, current episode: 6
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1446.7435, current episode: 6
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2965.5105, current episode: 7
[2023-06-29 13:05:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1515.6320, current episode: 7
[2023-06-29 13:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3517.4360, current episode: 8
[2023-06-29 13:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3630.8779, current episode: 9
[2023-06-29 13:05:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3647.8091, current episode: 10
[2023-06-29 13:05:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 374500.000000 | iteration_374500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523746      | 6562.772656         | 6.562773             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2612.594678 | 790.188633 | 3647.809082 | 1446.743530 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 807.3626, current episode: 1
[2023-06-29 13:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 856.3863, current episode: 2
[2023-06-29 13:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 807.3626, current episode: 2
[2023-06-29 13:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1776.4518, current episode: 3
[2023-06-29 13:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 856.3863, current episode: 3
[2023-06-29 13:05:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1925.5651, current episode: 4
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2333.4880, current episode: 5
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2314.6257, current episode: 6
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 807.3626, current episode: 6
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2650.0906, current episode: 7
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 856.3863, current episode: 7
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2873.2302, current episode: 8
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3259.3560, current episode: 9
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 807.3626, current episode: 9
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1776.4518, current episode: 9
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 856.3863, current episode: 9
[2023-06-29 13:05:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3573.7102, current episode: 10
[2023-06-29 13:05:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 375000.000000 | iteration_375000.pth.tar | 10.000000     | 9480.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 948.000000              | 1.484894      | 6384.295488         | 6.734489             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2237.026648 | 876.460378 | 3573.710205 | 807.362610 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:05:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 833.7452, current episode: 1
[2023-06-29 13:05:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1077.8212, current episode: 2
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1604.2930, current episode: 3
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1591.0009, current episode: 4
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 833.7452, current episode: 4
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1995.8102, current episode: 5
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2042.3900, current episode: 6
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2080.3711, current episode: 7
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2109.1907, current episode: 8
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1077.8212, current episode: 8
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 833.7452, current episode: 8
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3092.7288, current episode: 9
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1604.2930, current episode: 9
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1591.0009, current episode: 9
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1077.8212, current episode: 9
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 833.7452, current episode: 9
[2023-06-29 13:05:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3779.8638, current episode: 10
[2023-06-29 13:05:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 375500.000000 | iteration_375500.pth.tar | 10.000000     | 9780.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 978.000000              | 1.497897      | 6529.155057         | 6.676028             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2020.721466 | 831.402576 | 3779.863770 | 833.745178 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1025.1864, current episode: 1
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1057.7155, current episode: 2
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1116.0875, current episode: 3
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1190.7312, current episode: 4
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1199.0371, current episode: 5
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1243.0823, current episode: 6
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1241.8424, current episode: 7
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1265.8862, current episode: 8
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1366.8312, current episode: 9
[2023-06-29 13:06:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1720.0057, current episode: 10
[2023-06-29 13:06:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 376000.000000 | iteration_376000.pth.tar | 10.000000     | 4570.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 457.000000              | 0.705964      | 6473.418566         | 14.165030            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1242.640552 | 185.993853 | 1720.005737 | 1025.186401 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3557.7048, current episode: 1
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3554.8220, current episode: 2
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3542.1658, current episode: 3
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3534.8689, current episode: 4
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3549.3850, current episode: 5
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3561.2605, current episode: 6
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3554.1394, current episode: 7
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3564.8687, current episode: 8
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3567.8245, current episode: 9
[2023-06-29 13:06:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3544.5354, current episode: 10
[2023-06-29 13:06:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 376500.000000 | iteration_376500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.474182      | 6783.424034         | 6.783424             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3553.157495 | 9.930790   | 3567.824463 | 3534.868896 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1065.7258, current episode: 1
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1107.5839, current episode: 2
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1114.7120, current episode: 3
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1135.9568, current episode: 4
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1138.9668, current episode: 5
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1151.0168, current episode: 6
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1270.3423, current episode: 7
[2023-06-29 13:06:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1503.0376, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1065.7258, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1107.5839, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1114.7120, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1135.9568, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1138.9668, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1151.0168, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1270.3423, current episode: 8
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2799.0676, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1503.0376, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1065.7258, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1107.5839, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1114.7120, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1135.9568, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1138.9668, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1151.0168, current episode: 9
[2023-06-29 13:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3514.0100, current episode: 10
[2023-06-29 13:06:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 377000.000000 | iteration_377000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536447      | 6508.520943         | 6.508521             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1580.041968 | 812.907788 | 3514.010010 | 1065.725830 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1269.5055, current episode: 1
[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1281.1279, current episode: 2
[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1359.5583, current episode: 3
[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1461.3796, current episode: 4
[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1559.2784, current episode: 5
[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1600.2585, current episode: 6
[2023-06-29 13:06:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1658.9291, current episode: 7
[2023-06-29 13:06:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1740.8850, current episode: 8
[2023-06-29 13:06:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1992.3485, current episode: 9
[2023-06-29 13:06:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1269.5055, current episode: 9
[2023-06-29 13:06:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1281.1279, current episode: 9
[2023-06-29 13:06:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1359.5583, current episode: 9
[2023-06-29 13:06:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2731.3879, current episode: 10
[2023-06-29 13:06:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 377500.000000 | iteration_377500.pth.tar | 10.000000     | 7350.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 735.000000              | 1.106093      | 6645.013690         | 9.040835             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1665.465894 | 412.799168 | 2731.387939 | 1269.505493 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3557.3108, current episode: 1
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3539.4075, current episode: 2
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3521.4922, current episode: 3
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3520.2454, current episode: 4
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3533.1917, current episode: 5
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3529.7114, current episode: 6
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3532.5303, current episode: 7
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3553.3997, current episode: 8
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3526.8062, current episode: 9
[2023-06-29 13:07:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3541.9995, current episode: 10
[2023-06-29 13:07:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 378000.000000 | iteration_378000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.480474      | 6754.592909         | 6.754593             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3535.609448 | 11.856060  | 3557.310791 | 3520.245361 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:07:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1403.1857, current episode: 1
[2023-06-29 13:07:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1413.3187, current episode: 2
[2023-06-29 13:07:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1451.9248, current episode: 3
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1814.7162, current episode: 4
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1849.4923, current episode: 5
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1882.4762, current episode: 6
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1948.6694, current episode: 7
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2026.8303, current episode: 8
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2440.1599, current episode: 9
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1403.1857, current episode: 9
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1413.3187, current episode: 9
[2023-06-29 13:07:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2862.1963, current episode: 10
[2023-06-29 13:07:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 378500.000000 | iteration_378500.pth.tar | 10.000000     | 7690.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 769.000000              | 1.140745      | 6741.211510         | 8.766205             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1909.296985 | 439.291554 | 2862.196289 | 1403.185669 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:07:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1270.5480, current episode: 1
[2023-06-29 13:07:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1287.7422, current episode: 2
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1446.9203, current episode: 3
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1435.7806, current episode: 4
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1521.2444, current episode: 5
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1564.0797, current episode: 6
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1591.3816, current episode: 7
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1688.5500, current episode: 8
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1698.0398, current episode: 9
[2023-06-29 13:07:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1773.4760, current episode: 10
[2023-06-29 13:07:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 379000.000000 | iteration_379000.pth.tar | 10.000000     | 4740.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 474.000000              | 0.729697      | 6495.843998         | 13.704312            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1527.776257 | 161.057783 | 1773.475952 | 1270.547974 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:07:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1941.5012, current episode: 1
[2023-06-29 13:07:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1978.1138, current episode: 2
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2340.2659, current episode: 3
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2562.0300, current episode: 4
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3097.7346, current episode: 5
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3118.8699, current episode: 6
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3150.9307, current episode: 7
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3629.8230, current episode: 8
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3562.2695, current episode: 9
[2023-06-29 13:07:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3574.1240, current episode: 10
[2023-06-29 13:07:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 379500.000000 | iteration_379500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497015      | 6679.960811         | 6.679961             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2895.566260 | 614.131785 | 3629.822998 | 1941.501221 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1798.3534, current episode: 1
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1837.0168, current episode: 2
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1926.2489, current episode: 3
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1967.1625, current episode: 4
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2314.2656, current episode: 5
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2338.2715, current episode: 6
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2355.3601, current episode: 7
[2023-06-29 13:08:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2354.7256, current episode: 8
[2023-06-29 13:08:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3521.6614, current episode: 9
[2023-06-29 13:08:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1798.3534, current episode: 9
[2023-06-29 13:08:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1837.0168, current episode: 9
[2023-06-29 13:08:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3573.1694, current episode: 10
[2023-06-29 13:08:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 380000.000000 | iteration_380000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497278      | 6678.784464         | 6.678784             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2398.623523 | 611.584189 | 3573.169434 | 1798.353394 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:08:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1462.0676, current episode: 1
[2023-06-29 13:08:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1684.6616, current episode: 2
[2023-06-29 13:08:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1798.4882, current episode: 3
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2300.8972, current episode: 4
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2552.3303, current episode: 5
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1462.0676, current episode: 5
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3295.8896, current episode: 6
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1684.6616, current episode: 6
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.1638, current episode: 7
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1798.4882, current episode: 7
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3766.0417, current episode: 8
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3680.3289, current episode: 9
[2023-06-29 13:08:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3571.0745, current episode: 10
[2023-06-29 13:08:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 380500.000000 | iteration_380500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.532788      | 6524.058021         | 6.524058             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2767.094348 | 863.810880 | 3766.041748 | 1462.067627 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:08:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2416.0881, current episode: 1
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3614.7395, current episode: 2
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3572.9502, current episode: 3
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3561.6565, current episode: 4
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3571.7898, current episode: 5
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3586.0222, current episode: 6
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3578.0522, current episode: 7
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3576.0754, current episode: 8
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3582.9705, current episode: 9
[2023-06-29 13:08:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3592.5435, current episode: 10
[2023-06-29 13:08:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 381000.000000 | iteration_381000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478319      | 6764.440019         | 6.764440             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3465.288794 | 349.998039 | 3614.739502 | 2416.088135 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:08:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2317.3101, current episode: 1
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3778.7402, current episode: 2
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3610.7273, current episode: 3
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.1963, current episode: 4
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3599.7434, current episode: 5
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3581.2693, current episode: 6
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3604.8621, current episode: 7
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3557.8650, current episode: 8
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3643.3035, current episode: 9
[2023-06-29 13:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3629.1497, current episode: 10
[2023-06-29 13:09:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 381500.000000 | iteration_381500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488818      | 6716.736637         | 6.716737             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3489.116675 | 395.005289 | 3778.740234 | 2317.310059 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2328.0149, current episode: 1
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2455.0300, current episode: 2
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2722.0251, current episode: 3
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3582.0771, current episode: 4
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3582.1538, current episode: 5
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.6106, current episode: 6
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3610.1072, current episode: 7
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3600.7693, current episode: 8
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3623.5950, current episode: 9
[2023-06-29 13:09:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3596.9324, current episode: 10
[2023-06-29 13:09:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 382000.000000 | iteration_382000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496932      | 6680.327959         | 6.680328             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3267.931543 | 509.785611 | 3623.594971 | 2328.014893 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 1
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 63.7778, current episode: 2
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 63.4325, current episode: 2
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3587.9561, current episode: 3
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3574.3220, current episode: 4
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3569.9995, current episode: 5
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3583.9895, current episode: 6
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3583.9451, current episode: 7
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.7820, current episode: 8
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3596.3513, current episode: 9
[2023-06-29 13:09:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3575.5115, current episode: 10
[2023-06-29 13:09:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 382500.000000 | iteration_382500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.624959      | 6154.001946         | 6.154002             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2876.906733 | 1406.672756 | 3596.351318 | 63.432545  |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3576.5718, current episode: 1
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3617.5696, current episode: 2
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3571.0469, current episode: 3
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3587.5286, current episode: 4
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3562.9443, current episode: 5
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3596.7905, current episode: 6
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3578.3833, current episode: 7
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3590.5854, current episode: 8
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3588.2617, current episode: 9
[2023-06-29 13:09:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3568.8398, current episode: 10
[2023-06-29 13:09:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 383000.000000 | iteration_383000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496674      | 6681.481416         | 6.681481             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3583.852197 | 15.139213  | 3617.569580 | 3562.944336 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3563.3884, current episode: 1
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3553.7837, current episode: 2
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3579.9353, current episode: 3
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3567.1619, current episode: 4
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3553.1514, current episode: 5
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3551.0793, current episode: 6
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3558.4185, current episode: 7
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3563.5286, current episode: 8
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3578.1814, current episode: 9
[2023-06-29 13:10:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3557.8809, current episode: 10
[2023-06-29 13:10:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 383500.000000 | iteration_383500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500089      | 6666.269012         | 6.666269             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3562.650928 | 9.513392   | 3579.935303 | 3551.079346 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3502.2749, current episode: 1
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3513.7012, current episode: 2
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3507.5244, current episode: 3
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3507.0806, current episode: 4
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3506.5146, current episode: 5
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3504.2266, current episode: 6
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3497.3804, current episode: 7
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3506.3611, current episode: 8
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3512.6904, current episode: 9
[2023-06-29 13:10:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3502.5061, current episode: 10
[2023-06-29 13:10:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 384000.000000 | iteration_384000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495058      | 6688.702698         | 6.688703             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3506.026025 | 4.598658   | 3513.701172 | 3497.380371 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3545.0950, current episode: 1
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3542.7888, current episode: 2
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3545.6982, current episode: 3
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.0471, current episode: 4
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.5317, current episode: 5
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3556.2495, current episode: 6
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3530.0510, current episode: 7
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3575.2581, current episode: 8
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3557.8584, current episode: 9
[2023-06-29 13:10:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3541.3354, current episode: 10
[2023-06-29 13:10:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 384500.000000 | iteration_384500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492963      | 6698.089033         | 6.698089             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3546.991333 | 12.390651  | 3575.258057 | 3530.051025 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 1
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.5611, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.3087, current episode: 2
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3517.6750, current episode: 3
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3522.2944, current episode: 4
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3524.7383, current episode: 5
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3521.2090, current episode: 6
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3517.0896, current episode: 7
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3525.8638, current episode: 8
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3514.5232, current episode: 9
[2023-06-29 13:10:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3524.6863, current episode: 10
[2023-06-29 13:10:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 385000.000000 | iteration_385000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.685899      | 5931.554123         | 5.931554             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2828.494941 | 1385.034394 | 3525.863770 | 58.308731  |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3573.5569, current episode: 1
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3611.9260, current episode: 2
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3593.8513, current episode: 3
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3586.4998, current episode: 4
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3588.7305, current episode: 5
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3593.1853, current episode: 6
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3599.6077, current episode: 7
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.7607, current episode: 8
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3592.9951, current episode: 9
[2023-06-29 13:11:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3606.3740, current episode: 10
[2023-06-29 13:11:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 385500.000000 | iteration_385500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491734      | 6703.607428         | 6.703607             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3594.848730 | 10.308097  | 3611.926025 | 3573.556885 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3611.0479, current episode: 1
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3617.1355, current episode: 2
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3613.6492, current episode: 3
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3606.7007, current episode: 4
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3610.2703, current episode: 5
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3613.9189, current episode: 6
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3628.5059, current episode: 7
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3606.9341, current episode: 8
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3605.4353, current episode: 9
[2023-06-29 13:11:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3616.3198, current episode: 10
[2023-06-29 13:11:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 386000.000000 | iteration_386000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505429      | 6642.626069         | 6.642626             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3612.991748 | 6.440374   | 3628.505859 | 3605.435303 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3591.9521, current episode: 1
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3593.8740, current episode: 2
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3597.6440, current episode: 3
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3599.2754, current episode: 4
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3591.8538, current episode: 5
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3593.1643, current episode: 6
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3598.2004, current episode: 7
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3599.9512, current episode: 8
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3622.2383, current episode: 9
[2023-06-29 13:11:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3601.9119, current episode: 10
[2023-06-29 13:11:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 386500.000000 | iteration_386500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.466139      | 6820.637791         | 6.820638             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3599.006543 | 8.444091   | 3622.238281 | 3591.853760 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3623.2134, current episode: 1
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3614.5122, current episode: 2
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3647.3384, current episode: 3
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3609.9270, current episode: 4
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3616.1226, current episode: 5
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3655.8704, current episode: 6
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3623.7395, current episode: 7
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3656.4771, current episode: 8
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3598.6836, current episode: 9
[2023-06-29 13:11:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3646.5352, current episode: 10
[2023-06-29 13:11:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 387000.000000 | iteration_387000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.473825      | 6785.064608         | 6.785065             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3629.241919 | 19.595774  | 3656.477051 | 3598.683594 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3609.5142, current episode: 1
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3636.8965, current episode: 2
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3619.1294, current episode: 3
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3615.8120, current episode: 4
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3593.2581, current episode: 5
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3621.5713, current episode: 6
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3615.1401, current episode: 7
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3624.3611, current episode: 8
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3626.6428, current episode: 9
[2023-06-29 13:12:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3584.8201, current episode: 10
[2023-06-29 13:12:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 387500.000000 | iteration_387500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.465875      | 6821.864642         | 6.821865             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3614.714551 | 14.752539  | 3636.896484 | 3584.820068 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:12:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2949.7625, current episode: 1
[2023-06-29 13:12:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3371.3015, current episode: 2
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3616.9685, current episode: 3
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3667.1675, current episode: 4
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3594.1543, current episode: 5
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3583.5845, current episode: 6
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.1685, current episode: 7
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3592.8416, current episode: 8
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3600.5452, current episode: 9
[2023-06-29 13:12:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3641.2151, current episode: 10
[2023-06-29 13:12:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 388000.000000 | iteration_388000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492969      | 6698.064936         | 6.698065             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3520.270898 | 204.601518 | 3667.167480 | 2949.762451 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3600.7937, current episode: 1
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3593.7708, current episode: 2
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3591.4651, current episode: 3
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3590.6738, current episode: 4
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3590.4856, current episode: 5
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3601.2007, current episode: 6
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3595.7998, current episode: 7
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3604.2190, current episode: 8
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3607.5349, current episode: 9
[2023-06-29 13:12:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3594.6877, current episode: 10
[2023-06-29 13:12:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 388500.000000 | iteration_388500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494845      | 6689.657465         | 6.689657             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3597.063110 | 5.704424   | 3607.534912 | 3590.485596 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3590.6235, current episode: 1
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3639.6448, current episode: 2
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3622.6519, current episode: 3
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3589.1257, current episode: 4
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3611.1055, current episode: 5
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3601.3752, current episode: 6
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3593.1389, current episode: 7
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.3809, current episode: 8
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3739.2019, current episode: 9
[2023-06-29 13:12:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3589.0867, current episode: 10
[2023-06-29 13:12:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 389000.000000 | iteration_389000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.462764      | 6836.370895         | 6.836371             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3617.733496 | 43.378207  | 3739.201904 | 3589.086670 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:13:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1615.8123, current episode: 1
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1615.8123, current episode: 1
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3607.6599, current episode: 2
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3660.8486, current episode: 3
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3631.6804, current episode: 4
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3595.3335, current episode: 5
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3639.8845, current episode: 6
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3626.5398, current episode: 7
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3627.3774, current episode: 8
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3621.2546, current episode: 9
[2023-06-29 13:13:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3626.2925, current episode: 10
[2023-06-29 13:13:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 389500.000000 | iteration_389500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496374      | 6682.820078         | 6.682820             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3425.268359 | 603.379144 | 3660.848633 | 1615.812256 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:13:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2015.9797, current episode: 1
[2023-06-29 13:13:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2217.9766, current episode: 2
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2784.3574, current episode: 3
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2940.2593, current episode: 4
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3162.1208, current episode: 5
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3627.4412, current episode: 6
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3638.2339, current episode: 7
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3660.6658, current episode: 8
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3651.7554, current episode: 9
[2023-06-29 13:13:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3600.8806, current episode: 10
[2023-06-29 13:13:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 390000.000000 | iteration_390000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506385      | 6638.411280         | 6.638411             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3129.967065 | 592.506772 | 3660.665771 | 2015.979736 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1024.5170, current episode: 1
[2023-06-29 13:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1903.5444, current episode: 2
[2023-06-29 13:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1931.5594, current episode: 3
[2023-06-29 13:13:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2018.0615, current episode: 4
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2226.2576, current episode: 5
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2292.9290, current episode: 6
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1024.5170, current episode: 6
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2606.5039, current episode: 7
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3165.3027, current episode: 8
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3217.7715, current episode: 9
[2023-06-29 13:13:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3452.3708, current episode: 10
[2023-06-29 13:13:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 390500.000000 | iteration_390500.pth.tar | 10.000000     | 9160.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 916.000000              | 1.370210      | 6685.106853         | 7.298152             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2383.881787 | 703.374343 | 3452.370850 | 1024.516968 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2966.6350, current episode: 1
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3586.3674, current episode: 2
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3685.5540, current episode: 3
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3717.4739, current episode: 4
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3644.2595, current episode: 5
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3669.6384, current episode: 6
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3660.5864, current episode: 7
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3690.0684, current episode: 8
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3605.9512, current episode: 9
[2023-06-29 13:13:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3639.2122, current episode: 10
[2023-06-29 13:13:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 391000.000000 | iteration_391000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.466037      | 6821.110304         | 6.821110             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3586.574634 | 209.956828 | 3717.473877 | 2966.635010 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 938.0095, current episode: 1
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1160.8104, current episode: 2
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1333.3727, current episode: 3
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1347.5697, current episode: 4
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1354.8447, current episode: 5
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1372.5039, current episode: 6
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1379.0609, current episode: 7
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1379.1545, current episode: 8
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1422.2815, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 938.0095, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1160.8104, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1333.3727, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1347.5697, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1354.8447, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1372.5039, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1379.0609, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1379.1545, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1422.2815, current episode: 9
[2023-06-29 13:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 938.0095, current episode: 9
[2023-06-29 13:14:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1160.8104, current episode: 9
[2023-06-29 13:14:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3619.0586, current episode: 10
[2023-06-29 13:14:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 391500.000000 | iteration_391500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.531731      | 6528.562701         | 6.528563             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1530.666644 | 709.611362 | 3619.058594 | 938.009460 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3588.3806, current episode: 1
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3578.4177, current episode: 2
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3581.8394, current episode: 3
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3603.8672, current episode: 4
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3561.8340, current episode: 5
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3587.7249, current episode: 6
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3570.0947, current episode: 7
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3587.1616, current episode: 8
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3587.1763, current episode: 9
[2023-06-29 13:14:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3582.1626, current episode: 10
[2023-06-29 13:14:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 392000.000000 | iteration_392000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541113      | 6488.818234         | 6.488818             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3582.865894 | 10.765162  | 3603.867188 | 3561.833984 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1360.4104, current episode: 1
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1369.5852, current episode: 2
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1394.9656, current episode: 3
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1558.9702, current episode: 4
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2213.8806, current episode: 5
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2593.2695, current episode: 6
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1360.4104, current episode: 6
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1369.5852, current episode: 6
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1394.9656, current episode: 6
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1558.9702, current episode: 6
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3444.0303, current episode: 7
[2023-06-29 13:14:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3478.5378, current episode: 8
[2023-06-29 13:14:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3608.4563, current episode: 9
[2023-06-29 13:14:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3622.4211, current episode: 10
[2023-06-29 13:14:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 392500.000000 | iteration_392500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497959      | 6675.749663         | 6.675750             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2464.452710 | 953.850180 | 3622.421143 | 1360.410400 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1532.6699, current episode: 1
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1618.0809, current episode: 2
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1891.6490, current episode: 3
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1983.2162, current episode: 4
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2001.6426, current episode: 5
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2773.6453, current episode: 6
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2853.9851, current episode: 7
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1532.6699, current episode: 7
[2023-06-29 13:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3181.6848, current episode: 8
[2023-06-29 13:14:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3167.2585, current episode: 9
[2023-06-29 13:14:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1618.0809, current episode: 9
[2023-06-29 13:14:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1891.6490, current episode: 9
[2023-06-29 13:14:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3661.0107, current episode: 10
[2023-06-29 13:14:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 393000.000000 | iteration_393000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497315      | 6678.623294         | 6.678623             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2466.484314 | 710.341714 | 3661.010742 | 1532.669922 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2009.1454, current episode: 1
[2023-06-29 13:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2211.4443, current episode: 2
[2023-06-29 13:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2234.7217, current episode: 3
[2023-06-29 13:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2337.5244, current episode: 4
[2023-06-29 13:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2402.9150, current episode: 5
[2023-06-29 13:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3202.3440, current episode: 6
[2023-06-29 13:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3421.0334, current episode: 7
[2023-06-29 13:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3623.4683, current episode: 8
[2023-06-29 13:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3622.0933, current episode: 9
[2023-06-29 13:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3598.9343, current episode: 10
[2023-06-29 13:15:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 393500.000000 | iteration_393500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523095      | 6565.577189         | 6.565577             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2866.362415 | 644.880253 | 3623.468262 | 2009.145386 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:15:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2258.9480, current episode: 1
[2023-06-29 13:15:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2855.4944, current episode: 2
[2023-06-29 13:15:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2968.8647, current episode: 3
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3431.9841, current episode: 4
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3565.6172, current episode: 5
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3670.3506, current episode: 6
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3656.1511, current episode: 7
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3595.6655, current episode: 8
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3714.1570, current episode: 9
[2023-06-29 13:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3610.6279, current episode: 10
[2023-06-29 13:15:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 394000.000000 | iteration_394000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483532      | 6740.670873         | 6.740671             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3332.786060 | 456.911929 | 3714.156982 | 2258.947998 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1729.1000, current episode: 1
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1877.0509, current episode: 2
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1934.8781, current episode: 3
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1935.5289, current episode: 4
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2382.0933, current episode: 5
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2667.2368, current episode: 6
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3330.5461, current episode: 7
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1729.1000, current episode: 7
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3583.7981, current episode: 8
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3654.3552, current episode: 9
[2023-06-29 13:15:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3633.9370, current episode: 10
[2023-06-29 13:15:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 394500.000000 | iteration_394500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500142      | 6666.035216         | 6.666035             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2672.852441 | 764.604973 | 3654.355225 | 1729.099976 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1974.3126, current episode: 1
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3449.9653, current episode: 2
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3593.3218, current episode: 3
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3608.3875, current episode: 4
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3597.0811, current episode: 5
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3592.0669, current episode: 6
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3602.3088, current episode: 7
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3636.3762, current episode: 8
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3604.7861, current episode: 9
[2023-06-29 13:15:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3617.9009, current episode: 10
[2023-06-29 13:15:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 395000.000000 | iteration_395000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.469878      | 6803.286605         | 6.803287             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3427.650720 | 486.845501 | 3636.376221 | 1974.312622 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3587.6067, current episode: 1
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3568.2268, current episode: 2
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3580.1565, current episode: 3
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3581.1907, current episode: 4
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3568.3613, current episode: 5
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3577.9695, current episode: 6
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3567.4336, current episode: 7
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3585.1177, current episode: 8
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3588.7510, current episode: 9
[2023-06-29 13:16:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3582.2866, current episode: 10
[2023-06-29 13:16:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 395500.000000 | iteration_395500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494603      | 6690.739827         | 6.690740             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3578.710034 | 7.660072   | 3588.750977 | 3567.433594 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3576.9790, current episode: 1
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3595.7920, current episode: 2
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.2971, current episode: 3
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3558.2458, current episode: 4
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3569.5762, current episode: 5
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3601.0046, current episode: 6
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3589.2874, current episode: 7
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3579.1575, current episode: 8
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3584.8271, current episode: 9
[2023-06-29 13:16:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3576.1467, current episode: 10
[2023-06-29 13:16:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 396000.000000 | iteration_396000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476142      | 6774.417840         | 6.774418             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3579.931348 | 12.424297  | 3601.004639 | 3558.245850 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3607.0583, current episode: 1
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3601.5554, current episode: 2
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3576.3921, current episode: 3
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3590.0430, current episode: 4
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3558.9941, current episode: 5
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3582.0793, current episode: 6
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3583.2627, current episode: 7
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3598.6768, current episode: 8
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3577.2869, current episode: 9
[2023-06-29 13:16:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3566.4675, current episode: 10
[2023-06-29 13:16:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 396500.000000 | iteration_396500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553408      | 6437.457453         | 6.437457             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3584.181616 | 14.599091  | 3607.058350 | 3558.994141 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3589.4150, current episode: 1
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3579.2937, current episode: 2
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3588.7048, current episode: 3
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3598.2573, current episode: 4
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3622.6272, current episode: 5
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3597.5693, current episode: 6
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3600.2053, current episode: 7
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3585.6301, current episode: 8
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3572.7712, current episode: 9
[2023-06-29 13:16:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3601.8982, current episode: 10
[2023-06-29 13:16:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 397000.000000 | iteration_397000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488193      | 6719.560787         | 6.719561             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3593.637231 | 13.175750  | 3622.627197 | 3572.771240 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3608.9519, current episode: 1
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3581.1814, current episode: 2
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3598.9900, current episode: 3
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3577.2595, current episode: 4
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3591.2642, current episode: 5
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3567.7222, current episode: 6
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3557.4023, current episode: 7
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3588.1360, current episode: 8
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3772.1890, current episode: 9
[2023-06-29 13:17:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3577.0813, current episode: 10
[2023-06-29 13:17:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 397500.000000 | iteration_397500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499628      | 6668.319094         | 6.668319             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3602.017773 | 58.446135  | 3772.188965 | 3557.402344 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3493.9775, current episode: 1
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3595.8816, current episode: 2
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3626.5356, current episode: 3
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3588.9272, current episode: 4
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3602.4819, current episode: 5
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3584.8140, current episode: 6
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3621.5359, current episode: 7
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3615.4604, current episode: 8
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3591.6982, current episode: 9
[2023-06-29 13:17:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3602.5042, current episode: 10
[2023-06-29 13:17:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 398000.000000 | iteration_398000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524393      | 6559.989430         | 6.559989             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3592.381665 | 35.382008  | 3626.535645 | 3493.977539 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3575.7078, current episode: 1
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3587.6306, current episode: 2
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3573.9768, current episode: 3
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3585.3848, current episode: 4
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3569.6694, current episode: 5
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3601.2178, current episode: 6
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.7463, current episode: 7
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3587.1841, current episode: 8
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3577.4165, current episode: 9
[2023-06-29 13:17:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3581.9976, current episode: 10
[2023-06-29 13:17:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 398500.000000 | iteration_398500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492419      | 6700.533041         | 6.700533             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3580.993164 | 9.254125   | 3601.217773 | 3569.669434 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3568.9329, current episode: 1
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3520.7688, current episode: 2
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3557.9138, current episode: 3
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3574.7114, current episode: 4
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3558.6819, current episode: 5
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3549.1055, current episode: 6
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3528.0381, current episode: 7
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3566.7019, current episode: 8
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.9897, current episode: 9
[2023-06-29 13:17:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3547.9290, current episode: 10
[2023-06-29 13:17:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 399000.000000 | iteration_399000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494036      | 6693.279643         | 6.693280             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3550.877295 | 17.077863  | 3574.711426 | 3520.768799 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.0334, current episode: 1
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3544.5840, current episode: 2
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3546.0730, current episode: 3
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3518.2432, current episode: 4
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3545.4822, current episode: 5
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3534.4790, current episode: 6
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3540.7576, current episode: 7
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3552.6206, current episode: 8
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3543.3049, current episode: 9
[2023-06-29 13:18:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3560.4563, current episode: 10
[2023-06-29 13:18:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 399500.000000 | iteration_399500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.480191      | 6755.883585         | 6.755884             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3543.903418 | 10.947740  | 3560.456299 | 3518.243164 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3580.1697, current episode: 1
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3581.7207, current episode: 2
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3587.0830, current episode: 3
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3578.3267, current episode: 4
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.1462, current episode: 5
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3581.2949, current episode: 6
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3586.3562, current episode: 7
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3585.5388, current episode: 8
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3590.5005, current episode: 9
[2023-06-29 13:18:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3591.1948, current episode: 10
[2023-06-29 13:18:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 400000.000000 | iteration_400000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.471438      | 6796.074703         | 6.796075             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3584.033154 | 4.528496   | 3591.194824 | 3578.146240 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3586.8162, current episode: 1
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3587.4670, current episode: 2
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3595.7937, current episode: 3
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3588.2837, current episode: 4
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3593.6033, current episode: 5
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3596.0337, current episode: 6
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3590.7207, current episode: 7
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3588.2766, current episode: 8
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3584.6953, current episode: 9
[2023-06-29 13:18:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3597.6211, current episode: 10
[2023-06-29 13:18:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 400500.000000 | iteration_400500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.513032      | 6609.245618         | 6.609246             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3590.931128 | 4.283628   | 3597.621094 | 3584.695312 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3580.7502, current episode: 1
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3574.4592, current episode: 2
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3587.6809, current episode: 3
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3585.4609, current episode: 4
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3583.2205, current episode: 5
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3567.7600, current episode: 6
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3573.2549, current episode: 7
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3559.4934, current episode: 8
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3572.4543, current episode: 9
[2023-06-29 13:18:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3578.6887, current episode: 10
[2023-06-29 13:18:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 401000.000000 | iteration_401000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504436      | 6647.009089         | 6.647009             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3576.322314 | 8.183456   | 3587.680908 | 3559.493408 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3572.0098, current episode: 1
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3565.4719, current episode: 2
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.7974, current episode: 3
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3608.4788, current episode: 4
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3581.8481, current episode: 5
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3586.3699, current episode: 6
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3598.2966, current episode: 7
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3602.9497, current episode: 8
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3581.4526, current episode: 9
[2023-06-29 13:19:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3613.2698, current episode: 10
[2023-06-29 13:19:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 401500.000000 | iteration_401500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479377      | 6759.603514         | 6.759604             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3589.294458 | 14.981119  | 3613.269775 | 3565.471924 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3570.4658, current episode: 1
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3572.4114, current episode: 2
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3558.1924, current episode: 3
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3566.2212, current episode: 4
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3571.6389, current episode: 5
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3567.7085, current episode: 6
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3565.5972, current episode: 7
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3573.1558, current episode: 8
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3572.9768, current episode: 9
[2023-06-29 13:19:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3565.6448, current episode: 10
[2023-06-29 13:19:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 402000.000000 | iteration_402000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.497598      | 6677.358156         | 6.677358             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3568.401270 | 4.464098   | 3573.155762 | 3558.192383 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3581.6492, current episode: 1
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3577.4836, current episode: 2
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3580.7141, current episode: 3
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3580.9683, current episode: 4
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3577.0422, current episode: 5
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3597.0684, current episode: 6
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3585.8774, current episode: 7
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3585.7229, current episode: 8
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3583.3030, current episode: 9
[2023-06-29 13:19:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3572.7698, current episode: 10
[2023-06-29 13:19:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 402500.000000 | iteration_402500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496267      | 6683.297679         | 6.683298             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3582.259888 | 6.244897   | 3597.068359 | 3572.769775 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3589.5957, current episode: 1
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3594.5105, current episode: 2
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3607.5659, current episode: 3
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3603.2595, current episode: 4
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3614.8262, current episode: 5
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3583.5452, current episode: 6
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3575.0295, current episode: 7
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3593.9773, current episode: 8
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3589.3274, current episode: 9
[2023-06-29 13:19:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3614.5540, current episode: 10
[2023-06-29 13:19:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 403000.000000 | iteration_403000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496267      | 6683.298769         | 6.683299             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3596.619116 | 12.522155  | 3614.826172 | 3575.029541 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2304.9136, current episode: 1
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2653.0100, current episode: 2
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3234.4143, current episode: 3
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3379.0439, current episode: 4
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3708.6628, current episode: 5
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3622.9553, current episode: 6
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3594.4775, current episode: 7
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3584.3098, current episode: 8
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3623.7834, current episode: 9
[2023-06-29 13:20:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3589.4998, current episode: 10
[2023-06-29 13:20:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 403500.000000 | iteration_403500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476161      | 6774.327647         | 6.774328             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3329.507056 | 451.457217 | 3708.662842 | 2304.913574 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.1426, current episode: 1
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3582.7932, current episode: 2
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3567.2151, current episode: 3
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3601.2827, current episode: 4
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3590.4302, current episode: 5
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3592.9236, current episode: 6
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3579.3987, current episode: 7
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.0361, current episode: 8
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3565.1121, current episode: 9
[2023-06-29 13:20:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3588.4453, current episode: 10
[2023-06-29 13:20:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 404000.000000 | iteration_404000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487372      | 6723.265642         | 6.723266             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3582.177954 | 11.106711  | 3601.282715 | 3565.112061 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:20:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2920.7415, current episode: 1
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3579.0034, current episode: 2
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3586.0195, current episode: 3
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3585.0413, current episode: 4
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3584.3464, current episode: 5
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3579.2920, current episode: 6
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3586.4536, current episode: 7
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3581.3643, current episode: 8
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3583.3728, current episode: 9
[2023-06-29 13:20:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3587.1589, current episode: 10
[2023-06-29 13:20:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 404500.000000 | iteration_404500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498074      | 6675.238329         | 6.675238             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3517.279370 | 198.864584 | 3587.158936 | 2920.741455 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:20:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1829.4489, current episode: 1
[2023-06-29 13:20:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1927.3434, current episode: 2
[2023-06-29 13:20:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1943.4557, current episode: 3
[2023-06-29 13:20:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1967.9324, current episode: 4
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2107.7771, current episode: 5
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2618.7883, current episode: 6
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1829.4489, current episode: 6
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3589.5725, current episode: 7
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3634.3647, current episode: 8
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3602.2607, current episode: 9
[2023-06-29 13:21:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3598.0381, current episode: 10
[2023-06-29 13:21:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 405000.000000 | iteration_405000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.470974      | 6798.217260         | 6.798217             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2681.898181 | 781.160033 | 3634.364746 | 1829.448853 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1720.2461, current episode: 1
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1758.5458, current episode: 2
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1772.2335, current episode: 3
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1815.2994, current episode: 4
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1862.9387, current episode: 5
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1918.5394, current episode: 6
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2109.5598, current episode: 7
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2316.3306, current episode: 8
[2023-06-29 13:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2392.6821, current episode: 9
[2023-06-29 13:21:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1720.2461, current episode: 9
[2023-06-29 13:21:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1758.5458, current episode: 9
[2023-06-29 13:21:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1772.2335, current episode: 9
[2023-06-29 13:21:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1815.2994, current episode: 9
[2023-06-29 13:21:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1862.9387, current episode: 9
[2023-06-29 13:21:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3638.8059, current episode: 10
[2023-06-29 13:21:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 405500.000000 | iteration_405500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520355      | 6577.410225         | 6.577410             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2130.518140 | 550.416067 | 3638.805908 | 1720.246094 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3581.7449, current episode: 1
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3586.8513, current episode: 2
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3569.6226, current episode: 3
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3567.8215, current episode: 4
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3581.7349, current episode: 5
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.1243, current episode: 6
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3574.5068, current episode: 7
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3561.7690, current episode: 8
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3572.3484, current episode: 9
[2023-06-29 13:21:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3586.7888, current episode: 10
[2023-06-29 13:21:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 406000.000000 | iteration_406000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503533      | 6650.999363         | 6.650999             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3576.831250 | 8.378708   | 3586.851318 | 3561.769043 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3239.6575, current episode: 1
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3597.8606, current episode: 2
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3587.1318, current episode: 3
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3598.8511, current episode: 4
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3587.8254, current episode: 5
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3616.2146, current episode: 6
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3595.9170, current episode: 7
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3617.4668, current episode: 8
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3598.2378, current episode: 9
[2023-06-29 13:21:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3583.8091, current episode: 10
[2023-06-29 13:21:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 406500.000000 | iteration_406500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501035      | 6662.071312         | 6.662071             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3562.297168 | 108.074666 | 3617.466797 | 3239.657471 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.5356, current episode: 1
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3579.8550, current episode: 2
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3589.7554, current episode: 3
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3589.6626, current episode: 4
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.0725, current episode: 5
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3571.3840, current episode: 6
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3591.4045, current episode: 7
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3587.5344, current episode: 8
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3586.7534, current episode: 9
[2023-06-29 13:22:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3599.4443, current episode: 10
[2023-06-29 13:22:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 407000.000000 | iteration_407000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485218      | 6733.016578         | 6.733017             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3584.540186 | 8.617068   | 3599.444336 | 3571.384033 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3585.3726, current episode: 1
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3592.4231, current episode: 2
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3600.3206, current episode: 3
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3596.8096, current episode: 4
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3588.7473, current episode: 5
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3595.4734, current episode: 6
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3596.6147, current episode: 7
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3586.0542, current episode: 8
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3584.2751, current episode: 9
[2023-06-29 13:22:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3594.1782, current episode: 10
[2023-06-29 13:22:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 407500.000000 | iteration_407500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.464208      | 6829.629588         | 6.829630             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3592.026880 | 5.293101   | 3600.320557 | 3584.275146 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2057.4873, current episode: 1
[2023-06-29 13:22:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2045.2518, current episode: 2
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2616.3840, current episode: 3
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2637.0000, current episode: 4
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3236.1926, current episode: 5
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3279.4595, current episode: 6
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3614.1707, current episode: 7
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3630.0425, current episode: 8
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3642.5693, current episode: 9
[2023-06-29 13:22:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3639.8564, current episode: 10
[2023-06-29 13:22:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 408000.000000 | iteration_408000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476850      | 6771.166238         | 6.771166             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3039.841418 | 615.896612 | 3642.569336 | 2045.251831 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3059.6125, current episode: 1
[2023-06-29 13:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3114.3569, current episode: 2
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3674.7583, current episode: 3
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3654.7988, current episode: 4
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3612.4941, current episode: 5
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3625.8218, current episode: 6
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3615.1555, current episode: 7
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3591.8872, current episode: 8
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3608.1018, current episode: 9
[2023-06-29 13:22:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3720.3970, current episode: 10
[2023-06-29 13:22:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 408500.000000 | iteration_408500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479473      | 6759.161791         | 6.759162             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3527.738403 | 223.589258 | 3720.396973 | 3059.612549 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2008.7493, current episode: 1
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3156.5127, current episode: 2
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3596.6091, current episode: 3
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3663.7603, current episode: 4
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3597.7722, current episode: 5
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3644.0083, current episode: 6
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3658.1865, current episode: 7
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3603.2913, current episode: 8
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3741.1240, current episode: 9
[2023-06-29 13:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3620.2795, current episode: 10
[2023-06-29 13:23:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 409000.000000 | iteration_409000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491657      | 6703.955784         | 6.703956             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3429.029321 | 496.607739 | 3741.124023 | 2008.749268 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1315.4724, current episode: 1
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1315.3330, current episode: 2
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1374.5067, current episode: 3
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1389.3372, current episode: 4
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1432.3160, current episode: 5
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1433.5702, current episode: 6
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1444.4408, current episode: 7
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1459.9050, current episode: 8
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1468.9570, current episode: 9
[2023-06-29 13:23:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1611.7812, current episode: 10
[2023-06-29 13:23:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 409500.000000 | iteration_409500.pth.tar | 10.000000     | 4150.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 415.000000              | 0.642077      | 6463.394683         | 15.574445            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1424.561963 | 81.477216  | 1611.781250 | 1315.333008 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2487.9648, current episode: 1
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3610.4578, current episode: 2
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3592.2227, current episode: 3
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3633.8376, current episode: 4
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3715.9148, current episode: 5
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3634.5090, current episode: 6
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3588.3979, current episode: 7
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3584.6467, current episode: 8
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3661.2820, current episode: 9
[2023-06-29 13:23:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3591.7791, current episode: 10
[2023-06-29 13:23:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 410000.000000 | iteration_410000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504444      | 6646.972954         | 6.646973             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3510.101245 | 342.919768 | 3715.914795 | 2487.964844 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3570.2349, current episode: 1
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3573.4448, current episode: 2
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3573.0669, current episode: 3
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3563.4573, current episode: 4
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3575.4871, current episode: 5
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3572.3870, current episode: 6
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3577.0645, current episode: 7
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.7014, current episode: 8
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3582.8914, current episode: 9
[2023-06-29 13:23:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3558.0945, current episode: 10
[2023-06-29 13:23:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 410500.000000 | iteration_410500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491984      | 6702.486899         | 6.702487             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3572.982959 | 7.460052   | 3583.701416 | 3558.094482 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.3828, current episode: 1
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3576.7966, current episode: 2
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.8999, current episode: 3
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3634.7224, current episode: 4
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3582.9504, current episode: 5
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3593.0020, current episode: 6
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3594.9578, current episode: 7
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3574.0940, current episode: 8
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3558.4170, current episode: 9
[2023-06-29 13:24:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3586.0527, current episode: 10
[2023-06-29 13:24:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 411000.000000 | iteration_411000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.476096      | 6774.627927         | 6.774628             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3585.327563 | 19.444645  | 3634.722412 | 3558.416992 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1989.7374, current episode: 1
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2162.2322, current episode: 2
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2161.5674, current episode: 3
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2240.5193, current episode: 4
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2303.6750, current episode: 5
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2369.0452, current episode: 6
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2692.5625, current episode: 7
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2972.5415, current episode: 8
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3431.2844, current episode: 9
[2023-06-29 13:24:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3577.7136, current episode: 10
[2023-06-29 13:24:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 411500.000000 | iteration_411500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.482407      | 6745.786930         | 6.745787             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2590.087854 | 531.035727 | 3577.713623 | 1989.737427 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1971.1387, current episode: 1
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1977.3711, current episode: 2
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1988.6382, current episode: 3
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1963.8513, current episode: 4
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2007.3198, current episode: 5
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2103.2954, current episode: 6
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2130.6584, current episode: 7
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2145.6860, current episode: 8
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2219.1755, current episode: 9
[2023-06-29 13:24:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2307.8330, current episode: 10
[2023-06-29 13:24:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 412000.000000 | iteration_412000.pth.tar | 10.000000     | 6040.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 604.000000              | 0.907433      | 6656.139818         | 11.020099            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2081.496753 | 113.217624 | 2307.833008 | 1963.851318 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1991.9478, current episode: 1
[2023-06-29 13:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2093.7910, current episode: 2
[2023-06-29 13:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2702.3198, current episode: 3
[2023-06-29 13:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2865.8601, current episode: 4
[2023-06-29 13:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2912.5527, current episode: 5
[2023-06-29 13:24:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3181.0491, current episode: 6
[2023-06-29 13:24:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3515.5476, current episode: 7
[2023-06-29 13:24:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3729.6799, current episode: 8
[2023-06-29 13:24:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3606.6133, current episode: 9
[2023-06-29 13:24:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3607.1780, current episode: 10
[2023-06-29 13:24:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 412500.000000 | iteration_412500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478980      | 6761.416741         | 6.761417             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3020.653931 | 592.875864 | 3729.679932 | 1991.947754 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:25:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2133.7766, current episode: 1
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3591.8301, current episode: 2
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3587.6196, current episode: 3
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3591.9473, current episode: 4
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3583.2041, current episode: 5
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3607.6284, current episode: 6
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3639.8667, current episode: 7
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3589.4858, current episode: 8
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3580.0876, current episode: 9
[2023-06-29 13:25:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3584.0068, current episode: 10
[2023-06-29 13:25:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 413000.000000 | iteration_413000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.482331      | 6746.129684         | 6.746130             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3448.945312 | 438.704136 | 3639.866699 | 2133.776611 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3580.5808, current episode: 1
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3586.7480, current episode: 2
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3588.8213, current episode: 3
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3579.8911, current episode: 4
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3587.6707, current episode: 5
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3592.5242, current episode: 6
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3588.8926, current episode: 7
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3594.8857, current episode: 8
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3569.6277, current episode: 9
[2023-06-29 13:25:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3600.5352, current episode: 10
[2023-06-29 13:25:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 413500.000000 | iteration_413500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.474206      | 6783.310572         | 6.783311             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3587.017725 | 8.227092   | 3600.535156 | 3569.627686 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3593.7957, current episode: 1
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3578.9006, current episode: 2
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3584.8062, current episode: 3
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3572.2922, current episode: 4
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3579.0679, current episode: 5
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3578.0928, current episode: 6
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3578.8557, current episode: 7
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3569.1736, current episode: 8
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3588.1284, current episode: 9
[2023-06-29 13:25:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3596.5588, current episode: 10
[2023-06-29 13:25:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 414000.000000 | iteration_414000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495658      | 6686.021196         | 6.686021             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3581.967187 | 8.358424   | 3596.558838 | 3569.173584 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.6707, current episode: 1
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3545.9004, current episode: 2
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3556.9568, current episode: 3
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3552.9453, current episode: 4
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3572.7339, current episode: 5
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3568.5874, current episode: 6
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.0081, current episode: 7
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3561.3247, current episode: 8
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3554.4456, current episode: 9
[2023-06-29 13:25:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3564.7146, current episode: 10
[2023-06-29 13:25:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 414500.000000 | iteration_414500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520439      | 6577.049549         | 6.577050             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3559.028735 | 7.616884   | 3572.733887 | 3545.900391 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.5762, current episode: 1
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3521.4517, current episode: 2
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3533.6448, current episode: 3
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3529.3259, current episode: 4
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3537.3738, current episode: 5
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3534.6125, current episode: 6
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.9045, current episode: 7
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3531.4385, current episode: 8
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3534.6838, current episode: 9
[2023-06-29 13:26:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3546.8127, current episode: 10
[2023-06-29 13:26:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 415000.000000 | iteration_415000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.472678      | 6790.352428         | 6.790352             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3529.582446 | 10.253878  | 3546.812744 | 3509.904541 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.8992, current episode: 1
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3498.1121, current episode: 2
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3504.0000, current episode: 3
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3482.5830, current episode: 4
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3501.6067, current episode: 5
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3492.1782, current episode: 6
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3511.3948, current episode: 7
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3512.1560, current episode: 8
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3492.6460, current episode: 9
[2023-06-29 13:26:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3492.1497, current episode: 10
[2023-06-29 13:26:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 415500.000000 | iteration_415500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506278      | 6638.880940         | 6.638881             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3500.372559 | 10.315959  | 3516.899170 | 3482.583008 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3523.5342, current episode: 1
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3500.1677, current episode: 2
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3508.6667, current episode: 3
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3514.4119, current episode: 4
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3524.9109, current episode: 5
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3511.5408, current episode: 6
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3521.9031, current episode: 7
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3521.0693, current episode: 8
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3529.1882, current episode: 9
[2023-06-29 13:26:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3521.9519, current episode: 10
[2023-06-29 13:26:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 416000.000000 | iteration_416000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483878      | 6739.096599         | 6.739097             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3517.734473 | 8.383480   | 3529.188232 | 3500.167725 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:26:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2138.6052, current episode: 1
[2023-06-29 13:26:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2458.1770, current episode: 2
[2023-06-29 13:26:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3042.1040, current episode: 3
[2023-06-29 13:26:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3090.0386, current episode: 4
[2023-06-29 13:26:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3322.7341, current episode: 5
[2023-06-29 13:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3543.6052, current episode: 6
[2023-06-29 13:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.5295, current episode: 7
[2023-06-29 13:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3512.2444, current episode: 8
[2023-06-29 13:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3508.7493, current episode: 9
[2023-06-29 13:26:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.4590, current episode: 10
[2023-06-29 13:26:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 416500.000000 | iteration_416500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483886      | 6739.063336         | 6.739063             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3165.024634 | 472.077569 | 3543.605225 | 2138.605225 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3470.0330, current episode: 1
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3503.2878, current episode: 2
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3489.9407, current episode: 3
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3494.7129, current episode: 4
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3487.1143, current episode: 5
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3510.2341, current episode: 6
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3494.3120, current episode: 7
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.9060, current episode: 8
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3493.6843, current episode: 9
[2023-06-29 13:27:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3486.0476, current episode: 10
[2023-06-29 13:27:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 417000.000000 | iteration_417000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488710      | 6717.222953         | 6.717223             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3493.127271 | 10.521197  | 3510.234131 | 3470.032959 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3503.6812, current episode: 1
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3520.7834, current episode: 2
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3510.7290, current episode: 3
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3512.0627, current episode: 4
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3505.8064, current episode: 5
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3507.1987, current episode: 6
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3505.8965, current episode: 7
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.7029, current episode: 8
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3506.7891, current episode: 9
[2023-06-29 13:27:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.5344, current episode: 10
[2023-06-29 13:27:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 417500.000000 | iteration_417500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495065      | 6688.670477         | 6.688670             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3506.918433 | 6.531807   | 3520.783447 | 3494.534424 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3495.6782, current episode: 1
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3539.7161, current episode: 2
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3500.6833, current episode: 3
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3525.2568, current episode: 4
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3521.7485, current episode: 5
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3535.3640, current episode: 6
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3511.2227, current episode: 7
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3517.1006, current episode: 8
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3520.8911, current episode: 9
[2023-06-29 13:27:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.7114, current episode: 10
[2023-06-29 13:27:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 418000.000000 | iteration_418000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495737      | 6685.665426         | 6.685665             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3518.237280 | 13.051013  | 3539.716064 | 3495.678223 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:27:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2082.1003, current episode: 1
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.5239, current episode: 2
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3563.8499, current episode: 3
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3568.9370, current episode: 4
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.1514, current episode: 5
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3527.5098, current episode: 6
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3540.1560, current episode: 7
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3623.8230, current episode: 8
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3521.1704, current episode: 9
[2023-06-29 13:27:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3528.3943, current episode: 10
[2023-06-29 13:27:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 418500.000000 | iteration_418500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494376      | 6691.756397         | 6.691756             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3405.461597 | 442.012756 | 3623.822998 | 2082.100342 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1975.7701, current episode: 1
[2023-06-29 13:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1992.6659, current episode: 2
[2023-06-29 13:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2006.5010, current episode: 3
[2023-06-29 13:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2572.0364, current episode: 4
[2023-06-29 13:28:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2969.9587, current episode: 5
[2023-06-29 13:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3454.2112, current episode: 6
[2023-06-29 13:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3559.1792, current episode: 7
[2023-06-29 13:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3526.7144, current episode: 8
[2023-06-29 13:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3618.1245, current episode: 9
[2023-06-29 13:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3591.8752, current episode: 10
[2023-06-29 13:28:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 419000.000000 | iteration_419000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514183      | 6604.220026         | 6.604220             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2926.703662 | 686.290924 | 3618.124512 | 1975.770142 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:28:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2093.3335, current episode: 1
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3527.3713, current episode: 2
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3489.8943, current episode: 3
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3512.4226, current episode: 4
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3506.8787, current episode: 5
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3503.3479, current episode: 6
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3536.4348, current episode: 7
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.5439, current episode: 8
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3507.6470, current episode: 9
[2023-06-29 13:28:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3514.0876, current episode: 10
[2023-06-29 13:28:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 419500.000000 | iteration_419500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517579      | 6589.440759         | 6.589441             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3371.896167 | 426.381519 | 3536.434814 | 2093.333496 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:28:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2621.1367, current episode: 1
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3437.1948, current episode: 2
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3505.7598, current episode: 3
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3578.3232, current episode: 4
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3543.5103, current episode: 5
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3487.4902, current episode: 6
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3554.9866, current episode: 7
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3511.5056, current episode: 8
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3500.6584, current episode: 9
[2023-06-29 13:28:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3493.7173, current episode: 10
[2023-06-29 13:28:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 420000.000000 | iteration_420000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488294      | 6719.102790         | 6.719103             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3423.428296 | 270.023341 | 3578.323242 | 2621.136719 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1958.6285, current episode: 1
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1950.8387, current episode: 2
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1967.2954, current episode: 3
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1981.8585, current episode: 4
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1984.2179, current episode: 5
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2119.6812, current episode: 6
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2226.6379, current episode: 7
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2285.5955, current episode: 8
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2278.1001, current episode: 9
[2023-06-29 13:28:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3622.0466, current episode: 10
[2023-06-29 13:28:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 420500.000000 | iteration_420500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496919      | 6680.386794         | 6.680387             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2237.490039 | 479.310865 | 3622.046631 | 1950.838745 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1383.9069, current episode: 1
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1419.0917, current episode: 2
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1505.7220, current episode: 3
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1524.2651, current episode: 4
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1532.4742, current episode: 5
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1551.5490, current episode: 6
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1619.7262, current episode: 7
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1687.0031, current episode: 8
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1672.0129, current episode: 9
[2023-06-29 13:29:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1787.9161, current episode: 10
[2023-06-29 13:29:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 421000.000000 | iteration_421000.pth.tar | 10.000000     | 4730.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 473.000000              | 0.718728      | 6581.075224         | 13.913478            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1568.366724 | 118.070213 | 1787.916138 | 1383.906860 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1386.9387, current episode: 1
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1392.7029, current episode: 2
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1414.0566, current episode: 3
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1468.0725, current episode: 4
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1569.8381, current episode: 5
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1686.9771, current episode: 6
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1677.1053, current episode: 7
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1684.3245, current episode: 8
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1699.5833, current episode: 9
[2023-06-29 13:29:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1782.7970, current episode: 10
[2023-06-29 13:29:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 421500.000000 | iteration_421500.pth.tar | 10.000000     | 4720.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 472.000000              | 0.722472      | 6533.127504         | 13.841372            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1576.239600 | 141.266979 | 1782.796997 | 1386.938721 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1327.2493, current episode: 1
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1392.8760, current episode: 2
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1429.7279, current episode: 3
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1432.9264, current episode: 4
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1432.0642, current episode: 5
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1439.2468, current episode: 6
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1441.6547, current episode: 7
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1460.1803, current episode: 8
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1458.4630, current episode: 9
[2023-06-29 13:29:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1508.5485, current episode: 10
[2023-06-29 13:29:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 422000.000000 | iteration_422000.pth.tar | 10.000000     | 3970.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 397.000000              | 0.597125      | 6648.521460         | 16.746905            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1432.293701 | 44.730732  | 1508.548462 | 1327.249268 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3256.2720, current episode: 1
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3573.2905, current episode: 2
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3557.2041, current episode: 3
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3559.2095, current episode: 4
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3749.0378, current episode: 5
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3550.4768, current episode: 6
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3555.5452, current episode: 7
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3570.7754, current episode: 8
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3561.4373, current episode: 9
[2023-06-29 13:29:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3525.2651, current episode: 10
[2023-06-29 13:29:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 422500.000000 | iteration_422500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491358      | 6705.300175         | 6.705300             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3545.851367 | 112.962155 | 3749.037842 | 3256.271973 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:30:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1862.7090, current episode: 1
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1862.7090, current episode: 1
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3700.8745, current episode: 2
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.8613, current episode: 3
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3524.2830, current episode: 4
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3495.9036, current episode: 5
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3487.6169, current episode: 6
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3476.5713, current episode: 7
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3485.9539, current episode: 8
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3600.4753, current episode: 9
[2023-06-29 13:30:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3531.6746, current episode: 10
[2023-06-29 13:30:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 423000.000000 | iteration_423000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.481936      | 6747.931798         | 6.747932             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3373.792334 | 507.893423 | 3700.874512 | 1862.708984 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3411.7185, current episode: 1
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3402.3943, current episode: 2
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3417.9309, current episode: 3
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3405.9851, current episode: 4
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3414.9631, current episode: 5
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3418.9055, current episode: 6
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3418.7227, current episode: 7
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3402.4961, current episode: 8
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3423.2791, current episode: 9
[2023-06-29 13:30:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3405.1733, current episode: 10
[2023-06-29 13:30:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 423500.000000 | iteration_423500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517124      | 6591.420516         | 6.591421             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3412.156860 | 7.275043   | 3423.279053 | 3402.394287 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1609.3346, current episode: 1
[2023-06-29 13:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3040.3210, current episode: 2
[2023-06-29 13:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1609.3346, current episode: 2
[2023-06-29 13:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3235.7026, current episode: 3
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3639.8301, current episode: 4
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3508.8933, current episode: 5
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3472.7017, current episode: 6
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3510.4248, current episode: 7
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3470.5400, current episode: 8
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3523.6108, current episode: 9
[2023-06-29 13:30:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3513.6755, current episode: 10
[2023-06-29 13:30:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 424000.000000 | iteration_424000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506604      | 6637.444733         | 6.637445             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3252.503455 | 571.430303 | 3639.830078 | 1609.334595 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3481.2556, current episode: 1
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3486.5037, current episode: 2
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3478.6396, current episode: 3
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3482.9368, current episode: 4
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3483.4631, current episode: 5
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3483.5950, current episode: 6
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3506.4849, current episode: 7
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3479.7317, current episode: 8
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3476.4138, current episode: 9
[2023-06-29 13:30:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3488.4873, current episode: 10
[2023-06-29 13:30:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 424500.000000 | iteration_424500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.498362      | 6673.953268         | 6.673953             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3484.751147 | 7.999672   | 3506.484863 | 3476.413818 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3482.1814, current episode: 1
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3470.0259, current episode: 2
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3491.2576, current episode: 3
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3498.0183, current episode: 4
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3508.1946, current episode: 5
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3453.4912, current episode: 6
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3464.5940, current episode: 7
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.3157, current episode: 8
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3466.6768, current episode: 9
[2023-06-29 13:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3475.8345, current episode: 10
[2023-06-29 13:31:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 425000.000000 | iteration_425000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495198      | 6688.077441         | 6.688077             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3481.158984 | 17.106768  | 3508.194580 | 3453.491211 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3470.1858, current episode: 1
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3473.5781, current episode: 2
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3463.5032, current episode: 3
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3453.6111, current episode: 4
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3457.1326, current episode: 5
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3498.0640, current episode: 6
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3499.0486, current episode: 7
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3464.2432, current episode: 8
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3479.0078, current episode: 9
[2023-06-29 13:31:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.1780, current episode: 10
[2023-06-29 13:31:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 425500.000000 | iteration_425500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.475988      | 6775.123223         | 6.775123             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3474.855225 | 15.512320  | 3499.048584 | 3453.611084 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1636.2738, current episode: 1
[2023-06-29 13:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1768.4784, current episode: 2
[2023-06-29 13:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1868.8118, current episode: 3
[2023-06-29 13:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1921.6552, current episode: 4
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2300.3550, current episode: 5
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2401.2031, current episode: 6
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1636.2738, current episode: 6
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1768.4784, current episode: 6
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1868.8118, current episode: 6
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3433.1848, current episode: 7
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3422.8091, current episode: 8
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3442.0186, current episode: 9
[2023-06-29 13:31:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3435.0693, current episode: 10
[2023-06-29 13:31:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 426000.000000 | iteration_426000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500005      | 6666.646593         | 6.666647             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2562.985901 | 742.168377 | 3442.018555 | 1636.273804 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3404.6477, current episode: 1
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3436.0469, current episode: 2
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3428.5996, current episode: 3
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3422.7478, current episode: 4
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3437.0596, current episode: 5
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3419.5012, current episode: 6
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3424.1807, current episode: 7
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3419.0066, current episode: 8
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3416.6665, current episode: 9
[2023-06-29 13:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3426.9275, current episode: 10
[2023-06-29 13:31:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 426500.000000 | iteration_426500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500021      | 6666.571724         | 6.666572             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3423.538403 | 9.046219   | 3437.059570 | 3404.647705 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:32:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1349.7897, current episode: 1
[2023-06-29 13:32:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1393.6299, current episode: 2
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.1194, current episode: 3
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1689.7352, current episode: 4
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1688.2340, current episode: 5
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1861.6138, current episode: 6
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1349.7897, current episode: 6
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1393.6299, current episode: 6
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.1194, current episode: 6
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1689.7352, current episode: 6
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1688.2340, current episode: 6
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3401.1536, current episode: 7
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3381.4810, current episode: 8
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3385.4263, current episode: 9
[2023-06-29 13:32:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3360.8164, current episode: 10
[2023-06-29 13:32:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 427000.000000 | iteration_427000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.492889      | 6698.421480         | 6.698421             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2302.699915 | 892.460431 | 3401.153564 | 1349.789673 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:32:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1304.1414, current episode: 1
[2023-06-29 13:32:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1634.0149, current episode: 2
[2023-06-29 13:32:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1943.5842, current episode: 3
[2023-06-29 13:32:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1304.1414, current episode: 3
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1634.0149, current episode: 3
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3337.2961, current episode: 4
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3327.1433, current episode: 5
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3296.1216, current episode: 6
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3287.3000, current episode: 7
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3324.1421, current episode: 8
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3317.5911, current episode: 9
[2023-06-29 13:32:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3275.1497, current episode: 10
[2023-06-29 13:32:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 427500.000000 | iteration_427500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512337      | 6612.284288         | 6.612284             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2804.648438 | 784.149479 | 3337.296143 | 1304.141357 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:32:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1392.7218, current episode: 1
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1392.7218, current episode: 1
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3386.3318, current episode: 2
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3379.9546, current episode: 3
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3327.7944, current episode: 4
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3382.6895, current episode: 5
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3383.3796, current episode: 6
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3358.8494, current episode: 7
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3335.4766, current episode: 8
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3366.2415, current episode: 9
[2023-06-29 13:32:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3374.6323, current episode: 10
[2023-06-29 13:32:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 428000.000000 | iteration_428000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503452      | 6651.359014         | 6.651359             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3168.807141 | 592.341318 | 3386.331787 | 1392.721802 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3390.1877, current episode: 1
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3363.0815, current episode: 2
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3420.7517, current episode: 3
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3418.7505, current episode: 4
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3419.1279, current episode: 5
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3430.0469, current episode: 6
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3429.7349, current episode: 7
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3392.5471, current episode: 8
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3369.0935, current episode: 9
[2023-06-29 13:32:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3401.2092, current episode: 10
[2023-06-29 13:32:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 428500.000000 | iteration_428500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.465445      | 6823.865470         | 6.823865             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3403.453101 | 22.994133  | 3430.046875 | 3363.081543 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3340.0693, current episode: 1
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3335.7732, current episode: 2
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3348.0537, current episode: 3
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3341.8772, current episode: 4
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3347.5581, current episode: 5
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3324.1189, current episode: 6
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3340.5254, current episode: 7
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3341.4404, current episode: 8
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3346.9207, current episode: 9
[2023-06-29 13:33:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3363.3997, current episode: 10
[2023-06-29 13:33:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 429000.000000 | iteration_429000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478466      | 6763.769249         | 6.763769             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3342.973657 | 9.512913   | 3363.399658 | 3324.118896 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3331.2209, current episode: 1
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3331.3774, current episode: 2
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3349.5752, current episode: 3
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3266.2644, current episode: 4
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3337.2151, current episode: 5
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3348.4651, current episode: 6
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3323.1985, current episode: 7
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3340.8689, current episode: 8
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3351.2700, current episode: 9
[2023-06-29 13:33:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3331.3022, current episode: 10
[2023-06-29 13:33:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 429500.000000 | iteration_429500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.473979      | 6784.357154         | 6.784357             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3331.075781 | 23.342557  | 3351.270020 | 3266.264404 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3386.6265, current episode: 1
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3334.6687, current episode: 2
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3392.9736, current episode: 3
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3326.5276, current episode: 4
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3348.7793, current episode: 5
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3347.1172, current episode: 6
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3361.3645, current episode: 7
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3374.0449, current episode: 8
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3357.1040, current episode: 9
[2023-06-29 13:33:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3364.7803, current episode: 10
[2023-06-29 13:33:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 430000.000000 | iteration_430000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.457382      | 6861.617459         | 6.861617             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3359.398657 | 20.191386  | 3392.973633 | 3326.527588 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3331.7319, current episode: 1
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3360.6660, current episode: 2
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3330.5369, current episode: 3
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3354.2122, current episode: 4
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3347.6201, current episode: 5
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3354.5952, current episode: 6
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3334.1191, current episode: 7
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3352.3254, current episode: 8
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3339.7776, current episode: 9
[2023-06-29 13:33:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3325.8008, current episode: 10
[2023-06-29 13:33:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 430500.000000 | iteration_430500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.503170      | 6652.606755         | 6.652607             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3343.138525 | 11.609189  | 3360.666016 | 3325.800781 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3306.9929, current episode: 1
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3294.0654, current episode: 2
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3309.9548, current episode: 3
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3292.1401, current episode: 4
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3322.6873, current episode: 5
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3312.1082, current episode: 6
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3346.4021, current episode: 7
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3309.9641, current episode: 8
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3311.9172, current episode: 9
[2023-06-29 13:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3316.2898, current episode: 10
[2023-06-29 13:34:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 431000.000000 | iteration_431000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.477891      | 6766.400033         | 6.766400             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3312.252197 | 14.369997  | 3346.402100 | 3292.140137 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3269.6089, current episode: 1
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3293.4998, current episode: 2
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3275.2808, current episode: 3
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3300.9011, current episode: 4
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3304.5125, current episode: 5
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3297.4021, current episode: 6
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3285.2415, current episode: 7
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3288.0103, current episode: 8
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3303.4304, current episode: 9
[2023-06-29 13:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3315.9363, current episode: 10
[2023-06-29 13:34:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 431500.000000 | iteration_431500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483716      | 6739.832352         | 6.739832             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3293.382349 | 13.394795  | 3315.936279 | 3269.608887 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1390.6405, current episode: 1
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1373.5272, current episode: 2
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1389.7972, current episode: 3
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1388.0206, current episode: 4
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1399.8330, current episode: 5
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1379.5804, current episode: 6
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1383.1948, current episode: 7
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1385.2319, current episode: 8
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1374.0929, current episode: 9
[2023-06-29 13:34:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1356.9033, current episode: 10
[2023-06-29 13:34:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 432000.000000 | iteration_432000.pth.tar | 10.000000     | 3960.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 396.000000              | 0.593107      | 6676.707012         | 16.860371            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1382.082202 | 11.276226  | 1399.833008 | 1356.903320 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3292.1372, current episode: 1
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3304.9456, current episode: 2
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3261.3333, current episode: 3
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3315.9346, current episode: 4
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3294.8110, current episode: 5
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3309.2720, current episode: 6
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3300.9539, current episode: 7
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3295.2332, current episode: 8
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3321.8438, current episode: 9
[2023-06-29 13:35:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3305.0505, current episode: 10
[2023-06-29 13:35:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 432500.000000 | iteration_432500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.474859      | 6780.308567         | 6.780309             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3300.151489 | 15.729798  | 3321.843750 | 3261.333252 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1452.5786, current episode: 1
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1518.5907, current episode: 2
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1564.0411, current episode: 3
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1608.5370, current episode: 4
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1632.6693, current episode: 5
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1724.8883, current episode: 6
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1872.2941, current episode: 7
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2508.0405, current episode: 8
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2660.3035, current episode: 9
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1452.5786, current episode: 9
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1518.5907, current episode: 9
[2023-06-29 13:35:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3050.0190, current episode: 10
[2023-06-29 13:35:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 433000.000000 | iteration_433000.pth.tar | 10.000000     | 8650.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 865.000000              | 1.301231      | 6647.551654         | 7.685031             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1959.196216 | 536.810203 | 3050.019043 | 1452.578613 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1382.0898, current episode: 1
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1409.9774, current episode: 2
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1403.0468, current episode: 3
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1517.5599, current episode: 4
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1571.9147, current episode: 5
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1678.5435, current episode: 6
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2244.5051, current episode: 7
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2581.9043, current episode: 8
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1382.0898, current episode: 8
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1409.9774, current episode: 8
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2789.9634, current episode: 9
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1403.0468, current episode: 9
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1517.5599, current episode: 9
[2023-06-29 13:35:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1571.9147, current episode: 9
[2023-06-29 13:35:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1678.5435, current episode: 9
[2023-06-29 13:35:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3441.2417, current episode: 10
[2023-06-29 13:35:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 433500.000000 | iteration_433500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506266      | 6638.933667         | 6.638934             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2002.074658 | 685.944944 | 3441.241699 | 1382.089844 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1408.7612, current episode: 1
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1408.1324, current episode: 2
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1399.8333, current episode: 3
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1458.1427, current episode: 4
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1447.1245, current episode: 5
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1430.5103, current episode: 6
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1479.7418, current episode: 7
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1425.0167, current episode: 8
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1495.8628, current episode: 9
[2023-06-29 13:35:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1496.1392, current episode: 10
[2023-06-29 13:35:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 434000.000000 | iteration_434000.pth.tar | 10.000000     | 4020.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 402.000000              | 0.623349      | 6449.035783         | 16.042378            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1444.926489 | 34.508268  | 1496.139160 | 1399.833252 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3385.4050, current episode: 1
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3381.7805, current episode: 2
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3379.5439, current episode: 3
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3389.1780, current episode: 4
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3411.3083, current episode: 5
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3405.6399, current episode: 6
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3402.9045, current episode: 7
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3430.1079, current episode: 8
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3324.1750, current episode: 9
[2023-06-29 13:36:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3383.6326, current episode: 10
[2023-06-29 13:36:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 434500.000000 | iteration_434500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501058      | 6661.967291         | 6.661967             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3389.367578 | 26.536712  | 3430.107910 | 3324.175049 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1216.7665, current episode: 1
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1221.6464, current episode: 2
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1236.1084, current episode: 3
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1236.2909, current episode: 4
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1219.2363, current episode: 5
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1272.1864, current episode: 6
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1393.0138, current episode: 7
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1383.6328, current episode: 8
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1371.2531, current episode: 9
[2023-06-29 13:36:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1358.7975, current episode: 10
[2023-06-29 13:36:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 435000.000000 | iteration_435000.pth.tar | 10.000000     | 3930.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 393.000000              | 0.625711      | 6280.850013         | 15.981807            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1290.893201 | 72.010612  | 1393.013794 | 1216.766479 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1131.3291, current episode: 1
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1138.9495, current episode: 2
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1125.8987, current episode: 3
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1138.9346, current episode: 4
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1137.5267, current episode: 5
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1133.1104, current episode: 6
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1132.7944, current episode: 7
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1136.2078, current episode: 8
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1221.9253, current episode: 9
[2023-06-29 13:36:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1273.4608, current episode: 10
[2023-06-29 13:36:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 435500.000000 | iteration_435500.pth.tar | 10.000000     | 3560.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 356.000000              | 0.560733      | 6348.831633         | 17.833797            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1157.013721 | 46.930834  | 1273.460815 | 1125.898682 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1137.9683, current episode: 1
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1109.5271, current episode: 2
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1155.6854, current episode: 3
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1124.6853, current episode: 4
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1162.6948, current episode: 5
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1144.5001, current episode: 6
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1189.1637, current episode: 7
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1143.1785, current episode: 8
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1159.0548, current episode: 9
[2023-06-29 13:36:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1162.1409, current episode: 10
[2023-06-29 13:36:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 436000.000000 | iteration_436000.pth.tar | 10.000000     | 3270.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 327.000000              | 0.523690      | 6244.149862         | 19.095260            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1148.859888 | 21.081043  | 1189.163696 | 1109.527100 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1321.6779, current episode: 1
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1311.6471, current episode: 2
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1318.3130, current episode: 3
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1328.6376, current episode: 4
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1371.2822, current episode: 5
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1391.3912, current episode: 6
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1381.0831, current episode: 7
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1407.5580, current episode: 8
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1381.5653, current episode: 9
[2023-06-29 13:37:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1467.3560, current episode: 10
[2023-06-29 13:37:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 436500.000000 | iteration_436500.pth.tar | 10.000000     | 4120.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 412.000000              | 0.673351      | 6118.648449         | 14.851088            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1368.051135 | 46.571572  | 1467.355957 | 1311.647095 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1222.7572, current episode: 1
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1245.8936, current episode: 2
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1237.2336, current episode: 3
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1259.9053, current episode: 4
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1277.7711, current episode: 5
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1272.8486, current episode: 6
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1280.6742, current episode: 7
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1283.0270, current episode: 8
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1299.8268, current episode: 9
[2023-06-29 13:37:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1345.1222, current episode: 10
[2023-06-29 13:37:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 437000.000000 | iteration_437000.pth.tar | 10.000000     | 3510.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 351.000000              | 0.561941      | 6246.208254         | 17.795465            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1272.505957 | 32.879885  | 1345.122192 | 1222.757202 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1067.8646, current episode: 1
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1081.2626, current episode: 2
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1082.1409, current episode: 3
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1180.9358, current episode: 4
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1223.3903, current episode: 5
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1239.7567, current episode: 6
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1234.2672, current episode: 7
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1253.6384, current episode: 8
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1250.8564, current episode: 9
[2023-06-29 13:37:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1560.2864, current episode: 10
[2023-06-29 13:37:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 437500.000000 | iteration_437500.pth.tar | 10.000000     | 4090.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 409.000000              | 0.659924      | 6197.680971         | 15.153254            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1217.439929 | 134.663550 | 1560.286377 | 1067.864624 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1091.4075, current episode: 1
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1100.1234, current episode: 2
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1137.3430, current episode: 3
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1226.5491, current episode: 4
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1336.3037, current episode: 5
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1357.7028, current episode: 6
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1606.7234, current episode: 7
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1602.1919, current episode: 8
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1599.3625, current episode: 9
[2023-06-29 13:37:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1627.7152, current episode: 10
[2023-06-29 13:37:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 438000.000000 | iteration_438000.pth.tar | 10.000000     | 4230.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 423.000000              | 0.681853      | 6203.682950         | 14.665917            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1368.542249 | 213.399946 | 1627.715210 | 1091.407471 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3455.0706, current episode: 1
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3460.1333, current episode: 2
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3478.1174, current episode: 3
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3481.3323, current episode: 4
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3451.6277, current episode: 5
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3496.4595, current episode: 6
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3456.6204, current episode: 7
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3445.6787, current episode: 8
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3439.2432, current episode: 9
[2023-06-29 13:38:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3463.3005, current episode: 10
[2023-06-29 13:38:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 438500.000000 | iteration_438500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500091      | 6666.260333         | 6.666260             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3462.758350 | 16.700866  | 3496.459473 | 3439.243164 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3423.3169, current episode: 1
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3447.3506, current episode: 2
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3424.6562, current episode: 3
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3437.6326, current episode: 4
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3443.5400, current episode: 5
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3443.8445, current episode: 6
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3434.5588, current episode: 7
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3467.6274, current episode: 8
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3444.5449, current episode: 9
[2023-06-29 13:38:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3441.6631, current episode: 10
[2023-06-29 13:38:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 439000.000000 | iteration_439000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.486810      | 6725.808682         | 6.725809             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3440.873511 | 11.871723  | 3467.627441 | 3423.316895 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1528.3846, current episode: 1
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1535.2208, current episode: 2
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1629.2991, current episode: 3
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1687.4230, current episode: 4
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1697.2375, current episode: 5
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1666.0242, current episode: 6
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1703.4359, current episode: 7
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1708.7778, current episode: 8
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1729.9325, current episode: 9
[2023-06-29 13:38:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1670.2996, current episode: 10
[2023-06-29 13:38:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 439500.000000 | iteration_439500.pth.tar | 10.000000     | 4550.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 455.000000              | 0.709645      | 6411.653599         | 14.091546            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1655.603503 | 67.141072  | 1729.932495 | 1528.384644 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.5146, current episode: 1
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3462.6162, current episode: 2
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3503.7549, current episode: 3
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3451.6392, current episode: 4
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3474.8721, current episode: 5
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3474.0339, current episode: 6
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3520.2463, current episode: 7
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3474.3562, current episode: 8
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3530.3928, current episode: 9
[2023-06-29 13:38:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3472.2429, current episode: 10
[2023-06-29 13:38:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 440000.000000 | iteration_440000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501880      | 6658.323172         | 6.658323             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3485.666919 | 24.123481  | 3530.392822 | 3451.639160 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3562.8127, current episode: 1
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.2153, current episode: 2
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3464.7031, current episode: 3
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3483.6062, current episode: 4
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3472.9563, current episode: 5
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3492.5754, current episode: 6
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3483.9729, current episode: 7
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3461.5432, current episode: 8
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3462.6677, current episode: 9
[2023-06-29 13:39:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3492.2031, current episode: 10
[2023-06-29 13:39:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 440500.000000 | iteration_440500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.471057      | 6797.832527         | 6.797833             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3493.025610 | 34.325334  | 3562.812744 | 3461.543213 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:39:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2273.0876, current episode: 1
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3378.9253, current episode: 2
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3346.2283, current episode: 3
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3393.7197, current episode: 4
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3379.7368, current episode: 5
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3398.5991, current episode: 6
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3480.1199, current episode: 7
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3408.9529, current episode: 8
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3381.0193, current episode: 9
[2023-06-29 13:39:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3399.9412, current episode: 10
[2023-06-29 13:39:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 441000.000000 | iteration_441000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478095      | 6765.465700         | 6.765466             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3284.033008 | 338.540276 | 3480.119873 | 2273.087646 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3473.4402, current episode: 1
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3473.2158, current episode: 2
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3447.1204, current episode: 3
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3465.0459, current episode: 4
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3478.6135, current episode: 5
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3440.7654, current episode: 6
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3431.1982, current episode: 7
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3457.5022, current episode: 8
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3444.8694, current episode: 9
[2023-06-29 13:39:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3455.1619, current episode: 10
[2023-06-29 13:39:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 441500.000000 | iteration_441500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487490      | 6722.734315         | 6.722734             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3456.693286 | 14.972830  | 3478.613525 | 3431.198242 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3449.3027, current episode: 1
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3467.1567, current episode: 2
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3496.4180, current episode: 3
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3487.4507, current episode: 4
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3480.9841, current episode: 5
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3470.0938, current episode: 6
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3449.3928, current episode: 7
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3479.1394, current episode: 8
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3484.1328, current episode: 9
[2023-06-29 13:39:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3498.1614, current episode: 10
[2023-06-29 13:39:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 442000.000000 | iteration_442000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522141      | 6569.692593         | 6.569693             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.223242 | 16.350085  | 3498.161377 | 3449.302734 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3459.6379, current episode: 1
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3451.9773, current episode: 2
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3453.2471, current episode: 3
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3435.4336, current episode: 4
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3471.5378, current episode: 5
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3462.3403, current episode: 6
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3446.3569, current episode: 7
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3459.1794, current episode: 8
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3458.8191, current episode: 9
[2023-06-29 13:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3448.1086, current episode: 10
[2023-06-29 13:40:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 442500.000000 | iteration_442500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510944      | 6618.378037         | 6.618378             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3454.663818 | 9.471332   | 3471.537842 | 3435.433594 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2247.4939, current episode: 1
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3502.5083, current episode: 2
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3577.4763, current episode: 3
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3501.7710, current episode: 4
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3504.6929, current episode: 5
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3493.5686, current episode: 6
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.4700, current episode: 7
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3491.0930, current episode: 8
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3496.9612, current episode: 9
[2023-06-29 13:40:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3517.5703, current episode: 10
[2023-06-29 13:40:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 443000.000000 | iteration_443000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514757      | 6601.719671         | 6.601720             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3384.260547 | 379.654802 | 3577.476318 | 2247.493896 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1511.0717, current episode: 1
[2023-06-29 13:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1702.1355, current episode: 2
[2023-06-29 13:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2048.6570, current episode: 3
[2023-06-29 13:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1511.0717, current episode: 3
[2023-06-29 13:40:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3025.8901, current episode: 4
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3315.5312, current episode: 5
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3310.5991, current episode: 6
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1702.1355, current episode: 6
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3712.0706, current episode: 7
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3660.3408, current episode: 8
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3553.4202, current episode: 9
[2023-06-29 13:40:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3761.0383, current episode: 10
[2023-06-29 13:40:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 443500.000000 | iteration_443500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507804      | 6632.159790         | 6.632160             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2960.075452 | 825.573952 | 3761.038330 | 1511.071655 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:40:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1672.9948, current episode: 1
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2292.6799, current episode: 2
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2357.7559, current episode: 3
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2581.2256, current episode: 4
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2956.5181, current episode: 5
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1672.9948, current episode: 5
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3708.5220, current episode: 6
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3565.5381, current episode: 7
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3609.8853, current episode: 8
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3600.6235, current episode: 9
[2023-06-29 13:40:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3545.4087, current episode: 10
[2023-06-29 13:40:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 444000.000000 | iteration_444000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488000      | 6720.432313         | 6.720432             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2989.115173 | 685.697896 | 3708.521973 | 1672.994751 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1519.4668, current episode: 1
[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1688.2029, current episode: 2
[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1762.1887, current episode: 3
[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1965.7729, current episode: 4
[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1946.1249, current episode: 5
[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2093.5110, current episode: 6
[2023-06-29 13:41:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2455.4922, current episode: 7
[2023-06-29 13:41:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2764.0186, current episode: 8
[2023-06-29 13:41:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1519.4668, current episode: 8
[2023-06-29 13:41:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1688.2029, current episode: 8
[2023-06-29 13:41:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1762.1887, current episode: 8
[2023-06-29 13:41:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3552.0850, current episode: 9
[2023-06-29 13:41:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3550.2300, current episode: 10
[2023-06-29 13:41:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 444500.000000 | iteration_444500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528482      | 6542.439122         | 6.542439             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2329.709290 | 700.984891 | 3552.084961 | 1519.466797 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1511.9536, current episode: 1
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1610.3239, current episode: 2
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1844.6700, current episode: 3
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2065.5093, current episode: 4
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2098.8655, current episode: 5
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2140.4780, current episode: 6
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2215.7942, current episode: 7
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2370.0186, current episode: 8
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2362.5681, current episode: 9
[2023-06-29 13:41:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2938.2051, current episode: 10
[2023-06-29 13:41:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 445000.000000 | iteration_445000.pth.tar | 10.000000     | 7710.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 771.000000              | 1.197020      | 6440.997003         | 8.354082             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2115.838623 | 388.451219 | 2938.205078 | 1511.953613 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1414.2090, current episode: 1
[2023-06-29 13:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1506.0975, current episode: 2
[2023-06-29 13:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1582.2616, current episode: 3
[2023-06-29 13:41:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1595.2043, current episode: 4
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2329.3911, current episode: 5
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2404.8787, current episode: 6
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1414.2090, current episode: 6
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2964.6377, current episode: 7
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1506.0975, current episode: 7
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3037.3452, current episode: 8
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1582.2616, current episode: 8
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1595.2043, current episode: 8
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3345.1912, current episode: 9
[2023-06-29 13:41:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3440.5693, current episode: 10
[2023-06-29 13:41:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 445500.000000 | iteration_445500.pth.tar | 10.000000     | 9130.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 913.000000              | 1.446516      | 6311.718893         | 6.913164             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2361.978564 | 760.196444 | 3440.569336 | 1414.208984 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2127.4700, current episode: 1
[2023-06-29 13:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2307.2104, current episode: 2
[2023-06-29 13:41:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2342.3923, current episode: 3
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3252.1101, current episode: 4
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3245.1685, current episode: 5
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3527.9875, current episode: 6
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3662.3528, current episode: 7
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3714.3357, current episode: 8
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3640.1060, current episode: 9
[2023-06-29 13:41:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3552.4763, current episode: 10
[2023-06-29 13:41:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 446000.000000 | iteration_446000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.545756      | 6469.325392         | 6.469325             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3137.160962 | 595.984304 | 3714.335693 | 2127.469971 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3000.6421, current episode: 1
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3296.2925, current episode: 2
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3293.5481, current episode: 3
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3619.7354, current episode: 4
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3732.3525, current episode: 5
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3573.9453, current episode: 6
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3577.7625, current episode: 7
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3582.4106, current episode: 8
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3516.9731, current episode: 9
[2023-06-29 13:42:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3570.7493, current episode: 10
[2023-06-29 13:42:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 446500.000000 | iteration_446500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.542400      | 6483.400848         | 6.483401             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.441138 | 204.902780 | 3732.352539 | 3000.642090 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2483.4602, current episode: 1
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3519.7817, current episode: 2
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3526.0752, current episode: 3
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3532.3696, current episode: 4
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3541.0720, current episode: 5
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3526.8396, current episode: 6
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3599.8196, current episode: 7
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3530.0083, current episode: 8
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3523.0669, current episode: 9
[2023-06-29 13:42:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3509.7632, current episode: 10
[2023-06-29 13:42:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 447000.000000 | iteration_447000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488590      | 6717.766631         | 6.717767             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3429.225635 | 316.114093 | 3599.819580 | 2483.460205 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3495.2476, current episode: 1
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3542.4517, current episode: 2
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3541.7390, current episode: 3
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3488.2148, current episode: 4
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3518.8132, current episode: 5
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3498.2656, current episode: 6
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3508.4888, current episode: 7
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3503.0078, current episode: 8
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.6741, current episode: 9
[2023-06-29 13:42:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3525.7051, current episode: 10
[2023-06-29 13:42:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 447500.000000 | iteration_447500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.530861      | 6532.272913         | 6.532273             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3513.860767 | 17.780280  | 3542.451660 | 3488.214844 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:42:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1454.4978, current episode: 1
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1454.4978, current episode: 1
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3513.2188, current episode: 2
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3517.3303, current episode: 3
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3572.4158, current episode: 4
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3589.2119, current episode: 5
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3544.1687, current episode: 6
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3570.4490, current episode: 7
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3572.9385, current episode: 8
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3505.3208, current episode: 9
[2023-06-29 13:42:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3571.3503, current episode: 10
[2023-06-29 13:42:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 448000.000000 | iteration_448000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.490706      | 6708.228971         | 6.708229             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3341.090186 | 629.490823 | 3589.211914 | 1454.497803 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1321.7488, current episode: 1
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1400.0048, current episode: 2
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1590.1631, current episode: 3
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1590.9330, current episode: 4
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1693.6969, current episode: 5
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1742.3247, current episode: 6
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1727.2876, current episode: 7
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1321.7488, current episode: 7
[2023-06-29 13:43:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1400.0048, current episode: 7
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1590.1631, current episode: 7
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1590.9330, current episode: 7
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1693.6969, current episode: 7
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1742.3247, current episode: 7
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1727.2876, current episode: 7
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3580.9087, current episode: 8
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3574.0188, current episode: 9
[2023-06-29 13:43:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3583.8462, current episode: 10
[2023-06-29 13:43:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 448500.000000 | iteration_448500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.555587      | 6428.443351         | 6.428443             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2180.493250 | 924.635573 | 3583.846191 | 1321.748779 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3577.6353, current episode: 1
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3615.9934, current episode: 2
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3593.8823, current episode: 3
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3533.9158, current episode: 4
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3596.3877, current episode: 5
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3596.2336, current episode: 6
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3584.8599, current episode: 7
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.7644, current episode: 8
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3602.5613, current episode: 9
[2023-06-29 13:43:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3592.6582, current episode: 10
[2023-06-29 13:43:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 449000.000000 | iteration_449000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553389      | 6437.539405         | 6.437539             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3585.689185 | 21.945244  | 3615.993408 | 3533.915771 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:43:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1672.3037, current episode: 1
[2023-06-29 13:43:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1990.4844, current episode: 2
[2023-06-29 13:43:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2208.9343, current episode: 3
[2023-06-29 13:43:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2198.2209, current episode: 4
[2023-06-29 13:43:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3034.9341, current episode: 5
[2023-06-29 13:43:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1672.3037, current episode: 5
[2023-06-29 13:43:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3445.6396, current episode: 6
[2023-06-29 13:43:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3577.6672, current episode: 7
[2023-06-29 13:43:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3556.3564, current episode: 8
[2023-06-29 13:43:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3616.7908, current episode: 9
[2023-06-29 13:43:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3619.8889, current episode: 10
[2023-06-29 13:43:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 449500.000000 | iteration_449500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.532973      | 6523.273562         | 6.523274             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2892.122046 | 744.439211 | 3619.888916 | 1672.303711 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1348.5065, current episode: 1
[2023-06-29 13:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1402.3097, current episode: 2
[2023-06-29 13:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1678.3351, current episode: 3
[2023-06-29 13:43:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1806.8602, current episode: 4
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2489.6941, current episode: 5
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1348.5065, current episode: 5
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1402.3097, current episode: 5
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1678.3351, current episode: 5
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1806.8602, current episode: 5
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3585.4941, current episode: 6
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3577.2017, current episode: 7
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3506.7329, current episode: 8
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3565.3889, current episode: 9
[2023-06-29 13:43:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3573.9153, current episode: 10
[2023-06-29 13:43:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 450000.000000 | iteration_450000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.556613      | 6424.206208         | 6.424206             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2653.443848 | 953.499506 | 3585.494141 | 1348.506470 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1319.8212, current episode: 1
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1319.8212, current episode: 1
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2579.2805, current episode: 2
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2569.8682, current episode: 3
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3563.5708, current episode: 4
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.8411, current episode: 5
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3603.0117, current episode: 6
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3577.8713, current episode: 7
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3544.7380, current episode: 8
[2023-06-29 13:44:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3575.7261, current episode: 9
[2023-06-29 13:44:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3581.6887, current episode: 10
[2023-06-29 13:44:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 450500.000000 | iteration_450500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494187      | 6692.603227         | 6.692603             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3147.641760 | 725.486958 | 3603.011719 | 1319.821167 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:44:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1129.2485, current episode: 1
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1140.8364, current episode: 2
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1144.3035, current episode: 3
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1148.6428, current episode: 4
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1337.7764, current episode: 5
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1945.6348, current episode: 6
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1129.2485, current episode: 6
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1140.8364, current episode: 6
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1144.3035, current episode: 6
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1148.6428, current episode: 6
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1337.7764, current episode: 6
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3033.9023, current episode: 7
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1129.2485, current episode: 7
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1140.8364, current episode: 7
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1144.3035, current episode: 7
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1148.6428, current episode: 7
[2023-06-29 13:44:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3560.5085, current episode: 8
[2023-06-29 13:44:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1945.6348, current episode: 8
[2023-06-29 13:44:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3610.3511, current episode: 9
[2023-06-29 13:44:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3615.5784, current episode: 10
[2023-06-29 13:44:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 451000.000000 | iteration_451000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548060      | 6459.699228         | 6.459699             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2166.678271 | 1087.407009 | 3615.578369 | 1129.248535 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1076.0686, current episode: 1
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1217.8013, current episode: 2
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1255.2805, current episode: 3
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1419.4443, current episode: 4
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1507.6715, current episode: 5
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1557.4475, current episode: 6
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1572.1720, current episode: 7
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1754.0929, current episode: 8
[2023-06-29 13:44:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2044.0326, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1076.0686, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1217.8013, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1255.2805, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1419.4443, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1507.6715, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1557.4475, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1572.1720, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1076.0686, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1754.0929, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1217.8013, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1255.2805, current episode: 9
[2023-06-29 13:44:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3560.6233, current episode: 10
[2023-06-29 13:44:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 451500.000000 | iteration_451500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.566413      | 6384.013035         | 6.384013             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1696.463452 | 674.909089 | 3560.623291 | 1076.068604 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1123.5156, current episode: 1
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1283.5045, current episode: 2
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1396.6877, current episode: 3
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1511.0088, current episode: 4
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1567.3513, current episode: 5
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1682.3015, current episode: 6
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1123.5156, current episode: 6
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1283.5045, current episode: 6
[2023-06-29 13:44:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1396.6877, current episode: 6
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1511.0088, current episode: 6
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1567.3513, current episode: 6
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1682.3015, current episode: 6
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1123.5156, current episode: 6
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3613.1990, current episode: 7
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3532.7004, current episode: 8
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3607.0867, current episode: 9
[2023-06-29 13:44:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3504.7861, current episode: 10
[2023-06-29 13:44:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 452000.000000 | iteration_452000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.522676      | 6567.383625         | 6.567384             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2282.214172 | 1057.120995 | 3613.198975 | 1123.515625 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1064.8268, current episode: 1
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1105.3116, current episode: 2
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1190.4668, current episode: 3
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.6904, current episode: 4
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1246.6591, current episode: 5
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1317.6215, current episode: 6
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1719.2697, current episode: 7
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1064.8268, current episode: 7
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1105.3116, current episode: 7
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1190.4668, current episode: 7
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.6904, current episode: 7
[2023-06-29 13:45:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1246.6591, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1317.6215, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1064.8268, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1719.2697, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1105.3116, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1190.4668, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.6904, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1246.6591, current episode: 7
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3582.8018, current episode: 8
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3567.1218, current episode: 9
[2023-06-29 13:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3612.7029, current episode: 10
[2023-06-29 13:45:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 452500.000000 | iteration_452500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.634954      | 6116.378739         | 6.116379             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 1960.447229 | 1078.532893 | 3612.702881 | 1064.826782 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 806.3944, current episode: 1
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1126.6101, current episode: 2
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.5698, current episode: 3
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1197.9609, current episode: 4
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1200.1335, current episode: 5
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 806.3944, current episode: 5
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1126.6101, current episode: 5
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.5698, current episode: 5
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1197.9609, current episode: 5
[2023-06-29 13:45:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1200.1335, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 806.3944, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1126.6101, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.5698, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1197.9609, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1200.1335, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 806.3944, current episode: 5
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3610.9307, current episode: 6
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3705.8789, current episode: 7
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3556.2168, current episode: 8
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3613.6611, current episode: 9
[2023-06-29 13:45:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3647.4670, current episode: 10
[2023-06-29 13:45:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 453000.000000 | iteration_453000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.551474      | 6445.482953         | 6.445483             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2361.682336 | 1269.930349 | 3705.878906 | 806.394409 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 13:45:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 750.4438, current episode: 1
[2023-06-29 13:45:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 828.8992, current episode: 2
[2023-06-29 13:45:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 960.0062, current episode: 3
[2023-06-29 13:45:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1117.6202, current episode: 4
[2023-06-29 13:45:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1152.9491, current episode: 5
[2023-06-29 13:45:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1272.3306, current episode: 6
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1421.0243, current episode: 7
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1636.3842, current episode: 8
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 750.4438, current episode: 8
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 828.8992, current episode: 8
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 960.0062, current episode: 8
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1117.6202, current episode: 8
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1152.9491, current episode: 8
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2399.6199, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1272.3306, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 750.4438, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1421.0243, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 828.8992, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 960.0062, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1636.3842, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1117.6202, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1152.9491, current episode: 9
[2023-06-29 13:45:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 750.4438, current episode: 9
[2023-06-29 13:45:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1272.3306, current episode: 9
[2023-06-29 13:45:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 828.8992, current episode: 9
[2023-06-29 13:45:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3580.2312, current episode: 10
[2023-06-29 13:45:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 453500.000000 | iteration_453500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.592933      | 6277.726562         | 6.277727             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1511.950861 | 823.552270 | 3580.231201 | 750.443787 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 901.3364, current episode: 1
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 991.5797, current episode: 2
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1039.6384, current episode: 3
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1026.5089, current episode: 4
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1075.4021, current episode: 5
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1074.8458, current episode: 6
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1133.3689, current episode: 7
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1224.3629, current episode: 8
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 901.3364, current episode: 8
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 991.5797, current episode: 8
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1039.6384, current episode: 8
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1026.5089, current episode: 8
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2144.2839, current episode: 9
[2023-06-29 13:46:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2164.5139, current episode: 10
[2023-06-29 13:46:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 454000.000000 | iteration_454000.pth.tar | 10.000000     | 5590.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 559.000000              | 0.855432      | 6534.712693         | 11.690005            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1277.584106 | 445.695155 | 2164.513916 | 901.336426 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 922.4705, current episode: 1
[2023-06-29 13:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 933.9568, current episode: 2
[2023-06-29 13:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 989.3261, current episode: 3
[2023-06-29 13:46:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1000.2184, current episode: 4
[2023-06-29 13:46:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1069.5286, current episode: 5
[2023-06-29 13:46:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1081.7377, current episode: 6
[2023-06-29 13:46:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1115.0455, current episode: 7
[2023-06-29 13:46:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1127.9137, current episode: 8
[2023-06-29 13:46:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1164.3840, current episode: 9
[2023-06-29 13:46:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1336.2231, current episode: 10
[2023-06-29 13:46:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 454500.000000 | iteration_454500.pth.tar | 10.000000     | 3440.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 344.000000              | 0.538692      | 6385.843881         | 18.563500            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1074.080450 | 116.956460 | 1336.223145 | 922.470520 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 657.3171, current episode: 1
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 659.6155, current episode: 2
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 661.9817, current episode: 3
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 664.3077, current episode: 4
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 667.4317, current episode: 5
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 666.2339, current episode: 6
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 810.2116, current episode: 7
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 887.1766, current episode: 8
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1450.1709, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 657.3171, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 659.6155, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 661.9817, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 664.3077, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 667.4317, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 666.2339, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 810.2116, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 887.1766, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 657.3171, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 659.6155, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 661.9817, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 664.3077, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 667.4317, current episode: 9
[2023-06-29 13:46:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 666.2339, current episode: 9
[2023-06-29 13:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 810.2116, current episode: 9
[2023-06-29 13:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 887.1766, current episode: 9
[2023-06-29 13:46:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2853.5857, current episode: 10
[2023-06-29 13:46:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 455000.000000 | iteration_455000.pth.tar | 10.000000     | 7490.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 749.000000              | 1.172703      | 6386.953885         | 8.527308             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 997.803247  | 661.012449 | 2853.585693 | 657.317078 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:46:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1035.6367, current episode: 1
[2023-06-29 13:46:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1077.2241, current episode: 2
[2023-06-29 13:46:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1076.3135, current episode: 3
[2023-06-29 13:46:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1078.2903, current episode: 4
[2023-06-29 13:46:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1119.6359, current episode: 5
[2023-06-29 13:46:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1289.6746, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1035.6367, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1077.2241, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1076.3135, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1078.2903, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1119.6359, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1289.6746, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1035.6367, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1077.2241, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1076.3135, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1078.2903, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1119.6359, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1289.6746, current episode: 6
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3589.8772, current episode: 7
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3563.1738, current episode: 8
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3563.6853, current episode: 9
[2023-06-29 13:46:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3578.1057, current episode: 10
[2023-06-29 13:46:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 455500.000000 | iteration_455500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535267      | 6513.525146         | 6.513525             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2097.161707 | 1207.319676 | 3589.877197 | 1035.636719 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1361.7281, current episode: 1
[2023-06-29 13:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1957.7010, current episode: 2
[2023-06-29 13:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2027.5150, current episode: 3
[2023-06-29 13:47:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2227.2439, current episode: 4
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2673.3955, current episode: 5
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2647.3889, current episode: 6
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1361.7281, current episode: 6
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2955.5522, current episode: 7
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3582.8074, current episode: 8
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3566.0566, current episode: 9
[2023-06-29 13:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3563.0723, current episode: 10
[2023-06-29 13:47:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 456000.000000 | iteration_456000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496929      | 6680.344302         | 6.680344             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2656.246106 | 730.865857 | 3582.807373 | 1361.728149 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1040.2310, current episode: 1
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1202.9753, current episode: 2
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1614.1388, current episode: 3
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1040.2310, current episode: 3
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1202.9753, current episode: 3
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1614.1388, current episode: 3
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3265.2358, current episode: 4
[2023-06-29 13:47:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1040.2310, current episode: 4
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1202.9753, current episode: 4
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3584.6997, current episode: 5
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3579.2004, current episode: 6
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3585.5562, current episode: 7
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3583.9287, current episode: 8
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3573.0146, current episode: 9
[2023-06-29 13:47:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3623.2869, current episode: 10
[2023-06-29 13:47:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 456500.000000 | iteration_456500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547626      | 6461.509023         | 6.461509             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2865.226746 | 1046.773295 | 3623.286865 | 1040.230957 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:47:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1385.7141, current episode: 1
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1385.7141, current episode: 1
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3530.8252, current episode: 2
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3548.2480, current episode: 3
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3527.8828, current episode: 4
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3557.9756, current episode: 5
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3560.3933, current episode: 6
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3558.0950, current episode: 7
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3548.9641, current episode: 8
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3553.9893, current episode: 9
[2023-06-29 13:47:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.3086, current episode: 10
[2023-06-29 13:47:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 457000.000000 | iteration_457000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478529      | 6763.481099         | 6.763481             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3330.739600 | 648.437512 | 3560.393311 | 1385.714111 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1256.0703, current episode: 1
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1298.1014, current episode: 2
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1832.8173, current episode: 3
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2328.4138, current episode: 4
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2383.1150, current episode: 5
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1256.0703, current episode: 5
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1298.1014, current episode: 5
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2959.1458, current episode: 6
[2023-06-29 13:47:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3009.5200, current episode: 7
[2023-06-29 13:47:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1832.8173, current episode: 7
[2023-06-29 13:47:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3559.5371, current episode: 8
[2023-06-29 13:47:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3573.3977, current episode: 9
[2023-06-29 13:47:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3560.3115, current episode: 10
[2023-06-29 13:47:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 457500.000000 | iteration_457500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485667      | 6730.984599         | 6.730985             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2576.042993 | 853.921548 | 3573.397705 | 1256.070312 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1380.8215, current episode: 1
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1675.2162, current episode: 2
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1717.6481, current episode: 3
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2010.3568, current episode: 4
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1380.8215, current episode: 4
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3198.7693, current episode: 5
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1675.2162, current episode: 5
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1717.6481, current episode: 5
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3536.5669, current episode: 6
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3567.9058, current episode: 7
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3549.0320, current episode: 8
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3681.6106, current episode: 9
[2023-06-29 13:48:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3584.1604, current episode: 10
[2023-06-29 13:48:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 458000.000000 | iteration_458000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493538      | 6695.511637         | 6.695512             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2790.208752 | 912.013717 | 3681.610596 | 1380.821533 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1157.4608, current episode: 1
[2023-06-29 13:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1282.7466, current episode: 2
[2023-06-29 13:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1279.2413, current episode: 3
[2023-06-29 13:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1286.7551, current episode: 4
[2023-06-29 13:48:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1555.8678, current episode: 5
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1157.4608, current episode: 5
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2457.7202, current episode: 6
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1282.7466, current episode: 6
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1279.2413, current episode: 6
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1286.7551, current episode: 6
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2855.9631, current episode: 7
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1555.8678, current episode: 7
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1157.4608, current episode: 7
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3560.5417, current episode: 8
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3569.8408, current episode: 9
[2023-06-29 13:48:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3534.8477, current episode: 10
[2023-06-29 13:48:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 458500.000000 | iteration_458500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.530387      | 6534.294036         | 6.534294             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2254.098523 | 1000.087877 | 3569.840820 | 1157.460815 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:48:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1458.7198, current episode: 1
[2023-06-29 13:48:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1810.4242, current episode: 2
[2023-06-29 13:48:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2097.2219, current episode: 3
[2023-06-29 13:48:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2315.8572, current episode: 4
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2949.4585, current episode: 5
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1458.7198, current episode: 5
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1810.4242, current episode: 5
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.1760, current episode: 6
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3597.6882, current episode: 7
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3546.2722, current episode: 8
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3532.6777, current episode: 9
[2023-06-29 13:48:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3547.0293, current episode: 10
[2023-06-29 13:48:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 459000.000000 | iteration_459000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499271      | 6669.907716         | 6.669908             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2842.452515 | 799.414137 | 3597.688232 | 1458.719849 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1091.9600, current episode: 1
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1343.1576, current episode: 2
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1373.3212, current episode: 3
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1385.4106, current episode: 4
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1438.0682, current episode: 5
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1452.9449, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1091.9600, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1343.1576, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1373.3212, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1385.4106, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1438.0682, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1452.9449, current episode: 6
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3122.5977, current episode: 7
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1091.9600, current episode: 7
[2023-06-29 13:48:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3397.6016, current episode: 8
[2023-06-29 13:48:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3537.4241, current episode: 9
[2023-06-29 13:48:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3563.1118, current episode: 10
[2023-06-29 13:48:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 459500.000000 | iteration_459500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.556943      | 6422.842236         | 6.422842             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2170.559766 | 1018.384125 | 3563.111816 | 1091.959961 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:49:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1412.3079, current episode: 1
[2023-06-29 13:49:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1458.5403, current episode: 2
[2023-06-29 13:49:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1610.6912, current episode: 3
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1969.8004, current episode: 4
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2103.9741, current episode: 5
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2087.8904, current episode: 6
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2152.9392, current episode: 7
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1412.3079, current episode: 7
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1458.5403, current episode: 7
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1610.6912, current episode: 7
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3267.5774, current episode: 8
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3370.6516, current episode: 9
[2023-06-29 13:49:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3562.7544, current episode: 10
[2023-06-29 13:49:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 460000.000000 | iteration_460000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.576283      | 6344.040114         | 6.344040             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2299.712683 | 765.658048 | 3562.754395 | 1412.307861 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 1
[2023-06-29 13:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 2
[2023-06-29 13:49:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1960.3850, current episode: 3
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 3
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 3
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 3
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 3
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2142.9907, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 4
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2286.9131, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 5
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3217.3879, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.1047, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 22.6796, current episode: 6
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3541.2588, current episode: 7
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3545.8801, current episode: 8
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3552.6033, current episode: 9
[2023-06-29 13:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3659.6099, current episode: 10
[2023-06-29 13:49:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 460500.000000 | iteration_460500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.948935      | 5131.006329         | 5.131006             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2395.281317 | 1333.113334 | 3659.609863 | 22.679640  |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1155.0239, current episode: 1
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1486.4197, current episode: 2
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1538.0040, current episode: 3
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1588.8794, current episode: 4
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1563.8900, current episode: 5
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1578.0226, current episode: 6
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1609.8636, current episode: 7
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2105.8833, current episode: 8
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1155.0239, current episode: 8
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2444.2898, current episode: 9
[2023-06-29 13:49:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2836.3965, current episode: 10
[2023-06-29 13:49:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 461000.000000 | iteration_461000.pth.tar | 10.000000     | 7590.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 759.000000              | 1.138346      | 6667.570299         | 8.784678             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1790.667285 | 484.833466 | 2836.396484 | 1155.023926 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:49:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2736.0894, current episode: 1
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3526.2542, current episode: 2
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3536.4795, current episode: 3
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3526.3896, current episode: 4
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3594.4092, current episode: 5
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3501.3108, current episode: 6
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3531.1187, current episode: 7
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3486.3228, current episode: 8
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3530.6226, current episode: 9
[2023-06-29 13:49:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3520.7156, current episode: 10
[2023-06-29 13:49:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 461500.000000 | iteration_461500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.546060      | 6468.053013         | 6.468053             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3448.971216 | 239.096984 | 3594.409180 | 2736.089355 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2117.9551, current episode: 1
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2256.2695, current episode: 2
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2323.8110, current episode: 3
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2545.8564, current episode: 4
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2554.2971, current episode: 5
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2767.5437, current episode: 6
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2787.5496, current episode: 7
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2887.0476, current episode: 8
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3368.8174, current episode: 9
[2023-06-29 13:50:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3579.8213, current episode: 10
[2023-06-29 13:50:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 462000.000000 | iteration_462000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508632      | 6628.520845         | 6.628521             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2718.896875 | 445.783118 | 3579.821289 | 2117.955078 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2084.5632, current episode: 1
[2023-06-29 13:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2258.5874, current episode: 2
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2360.4946, current episode: 3
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2512.2000, current episode: 4
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2488.7554, current episode: 5
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3275.3699, current episode: 6
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3435.8872, current episode: 7
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3691.7456, current episode: 8
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3655.2029, current episode: 9
[2023-06-29 13:50:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3535.2104, current episode: 10
[2023-06-29 13:50:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 462500.000000 | iteration_462500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.532870      | 6523.708888         | 6.523709             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2929.801660 | 608.835394 | 3691.745605 | 2084.563232 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:50:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1950.8530, current episode: 1
[2023-06-29 13:50:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1959.8141, current episode: 2
[2023-06-29 13:50:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2045.4373, current episode: 3
[2023-06-29 13:50:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2569.7900, current episode: 4
[2023-06-29 13:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2870.3823, current episode: 5
[2023-06-29 13:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3512.5427, current episode: 6
[2023-06-29 13:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3628.2888, current episode: 7
[2023-06-29 13:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3520.7178, current episode: 8
[2023-06-29 13:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3521.7090, current episode: 9
[2023-06-29 13:50:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3612.5237, current episode: 10
[2023-06-29 13:50:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 463000.000000 | iteration_463000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509004      | 6626.887009         | 6.626887             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2919.205872 | 693.285654 | 3628.288818 | 1950.853027 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:50:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2220.7307, current episode: 1
[2023-06-29 13:50:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2745.8059, current episode: 2
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3624.0869, current episode: 3
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3517.6443, current episode: 4
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3482.5522, current episode: 5
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3469.7366, current episode: 6
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3481.6648, current episode: 7
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3469.9121, current episode: 8
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3487.0476, current episode: 9
[2023-06-29 13:50:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3505.8110, current episode: 10
[2023-06-29 13:50:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 463500.000000 | iteration_463500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.546377      | 6466.729576         | 6.466730             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3300.499219 | 427.282716 | 3624.086914 | 2220.730713 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3470.0916, current episode: 1
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3485.4033, current episode: 2
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3460.9126, current episode: 3
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3450.9395, current episode: 4
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3469.6536, current episode: 5
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3521.9722, current episode: 6
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3484.6472, current episode: 7
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3495.3547, current episode: 8
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3459.5730, current episode: 9
[2023-06-29 13:51:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3466.6062, current episode: 10
[2023-06-29 13:51:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 464000.000000 | iteration_464000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.512808      | 6610.223705         | 6.610224             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.515381 | 19.843196  | 3521.972168 | 3450.939453 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:51:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2166.4866, current episode: 1
[2023-06-29 13:51:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2481.7468, current episode: 2
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3641.2944, current episode: 3
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3511.5916, current episode: 4
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3483.9675, current episode: 5
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3622.5811, current episode: 6
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3563.4214, current episode: 7
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3478.5593, current episode: 8
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.3171, current episode: 9
[2023-06-29 13:51:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.5442, current episode: 10
[2023-06-29 13:51:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 464500.000000 | iteration_464500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488688      | 6717.323750         | 6.717324             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3292.151001 | 492.289896 | 3641.294434 | 2166.486572 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:51:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2193.8430, current episode: 1
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2665.1218, current episode: 2
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3160.4358, current episode: 3
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3539.3789, current episode: 4
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.4221, current episode: 5
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3503.5061, current episode: 6
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3520.0757, current episode: 7
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3487.2778, current episode: 8
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3479.4170, current episode: 9
[2023-06-29 13:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3476.8308, current episode: 10
[2023-06-29 13:51:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 465000.000000 | iteration_465000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.475107      | 6779.171228         | 6.779171             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3257.730908 | 440.131905 | 3551.422119 | 2193.843018 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2228.4424, current episode: 1
[2023-06-29 13:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2281.5227, current episode: 2
[2023-06-29 13:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2610.5344, current episode: 3
[2023-06-29 13:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2800.2566, current episode: 4
[2023-06-29 13:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2815.4407, current episode: 5
[2023-06-29 13:51:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2999.8870, current episode: 6
[2023-06-29 13:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3451.7749, current episode: 7
[2023-06-29 13:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3448.6687, current episode: 8
[2023-06-29 13:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3439.5278, current episode: 9
[2023-06-29 13:51:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3528.3574, current episode: 10
[2023-06-29 13:51:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 465500.000000 | iteration_465500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478108      | 6765.407592         | 6.765408             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2960.441260 | 468.962185 | 3528.357422 | 2228.442383 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1299.9041, current episode: 1
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1377.6198, current episode: 2
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1393.5740, current episode: 3
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1439.2505, current episode: 4
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1516.1642, current episode: 5
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1757.6139, current episode: 6
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1767.2388, current episode: 7
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1790.0548, current episode: 8
[2023-06-29 13:52:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1895.0225, current episode: 9
[2023-06-29 13:52:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2377.0974, current episode: 10
[2023-06-29 13:52:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 466000.000000 | iteration_466000.pth.tar | 10.000000     | 6440.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 644.000000              | 0.980358      | 6569.026195         | 10.200351            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1661.353979 | 309.386233 | 2377.097412 | 1299.904053 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1099.3740, current episode: 1
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1105.0442, current episode: 2
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1158.9963, current episode: 3
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1227.1193, current episode: 4
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1254.8035, current episode: 5
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1293.8575, current episode: 6
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1329.8004, current episode: 7
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1352.9956, current episode: 8
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1488.1487, current episode: 9
[2023-06-29 13:52:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1558.5129, current episode: 10
[2023-06-29 13:52:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 466500.000000 | iteration_466500.pth.tar | 10.000000     | 4210.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 421.000000              | 0.661053      | 6368.625467         | 15.127376            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1286.865247 | 144.821576 | 1558.512939 | 1099.374023 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1156.1752, current episode: 1
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1208.6642, current episode: 2
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1274.1790, current episode: 3
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1339.8396, current episode: 4
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1413.7159, current episode: 5
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1397.2737, current episode: 6
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1577.1428, current episode: 7
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1583.3967, current episode: 8
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1759.9645, current episode: 9
[2023-06-29 13:52:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1924.7042, current episode: 10
[2023-06-29 13:52:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 467000.000000 | iteration_467000.pth.tar | 10.000000     | 5140.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 514.000000              | 0.789331      | 6511.842619         | 12.668955            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1463.505579 | 233.512101 | 1924.704224 | 1156.175171 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1234.0909, current episode: 1
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1307.8300, current episode: 2
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1341.7826, current episode: 3
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1361.7809, current episode: 4
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1353.6282, current episode: 5
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1383.3807, current episode: 6
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1425.5127, current episode: 7
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1680.1687, current episode: 8
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1756.0635, current episode: 9
[2023-06-29 13:52:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2261.4844, current episode: 10
[2023-06-29 13:52:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 467500.000000 | iteration_467500.pth.tar | 10.000000     | 6020.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 602.000000              | 0.917496      | 6561.334091         | 10.899226            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1510.572253 | 294.807961 | 2261.484375 | 1234.090942 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:53:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1119.0717, current episode: 1
[2023-06-29 13:53:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1121.7351, current episode: 2
[2023-06-29 13:53:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1199.9386, current episode: 3
[2023-06-29 13:53:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1193.6639, current episode: 4
[2023-06-29 13:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1479.6681, current episode: 5
[2023-06-29 13:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1538.8237, current episode: 6
[2023-06-29 13:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1652.7283, current episode: 7
[2023-06-29 13:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1872.0336, current episode: 8
[2023-06-29 13:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1882.2108, current episode: 9
[2023-06-29 13:53:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1971.3744, current episode: 10
[2023-06-29 13:53:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 468000.000000 | iteration_468000.pth.tar | 10.000000     | 5320.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 532.000000              | 0.936528      | 5680.556546         | 10.677738            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1503.124817 | 316.844790 | 1971.374390 | 1119.071655 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1104.5135, current episode: 1
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1148.6637, current episode: 2
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1159.4980, current episode: 3
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1180.9706, current episode: 4
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1197.6793, current episode: 5
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1222.1705, current episode: 6
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1305.1674, current episode: 7
[2023-06-29 13:53:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1333.4443, current episode: 8
[2023-06-29 13:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1452.3180, current episode: 9
[2023-06-29 13:53:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1871.2823, current episode: 10
[2023-06-29 13:53:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 468500.000000 | iteration_468500.pth.tar | 10.000000     | 4960.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 496.000000              | 0.791691      | 6265.070273         | 12.631190            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1297.570776 | 214.989275 | 1871.282349 | 1104.513550 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1242.0598, current episode: 1
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1260.0468, current episode: 2
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1262.2902, current episode: 3
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1289.0573, current episode: 4
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1334.1824, current episode: 5
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1337.7571, current episode: 6
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1442.5441, current episode: 7
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1473.3187, current episode: 8
[2023-06-29 13:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1599.6367, current episode: 9
[2023-06-29 13:53:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2020.4557, current episode: 10
[2023-06-29 13:53:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 469000.000000 | iteration_469000.pth.tar | 10.000000     | 5430.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 543.000000              | 0.848727      | 6397.817963         | 11.782354            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1426.134863 | 225.651468 | 2020.455688 | 1242.059814 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1095.4524, current episode: 1
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1184.4490, current episode: 2
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1205.3676, current episode: 3
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1244.1586, current episode: 4
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1255.4160, current episode: 5
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1284.7969, current episode: 6
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1286.8076, current episode: 7
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1307.6486, current episode: 8
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1311.5255, current episode: 9
[2023-06-29 13:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1340.8497, current episode: 10
[2023-06-29 13:53:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 469500.000000 | iteration_469500.pth.tar | 10.000000     | 3590.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 359.000000              | 0.561424      | 6394.456060         | 17.811855            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1251.647180 | 69.381785  | 1340.849731 | 1095.452393 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1418.9733, current episode: 1
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1440.9785, current episode: 2
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1509.0977, current episode: 3
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1488.9717, current episode: 4
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1635.2545, current episode: 5
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1842.5599, current episode: 6
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1887.7991, current episode: 7
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2086.0068, current episode: 8
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2424.3979, current episode: 9
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1418.9733, current episode: 9
[2023-06-29 13:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1440.9785, current episode: 9
[2023-06-29 13:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1509.0977, current episode: 9
[2023-06-29 13:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1488.9717, current episode: 9
[2023-06-29 13:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1635.2545, current episode: 9
[2023-06-29 13:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1842.5599, current episode: 9
[2023-06-29 13:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3540.3757, current episode: 10
[2023-06-29 13:54:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 470000.000000 | iteration_470000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.542462      | 6483.142247         | 6.483142             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1927.441516 | 618.891645 | 3540.375732 | 1418.973267 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1356.4786, current episode: 1
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1418.6088, current episode: 2
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1420.5465, current episode: 3
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1438.5634, current episode: 4
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1469.6084, current episode: 5
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1495.3501, current episode: 6
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1769.9919, current episode: 7
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1780.9871, current episode: 8
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1996.9401, current episode: 9
[2023-06-29 13:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2054.8477, current episode: 10
[2023-06-29 13:54:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 470500.000000 | iteration_470500.pth.tar | 10.000000     | 5680.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 568.000000              | 0.865087      | 6565.811021         | 11.559526            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1620.192249 | 245.040500 | 2054.847656 | 1356.478638 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1228.0001, current episode: 1
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1263.8953, current episode: 2
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1241.7848, current episode: 3
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1267.0625, current episode: 4
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1293.4707, current episode: 5
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1320.1714, current episode: 6
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1321.3519, current episode: 7
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1301.3605, current episode: 8
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1326.6021, current episode: 9
[2023-06-29 13:54:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1334.8199, current episode: 10
[2023-06-29 13:54:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 471000.000000 | iteration_471000.pth.tar | 10.000000     | 3740.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 374.000000              | 0.574518      | 6509.805371         | 17.405897            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1289.851917 | 35.719684  | 1334.819946 | 1228.000122 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1366.6321, current episode: 1
[2023-06-29 13:54:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1492.9236, current episode: 2
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1366.6321, current episode: 2
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2610.1892, current episode: 3
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1492.9236, current episode: 3
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3353.6240, current episode: 4
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3383.0872, current episode: 5
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3388.3838, current episode: 6
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3383.6145, current episode: 7
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3377.2117, current episode: 8
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3359.8962, current episode: 9
[2023-06-29 13:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3393.8577, current episode: 10
[2023-06-29 13:54:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 471500.000000 | iteration_471500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.491951      | 6702.632772         | 6.702633             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2910.941992 | 775.148685 | 3393.857666 | 1366.632080 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1435.6339, current episode: 1
[2023-06-29 13:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1512.7192, current episode: 2
[2023-06-29 13:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1516.6129, current episode: 3
[2023-06-29 13:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1435.6339, current episode: 3
[2023-06-29 13:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1512.7192, current episode: 3
[2023-06-29 13:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1516.6129, current episode: 3
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3411.3333, current episode: 4
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3412.7244, current episode: 5
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3382.1836, current episode: 6
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3435.5803, current episode: 7
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3452.7522, current episode: 8
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3435.7903, current episode: 9
[2023-06-29 13:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3448.9893, current episode: 10
[2023-06-29 13:55:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 472000.000000 | iteration_472000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504475      | 6646.838123         | 6.646838             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2844.431934 | 888.227920 | 3452.752197 | 1435.633911 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3454.6050, current episode: 1
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3445.7595, current episode: 2
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3466.0708, current episode: 3
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3475.5510, current episode: 4
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3436.7029, current episode: 5
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3471.7205, current episode: 6
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3445.7034, current episode: 7
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3455.2480, current episode: 8
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3485.2024, current episode: 9
[2023-06-29 13:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3460.4827, current episode: 10
[2023-06-29 13:55:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 472500.000000 | iteration_472500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.537498      | 6504.074336         | 6.504074             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3459.704614 | 14.325527  | 3485.202393 | 3436.702881 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3473.4929, current episode: 1
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3468.3306, current episode: 2
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3440.4727, current episode: 3
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3455.1375, current episode: 4
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3468.1997, current episode: 5
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3476.9009, current episode: 6
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3478.3669, current episode: 7
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3463.3528, current episode: 8
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3489.8364, current episode: 9
[2023-06-29 13:55:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3470.5103, current episode: 10
[2023-06-29 13:55:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 473000.000000 | iteration_473000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.570427      | 6367.694893         | 6.367695             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3468.460059 | 12.817298  | 3489.836426 | 3440.472656 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3396.4409, current episode: 1
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3435.1157, current episode: 2
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3438.7678, current episode: 3
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3433.5278, current episode: 4
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3399.8142, current episode: 5
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3436.8357, current episode: 6
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3390.9680, current episode: 7
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3453.0286, current episode: 8
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3435.3728, current episode: 9
[2023-06-29 13:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3426.4026, current episode: 10
[2023-06-29 13:56:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 473500.000000 | iteration_473500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501016      | 6662.152039         | 6.662152             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3424.627417 | 20.016453  | 3453.028564 | 3390.968018 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1387.3917, current episode: 1
[2023-06-29 13:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1379.0909, current episode: 2
[2023-06-29 13:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1435.8551, current episode: 3
[2023-06-29 13:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1507.3733, current episode: 4
[2023-06-29 13:56:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1604.1885, current episode: 5
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2549.5813, current episode: 6
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1387.3917, current episode: 6
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1379.0909, current episode: 6
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1435.8551, current episode: 6
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1507.3733, current episode: 6
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1604.1885, current episode: 6
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3462.4485, current episode: 7
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3474.4880, current episode: 8
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3501.2927, current episode: 9
[2023-06-29 13:56:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3496.6750, current episode: 10
[2023-06-29 13:56:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 474000.000000 | iteration_474000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523461      | 6564.001054         | 6.564001             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2379.838513 | 956.267614 | 3501.292725 | 1379.090942 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1270.6807, current episode: 1
[2023-06-29 13:56:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1270.6807, current episode: 1
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3509.4729, current episode: 2
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3501.2307, current episode: 3
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3483.2083, current episode: 4
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3496.4438, current episode: 5
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3523.2073, current episode: 6
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3502.3386, current episode: 7
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3499.9851, current episode: 8
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3508.6086, current episode: 9
[2023-06-29 13:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3491.2612, current episode: 10
[2023-06-29 13:56:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 474500.000000 | iteration_474500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.470841      | 6798.829990         | 6.798830             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3278.643726 | 669.399662 | 3523.207275 | 1270.680664 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 995.1357, current episode: 1
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1030.5107, current episode: 2
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1048.5570, current episode: 3
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1052.7833, current episode: 4
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1095.5570, current episode: 5
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1104.2025, current episode: 6
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1180.4111, current episode: 7
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1214.2185, current episode: 8
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1222.2438, current episode: 9
[2023-06-29 13:56:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1277.1135, current episode: 10
[2023-06-29 13:56:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 475000.000000 | iteration_475000.pth.tar | 10.000000     | 3420.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 342.000000              | 0.531641      | 6432.910326         | 18.809679            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1122.073322 | 90.382920  | 1277.113525 | 995.135681 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 971.3137, current episode: 1
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 984.9570, current episode: 2
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.1566, current episode: 3
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 998.3406, current episode: 4
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1023.1255, current episode: 5
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1116.3584, current episode: 6
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1199.7197, current episode: 7
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1251.5725, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 971.3137, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 984.9570, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.1566, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 998.3406, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1023.1255, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1116.3584, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1199.7197, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1251.5725, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 971.3137, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 984.9570, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 991.1566, current episode: 8
[2023-06-29 13:57:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 998.3406, current episode: 8
[2023-06-29 13:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1023.1255, current episode: 8
[2023-06-29 13:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1116.3584, current episode: 8
[2023-06-29 13:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1199.7197, current episode: 8
[2023-06-29 13:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1251.5725, current episode: 8
[2023-06-29 13:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3547.4036, current episode: 9
[2023-06-29 13:57:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3515.0510, current episode: 10
[2023-06-29 13:57:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 475500.000000 | iteration_475500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541259      | 6488.203579         | 6.488204             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1559.899866 | 989.861046 | 3547.403564 | 971.313721 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1182.4408, current episode: 1
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1177.6829, current episode: 2
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1204.0304, current episode: 3
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1303.5616, current episode: 4
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1425.5719, current episode: 5
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1182.4408, current episode: 5
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1177.6829, current episode: 5
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1204.0304, current episode: 5
[2023-06-29 13:57:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1303.5616, current episode: 5
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1425.5719, current episode: 5
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3441.7844, current episode: 6
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1182.4408, current episode: 6
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1177.6829, current episode: 6
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1204.0304, current episode: 6
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3510.1074, current episode: 7
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3524.0264, current episode: 8
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3589.1448, current episode: 9
[2023-06-29 13:57:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3521.4128, current episode: 10
[2023-06-29 13:57:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 476000.000000 | iteration_476000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517292      | 6590.690296         | 6.590690             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2387.976343 | 1131.804533 | 3589.144775 | 1177.682861 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 13:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1669.3884, current episode: 1
[2023-06-29 13:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1805.2197, current episode: 2
[2023-06-29 13:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1669.3884, current episode: 2
[2023-06-29 13:57:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1805.2197, current episode: 2
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3523.7234, current episode: 3
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3526.1060, current episode: 4
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3516.6758, current episode: 5
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.2224, current episode: 6
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3522.1514, current episode: 7
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3513.6731, current episode: 8
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3513.7534, current episode: 9
[2023-06-29 13:57:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3507.0144, current episode: 10
[2023-06-29 13:57:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 476500.000000 | iteration_476500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528727      | 6541.391148         | 6.541391             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3160.992798 | 712.513007 | 3526.105957 | 1669.388428 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1458.5126, current episode: 1
[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1467.8741, current episode: 2
[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1619.5769, current episode: 3
[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1666.7858, current episode: 4
[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1671.3009, current episode: 5
[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1665.2610, current episode: 6
[2023-06-29 13:57:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1884.8201, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1458.5126, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1467.8741, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1619.5769, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1666.7858, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1671.3009, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1665.2610, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1884.8201, current episode: 7
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3516.4194, current episode: 8
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3504.7886, current episode: 9
[2023-06-29 13:57:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3515.4731, current episode: 10
[2023-06-29 13:57:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 477000.000000 | iteration_477000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.539940      | 6493.759229         | 6.493759             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2197.081250 | 868.196115 | 3516.419434 | 1458.512573 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1335.9463, current episode: 1
[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1416.2134, current episode: 2
[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1546.5227, current episode: 3
[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1830.2238, current episode: 4
[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1335.9463, current episode: 4
[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1416.2134, current episode: 4
[2023-06-29 13:58:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1546.5227, current episode: 4
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1830.2238, current episode: 4
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3446.4653, current episode: 5
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3465.5918, current episode: 6
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3442.0256, current episode: 7
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3486.2385, current episode: 8
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3493.9072, current episode: 9
[2023-06-29 13:58:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3494.2483, current episode: 10
[2023-06-29 13:58:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 477500.000000 | iteration_477500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.495579      | 6686.373730         | 6.686374             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2695.738293 | 957.539710 | 3494.248291 | 1335.946289 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3461.9690, current episode: 1
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3481.2136, current episode: 2
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3462.2812, current episode: 3
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3486.0642, current episode: 4
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3472.9675, current episode: 5
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3482.0344, current episode: 6
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3462.5808, current episode: 7
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3406.0032, current episode: 8
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3475.5022, current episode: 9
[2023-06-29 13:58:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3512.3340, current episode: 10
[2023-06-29 13:58:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 478000.000000 | iteration_478000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509186      | 6626.086738         | 6.626087             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3470.295020 | 25.756013  | 3512.333984 | 3406.003174 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3448.2681, current episode: 1
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3452.7397, current episode: 2
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3483.9333, current episode: 3
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3545.2742, current episode: 4
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3433.6692, current episode: 5
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3447.5747, current episode: 6
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3490.0950, current episode: 7
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3461.5178, current episode: 8
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3462.9355, current episode: 9
[2023-06-29 13:58:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3533.2424, current episode: 10
[2023-06-29 13:58:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 478500.000000 | iteration_478500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.521352      | 6573.100549         | 6.573101             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3475.925000 | 35.535284  | 3545.274170 | 3433.669189 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.0220, current episode: 1
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3527.6785, current episode: 2
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3487.3340, current episode: 3
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3470.6721, current episode: 4
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3502.4858, current episode: 5
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3532.3044, current episode: 6
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3495.4412, current episode: 7
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3506.1743, current episode: 8
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3457.3821, current episode: 9
[2023-06-29 13:58:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.9280, current episode: 10
[2023-06-29 13:58:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 479000.000000 | iteration_479000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.472602      | 6790.701977         | 6.790702             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3496.242236 | 21.717139  | 3532.304443 | 3457.382080 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2688.8855, current episode: 1
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3513.8286, current episode: 2
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3505.2969, current episode: 3
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3523.5571, current episode: 4
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.8511, current episode: 5
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3517.5129, current episode: 6
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3562.3887, current episode: 7
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3590.1033, current episode: 8
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3528.2529, current episode: 9
[2023-06-29 13:59:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.3416, current episode: 10
[2023-06-29 13:59:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 479500.000000 | iteration_479500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487257      | 6723.787672         | 6.723788             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3447.101855 | 253.905138 | 3590.103271 | 2688.885498 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:59:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1364.6539, current episode: 1
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1364.6539, current episode: 1
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3470.8113, current episode: 2
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3485.8472, current episode: 3
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3449.0889, current episode: 4
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3472.0457, current episode: 5
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3540.7373, current episode: 6
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3503.8606, current episode: 7
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3450.9868, current episode: 8
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3514.6523, current episode: 9
[2023-06-29 13:59:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3477.0195, current episode: 10
[2023-06-29 13:59:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 480000.000000 | iteration_480000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.473449      | 6786.797624         | 6.786798             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3272.970349 | 636.672868 | 3540.737305 | 1364.653931 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1221.3701, current episode: 1
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1309.4196, current episode: 2
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1327.7928, current episode: 3
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1520.3629, current episode: 4
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1661.9475, current episode: 5
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1851.2314, current episode: 6
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1221.3701, current episode: 6
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2524.7517, current episode: 7
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1309.4196, current episode: 7
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1327.7928, current episode: 7
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1520.3629, current episode: 7
[2023-06-29 13:59:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1661.9475, current episode: 7
[2023-06-29 13:59:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3570.7515, current episode: 8
[2023-06-29 13:59:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3591.0039, current episode: 9
[2023-06-29 13:59:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3598.3970, current episode: 10
[2023-06-29 13:59:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 480500.000000 | iteration_480500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506409      | 6638.302617         | 6.638303             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2217.702844 | 962.098600 | 3598.396973 | 1221.370117 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1014.5155, current episode: 1
[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1075.6396, current episode: 2
[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1238.9219, current episode: 3
[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1258.2281, current episode: 4
[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1346.4243, current episode: 5
[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1411.5426, current episode: 6
[2023-06-29 13:59:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1553.6489, current episode: 7
[2023-06-29 13:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1901.8579, current episode: 8
[2023-06-29 13:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2076.3691, current episode: 9
[2023-06-29 13:59:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2006.8969, current episode: 10
[2023-06-29 13:59:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 481000.000000 | iteration_481000.pth.tar | 10.000000     | 5510.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 551.000000              | 0.835691      | 6593.346271         | 11.966146            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1488.404492 | 364.138951 | 2076.369141 | 1014.515503 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1047.4989, current episode: 1
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1120.8749, current episode: 2
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1162.5950, current episode: 3
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1183.5641, current episode: 4
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1241.9142, current episode: 5
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1341.8910, current episode: 6
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1343.6111, current episode: 7
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1359.5801, current episode: 8
[2023-06-29 14:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1539.1095, current episode: 9
[2023-06-29 14:00:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1803.6572, current episode: 10
[2023-06-29 14:00:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 481500.000000 | iteration_481500.pth.tar | 10.000000     | 4800.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 480.000000              | 0.752590      | 6377.977086         | 13.287452            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1314.429590 | 211.570894 | 1803.657227 | 1047.498901 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1079.1656, current episode: 1
[2023-06-29 14:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1310.9210, current episode: 2
[2023-06-29 14:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1304.8656, current episode: 3
[2023-06-29 14:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1365.9008, current episode: 4
[2023-06-29 14:00:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1655.6989, current episode: 5
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1717.1547, current episode: 6
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1821.8361, current episode: 7
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1934.9001, current episode: 8
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1079.1656, current episode: 8
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2283.6357, current episode: 9
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1310.9210, current episode: 9
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1304.8656, current episode: 9
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1365.9008, current episode: 9
[2023-06-29 14:00:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2775.2996, current episode: 10
[2023-06-29 14:00:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 482000.000000 | iteration_482000.pth.tar | 10.000000     | 7480.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 748.000000              | 1.164573      | 6422.954361         | 8.586837             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1724.937805 | 486.572821 | 2775.299561 | 1079.165649 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 898.6295, current episode: 1
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 944.6062, current episode: 2
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.4170, current episode: 3
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1042.9213, current episode: 4
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1017.3779, current episode: 5
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1131.1378, current episode: 6
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1198.9755, current episode: 7
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1497.8953, current episode: 8
[2023-06-29 14:00:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1516.2406, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 898.6295, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 944.6062, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.4170, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1042.9213, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1017.3779, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1131.1378, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1198.9755, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 898.6295, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1497.8953, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 944.6062, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1516.2406, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 956.4170, current episode: 9
[2023-06-29 14:00:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3052.5288, current episode: 10
[2023-06-29 14:00:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 482500.000000 | iteration_482500.pth.tar | 10.000000     | 8140.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 814.000000              | 1.266948      | 6424.886322         | 7.892981             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1325.672980 | 611.622938 | 3052.528809 | 898.629517 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 694.2074, current episode: 1
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 756.2191, current episode: 2
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 758.1931, current episode: 3
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 917.8984, current episode: 4
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 923.5819, current episode: 5
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 981.6303, current episode: 6
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1006.4039, current episode: 7
[2023-06-29 14:00:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1217.9253, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 694.2074, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 756.2191, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 758.1931, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 917.8984, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 923.5819, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 981.6303, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1006.4039, current episode: 8
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2034.3950, current episode: 9
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 694.2074, current episode: 9
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1217.9253, current episode: 9
[2023-06-29 14:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2507.3635, current episode: 10
[2023-06-29 14:00:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 483000.000000 | iteration_483000.pth.tar | 10.000000     | 6670.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 667.000000              | 1.051474      | 6343.475926         | 9.510459             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1179.781793 | 573.651641 | 2507.363525 | 694.207397 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 733.2608, current episode: 1
[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 866.2775, current episode: 2
[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 872.3970, current episode: 3
[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 888.9156, current episode: 4
[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1012.0396, current episode: 5
[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1096.9122, current episode: 6
[2023-06-29 14:01:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1202.7062, current episode: 7
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 733.2608, current episode: 7
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1642.7948, current episode: 8
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1705.5177, current episode: 9
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 866.2775, current episode: 9
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 872.3970, current episode: 9
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 888.9156, current episode: 9
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1012.0396, current episode: 9
[2023-06-29 14:01:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2173.5139, current episode: 10
[2023-06-29 14:01:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 483500.000000 | iteration_483500.pth.tar | 10.000000     | 5860.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 586.000000              | 0.925902      | 6328.962442         | 10.800277            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1219.433527 | 444.392289 | 2173.513916 | 733.260803 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 929.9232, current episode: 1
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 956.2623, current episode: 2
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 968.2375, current episode: 3
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 980.4581, current episode: 4
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1140.7369, current episode: 5
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1256.7406, current episode: 6
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1461.5015, current episode: 7
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1750.1985, current episode: 8
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 929.9232, current episode: 8
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 956.2623, current episode: 8
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 968.2375, current episode: 8
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 980.4581, current episode: 8
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2195.4146, current episode: 9
[2023-06-29 14:01:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1140.7369, current episode: 9
[2023-06-29 14:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1256.7406, current episode: 9
[2023-06-29 14:01:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2667.4270, current episode: 10
[2023-06-29 14:01:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 484000.000000 | iteration_484000.pth.tar | 10.000000     | 7170.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 717.000000              | 1.097860      | 6530.885997         | 9.108628             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1430.690015 | 567.812324 | 2667.427002 | 929.923157 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 896.3862, current episode: 1
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 989.9332, current episode: 2
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 982.7154, current episode: 3
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1012.0474, current episode: 4
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 998.5139, current episode: 5
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1016.3480, current episode: 6
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1035.0536, current episode: 7
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1042.2765, current episode: 8
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1157.5417, current episode: 9
[2023-06-29 14:01:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1293.2349, current episode: 10
[2023-06-29 14:01:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 484500.000000 | iteration_484500.pth.tar | 10.000000     | 3430.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 343.000000              | 0.530226      | 6468.936520         | 18.859873            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1042.405084 | 103.629508 | 1293.234863 | 896.386230 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:01:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1431.0653, current episode: 1
[2023-06-29 14:01:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1988.1033, current episode: 2
[2023-06-29 14:01:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2033.7334, current episode: 3
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2060.2097, current episode: 4
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2258.4600, current episode: 5
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2265.7529, current episode: 6
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2349.7388, current episode: 7
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2431.8330, current episode: 8
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2699.7351, current episode: 9
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1431.0653, current episode: 9
[2023-06-29 14:01:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3564.8625, current episode: 10
[2023-06-29 14:01:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 485000.000000 | iteration_485000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509236      | 6625.870222         | 6.625870             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2308.349402 | 525.589666 | 3564.862549 | 1431.065308 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1192.2330, current episode: 1
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1229.9974, current episode: 2
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1932.6643, current episode: 3
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2025.1895, current episode: 4
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2209.9841, current episode: 5
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1192.2330, current episode: 5
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1229.9974, current episode: 5
[2023-06-29 14:02:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3096.9919, current episode: 6
[2023-06-29 14:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3536.6316, current episode: 7
[2023-06-29 14:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1192.2330, current episode: 7
[2023-06-29 14:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1229.9974, current episode: 7
[2023-06-29 14:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3585.6279, current episode: 8
[2023-06-29 14:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3534.9514, current episode: 9
[2023-06-29 14:02:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3588.1570, current episode: 10
[2023-06-29 14:02:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 485500.000000 | iteration_485500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508318      | 6629.902219         | 6.629902             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2593.242822 | 934.475535 | 3588.156982 | 1192.233032 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:02:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1360.2318, current episode: 1
[2023-06-29 14:02:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2219.8438, current episode: 2
[2023-06-29 14:02:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2335.1763, current episode: 3
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2569.9927, current episode: 4
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2769.6587, current episode: 5
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1360.2318, current episode: 5
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2808.2307, current episode: 6
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2906.5522, current episode: 7
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3252.4082, current episode: 8
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3289.2720, current episode: 9
[2023-06-29 14:02:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3452.1245, current episode: 10
[2023-06-29 14:02:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 486000.000000 | iteration_486000.pth.tar | 10.000000     | 9210.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 921.000000              | 1.397801      | 6588.920621         | 7.154094             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2696.349084 | 587.597771 | 3452.124512 | 1360.231812 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1250.5789, current episode: 1
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1406.1605, current episode: 2
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1699.5708, current episode: 3
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1916.4020, current episode: 4
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1250.5789, current episode: 4
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1406.1605, current episode: 4
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2865.2278, current episode: 5
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3210.6130, current episode: 6
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1699.5708, current episode: 6
[2023-06-29 14:02:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3514.0803, current episode: 7
[2023-06-29 14:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3591.5237, current episode: 8
[2023-06-29 14:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3653.7581, current episode: 9
[2023-06-29 14:02:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3658.0862, current episode: 10
[2023-06-29 14:02:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 486500.000000 | iteration_486500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494641      | 6690.569335         | 6.690569             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2676.600122 | 946.435515 | 3658.086182 | 1250.578857 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:02:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1518.6835, current episode: 1
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1518.6835, current episode: 1
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3539.9756, current episode: 2
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3541.4448, current episode: 3
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3543.3459, current episode: 4
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3552.8276, current episode: 5
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3540.4932, current episode: 6
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3557.3857, current episode: 7
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.0310, current episode: 8
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3539.9526, current episode: 9
[2023-06-29 14:02:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3548.2637, current episode: 10
[2023-06-29 14:02:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 487000.000000 | iteration_487000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514551      | 6602.616238         | 6.602616             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3340.940369 | 607.469338 | 3557.385742 | 1518.683472 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1305.3619, current episode: 1
[2023-06-29 14:03:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1305.3619, current episode: 1
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.4749, current episode: 2
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3516.8220, current episode: 3
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3561.2463, current episode: 4
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3584.8887, current episode: 5
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3554.4507, current episode: 6
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3533.5706, current episode: 7
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3539.5479, current episode: 8
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3563.1250, current episode: 9
[2023-06-29 14:03:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3557.5315, current episode: 10
[2023-06-29 14:03:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 487500.000000 | iteration_487500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493334      | 6696.423462         | 6.696423             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3328.801941 | 674.733120 | 3584.888672 | 1305.361938 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2236.4690, current episode: 1
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2356.0581, current episode: 2
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2302.0032, current episode: 3
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3194.4905, current episode: 4
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3571.3279, current episode: 5
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3544.6484, current episode: 6
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3684.1895, current episode: 7
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3545.0286, current episode: 8
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3552.9634, current episode: 9
[2023-06-29 14:03:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3575.1497, current episode: 10
[2023-06-29 14:03:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 488000.000000 | iteration_488000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500010      | 6666.623264         | 6.666623             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3156.232812 | 574.749893 | 3684.189453 | 2236.468994 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1222.7352, current episode: 1
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1273.6190, current episode: 2
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1645.2866, current episode: 3
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2226.2910, current episode: 4
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1222.7352, current episode: 4
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2530.0557, current episode: 5
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1273.6190, current episode: 5
[2023-06-29 14:03:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2890.0608, current episode: 6
[2023-06-29 14:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3136.6255, current episode: 7
[2023-06-29 14:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3167.0024, current episode: 8
[2023-06-29 14:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1645.2866, current episode: 8
[2023-06-29 14:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1222.7352, current episode: 8
[2023-06-29 14:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3573.3479, current episode: 9
[2023-06-29 14:03:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3604.6699, current episode: 10
[2023-06-29 14:03:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 488500.000000 | iteration_488500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510125      | 6621.967845         | 6.621968             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2526.969409 | 854.938598 | 3604.669922 | 1222.735229 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 353.1645, current episode: 1
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 355.4189, current episode: 2
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 462.1555, current episode: 3
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 505.4460, current episode: 4
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 525.0590, current episode: 5
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 649.0605, current episode: 6
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 676.9437, current episode: 7
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 715.1080, current episode: 8
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 353.1645, current episode: 8
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 355.4189, current episode: 8
[2023-06-29 14:03:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1030.1021, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 462.1555, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 505.4460, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 525.0590, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 353.1645, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 649.0605, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 355.4189, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 676.9437, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 715.1080, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 462.1555, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 505.4460, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 525.0590, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 353.1645, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 355.4189, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1030.1021, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 649.0605, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 676.9437, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 715.1080, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 462.1555, current episode: 9
[2023-06-29 14:03:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2580.0989, current episode: 10
[2023-06-29 14:03:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 489000.000000 | iteration_489000.pth.tar | 10.000000     | 6900.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 690.000000              | 1.131802      | 6096.470064         | 8.835464             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 785.255698  | 627.571918 | 2580.098877 | 353.164490 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 1
[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 2
[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 3
[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 475.4391, current episode: 4
[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 514.6124, current episode: 5
[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 642.3992, current episode: 6
[2023-06-29 14:04:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 794.9531, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 475.4391, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 514.6124, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 642.3992, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 794.9531, current episode: 7
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1841.6499, current episode: 8
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 475.4391, current episode: 8
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 8
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 8
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 514.6124, current episode: 8
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 8
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2009.1226, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 642.3992, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 475.4391, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 514.6124, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 794.9531, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 642.3992, current episode: 9
[2023-06-29 14:04:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 475.4391, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 514.6124, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 303.5369, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 307.9310, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 316.2967, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 794.9531, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1841.6499, current episode: 9
[2023-06-29 14:04:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3498.6638, current episode: 10
[2023-06-29 14:04:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 489500.000000 | iteration_489500.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.614174      | 6194.499200         | 6.195119             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1070.460474 | 1001.625445 | 3498.663818 | 303.536865 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:04:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 848.9481, current episode: 1
[2023-06-29 14:04:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1207.5482, current episode: 2
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1370.8059, current episode: 3
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1604.4725, current episode: 4
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1762.6371, current episode: 5
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 848.9481, current episode: 5
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2166.1765, current episode: 6
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1207.5482, current episode: 6
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 848.9481, current episode: 6
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2756.3167, current episode: 7
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1370.8059, current episode: 7
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3230.5420, current episode: 8
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1604.4725, current episode: 8
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3471.9773, current episode: 9
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1762.6371, current episode: 9
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 848.9481, current episode: 9
[2023-06-29 14:04:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3487.9949, current episode: 10
[2023-06-29 14:04:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 490000.000000 | iteration_490000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535733      | 6511.549455         | 6.511549             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2190.741919 | 932.333245 | 3487.994873 | 848.948120 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:04:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1518.1844, current episode: 1
[2023-06-29 14:04:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1833.5052, current episode: 2
[2023-06-29 14:04:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1953.9563, current episode: 3
[2023-06-29 14:04:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2142.7041, current episode: 4
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1518.1844, current episode: 4
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3049.3137, current episode: 5
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3376.6768, current episode: 6
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3503.4558, current episode: 7
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.0107, current episode: 8
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3693.1826, current episode: 9
[2023-06-29 14:04:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3553.1399, current episode: 10
[2023-06-29 14:04:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 490500.000000 | iteration_490500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487460      | 6722.868932         | 6.722869             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2815.612964 | 807.028594 | 3693.182617 | 1518.184448 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1671.0592, current episode: 1
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1741.7715, current episode: 2
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2245.8301, current episode: 3
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2336.4761, current episode: 4
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2479.2915, current episode: 5
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3071.1472, current episode: 6
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1671.0592, current episode: 6
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3448.5305, current episode: 7
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1741.7715, current episode: 7
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3516.7834, current episode: 8
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3554.6846, current episode: 9
[2023-06-29 14:04:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3529.7869, current episode: 10
[2023-06-29 14:04:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 491000.000000 | iteration_491000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506358      | 6638.526941         | 6.638527             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2759.536096 | 715.040078 | 3554.684570 | 1671.059204 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1371.9259, current episode: 1
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1378.8544, current episode: 2
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1400.1660, current episode: 3
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1448.7753, current episode: 4
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1561.1040, current episode: 5
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1892.6508, current episode: 6
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2046.8474, current episode: 7
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2294.2224, current episode: 8
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1371.9259, current episode: 8
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1378.8544, current episode: 8
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1400.1660, current episode: 8
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1448.7753, current episode: 8
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1561.1040, current episode: 8
[2023-06-29 14:05:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3240.1089, current episode: 9
[2023-06-29 14:05:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3519.2043, current episode: 10
[2023-06-29 14:05:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 491500.000000 | iteration_491500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.518643      | 6584.827358         | 6.584827             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2015.385937 | 747.017280 | 3519.204346 | 1371.925903 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3553.0605, current episode: 1
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3516.5234, current episode: 2
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3521.9270, current episode: 3
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3534.1704, current episode: 4
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3504.7581, current episode: 5
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3556.6533, current episode: 6
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3559.7783, current episode: 7
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3521.4648, current episode: 8
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3560.5906, current episode: 9
[2023-06-29 14:05:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3470.9688, current episode: 10
[2023-06-29 14:05:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 492000.000000 | iteration_492000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.487809      | 6721.292484         | 6.721292             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3529.989526 | 27.429173  | 3560.590576 | 3470.968750 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3534.8123, current episode: 1
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3561.9399, current episode: 2
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3549.9541, current episode: 3
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3530.7595, current episode: 4
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3545.9131, current episode: 5
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3525.7087, current episode: 6
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3549.5212, current episode: 7
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3556.4519, current episode: 8
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.1814, current episode: 9
[2023-06-29 14:05:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3567.3359, current episode: 10
[2023-06-29 14:05:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 492500.000000 | iteration_492500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.527033      | 6548.646604         | 6.548647             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3545.757812 | 13.161370  | 3567.335938 | 3525.708740 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3537.2817, current episode: 1
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3552.5916, current episode: 2
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3541.1611, current episode: 3
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3547.0022, current episode: 4
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.9993, current episode: 5
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3533.8020, current episode: 6
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3567.3835, current episode: 7
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3564.4275, current episode: 8
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3544.0801, current episode: 9
[2023-06-29 14:05:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3548.0481, current episode: 10
[2023-06-29 14:05:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 493000.000000 | iteration_493000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.496405      | 6682.681064         | 6.682681             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3548.777710 | 10.277210  | 3567.383545 | 3533.802002 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:06:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2719.5762, current episode: 1
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3572.1912, current episode: 2
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3547.0637, current episode: 3
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3546.6658, current episode: 4
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3578.9165, current episode: 5
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3544.0386, current episode: 6
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3550.0789, current episode: 7
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3559.4539, current episode: 8
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3556.0000, current episode: 9
[2023-06-29 14:06:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3536.6682, current episode: 10
[2023-06-29 14:06:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 493500.000000 | iteration_493500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.485186      | 6733.165443         | 6.733165             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3471.065283 | 250.795504 | 3578.916504 | 2719.576172 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3495.9243, current episode: 1
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3562.7449, current episode: 2
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3543.1218, current episode: 3
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3552.1091, current episode: 4
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3540.1382, current episode: 5
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3509.0095, current episode: 6
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3557.6370, current episode: 7
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3506.6204, current episode: 8
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3528.3486, current episode: 9
[2023-06-29 14:06:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.2700, current episode: 10
[2023-06-29 14:06:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 494000.000000 | iteration_494000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.489313      | 6714.504781         | 6.714505             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3532.492383 | 21.654808  | 3562.744873 | 3495.924316 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:06:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1634.7937, current episode: 1
[2023-06-29 14:06:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1768.0062, current episode: 2
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2944.2993, current episode: 3
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1634.7937, current episode: 3
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1768.0062, current episode: 3
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3577.4390, current episode: 4
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3547.2656, current episode: 5
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3759.6528, current episode: 6
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3695.7781, current episode: 7
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3561.3958, current episode: 8
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3599.2261, current episode: 9
[2023-06-29 14:06:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3625.1750, current episode: 10
[2023-06-29 14:06:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 494500.000000 | iteration_494500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.501607      | 6659.531841         | 6.659532             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3171.303162 | 764.882189 | 3759.652832 | 1634.793701 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1560.8143, current episode: 1
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1827.5248, current episode: 2
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1885.0292, current episode: 3
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1954.2551, current episode: 4
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2580.7573, current episode: 5
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2905.4390, current episode: 6
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2950.0784, current episode: 7
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1560.8143, current episode: 7
[2023-06-29 14:06:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3443.7500, current episode: 8
[2023-06-29 14:07:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1827.5248, current episode: 8
[2023-06-29 14:07:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3534.6052, current episode: 9
[2023-06-29 14:07:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3601.7153, current episode: 10
[2023-06-29 14:07:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 495000.000000 | iteration_495000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.499035      | 6670.957078         | 6.670957             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2624.396863 | 735.111908 | 3601.715332 | 1560.814331 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:07:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2927.7583, current episode: 1
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3551.6499, current episode: 2
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3534.1018, current episode: 3
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3553.0757, current episode: 4
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3576.3813, current episode: 5
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3513.2847, current episode: 6
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3529.1458, current episode: 7
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3518.3105, current episode: 8
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3506.6357, current episode: 9
[2023-06-29 14:07:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3559.1118, current episode: 10
[2023-06-29 14:07:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 495500.000000 | iteration_495500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.464919      | 6826.316818         | 6.826317             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3476.945557 | 184.262515 | 3576.381348 | 2927.758301 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 1
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2253.3499, current episode: 2
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 2
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 2
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2531.1387, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 3
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3501.8499, current episode: 4
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 66.3535, current episode: 4
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3503.2947, current episode: 5
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3481.0991, current episode: 6
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3512.7402, current episode: 7
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3519.3579, current episode: 8
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3480.8591, current episode: 9
[2023-06-29 14:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.8843, current episode: 10
[2023-06-29 14:07:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 496000.000000 | iteration_496000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.584249      | 6312.138484         | 6.312138             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2937.392722 | 1054.482485 | 3523.884277 | 66.353493  |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:07:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2021.8921, current episode: 1
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3130.1243, current episode: 2
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3492.0010, current episode: 3
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3489.8213, current episode: 4
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3504.6248, current episode: 5
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3487.3042, current episode: 6
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3508.9087, current episode: 7
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3508.9292, current episode: 8
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3513.3943, current episode: 9
[2023-06-29 14:07:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3479.8613, current episode: 10
[2023-06-29 14:07:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 496500.000000 | iteration_496500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.521250      | 6573.543605         | 6.573544             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3313.686108 | 444.474591 | 3513.394287 | 2021.892090 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2824.5400, current episode: 1
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3046.7783, current episode: 2
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3295.2473, current episode: 3
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3420.0776, current episode: 4
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3611.3181, current episode: 5
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3555.6694, current episode: 6
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3499.8245, current episode: 7
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.1802, current episode: 8
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3519.5781, current episode: 9
[2023-06-29 14:08:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3648.0063, current episode: 10
[2023-06-29 14:08:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 497000.000000 | iteration_497000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519303      | 6581.964053         | 6.581964             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3395.321997 | 252.825639 | 3648.006348 | 2824.540039 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:08:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1246.9840, current episode: 1
[2023-06-29 14:08:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1743.0836, current episode: 2
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2026.2040, current episode: 3
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2013.6003, current episode: 4
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2088.2336, current episode: 5
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1246.9840, current episode: 5
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2877.9250, current episode: 6
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1743.0836, current episode: 6
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3535.8870, current episode: 7
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3529.0513, current episode: 8
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3521.7803, current episode: 9
[2023-06-29 14:08:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3500.6494, current episode: 10
[2023-06-29 14:08:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 497500.000000 | iteration_497500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540356      | 6492.003867         | 6.492004             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2608.339856 | 835.247562 | 3535.886963 | 1246.984009 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1440.1787, current episode: 1
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1695.8344, current episode: 2
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1847.0154, current episode: 3
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1874.2489, current episode: 4
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1870.3967, current episode: 5
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1933.2874, current episode: 6
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2778.6106, current episode: 7
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1440.1787, current episode: 7
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2990.3523, current episode: 8
[2023-06-29 14:08:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1695.8344, current episode: 8
[2023-06-29 14:08:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1847.0154, current episode: 8
[2023-06-29 14:08:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1874.2489, current episode: 8
[2023-06-29 14:08:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1870.3967, current episode: 8
[2023-06-29 14:08:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3561.3608, current episode: 9
[2023-06-29 14:08:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.4902, current episode: 10
[2023-06-29 14:08:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 498000.000000 | iteration_498000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.513119      | 6608.864381         | 6.608864             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2351.877539 | 747.416218 | 3561.360840 | 1440.178711 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1593.6096, current episode: 1
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1623.6196, current episode: 2
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2267.4695, current episode: 3
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2734.8250, current episode: 4
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1593.6096, current episode: 4
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1623.6196, current episode: 4
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3413.0425, current episode: 5
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3533.6492, current episode: 6
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3588.6931, current episode: 7
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3510.4177, current episode: 8
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3553.8533, current episode: 9
[2023-06-29 14:08:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3539.5205, current episode: 10
[2023-06-29 14:08:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 498500.000000 | iteration_498500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.529637      | 6537.498403         | 6.537498             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2935.869995 | 780.926130 | 3588.693115 | 1593.609619 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:09:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3181.3811, current episode: 1
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3510.5020, current episode: 2
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3531.1917, current episode: 3
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3510.9797, current episode: 4
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3504.9224, current episode: 5
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3532.2429, current episode: 6
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3508.9937, current episode: 7
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3511.0957, current episode: 8
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3509.5823, current episode: 9
[2023-06-29 14:09:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3530.9314, current episode: 10
[2023-06-29 14:09:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 499000.000000 | iteration_499000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.471604      | 6795.304637         | 6.795305             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3483.182275 | 101.098870 | 3532.242920 | 3181.381104 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:09:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1493.4865, current episode: 1
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2575.9890, current episode: 2
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2860.1213, current episode: 3
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1493.4865, current episode: 3
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3483.5039, current episode: 4
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3643.0303, current episode: 5
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3539.7705, current episode: 6
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3516.4888, current episode: 7
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3535.5166, current episode: 8
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3538.9287, current episode: 9
[2023-06-29 14:09:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3532.5339, current episode: 10
[2023-06-29 14:09:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 499500.000000 | iteration_499500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.494905      | 6689.388704         | 6.689389             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3171.936951 | 651.114634 | 3643.030273 | 1493.486450 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2120.2529, current episode: 1
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3555.3650, current episode: 2
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3499.3425, current episode: 3
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3492.1421, current episode: 4
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3555.6624, current episode: 5
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3507.3220, current episode: 6
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3505.5959, current episode: 7
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3517.4900, current episode: 8
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3529.3970, current episode: 9
[2023-06-29 14:09:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3499.9375, current episode: 10
[2023-06-29 14:09:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 500000.000000 | iteration_500000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506008      | 6640.070181         | 6.640070             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3378.250732 | 419.875447 | 3555.662354 | 2120.252930 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1343.9248, current episode: 1
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1387.6467, current episode: 2
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1365.1465, current episode: 3
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1416.7312, current episode: 4
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1544.1609, current episode: 5
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1533.1818, current episode: 6
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1559.0179, current episode: 7
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1590.5938, current episode: 8
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1696.3004, current episode: 9
[2023-06-29 14:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1824.0232, current episode: 10
[2023-06-29 14:09:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 500500.000000 | iteration_500500.pth.tar | 10.000000     | 4940.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 494.000000              | 0.788047      | 6268.664092         | 12.689603            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1526.072717 | 146.140502 | 1824.023193 | 1343.924805 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1224.9005, current episode: 1
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1333.3588, current episode: 2
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1359.4238, current episode: 3
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1463.5587, current episode: 4
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1510.1940, current episode: 5
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1526.7340, current episode: 6
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1533.8378, current episode: 7
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1931.7468, current episode: 8
[2023-06-29 14:10:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2095.6379, current episode: 9
[2023-06-29 14:10:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2219.7058, current episode: 10
[2023-06-29 14:10:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 501000.000000 | iteration_501000.pth.tar | 10.000000     | 6210.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 621.000000              | 0.945126      | 6570.552661         | 10.580600            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1619.909814 | 322.782430 | 2219.705811 | 1224.900513 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1982.6807, current episode: 1
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2186.2139, current episode: 2
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2220.2498, current episode: 3
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3532.2913, current episode: 4
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3512.8289, current episode: 5
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3514.8975, current episode: 6
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3485.9651, current episode: 7
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3663.1042, current episode: 8
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3502.8696, current episode: 9
[2023-06-29 14:10:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3534.8936, current episode: 10
[2023-06-29 14:10:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 501500.000000 | iteration_501500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514866      | 6601.241955         | 6.601242             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3113.599438 | 648.263351 | 3663.104248 | 1982.680664 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:10:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1494.7869, current episode: 1
[2023-06-29 14:10:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1688.6425, current episode: 2
[2023-06-29 14:10:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1682.7534, current episode: 3
[2023-06-29 14:10:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1774.8988, current episode: 4
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1967.9221, current episode: 5
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2327.8206, current episode: 6
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2509.8538, current episode: 7
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1494.7869, current episode: 7
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1688.6425, current episode: 7
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1682.7534, current episode: 7
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1774.8988, current episode: 7
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3513.6277, current episode: 8
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3518.9539, current episode: 9
[2023-06-29 14:10:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3559.7087, current episode: 10
[2023-06-29 14:10:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 502000.000000 | iteration_502000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.493233      | 6696.880016         | 6.696880             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2403.896826 | 791.934367 | 3559.708740 | 1494.786865 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1481.9515, current episode: 1
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1504.1958, current episode: 2
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1522.1948, current episode: 3
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1599.8876, current episode: 4
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1667.5060, current episode: 5
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1807.7661, current episode: 6
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1942.9326, current episode: 7
[2023-06-29 14:10:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2404.3853, current episode: 8
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1481.9515, current episode: 8
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1504.1958, current episode: 8
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1522.1948, current episode: 8
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3178.9365, current episode: 9
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1599.8876, current episode: 9
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1667.5060, current episode: 9
[2023-06-29 14:10:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3398.8701, current episode: 10
[2023-06-29 14:10:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 502500.000000 | iteration_502500.pth.tar | 10.000000     | 8970.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 897.000000              | 1.372770      | 6534.234191         | 7.284542             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2050.862634 | 673.626964 | 3398.870117 | 1481.951538 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1372.6118, current episode: 1
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1508.1501, current episode: 2
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1548.8181, current episode: 3
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1574.4330, current episode: 4
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1604.9606, current episode: 5
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1601.3794, current episode: 6
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1695.8354, current episode: 7
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1974.0659, current episode: 8
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2035.2172, current episode: 9
[2023-06-29 14:11:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2576.9441, current episode: 10
[2023-06-29 14:11:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 503000.000000 | iteration_503000.pth.tar | 10.000000     | 6980.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 698.000000              | 1.232066      | 5665.280734         | 8.116448             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1749.241565 | 336.697874 | 2576.944092 | 1372.611816 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1295.3107, current episode: 1
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1388.3068, current episode: 2
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1500.8787, current episode: 3
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1641.6035, current episode: 4
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1666.3986, current episode: 5
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1995.2858, current episode: 6
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2072.2273, current episode: 7
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2270.6863, current episode: 8
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2404.9263, current episode: 9
[2023-06-29 14:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1295.3107, current episode: 9
[2023-06-29 14:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1388.3068, current episode: 9
[2023-06-29 14:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1500.8787, current episode: 9
[2023-06-29 14:11:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3144.3481, current episode: 10
[2023-06-29 14:11:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 503500.000000 | iteration_503500.pth.tar | 10.000000     | 8390.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 839.000000              | 1.276654      | 6571.867756         | 7.832977             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1937.997192 | 536.020549 | 3144.348145 | 1295.310669 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:11:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1376.2810, current episode: 1
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1781.5249, current episode: 2
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1891.8722, current episode: 3
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2221.1252, current episode: 4
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2365.8687, current episode: 5
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2657.3425, current episode: 6
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1376.2810, current episode: 6
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1781.5249, current episode: 6
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3533.2791, current episode: 7
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3575.6824, current episode: 8
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3568.4927, current episode: 9
[2023-06-29 14:11:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3556.4888, current episode: 10
[2023-06-29 14:11:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 504000.000000 | iteration_504000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502151      | 6657.118729         | 6.657119             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2652.795740 | 807.367772 | 3575.682373 | 1376.281006 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:11:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1467.5742, current episode: 1
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1467.5742, current episode: 1
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2772.7695, current episode: 2
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3065.5022, current episode: 3
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3539.3936, current episode: 4
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3552.0129, current episode: 5
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3612.1355, current episode: 6
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3601.1326, current episode: 7
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3570.8479, current episode: 8
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3577.0923, current episode: 9
[2023-06-29 14:11:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3557.2317, current episode: 10
[2023-06-29 14:11:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 504500.000000 | iteration_504500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502988      | 6653.413984         | 6.653414             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3231.569238 | 645.689847 | 3612.135498 | 1467.574219 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:12:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 746.6573, current episode: 1
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1028.4736, current episode: 2
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 746.6573, current episode: 2
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1861.8326, current episode: 3
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1028.4736, current episode: 3
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 746.6573, current episode: 3
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1028.4736, current episode: 3
[2023-06-29 14:12:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 746.6573, current episode: 3
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3560.1831, current episode: 4
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3534.6416, current episode: 5
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3522.1919, current episode: 6
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3539.6594, current episode: 7
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3535.6238, current episode: 8
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3543.0310, current episode: 9
[2023-06-29 14:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3558.7444, current episode: 10
[2023-06-29 14:12:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 505000.000000 | iteration_505000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.531979      | 6527.505123         | 6.527505             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2843.103882 | 1098.693067 | 3560.183105 | 746.657349 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1254.7921, current episode: 1
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1276.3391, current episode: 2
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1327.9495, current episode: 3
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1575.5256, current episode: 4
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1254.7921, current episode: 4
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1276.3391, current episode: 4
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1327.9495, current episode: 4
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1575.5256, current episode: 4
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3182.2834, current episode: 5
[2023-06-29 14:12:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3485.7864, current episode: 6
[2023-06-29 14:12:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3528.2029, current episode: 7
[2023-06-29 14:12:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3565.8484, current episode: 8
[2023-06-29 14:12:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3612.4304, current episode: 9
[2023-06-29 14:12:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3568.9375, current episode: 10
[2023-06-29 14:12:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 505500.000000 | iteration_505500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.591393      | 6283.802188         | 6.283802             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2637.809534 | 1053.421926 | 3612.430420 | 1254.792114 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:12:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2673.7634, current episode: 1
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3616.1455, current episode: 2
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3584.5112, current episode: 3
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3555.2905, current episode: 4
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3592.7820, current episode: 5
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3580.2227, current episode: 6
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3544.6475, current episode: 7
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3562.4612, current episode: 8
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3570.7405, current episode: 9
[2023-06-29 14:12:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3610.7004, current episode: 10
[2023-06-29 14:12:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 506000.000000 | iteration_506000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.587294      | 6300.030816         | 6.300031             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3489.126489 | 272.648359 | 3616.145508 | 2673.763428 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:12:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2027.7148, current episode: 1
[2023-06-29 14:12:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3228.2520, current episode: 2
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3515.4973, current episode: 3
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3534.3196, current episode: 4
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3510.0989, current episode: 5
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3551.9346, current episode: 6
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3536.4246, current episode: 7
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3506.1658, current episode: 8
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3527.0371, current episode: 9
[2023-06-29 14:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3550.9504, current episode: 10
[2023-06-29 14:12:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 506500.000000 | iteration_506500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.660612      | 6021.876053         | 6.021876             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3348.839502 | 449.653703 | 3551.934570 | 2027.714844 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:13:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1966.2148, current episode: 1
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2289.2722, current episode: 2
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3479.2378, current episode: 3
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3537.9944, current episode: 4
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3513.0698, current episode: 5
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3529.6301, current episode: 6
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3542.3447, current episode: 7
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3525.4622, current episode: 8
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.0532, current episode: 9
[2023-06-29 14:13:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3518.3074, current episode: 10
[2023-06-29 14:13:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 507000.000000 | iteration_507000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.474165      | 6783.501550         | 6.783502             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3241.758667 | 561.910178 | 3542.344727 | 1966.214844 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.3091, current episode: 1
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1913.8412, current episode: 2
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1961.1163, current episode: 3
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2235.3635, current episode: 4
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2523.4314, current episode: 5
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2888.1655, current episode: 6
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1515.3091, current episode: 6
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3158.2524, current episode: 7
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3167.0002, current episode: 8
[2023-06-29 14:13:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3439.1472, current episode: 9
[2023-06-29 14:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3542.6819, current episode: 10
[2023-06-29 14:13:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 507500.000000 | iteration_507500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.571479      | 6363.433128         | 6.363433             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2634.430884 | 670.186535 | 3542.681885 | 1515.309082 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3510.4548, current episode: 1
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3438.0659, current episode: 2
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3508.8467, current episode: 3
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3497.3301, current episode: 4
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3554.3269, current episode: 5
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3491.1912, current episode: 6
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3424.9739, current episode: 7
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3431.8674, current episode: 8
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3497.8740, current episode: 9
[2023-06-29 14:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3515.5852, current episode: 10
[2023-06-29 14:13:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 508000.000000 | iteration_508000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.526799      | 6549.649775         | 6.549650             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3487.051611 | 39.876448  | 3554.326904 | 3424.973877 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:14:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2059.7747, current episode: 1
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3513.4231, current episode: 2
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3416.5300, current episode: 3
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3519.6182, current episode: 4
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3470.9260, current episode: 5
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3507.4558, current episode: 6
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3509.1677, current episode: 7
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3425.8979, current episode: 8
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.0017, current episode: 9
[2023-06-29 14:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.4712, current episode: 10
[2023-06-29 14:14:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 508500.000000 | iteration_508500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.504362      | 6647.337024         | 6.647337             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3343.526636 | 429.391763 | 3519.618164 | 2059.774658 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1729.1466, current episode: 1
[2023-06-29 14:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1857.1007, current episode: 2
[2023-06-29 14:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1918.8160, current episode: 3
[2023-06-29 14:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1918.9155, current episode: 4
[2023-06-29 14:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2214.1082, current episode: 5
[2023-06-29 14:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2252.7974, current episode: 6
[2023-06-29 14:14:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3355.1614, current episode: 7
[2023-06-29 14:14:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1729.1466, current episode: 7
[2023-06-29 14:14:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1857.1007, current episode: 7
[2023-06-29 14:14:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3530.1248, current episode: 8
[2023-06-29 14:14:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3561.5574, current episode: 9
[2023-06-29 14:14:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3551.0000, current episode: 10
[2023-06-29 14:14:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 509000.000000 | iteration_509000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.592372      | 6279.938853         | 6.279939             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2588.872791 | 759.657227 | 3561.557373 | 1729.146606 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1457.5150, current episode: 1
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1605.5427, current episode: 2
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1949.3164, current episode: 3
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2025.7102, current episode: 4
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2225.4463, current episode: 5
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2537.7039, current episode: 6
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1457.5150, current episode: 6
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1605.5427, current episode: 6
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3503.4124, current episode: 7
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3502.3328, current episode: 8
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3532.3499, current episode: 9
[2023-06-29 14:14:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3692.2146, current episode: 10
[2023-06-29 14:14:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 509500.000000 | iteration_509500.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.559847      | 6410.242890         | 6.410884             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2603.154407 | 829.702006 | 3692.214600 | 1457.515015 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1299.3591, current episode: 1
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1315.6128, current episode: 2
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1464.6678, current episode: 3
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1553.9362, current episode: 4
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1597.0817, current episode: 5
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1624.4634, current episode: 6
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1879.8484, current episode: 7
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2139.5835, current episode: 8
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2474.7314, current episode: 9
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1299.3591, current episode: 9
[2023-06-29 14:14:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1315.6128, current episode: 9
[2023-06-29 14:14:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2859.8801, current episode: 10
[2023-06-29 14:14:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 510000.000000 | iteration_510000.pth.tar | 10.000000     | 7780.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 778.000000              | 1.258602      | 6181.463802         | 7.945326             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1820.916443 | 492.562932 | 2859.880127 | 1299.359131 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1255.1277, current episode: 1
[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1459.9636, current episode: 2
[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1627.2152, current episode: 3
[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1602.6671, current episode: 4
[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1666.9248, current episode: 5
[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2103.9446, current episode: 6
[2023-06-29 14:15:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2204.5510, current episode: 7
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2238.6155, current episode: 8
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1255.1277, current episode: 8
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1459.9636, current episode: 8
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1627.2152, current episode: 8
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1602.6671, current episode: 8
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1666.9248, current episode: 8
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3417.0203, current episode: 9
[2023-06-29 14:15:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3628.7493, current episode: 10
[2023-06-29 14:15:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 510500.000000 | iteration_510500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.629274      | 6137.703790         | 6.137704             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2120.477905 | 766.776327 | 3628.749268 | 1255.127686 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1340.7284, current episode: 1
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1388.6656, current episode: 2
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1501.4038, current episode: 3
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1878.4248, current episode: 4
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2109.0205, current episode: 5
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2115.7834, current episode: 6
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2155.7874, current episode: 7
[2023-06-29 14:15:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2200.4353, current episode: 8
[2023-06-29 14:15:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1340.7284, current episode: 8
[2023-06-29 14:15:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1388.6656, current episode: 8
[2023-06-29 14:15:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1501.4038, current episode: 8
[2023-06-29 14:15:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3128.1372, current episode: 9
[2023-06-29 14:15:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3565.5818, current episode: 10
[2023-06-29 14:15:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 511000.000000 | iteration_511000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.591100      | 6284.958740         | 6.284959             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2138.396826 | 685.104794 | 3565.581787 | 1340.728394 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:15:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1512.2590, current episode: 1
[2023-06-29 14:15:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1607.6151, current episode: 2
[2023-06-29 14:15:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1833.0679, current episode: 3
[2023-06-29 14:15:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1839.3135, current episode: 4
[2023-06-29 14:15:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1852.1058, current episode: 5
[2023-06-29 14:15:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1926.7950, current episode: 6
[2023-06-29 14:15:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1937.8628, current episode: 7
[2023-06-29 14:15:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2025.6451, current episode: 8
[2023-06-29 14:15:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2512.7998, current episode: 9
[2023-06-29 14:15:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2779.8752, current episode: 10
[2023-06-29 14:15:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 511500.000000 | iteration_511500.pth.tar | 10.000000     | 7530.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 753.000000              | 1.299026      | 5796.649083         | 7.698073             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1982.733936 | 366.808106 | 2779.875244 | 1512.259033 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:15:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1617.3073, current episode: 1
[2023-06-29 14:15:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1633.1423, current episode: 2
[2023-06-29 14:15:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1648.4537, current episode: 3
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1901.1199, current episode: 4
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2247.1660, current episode: 5
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2621.2781, current episode: 6
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2657.6848, current episode: 7
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1617.3073, current episode: 7
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1633.1423, current episode: 7
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1648.4537, current episode: 7
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3386.8826, current episode: 8
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3589.8682, current episode: 9
[2023-06-29 14:15:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3513.4070, current episode: 10
[2023-06-29 14:15:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 512000.000000 | iteration_512000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.572370      | 6359.824294         | 6.359824             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2481.630981 | 756.033588 | 3589.868164 | 1617.307251 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1425.0541, current episode: 1
[2023-06-29 14:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1586.4844, current episode: 2
[2023-06-29 14:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1601.3137, current episode: 3
[2023-06-29 14:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1710.1927, current episode: 4
[2023-06-29 14:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1767.9198, current episode: 5
[2023-06-29 14:16:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1933.8289, current episode: 6
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1425.0541, current episode: 6
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3001.6396, current episode: 7
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1586.4844, current episode: 7
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1601.3137, current episode: 7
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3301.5837, current episode: 8
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3396.4414, current episode: 9
[2023-06-29 14:16:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3415.2280, current episode: 10
[2023-06-29 14:16:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 512500.000000 | iteration_512500.pth.tar | 10.000000     | 9220.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 922.000000              | 1.515866      | 6082.331949         | 6.596889             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2313.968640 | 804.194935 | 3415.228027 | 1425.054077 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1199.3036, current episode: 1
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1347.1731, current episode: 2
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1519.6265, current episode: 3
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1854.6711, current episode: 4
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1846.4233, current episode: 5
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1872.1598, current episode: 6
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2333.9368, current episode: 7
[2023-06-29 14:16:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1199.3036, current episode: 7
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1347.1731, current episode: 7
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1519.6265, current episode: 7
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3274.2878, current episode: 8
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1199.3036, current episode: 8
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1854.6711, current episode: 8
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1846.4233, current episode: 8
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3534.4756, current episode: 9
[2023-06-29 14:16:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3528.5640, current episode: 10
[2023-06-29 14:16:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 513000.000000 | iteration_513000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.566175      | 6384.984313         | 6.384984             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2231.062158 | 851.566498 | 3534.475586 | 1199.303589 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1337.6412, current episode: 1
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1437.3221, current episode: 2
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1643.5150, current episode: 3
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1648.9457, current episode: 4
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1685.5033, current episode: 5
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1693.5951, current episode: 6
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1862.5244, current episode: 7
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2188.0430, current episode: 8
[2023-06-29 14:16:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2538.1929, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1337.6412, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1437.3221, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1643.5150, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1648.9457, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1685.5033, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1693.5951, current episode: 9
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3601.0596, current episode: 10
[2023-06-29 14:16:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1862.5244, current episode: 10
[2023-06-29 14:16:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 513500.000000 | iteration_513500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.611185      | 6206.611208         | 6.206611             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1963.634229 | 639.727805 | 3601.059570 | 1337.641235 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1282.8060, current episode: 1
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1323.9380, current episode: 2
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1364.4238, current episode: 3
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1763.7814, current episode: 4
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2038.5444, current episode: 5
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2290.2283, current episode: 6
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2254.1023, current episode: 7
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2262.8088, current episode: 8
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1282.8060, current episode: 8
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1323.9380, current episode: 8
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1364.4238, current episode: 8
[2023-06-29 14:17:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2788.8354, current episode: 9
[2023-06-29 14:17:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1763.7814, current episode: 9
[2023-06-29 14:17:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3591.7188, current episode: 10
[2023-06-29 14:17:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 514000.000000 | iteration_514000.pth.tar | 10.000000     | 9710.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 971.000000              | 1.547184      | 6275.917227         | 6.463355             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2096.118726 | 686.584283 | 3591.718750 | 1282.806030 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:17:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1585.0547, current episode: 1
[2023-06-29 14:17:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1550.4406, current episode: 2
[2023-06-29 14:17:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1643.5048, current episode: 3
[2023-06-29 14:17:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2172.6409, current episode: 4
[2023-06-29 14:17:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2288.5786, current episode: 5
[2023-06-29 14:17:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2723.0144, current episode: 6
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1585.0547, current episode: 6
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1550.4406, current episode: 6
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3141.5042, current episode: 7
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1643.5048, current episode: 7
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3315.1775, current episode: 8
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3258.0342, current episode: 9
[2023-06-29 14:17:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3703.8384, current episode: 10
[2023-06-29 14:17:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 514500.000000 | iteration_514500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.529206      | 6539.342142         | 6.539342             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2538.178809 | 758.899134 | 3703.838379 | 1550.440552 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1218.7235, current episode: 1
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1264.5232, current episode: 2
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1326.4207, current episode: 3
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1656.7515, current episode: 4
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2056.1238, current episode: 5
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1218.7235, current episode: 5
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1264.5232, current episode: 5
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2562.8210, current episode: 6
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1326.4207, current episode: 6
[2023-06-29 14:17:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1656.7515, current episode: 6
[2023-06-29 14:17:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3439.4094, current episode: 7
[2023-06-29 14:17:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1218.7235, current episode: 7
[2023-06-29 14:17:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1264.5232, current episode: 7
[2023-06-29 14:17:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3518.7805, current episode: 8
[2023-06-29 14:17:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3529.0054, current episode: 9
[2023-06-29 14:17:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3536.5125, current episode: 10
[2023-06-29 14:17:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 515000.000000 | iteration_515000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.622111      | 6164.806376         | 6.164806             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2410.907141 | 971.166314 | 3536.512451 | 1218.723511 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:17:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 778.3983, current episode: 1
[2023-06-29 14:17:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 831.9183, current episode: 2
[2023-06-29 14:17:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 983.6241, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 778.3983, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 831.9183, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 983.6241, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 778.3983, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 831.9183, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 983.6241, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 778.3983, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 831.9183, current episode: 3
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3488.1169, current episode: 4
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3422.8816, current episode: 5
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3479.8303, current episode: 6
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3486.7937, current episode: 7
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3434.5413, current episode: 8
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3441.1912, current episode: 9
[2023-06-29 14:17:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3467.6677, current episode: 10
[2023-06-29 14:17:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 515500.000000 | iteration_515500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.567625      | 6379.076629         | 6.379077             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2681.496338 | 1190.541873 | 3488.116943 | 778.398315 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3473.8418, current episode: 1
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3423.9141, current episode: 2
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3455.4128, current episode: 3
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3462.7253, current episode: 4
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3496.0159, current episode: 5
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3408.4563, current episode: 6
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3427.0876, current episode: 7
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3369.3335, current episode: 8
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3458.9790, current episode: 9
[2023-06-29 14:18:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3472.4441, current episode: 10
[2023-06-29 14:18:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 516000.000000 | iteration_516000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.513168      | 6608.652721         | 6.608653             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3444.821045 | 35.541081  | 3496.015869 | 3369.333496 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 613.4135, current episode: 1
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 631.7084, current episode: 2
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 671.8161, current episode: 3
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 680.1680, current episode: 4
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 701.3329, current episode: 5
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 858.6129, current episode: 6
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 883.4050, current episode: 7
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 890.9308, current episode: 8
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.7952, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 613.4135, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 631.7084, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 671.8161, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 680.1680, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 701.3329, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 858.6129, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 883.4050, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 890.9308, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.7952, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 613.4135, current episode: 9
[2023-06-29 14:18:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 631.7084, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 671.8161, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 680.1680, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 701.3329, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 858.6129, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 613.4135, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 883.4050, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 631.7084, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 890.9308, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.7952, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 671.8161, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 680.1680, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 701.3329, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 613.4135, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 631.7084, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 858.6129, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 671.8161, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 883.4050, current episode: 9
[2023-06-29 14:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3447.4707, current episode: 10
[2023-06-29 14:18:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 516500.000000 | iteration_516500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.636631      | 6110.111033         | 6.110111             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1028.565344 | 813.658902 | 3447.470703 | 613.413452 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1027.7938, current episode: 1
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1036.1984, current episode: 2
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1438.7166, current episode: 3
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2023.7231, current episode: 4
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1027.7938, current episode: 4
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1036.1984, current episode: 4
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2644.9797, current episode: 5
[2023-06-29 14:18:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1438.7166, current episode: 5
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1027.7938, current episode: 5
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1036.1984, current episode: 5
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3456.3896, current episode: 6
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3559.7568, current episode: 7
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3520.3464, current episode: 8
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3477.1941, current episode: 9
[2023-06-29 14:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3476.1638, current episode: 10
[2023-06-29 14:18:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 517000.000000 | iteration_517000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536112      | 6509.940692         | 6.509941             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2566.126245 | 1030.884932 | 3559.756836 | 1027.793823 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:18:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1030.8000, current episode: 1
[2023-06-29 14:18:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1049.5469, current episode: 2
[2023-06-29 14:18:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1353.5236, current episode: 3
[2023-06-29 14:18:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1653.7322, current episode: 4
[2023-06-29 14:18:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1030.8000, current episode: 4
[2023-06-29 14:18:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1049.5469, current episode: 4
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1353.5236, current episode: 4
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1030.8000, current episode: 4
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1049.5469, current episode: 4
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1653.7322, current episode: 4
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3446.7244, current episode: 5
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3602.8655, current episode: 6
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3515.9377, current episode: 7
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3506.8069, current episode: 8
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3516.5786, current episode: 9
[2023-06-29 14:18:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3465.8481, current episode: 10
[2023-06-29 14:18:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 517500.000000 | iteration_517500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541760      | 6486.091720         | 6.486092             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2614.236389 | 1108.473017 | 3602.865479 | 1030.800049 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:19:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1104.0574, current episode: 1
[2023-06-29 14:19:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1516.4531, current episode: 2
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1104.0574, current episode: 2
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2862.7117, current episode: 3
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1516.4531, current episode: 3
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1104.0574, current episode: 3
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3478.5615, current episode: 4
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3486.8997, current episode: 5
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3481.0442, current episode: 6
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3481.4526, current episode: 7
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3470.3372, current episode: 8
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3530.9053, current episode: 9
[2023-06-29 14:19:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3510.2107, current episode: 10
[2023-06-29 14:19:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 518000.000000 | iteration_518000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.592001      | 6281.404145         | 6.281404             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2992.263330 | 866.397384 | 3530.905273 | 1104.057373 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 755.2489, current episode: 1
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 797.8304, current episode: 2
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 828.2618, current episode: 3
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1581.7778, current episode: 4
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 755.2489, current episode: 4
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1674.2045, current episode: 5
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 797.8304, current episode: 5
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 828.2618, current episode: 5
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1661.9178, current episode: 6
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 755.2489, current episode: 6
[2023-06-29 14:19:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 797.8304, current episode: 6
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 828.2618, current episode: 6
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2643.8337, current episode: 7
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1581.7778, current episode: 7
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3082.0835, current episode: 8
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 755.2489, current episode: 8
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1674.2045, current episode: 8
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 797.8304, current episode: 8
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 828.2618, current episode: 8
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1661.9178, current episode: 8
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3516.3176, current episode: 9
[2023-06-29 14:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3520.3618, current episode: 10
[2023-06-29 14:19:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 518500.000000 | iteration_518500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541494      | 6487.212976         | 6.487213             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2006.183789 | 1046.838239 | 3520.361816 | 755.248901 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:19:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1177.6329, current episode: 1
[2023-06-29 14:19:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1243.5134, current episode: 2
[2023-06-29 14:19:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1266.7050, current episode: 3
[2023-06-29 14:19:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1312.2993, current episode: 4
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1177.6329, current episode: 4
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1243.5134, current episode: 4
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1266.7050, current episode: 4
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1312.2993, current episode: 4
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3457.9312, current episode: 5
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3483.8071, current episode: 6
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1177.6329, current episode: 6
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3582.3225, current episode: 7
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3526.5427, current episode: 8
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3562.0674, current episode: 9
[2023-06-29 14:19:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3521.6716, current episode: 10
[2023-06-29 14:19:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 519000.000000 | iteration_519000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 2.055740      | 4864.429560         | 4.864430             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2613.449316 | 1114.130865 | 3582.322510 | 1177.632935 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:19:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 808.6467, current episode: 1
[2023-06-29 14:19:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 954.3972, current episode: 2
[2023-06-29 14:19:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 808.6467, current episode: 2
[2023-06-29 14:19:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 954.3972, current episode: 2
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 808.6467, current episode: 2
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 954.3972, current episode: 2
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2914.1609, current episode: 3
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3299.1541, current episode: 4
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 808.6467, current episode: 4
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3514.6885, current episode: 5
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3515.0967, current episode: 6
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3505.6584, current episode: 7
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3496.3423, current episode: 8
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3506.1748, current episode: 9
[2023-06-29 14:19:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3513.7930, current episode: 10
[2023-06-29 14:19:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 519500.000000 | iteration_519500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.588458      | 6295.413992         | 6.295414             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2902.811255 | 1026.713007 | 3515.096680 | 808.646729 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3463.8455, current episode: 1
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3438.7109, current episode: 2
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3500.9502, current episode: 3
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3454.5500, current episode: 4
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3452.8408, current episode: 5
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3459.9634, current episode: 6
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3609.5420, current episode: 7
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3467.2825, current episode: 8
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3390.2019, current episode: 9
[2023-06-29 14:20:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3482.0588, current episode: 10
[2023-06-29 14:20:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 520000.000000 | iteration_520000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524483      | 6559.601773         | 6.559602             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3471.994604 | 53.442858  | 3609.541992 | 3390.201904 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3473.8792, current episode: 1
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3475.5776, current episode: 2
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3467.4204, current episode: 3
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.4824, current episode: 4
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3494.4795, current episode: 5
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3495.0845, current episode: 6
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3414.8926, current episode: 7
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3450.8904, current episode: 8
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3458.5413, current episode: 9
[2023-06-29 14:20:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3481.7739, current episode: 10
[2023-06-29 14:20:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 520500.000000 | iteration_520500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.514518      | 6602.758860         | 6.602759             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3469.302173 | 22.490517  | 3495.084473 | 3414.892578 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:20:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2565.8738, current episode: 1
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2782.1748, current episode: 2
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3496.8545, current episode: 3
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3456.9128, current episode: 4
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3489.1511, current episode: 5
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3509.0498, current episode: 6
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3480.4592, current episode: 7
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3478.5295, current episode: 8
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3512.6533, current episode: 9
[2023-06-29 14:20:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3492.4812, current episode: 10
[2023-06-29 14:20:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 521000.000000 | iteration_521000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.480018      | 6756.674835         | 6.756675             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3326.414014 | 330.101396 | 3512.653320 | 2565.873779 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1650.7593, current episode: 1
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1733.1613, current episode: 2
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1880.4866, current episode: 3
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2202.2058, current episode: 4
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2429.7998, current episode: 5
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2418.0356, current episode: 6
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2635.3596, current episode: 7
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3112.8088, current episode: 8
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1650.7593, current episode: 8
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1733.1613, current episode: 8
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1880.4866, current episode: 8
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3503.5051, current episode: 9
[2023-06-29 14:20:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3654.7183, current episode: 10
[2023-06-29 14:20:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 521500.000000 | iteration_521500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.488887      | 6716.427149         | 6.716427             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2522.084021 | 672.514135 | 3654.718262 | 1650.759277 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1973.2520, current episode: 1
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2177.1714, current episode: 2
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2147.0967, current episode: 3
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2905.7605, current episode: 4
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3230.0007, current episode: 5
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3633.7935, current episode: 6
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3509.4463, current episode: 7
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3522.4482, current episode: 8
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3489.1770, current episode: 9
[2023-06-29 14:21:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3555.4644, current episode: 10
[2023-06-29 14:21:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 522000.000000 | iteration_522000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.477953      | 6766.113894         | 6.766114             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3014.361060 | 632.490173 | 3633.793457 | 1973.251953 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1499.5898, current episode: 1
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1631.1460, current episode: 2
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1650.0682, current episode: 3
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1677.8282, current episode: 4
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2042.4435, current episode: 5
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2262.5002, current episode: 6
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2287.5247, current episode: 7
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2289.3970, current episode: 8
[2023-06-29 14:21:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2356.9883, current episode: 9
[2023-06-29 14:21:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2946.4746, current episode: 10
[2023-06-29 14:21:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 522500.000000 | iteration_522500.pth.tar | 10.000000     | 7920.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 792.000000              | 1.191055      | 6649.567362         | 8.395918             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2064.396057 | 427.974957 | 2946.474609 | 1499.589844 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1407.2621, current episode: 1
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1834.4735, current episode: 2
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1886.3187, current episode: 3
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2009.6262, current episode: 4
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2084.5811, current episode: 5
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2159.4514, current episode: 6
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2248.0830, current episode: 7
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2669.8452, current episode: 8
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2654.8535, current episode: 9
[2023-06-29 14:21:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2762.1494, current episode: 10
[2023-06-29 14:21:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 523000.000000 | iteration_523000.pth.tar | 10.000000     | 7540.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 754.000000              | 1.167837      | 6456.381621         | 8.562840             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2171.664417 | 406.151202 | 2762.149414 | 1407.262085 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:21:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1814.3589, current episode: 1
[2023-06-29 14:21:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2016.4192, current episode: 2
[2023-06-29 14:21:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2226.3206, current episode: 3
[2023-06-29 14:21:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2325.0901, current episode: 4
[2023-06-29 14:21:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2298.1689, current episode: 5
[2023-06-29 14:22:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2804.6179, current episode: 6
[2023-06-29 14:22:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2945.4922, current episode: 7
[2023-06-29 14:22:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3134.8760, current episode: 8
[2023-06-29 14:22:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3446.3894, current episode: 9
[2023-06-29 14:22:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3537.9209, current episode: 10
[2023-06-29 14:22:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 523500.000000 | iteration_523500.pth.tar | 10.000000     | 9630.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 963.000000              | 1.490419      | 6461.268937         | 6.709521             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2654.965405 | 572.476779 | 3537.920898 | 1814.358887 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:22:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1996.3257, current episode: 1
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3550.6426, current episode: 2
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3482.4087, current episode: 3
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3479.1980, current episode: 4
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3571.7300, current episode: 5
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3569.4812, current episode: 6
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3469.1133, current episode: 7
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3596.6992, current episode: 8
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3421.0007, current episode: 9
[2023-06-29 14:22:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3442.5222, current episode: 10
[2023-06-29 14:22:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 524000.000000 | iteration_524000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507149      | 6635.042224         | 6.635042             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3357.912158 | 457.414023 | 3596.699219 | 1996.325684 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:22:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 981.9977, current episode: 1
[2023-06-29 14:22:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1090.3601, current episode: 2
[2023-06-29 14:22:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1107.5858, current episode: 3
[2023-06-29 14:22:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1282.5974, current episode: 4
[2023-06-29 14:22:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1286.4697, current episode: 5
[2023-06-29 14:22:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1288.8955, current episode: 6
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1530.4297, current episode: 7
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 981.9977, current episode: 7
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1090.3601, current episode: 7
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1107.5858, current episode: 7
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2305.6912, current episode: 8
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1282.5974, current episode: 8
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1286.4697, current episode: 8
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1288.8955, current episode: 8
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2663.1907, current episode: 9
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 981.9977, current episode: 9
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1530.4297, current episode: 9
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1090.3601, current episode: 9
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1107.5858, current episode: 9
[2023-06-29 14:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3605.9763, current episode: 10
[2023-06-29 14:22:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 524500.000000 | iteration_524500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.618033      | 6180.342422         | 6.180342             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1714.319415 | 818.927905 | 3605.976318 | 981.997742 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2345.7686, current episode: 1
[2023-06-29 14:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2861.6819, current episode: 2
[2023-06-29 14:22:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3405.6658, current episode: 3
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3651.3584, current episode: 4
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3530.3743, current episode: 5
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.6902, current episode: 6
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3548.1318, current episode: 7
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3484.2356, current episode: 8
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3509.5999, current episode: 9
[2023-06-29 14:22:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3527.6760, current episode: 10
[2023-06-29 14:22:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 525000.000000 | iteration_525000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.580913      | 6325.459891         | 6.325460             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3334.518237 | 387.606140 | 3651.358398 | 2345.768555 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1342.9381, current episode: 1
[2023-06-29 14:23:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1694.8182, current episode: 2
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2299.9568, current episode: 3
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1342.9381, current episode: 3
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1694.8182, current episode: 3
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3441.5811, current episode: 4
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3486.1965, current episode: 5
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3460.8752, current episode: 6
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3467.4980, current episode: 7
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3488.6316, current episode: 8
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3440.8818, current episode: 9
[2023-06-29 14:23:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3490.1318, current episode: 10
[2023-06-29 14:23:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 525500.000000 | iteration_525500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508474      | 6629.213874         | 6.629214             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2961.350928 | 803.752741 | 3490.131836 | 1342.938110 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1029.7318, current episode: 1
[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1292.7395, current episode: 2
[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1361.4241, current episode: 3
[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1029.7318, current episode: 3
[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1292.7395, current episode: 3
[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1361.4241, current episode: 3
[2023-06-29 14:23:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2918.4680, current episode: 4
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1029.7318, current episode: 4
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3302.1870, current episode: 5
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3504.1223, current episode: 6
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3569.4009, current episode: 7
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3626.3450, current episode: 8
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3563.3489, current episode: 9
[2023-06-29 14:23:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3537.5049, current episode: 10
[2023-06-29 14:23:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 526000.000000 | iteration_526000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.875947      | 5330.641984         | 5.330642             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2770.527234 | 1031.016552 | 3626.344971 | 1029.731812 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:23:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1321.0231, current episode: 1
[2023-06-29 14:23:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1352.1522, current episode: 2
[2023-06-29 14:23:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1399.2281, current episode: 3
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1321.0231, current episode: 3
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1352.1522, current episode: 3
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2704.0540, current episode: 4
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1399.2281, current episode: 4
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3343.5857, current episode: 5
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3634.2739, current episode: 6
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3615.8203, current episode: 7
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3553.8826, current episode: 8
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3601.1729, current episode: 9
[2023-06-29 14:23:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3525.6321, current episode: 10
[2023-06-29 14:23:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 526500.000000 | iteration_526500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515248      | 6599.579535         | 6.599580             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2805.082483 | 982.271093 | 3634.273926 | 1321.023071 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1219.6467, current episode: 1
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1260.5613, current episode: 2
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1286.1594, current episode: 3
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1351.7648, current episode: 4
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1362.3159, current episode: 5
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1367.6509, current episode: 6
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1219.6467, current episode: 6
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1260.5613, current episode: 6
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1286.1594, current episode: 6
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1351.7648, current episode: 6
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1362.3159, current episode: 6
[2023-06-29 14:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1367.6509, current episode: 6
[2023-06-29 14:23:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1219.6467, current episode: 6
[2023-06-29 14:23:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3551.0129, current episode: 7
[2023-06-29 14:23:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3545.1931, current episode: 8
[2023-06-29 14:23:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3570.3320, current episode: 9
[2023-06-29 14:23:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3544.8684, current episode: 10
[2023-06-29 14:23:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 527000.000000 | iteration_527000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540386      | 6491.880909         | 6.491881             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2205.950549 | 1100.621290 | 3570.332031 | 1219.646729 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:24:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1629.8308, current episode: 1
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3068.1240, current episode: 2
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1629.8308, current episode: 2
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3666.0149, current episode: 3
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3655.5334, current episode: 4
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3493.9248, current episode: 5
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3545.0364, current episode: 6
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3512.3894, current episode: 7
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3538.0398, current episode: 8
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3579.0347, current episode: 9
[2023-06-29 14:24:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3545.4619, current episode: 10
[2023-06-29 14:24:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 527500.000000 | iteration_527500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.539952      | 6493.709298         | 6.493709             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3323.339014 | 586.147523 | 3666.014893 | 1629.830811 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 410.9027, current episode: 1
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 410.9027, current episode: 1
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1172.2937, current episode: 2
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1227.5292, current episode: 3
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1284.0692, current episode: 4
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 410.9027, current episode: 4
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2213.5796, current episode: 5
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 410.9027, current episode: 5
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1172.2937, current episode: 5
[2023-06-29 14:24:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1227.5292, current episode: 5
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1284.0692, current episode: 5
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 410.9027, current episode: 5
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 410.9027, current episode: 5
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1172.2937, current episode: 5
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1227.5292, current episode: 5
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3717.9126, current episode: 6
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3518.3088, current episode: 7
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3554.3569, current episode: 8
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3557.6138, current episode: 9
[2023-06-29 14:24:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3562.4348, current episode: 10
[2023-06-29 14:24:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 528000.000000 | iteration_528000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.609349      | 6213.069367         | 6.213691             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2421.900131 | 1229.841015 | 3717.912598 | 410.902679 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:24:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1012.1816, current episode: 1
[2023-06-29 14:24:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1018.9792, current episode: 2
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1942.6011, current episode: 3
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2070.6565, current episode: 4
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1012.1816, current episode: 4
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1018.9792, current episode: 4
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2326.3276, current episode: 5
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2327.6887, current episode: 6
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2646.9275, current episode: 7
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2731.2366, current episode: 8
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2742.1670, current episode: 9
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1012.1816, current episode: 9
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1018.9792, current episode: 9
[2023-06-29 14:24:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3702.1382, current episode: 10
[2023-06-29 14:24:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 528500.000000 | iteration_528500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.607231      | 6221.881626         | 6.221882             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2252.090399 | 769.815315 | 3702.138184 | 1012.181580 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1035.1516, current episode: 1
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1028.9136, current episode: 2
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1068.6364, current episode: 3
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1368.7328, current episode: 4
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1501.5205, current episode: 5
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1598.5173, current episode: 6
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1035.1516, current episode: 6
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1028.9136, current episode: 6
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1068.6364, current episode: 6
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2429.1519, current episode: 7
[2023-06-29 14:24:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2567.3396, current episode: 8
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1368.7328, current episode: 8
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2875.2769, current episode: 9
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1501.5205, current episode: 9
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1598.5173, current episode: 9
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1035.1516, current episode: 9
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1028.9136, current episode: 9
[2023-06-29 14:24:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3251.2312, current episode: 10
[2023-06-29 14:24:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 529000.000000 | iteration_529000.pth.tar | 10.000000     | 8850.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 885.000000              | 1.449887      | 6103.922062         | 6.897087             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1872.447168 | 788.960412 | 3251.231201 | 1028.913574 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:25:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 978.4105, current episode: 1
[2023-06-29 14:25:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1602.8760, current episode: 2
[2023-06-29 14:25:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1617.9604, current episode: 3
[2023-06-29 14:25:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1859.6091, current episode: 4
[2023-06-29 14:25:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 978.4105, current episode: 4
[2023-06-29 14:25:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2928.0811, current episode: 5
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 978.4105, current episode: 5
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1602.8760, current episode: 5
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1617.9604, current episode: 5
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1859.6091, current episode: 5
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3684.5583, current episode: 6
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3589.8584, current episode: 7
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3557.0535, current episode: 8
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3614.6089, current episode: 9
[2023-06-29 14:25:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.2878, current episode: 10
[2023-06-29 14:25:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 529500.000000 | iteration_529500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536493      | 6508.328587         | 6.508329             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2696.830408 | 1006.304989 | 3684.558350 | 978.410522 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.6472, current episode: 1
[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 999.9136, current episode: 2
[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1005.6966, current episode: 3
[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1018.8401, current episode: 4
[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1037.3931, current episode: 5
[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1165.1193, current episode: 6
[2023-06-29 14:25:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1368.8341, current episode: 7
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1683.1125, current episode: 8
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1776.3248, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.6472, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 999.9136, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1005.6966, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1018.8401, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1037.3931, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1165.1193, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1368.8341, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.6472, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 999.9136, current episode: 9
[2023-06-29 14:25:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3090.6394, current episode: 10
[2023-06-29 14:25:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 530000.000000 | iteration_530000.pth.tar | 10.000000     | 8230.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 823.000000              | 1.259057      | 6536.638099         | 7.942452             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1413.152075 | 624.375237 | 3090.639404 | 985.647217 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:25:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1181.5388, current episode: 1
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1193.4795, current episode: 2
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1332.3228, current episode: 3
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1343.6322, current episode: 4
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1610.3962, current episode: 5
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1722.9569, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1181.5388, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1193.4795, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1332.3228, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1343.6322, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1610.3962, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1722.9569, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1181.5388, current episode: 6
[2023-06-29 14:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1193.4795, current episode: 6
[2023-06-29 14:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3713.3496, current episode: 7
[2023-06-29 14:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3559.6892, current episode: 8
[2023-06-29 14:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3564.8279, current episode: 9
[2023-06-29 14:25:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3593.6516, current episode: 10
[2023-06-29 14:25:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 530500.000000 | iteration_530500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.538647      | 6499.214572         | 6.499215             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2281.584473 | 1094.952990 | 3713.349609 | 1181.538818 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:25:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1052.4595, current episode: 1
[2023-06-29 14:25:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1054.7205, current episode: 2
[2023-06-29 14:25:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1064.1309, current episode: 3
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1052.4595, current episode: 3
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1054.7205, current episode: 3
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1064.1309, current episode: 3
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2341.7000, current episode: 4
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1052.4595, current episode: 4
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1054.7205, current episode: 4
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1064.1309, current episode: 4
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3622.8330, current episode: 5
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3598.8496, current episode: 6
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3570.9417, current episode: 7
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3588.6519, current episode: 8
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3587.3564, current episode: 9
[2023-06-29 14:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3583.9082, current episode: 10
[2023-06-29 14:25:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 531000.000000 | iteration_531000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.538055      | 6501.717336         | 6.501717             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2706.555151 | 1140.256097 | 3622.833008 | 1052.459473 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:26:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1060.7036, current episode: 1
[2023-06-29 14:26:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1562.6962, current episode: 2
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1984.6356, current episode: 3
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2014.5660, current episode: 4
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1060.7036, current episode: 4
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2255.7820, current episode: 5
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2586.9109, current episode: 6
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2817.2996, current episode: 7
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2867.2295, current episode: 8
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1562.6962, current episode: 8
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1060.7036, current episode: 8
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3610.9954, current episode: 9
[2023-06-29 14:26:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3567.8462, current episode: 10
[2023-06-29 14:26:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 531500.000000 | iteration_531500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.755113      | 5697.639910         | 5.697640             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2432.866492 | 779.976198 | 3610.995361 | 1060.703613 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1297.5007, current episode: 1
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1475.3835, current episode: 2
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1542.0869, current episode: 3
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1631.8577, current episode: 4
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1656.1573, current episode: 5
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2543.5349, current episode: 6
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1297.5007, current episode: 6
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2829.7554, current episode: 7
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1475.3835, current episode: 7
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1542.0869, current episode: 7
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3212.4592, current episode: 8
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1631.8577, current episode: 8
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3258.6316, current episode: 9
[2023-06-29 14:26:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1656.1573, current episode: 9
[2023-06-29 14:26:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3590.0315, current episode: 10
[2023-06-29 14:26:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 532000.000000 | iteration_532000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.552252      | 6442.252621         | 6.442253             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2303.739880 | 829.211953 | 3590.031494 | 1297.500732 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:26:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1007.2529, current episode: 1
[2023-06-29 14:26:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1035.1938, current episode: 2
[2023-06-29 14:26:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1090.2902, current episode: 3
[2023-06-29 14:26:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1461.4427, current episode: 4
[2023-06-29 14:26:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1525.0150, current episode: 5
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1930.7122, current episode: 6
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2015.2271, current episode: 7
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1007.2529, current episode: 7
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1035.1938, current episode: 7
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1090.2902, current episode: 7
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2323.5859, current episode: 8
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2615.6221, current episode: 9
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1461.4427, current episode: 9
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1525.0150, current episode: 9
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1007.2529, current episode: 9
[2023-06-29 14:26:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3183.2898, current episode: 10
[2023-06-29 14:26:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 532500.000000 | iteration_532500.pth.tar | 10.000000     | 8560.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 856.000000              | 1.341485      | 6380.986561         | 7.454424             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1818.763171 | 694.266679 | 3183.289795 | 1007.252930 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1033.9098, current episode: 1
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1021.7474, current episode: 2
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1218.8290, current episode: 3
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1419.1218, current episode: 4
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1502.4331, current episode: 5
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1683.8981, current episode: 6
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1672.6411, current episode: 7
[2023-06-29 14:27:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1671.3163, current episode: 8
[2023-06-29 14:27:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1033.9098, current episode: 8
[2023-06-29 14:27:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1021.7474, current episode: 8
[2023-06-29 14:27:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2391.2654, current episode: 9
[2023-06-29 14:27:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1218.8290, current episode: 9
[2023-06-29 14:27:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2758.9854, current episode: 10
[2023-06-29 14:27:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 533000.000000 | iteration_533000.pth.tar | 10.000000     | 7440.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 744.000000              | 1.129682      | 6585.926987         | 8.852052             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1637.414728 | 530.576360 | 2758.985352 | 1021.747375 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1046.6329, current episode: 1
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1068.2654, current episode: 2
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1139.5464, current episode: 3
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1255.0205, current episode: 4
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1995.0619, current episode: 5
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1046.6329, current episode: 5
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1068.2654, current episode: 5
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2277.1106, current episode: 6
[2023-06-29 14:27:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1139.5464, current episode: 6
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1255.0205, current episode: 6
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2582.5969, current episode: 7
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2687.1609, current episode: 8
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1046.6329, current episode: 8
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1068.2654, current episode: 8
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1139.5464, current episode: 8
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3557.1194, current episode: 9
[2023-06-29 14:27:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3562.1829, current episode: 10
[2023-06-29 14:27:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 533500.000000 | iteration_533500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505454      | 6642.515652         | 6.642516             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2117.069775 | 932.138386 | 3562.182861 | 1046.632935 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1013.1565, current episode: 1
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1029.6750, current episode: 2
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1056.6245, current episode: 3
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1099.0026, current episode: 4
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1159.3104, current episode: 5
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1262.4618, current episode: 6
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1279.5342, current episode: 7
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1283.8661, current episode: 8
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1282.7532, current episode: 9
[2023-06-29 14:27:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1370.6699, current episode: 10
[2023-06-29 14:27:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 534000.000000 | iteration_534000.pth.tar | 10.000000     | 3700.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 370.000000              | 0.568506      | 6508.285447         | 17.589961            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1183.705420 | 121.208745 | 1370.669922 | 1013.156494 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1042.9932, current episode: 1
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1045.6830, current episode: 2
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1158.4797, current episode: 3
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1177.1122, current episode: 4
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1194.9093, current episode: 5
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1230.1898, current episode: 6
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.6193, current episode: 7
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1334.6104, current episode: 8
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1042.9932, current episode: 8
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1045.6830, current episode: 8
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2241.4353, current episode: 9
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1158.4797, current episode: 9
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1177.1122, current episode: 9
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1194.9093, current episode: 9
[2023-06-29 14:27:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1230.1898, current episode: 9
[2023-06-29 14:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.6193, current episode: 9
[2023-06-29 14:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1334.6104, current episode: 9
[2023-06-29 14:27:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2806.4312, current episode: 10
[2023-06-29 14:27:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 534500.000000 | iteration_534500.pth.tar | 10.000000     | 7470.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 747.000000              | 1.227936      | 6083.378764         | 8.143747             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1451.646326 | 557.573330 | 2806.431152 | 1042.993164 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1162.1632, current episode: 1
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1171.0879, current episode: 2
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1266.2319, current episode: 3
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1261.2882, current episode: 4
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1304.4497, current episode: 5
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1605.5629, current episode: 6
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2251.4651, current episode: 7
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2318.6438, current episode: 8
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1162.1632, current episode: 8
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1171.0879, current episode: 8
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2400.9922, current episode: 9
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1266.2319, current episode: 9
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1261.2882, current episode: 9
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1304.4497, current episode: 9
[2023-06-29 14:28:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1605.5629, current episode: 9
[2023-06-29 14:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1162.1632, current episode: 9
[2023-06-29 14:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1171.0879, current episode: 9
[2023-06-29 14:28:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3557.8872, current episode: 10
[2023-06-29 14:28:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 535000.000000 | iteration_535000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.581714      | 6322.257472         | 6.322257             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1829.977209 | 746.729247 | 3557.887207 | 1162.163208 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1159.4816, current episode: 1
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1291.7855, current episode: 2
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1328.4489, current episode: 3
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1413.3534, current episode: 4
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1604.9243, current episode: 5
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1621.3064, current episode: 6
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1826.1716, current episode: 7
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1967.2625, current episode: 8
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1159.4816, current episode: 8
[2023-06-29 14:28:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1291.7855, current episode: 8
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1328.4489, current episode: 8
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2710.8252, current episode: 9
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1413.3534, current episode: 9
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1604.9243, current episode: 9
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1621.3064, current episode: 9
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1159.4816, current episode: 9
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1826.1716, current episode: 9
[2023-06-29 14:28:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3578.3821, current episode: 10
[2023-06-29 14:28:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 535500.000000 | iteration_535500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524873      | 6557.921933         | 6.557922             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1850.194141 | 714.569825 | 3578.382080 | 1159.481567 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1071.7887, current episode: 1
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1128.1691, current episode: 2
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1301.3940, current episode: 3
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1342.7617, current episode: 4
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1604.7961, current episode: 5
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1937.2856, current episode: 6
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1980.4431, current episode: 7
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1071.7887, current episode: 7
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2277.7920, current episode: 8
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1128.1691, current episode: 8
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1301.3940, current episode: 8
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1342.7617, current episode: 8
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2965.7615, current episode: 9
[2023-06-29 14:28:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3005.9055, current episode: 10
[2023-06-29 14:28:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 536000.000000 | iteration_536000.pth.tar | 10.000000     | 8060.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 806.000000              | 1.232396      | 6540.107580         | 8.114277             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1861.609741 | 673.228816 | 3005.905518 | 1071.788696 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1020.8356, current episode: 1
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1158.1658, current episode: 2
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.1392, current episode: 3
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1204.3314, current episode: 4
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1235.3138, current episode: 5
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1312.0046, current episode: 6
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1326.7908, current episode: 7
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1364.8826, current episode: 8
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1509.3171, current episode: 9
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1020.8356, current episode: 9
[2023-06-29 14:28:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2266.2908, current episode: 10
[2023-06-29 14:28:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 536500.000000 | iteration_536500.pth.tar | 10.000000     | 6190.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 619.000000              | 0.977871      | 6330.080462         | 10.226301            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1358.407172 | 327.542349 | 2266.290771 | 1020.835632 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1231.2947, current episode: 1
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1267.9666, current episode: 2
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1279.1691, current episode: 3
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1327.7262, current episode: 4
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1913.8253, current episode: 5
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2095.8696, current episode: 6
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2169.0718, current episode: 7
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2272.1992, current episode: 8
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2390.8105, current episode: 9
[2023-06-29 14:29:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2448.5090, current episode: 10
[2023-06-29 14:29:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 537000.000000 | iteration_537000.pth.tar | 10.000000     | 6480.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 648.000000              | 0.983240      | 6590.459382         | 10.170462            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1839.644202 | 481.079858 | 2448.509033 | 1231.294678 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1230.7554, current episode: 1
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1496.4213, current episode: 2
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1603.3971, current episode: 3
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1607.7075, current episode: 4
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1604.4957, current episode: 5
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1599.7509, current episode: 6
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1633.3574, current episode: 7
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1720.2151, current episode: 8
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1852.4674, current episode: 9
[2023-06-29 14:29:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2437.5474, current episode: 10
[2023-06-29 14:29:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 537500.000000 | iteration_537500.pth.tar | 10.000000     | 6560.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 656.000000              | 0.990862      | 6620.495668         | 10.092219            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1678.611511 | 294.304848 | 2437.547363 | 1230.755371 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1334.7162, current episode: 1
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1451.6439, current episode: 2
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1521.9969, current episode: 3
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1587.2612, current episode: 4
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1819.1613, current episode: 5
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1963.9719, current episode: 6
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1949.9591, current episode: 7
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2287.7908, current episode: 8
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2650.3381, current episode: 9
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1334.7162, current episode: 9
[2023-06-29 14:29:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2843.5149, current episode: 10
[2023-06-29 14:29:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 538000.000000 | iteration_538000.pth.tar | 10.000000     | 7630.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 763.000000              | 1.231887      | 6193.747645         | 8.117625             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1941.035437 | 485.917103 | 2843.514893 | 1334.716187 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1248.5304, current episode: 1
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1281.7533, current episode: 2
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1339.4373, current episode: 3
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1660.0885, current episode: 4
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1848.9297, current episode: 5
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1925.1210, current episode: 6
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1939.6283, current episode: 7
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2454.6492, current episode: 8
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1248.5304, current episode: 8
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1281.7533, current episode: 8
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1339.4373, current episode: 8
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2826.9875, current episode: 9
[2023-06-29 14:29:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2927.4304, current episode: 10
[2023-06-29 14:29:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 538500.000000 | iteration_538500.pth.tar | 10.000000     | 7870.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 787.000000              | 1.209170      | 6508.598541         | 8.270138             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1945.255554 | 581.834480 | 2927.430420 | 1248.530396 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1279.8022, current episode: 1
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1324.0448, current episode: 2
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1678.0721, current episode: 3
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1678.5254, current episode: 4
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1889.2139, current episode: 5
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1945.1975, current episode: 6
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1967.7109, current episode: 7
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1279.8022, current episode: 7
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2614.0916, current episode: 8
[2023-06-29 14:30:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1324.0448, current episode: 8
[2023-06-29 14:30:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1678.0721, current episode: 8
[2023-06-29 14:30:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1678.5254, current episode: 8
[2023-06-29 14:30:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3564.7705, current episode: 9
[2023-06-29 14:30:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3564.2039, current episode: 10
[2023-06-29 14:30:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 539000.000000 | iteration_539000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515798      | 6597.185228         | 6.597185             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2150.563281 | 790.225224 | 3564.770508 | 1279.802246 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:30:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1185.9927, current episode: 1
[2023-06-29 14:30:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1352.4576, current episode: 2
[2023-06-29 14:30:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1418.9460, current episode: 3
[2023-06-29 14:30:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1672.2876, current episode: 4
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1949.5266, current episode: 5
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2034.1040, current episode: 6
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2252.6328, current episode: 7
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2284.2400, current episode: 8
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1185.9927, current episode: 8
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1352.4576, current episode: 8
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1418.9460, current episode: 8
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3193.5669, current episode: 9
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1672.2876, current episode: 9
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1185.9927, current episode: 9
[2023-06-29 14:30:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3549.6580, current episode: 10
[2023-06-29 14:30:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 539500.000000 | iteration_539500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.537749      | 6503.013836         | 6.503014             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2089.341223 | 736.307523 | 3549.657959 | 1185.992676 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:30:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 818.1687, current episode: 1
[2023-06-29 14:30:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1189.9171, current episode: 2
[2023-06-29 14:30:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1275.9187, current episode: 3
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 818.1687, current episode: 3
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1874.0100, current episode: 4
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1989.1350, current episode: 5
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1189.9171, current episode: 5
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 818.1687, current episode: 5
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1275.9187, current episode: 5
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 818.1687, current episode: 5
[2023-06-29 14:30:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1189.9171, current episode: 5
[2023-06-29 14:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3497.6042, current episode: 6
[2023-06-29 14:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3524.5222, current episode: 7
[2023-06-29 14:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3527.1062, current episode: 8
[2023-06-29 14:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3510.3291, current episode: 9
[2023-06-29 14:30:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3487.5908, current episode: 10
[2023-06-29 14:30:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 540000.000000 | iteration_540000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.541999      | 6485.088927         | 6.485089             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2469.430212 | 1085.479515 | 3527.106201 | 818.168701 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1183.8809, current episode: 1
[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1168.9996, current episode: 2
[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1282.0861, current episode: 3
[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1536.6848, current episode: 4
[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1630.8560, current episode: 5
[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2127.0994, current episode: 6
[2023-06-29 14:30:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1183.8809, current episode: 6
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1168.9996, current episode: 6
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1282.0861, current episode: 6
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2986.5935, current episode: 7
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3050.5151, current episode: 8
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1536.6848, current episode: 8
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1630.8560, current episode: 8
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1183.8809, current episode: 8
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1168.9996, current episode: 8
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3529.6394, current episode: 9
[2023-06-29 14:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3530.8562, current episode: 10
[2023-06-29 14:30:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 540500.000000 | iteration_540500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.608017      | 6218.840795         | 6.218841             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2202.721094 | 926.736360 | 3530.856201 | 1168.999634 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.6385, current episode: 1
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 686.2479, current episode: 2
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.3397, current episode: 3
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1085.9775, current episode: 4
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1144.6686, current episode: 5
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1154.9320, current episode: 6
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1307.0948, current episode: 7
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.6385, current episode: 7
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 686.2479, current episode: 7
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.3397, current episode: 7
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2106.7703, current episode: 8
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1085.9775, current episode: 8
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.6385, current episode: 8
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 686.2479, current episode: 8
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1144.6686, current episode: 8
[2023-06-29 14:31:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1154.9320, current episode: 8
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2564.0774, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1307.0948, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.6385, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 984.3397, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 686.2479, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1085.9775, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1144.6686, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1154.9320, current episode: 9
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3506.6238, current episode: 10
[2023-06-29 14:31:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.6385, current episode: 10
[2023-06-29 14:31:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 541000.000000 | iteration_541000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.572799      | 6357.456415         | 6.358092             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1519.837048 | 872.620480 | 3506.623779 | 657.638550 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 639.2936, current episode: 1
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 621.9833, current episode: 2
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 713.4672, current episode: 3
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 722.2744, current episode: 4
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 968.6036, current episode: 5
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1040.7727, current episode: 6
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1074.9138, current episode: 7
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1100.2834, current episode: 8
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1217.0005, current episode: 9
[2023-06-29 14:31:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1251.2134, current episode: 10
[2023-06-29 14:31:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 541500.000000 | iteration_541500.pth.tar | 10.000000     | 3450.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 345.000000              | 0.554738      | 6219.148951         | 18.026519            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 934.980591  | 227.700996 | 1251.213379 | 621.983276 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 925.7007, current episode: 1
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 971.7806, current episode: 2
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 968.0471, current episode: 3
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1022.4331, current episode: 4
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 981.8470, current episode: 5
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1171.3739, current episode: 6
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1273.6039, current episode: 7
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1303.8351, current episode: 8
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1500.4412, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 925.7007, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 971.7806, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 968.0471, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1022.4331, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 981.8470, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1171.3739, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1273.6039, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1303.8351, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 925.7007, current episode: 9
[2023-06-29 14:31:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2909.4224, current episode: 10
[2023-06-29 14:31:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 542000.000000 | iteration_542000.pth.tar | 10.000000     | 7890.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 789.000000              | 1.341123      | 5883.129082         | 7.456437             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1302.848499 | 564.258568 | 2909.422363 | 925.700745 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 970.9936, current episode: 1
[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1001.2243, current episode: 2
[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 995.8352, current episode: 3
[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1233.2180, current episode: 4
[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1700.5758, current episode: 5
[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 970.9936, current episode: 5
[2023-06-29 14:31:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1001.2243, current episode: 5
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 995.8352, current episode: 5
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1233.2180, current episode: 5
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2656.8232, current episode: 6
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 970.9936, current episode: 6
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1001.2243, current episode: 6
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 995.8352, current episode: 6
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3227.9270, current episode: 7
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1700.5758, current episode: 7
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3504.9141, current episode: 8
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3501.7749, current episode: 9
[2023-06-29 14:31:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3522.4329, current episode: 10
[2023-06-29 14:31:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 542500.000000 | iteration_542500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.534477      | 6516.876618         | 6.516877             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2231.571899 | 1094.679201 | 3522.432861 | 970.993591 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1063.8512, current episode: 1
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1334.4164, current episode: 2
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1327.1013, current episode: 3
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1063.8512, current episode: 3
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2246.6257, current episode: 4
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2226.8198, current episode: 5
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2231.3403, current episode: 6
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1334.4164, current episode: 6
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1327.1013, current episode: 6
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2999.3105, current episode: 7
[2023-06-29 14:32:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3227.8882, current episode: 8
[2023-06-29 14:32:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1063.8512, current episode: 8
[2023-06-29 14:32:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3553.1257, current episode: 9
[2023-06-29 14:32:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3489.4111, current episode: 10
[2023-06-29 14:32:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 543000.000000 | iteration_543000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523954      | 6561.875838         | 6.561876             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2369.989038 | 877.833455 | 3553.125732 | 1063.851196 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 973.6998, current episode: 1
[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 995.0621, current episode: 2
[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1170.6370, current episode: 3
[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 973.6998, current episode: 3
[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 995.0621, current episode: 3
[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2101.5161, current episode: 4
[2023-06-29 14:32:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1170.6370, current episode: 4
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2947.6504, current episode: 5
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 973.6998, current episode: 5
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 995.0621, current episode: 5
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1170.6370, current episode: 5
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3482.4937, current episode: 6
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3480.3879, current episode: 7
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3456.2803, current episode: 8
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3518.7610, current episode: 9
[2023-06-29 14:32:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3484.0576, current episode: 10
[2023-06-29 14:32:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 543500.000000 | iteration_543500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.664022      | 6009.537353         | 6.009537             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2561.054578 | 1073.811432 | 3518.760986 | 973.699768 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 957.7767, current episode: 1
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 975.5022, current episode: 2
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 966.4424, current episode: 3
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 986.8472, current episode: 4
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1025.6901, current episode: 5
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1192.8257, current episode: 6
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1289.3867, current episode: 7
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1283.7239, current episode: 8
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1592.9219, current episode: 9
[2023-06-29 14:32:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1669.8876, current episode: 10
[2023-06-29 14:32:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 544000.000000 | iteration_544000.pth.tar | 10.000000     | 4610.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 461.000000              | 0.756811      | 6091.351760         | 13.213344            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1194.100427 | 250.863239 | 1669.887573 | 957.776672 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 869.7225, current episode: 1
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 879.9694, current episode: 2
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.8706, current episode: 3
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 919.6678, current episode: 4
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1308.7241, current episode: 5
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1321.9189, current episode: 6
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1357.3265, current episode: 7
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1544.7845, current episode: 8
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1623.1455, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 869.7225, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 879.9694, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 906.8706, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 919.6678, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1308.7241, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1321.9189, current episode: 9
[2023-06-29 14:33:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2658.2832, current episode: 10
[2023-06-29 14:33:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 544500.000000 | iteration_544500.pth.tar | 10.000000     | 7310.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 731.000000              | 1.115698      | 6551.949375         | 8.962995             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1339.041315 | 515.620417 | 2658.283203 | 869.722534 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 918.9603, current episode: 1
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 991.3213, current episode: 2
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1015.6901, current episode: 3
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1101.4004, current episode: 4
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1104.0079, current episode: 5
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1131.2462, current episode: 6
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1166.5824, current episode: 7
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1200.1565, current episode: 8
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1321.9980, current episode: 9
[2023-06-29 14:33:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1436.4017, current episode: 10
[2023-06-29 14:33:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 545000.000000 | iteration_545000.pth.tar | 10.000000     | 3960.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 396.000000              | 0.609987      | 6491.946833         | 16.393805            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1138.776483 | 146.480922 | 1436.401733 | 918.960266 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1012.1393, current episode: 1
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1000.5391, current episode: 2
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1006.0983, current episode: 3
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1024.8447, current episode: 4
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1029.1937, current episode: 5
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1036.7178, current episode: 6
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1037.4363, current episode: 7
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1058.3579, current episode: 8
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1076.0814, current episode: 9
[2023-06-29 14:33:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1074.8621, current episode: 10
[2023-06-29 14:33:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 545500.000000 | iteration_545500.pth.tar | 10.000000     | 3070.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 307.000000              | 0.495352      | 6197.618484         | 20.187682            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1035.627057 | 25.513782  | 1076.081421 | 1000.539062 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 935.7157, current episode: 1
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 943.8901, current episode: 2
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 967.0264, current episode: 3
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 974.3186, current episode: 4
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 992.5380, current episode: 5
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1010.2983, current episode: 6
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1012.1423, current episode: 7
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1033.1492, current episode: 8
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1043.2621, current episode: 9
[2023-06-29 14:33:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1055.0725, current episode: 10
[2023-06-29 14:33:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 546000.000000 | iteration_546000.pth.tar | 10.000000     | 2990.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 299.000000              | 0.483104      | 6189.142706         | 20.699474            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 996.741315  | 39.030793  | 1055.072510 | 935.715698 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1060.7218, current episode: 1
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1171.6042, current episode: 2
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1304.1183, current episode: 3
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1428.9039, current episode: 4
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1473.9667, current episode: 5
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1495.8757, current episode: 6
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1641.7023, current episode: 7
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1892.0612, current episode: 8
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2045.5958, current episode: 9
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1060.7218, current episode: 9
[2023-06-29 14:34:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2324.8923, current episode: 10
[2023-06-29 14:34:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 546500.000000 | iteration_546500.pth.tar | 10.000000     | 6250.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 625.000000              | 0.962263      | 6495.102921         | 10.392165            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1583.944226 | 377.673863 | 2324.892334 | 1060.721802 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 970.1654, current episode: 1
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1204.3796, current episode: 2
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1228.4330, current episode: 3
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1325.6958, current episode: 4
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1416.3429, current episode: 5
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1539.3053, current episode: 6
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1573.2897, current episode: 7
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1669.7894, current episode: 8
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 970.1654, current episode: 8
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2152.9993, current episode: 9
[2023-06-29 14:34:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2297.0979, current episode: 10
[2023-06-29 14:34:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 547000.000000 | iteration_547000.pth.tar | 10.000000     | 6300.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 630.000000              | 0.968503      | 6504.881125         | 10.325208            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1537.749829 | 395.286295 | 2297.097900 | 970.165405 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1109.9559, current episode: 1
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1153.3660, current episode: 2
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1224.9727, current episode: 3
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1496.8925, current episode: 4
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1895.2208, current episode: 5
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1109.9559, current episode: 5
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1153.3660, current episode: 5
[2023-06-29 14:34:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1224.9727, current episode: 5
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2671.7153, current episode: 6
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2714.5618, current episode: 7
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1496.8925, current episode: 7
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3304.8650, current episode: 8
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1109.9559, current episode: 8
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1153.3660, current episode: 8
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3595.2957, current episode: 9
[2023-06-29 14:34:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3665.6284, current episode: 10
[2023-06-29 14:34:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 547500.000000 | iteration_547500.pth.tar | 10.000000     | 9870.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 987.000000              | 1.494737      | 6603.166971         | 6.690139             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2283.247400 | 977.506977 | 3665.628418 | 1109.955933 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.5740, current episode: 1
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1129.8369, current episode: 2
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1141.1536, current episode: 3
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1277.7119, current episode: 4
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1588.0433, current episode: 5
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1597.4276, current episode: 6
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1651.0759, current episode: 7
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1664.9008, current episode: 8
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1700.5366, current episode: 9
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.5740, current episode: 9
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1129.8369, current episode: 9
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1141.1536, current episode: 9
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1277.7119, current episode: 9
[2023-06-29 14:34:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2860.6606, current episode: 10
[2023-06-29 14:34:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 548000.000000 | iteration_548000.pth.tar | 10.000000     | 7690.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 769.000000              | 1.198576      | 6415.949271         | 8.343237             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1567.292126 | 492.037685 | 2860.660645 | 1061.573975 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1159.3357, current episode: 1
[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1204.0223, current episode: 2
[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1242.0619, current episode: 3
[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1404.2964, current episode: 4
[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1581.3922, current episode: 5
[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1886.8817, current episode: 6
[2023-06-29 14:35:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1962.6777, current episode: 7
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1159.3357, current episode: 7
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1204.0223, current episode: 7
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1242.0619, current episode: 7
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2810.2122, current episode: 8
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1404.2964, current episode: 8
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1581.3922, current episode: 8
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1159.3357, current episode: 8
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3551.1726, current episode: 9
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1204.0223, current episode: 9
[2023-06-29 14:35:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3562.3677, current episode: 10
[2023-06-29 14:35:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 548500.000000 | iteration_548500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540081      | 6493.166283         | 6.493166             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2036.442041 | 891.590926 | 3562.367676 | 1159.335693 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1058.1606, current episode: 1
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1064.6766, current episode: 2
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1120.7446, current episode: 3
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1120.7334, current episode: 4
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.2260, current episode: 5
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1290.6365, current episode: 6
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1365.8542, current episode: 7
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1818.4698, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1058.1606, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1064.6766, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1120.7446, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1120.7334, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.2260, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1290.6365, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1365.8542, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1058.1606, current episode: 8
[2023-06-29 14:35:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1064.6766, current episode: 8
[2023-06-29 14:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1120.7446, current episode: 8
[2023-06-29 14:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1120.7334, current episode: 8
[2023-06-29 14:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1151.2260, current episode: 8
[2023-06-29 14:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1818.4698, current episode: 8
[2023-06-29 14:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3552.1704, current episode: 9
[2023-06-29 14:35:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3507.8223, current episode: 10
[2023-06-29 14:35:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 549000.000000 | iteration_549000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547651      | 6461.405054         | 6.461405             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1705.049451 | 936.995286 | 3552.170410 | 1058.160645 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.5173, current episode: 1
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1225.0728, current episode: 2
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1288.8380, current episode: 3
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1335.8219, current episode: 4
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1477.8625, current episode: 5
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1648.6082, current episode: 6
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1805.7050, current episode: 7
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.5173, current episode: 7
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1225.0728, current episode: 7
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1288.8380, current episode: 7
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2656.5161, current episode: 8
[2023-06-29 14:35:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1335.8219, current episode: 8
[2023-06-29 14:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1477.8625, current episode: 8
[2023-06-29 14:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1648.6082, current episode: 8
[2023-06-29 14:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.5173, current episode: 8
[2023-06-29 14:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1805.7050, current episode: 8
[2023-06-29 14:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3502.8203, current episode: 9
[2023-06-29 14:35:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3544.1421, current episode: 10
[2023-06-29 14:35:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 549500.000000 | iteration_549500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540070      | 6493.210030         | 6.493210             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1955.490417 | 888.881011 | 3544.142090 | 1069.517334 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 846.4609, current episode: 1
[2023-06-29 14:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1212.9906, current episode: 2
[2023-06-29 14:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1284.2189, current episode: 3
[2023-06-29 14:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1305.1866, current episode: 4
[2023-06-29 14:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1310.4885, current episode: 5
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 846.4609, current episode: 5
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2391.6631, current episode: 6
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1212.9906, current episode: 6
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2497.4211, current episode: 7
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1284.2189, current episode: 7
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1305.1866, current episode: 7
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1310.4885, current episode: 7
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3060.2434, current episode: 8
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 846.4609, current episode: 8
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3217.3020, current episode: 9
[2023-06-29 14:35:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3542.9893, current episode: 10
[2023-06-29 14:35:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 550000.000000 | iteration_550000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.519833      | 6579.668119         | 6.579668             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2066.896442 | 936.130500 | 3542.989258 | 846.460876 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 897.4482, current episode: 1
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1053.5698, current episode: 2
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1119.4210, current episode: 3
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1115.7545, current episode: 4
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1206.4075, current episode: 5
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1352.2695, current episode: 6
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1556.3832, current episode: 7
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1637.5321, current episode: 8
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 897.4482, current episode: 8
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2116.3779, current episode: 9
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1053.5698, current episode: 9
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1119.4210, current episode: 9
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1115.7545, current episode: 9
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1206.4075, current episode: 9
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1352.2695, current episode: 9
[2023-06-29 14:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 897.4482, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1556.3832, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1053.5698, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1637.5321, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1119.4210, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1115.7545, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1206.4075, current episode: 9
[2023-06-29 14:36:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3541.9263, current episode: 10
[2023-06-29 14:36:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 550500.000000 | iteration_550500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547991      | 6459.985508         | 6.459986             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1559.709009 | 741.532296 | 3541.926270 | 897.448242 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:36:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1089.2140, current episode: 1
[2023-06-29 14:36:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1103.6600, current episode: 2
[2023-06-29 14:36:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1210.8898, current episode: 3
[2023-06-29 14:36:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1284.7886, current episode: 4
[2023-06-29 14:36:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1351.0630, current episode: 5
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1773.4442, current episode: 6
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1852.6488, current episode: 7
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2190.2292, current episode: 8
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1089.2140, current episode: 8
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1103.6600, current episode: 8
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1210.8898, current episode: 8
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1284.7886, current episode: 8
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2615.7302, current episode: 9
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1351.0630, current episode: 9
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1089.2140, current episode: 9
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1103.6600, current episode: 9
[2023-06-29 14:36:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3542.6765, current episode: 10
[2023-06-29 14:36:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 551000.000000 | iteration_551000.pth.tar | 10.000000     | 9720.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 972.000000              | 1.538523      | 6317.745809         | 6.499738             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1801.434436 | 752.477032 | 3542.676514 | 1089.213989 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 588.2280, current episode: 1
[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1331.9159, current episode: 2
[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1387.4056, current episode: 3
[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 588.2280, current episode: 3
[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1674.9382, current episode: 4
[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1695.7720, current episode: 5
[2023-06-29 14:36:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1764.5656, current episode: 6
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2057.1711, current episode: 7
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 588.2280, current episode: 7
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1331.9159, current episode: 7
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2708.4854, current episode: 8
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1387.4056, current episode: 8
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2823.9055, current episode: 9
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 588.2280, current episode: 9
[2023-06-29 14:36:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3091.1394, current episode: 10
[2023-06-29 14:36:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 551500.000000 | iteration_551500.pth.tar | 10.000000     | 8470.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 847.000000              | 1.327567      | 6380.092811         | 7.532577             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1912.352673 | 732.540958 | 3091.139404 | 588.228027 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:36:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1122.9828, current episode: 1
[2023-06-29 14:36:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1127.7579, current episode: 2
[2023-06-29 14:36:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.2869, current episode: 3
[2023-06-29 14:36:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1267.4132, current episode: 4
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1140.5894, current episode: 5
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1511.4001, current episode: 6
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1456.5988, current episode: 7
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1846.9945, current episode: 8
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1852.4651, current episode: 9
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1122.9828, current episode: 9
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1127.7579, current episode: 9
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.2869, current episode: 9
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1267.4132, current episode: 9
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1140.5894, current episode: 9
[2023-06-29 14:36:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3130.9624, current episode: 10
[2023-06-29 14:36:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 552000.000000 | iteration_552000.pth.tar | 10.000000     | 8400.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 840.000000              | 1.275755      | 6584.335679         | 7.838495             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1563.345105 | 586.117032 | 3130.962402 | 1122.982788 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.2795, current episode: 1
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1054.1396, current episode: 2
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1378.8700, current episode: 3
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.2795, current episode: 3
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1054.1396, current episode: 3
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2469.6448, current episode: 4
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2535.3586, current episode: 5
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1378.8700, current episode: 5
[2023-06-29 14:37:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2737.5134, current episode: 6
[2023-06-29 14:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.2795, current episode: 6
[2023-06-29 14:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3253.1008, current episode: 7
[2023-06-29 14:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1054.1396, current episode: 7
[2023-06-29 14:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3558.6963, current episode: 8
[2023-06-29 14:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3585.6135, current episode: 9
[2023-06-29 14:37:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3534.9900, current episode: 10
[2023-06-29 14:37:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 552500.000000 | iteration_552500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.540529      | 6491.275961         | 6.491276             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2512.520660 | 976.764102 | 3585.613525 | 1017.279480 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:37:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 842.4404, current episode: 1
[2023-06-29 14:37:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1059.8137, current episode: 2
[2023-06-29 14:37:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1519.8348, current episode: 3
[2023-06-29 14:37:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1588.3917, current episode: 4
[2023-06-29 14:37:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1577.0669, current episode: 5
[2023-06-29 14:37:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1778.7045, current episode: 6
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1906.9619, current episode: 7
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1764.7078, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 842.4404, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1059.8137, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 842.4404, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1519.8348, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1588.3917, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1577.0669, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1059.8137, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1778.7045, current episode: 8
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3659.1060, current episode: 9
[2023-06-29 14:37:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.6838, current episode: 10
[2023-06-29 14:37:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 553000.000000 | iteration_553000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510321      | 6621.109361         | 6.621109             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1926.671149 | 898.805088 | 3659.105957 | 842.440369 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:37:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 530.5333, current episode: 1
[2023-06-29 14:37:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 540.9922, current episode: 2
[2023-06-29 14:37:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 583.8469, current episode: 3
[2023-06-29 14:37:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 605.8464, current episode: 4
[2023-06-29 14:37:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 657.6013, current episode: 5
[2023-06-29 14:37:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 700.3483, current episode: 6
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 530.5333, current episode: 6
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 540.9922, current episode: 6
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1128.6980, current episode: 7
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 583.8469, current episode: 7
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 605.8464, current episode: 7
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 657.6013, current episode: 7
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 700.3483, current episode: 7
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1697.4650, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 530.5333, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 540.9922, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 583.8469, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 605.8464, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 657.6013, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 700.3483, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 530.5333, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 540.9922, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1128.6980, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 583.8469, current episode: 8
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2704.6543, current episode: 9
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 605.8464, current episode: 9
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 657.6013, current episode: 9
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 700.3483, current episode: 9
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 530.5333, current episode: 9
[2023-06-29 14:37:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 540.9922, current episode: 9
[2023-06-29 14:37:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 583.8469, current episode: 9
[2023-06-29 14:37:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 605.8464, current episode: 9
[2023-06-29 14:37:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1697.4650, current episode: 9
[2023-06-29 14:37:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 657.6013, current episode: 9
[2023-06-29 14:37:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3547.2085, current episode: 10
[2023-06-29 14:37:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 553500.000000 | iteration_553500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.589939      | 6289.549129         | 6.289549             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1269.719403 | 1006.792337 | 3547.208496 | 530.533264 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 869.8176, current episode: 1
[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 870.4520, current episode: 2
[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 961.3185, current episode: 3
[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 988.3054, current episode: 4
[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1081.5476, current episode: 5
[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1461.2410, current episode: 6
[2023-06-29 14:37:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1610.6996, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 869.8176, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 870.4520, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 961.3185, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 988.3054, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1081.5476, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 869.8176, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 870.4520, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 961.3185, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1461.2410, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 988.3054, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1610.6996, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1081.5476, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 869.8176, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 870.4520, current episode: 7
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3547.6941, current episode: 8
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3533.0278, current episode: 9
[2023-06-29 14:37:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3530.9004, current episode: 10
[2023-06-29 14:37:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 554000.000000 | iteration_554000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.568287      | 6376.383966         | 6.376384             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1845.500403 | 1130.992176 | 3547.694092 | 869.817627 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 813.1331, current episode: 1
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 820.3848, current episode: 2
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 875.3309, current episode: 3
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 931.5557, current episode: 4
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 921.4689, current episode: 5
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 947.7363, current episode: 6
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 959.5310, current episode: 7
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1158.4971, current episode: 8
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1588.2186, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 813.1331, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 820.3848, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 875.3309, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 931.5557, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 921.4689, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 947.7363, current episode: 9
[2023-06-29 14:38:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 959.5310, current episode: 9
[2023-06-29 14:38:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1158.4971, current episode: 9
[2023-06-29 14:38:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2490.3079, current episode: 10
[2023-06-29 14:38:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 554500.000000 | iteration_554500.pth.tar | 10.000000     | 6700.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 670.000000              | 1.025689      | 6532.197013         | 9.749548             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1150.616425 | 496.309496 | 2490.307861 | 813.133118 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 934.4774, current episode: 1
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1047.1167, current episode: 2
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1156.7717, current episode: 3
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1387.3475, current episode: 4
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1502.6886, current episode: 5
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1462.8303, current episode: 6
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1525.9719, current episode: 7
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1848.9740, current episode: 8
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 934.4774, current episode: 8
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1911.3680, current episode: 9
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1047.1167, current episode: 9
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1156.7717, current episode: 9
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1387.3475, current episode: 9
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 934.4774, current episode: 9
[2023-06-29 14:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1502.6886, current episode: 9
[2023-06-29 14:38:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1047.1167, current episode: 9
[2023-06-29 14:38:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1462.8303, current episode: 9
[2023-06-29 14:38:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1525.9719, current episode: 9
[2023-06-29 14:38:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3529.5425, current episode: 10
[2023-06-29 14:38:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 555000.000000 | iteration_555000.pth.tar | 10.000000     | 9520.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 952.000000              | 1.535666      | 6199.263635         | 6.511832             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1630.708875 | 699.762799 | 3529.542480 | 934.477417 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1278.7111, current episode: 1
[2023-06-29 14:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1632.3119, current episode: 2
[2023-06-29 14:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1807.7037, current episode: 3
[2023-06-29 14:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2134.0808, current episode: 4
[2023-06-29 14:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2740.7676, current episode: 5
[2023-06-29 14:38:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1278.7111, current episode: 5
[2023-06-29 14:38:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1632.3119, current episode: 5
[2023-06-29 14:38:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3523.3259, current episode: 6
[2023-06-29 14:38:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3560.6873, current episode: 7
[2023-06-29 14:38:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3536.8201, current episode: 8
[2023-06-29 14:38:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3493.3225, current episode: 9
[2023-06-29 14:38:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3492.0110, current episode: 10
[2023-06-29 14:38:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 555500.000000 | iteration_555500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.553220      | 6438.237092         | 6.438237             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2719.974182 | 874.626068 | 3560.687256 | 1278.711060 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1036.2529, current episode: 1
[2023-06-29 14:38:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1088.3311, current episode: 2
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.5353, current episode: 3
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1518.2102, current episode: 4
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1581.2532, current episode: 5
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1997.1895, current episode: 6
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1898.5107, current episode: 7
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1036.2529, current episode: 7
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1088.3311, current episode: 7
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2195.3940, current episode: 8
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.5353, current episode: 8
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1036.2529, current episode: 8
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1518.2102, current episode: 8
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1581.2532, current episode: 8
[2023-06-29 14:38:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1088.3311, current episode: 8
[2023-06-29 14:38:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3493.2051, current episode: 9
[2023-06-29 14:38:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3477.1282, current episode: 10
[2023-06-29 14:38:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 556000.000000 | iteration_556000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520029      | 6578.823737         | 6.578824             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1946.201013 | 853.031399 | 3493.205078 | 1036.252930 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1090.4153, current episode: 1
[2023-06-29 14:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1377.4680, current episode: 2
[2023-06-29 14:39:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1659.0035, current episode: 3
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2071.2476, current episode: 4
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2110.2732, current episode: 5
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2107.1428, current episode: 6
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2227.6797, current episode: 7
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2220.6226, current episode: 8
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1090.4153, current episode: 8
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2567.4023, current episode: 9
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1377.4680, current episode: 9
[2023-06-29 14:39:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3219.1914, current episode: 10
[2023-06-29 14:39:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 556500.000000 | iteration_556500.pth.tar | 10.000000     | 8650.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 865.000000              | 1.326940      | 6518.757130         | 7.536135             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2065.044641 | 568.019576 | 3219.191406 | 1090.415283 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1021.5613, current episode: 1
[2023-06-29 14:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1024.6833, current episode: 2
[2023-06-29 14:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1180.8053, current episode: 3
[2023-06-29 14:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1200.1083, current episode: 4
[2023-06-29 14:39:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1369.3108, current episode: 5
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1667.4459, current episode: 6
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1713.9349, current episode: 7
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1830.0375, current episode: 8
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2082.6040, current episode: 9
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1021.5613, current episode: 9
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1024.6833, current episode: 9
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1180.8053, current episode: 9
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1200.1083, current episode: 9
[2023-06-29 14:39:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2565.6597, current episode: 10
[2023-06-29 14:39:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 557000.000000 | iteration_557000.pth.tar | 10.000000     | 6910.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 691.000000              | 1.067178      | 6475.023389         | 9.370511             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1565.615106 | 477.332694 | 2565.659668 | 1021.561340 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1060.4683, current episode: 1
[2023-06-29 14:39:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1624.4398, current episode: 2
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1060.4683, current episode: 2
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2344.2612, current episode: 3
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3189.6311, current episode: 4
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1624.4398, current episode: 4
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1060.4683, current episode: 4
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3364.6133, current episode: 5
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3531.3396, current episode: 6
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3555.2239, current episode: 7
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3569.2424, current episode: 8
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3598.4009, current episode: 9
[2023-06-29 14:39:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3609.6113, current episode: 10
[2023-06-29 14:39:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 557500.000000 | iteration_557500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505531      | 6642.174190         | 6.642174             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2944.723181 | 886.940353 | 3609.611328 | 1060.468262 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1301.2126, current episode: 1
[2023-06-29 14:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1513.2971, current episode: 2
[2023-06-29 14:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1519.6478, current episode: 3
[2023-06-29 14:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1950.9772, current episode: 4
[2023-06-29 14:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2232.9919, current episode: 5
[2023-06-29 14:39:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1301.2126, current episode: 5
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1513.2971, current episode: 5
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1519.6478, current episode: 5
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3454.2102, current episode: 6
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3531.4277, current episode: 7
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3533.9346, current episode: 8
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3505.1716, current episode: 9
[2023-06-29 14:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3588.6707, current episode: 10
[2023-06-29 14:39:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 558000.000000 | iteration_558000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506859      | 6636.318794         | 6.636319             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2613.154150 | 941.031328 | 3588.670654 | 1301.212646 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:40:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1721.2534, current episode: 1
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1721.2534, current episode: 1
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3460.4280, current episode: 2
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3477.6685, current episode: 3
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3521.5989, current episode: 4
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3736.6179, current episode: 5
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3555.0732, current episode: 6
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3514.1316, current episode: 7
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3491.1035, current episode: 8
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3509.2820, current episode: 9
[2023-06-29 14:40:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3509.8530, current episode: 10
[2023-06-29 14:40:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 558500.000000 | iteration_558500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.528314      | 6543.158689         | 6.543159             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3349.701001 | 547.727656 | 3736.617920 | 1721.253418 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:40:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1582.0786, current episode: 1
[2023-06-29 14:40:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1666.8352, current episode: 2
[2023-06-29 14:40:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2702.0527, current episode: 3
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1582.0786, current episode: 3
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1666.8352, current episode: 3
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3456.3206, current episode: 4
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3504.6812, current episode: 5
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3517.7542, current episode: 6
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3454.1863, current episode: 7
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3476.7651, current episode: 8
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3472.4646, current episode: 9
[2023-06-29 14:40:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3559.9656, current episode: 10
[2023-06-29 14:40:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 559000.000000 | iteration_559000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.500188      | 6665.830183         | 6.665830             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3039.310400 | 745.823318 | 3559.965576 | 1582.078613 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:40:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1406.2089, current episode: 1
[2023-06-29 14:40:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1438.7673, current episode: 2
[2023-06-29 14:40:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1576.5952, current episode: 3
[2023-06-29 14:40:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2008.1409, current episode: 4
[2023-06-29 14:40:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1406.2089, current episode: 4
[2023-06-29 14:40:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1438.7673, current episode: 4
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3050.8406, current episode: 5
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1576.5952, current episode: 5
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3533.1172, current episode: 6
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3573.6482, current episode: 7
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3528.4624, current episode: 8
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3576.3372, current episode: 9
[2023-06-29 14:40:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3605.2371, current episode: 10
[2023-06-29 14:40:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 559500.000000 | iteration_559500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.554142      | 6434.419115         | 6.434419             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2729.735486 | 940.780216 | 3605.237061 | 1406.208862 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1817.7788, current episode: 1
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1920.4342, current episode: 2
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2491.1838, current episode: 3
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2449.0010, current episode: 4
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2804.1460, current episode: 5
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2960.1770, current episode: 6
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3062.3423, current episode: 7
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3651.3125, current episode: 8
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3538.0837, current episode: 9
[2023-06-29 14:40:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3454.9124, current episode: 10
[2023-06-29 14:40:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 560000.000000 | iteration_560000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.515276      | 6599.458848         | 6.599459             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2814.937170 | 612.179640 | 3651.312500 | 1817.778809 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:41:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1317.8640, current episode: 1
[2023-06-29 14:41:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1482.2922, current episode: 2
[2023-06-29 14:41:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1493.2438, current episode: 3
[2023-06-29 14:41:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1530.9246, current episode: 4
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1850.6783, current episode: 5
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2291.4512, current episode: 6
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2492.4548, current episode: 7
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1317.8640, current episode: 7
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1482.2922, current episode: 7
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3283.6748, current episode: 8
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1493.2438, current episode: 8
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1530.9246, current episode: 8
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3519.7444, current episode: 9
[2023-06-29 14:41:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3487.0293, current episode: 10
[2023-06-29 14:41:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 560500.000000 | iteration_560500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.598786      | 6254.745746         | 6.254746             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2274.935742 | 835.028172 | 3519.744385 | 1317.864014 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 877.7521, current episode: 1
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1175.2019, current episode: 2
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1259.9771, current episode: 3
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1548.7782, current episode: 4
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1838.8024, current episode: 5
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 877.7521, current episode: 5
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1175.2019, current episode: 5
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1259.9771, current episode: 5
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2748.2397, current episode: 6
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1548.7782, current episode: 6
[2023-06-29 14:41:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 877.7521, current episode: 6
[2023-06-29 14:41:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1175.2019, current episode: 6
[2023-06-29 14:41:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3351.4670, current episode: 7
[2023-06-29 14:41:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3370.6648, current episode: 8
[2023-06-29 14:41:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3404.7615, current episode: 9
[2023-06-29 14:41:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3482.6375, current episode: 10
[2023-06-29 14:41:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 561000.000000 | iteration_561000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.531223      | 6530.727303         | 6.530727             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2305.828217 | 1010.854065 | 3482.637451 | 877.752136 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1922.8510, current episode: 1
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1963.2651, current episode: 2
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2088.7446, current episode: 3
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2818.3711, current episode: 4
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2862.6743, current episode: 5
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3033.1470, current episode: 6
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3507.0667, current episode: 7
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3415.7625, current episode: 8
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3448.5957, current episode: 9
[2023-06-29 14:41:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3489.4343, current episode: 10
[2023-06-29 14:41:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 561500.000000 | iteration_561500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511910      | 6614.150698         | 6.614151             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2854.991223 | 614.726389 | 3507.066650 | 1922.850952 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:42:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1322.2054, current episode: 1
[2023-06-29 14:42:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1326.6410, current episode: 2
[2023-06-29 14:42:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1761.4445, current episode: 3
[2023-06-29 14:42:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1748.5210, current episode: 4
[2023-06-29 14:42:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1862.8005, current episode: 5
[2023-06-29 14:42:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2244.2283, current episode: 6
[2023-06-29 14:42:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2492.0479, current episode: 7
[2023-06-29 14:42:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2525.5171, current episode: 8
[2023-06-29 14:42:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2601.9004, current episode: 9
[2023-06-29 14:42:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1322.2054, current episode: 9
[2023-06-29 14:42:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2676.7666, current episode: 10
[2023-06-29 14:42:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 562000.000000 | iteration_562000.pth.tar | 10.000000     | 7190.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 719.000000              | 1.105087      | 6506.273421         | 9.049059             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2056.207263 | 491.774668 | 2676.766602 | 1322.205444 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:42:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1382.0574, current episode: 1
[2023-06-29 14:42:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1497.2743, current episode: 2
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2339.4109, current episode: 3
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2363.6460, current episode: 4
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2548.9495, current episode: 5
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2591.2292, current episode: 6
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2656.9358, current episode: 7
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1382.0574, current episode: 7
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1497.2743, current episode: 7
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2983.3540, current episode: 8
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3593.1704, current episode: 9
[2023-06-29 14:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3530.4065, current episode: 10
[2023-06-29 14:42:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 562500.000000 | iteration_562500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.511334      | 6616.672772         | 6.616673             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2548.643396 | 692.943857 | 3593.170410 | 1382.057373 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1048.8007, current episode: 1
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1080.8523, current episode: 2
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1085.6265, current episode: 3
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1130.2837, current episode: 4
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1289.8170, current episode: 5
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1355.9933, current episode: 6
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1478.8522, current episode: 7
[2023-06-29 14:42:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1570.2324, current episode: 8
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1609.4553, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1048.8007, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1080.8523, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1085.6265, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1130.2837, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1289.8170, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1355.9933, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1478.8522, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1570.2324, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1048.8007, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1609.4553, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1080.8523, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1085.6265, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1130.2837, current episode: 9
[2023-06-29 14:42:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.0327, current episode: 10
[2023-06-29 14:42:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 563000.000000 | iteration_563000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.695111      | 5899.320095         | 5.899320             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1514.694604 | 689.631545 | 3497.032715 | 1048.800659 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1097.8977, current episode: 1
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1117.1410, current episode: 2
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1231.0824, current episode: 3
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1302.2100, current episode: 4
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1333.4907, current episode: 5
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1588.1416, current episode: 6
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1735.4586, current episode: 7
[2023-06-29 14:42:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1868.0803, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1097.8977, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1117.1410, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1231.0824, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1302.2100, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1333.4907, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1588.1416, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1097.8977, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1117.1410, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1735.4586, current episode: 8
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3644.2571, current episode: 9
[2023-06-29 14:42:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3546.3564, current episode: 10
[2023-06-29 14:42:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 563500.000000 | iteration_563500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.578755      | 6334.104039         | 6.334104             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1846.411584 | 907.277592 | 3644.257080 | 1097.897705 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1056.0432, current episode: 1
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1120.5430, current episode: 2
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1238.6583, current episode: 3
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1327.2063, current episode: 4
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1630.8185, current episode: 5
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1512.4390, current episode: 6
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1652.9764, current episode: 7
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1889.1602, current episode: 8
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1848.4326, current episode: 9
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1056.0432, current episode: 9
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1120.5430, current episode: 9
[2023-06-29 14:43:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2332.6455, current episode: 10
[2023-06-29 14:43:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 564000.000000 | iteration_564000.pth.tar | 10.000000     | 6310.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 631.000000              | 0.963448      | 6549.396761         | 10.379393            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1560.892297 | 375.364241 | 2332.645508 | 1056.043213 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 576.5967, current episode: 1
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1237.6547, current episode: 2
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 576.5967, current episode: 2
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1616.8711, current episode: 3
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1642.0238, current episode: 4
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1503.0305, current episode: 5
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1906.0232, current episode: 6
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1832.8545, current episode: 7
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 576.5967, current episode: 7
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2307.0669, current episode: 8
[2023-06-29 14:43:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1237.6547, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 576.5967, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1616.8711, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1642.0238, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1503.0305, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 576.5967, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1237.6547, current episode: 8
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3520.8289, current episode: 9
[2023-06-29 14:43:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3525.1460, current episode: 10
[2023-06-29 14:43:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 564500.000000 | iteration_564500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.525433      | 6555.515259         | 6.555515             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1966.809625 | 888.155093 | 3525.145996 | 576.596741 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:43:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1159.6060, current episode: 1
[2023-06-29 14:43:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1357.2468, current episode: 2
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1333.8374, current episode: 3
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1190.0541, current episode: 4
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1408.1608, current episode: 5
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1505.1763, current episode: 6
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1663.5955, current episode: 7
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1845.8795, current episode: 8
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1159.6060, current episode: 8
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1357.2468, current episode: 8
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1333.8374, current episode: 8
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1190.0541, current episode: 8
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1408.1608, current episode: 8
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3027.9426, current episode: 9
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3153.3491, current episode: 10
[2023-06-29 14:43:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1505.1763, current episode: 10
[2023-06-29 14:43:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 565000.000000 | iteration_565000.pth.tar | 10.000000     | 9000.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 900.000000              | 1.384753      | 6499.355512         | 7.221506             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1764.484802 | 691.623474 | 3153.349121 | 1159.605957 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1330.8356, current episode: 1
[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1378.1010, current episode: 2
[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1447.3889, current episode: 3
[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1521.2283, current episode: 4
[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1647.4706, current episode: 5
[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1821.7661, current episode: 6
[2023-06-29 14:43:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2017.7573, current episode: 7
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1330.8356, current episode: 7
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1378.1010, current episode: 7
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1447.3889, current episode: 7
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2939.5095, current episode: 8
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1521.2283, current episode: 8
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3052.5273, current episode: 9
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1647.4706, current episode: 9
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1821.7661, current episode: 9
[2023-06-29 14:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3591.2168, current episode: 10
[2023-06-29 14:43:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 565500.000000 | iteration_565500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.571149      | 6364.767036         | 6.364767             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2074.780139 | 774.082852 | 3591.216797 | 1330.835571 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:44:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1387.8517, current episode: 1
[2023-06-29 14:44:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1529.6378, current episode: 2
[2023-06-29 14:44:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1506.7028, current episode: 3
[2023-06-29 14:44:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1927.2076, current episode: 4
[2023-06-29 14:44:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2146.8535, current episode: 5
[2023-06-29 14:44:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2348.3462, current episode: 6
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1387.8517, current episode: 6
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2991.4243, current episode: 7
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1529.6378, current episode: 7
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1506.7028, current episode: 7
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3424.9219, current episode: 8
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3610.4263, current episode: 9
[2023-06-29 14:44:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3523.8008, current episode: 10
[2023-06-29 14:44:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 566000.000000 | iteration_566000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.636020      | 6112.396009         | 6.112396             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2439.717285 | 835.629779 | 3610.426270 | 1387.851685 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1378.6069, current episode: 1
[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2239.4441, current episode: 2
[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2335.6187, current episode: 3
[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2697.0183, current episode: 4
[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1378.6069, current episode: 4
[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2798.2842, current episode: 5
[2023-06-29 14:44:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3324.6536, current episode: 6
[2023-06-29 14:44:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3487.6658, current episode: 7
[2023-06-29 14:44:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3455.4277, current episode: 8
[2023-06-29 14:44:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3566.4785, current episode: 9
[2023-06-29 14:44:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3511.0662, current episode: 10
[2023-06-29 14:44:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 566500.000000 | iteration_566500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.544463      | 6474.740765         | 6.474741             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2879.426392 | 690.549735 | 3566.478516 | 1378.606934 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:44:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1446.2286, current episode: 1
[2023-06-29 14:44:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1500.5067, current episode: 2
[2023-06-29 14:44:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1539.1124, current episode: 3
[2023-06-29 14:44:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1765.2404, current episode: 4
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1895.1138, current episode: 5
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2131.6624, current episode: 6
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2128.9065, current episode: 7
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2465.1233, current episode: 8
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2961.0371, current episode: 9
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1446.2286, current episode: 9
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1500.5067, current episode: 9
[2023-06-29 14:44:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3274.1528, current episode: 10
[2023-06-29 14:44:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 567000.000000 | iteration_567000.pth.tar | 10.000000     | 9050.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 905.000000              | 1.403061      | 6450.184372         | 7.127276             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2110.708398 | 592.408021 | 3274.152832 | 1446.228638 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 979.3680, current episode: 1
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 991.7281, current episode: 2
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 998.7244, current episode: 3
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1024.7163, current episode: 4
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1046.0048, current episode: 5
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1130.8511, current episode: 6
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1437.7939, current episode: 7
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1590.6656, current episode: 8
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 979.3680, current episode: 8
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 991.7281, current episode: 8
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 998.7244, current episode: 8
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1024.7163, current episode: 8
[2023-06-29 14:44:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1046.0048, current episode: 8
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1130.8511, current episode: 8
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1437.7939, current episode: 8
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 979.3680, current episode: 8
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 991.7281, current episode: 8
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 998.7244, current episode: 8
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3108.1609, current episode: 9
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1024.7163, current episode: 9
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1046.0048, current episode: 9
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1590.6656, current episode: 9
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1130.8511, current episode: 9
[2023-06-29 14:44:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3486.2852, current episode: 10
[2023-06-29 14:44:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 567500.000000 | iteration_567500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.616397      | 6186.600000         | 6.186600             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1579.429834 | 884.842438 | 3486.285156 | 979.368042 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 952.9840, current episode: 1
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 980.8235, current episode: 2
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 998.0381, current episode: 3
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1023.5872, current episode: 4
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1029.8488, current episode: 5
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1067.3175, current episode: 6
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1119.5135, current episode: 7
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1252.7192, current episode: 8
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 952.9840, current episode: 8
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 980.8235, current episode: 8
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1974.7986, current episode: 9
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 998.0381, current episode: 9
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1023.5872, current episode: 9
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1029.8488, current episode: 9
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1067.3175, current episode: 9
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1119.5135, current episode: 9
[2023-06-29 14:45:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1252.7192, current episode: 9
[2023-06-29 14:45:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 952.9840, current episode: 9
[2023-06-29 14:45:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 980.8235, current episode: 9
[2023-06-29 14:45:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 998.0381, current episode: 9
[2023-06-29 14:45:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3102.4883, current episode: 10
[2023-06-29 14:45:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 568000.000000 | iteration_568000.pth.tar | 10.000000     | 8530.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 853.000000              | 1.343152      | 6350.731575         | 7.445172             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1350.211871 | 650.455013 | 3102.488281 | 952.984009 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 594.1576, current episode: 1
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 805.9677, current episode: 2
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1028.7672, current episode: 3
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1020.5208, current episode: 4
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1073.5083, current episode: 5
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1382.4303, current episode: 6
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1393.2937, current episode: 7
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1415.9916, current episode: 8
[2023-06-29 14:45:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 594.1576, current episode: 8
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 805.9677, current episode: 8
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1839.6730, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1028.7672, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1020.5208, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1073.5083, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 594.1576, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 805.9677, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1382.4303, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1393.2937, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1415.9916, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 594.1576, current episode: 9
[2023-06-29 14:45:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3010.4548, current episode: 10
[2023-06-29 14:45:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 568500.000000 | iteration_568500.pth.tar | 10.000000     | 8330.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 833.000000              | 1.295324      | 6430.821793         | 7.720074             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1356.476501 | 644.919759 | 3010.454834 | 594.157593 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1042.8248, current episode: 1
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1055.9990, current episode: 2
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1083.4845, current episode: 3
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1078.9332, current episode: 4
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1165.6841, current episode: 5
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1197.0311, current episode: 6
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1254.4692, current episode: 7
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1289.3938, current episode: 8
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1665.0273, current episode: 9
[2023-06-29 14:45:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2182.0073, current episode: 10
[2023-06-29 14:45:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 569000.000000 | iteration_569000.pth.tar | 10.000000     | 5800.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 580.000000              | 0.918691      | 6313.327806         | 10.885048            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1301.485449 | 341.088513 | 2182.007324 | 1042.824829 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 814.8107, current episode: 1
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1155.4343, current episode: 2
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.1827, current episode: 3
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1225.3986, current episode: 4
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1231.9741, current episode: 5
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1282.2017, current episode: 6
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1554.2410, current episode: 7
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 814.8107, current episode: 7
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1982.5520, current episode: 8
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1989.9922, current episode: 9
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1155.4343, current episode: 9
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.1827, current episode: 9
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1225.3986, current episode: 9
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1231.9741, current episode: 9
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 814.8107, current episode: 9
[2023-06-29 14:45:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1282.2017, current episode: 9
[2023-06-29 14:45:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1554.2410, current episode: 9
[2023-06-29 14:45:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3187.9871, current episode: 10
[2023-06-29 14:45:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 569500.000000 | iteration_569500.pth.tar | 10.000000     | 8710.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 871.000000              | 1.353299      | 6436.122948         | 7.389349             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1562.177435 | 645.067354 | 3187.987061 | 814.810730 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:46:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1298.2855, current episode: 1
[2023-06-29 14:46:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1314.2242, current episode: 2
[2023-06-29 14:46:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1556.8286, current episode: 3
[2023-06-29 14:46:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1680.9604, current episode: 4
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1923.6471, current episode: 5
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2041.2023, current episode: 6
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2118.4255, current episode: 7
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2204.5017, current episode: 8
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1298.2855, current episode: 8
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1314.2242, current episode: 8
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3000.2786, current episode: 9
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1556.8286, current episode: 9
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1680.9604, current episode: 9
[2023-06-29 14:46:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3494.5439, current episode: 10
[2023-06-29 14:46:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 570000.000000 | iteration_570000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.542135      | 6484.514501         | 6.484515             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2063.289795 | 672.191527 | 3494.543945 | 1298.285522 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:46:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1127.2222, current episode: 1
[2023-06-29 14:46:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1152.0786, current episode: 2
[2023-06-29 14:46:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1209.1741, current episode: 3
[2023-06-29 14:46:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1249.0155, current episode: 4
[2023-06-29 14:46:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1318.8029, current episode: 5
[2023-06-29 14:46:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1345.0648, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1127.2222, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1152.0786, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1209.1741, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1249.0155, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1318.8029, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1345.0648, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1127.2222, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1152.0786, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1209.1741, current episode: 6
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3495.4268, current episode: 7
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3513.6379, current episode: 8
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3487.9856, current episode: 9
[2023-06-29 14:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3433.6228, current episode: 10
[2023-06-29 14:46:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 570500.000000 | iteration_570500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.550863      | 6448.023164         | 6.448023             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2133.203113 | 1103.739580 | 3513.637939 | 1127.222168 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1243.3350, current episode: 1
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1273.3405, current episode: 2
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1434.9995, current episode: 3
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1449.8302, current episode: 4
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1687.2009, current episode: 5
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1819.5475, current episode: 6
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1948.6578, current episode: 7
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1966.8877, current episode: 8
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1243.3350, current episode: 8
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1273.3405, current episode: 8
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2577.6001, current episode: 9
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1434.9995, current episode: 9
[2023-06-29 14:46:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1449.8302, current episode: 9
[2023-06-29 14:46:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1687.2009, current episode: 9
[2023-06-29 14:46:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1819.5475, current episode: 9
[2023-06-29 14:46:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3637.6138, current episode: 10
[2023-06-29 14:46:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 571000.000000 | iteration_571000.pth.tar | 10.000000     | 9880.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 988.000000              | 1.542219      | 6406.352960         | 6.484163             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1903.901294 | 691.352180 | 3637.613770 | 1243.334961 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:46:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1309.2172, current episode: 1
[2023-06-29 14:46:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1330.7515, current episode: 2
[2023-06-29 14:46:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1549.1375, current episode: 3
[2023-06-29 14:46:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1638.0243, current episode: 4
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2087.4507, current episode: 5
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1309.2172, current episode: 5
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1330.7515, current episode: 5
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2805.7871, current episode: 6
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1549.1375, current episode: 6
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1638.0243, current episode: 6
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3510.1018, current episode: 7
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3458.5500, current episode: 8
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3498.2910, current episode: 9
[2023-06-29 14:46:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3563.7405, current episode: 10
[2023-06-29 14:46:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 571500.000000 | iteration_571500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.530159      | 6535.268311         | 6.535268             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2475.105151 | 935.788725 | 3563.740479 | 1309.217163 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 578.7192, current episode: 1
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 579.1920, current episode: 2
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1049.0967, current episode: 3
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1170.9775, current episode: 4
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1196.9814, current episode: 5
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1318.6729, current episode: 6
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1340.6425, current episode: 7
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1347.6344, current episode: 8
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1389.0964, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 578.7192, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 579.1920, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1049.0967, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 578.7192, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 579.1920, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1170.9775, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1196.9814, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1318.6729, current episode: 9
[2023-06-29 14:47:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1340.6425, current episode: 9
[2023-06-29 14:47:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1347.6344, current episode: 9
[2023-06-29 14:47:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1389.0964, current episode: 9
[2023-06-29 14:47:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 578.7192, current episode: 9
[2023-06-29 14:47:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 579.1920, current episode: 9
[2023-06-29 14:47:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1049.0967, current episode: 9
[2023-06-29 14:47:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3061.9109, current episode: 10
[2023-06-29 14:47:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 572000.000000 | iteration_572000.pth.tar | 10.000000     | 8900.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 890.000000              | 1.404168      | 6338.271401         | 7.121653             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1303.292383 | 651.648036 | 3061.910889 | 578.719177 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:47:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1261.4091, current episode: 1
[2023-06-29 14:47:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1338.4521, current episode: 2
[2023-06-29 14:47:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1415.4629, current episode: 3
[2023-06-29 14:47:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1646.5543, current episode: 4
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1261.4091, current episode: 4
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1338.4521, current episode: 4
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1415.4629, current episode: 4
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1646.5543, current episode: 4
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3503.5063, current episode: 5
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3515.8296, current episode: 6
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3497.1650, current episode: 7
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3560.0664, current episode: 8
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3501.8000, current episode: 9
[2023-06-29 14:47:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3471.6953, current episode: 10
[2023-06-29 14:47:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 572500.000000 | iteration_572500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.483979      | 6738.640369         | 6.738640             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2671.194116 | 1029.544837 | 3560.066406 | 1261.409058 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.4192, current episode: 1
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1182.3796, current episode: 2
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1194.5844, current episode: 3
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1227.9944, current episode: 4
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1321.5020, current episode: 5
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1332.5005, current episode: 6
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1368.0021, current episode: 7
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1993.9755, current episode: 8
[2023-06-29 14:47:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.4192, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1182.3796, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1194.5844, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1227.9944, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1321.5020, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1332.5005, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1368.0021, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1069.4192, current episode: 8
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3567.5200, current episode: 9
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1182.3796, current episode: 9
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1194.5844, current episode: 9
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1227.9944, current episode: 9
[2023-06-29 14:47:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3487.8726, current episode: 10
[2023-06-29 14:47:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 573000.000000 | iteration_573000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.516723      | 6593.161076         | 6.593161             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1774.575012 | 908.144433 | 3567.520020 | 1069.419189 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1411.5576, current episode: 1
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1789.5732, current episode: 2
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2027.4236, current episode: 3
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2226.9524, current episode: 4
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2227.8582, current episode: 5
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2277.8608, current episode: 6
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1411.5576, current episode: 6
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2922.6492, current episode: 7
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3560.0676, current episode: 8
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1789.5732, current episode: 8
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3534.2712, current episode: 9
[2023-06-29 14:48:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3493.6633, current episode: 10
[2023-06-29 14:48:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 573500.000000 | iteration_573500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.502817      | 6654.169521         | 6.654170             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2547.187720 | 738.098649 | 3560.067627 | 1411.557617 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:48:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1344.7511, current episode: 1
[2023-06-29 14:48:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1376.0359, current episode: 2
[2023-06-29 14:48:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1354.5073, current episode: 3
[2023-06-29 14:48:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1471.4420, current episode: 4
[2023-06-29 14:48:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1914.8823, current episode: 5
[2023-06-29 14:48:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2046.6624, current episode: 6
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2390.0198, current episode: 7
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2485.1768, current episode: 8
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1344.7511, current episode: 8
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1376.0359, current episode: 8
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1354.5073, current episode: 8
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1471.4420, current episode: 8
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3455.4824, current episode: 9
[2023-06-29 14:48:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3554.3713, current episode: 10
[2023-06-29 14:48:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 574000.000000 | iteration_574000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.507765      | 6632.332150         | 6.632332             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2139.333130 | 790.696725 | 3554.371338 | 1344.751099 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:48:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1368.6074, current episode: 1
[2023-06-29 14:48:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1384.7604, current episode: 2
[2023-06-29 14:48:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1462.3413, current episode: 3
[2023-06-29 14:48:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1649.5331, current episode: 4
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1839.7076, current episode: 5
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2544.2034, current episode: 6
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1368.6074, current episode: 6
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1384.7604, current episode: 6
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1462.3413, current episode: 6
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3165.4719, current episode: 7
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1649.5331, current episode: 7
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3482.7634, current episode: 8
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1839.7076, current episode: 8
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3506.8042, current episode: 9
[2023-06-29 14:48:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3645.8208, current episode: 10
[2023-06-29 14:48:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 574500.000000 | iteration_574500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509289      | 6625.637643         | 6.625638             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2405.001355 | 916.884261 | 3645.820801 | 1368.607422 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:48:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 890.2695, current episode: 1
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1018.9797, current episode: 2
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1098.6429, current episode: 3
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1197.9238, current episode: 4
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1342.7357, current episode: 5
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1361.1877, current episode: 6
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1409.3529, current episode: 7
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 890.2695, current episode: 7
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1960.6804, current episode: 8
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1018.9797, current episode: 8
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1098.6429, current episode: 8
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1197.9238, current episode: 8
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2477.0967, current episode: 9
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1342.7357, current episode: 9
[2023-06-29 14:48:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2737.8567, current episode: 10
[2023-06-29 14:48:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 575000.000000 | iteration_575000.pth.tar | 10.000000     | 7320.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 732.000000              | 1.122365      | 6521.943981         | 8.909760             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1549.472614 | 598.536987 | 2737.856689 | 890.269531 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 710.0477, current episode: 1
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1055.9564, current episode: 2
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1147.5856, current episode: 3
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1168.2262, current episode: 4
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1306.2040, current episode: 5
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 710.0477, current episode: 5
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1538.6632, current episode: 6
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1640.2103, current episode: 7
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1685.8212, current episode: 8
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1055.9564, current episode: 8
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 710.0477, current episode: 8
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1147.5856, current episode: 8
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1168.2262, current episode: 8
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2438.4429, current episode: 9
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1306.2040, current episode: 9
[2023-06-29 14:49:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 710.0477, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1538.6632, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1640.2103, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1055.9564, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1685.8212, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1147.5856, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1168.2262, current episode: 9
[2023-06-29 14:49:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3521.2039, current episode: 10
[2023-06-29 14:49:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 575500.000000 | iteration_575500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.571734      | 6362.397732         | 6.362398             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1621.236133 | 772.506784 | 3521.203857 | 710.047729 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:49:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1001.4837, current episode: 1
[2023-06-29 14:49:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1119.1857, current episode: 2
[2023-06-29 14:49:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1156.8037, current episode: 3
[2023-06-29 14:49:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1220.8505, current episode: 4
[2023-06-29 14:49:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1235.8193, current episode: 5
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1315.5948, current episode: 6
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1443.8711, current episode: 7
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1608.9222, current episode: 8
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1677.3988, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1001.4837, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1119.1857, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1156.8037, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1220.8505, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1235.8193, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1315.5948, current episode: 9
[2023-06-29 14:49:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2648.8342, current episode: 10
[2023-06-29 14:49:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 576000.000000 | iteration_576000.pth.tar | 10.000000     | 7130.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 713.000000              | 1.115602      | 6391.167186         | 8.963769             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1442.876410 | 450.190712 | 2648.834229 | 1001.483704 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:49:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.3494, current episode: 1
[2023-06-29 14:49:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1203.0955, current episode: 2
[2023-06-29 14:49:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1239.8737, current episode: 3
[2023-06-29 14:49:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1319.3774, current episode: 4
[2023-06-29 14:49:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1338.7500, current episode: 5
[2023-06-29 14:49:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1355.9492, current episode: 6
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2275.9189, current episode: 7
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.3494, current episode: 7
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1203.0955, current episode: 7
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2513.2712, current episode: 8
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1239.8737, current episode: 8
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1319.3774, current episode: 8
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1338.7500, current episode: 8
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1355.9492, current episode: 8
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3113.8459, current episode: 9
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1197.3494, current episode: 9
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1203.0955, current episode: 9
[2023-06-29 14:49:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3651.3762, current episode: 10
[2023-06-29 14:49:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 576500.000000 | iteration_576500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.518696      | 6584.595535         | 6.584596             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1920.880750 | 861.224319 | 3651.376221 | 1197.349365 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 542.9938, current episode: 1
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 633.3455, current episode: 2
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 688.4521, current episode: 3
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 995.8722, current episode: 4
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.0808, current episode: 5
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 542.9938, current episode: 5
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1330.8550, current episode: 6
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1328.9896, current episode: 7
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1343.9562, current episode: 8
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1352.3873, current episode: 9
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 633.3455, current episode: 9
[2023-06-29 14:49:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 688.4521, current episode: 9
[2023-06-29 14:49:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 542.9938, current episode: 9
[2023-06-29 14:49:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1944.2596, current episode: 10
[2023-06-29 14:49:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 577000.000000 | iteration_577000.pth.tar | 10.000000     | 5170.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 517.000000              | 0.823582      | 6277.454183         | 12.142078            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1117.619214 | 406.701626 | 1944.259644 | 542.993774 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1159.1990, current episode: 1
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1183.9242, current episode: 2
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1291.3909, current episode: 3
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.5178, current episode: 4
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1307.9816, current episode: 5
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1320.7008, current episode: 6
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1331.2286, current episode: 7
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1335.1384, current episode: 8
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1333.8402, current episode: 9
[2023-06-29 14:50:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1473.3834, current episode: 10
[2023-06-29 14:50:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 577500.000000 | iteration_577500.pth.tar | 10.000000     | 3980.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 398.000000              | 0.628393      | 6333.620932         | 15.913620            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1302.130493 | 82.143827  | 1473.383423 | 1159.198975 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:50:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1084.8021, current episode: 1
[2023-06-29 14:50:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1112.0220, current episode: 2
[2023-06-29 14:50:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1154.3029, current episode: 3
[2023-06-29 14:50:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1169.4719, current episode: 4
[2023-06-29 14:50:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1153.7838, current episode: 5
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1288.7247, current episode: 6
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1328.1571, current episode: 7
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1640.4021, current episode: 8
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1982.9340, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1084.8021, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1112.0220, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1154.3029, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1169.4719, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1153.7838, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1288.7247, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1328.1571, current episode: 9
[2023-06-29 14:50:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2916.0002, current episode: 10
[2023-06-29 14:50:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 578000.000000 | iteration_578000.pth.tar | 10.000000     | 7990.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 799.000000              | 1.218818      | 6555.530394         | 8.204669             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1483.060083 | 547.798271 | 2916.000244 | 1084.802124 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1002.2343, current episode: 1
[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1072.3459, current episode: 2
[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1104.1997, current episode: 3
[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1222.2007, current episode: 4
[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1302.8994, current episode: 5
[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1373.0568, current episode: 6
[2023-06-29 14:50:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1641.1671, current episode: 7
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1002.2343, current episode: 7
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1072.3459, current episode: 7
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1104.1997, current episode: 7
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1222.2007, current episode: 7
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1302.8994, current episode: 7
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2905.4077, current episode: 8
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1373.0568, current episode: 8
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2963.3115, current episode: 9
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1002.2343, current episode: 9
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1641.1671, current episode: 9
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1072.3459, current episode: 9
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1104.1997, current episode: 9
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1222.2007, current episode: 9
[2023-06-29 14:50:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3520.1777, current episode: 10
[2023-06-29 14:50:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 578500.000000 | iteration_578500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535935      | 6510.690384         | 6.510690             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1810.700092 | 892.838420 | 3520.177734 | 1002.234314 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1246.7953, current episode: 1
[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.6006, current episode: 2
[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1291.0808, current episode: 3
[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1309.0846, current episode: 4
[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1328.2100, current episode: 5
[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1401.0089, current episode: 6
[2023-06-29 14:50:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1449.0292, current episode: 7
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2116.2620, current episode: 8
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2272.5220, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1246.7953, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.6006, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1291.0808, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1309.0846, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1328.2100, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1401.0089, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1449.0292, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1246.7953, current episode: 9
[2023-06-29 14:50:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3536.7146, current episode: 10
[2023-06-29 14:50:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 579000.000000 | iteration_579000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.557835      | 6419.164214         | 6.419164             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1723.530786 | 696.966984 | 3536.714600 | 1246.795288 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1073.7102, current episode: 1
[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1285.9440, current episode: 2
[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1352.2166, current episode: 3
[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1383.1211, current episode: 4
[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1920.0773, current episode: 5
[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1972.1350, current episode: 6
[2023-06-29 14:51:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1073.7102, current episode: 6
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2427.2876, current episode: 7
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1285.9440, current episode: 7
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2674.7771, current episode: 8
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1352.2166, current episode: 8
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1383.1211, current episode: 8
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1073.7102, current episode: 8
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3659.3762, current episode: 9
[2023-06-29 14:51:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3546.3413, current episode: 10
[2023-06-29 14:51:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 579500.000000 | iteration_579500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.542121      | 6484.576097         | 6.484576             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2129.498633 | 882.616374 | 3659.376221 | 1073.710205 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 957.0423, current episode: 1
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1023.3405, current episode: 2
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1119.0446, current episode: 3
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1200.1829, current episode: 4
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1211.7567, current episode: 5
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1190.7408, current episode: 6
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1583.7665, current episode: 7
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1624.9957, current episode: 8
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 957.0423, current episode: 8
[2023-06-29 14:51:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1023.3405, current episode: 8
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2264.0688, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1119.0446, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1200.1829, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1211.7567, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1190.7408, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 957.0423, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1583.7665, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1624.9957, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1023.3405, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1119.0446, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1200.1829, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1211.7567, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1190.7408, current episode: 9
[2023-06-29 14:51:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3517.8010, current episode: 10
[2023-06-29 14:51:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 580000.000000 | iteration_580000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.530195      | 6535.115556         | 6.535116             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1569.273981 | 746.037819 | 3517.801025 | 957.042297 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 988.2668, current episode: 1
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 995.1216, current episode: 2
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1007.1364, current episode: 3
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1131.6816, current episode: 4
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1192.3176, current episode: 5
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1243.0312, current episode: 6
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1270.8518, current episode: 7
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1386.2542, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 988.2668, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 995.1216, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1007.1364, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1131.6816, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1192.3176, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1243.0312, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1270.8518, current episode: 8
[2023-06-29 14:51:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1386.2542, current episode: 8
[2023-06-29 14:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2981.5515, current episode: 9
[2023-06-29 14:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 988.2668, current episode: 9
[2023-06-29 14:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 995.1216, current episode: 9
[2023-06-29 14:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1007.1364, current episode: 9
[2023-06-29 14:51:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3206.4546, current episode: 10
[2023-06-29 14:51:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 580500.000000 | iteration_580500.pth.tar | 10.000000     | 8710.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 871.000000              | 1.418280      | 6141.242434         | 7.050795             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1540.266742 | 788.179067 | 3206.454590 | 988.266846 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1097.4685, current episode: 1
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1091.9750, current episode: 2
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.5616, current episode: 3
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1155.3682, current episode: 4
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1210.1027, current episode: 5
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1199.6444, current episode: 6
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1275.3291, current episode: 7
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1331.0718, current episode: 8
[2023-06-29 14:51:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1622.3688, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1097.4685, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1091.9750, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.5616, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1155.3682, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1210.1027, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1199.6444, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1275.3291, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1331.0718, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1622.3688, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1097.4685, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1091.9750, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.5616, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1155.3682, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1210.1027, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1199.6444, current episode: 9
[2023-06-29 14:51:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3548.4409, current episode: 10
[2023-06-29 14:51:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 581000.000000 | iteration_581000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.558519      | 6416.348153         | 6.416348             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1468.433093 | 708.688074 | 3548.440918 | 1091.974976 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1062.4069, current episode: 1
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1063.0137, current episode: 2
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.7378, current episode: 3
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1214.2046, current episode: 4
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1212.9532, current episode: 5
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1234.8059, current episode: 6
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1303.7140, current episode: 7
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1578.3799, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1062.4069, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1063.0137, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.7378, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1214.2046, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1212.9532, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1234.8059, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1303.7140, current episode: 8
[2023-06-29 14:52:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1578.3799, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1062.4069, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1063.0137, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1186.7378, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1214.2046, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1212.9532, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1234.8059, current episode: 8
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3495.9622, current episode: 9
[2023-06-29 14:52:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3492.5049, current episode: 10
[2023-06-29 14:52:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 581500.000000 | iteration_581500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.636197      | 6111.733865         | 6.111734             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1684.468298 | 915.057785 | 3495.962158 | 1062.406860 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1104.4072, current episode: 1
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1234.3376, current episode: 2
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1481.7020, current episode: 3
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1427.6226, current episode: 4
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1667.8141, current episode: 5
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1104.4072, current episode: 5
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2286.2117, current episode: 6
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1234.3376, current episode: 6
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1481.7020, current episode: 6
[2023-06-29 14:52:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1427.6226, current episode: 6
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1667.8141, current episode: 6
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1104.4072, current episode: 6
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3572.8411, current episode: 7
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1234.3376, current episode: 7
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3515.0784, current episode: 8
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3500.6135, current episode: 9
[2023-06-29 14:52:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3493.9177, current episode: 10
[2023-06-29 14:52:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 582000.000000 | iteration_582000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.543165      | 6480.188280         | 6.480188             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2328.454590 | 1017.395548 | 3572.841064 | 1104.407227 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 991.6218, current episode: 1
[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.5389, current episode: 2
[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1345.5007, current episode: 3
[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1346.2726, current episode: 4
[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1343.6869, current episode: 5
[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1428.1760, current episode: 6
[2023-06-29 14:52:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1561.6787, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 991.6218, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.5389, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1345.5007, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1346.2726, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1343.6869, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1428.1760, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 991.6218, current episode: 7
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3099.4500, current episode: 8
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1561.6787, current episode: 8
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1227.5389, current episode: 8
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3530.6145, current episode: 9
[2023-06-29 14:52:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3574.8782, current episode: 10
[2023-06-29 14:52:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 582500.000000 | iteration_582500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.572522      | 6359.211619         | 6.359212             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1944.941833 | 970.597999 | 3574.878174 | 991.621826 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:52:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1097.0079, current episode: 1
[2023-06-29 14:52:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1337.1442, current episode: 2
[2023-06-29 14:52:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1353.6658, current episode: 3
[2023-06-29 14:52:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1355.7700, current episode: 4
[2023-06-29 14:52:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1367.2452, current episode: 5
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1408.7805, current episode: 6
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1517.1730, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1097.0079, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1337.1442, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1353.6658, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1355.7700, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1367.2452, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1408.7805, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1517.1730, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1097.0079, current episode: 7
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3515.6763, current episode: 8
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3443.9656, current episode: 9
[2023-06-29 14:52:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3508.1008, current episode: 10
[2023-06-29 14:52:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 583000.000000 | iteration_583000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.557314      | 6421.313242         | 6.421313             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1990.452930 | 986.223176 | 3515.676270 | 1097.007935 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 971.3952, current episode: 1
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1025.1233, current episode: 2
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1150.5969, current episode: 3
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1424.0450, current episode: 4
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1546.0245, current episode: 5
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1628.7704, current episode: 6
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1728.0983, current episode: 7
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1926.8411, current episode: 8
[2023-06-29 14:53:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 971.3952, current episode: 8
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1025.1233, current episode: 8
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2306.3557, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1150.5969, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1424.0450, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1546.0245, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 971.3952, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1025.1233, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1628.7704, current episode: 9
[2023-06-29 14:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3340.6738, current episode: 10
[2023-06-29 14:53:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 583500.000000 | iteration_583500.pth.tar | 10.000000     | 9050.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 905.000000              | 1.367403      | 6618.386176         | 7.313134             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1704.792426 | 671.162802 | 3340.673828 | 971.395203 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:53:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1103.9762, current episode: 1
[2023-06-29 14:53:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1131.6344, current episode: 2
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1470.1738, current episode: 3
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1633.2101, current episode: 4
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1745.3212, current episode: 5
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1966.4520, current episode: 6
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2141.9805, current episode: 7
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2208.2334, current episode: 8
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1103.9762, current episode: 8
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1131.6344, current episode: 8
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2886.3164, current episode: 9
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1470.1738, current episode: 9
[2023-06-29 14:53:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3142.2263, current episode: 10
[2023-06-29 14:53:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 584000.000000 | iteration_584000.pth.tar | 10.000000     | 8530.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 853.000000              | 1.307922      | 6521.795048         | 7.645715             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1942.952429 | 644.931620 | 3142.226318 | 1103.976196 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1003.0512, current episode: 1
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1324.8322, current episode: 2
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1361.9299, current episode: 3
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1391.7704, current episode: 4
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2093.6069, current episode: 5
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2007.0522, current episode: 6
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1003.0512, current episode: 6
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1324.8322, current episode: 6
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2690.0266, current episode: 7
[2023-06-29 14:53:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1361.9299, current episode: 7
[2023-06-29 14:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2711.9639, current episode: 8
[2023-06-29 14:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1391.7704, current episode: 8
[2023-06-29 14:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1003.0512, current episode: 8
[2023-06-29 14:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3303.6240, current episode: 9
[2023-06-29 14:53:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3498.0664, current episode: 10
[2023-06-29 14:53:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 584500.000000 | iteration_584500.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.537477      | 6503.513257         | 6.504164             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2138.592377 | 834.879425 | 3498.066406 | 1003.051208 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1195.8010, current episode: 1
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1221.2747, current episode: 2
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1248.5182, current episode: 3
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1294.9070, current episode: 4
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1367.4344, current episode: 5
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1845.3187, current episode: 6
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2008.0757, current episode: 7
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1195.8010, current episode: 7
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1221.2747, current episode: 7
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1248.5182, current episode: 7
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1294.9070, current episode: 7
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2582.1099, current episode: 8
[2023-06-29 14:53:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1367.4344, current episode: 8
[2023-06-29 14:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1195.8010, current episode: 8
[2023-06-29 14:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1221.2747, current episode: 8
[2023-06-29 14:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3640.2070, current episode: 9
[2023-06-29 14:53:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3519.9626, current episode: 10
[2023-06-29 14:53:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 585000.000000 | iteration_585000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.555283      | 6429.696659         | 6.429697             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1992.360925 | 898.776658 | 3640.207031 | 1195.801025 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 1
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 1
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 1
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 1
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1012.2526, current episode: 2
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 2
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1348.8252, current episode: 3
[2023-06-29 14:54:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 3
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 3
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1851.3162, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1012.2526, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1348.8252, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1012.2526, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 125.6746, current episode: 4
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3531.4341, current episode: 5
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3513.5288, current episode: 6
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3502.2283, current episode: 7
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3517.1121, current episode: 8
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3426.9207, current episode: 9
[2023-06-29 14:54:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3489.9656, current episode: 10
[2023-06-29 14:54:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 585500.000000 | iteration_585500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.760043      | 5681.678287         | 5.681678             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2531.925793 | 1247.233115 | 3531.434082 | 125.674561 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1251.1827, current episode: 1
[2023-06-29 14:54:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1251.1827, current episode: 1
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3502.5862, current episode: 2
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3523.2156, current episode: 3
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3507.9121, current episode: 4
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3465.8801, current episode: 5
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3512.2900, current episode: 6
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3527.9421, current episode: 7
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3451.4553, current episode: 8
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3488.8660, current episode: 9
[2023-06-29 14:54:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3523.7095, current episode: 10
[2023-06-29 14:54:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 586000.000000 | iteration_586000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.521244      | 6573.568397         | 6.573568             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3275.503967 | 675.199326 | 3527.942139 | 1251.182739 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3202.5203, current episode: 1
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3507.1680, current episode: 2
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3516.0945, current episode: 3
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3500.9429, current episode: 4
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3526.5684, current episode: 5
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3512.2178, current episode: 6
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3516.5569, current episode: 7
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3501.4209, current episode: 8
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3483.6997, current episode: 9
[2023-06-29 14:54:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3487.1204, current episode: 10
[2023-06-29 14:54:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 586500.000000 | iteration_586500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.545065      | 6472.218327         | 6.472218             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3475.430957 | 91.832457  | 3526.568359 | 3202.520264 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1311.5449, current episode: 1
[2023-06-29 14:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1346.8348, current episode: 2
[2023-06-29 14:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1348.5175, current episode: 3
[2023-06-29 14:54:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1378.3660, current episode: 4
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1311.5449, current episode: 4
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1346.8348, current episode: 4
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1348.5175, current episode: 4
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1378.3660, current episode: 4
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3527.4480, current episode: 5
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3558.6345, current episode: 6
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3470.9656, current episode: 7
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3521.6733, current episode: 8
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3522.8384, current episode: 9
[2023-06-29 14:55:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3535.0996, current episode: 10
[2023-06-29 14:55:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 587000.000000 | iteration_587000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.600179      | 6249.299128         | 6.249299             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2652.192261 | 1066.543109 | 3558.634521 | 1311.544922 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1283.8687, current episode: 1
[2023-06-29 14:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1350.0170, current episode: 2
[2023-06-29 14:55:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1512.3132, current episode: 3
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1283.8687, current episode: 3
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1350.0170, current episode: 3
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2646.0391, current episode: 4
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1512.3132, current episode: 4
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3524.8782, current episode: 5
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3529.0747, current episode: 6
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3506.6958, current episode: 7
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3516.3193, current episode: 8
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3538.0457, current episode: 9
[2023-06-29 14:55:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3529.6375, current episode: 10
[2023-06-29 14:55:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 587500.000000 | iteration_587500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.548425      | 6458.175548         | 6.458176             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2793.688904 | 960.685213 | 3538.045654 | 1283.868652 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 472.0410, current episode: 1
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 511.6888, current episode: 2
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 587.7535, current episode: 3
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 609.2922, current episode: 4
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 641.2628, current episode: 5
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 472.0410, current episode: 5
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 511.6888, current episode: 5
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 587.7535, current episode: 5
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 609.2922, current episode: 5
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 641.2628, current episode: 5
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1341.4583, current episode: 6
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1440.3765, current episode: 7
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1498.8110, current episode: 8
[2023-06-29 14:55:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 472.0410, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 511.6888, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 587.7535, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 609.2922, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 641.2628, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 472.0410, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 511.6888, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 587.7535, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 609.2922, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 472.0410, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 641.2628, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1341.4583, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 511.6888, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1440.3765, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1498.8110, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 587.7535, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 472.0410, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 609.2922, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 511.6888, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 641.2628, current episode: 8
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3530.6892, current episode: 9
[2023-06-29 14:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3541.0974, current episode: 10
[2023-06-29 14:55:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 588000.000000 | iteration_588000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.574297      | 6352.041097         | 6.352041             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1417.447064 | 1124.578221 | 3541.097412 | 472.040955 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.0043, current episode: 1
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.6167, current episode: 2
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1366.7615, current episode: 3
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1472.9034, current episode: 4
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.0043, current episode: 4
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.6167, current episode: 4
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1366.7615, current episode: 4
[2023-06-29 14:55:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1472.9034, current episode: 4
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1015.0043, current episode: 4
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1061.6167, current episode: 4
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3445.7671, current episode: 5
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3512.0735, current episode: 6
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3540.7410, current episode: 7
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3492.0864, current episode: 8
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3489.6619, current episode: 9
[2023-06-29 14:55:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.2417, current episode: 10
[2023-06-29 14:55:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 588500.000000 | iteration_588500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.531323      | 6530.301452         | 6.530301             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2592.585748 | 1120.379792 | 3540.740967 | 1015.004333 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1124.6616, current episode: 1
[2023-06-29 14:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1243.8167, current episode: 2
[2023-06-29 14:56:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1315.4336, current episode: 3
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1124.6616, current episode: 3
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2297.2385, current episode: 4
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1243.8167, current episode: 4
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1315.4336, current episode: 4
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2814.4333, current episode: 5
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3150.8586, current episode: 6
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3310.2463, current episode: 7
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3363.3250, current episode: 8
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1124.6616, current episode: 8
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1243.8167, current episode: 8
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3540.0225, current episode: 9
[2023-06-29 14:56:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3545.0188, current episode: 10
[2023-06-29 14:56:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 589000.000000 | iteration_589000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.560056      | 6410.028189         | 6.410028             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2570.505493 | 946.687764 | 3545.018799 | 1124.661621 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 772.6782, current episode: 1
[2023-06-29 14:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1424.7489, current episode: 2
[2023-06-29 14:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 772.6782, current episode: 2
[2023-06-29 14:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1643.4183, current episode: 3
[2023-06-29 14:56:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 772.6782, current episode: 3
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1424.7489, current episode: 3
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2737.5903, current episode: 4
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 772.6782, current episode: 4
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1643.4183, current episode: 4
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3491.2988, current episode: 5
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3500.9346, current episode: 6
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3456.8550, current episode: 7
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3479.1128, current episode: 8
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3498.8330, current episode: 9
[2023-06-29 14:56:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3486.9441, current episode: 10
[2023-06-29 14:56:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 589500.000000 | iteration_589500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505379      | 6642.845298         | 6.642845             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2749.241400 | 1006.939766 | 3500.934570 | 772.678162 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 14:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1034.9812, current episode: 1
[2023-06-29 14:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1075.7987, current episode: 2
[2023-06-29 14:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1144.7665, current episode: 3
[2023-06-29 14:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1375.7905, current episode: 4
[2023-06-29 14:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1529.9379, current episode: 5
[2023-06-29 14:56:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1670.9037, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1034.9812, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1075.7987, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1144.7665, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1375.7905, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1529.9379, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1034.9812, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1075.7987, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1670.9037, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1144.7665, current episode: 6
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3492.4905, current episode: 7
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3439.0330, current episode: 8
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3514.2766, current episode: 9
[2023-06-29 14:56:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3487.4253, current episode: 10
[2023-06-29 14:56:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 590000.000000 | iteration_590000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.547211      | 6463.243851         | 6.463244             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2176.540381 | 1082.953380 | 3514.276611 | 1034.981201 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 14:56:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.5270, current episode: 1
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1032.9022, current episode: 2
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1076.1808, current episode: 3
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1228.6909, current episode: 4
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.5270, current episode: 4
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2097.5798, current episode: 5
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2111.2200, current episode: 6
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1032.9022, current episode: 6
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1076.1808, current episode: 6
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.5270, current episode: 6
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2380.3801, current episode: 7
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1228.6909, current episode: 7
[2023-06-29 14:56:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.5270, current episode: 7
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1032.9022, current episode: 7
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1076.1808, current episode: 7
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3282.6760, current episode: 8
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3197.1980, current episode: 9
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 657.5270, current episode: 9
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1228.6909, current episode: 9
[2023-06-29 14:56:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3534.9741, current episode: 10
[2023-06-29 14:56:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 590500.000000 | iteration_590500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.555075      | 6430.556194         | 6.430556             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2059.932904 | 987.482608 | 3534.974121 | 657.527039 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:57:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 564.5103, current episode: 1
[2023-06-29 14:57:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1011.1524, current episode: 2
[2023-06-29 14:57:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1166.6537, current episode: 3
[2023-06-29 14:57:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 564.5103, current episode: 3
[2023-06-29 14:57:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1843.1064, current episode: 4
[2023-06-29 14:57:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 564.5103, current episode: 4
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1011.1524, current episode: 4
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2036.1519, current episode: 5
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1166.6537, current episode: 5
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 564.5103, current episode: 5
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2592.5972, current episode: 6
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2817.6401, current episode: 7
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2995.6230, current episode: 8
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3063.4077, current episode: 9
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 564.5103, current episode: 9
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1011.1524, current episode: 9
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1166.6537, current episode: 9
[2023-06-29 14:57:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3528.9741, current episode: 10
[2023-06-29 14:57:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 591000.000000 | iteration_591000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.536155      | 6509.760150         | 6.509760             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 2161.981683 | 947.419032 | 3528.974121 | 564.510254 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 919.0117, current episode: 1
[2023-06-29 14:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 934.5529, current episode: 2
[2023-06-29 14:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 970.8648, current episode: 3
[2023-06-29 14:57:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1059.5236, current episode: 4
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1291.3092, current episode: 5
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1362.3516, current episode: 6
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1451.0990, current episode: 7
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1778.7427, current episode: 8
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 919.0117, current episode: 8
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 934.5529, current episode: 8
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 970.8648, current episode: 8
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1059.5236, current episode: 8
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2214.1792, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1291.3092, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1362.3516, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 919.0117, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1451.0990, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 934.5529, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 970.8648, current episode: 9
[2023-06-29 14:57:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3088.0217, current episode: 10
[2023-06-29 14:57:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 591500.000000 | iteration_591500.pth.tar | 10.000000     | 8180.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 818.000000              | 1.256634      | 6509.454756         | 7.957769             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1506.965625 | 656.143958 | 3088.021729 | 919.011658 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.7455, current episode: 1
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1011.7565, current episode: 2
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1023.5733, current episode: 3
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1102.9749, current episode: 4
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1216.0674, current episode: 5
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1236.1094, current episode: 6
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1421.2419, current episode: 7
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1509.3188, current episode: 8
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.7455, current episode: 8
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1011.7565, current episode: 8
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1023.5733, current episode: 8
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2209.3096, current episode: 9
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1102.9749, current episode: 9
[2023-06-29 14:57:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1216.0674, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1236.1094, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1421.2419, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1509.3188, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.7455, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1011.7565, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1023.5733, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1102.9749, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1216.0674, current episode: 9
[2023-06-29 14:57:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3476.1887, current episode: 10
[2023-06-29 14:57:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 592000.000000 | iteration_592000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.586036      | 6305.026596         | 6.305027             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1520.828607 | 737.014236 | 3476.188721 | 1001.745544 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.8589, current episode: 1
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 990.3040, current episode: 2
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1003.0376, current episode: 3
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1009.0499, current episode: 4
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1069.5193, current episode: 5
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1277.5618, current episode: 6
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.8589, current episode: 6
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1548.6127, current episode: 7
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1687.2024, current episode: 8
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1918.2440, current episode: 9
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 990.3040, current episode: 9
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1003.0376, current episode: 9
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1009.0499, current episode: 9
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.8589, current episode: 9
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1069.5193, current episode: 9
[2023-06-29 14:57:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1277.5618, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.8589, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1548.6127, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 990.3040, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1003.0376, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1009.0499, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1069.5193, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1687.2024, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.8589, current episode: 9
[2023-06-29 14:57:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3556.6536, current episode: 10
[2023-06-29 14:57:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 592500.000000 | iteration_592500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.657860      | 6031.873355         | 6.031873             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1471.404407 | 783.104313 | 3556.653564 | 653.858887 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 954.5088, current episode: 1
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 994.5490, current episode: 2
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1006.1015, current episode: 3
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1015.9409, current episode: 4
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1407.8313, current episode: 5
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1489.7665, current episode: 6
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1627.6166, current episode: 7
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 954.5088, current episode: 7
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 994.5490, current episode: 7
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1006.1015, current episode: 7
[2023-06-29 14:58:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1015.9409, current episode: 7
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2503.3743, current episode: 8
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1407.8313, current episode: 8
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1489.7665, current episode: 8
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 954.5088, current episode: 8
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 994.5490, current episode: 8
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3164.3665, current episode: 9
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1006.1015, current episode: 9
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1015.9409, current episode: 9
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1627.6166, current episode: 9
[2023-06-29 14:58:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3558.8098, current episode: 10
[2023-06-29 14:58:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 593000.000000 | iteration_593000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.590664      | 6286.682547         | 6.286683             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1772.286505 | 912.707521 | 3558.809814 | 954.508789 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1134.9340, current episode: 1
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1205.1635, current episode: 2
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1271.4121, current episode: 3
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1299.9510, current episode: 4
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1321.6960, current episode: 5
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1591.6208, current episode: 6
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1673.5684, current episode: 7
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2068.5249, current episode: 8
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1134.9340, current episode: 8
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1205.1635, current episode: 8
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1271.4121, current episode: 8
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2559.7261, current episode: 9
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1299.9510, current episode: 9
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1321.6960, current episode: 9
[2023-06-29 14:58:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2661.4014, current episode: 10
[2023-06-29 14:58:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 593500.000000 | iteration_593500.pth.tar | 10.000000     | 7320.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 732.000000              | 1.135750      | 6445.082422         | 8.804757             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1678.799817 | 534.620031 | 2661.401367 | 1134.933960 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 893.0794, current episode: 1
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 994.9780, current episode: 2
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1140.2939, current episode: 3
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1166.8094, current episode: 4
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1210.9858, current episode: 5
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1212.0210, current episode: 6
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1303.1875, current episode: 7
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 893.0794, current episode: 7
[2023-06-29 14:58:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 994.9780, current episode: 7
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2106.4954, current episode: 8
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1140.2939, current episode: 8
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1166.8094, current episode: 8
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1210.9858, current episode: 8
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1212.0210, current episode: 8
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2385.4536, current episode: 9
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1303.1875, current episode: 9
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 893.0794, current episode: 9
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 994.9780, current episode: 9
[2023-06-29 14:58:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3101.1887, current episode: 10
[2023-06-29 14:58:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 594000.000000 | iteration_594000.pth.tar | 10.000000     | 8480.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 848.000000              | 1.401266      | 6051.671510         | 7.136405             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1551.449286 | 689.797086 | 3101.188721 | 893.079407 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 863.2588, current episode: 1
[2023-06-29 14:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 924.6722, current episode: 2
[2023-06-29 14:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 922.3177, current episode: 3
[2023-06-29 14:58:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 966.8447, current episode: 4
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 991.0684, current episode: 5
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1003.5132, current episode: 6
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1016.6113, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 863.2588, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 924.6722, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 922.3177, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 966.8447, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 991.0684, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1003.5132, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1016.6113, current episode: 7
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2222.3689, current episode: 8
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2485.6172, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 863.2588, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 924.6722, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 922.3177, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 966.8447, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 991.0684, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1003.5132, current episode: 9
[2023-06-29 14:58:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1016.6113, current episode: 9
[2023-06-29 14:58:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 863.2588, current episode: 9
[2023-06-29 14:58:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3531.6814, current episode: 10
[2023-06-29 14:58:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 594500.000000 | iteration_594500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.573564      | 6354.998666         | 6.354999             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1492.795386 | 878.297001 | 3531.681396 | 863.258789 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:59:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 955.6661, current episode: 1
[2023-06-29 14:59:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.4183, current episode: 2
[2023-06-29 14:59:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 997.5982, current episode: 3
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1122.6656, current episode: 4
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1201.9478, current episode: 5
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1260.4523, current episode: 6
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1315.7159, current episode: 7
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1365.5109, current episode: 8
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1469.5881, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 955.6661, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 983.4183, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 997.5982, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1122.6656, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1201.9478, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1260.4523, current episode: 9
[2023-06-29 14:59:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2517.5527, current episode: 10
[2023-06-29 14:59:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 595000.000000 | iteration_595000.pth.tar | 10.000000     | 6820.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 682.000000              | 1.039092      | 6563.424735         | 9.623790             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1319.011591 | 431.854313 | 2517.552734 | 955.666077 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1070.2341, current episode: 1
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1103.2596, current episode: 2
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1302.4218, current episode: 3
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1291.4828, current episode: 4
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1317.4104, current episode: 5
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1354.5205, current episode: 6
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1493.7687, current episode: 7
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1569.0101, current episode: 8
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1664.1163, current episode: 9
[2023-06-29 14:59:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1875.1550, current episode: 10
[2023-06-29 14:59:24][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 595500.000000 | iteration_595500.pth.tar | 10.000000     | 5070.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 507.000000              | 0.776085      | 6532.789907         | 12.885187            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1404.137939 | 236.580387 | 1875.155029 | 1070.234131 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 14:59:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 966.2432, current episode: 1
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1146.0137, current episode: 2
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1274.7047, current episode: 3
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1395.8052, current episode: 4
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1385.3346, current episode: 5
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1646.8994, current episode: 6
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1711.4299, current episode: 7
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1816.2068, current episode: 8
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1876.7963, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 966.2432, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1146.0137, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1274.7047, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1395.8052, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1385.3346, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 966.2432, current episode: 9
[2023-06-29 14:59:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1646.8994, current episode: 9
[2023-06-29 14:59:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1711.4299, current episode: 9
[2023-06-29 14:59:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1146.0137, current episode: 9
[2023-06-29 14:59:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1816.2068, current episode: 9
[2023-06-29 14:59:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3517.7493, current episode: 10
[2023-06-29 14:59:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 596000.000000 | iteration_596000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.558160      | 6417.824505         | 6.417825             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1673.718298 | 675.480659 | 3517.749268 | 966.243164 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1001.6475, current episode: 1
[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1296.0288, current episode: 2
[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1312.1536, current episode: 3
[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1328.2983, current episode: 4
[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1359.4829, current episode: 5
[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1388.0503, current episode: 6
[2023-06-29 14:59:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1614.1599, current episode: 7
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1001.6475, current episode: 7
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2136.5015, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1296.0288, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1312.1536, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1328.2983, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1359.4829, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1388.0503, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1001.6475, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1614.1599, current episode: 8
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3565.8250, current episode: 9
[2023-06-29 14:59:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3594.4617, current episode: 10
[2023-06-29 14:59:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 596500.000000 | iteration_596500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.556960      | 6422.773751         | 6.422774             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1859.660938 | 903.660011 | 3594.461670 | 1001.647461 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1285.2223, current episode: 1
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1275.6068, current episode: 2
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1368.2256, current episode: 3
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1363.2545, current episode: 4
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1375.3984, current episode: 5
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1366.8201, current episode: 6
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1488.7599, current episode: 7
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1524.6262, current episode: 8
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1557.1143, current episode: 9
[2023-06-29 15:00:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2346.7314, current episode: 10
[2023-06-29 15:00:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 597000.000000 | iteration_597000.pth.tar | 10.000000     | 6920.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 692.000000              | 1.082649      | 6391.727470         | 9.236600             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1495.175952 | 297.745578 | 2346.731445 | 1275.606812 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1030.4070, current episode: 1
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1260.4589, current episode: 2
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1317.0963, current episode: 3
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1296.0480, current episode: 4
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1504.3575, current episode: 5
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1484.8772, current episode: 6
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1430.0044, current episode: 7
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1820.2078, current episode: 8
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1030.4070, current episode: 8
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2267.7168, current episode: 9
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1260.4589, current episode: 9
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1317.0963, current episode: 9
[2023-06-29 15:00:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1296.0480, current episode: 9
[2023-06-29 15:00:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2843.2363, current episode: 10
[2023-06-29 15:00:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 597500.000000 | iteration_597500.pth.tar | 10.000000     | 7870.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 787.000000              | 1.217803      | 6462.459450         | 8.211511             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1625.441016 | 519.321313 | 2843.236328 | 1030.406982 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1161.6692, current episode: 1
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1202.2120, current episode: 2
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1224.5029, current episode: 3
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1203.9202, current episode: 4
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1248.2521, current episode: 5
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1231.6748, current episode: 6
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1302.4391, current episode: 7
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1392.8979, current episode: 8
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1577.3774, current episode: 9
[2023-06-29 15:00:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1732.4912, current episode: 10
[2023-06-29 15:00:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 598000.000000 | iteration_598000.pth.tar | 10.000000     | 4710.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 471.000000              | 0.709787      | 6635.797097         | 14.088741            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1327.743689 | 177.736032 | 1732.491211 | 1161.669189 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1240.1899, current episode: 1
[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1566.6013, current episode: 2
[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1660.4288, current episode: 3
[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1710.2660, current episode: 4
[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1939.4960, current episode: 5
[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1954.7809, current episode: 6
[2023-06-29 15:00:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2233.5281, current episode: 7
[2023-06-29 15:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1240.1899, current episode: 7
[2023-06-29 15:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2762.4150, current episode: 8
[2023-06-29 15:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2808.0388, current episode: 9
[2023-06-29 15:00:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3091.4382, current episode: 10
[2023-06-29 15:00:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 598500.000000 | iteration_598500.pth.tar | 10.000000     | 8270.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 827.000000              | 1.257977      | 6574.049348         | 7.949274             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2096.718311 | 579.356324 | 3091.438232 | 1240.189941 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1181.3965, current episode: 1
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1232.6692, current episode: 2
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1240.5662, current episode: 3
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1308.4358, current episode: 4
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1317.2992, current episode: 5
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1329.3722, current episode: 6
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1377.9349, current episode: 7
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1440.4144, current episode: 8
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1535.9015, current episode: 9
[2023-06-29 15:01:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2312.4678, current episode: 10
[2023-06-29 15:01:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 599000.000000 | iteration_599000.pth.tar | 10.000000     | 6340.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 634.000000              | 0.968398      | 6546.896556         | 10.326335            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1427.645764 | 310.960114 | 2312.467773 | 1181.396484 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1262.2086, current episode: 1
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1272.6321, current episode: 2
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1307.3500, current episode: 3
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1343.3712, current episode: 4
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1398.2308, current episode: 5
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1526.8433, current episode: 6
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1669.1689, current episode: 7
[2023-06-29 15:01:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2145.5896, current episode: 8
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1262.2086, current episode: 8
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1272.6321, current episode: 8
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1307.3500, current episode: 8
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1343.3712, current episode: 8
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1398.2308, current episode: 8
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2935.6511, current episode: 9
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1526.8433, current episode: 9
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1669.1689, current episode: 9
[2023-06-29 15:01:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3361.0818, current episode: 10
[2023-06-29 15:01:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 599500.000000 | iteration_599500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.579157      | 6332.494128         | 6.332494             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1822.212744 | 715.043925 | 3361.081787 | 1262.208618 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:01:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1125.6708, current episode: 1
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1320.9482, current episode: 2
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1302.5645, current episode: 3
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1321.2828, current episode: 4
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1367.2437, current episode: 5
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1366.7385, current episode: 6
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1345.5370, current episode: 7
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1376.3163, current episode: 8
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1796.8274, current episode: 9
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1125.6708, current episode: 9
[2023-06-29 15:01:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2416.8372, current episode: 10
[2023-06-29 15:01:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 600000.000000 | iteration_600000.pth.tar | 10.000000     | 6560.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 656.000000              | 1.004397      | 6531.279353         | 9.956219             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1473.996631 | 352.076269 | 2416.837158 | 1125.670776 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1162.4644, current episode: 1
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1251.4769, current episode: 2
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1211.3464, current episode: 3
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1266.6128, current episode: 4
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1223.7274, current episode: 5
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1274.6472, current episode: 6
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1273.6895, current episode: 7
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1307.9520, current episode: 8
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1315.7751, current episode: 9
[2023-06-29 15:01:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1344.1139, current episode: 10
[2023-06-29 15:01:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 600500.000000 | iteration_600500.pth.tar | 10.000000     | 3750.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 375.000000              | 0.587888      | 6378.768005         | 17.010048            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1263.180566 | 51.086824  | 1344.113892 | 1162.464355 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1247.8438, current episode: 1
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1244.0184, current episode: 2
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1264.1910, current episode: 3
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1296.1147, current episode: 4
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1275.7584, current episode: 5
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1323.9993, current episode: 6
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1325.4978, current episode: 7
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1307.1332, current episode: 8
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1339.2340, current episode: 9
[2023-06-29 15:02:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1374.2949, current episode: 10
[2023-06-29 15:02:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 601000.000000 | iteration_601000.pth.tar | 10.000000     | 3820.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 382.000000              | 0.606502      | 6298.408282         | 16.487980            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1299.808557 | 40.093519  | 1374.294922 | 1244.018433 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1208.4259, current episode: 1
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1271.7612, current episode: 2
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1254.6294, current episode: 3
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1346.7089, current episode: 4
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1326.7467, current episode: 5
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1372.5210, current episode: 6
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1362.2900, current episode: 7
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1440.5334, current episode: 8
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1571.5837, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1208.4259, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1271.7612, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1254.6294, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1346.7089, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1326.7467, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1372.5210, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1362.2900, current episode: 9
[2023-06-29 15:02:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1440.5334, current episode: 9
[2023-06-29 15:02:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1571.5837, current episode: 9
[2023-06-29 15:02:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3550.4575, current episode: 10
[2023-06-29 15:02:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 601500.000000 | iteration_601500.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.546711      | 6464.685648         | 6.465332             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1570.565784 | 667.029698 | 3550.457520 | 1208.425903 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:02:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1389.4434, current episode: 1
[2023-06-29 15:02:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1555.6643, current episode: 2
[2023-06-29 15:02:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1593.3292, current episode: 3
[2023-06-29 15:02:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1556.3870, current episode: 4
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2234.8997, current episode: 5
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2385.4663, current episode: 6
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2511.2246, current episode: 7
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1389.4434, current episode: 7
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1555.6643, current episode: 7
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1593.3292, current episode: 7
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1556.3870, current episode: 7
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3552.5344, current episode: 8
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3489.3564, current episode: 9
[2023-06-29 15:02:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3401.8264, current episode: 10
[2023-06-29 15:02:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 602000.000000 | iteration_602000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.505147      | 6643.867841         | 6.643868             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2367.013171 | 815.118174 | 3552.534424 | 1389.443359 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 928.2147, current episode: 1
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1104.3755, current episode: 2
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1102.1200, current episode: 3
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1179.3507, current episode: 4
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1154.4150, current episode: 5
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1226.8033, current episode: 6
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1312.6218, current episode: 7
[2023-06-29 15:02:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1279.6464, current episode: 8
[2023-06-29 15:02:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1595.8997, current episode: 9
[2023-06-29 15:02:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1667.6145, current episode: 10
[2023-06-29 15:02:58][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 602500.000000 | iteration_602500.pth.tar | 10.000000     | 4710.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 471.000000              | 0.728690      | 6463.653933         | 13.723257            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1255.106165 | 214.446909 | 1667.614502 | 928.214722 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.4297, current episode: 1
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1143.2317, current episode: 2
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1140.7584, current episode: 3
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1146.0265, current episode: 4
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1237.5931, current episode: 5
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1446.7518, current episode: 6
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1526.2251, current episode: 7
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1649.5009, current episode: 8
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1868.9349, current episode: 9
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.4297, current episode: 9
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1143.2317, current episode: 9
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1140.7584, current episode: 9
[2023-06-29 15:03:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1146.0265, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1237.5931, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1446.7518, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 958.4297, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1526.2251, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1649.5009, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1143.2317, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1140.7584, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1146.0265, current episode: 9
[2023-06-29 15:03:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3529.8687, current episode: 10
[2023-06-29 15:03:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 603000.000000 | iteration_603000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.533717      | 6520.106993         | 6.520107             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1564.732086 | 705.991644 | 3529.868652 | 958.429749 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 965.5908, current episode: 1
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 961.5060, current episode: 2
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 974.2838, current episode: 3
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 989.7150, current episode: 4
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1011.4332, current episode: 5
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1221.3604, current episode: 6
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1327.0328, current episode: 7
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1608.8763, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 965.5908, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 961.5060, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 974.2838, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 989.7150, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1011.4332, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1221.3604, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1327.0328, current episode: 8
[2023-06-29 15:03:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2777.8967, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 965.5908, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 961.5060, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 974.2838, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 989.7150, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1011.4332, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1608.8763, current episode: 9
[2023-06-29 15:03:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3525.0938, current episode: 10
[2023-06-29 15:03:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 603500.000000 | iteration_603500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.535972      | 6510.534636         | 6.510535             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1536.278870 | 848.015911 | 3525.093750 | 961.505981 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:03:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 931.8181, current episode: 1
[2023-06-29 15:03:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 963.0435, current episode: 2
[2023-06-29 15:03:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 976.9993, current episode: 3
[2023-06-29 15:03:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 986.8906, current episode: 4
[2023-06-29 15:03:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 997.1662, current episode: 5
[2023-06-29 15:03:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1270.0535, current episode: 6
[2023-06-29 15:03:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1290.1211, current episode: 7
[2023-06-29 15:03:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1310.9240, current episode: 8
[2023-06-29 15:03:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1385.9319, current episode: 9
[2023-06-29 15:03:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1640.1068, current episode: 10
[2023-06-29 15:03:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 604000.000000 | iteration_604000.pth.tar | 10.000000     | 4640.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 464.000000              | 0.713585      | 6502.375853         | 14.013741            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1175.305487 | 226.242417 | 1640.106812 | 931.818115 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:03:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1321.1526, current episode: 1
[2023-06-29 15:03:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1340.5642, current episode: 2
[2023-06-29 15:03:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1455.9054, current episode: 3
[2023-06-29 15:03:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2177.3357, current episode: 4
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2581.6177, current episode: 5
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2679.6875, current episode: 6
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1321.1526, current episode: 6
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1340.5642, current episode: 6
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1455.9054, current episode: 6
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3499.5806, current episode: 7
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3520.9395, current episode: 8
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3558.5662, current episode: 9
[2023-06-29 15:03:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3509.1050, current episode: 10
[2023-06-29 15:03:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 604500.000000 | iteration_604500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.508700      | 6628.223724         | 6.628224             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2564.445422 | 900.331558 | 3558.566162 | 1321.152588 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 997.4158, current episode: 1
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1242.6123, current episode: 2
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1260.0469, current episode: 3
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1281.2672, current episode: 4
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1283.0391, current episode: 5
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1492.5977, current episode: 6
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1791.1162, current episode: 7
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1809.3929, current episode: 8
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1801.1793, current episode: 9
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 997.4158, current episode: 9
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1242.6123, current episode: 9
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1260.0469, current episode: 9
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1281.2672, current episode: 9
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1283.0391, current episode: 9
[2023-06-29 15:04:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1492.5977, current episode: 9
[2023-06-29 15:04:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 997.4158, current episode: 9
[2023-06-29 15:04:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1791.1162, current episode: 9
[2023-06-29 15:04:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1809.3929, current episode: 9
[2023-06-29 15:04:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1801.1793, current episode: 9
[2023-06-29 15:04:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3569.5693, current episode: 10
[2023-06-29 15:04:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 605000.000000 | iteration_605000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.543311      | 6479.577309         | 6.479577             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1652.823669 | 692.252543 | 3569.569336 | 997.415771 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 937.7856, current episode: 1
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 936.7695, current episode: 2
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 955.7073, current episode: 3
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.2441, current episode: 4
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 994.5892, current episode: 5
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.3583, current episode: 6
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.0217, current episode: 7
[2023-06-29 15:04:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1334.3970, current episode: 8
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1670.8838, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 937.7856, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 936.7695, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 955.7073, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.2441, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 994.5892, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.3583, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.0217, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1334.3970, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 937.7856, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 936.7695, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 955.7073, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 985.2441, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 994.5892, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1001.3583, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1017.0217, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1670.8838, current episode: 9
[2023-06-29 15:04:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3477.0710, current episode: 10
[2023-06-29 15:04:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 605500.000000 | iteration_605500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.556690      | 6423.886822         | 6.423887             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1331.082745 | 749.132744 | 3477.071045 | 936.769470 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 695.9595, current episode: 1
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 839.8556, current episode: 2
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 869.9251, current episode: 3
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 880.3035, current episode: 4
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 974.5843, current episode: 5
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 993.9805, current episode: 6
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1236.4232, current episode: 7
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1268.7120, current episode: 8
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1282.2157, current episode: 9
[2023-06-29 15:04:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1312.2019, current episode: 10
[2023-06-29 15:04:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 606000.000000 | iteration_606000.pth.tar | 10.000000     | 3740.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 374.000000              | 0.587994      | 6360.613543         | 17.006988            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1035.416132 | 210.402137 | 1312.201904 | 695.959473 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1261.8276, current episode: 1
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1276.8625, current episode: 2
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1297.8019, current episode: 3
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1297.1001, current episode: 4
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1301.8716, current episode: 5
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1343.8816, current episode: 6
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1519.2870, current episode: 7
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1900.8314, current episode: 8
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1261.8276, current episode: 8
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1276.8625, current episode: 8
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2629.2615, current episode: 9
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1297.8019, current episode: 9
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1297.1001, current episode: 9
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1301.8716, current episode: 9
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1343.8816, current episode: 9
[2023-06-29 15:05:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1519.2870, current episode: 9
[2023-06-29 15:05:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3235.3418, current episode: 10
[2023-06-29 15:05:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 606500.000000 | iteration_606500.pth.tar | 10.000000     | 8890.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 889.000000              | 1.351089      | 6579.876281         | 7.401436             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1706.406702 | 653.746117 | 3235.341797 | 1261.827637 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1244.3505, current episode: 1
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1245.2976, current episode: 2
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1238.8119, current episode: 3
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1260.2903, current episode: 4
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1298.0359, current episode: 5
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1300.6581, current episode: 6
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1311.2902, current episode: 7
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1357.3434, current episode: 8
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1444.0264, current episode: 9
[2023-06-29 15:05:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1503.7476, current episode: 10
[2023-06-29 15:05:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 607000.000000 | iteration_607000.pth.tar | 10.000000     | 4160.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 416.000000              | 0.645776      | 6441.862793         | 15.485247            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1320.385168 | 85.399767  | 1503.747559 | 1238.811890 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:05:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1221.9225, current episode: 1
[2023-06-29 15:05:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1236.0446, current episode: 2
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1246.1584, current episode: 3
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1265.8345, current episode: 4
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1283.6970, current episode: 5
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1261.3398, current episode: 6
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1278.5646, current episode: 7
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1294.7955, current episode: 8
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1292.6415, current episode: 9
[2023-06-29 15:05:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2118.4700, current episode: 10
[2023-06-29 15:05:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 607500.000000 | iteration_607500.pth.tar | 10.000000     | 5900.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 590.000000              | 0.904939      | 6519.778483         | 11.050472            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1349.946838 | 257.196409 | 2118.469971 | 1221.922485 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1329.5529, current episode: 1
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1333.7252, current episode: 2
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1333.7292, current episode: 3
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1355.1726, current episode: 4
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1355.3346, current episode: 5
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1347.0059, current episode: 6
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1338.0598, current episode: 7
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1587.7365, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1329.5529, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1333.7252, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1333.7292, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1355.1726, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1355.3346, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1347.0059, current episode: 8
[2023-06-29 15:05:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1338.0598, current episode: 8
[2023-06-29 15:05:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1587.7365, current episode: 8
[2023-06-29 15:05:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3438.5022, current episode: 9
[2023-06-29 15:05:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3511.3218, current episode: 10
[2023-06-29 15:05:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 608000.000000 | iteration_608000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.549362      | 6454.270837         | 6.454271             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1793.014062 | 844.287375 | 3511.321777 | 1329.552856 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1269.8853, current episode: 1
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1262.3951, current episode: 2
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1293.2500, current episode: 3
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1281.1188, current episode: 4
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1279.1183, current episode: 5
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1291.5500, current episode: 6
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1327.4750, current episode: 7
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1338.6174, current episode: 8
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1320.3956, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1269.8853, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1262.3951, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1293.2500, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1281.1188, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1279.1183, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1291.5500, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1327.4750, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1338.6174, current episode: 9
[2023-06-29 15:06:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1320.3956, current episode: 9
[2023-06-29 15:06:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3520.8943, current episode: 10
[2023-06-29 15:06:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 608500.000000 | iteration_608500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.539643      | 6495.011360         | 6.495011             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1518.469983 | 667.905143 | 3520.894287 | 1262.395142 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 1
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 1
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 1
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 1
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 1
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1368.2739, current episode: 2
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1385.3741, current episode: 3
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 3
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1459.4257, current episode: 4
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1456.8412, current episode: 5
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1485.2335, current episode: 6
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1523.3177, current episode: 7
[2023-06-29 15:06:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 7
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 7
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1980.3763, current episode: 8
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2011.2539, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1368.2739, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1385.3741, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1459.4257, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1456.8412, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1485.2335, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1523.3177, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 119.1936, current episode: 9
[2023-06-29 15:06:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3345.6975, current episode: 10
[2023-06-29 15:06:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 609000.000000 | iteration_609000.pth.tar | 10.000000     | 9110.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 911.000000              | 1.436132      | 6343.426070         | 6.963146             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1613.498759 | 755.732052 | 3345.697510 | 119.193649 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:06:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 1
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 1
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 1
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 1
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 925.2462, current episode: 2
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 2
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 2
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1599.4786, current episode: 3
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 3
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 3
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2112.3386, current episode: 4
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2134.0129, current episode: 5
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 925.2462, current episode: 5
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 5
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 5
[2023-06-29 15:06:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 5
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2889.9341, current episode: 6
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2922.5881, current episode: 7
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 7
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1599.4786, current episode: 7
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 7
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 925.2462, current episode: 7
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3290.0369, current episode: 8
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3529.3401, current episode: 9
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 124.7984, current episode: 9
[2023-06-29 15:06:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3526.9297, current episode: 10
[2023-06-29 15:06:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 609500.000000 | iteration_609500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.583409      | 6315.488891         | 6.315489             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2305.470363 | 1091.196330 | 3529.340088 | 124.798355 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2057.7068, current episode: 1
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2410.6172, current episode: 2
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3130.9578, current episode: 3
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3374.2061, current episode: 4
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3443.7139, current episode: 5
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3250.4758, current episode: 6
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3302.4966, current episode: 7
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3296.9065, current episode: 8
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3292.8259, current episode: 9
[2023-06-29 15:06:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3341.2681, current episode: 10
[2023-06-29 15:06:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 610000.000000 | iteration_610000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.510131      | 6621.943757         | 6.621944             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3090.117456 | 441.898840 | 3443.713867 | 2057.706787 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:07:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1330.8271, current episode: 1
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1330.8271, current episode: 1
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3059.8689, current episode: 2
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3368.6516, current episode: 3
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3351.2415, current episode: 4
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3320.7312, current episode: 5
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3270.5398, current episode: 6
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3334.5859, current episode: 7
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3330.6841, current episode: 8
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3314.0540, current episode: 9
[2023-06-29 15:07:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3316.0188, current episode: 10
[2023-06-29 15:07:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 610500.000000 | iteration_610500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.478271      | 6764.657308         | 6.764657             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 3099.720288 | 595.433730 | 3368.651611 | 1330.827148 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 444.9244, current episode: 1
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 566.2538, current episode: 2
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 577.5033, current episode: 3
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.6762, current episode: 4
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 444.9244, current episode: 4
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1203.3096, current episode: 5
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 566.2538, current episode: 5
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.1605, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 577.5033, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 444.9244, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.6762, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 566.2538, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 577.5033, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 444.9244, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1203.3096, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.6762, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 566.2538, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1284.1605, current episode: 6
[2023-06-29 15:07:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 577.5033, current episode: 6
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 444.9244, current episode: 6
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2941.0210, current episode: 7
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 566.2538, current episode: 7
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 577.5033, current episode: 7
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 444.9244, current episode: 7
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 801.6762, current episode: 7
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3338.7283, current episode: 8
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3486.5129, current episode: 9
[2023-06-29 15:07:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3310.7117, current episode: 10
[2023-06-29 15:07:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 611000.000000 | iteration_611000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.578668      | 6334.452765         | 6.334453             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1795.480167 | 1235.622231 | 3486.512939 | 444.924408 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1570.1104, current episode: 1
[2023-06-29 15:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1716.6154, current episode: 2
[2023-06-29 15:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1869.5803, current episode: 3
[2023-06-29 15:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2131.7808, current episode: 4
[2023-06-29 15:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2343.4846, current episode: 5
[2023-06-29 15:07:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1570.1104, current episode: 5
[2023-06-29 15:07:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1716.6154, current episode: 5
[2023-06-29 15:07:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3284.3818, current episode: 6
[2023-06-29 15:07:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3302.8967, current episode: 7
[2023-06-29 15:07:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3471.1462, current episode: 8
[2023-06-29 15:07:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3362.8760, current episode: 9
[2023-06-29 15:07:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3362.2646, current episode: 10
[2023-06-29 15:07:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 611500.000000 | iteration_611500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.479906      | 6757.184788         | 6.757185             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2641.513684 | 743.418778 | 3471.146240 | 1570.110352 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:07:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 452.1361, current episode: 1
[2023-06-29 15:07:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 660.5215, current episode: 2
[2023-06-29 15:07:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 452.1361, current episode: 2
[2023-06-29 15:07:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 660.5215, current episode: 2
[2023-06-29 15:07:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 452.1361, current episode: 2
[2023-06-29 15:07:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 660.5215, current episode: 2
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 452.1361, current episode: 2
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 660.5215, current episode: 2
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 452.1361, current episode: 2
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3284.8301, current episode: 3
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3304.3428, current episode: 4
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3355.5251, current episode: 5
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3289.5359, current episode: 6
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3378.1506, current episode: 7
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3357.9395, current episode: 8
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3382.6423, current episode: 9
[2023-06-29 15:07:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3302.9697, current episode: 10
[2023-06-29 15:07:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 612000.000000 | iteration_612000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.524832      | 6558.099906         | 6.558100             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2776.859366 | 1111.762511 | 3382.642334 | 452.136078 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:08:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 456.0501, current episode: 1
[2023-06-29 15:08:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 941.4459, current episode: 2
[2023-06-29 15:08:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1178.3367, current episode: 3
[2023-06-29 15:08:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 456.0501, current episode: 3
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1723.2705, current episode: 4
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1832.6700, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 941.4459, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 456.0501, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1178.3367, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 456.0501, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 941.4459, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1723.2705, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 456.0501, current episode: 5
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3446.3547, current episode: 6
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3330.7571, current episode: 7
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3428.9746, current episode: 8
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3405.4358, current episode: 9
[2023-06-29 15:08:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3344.7917, current episode: 10
[2023-06-29 15:08:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 612500.000000 | iteration_612500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509197      | 6626.042255         | 6.626042             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2308.808725 | 1141.005620 | 3446.354736 | 456.050140 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:08:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.8094, current episode: 1
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 988.7699, current episode: 2
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1053.7421, current episode: 3
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1060.5397, current episode: 4
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.8094, current episode: 4
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1217.7527, current episode: 5
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1177.4199, current episode: 6
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1410.5920, current episode: 7
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.8094, current episode: 7
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1703.6564, current episode: 8
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1864.7961, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 988.7699, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1053.7421, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1060.5397, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.8094, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1217.7527, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1177.4199, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.8094, current episode: 9
[2023-06-29 15:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1410.5920, current episode: 9
[2023-06-29 15:08:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 988.7699, current episode: 9
[2023-06-29 15:08:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1053.7421, current episode: 9
[2023-06-29 15:08:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1060.5397, current episode: 9
[2023-06-29 15:08:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 447.8094, current episode: 9
[2023-06-29 15:08:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3446.2070, current episode: 10
[2023-06-29 15:08:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 613000.000000 | iteration_613000.pth.tar | 10.000000     | 9590.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 959.000000              | 1.478477      | 6486.404368         | 6.763717             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1437.128528 | 766.498119 | 3446.207031 | 447.809448 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1097.6548, current episode: 1
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1118.8920, current episode: 2
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1296.5792, current episode: 3
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1303.0081, current episode: 4
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1400.6259, current episode: 5
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1472.0729, current episode: 6
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1664.8885, current episode: 7
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1772.1359, current episode: 8
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1852.6759, current episode: 9
[2023-06-29 15:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1846.4736, current episode: 10
[2023-06-29 15:08:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 613500.000000 | iteration_613500.pth.tar | 10.000000     | 5150.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 515.000000              | 0.783925      | 6569.509183         | 12.756329            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1482.500671 | 272.134922 | 1852.675903 | 1097.654785 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1058.6240, current episode: 1
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1089.6154, current episode: 2
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1152.8003, current episode: 3
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1176.5714, current episode: 4
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1200.8295, current episode: 5
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1224.9015, current episode: 6
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.1383, current episode: 7
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1246.2444, current episode: 8
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1288.5552, current episode: 9
[2023-06-29 15:08:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1441.9292, current episode: 10
[2023-06-29 15:08:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 614000.000000 | iteration_614000.pth.tar | 10.000000     | 4040.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 404.000000              | 0.621776      | 6497.519332         | 16.082969            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1212.220911 | 102.157648 | 1441.929199 | 1058.624023 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1258.5470, current episode: 1
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1376.8484, current episode: 2
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1596.9181, current episode: 3
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1732.6586, current episode: 4
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1703.8588, current episode: 5
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1828.6630, current episode: 6
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1935.3177, current episode: 7
[2023-06-29 15:09:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2270.0781, current episode: 8
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1258.5470, current episode: 8
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1376.8484, current episode: 8
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2887.0664, current episode: 9
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1596.9181, current episode: 9
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1732.6586, current episode: 9
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1703.8588, current episode: 9
[2023-06-29 15:09:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3469.6218, current episode: 10
[2023-06-29 15:09:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 614500.000000 | iteration_614500.pth.tar | 10.000000     | 9560.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 956.000000              | 1.472420      | 6492.713560         | 6.791541             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2005.957788 | 656.697733 | 3469.621826 | 1258.546997 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:09:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1000.2336, current episode: 1
[2023-06-29 15:09:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1457.4680, current episode: 2
[2023-06-29 15:09:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1552.1686, current episode: 3
[2023-06-29 15:09:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1567.9579, current episode: 4
[2023-06-29 15:09:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1610.4543, current episode: 5
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1735.1970, current episode: 6
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1000.2336, current episode: 6
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2111.5735, current episode: 7
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2277.8059, current episode: 8
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2830.6968, current episode: 9
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1457.4680, current episode: 9
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1552.1686, current episode: 9
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1000.2336, current episode: 9
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1567.9579, current episode: 9
[2023-06-29 15:09:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3219.9026, current episode: 10
[2023-06-29 15:09:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 615000.000000 | iteration_615000.pth.tar | 10.000000     | 9010.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 901.000000              | 1.359059      | 6629.586689         | 7.358032             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1936.345825 | 642.672484 | 3219.902588 | 1000.233643 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:09:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 441.0961, current episode: 1
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1037.4027, current episode: 2
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1186.2648, current episode: 3
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 441.0961, current episode: 3
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1608.1033, current episode: 4
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1766.6736, current episode: 5
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2088.8186, current episode: 6
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2078.8691, current episode: 7
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 441.0961, current episode: 7
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1037.4027, current episode: 7
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2247.7065, current episode: 8
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1186.2648, current episode: 8
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2509.3362, current episode: 9
[2023-06-29 15:09:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 441.0961, current episode: 9
[2023-06-29 15:09:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1037.4027, current episode: 9
[2023-06-29 15:09:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1608.1033, current episode: 9
[2023-06-29 15:09:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 441.0961, current episode: 9
[2023-06-29 15:09:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3497.1035, current episode: 10
[2023-06-29 15:09:38][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 615500.000000 | iteration_615500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.597425      | 6260.074617         | 6.260075             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1846.137442 | 810.335562 | 3497.103516 | 441.096100 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 456.7400, current episode: 1
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 452.1931, current episode: 2
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1234.9744, current episode: 3
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 456.7400, current episode: 3
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 452.1931, current episode: 3
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1406.7759, current episode: 4
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1457.9009, current episode: 5
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1607.6494, current episode: 6
[2023-06-29 15:09:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1776.0770, current episode: 7
[2023-06-29 15:09:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1948.4583, current episode: 8
[2023-06-29 15:09:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1945.4738, current episode: 9
[2023-06-29 15:09:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 456.7400, current episode: 9
[2023-06-29 15:09:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 452.1931, current episode: 9
[2023-06-29 15:09:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2084.5317, current episode: 10
[2023-06-29 15:09:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 616000.000000 | iteration_616000.pth.tar | 10.000000     | 5870.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 587.000000              | 0.911161      | 6442.329231         | 10.975007            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1437.077444 | 552.851316 | 2084.531738 | 452.193115 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:10:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1223.5530, current episode: 1
[2023-06-29 15:10:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1386.4718, current episode: 2
[2023-06-29 15:10:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1493.6860, current episode: 3
[2023-06-29 15:10:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1955.9064, current episode: 4
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2413.0786, current episode: 5
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1223.5530, current episode: 5
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2782.9504, current episode: 6
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1386.4718, current episode: 6
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3084.7866, current episode: 7
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1493.6860, current episode: 7
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3207.4106, current episode: 8
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3255.3103, current episode: 9
[2023-06-29 15:10:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3521.9910, current episode: 10
[2023-06-29 15:10:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 616500.000000 | iteration_616500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.577238      | 6340.198554         | 6.340199             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2432.514478 | 817.153929 | 3521.990967 | 1223.552979 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:10:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 426.1296, current episode: 1
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1268.6312, current episode: 2
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 426.1296, current episode: 2
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1607.5990, current episode: 3
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 426.1296, current episode: 3
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1989.0022, current episode: 4
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2341.9712, current episode: 5
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1268.6312, current episode: 5
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 426.1296, current episode: 5
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1607.5990, current episode: 5
[2023-06-29 15:10:24][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 426.1296, current episode: 5
[2023-06-29 15:10:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3477.4766, current episode: 6
[2023-06-29 15:10:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3559.3652, current episode: 7
[2023-06-29 15:10:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3500.2917, current episode: 8
[2023-06-29 15:10:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3487.4712, current episode: 9
[2023-06-29 15:10:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3476.8599, current episode: 10
[2023-06-29 15:10:25][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 617000.000000 | iteration_617000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.572191      | 6360.550178         | 6.360550             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2513.479782 | 1091.123965 | 3559.365234 | 426.129608 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:10:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 440.9981, current episode: 1
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1259.1426, current episode: 2
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 440.9981, current episode: 2
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1822.6089, current episode: 3
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 440.9981, current episode: 3
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2203.1135, current episode: 4
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1259.1426, current episode: 4
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 440.9981, current episode: 4
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3153.2412, current episode: 5
[2023-06-29 15:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 440.9981, current episode: 5
[2023-06-29 15:10:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3427.7444, current episode: 6
[2023-06-29 15:10:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3446.7693, current episode: 7
[2023-06-29 15:10:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3467.1001, current episode: 8
[2023-06-29 15:10:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3492.1572, current episode: 9
[2023-06-29 15:10:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3535.6787, current episode: 10
[2023-06-29 15:10:41][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 617500.000000 | iteration_617500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.523671      | 6563.098641         | 6.563099             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2624.855402 | 1065.195864 | 3535.678711 | 440.998108 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.4990, current episode: 1
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 412.3788, current episode: 2
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 421.5402, current episode: 3
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.4990, current episode: 3
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 412.3788, current episode: 3
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 421.5402, current episode: 3
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1483.7257, current episode: 4
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1622.6730, current episode: 5
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1638.7531, current episode: 6
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.4990, current episode: 6
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 412.3788, current episode: 6
[2023-06-29 15:10:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 421.5402, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.4990, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 412.3788, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 421.5402, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1483.7257, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1622.6730, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1638.7531, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.4990, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 412.3788, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 421.5402, current episode: 6
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3588.0498, current episode: 7
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3434.5320, current episode: 8
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3448.6729, current episode: 9
[2023-06-29 15:10:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3397.7402, current episode: 10
[2023-06-29 15:10:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 618000.000000 | iteration_618000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.558450      | 6416.630603         | 6.416631             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1985.256461 | 1293.331176 | 3588.049805 | 404.498993 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:11:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 414.6809, current episode: 1
[2023-06-29 15:11:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 428.3515, current episode: 2
[2023-06-29 15:11:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 414.6809, current episode: 2
[2023-06-29 15:11:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 428.3515, current episode: 2
[2023-06-29 15:11:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 414.6809, current episode: 2
[2023-06-29 15:11:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 428.3515, current episode: 2
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 2606.4031, current episode: 3
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 414.6809, current episode: 3
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 428.3515, current episode: 3
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3222.3914, current episode: 4
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 414.6809, current episode: 4
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 428.3515, current episode: 4
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3591.4478, current episode: 5
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3422.5027, current episode: 6
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3437.4189, current episode: 7
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3317.2324, current episode: 8
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3465.5249, current episode: 9
[2023-06-29 15:11:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3442.4607, current episode: 10
[2023-06-29 15:11:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 618500.000000 | iteration_618500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.546143      | 6467.706784         | 6.467707             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 2734.841422 | 1184.538404 | 3591.447754 | 414.680908 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:11:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1353.9624, current episode: 1
[2023-06-29 15:11:25][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1496.1062, current episode: 2
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1603.1229, current episode: 3
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1647.3374, current episode: 4
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1558.7267, current episode: 5
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1854.2991, current episode: 6
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1929.4607, current episode: 7
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2053.4939, current episode: 8
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1353.9624, current episode: 8
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3164.1255, current episode: 9
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1496.1062, current episode: 9
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1603.1229, current episode: 9
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1647.3374, current episode: 9
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1558.7267, current episode: 9
[2023-06-29 15:11:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3297.9172, current episode: 10
[2023-06-29 15:11:26][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 619000.000000 | iteration_619000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.594682      | 6270.842207         | 6.270842             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1995.855200 | 649.349648 | 3297.917236 | 1353.962402 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 412.7657, current episode: 1
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.6660, current episode: 2
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 412.8521, current episode: 3
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 656.9006, current episode: 4
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 412.7657, current episode: 4
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.6660, current episode: 4
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 412.8521, current episode: 4
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 656.9006, current episode: 4
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1578.9707, current episode: 5
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1602.9874, current episode: 6
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 412.7657, current episode: 6
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.6660, current episode: 6
[2023-06-29 15:11:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 412.8521, current episode: 6
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 656.9006, current episode: 6
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 412.7657, current episode: 6
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.6660, current episode: 6
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 412.8521, current episode: 6
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 656.9006, current episode: 6
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3246.6951, current episode: 7
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1578.9707, current episode: 7
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1602.9874, current episode: 7
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 412.7657, current episode: 7
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 404.6660, current episode: 7
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 412.8521, current episode: 7
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3418.9639, current episode: 8
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3425.7537, current episode: 9
[2023-06-29 15:11:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3438.6995, current episode: 10
[2023-06-29 15:11:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 619500.000000 | iteration_619500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.581459      | 6323.273010         | 6.323273             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min |
+-------+-------------+-------------+-------------+------------+
| Value | 1859.925458 | 1311.349320 | 3438.699463 | 404.666046 |
+-------+-------------+-------------+-------------+------------+


[2023-06-29 15:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1337.9556, current episode: 1
[2023-06-29 15:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1588.9380, current episode: 2
[2023-06-29 15:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1585.5885, current episode: 3
[2023-06-29 15:11:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1620.2483, current episode: 4
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2019.1877, current episode: 5
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2342.7205, current episode: 6
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 2695.9114, current episode: 7
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1337.9556, current episode: 7
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1588.9380, current episode: 7
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1585.5885, current episode: 7
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3298.0400, current episode: 8
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1620.2483, current episode: 8
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3476.6084, current episode: 9
[2023-06-29 15:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3477.3679, current episode: 10
[2023-06-29 15:11:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 620000.000000 | iteration_620000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.527141      | 6548.184390         | 6.548184             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2344.256628 | 799.256605 | 3477.367920 | 1337.955566 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1650.2140, current episode: 1
[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1711.0328, current episode: 2
[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1723.4016, current episode: 3
[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1784.4523, current episode: 4
[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2029.0859, current episode: 5
[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2149.4048, current episode: 6
[2023-06-29 15:12:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2756.7712, current episode: 7
[2023-06-29 15:12:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3112.6035, current episode: 8
[2023-06-29 15:12:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1650.2140, current episode: 8
[2023-06-29 15:12:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1711.0328, current episode: 8
[2023-06-29 15:12:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1723.4016, current episode: 8
[2023-06-29 15:12:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.3333, current episode: 9
[2023-06-29 15:12:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3523.4973, current episode: 10
[2023-06-29 15:12:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 620500.000000 | iteration_620500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.615960      | 6188.271202         | 6.188271             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2397.279675 | 724.800297 | 3532.333252 | 1650.213989 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1695.8732, current episode: 1
[2023-06-29 15:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1719.8289, current episode: 2
[2023-06-29 15:12:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1713.6521, current episode: 3
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1742.3273, current episode: 4
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2739.4617, current episode: 5
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3074.5542, current episode: 6
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3399.8267, current episode: 7
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1695.8732, current episode: 7
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1719.8289, current episode: 7
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1713.6521, current episode: 7
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1742.3273, current episode: 7
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3530.6226, current episode: 8
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3499.9580, current episode: 9
[2023-06-29 15:12:29][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3447.1541, current episode: 10
[2023-06-29 15:12:29][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 621000.000000 | iteration_621000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.530770      | 6532.659950         | 6.532660             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2656.325854 | 797.474911 | 3530.622559 | 1695.873169 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1755.4337, current episode: 1
[2023-06-29 15:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1825.9133, current episode: 2
[2023-06-29 15:12:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2013.3024, current episode: 3
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3043.4434, current episode: 4
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3468.9824, current episode: 5
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3467.2686, current episode: 6
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1755.4337, current episode: 6
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3503.7654, current episode: 7
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3500.6167, current episode: 8
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3589.1213, current episode: 9
[2023-06-29 15:12:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3494.5918, current episode: 10
[2023-06-29 15:12:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 621500.000000 | iteration_621500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.546551      | 6465.999671         | 6.466000             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2966.243896 | 736.604072 | 3589.121338 | 1755.433716 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:12:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1337.6202, current episode: 1
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1685.8275, current episode: 2
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1704.6305, current episode: 3
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1827.5980, current episode: 4
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2641.0352, current episode: 5
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2677.8682, current episode: 6
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1337.6202, current episode: 6
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 3014.8477, current episode: 7
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3134.7678, current episode: 8
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1685.8275, current episode: 8
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1704.6305, current episode: 8
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3508.7378, current episode: 9
[2023-06-29 15:13:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3467.9434, current episode: 10
[2023-06-29 15:13:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 622000.000000 | iteration_622000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.506169      | 6639.362504         | 6.639363             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2500.087622 | 759.785043 | 3508.737793 | 1337.620239 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1220.6840, current episode: 1
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1214.2377, current episode: 2
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1366.9934, current episode: 3
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1360.4005, current episode: 4
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1358.8419, current episode: 5
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1425.4028, current episode: 6
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1661.5975, current episode: 7
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2072.1660, current episode: 8
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2309.6230, current episode: 9
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1220.6840, current episode: 9
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1214.2377, current episode: 9
[2023-06-29 15:13:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2817.4148, current episode: 10
[2023-06-29 15:13:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 622500.000000 | iteration_622500.pth.tar | 10.000000     | 7730.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 773.000000              | 1.174269      | 6582.821254         | 8.515940             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1680.736169 | 513.833628 | 2817.414795 | 1214.237671 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1163.2522, current episode: 1
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1185.8018, current episode: 2
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1196.2448, current episode: 3
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1207.1155, current episode: 4
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1226.5282, current episode: 5
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1268.5771, current episode: 6
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1319.9854, current episode: 7
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1331.4431, current episode: 8
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1361.4985, current episode: 9
[2023-06-29 15:13:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1896.1465, current episode: 10
[2023-06-29 15:13:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 623000.000000 | iteration_623000.pth.tar | 10.000000     | 5440.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 544.000000              | 0.824716      | 6596.210550         | 12.125387            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1315.659302 | 203.869575 | 1896.146484 | 1163.252197 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1295.3623, current episode: 1
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1333.6211, current episode: 2
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1345.2173, current episode: 3
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1361.8466, current episode: 4
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2093.0356, current episode: 5
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2301.6162, current episode: 6
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2298.6775, current episode: 7
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2328.4363, current episode: 8
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2564.9470, current episode: 9
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1295.3623, current episode: 9
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1333.6211, current episode: 9
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1345.2173, current episode: 9
[2023-06-29 15:13:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1361.8466, current episode: 9
[2023-06-29 15:13:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3518.8257, current episode: 10
[2023-06-29 15:13:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 623500.000000 | iteration_623500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.517465      | 6589.936382         | 6.589936             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2044.158557 | 684.087623 | 3518.825684 | 1295.362305 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:14:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 517.3204, current episode: 1
[2023-06-29 15:14:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 519.4902, current episode: 2
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 533.0728, current episode: 3
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 517.3204, current episode: 3
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 519.4902, current episode: 3
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 533.0728, current episode: 3
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1659.1246, current episode: 4
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1668.2601, current episode: 5
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1655.1500, current episode: 6
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1748.5470, current episode: 7
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1766.6487, current episode: 8
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 517.3204, current episode: 8
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 519.4902, current episode: 8
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 533.0728, current episode: 8
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2434.4282, current episode: 9
[2023-06-29 15:14:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2524.2529, current episode: 10
[2023-06-29 15:14:01][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 624000.000000 | iteration_624000.pth.tar | 10.000000     | 7010.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 701.000000              | 1.207846      | 5803.719091         | 8.279200             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1502.629498 | 706.736779 | 2524.252930 | 517.320435 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1129.2333, current episode: 1
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1156.4678, current episode: 2
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1119.6787, current episode: 3
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1209.2263, current episode: 4
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1278.2240, current episode: 5
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1294.9243, current episode: 6
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1370.5853, current episode: 7
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1382.8121, current episode: 8
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1389.0015, current episode: 9
[2023-06-29 15:14:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1817.2043, current episode: 10
[2023-06-29 15:14:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 624500.000000 | iteration_624500.pth.tar | 10.000000     | 5200.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 520.000000              | 0.804528      | 6463.413505         | 12.429641            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1314.735767 | 193.935212 | 1817.204346 | 1119.678711 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1261.1511, current episode: 1
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1278.5229, current episode: 2
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1291.1406, current episode: 3
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1312.2722, current episode: 4
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1280.2906, current episode: 5
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1332.9336, current episode: 6
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1474.3326, current episode: 7
[2023-06-29 15:14:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1826.2847, current episode: 8
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1261.1511, current episode: 8
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1278.5229, current episode: 8
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1291.1406, current episode: 8
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1312.2722, current episode: 8
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1280.2906, current episode: 8
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2649.1575, current episode: 9
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1332.9336, current episode: 9
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1474.3326, current episode: 9
[2023-06-29 15:14:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3562.0356, current episode: 10
[2023-06-29 15:14:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 625000.000000 | iteration_625000.pth.tar | 10.000000     | 9999.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 999.900000              | 1.552999      | 6438.509154         | 6.439153             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1726.812158 | 736.640010 | 3562.035645 | 1261.151123 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1315.0173, current episode: 1
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1330.9178, current episode: 2
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1593.5488, current episode: 3
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1666.7869, current episode: 4
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1874.2213, current episode: 5
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1948.4019, current episode: 6
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2184.6777, current episode: 7
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 2646.5405, current episode: 8
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1315.0173, current episode: 8
[2023-06-29 15:14:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1330.9178, current episode: 8
[2023-06-29 15:14:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1593.5488, current episode: 8
[2023-06-29 15:14:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1666.7869, current episode: 8
[2023-06-29 15:14:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 3375.9707, current episode: 9
[2023-06-29 15:14:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3400.6956, current episode: 10
[2023-06-29 15:14:48][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 625500.000000 | iteration_625500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.520053      | 6578.715959         | 6.578716             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2133.677856 | 730.770458 | 3400.695557 | 1315.017334 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:15:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1191.9658, current episode: 1
[2023-06-29 15:15:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1294.9645, current episode: 2
[2023-06-29 15:15:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1426.3340, current episode: 3
[2023-06-29 15:15:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1410.7828, current episode: 4
[2023-06-29 15:15:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1535.4954, current episode: 5
[2023-06-29 15:15:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 2304.2109, current episode: 6
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2378.2908, current episode: 7
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 2442.7637, current episode: 8
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1191.9658, current episode: 8
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1294.9645, current episode: 8
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1426.3340, current episode: 8
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1410.7828, current episode: 8
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1535.4954, current episode: 8
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3615.1152, current episode: 9
[2023-06-29 15:15:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 3562.1428, current episode: 10
[2023-06-29 15:15:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 626000.000000 | iteration_626000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.509844      | 6623.201369         | 6.623201             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2116.206592 | 859.509396 | 3615.115234 | 1191.965820 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1326.7218, current episode: 1
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1279.0907, current episode: 2
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1357.0750, current episode: 3
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1344.3860, current episode: 4
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1416.2891, current episode: 5
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1579.0720, current episode: 6
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1672.6663, current episode: 7
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2225.4661, current episode: 8
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2223.6123, current episode: 9
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1326.7218, current episode: 9
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1279.0907, current episode: 9
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1357.0750, current episode: 9
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1344.3860, current episode: 9
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1416.2891, current episode: 9
[2023-06-29 15:15:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1579.0720, current episode: 9
[2023-06-29 15:15:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1672.6663, current episode: 9
[2023-06-29 15:15:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3437.9873, current episode: 10
[2023-06-29 15:15:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 626500.000000 | iteration_626500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.529143      | 6539.610987         | 6.539611             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1786.236646 | 644.433044 | 3437.987305 | 1279.090698 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1233.3158, current episode: 1
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1276.6676, current episode: 2
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1293.3751, current episode: 3
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1296.3311, current episode: 4
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1296.4545, current episode: 5
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1306.3195, current episode: 6
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1349.8788, current episode: 7
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1896.5396, current episode: 8
[2023-06-29 15:15:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1905.8129, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1233.3158, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1276.6676, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1293.3751, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1296.3311, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1296.4545, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1306.3195, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1349.8788, current episode: 9
[2023-06-29 15:15:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 2834.9712, current episode: 10
[2023-06-29 15:15:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 627000.000000 | iteration_627000.pth.tar | 10.000000     | 8080.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 808.000000              | 1.231669      | 6560.202422         | 8.119062             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1568.966589 | 486.123842 | 2834.971191 | 1233.315796 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 978.2313, current episode: 1
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1293.7533, current episode: 2
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1338.4772, current episode: 3
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1376.5807, current episode: 4
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1467.2275, current episode: 5
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1764.2574, current episode: 6
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1784.8971, current episode: 7
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 2111.1157, current episode: 8
[2023-06-29 15:15:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 978.2313, current episode: 8
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1293.7533, current episode: 8
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2571.4502, current episode: 9
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1338.4772, current episode: 9
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1376.5807, current episode: 9
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1467.2275, current episode: 9
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 978.2313, current episode: 9
[2023-06-29 15:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3547.1655, current episode: 10
[2023-06-29 15:15:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 627500.000000 | iteration_627500.pth.tar | 10.000000     | 9870.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 987.000000              | 1.551887      | 6360.000802         | 6.443770             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min |
+-------+-------------+------------+-------------+------------+
| Value | 1823.315601 | 719.388592 | 3547.165527 | 978.231323 |
+-------+-------------+------------+-------------+------------+


[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1000.1870, current episode: 1
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1021.7163, current episode: 2
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1099.8025, current episode: 3
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1266.3430, current episode: 4
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1320.6927, current episode: 5
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1000.1870, current episode: 5
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1021.7163, current episode: 5
[2023-06-29 15:16:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1099.8025, current episode: 5
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 2478.3103, current episode: 6
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1266.3430, current episode: 6
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 2659.0305, current episode: 7
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1320.6927, current episode: 7
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1000.1870, current episode: 7
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1021.7163, current episode: 7
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1099.8025, current episode: 7
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 3295.3374, current episode: 8
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 3383.3191, current episode: 9
[2023-06-29 15:16:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3394.1660, current episode: 10
[2023-06-29 15:16:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 628000.000000 | iteration_628000.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.526233      | 6552.078345         | 6.552078             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 2091.890485 | 994.010287 | 3394.166016 | 1000.186951 |
+-------+-------------+------------+-------------+-------------+


[2023-06-29 15:16:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1022.4521, current episode: 1
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1128.6782, current episode: 2
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.3174, current episode: 3
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1262.4844, current episode: 4
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1022.4521, current episode: 4
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1128.6782, current episode: 4
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1176.3174, current episode: 4
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1262.4844, current episode: 4
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 2981.8181, current episode: 5
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 3151.4487, current episode: 6
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 3009.3374, current episode: 7
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 3068.9084, current episode: 8
[2023-06-29 15:16:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1022.4521, current episode: 8
[2023-06-29 15:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 3495.0769, current episode: 9
[2023-06-29 15:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1128.6782, current episode: 9
[2023-06-29 15:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 3532.4824, current episode: 10
[2023-06-29 15:16:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 628500.000000 | iteration_628500.pth.tar | 10.000000     | 10000.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 1000.000000             | 1.610659      | 6208.639073         | 6.208639             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+-------------+-------------+-------------+
| Name  | reward_mean | reward_std  | reward_max  | reward_min  |
+-------+-------------+-------------+-------------+-------------+
| Value | 2382.900415 | 1024.984980 | 3532.482422 | 1022.452148 |
+-------+-------------+-------------+-------------+-------------+


[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1002.7173, current episode: 1
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1157.1646, current episode: 2
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1163.9830, current episode: 3
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1221.2809, current episode: 4
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 8 finish episode, final reward: 1248.3270, current episode: 5
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 9 finish episode, final reward: 1268.8195, current episode: 6
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1266.1611, current episode: 7
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1314.4465, current episode: 8
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1541.2117, current episode: 9
[2023-06-29 15:16:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1555.5007, current episode: 10
[2023-06-29 15:16:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 629000.000000 | iteration_629000.pth.tar | 10.000000     | 4510.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 451.000000              | 0.719284      | 6270.124209         | 13.902714            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1273.961237 | 159.735992 | 1555.500732 | 1002.717346 |
+-------+-------------+------------+-------------+-------------+


